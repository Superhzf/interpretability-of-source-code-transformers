#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=8
#SBATCH --mem=128G
#SBATCH --time=1-10:00:00
#SBATCH --partition=gpu #specify the gpu partition
#SBATCH --gres=gpu:1

#Run experiments after extraction-- details in example_config.json

module load ml-gpu

cd /work/LAS/jannesar-lab/arushi/Redundancy/analyzing-redundancy-in-pretrained-transformer-models/experiments/classification/

CUDA_LAUNCH_BLOCKING=1 ml-gpu /work/LAS/jannesar-lab/arushi/Environments/aux_classifier_env/bin/python run_sentence_pipeline_all.py --config config_clonedet_codebert.json > Results/CodeBERT_CloneDet/output_codebert_clonedet_sentence_pipeline_all1

CUDA_LAUNCH_BLOCKING=1 ml-gpu /work/LAS/jannesar-lab/arushi/Environments/aux_classifier_env/bin/python run_sentence_pipeline_all.py --config config_clondet_graphcodebert.json > Results/GraphCodeBERT_CloneDet/output_graphcodebert_clonedet_sentence_pipeline_all1

CUDA_LAUNCH_BLOCKING=1 ml-gpu /work/LAS/jannesar-lab/arushi/Environments/aux_classifier_env/bin/python run_sentence_pipeline_all.py --config config_defdet_codebert.json > Results/CodeBERT1_DefDet/output_codebert_defdet_sentence_pipeline_all1

CUDA_LAUNCH_BLOCKING=1 ml-gpu /work/LAS/jannesar-lab/arushi/Environments/aux_classifier_env/bin/python run_sentence_pipeline_all.py --config config_defdet_graphcodebert.json > Results/GraphCodeBERT_DefDet/output_graphcodebert_defdet_sentence_pipeline_all1
