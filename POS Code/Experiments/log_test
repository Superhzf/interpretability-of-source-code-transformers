Loading model: bert-base-uncased
Reading input corpus
Preparing output file
Extracting representations from model
Sentence         : "\n"
Original    (001): ['\\n']
Tokenized   (004): ['[CLS]', '\\', 'n', '[SEP]']
Filtered   (002): ['\\', 'n']
Detokenized (001): ['\\n']
Counter: 2
===================================================================
Hidden states:  (13, 1, 768)
# Extracted words:  1
Sentence         : "# \n"
Original    (002): ['#', '\\n']
Tokenized   (005): ['[CLS]', '#', '\\', 'n', '[SEP]']
Filtered   (003): ['#', '\\', 'n']
Detokenized (002): ['#', '\\n']
Counter: 3
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "template_name = \n"
Original    (003): ['template_name', '=', '\\n']
Tokenized   (008): ['[CLS]', 'template', '_', 'name', '=', '\\', 'n', '[SEP]']
Filtered   (006): ['template', '_', 'name', '=', '\\', 'n']
Detokenized (003): ['template_name', '=', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "slug = "policy_profile" \n"
Original    (004): ['slug', '=', '"policy_profile"', '\\n']
Tokenized   (011): ['[CLS]', 'slug', '=', '"', 'policy', '_', 'profile', '"', '\\', 'n', '[SEP]']
Filtered   (009): ['slug', '=', '"', 'policy', '_', 'profile', '"', '\\', 'n']
Detokenized (004): ['slug', '=', '"policy_profile"', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "preload = False \n"
Original    (004): ['preload', '=', 'False', '\\n']
Tokenized   (008): ['[CLS]', 'pre', '##load', '=', 'false', '\\', 'n', '[SEP]']
Filtered   (006): ['pre', '##load', '=', 'false', '\\', 'n']
Detokenized (004): ['pre##load', '=', 'false', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "tabs = ( NetworkProfileTab , PolicyProfileTab ) \n"
Original    (008): ['tabs', '=', '(', 'NetworkProfileTab', ',', 'PolicyProfileTab', ')', '\\n']
Tokenized   (020): ['[CLS]', 'tab', '##s', '=', '(', 'network', '##pro', '##fi', '##let', '##ab', ',', 'policy', '##pro', '##fi', '##let', '##ab', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['tab', '##s', '=', '(', 'network', '##pro', '##fi', '##let', '##ab', ',', 'policy', '##pro', '##fi', '##let', '##ab', ')', '\\', 'n']
Detokenized (008): ['tab##s', '=', '(', 'network##pro##fi##let##ab', ',', 'policy##pro##fi##let##ab', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "weak_store = WeakLocal ( ) \n"
Original    (006): ['weak_store', '=', 'WeakLocal', '(', ')', '\\n']
Tokenized   (013): ['[CLS]', 'weak', '_', 'store', '=', 'weak', '##lo', '##cal', '(', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['weak', '_', 'store', '=', 'weak', '##lo', '##cal', '(', ')', '\\', 'n']
Detokenized (006): ['weak_store', '=', 'weak##lo##cal', '(', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "strong_store = corolocal . local \n"
Original    (006): ['strong_store', '=', 'corolocal', '.', 'local', '\\n']
Tokenized   (014): ['[CLS]', 'strong', '_', 'store', '=', 'co', '##rol', '##oca', '##l', '.', 'local', '\\', 'n', '[SEP]']
Filtered   (012): ['strong', '_', 'store', '=', 'co', '##rol', '##oca', '##l', '.', 'local', '\\', 'n']
Detokenized (006): ['strong_store', '=', 'co##rol##oca##l', '.', 'local', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "eventlet . monkey_patch ( ) \n"
Original    (006): ['eventlet', '.', 'monkey_patch', '(', ')', '\\n']
Tokenized   (012): ['[CLS]', 'event', '##let', '.', 'monkey', '_', 'patch', '(', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['event', '##let', '.', 'monkey', '_', 'patch', '(', ')', '\\', 'n']
Detokenized (006): ['event##let', '.', 'monkey_patch', '(', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "CONF . register_opts ( impl_zmq . zmq_opts ) \n"
Original    (009): ['CONF', '.', 'register_opts', '(', 'impl_zmq', '.', 'zmq_opts', ')', '\\n']
Tokenized   (026): ['[CLS]', 'con', '##f', '.', 'register', '_', 'opt', '##s', '(', 'imp', '##l', '_', 'z', '##m', '##q', '.', 'z', '##m', '##q', '_', 'opt', '##s', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['con', '##f', '.', 'register', '_', 'opt', '##s', '(', 'imp', '##l', '_', 'z', '##m', '##q', '.', 'z', '##m', '##q', '_', 'opt', '##s', ')', '\\', 'n']
Detokenized (009): ['con##f', '.', 'register_opt##s', '(', 'imp##l_z##m##q', '.', 'z##m##q_opt##s', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "vpnservices_dict = { : self . api_vpnservices . list ( ) } \n"
Original    (013): ['vpnservices_dict', '=', '{', ':', 'self', '.', 'api_vpnservices', '.', 'list', '(', ')', '}', '\\n']
Tokenized   (029): ['[CLS]', 'vp', '##nse', '##r', '##vic', '##es', '_', 'di', '##ct', '=', '{', ':', 'self', '.', 'api', '_', 'vp', '##nse', '##r', '##vic', '##es', '.', 'list', '(', ')', '}', '\\', 'n', '[SEP]']
Filtered   (027): ['vp', '##nse', '##r', '##vic', '##es', '_', 'di', '##ct', '=', '{', ':', 'self', '.', 'api', '_', 'vp', '##nse', '##r', '##vic', '##es', '.', 'list', '(', ')', '}', '\\', 'n']
Detokenized (013): ['vp##nse##r##vic##es_di##ct', '=', '{', ':', 'self', '.', 'api_vp##nse##r##vic##es', '.', 'list', '(', ')', '}', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "vpnservice [ ] [ ] ) \n"
Original    (007): ['vpnservice', '[', ']', '[', ']', ')', '\\n']
Tokenized   (014): ['[CLS]', 'vp', '##nse', '##r', '##vic', '##e', '[', ']', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['vp', '##nse', '##r', '##vic', '##e', '[', ']', '[', ']', ')', '\\', 'n']
Detokenized (007): ['vp##nse##r##vic##e', '[', ']', '[', ']', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "form_data } ) . AndReturn ( ipsecsiteconnection ) \n"
Original    (009): ['form_data', '}', ')', '.', 'AndReturn', '(', 'ipsecsiteconnection', ')', '\\n']
Tokenized   (021): ['[CLS]', 'form', '_', 'data', '}', ')', '.', 'andre', '##turn', '(', 'ip', '##se', '##cs', '##ite', '##con', '##ne', '##ction', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['form', '_', 'data', '}', ')', '.', 'andre', '##turn', '(', 'ip', '##se', '##cs', '##ite', '##con', '##ne', '##ction', ')', '\\', 'n']
Detokenized (009): ['form_data', '}', ')', '.', 'andre##turn', '(', 'ip##se##cs##ite##con##ne##ction', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "ipsecsiteconnections_dict ) \n"
Original    (003): ['ipsecsiteconnections_dict', ')', '\\n']
Tokenized   (015): ['[CLS]', 'ip', '##se', '##cs', '##ite', '##con', '##ne', '##ctions', '_', 'di', '##ct', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['ip', '##se', '##cs', '##ite', '##con', '##ne', '##ctions', '_', 'di', '##ct', ')', '\\', 'n']
Detokenized (003): ['ip##se##cs##ite##con##ne##ctions_di##ct', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "ipsecsiteconnections [ ] ) : \n"
Original    (006): ['ipsecsiteconnections', '[', ']', ')', ':', '\\n']
Tokenized   (015): ['[CLS]', 'ip', '##se', '##cs', '##ite', '##con', '##ne', '##ctions', '[', ']', ')', ':', '\\', 'n', '[SEP]']
Filtered   (013): ['ip', '##se', '##cs', '##ite', '##con', '##ne', '##ctions', '[', ']', ')', ':', '\\', 'n']
Detokenized (006): ['ip##se##cs##ite##con##ne##ctions', '[', ']', ')', ':', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "neutronclient . show_ipsec_site_connection ( \n"
Original    (005): ['neutronclient', '.', 'show_ipsec_site_connection', '(', '\\n']
Tokenized   (018): ['[CLS]', 'neutron', '##cl', '##ient', '.', 'show', '_', 'ip', '##se', '##c', '_', 'site', '_', 'connection', '(', '\\', 'n', '[SEP]']
Filtered   (016): ['neutron', '##cl', '##ient', '.', 'show', '_', 'ip', '##se', '##c', '_', 'site', '_', 'connection', '(', '\\', 'n']
Detokenized (005): ['neutron##cl##ient', '.', 'show_ip##se##c_site_connection', '(', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "ret_val = api . vpn . ipsecsiteconnection_get ( self . request , \n"
Original    (013): ['ret_val', '=', 'api', '.', 'vpn', '.', 'ipsecsiteconnection_get', '(', 'self', '.', 'request', ',', '\\n']
Tokenized   (028): ['[CLS]', 're', '##t', '_', 'val', '=', 'api', '.', 'vp', '##n', '.', 'ip', '##se', '##cs', '##ite', '##con', '##ne', '##ction', '_', 'get', '(', 'self', '.', 'request', ',', '\\', 'n', '[SEP]']
Filtered   (026): ['re', '##t', '_', 'val', '=', 'api', '.', 'vp', '##n', '.', 'ip', '##se', '##cs', '##ite', '##con', '##ne', '##ction', '_', 'get', '(', 'self', '.', 'request', ',', '\\', 'n']
Detokenized (013): ['re##t_val', '=', 'api', '.', 'vp##n', '.', 'ip##se##cs##ite##con##ne##ction_get', '(', 'self', '.', 'request', ',', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "response_kwargs . setdefault ( "filename" , "usage.csv" ) \n"
Original    (009): ['response_kwargs', '.', 'setdefault', '(', '"filename"', ',', '"usage.csv"', ')', '\\n']
Tokenized   (027): ['[CLS]', 'response', '_', 'kw', '##ar', '##gs', '.', 'set', '##de', '##fa', '##ult', '(', '"', 'file', '##name', '"', ',', '"', 'usage', '.', 'cs', '##v', '"', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['response', '_', 'kw', '##ar', '##gs', '.', 'set', '##de', '##fa', '##ult', '(', '"', 'file', '##name', '"', ',', '"', 'usage', '.', 'cs', '##v', '"', ')', '\\', 'n']
Detokenized (009): ['response_kw##ar##gs', '.', 'set##de##fa##ult', '(', '"file##name"', ',', '"usage.cs##v"', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "BlendProbes = 1 \n"
Original    (004): ['BlendProbes', '=', '1', '\\n']
Tokenized   (009): ['[CLS]', 'blend', '##pro', '##bes', '=', '1', '\\', 'n', '[SEP]']
Filtered   (007): ['blend', '##pro', '##bes', '=', '1', '\\', 'n']
Detokenized (004): ['blend##pro##bes', '=', '1', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "lightmap_index = field ( "m_LightmapIndex" ) \n"
Original    (007): ['lightmap_index', '=', 'field', '(', '"m_LightmapIndex"', ')', '\\n']
Tokenized   (022): ['[CLS]', 'light', '##ma', '##p', '_', 'index', '=', 'field', '(', '"', 'm', '_', 'light', '##ma', '##pin', '##de', '##x', '"', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['light', '##ma', '##p', '_', 'index', '=', 'field', '(', '"', 'm', '_', 'light', '##ma', '##pin', '##de', '##x', '"', ')', '\\', 'n']
Detokenized (007): ['light##ma##p_index', '=', 'field', '(', '"m_light##ma##pin##de##x"', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "receive_shadows = field ( "m_ReceiveShadows" , bool ) \n"
Original    (009): ['receive_shadows', '=', 'field', '(', '"m_ReceiveShadows"', ',', 'bool', ')', '\\n']
Tokenized   (021): ['[CLS]', 'receive', '_', 'shadows', '=', 'field', '(', '"', 'm', '_', 'receives', '##had', '##ows', '"', ',', 'boo', '##l', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['receive', '_', 'shadows', '=', 'field', '(', '"', 'm', '_', 'receives', '##had', '##ows', '"', ',', 'boo', '##l', ')', '\\', 'n']
Detokenized (009): ['receive_shadows', '=', 'field', '(', '"m_receives##had##ows"', ',', 'boo##l', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "Config . parser . readfp ( sconf ) \n"
Original    (009): ['Config', '.', 'parser', '.', 'readfp', '(', 'sconf', ')', '\\n']
Tokenized   (018): ['[CLS]', 'con', '##fi', '##g', '.', 'par', '##ser', '.', 'read', '##fp', '(', 'sc', '##on', '##f', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['con', '##fi', '##g', '.', 'par', '##ser', '.', 'read', '##fp', '(', 'sc', '##on', '##f', ')', '\\', 'n']
Detokenized (009): ['con##fi##g', '.', 'par##ser', '.', 'read##fp', '(', 'sc##on##f', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "BBS_XMPP_CERT_FILE = BBS_ROOT + "xmpp.crt" \n"
Original    (006): ['BBS_XMPP_CERT_FILE', '=', 'BBS_ROOT', '+', '"xmpp.crt"', '\\n']
Tokenized   (029): ['[CLS]', 'bb', '##s', '_', 'x', '##mp', '##p', '_', 'ce', '##rt', '_', 'file', '=', 'bb', '##s', '_', 'root', '+', '"', 'x', '##mp', '##p', '.', 'cr', '##t', '"', '\\', 'n', '[SEP]']
Filtered   (027): ['bb', '##s', '_', 'x', '##mp', '##p', '_', 'ce', '##rt', '_', 'file', '=', 'bb', '##s', '_', 'root', '+', '"', 'x', '##mp', '##p', '.', 'cr', '##t', '"', '\\', 'n']
Detokenized (006): ['bb##s_x##mp##p_ce##rt_file', '=', 'bb##s_root', '+', '"x##mp##p.cr##t"', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "BOARDS_FILE = BBS_ROOT + \n"
Original    (005): ['BOARDS_FILE', '=', 'BBS_ROOT', '+', '\\n']
Tokenized   (013): ['[CLS]', 'boards', '_', 'file', '=', 'bb', '##s', '_', 'root', '+', '\\', 'n', '[SEP]']
Filtered   (011): ['boards', '_', 'file', '=', 'bb', '##s', '_', 'root', '+', '\\', 'n']
Detokenized (005): ['boards_file', '=', 'bb##s_root', '+', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "USHM_SIZE = MAXACTIVE + 10 \n"
Original    (006): ['USHM_SIZE', '=', 'MAXACTIVE', '+', '10', '\\n']
Tokenized   (013): ['[CLS]', 'us', '##hm', '_', 'size', '=', 'max', '##active', '+', '10', '\\', 'n', '[SEP]']
Filtered   (011): ['us', '##hm', '_', 'size', '=', 'max', '##active', '+', '10', '\\', 'n']
Detokenized (006): ['us##hm_size', '=', 'max##active', '+', '10', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "UTMP_HASHSIZE = USHM_SIZE * 4 \n"
Original    (006): ['UTMP_HASHSIZE', '=', 'USHM_SIZE', '*', '4', '\\n']
Tokenized   (017): ['[CLS]', 'ut', '##mp', '_', 'hash', '##si', '##ze', '=', 'us', '##hm', '_', 'size', '*', '4', '\\', 'n', '[SEP]']
Filtered   (015): ['ut', '##mp', '_', 'hash', '##si', '##ze', '=', 'us', '##hm', '_', 'size', '*', '4', '\\', 'n']
Detokenized (006): ['ut##mp_hash##si##ze', '=', 'us##hm_size', '*', '4', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "SESSION_TIMEOUT = datetime . timedelta ( 30 ) \n"
Original    (009): ['SESSION_TIMEOUT', '=', 'datetime', '.', 'timedelta', '(', '30', ')', '\\n']
Tokenized   (018): ['[CLS]', 'session', '_', 'time', '##out', '=', 'date', '##time', '.', 'timed', '##elt', '##a', '(', '30', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['session', '_', 'time', '##out', '=', 'date', '##time', '.', 'timed', '##elt', '##a', '(', '30', ')', '\\', 'n']
Detokenized (009): ['session_time##out', '=', 'date##time', '.', 'timed##elt##a', '(', '30', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "SESSION_TIMEOUT_SECONDS = 86400 * 30 \n"
Original    (006): ['SESSION_TIMEOUT_SECONDS', '=', '86400', '*', '30', '\\n']
Tokenized   (015): ['[CLS]', 'session', '_', 'time', '##out', '_', 'seconds', '=', '86', '##400', '*', '30', '\\', 'n', '[SEP]']
Filtered   (013): ['session', '_', 'time', '##out', '_', 'seconds', '=', '86', '##400', '*', '30', '\\', 'n']
Detokenized (006): ['session_time##out_seconds', '=', '86##400', '*', '30', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "MAX_ATTACHSIZE = 20 * 1024 * 1024 \n"
Original    (008): ['MAX_ATTACHSIZE', '=', '20', '*', '1024', '*', '1024', '\\n']
Tokenized   (017): ['[CLS]', 'max', '_', 'attach', '##si', '##ze', '=', '20', '*', '102', '##4', '*', '102', '##4', '\\', 'n', '[SEP]']
Filtered   (015): ['max', '_', 'attach', '##si', '##ze', '=', '20', '*', '102', '##4', '*', '102', '##4', '\\', 'n']
Detokenized (008): ['max_attach##si##ze', '=', '20', '*', '102##4', '*', '102##4', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "MAIL_SIZE_LIMIT = - 1 \n"
Original    (005): ['MAIL_SIZE_LIMIT', '=', '-', '1', '\\n']
Tokenized   (012): ['[CLS]', 'mail', '_', 'size', '_', 'limit', '=', '-', '1', '\\', 'n', '[SEP]']
Filtered   (010): ['mail', '_', 'size', '_', 'limit', '=', '-', '1', '\\', 'n']
Detokenized (005): ['mail_size_limit', '=', '-', '1', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "newparts = [ ] \n"
Original    (005): ['newparts', '=', '[', ']', '\\n']
Tokenized   (009): ['[CLS]', 'new', '##parts', '=', '[', ']', '\\', 'n', '[SEP]']
Filtered   (007): ['new', '##parts', '=', '[', ']', '\\', 'n']
Detokenized (005): ['new##parts', '=', '[', ']', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "firstitem = self . GetItem ( user , route + [ start ] , has_perm , need_perm ) \n"
Original    (019): ['firstitem', '=', 'self', '.', 'GetItem', '(', 'user', ',', 'route', '+', '[', 'start', ']', ',', 'has_perm', ',', 'need_perm', ')', '\\n']
Tokenized   (032): ['[CLS]', 'first', '##ite', '##m', '=', 'self', '.', 'get', '##ite', '##m', '(', 'user', ',', 'route', '+', '[', 'start', ']', ',', 'has', '_', 'per', '##m', ',', 'need', '_', 'per', '##m', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['first', '##ite', '##m', '=', 'self', '.', 'get', '##ite', '##m', '(', 'user', ',', 'route', '+', '[', 'start', ']', ',', 'has', '_', 'per', '##m', ',', 'need', '_', 'per', '##m', ')', '\\', 'n']
Detokenized (019): ['first##ite##m', '=', 'self', '.', 'get##ite##m', '(', 'user', ',', 'route', '+', '[', 'start', ']', ',', 'has_per##m', ',', 'need_per##m', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "_id = start - 1 \n"
Original    (006): ['_id', '=', 'start', '-', '1', '\\n']
Tokenized   (010): ['[CLS]', '_', 'id', '=', 'start', '-', '1', '\\', 'n', '[SEP]']
Filtered   (008): ['_', 'id', '=', 'start', '-', '1', '\\', 'n']
Detokenized (006): ['_id', '=', 'start', '-', '1', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "linkfile = "%s/boards/xattach/%s" % ( Config . BBS_ROOT , filename ) \n"
Original    (012): ['linkfile', '=', '"%s/boards/xattach/%s"', '%', '(', 'Config', '.', 'BBS_ROOT', ',', 'filename', ')', '\\n']
Tokenized   (035): ['[CLS]', 'link', '##fi', '##le', '=', '"', '%', 's', '/', 'boards', '/', 'x', '##att', '##ach', '/', '%', 's', '"', '%', '(', 'con', '##fi', '##g', '.', 'bb', '##s', '_', 'root', ',', 'file', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (033): ['link', '##fi', '##le', '=', '"', '%', 's', '/', 'boards', '/', 'x', '##att', '##ach', '/', '%', 's', '"', '%', '(', 'con', '##fi', '##g', '.', 'bb', '##s', '_', 'root', ',', 'file', '##name', ')', '\\', 'n']
Detokenized (012): ['link##fi##le', '=', '"%s/boards/x##att##ach/%s"', '%', '(', 'con##fi##g', '.', 'bb##s_root', ',', 'file##name', ')', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "boardname = svc . get_str ( params , , ) \n"
Original    (011): ['boardname', '=', 'svc', '.', 'get_str', '(', 'params', ',', ',', ')', '\\n']
Tokenized   (020): ['[CLS]', 'board', '##name', '=', 'sv', '##c', '.', 'get', '_', 'st', '##r', '(', 'para', '##ms', ',', ',', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['board', '##name', '=', 'sv', '##c', '.', 'get', '_', 'st', '##r', '(', 'para', '##ms', ',', ',', ')', '\\', 'n']
Detokenized (011): ['board##name', '=', 'sv##c', '.', 'get_st##r', '(', 'para##ms', ',', ',', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "has_perm = user . IsDigestMgr ( ) \n"
Original    (008): ['has_perm', '=', 'user', '.', 'IsDigestMgr', '(', ')', '\\n']
Tokenized   (018): ['[CLS]', 'has', '_', 'per', '##m', '=', 'user', '.', 'is', '##di', '##ges', '##tm', '##gr', '(', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['has', '_', 'per', '##m', '=', 'user', '.', 'is', '##di', '##ges', '##tm', '##gr', '(', ')', '\\', 'n']
Detokenized (008): ['has_per##m', '=', 'user', '.', 'is##di##ges##tm##gr', '(', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Digest . View ( svc , basenode , route , session , has_perm , start , count ) \n"
Original    (019): ['Digest', '.', 'View', '(', 'svc', ',', 'basenode', ',', 'route', ',', 'session', ',', 'has_perm', ',', 'start', ',', 'count', ')', '\\n']
Tokenized   (028): ['[CLS]', 'digest', '.', 'view', '(', 'sv', '##c', ',', 'base', '##no', '##de', ',', 'route', ',', 'session', ',', 'has', '_', 'per', '##m', ',', 'start', ',', 'count', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['digest', '.', 'view', '(', 'sv', '##c', ',', 'base', '##no', '##de', ',', 'route', ',', 'session', ',', 'has', '_', 'per', '##m', ',', 'start', ',', 'count', ')', '\\', 'n']
Detokenized (019): ['digest', '.', 'view', '(', 'sv##c', ',', 'base##no##de', ',', 'route', ',', 'session', ',', 'has_per##m', ',', 'start', ',', 'count', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "svc . writedata ( json . dumps ( result ) ) \n"
Original    (012): ['svc', '.', 'writedata', '(', 'json', '.', 'dumps', '(', 'result', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'sv', '##c', '.', 'write', '##da', '##ta', '(', 'j', '##son', '.', 'dump', '##s', '(', 'result', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['sv', '##c', '.', 'write', '##da', '##ta', '(', 'j', '##son', '.', 'dump', '##s', '(', 'result', ')', ')', '\\', 'n']
Detokenized (012): ['sv##c', '.', 'write##da##ta', '(', 'j##son', '.', 'dump##s', '(', 'result', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "postinfo = Post . Post ( item . realpath ( ) , None ) \n"
Original    (015): ['postinfo', '=', 'Post', '.', 'Post', '(', 'item', '.', 'realpath', '(', ')', ',', 'None', ')', '\\n']
Tokenized   (021): ['[CLS]', 'post', '##in', '##fo', '=', 'post', '.', 'post', '(', 'item', '.', 'real', '##path', '(', ')', ',', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['post', '##in', '##fo', '=', 'post', '.', 'post', '(', 'item', '.', 'real', '##path', '(', ')', ',', 'none', ')', '\\', 'n']
Detokenized (015): ['post##in##fo', '=', 'post', '.', 'post', '(', 'item', '.', 'real##path', '(', ')', ',', 'none', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "msg_count = msgbox . GetMsgCount ( all = False ) \n"
Original    (011): ['msg_count', '=', 'msgbox', '.', 'GetMsgCount', '(', 'all', '=', 'False', ')', '\\n']
Tokenized   (022): ['[CLS]', 'ms', '##g', '_', 'count', '=', 'ms', '##gb', '##ox', '.', 'get', '##ms', '##gc', '##ount', '(', 'all', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['ms', '##g', '_', 'count', '=', 'ms', '##gb', '##ox', '.', 'get', '##ms', '##gc', '##ount', '(', 'all', '=', 'false', ')', '\\', 'n']
Detokenized (011): ['ms##g_count', '=', 'ms##gb##ox', '.', 'get##ms##gc##ount', '(', 'all', '=', 'false', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "xmpp_read = self . rosters . get_xmpp_read ( self . _user . GetUID ( ) ) \n"
Original    (017): ['xmpp_read', '=', 'self', '.', 'rosters', '.', 'get_xmpp_read', '(', 'self', '.', '_user', '.', 'GetUID', '(', ')', ')', '\\n']
Tokenized   (033): ['[CLS]', 'x', '##mp', '##p', '_', 'read', '=', 'self', '.', 'roster', '##s', '.', 'get', '_', 'x', '##mp', '##p', '_', 'read', '(', 'self', '.', '_', 'user', '.', 'get', '##uid', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['x', '##mp', '##p', '_', 'read', '=', 'self', '.', 'roster', '##s', '.', 'get', '_', 'x', '##mp', '##p', '_', 'read', '(', 'self', '.', '_', 'user', '.', 'get', '##uid', '(', ')', ')', '\\', 'n']
Detokenized (017): ['x##mp##p_read', '=', 'self', '.', 'roster##s', '.', 'get_x##mp##p_read', '(', 'self', '.', '_user', '.', 'get##uid', '(', ')', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "read_count = msg_count - msg_unread \n"
Original    (006): ['read_count', '=', 'msg_count', '-', 'msg_unread', '\\n']
Tokenized   (019): ['[CLS]', 'read', '_', 'count', '=', 'ms', '##g', '_', 'count', '-', 'ms', '##g', '_', 'un', '##rea', '##d', '\\', 'n', '[SEP]']
Filtered   (017): ['read', '_', 'count', '=', 'ms', '##g', '_', 'count', '-', 'ms', '##g', '_', 'un', '##rea', '##d', '\\', 'n']
Detokenized (006): ['read_count', '=', 'ms##g_count', '-', 'ms##g_un##rea##d', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "term_read = self . rosters . get_term_read ( self . get_uid ( ) ) \n"
Original    (015): ['term_read', '=', 'self', '.', 'rosters', '.', 'get_term_read', '(', 'self', '.', 'get_uid', '(', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'term', '_', 'read', '=', 'self', '.', 'roster', '##s', '.', 'get', '_', 'term', '_', 'read', '(', 'self', '.', 'get', '_', 'ui', '##d', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['term', '_', 'read', '=', 'self', '.', 'roster', '##s', '.', 'get', '_', 'term', '_', 'read', '(', 'self', '.', 'get', '_', 'ui', '##d', '(', ')', ')', '\\', 'n']
Detokenized (015): ['term_read', '=', 'self', '.', 'roster##s', '.', 'get_term_read', '(', 'self', '.', 'get_ui##d', '(', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "new_unread [ msghead . topid ] = i \n"
Original    (009): ['new_unread', '[', 'msghead', '.', 'topid', ']', '=', 'i', '\\n']
Tokenized   (019): ['[CLS]', 'new', '_', 'un', '##rea', '##d', '[', 'ms', '##gh', '##ead', '.', 'top', '##id', ']', '=', 'i', '\\', 'n', '[SEP]']
Filtered   (017): ['new', '_', 'un', '##rea', '##d', '[', 'ms', '##gh', '##ead', '.', 'top', '##id', ']', '=', 'i', '\\', 'n']
Detokenized (009): ['new_un##rea##d', '[', 'ms##gh##ead', '.', 'top##id', ']', '=', 'i', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "to_steal = { } \n"
Original    (005): ['to_steal', '=', '{', '}', '\\n']
Tokenized   (010): ['[CLS]', 'to', '_', 'steal', '=', '{', '}', '\\', 'n', '[SEP]']
Filtered   (008): ['to', '_', 'steal', '=', '{', '}', '\\', 'n']
Detokenized (005): ['to_steal', '=', '{', '}', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "to_steal_begin = msg_count \n"
Original    (004): ['to_steal_begin', '=', 'msg_count', '\\n']
Tokenized   (014): ['[CLS]', 'to', '_', 'steal', '_', 'begin', '=', 'ms', '##g', '_', 'count', '\\', 'n', '[SEP]']
Filtered   (012): ['to', '_', 'steal', '_', 'begin', '=', 'ms', '##g', '_', 'count', '\\', 'n']
Detokenized (004): ['to_steal_begin', '=', 'ms##g_count', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "pass \n"
Original    (002): ['pass', '\\n']
Tokenized   (005): ['[CLS]', 'pass', '\\', 'n', '[SEP]']
Filtered   (003): ['pass', '\\', 'n']
Detokenized (002): ['pass', '\\n']
Counter: 3
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "final_unread [ pid ] = ( new_unread [ pid ] , 1 ) \n"
Original    (014): ['final_unread', '[', 'pid', ']', '=', '(', 'new_unread', '[', 'pid', ']', ',', '1', ')', '\\n']
Tokenized   (027): ['[CLS]', 'final', '_', 'un', '##rea', '##d', '[', 'pi', '##d', ']', '=', '(', 'new', '_', 'un', '##rea', '##d', '[', 'pi', '##d', ']', ',', '1', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['final', '_', 'un', '##rea', '##d', '[', 'pi', '##d', ']', '=', '(', 'new', '_', 'un', '##rea', '##d', '[', 'pi', '##d', ']', ',', '1', ')', '\\', 'n']
Detokenized (014): ['final_un##rea##d', '[', 'pi##d', ']', '=', '(', 'new_un##rea##d', '[', 'pi##d', ']', ',', '1', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "msgtext = msgbox . LoadMsgText ( msghead ) \n"
Original    (009): ['msgtext', '=', 'msgbox', '.', 'LoadMsgText', '(', 'msghead', ')', '\\n']
Tokenized   (023): ['[CLS]', 'ms', '##gt', '##ex', '##t', '=', 'ms', '##gb', '##ox', '.', 'load', '##ms', '##gt', '##ex', '##t', '(', 'ms', '##gh', '##ead', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['ms', '##gt', '##ex', '##t', '=', 'ms', '##gb', '##ox', '.', 'load', '##ms', '##gt', '##ex', '##t', '(', 'ms', '##gh', '##ead', ')', '\\', 'n']
Detokenized (009): ['ms##gt##ex##t', '=', 'ms##gb##ox', '.', 'load##ms##gt##ex##t', '(', 'ms##gh##ead', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "roster = self . rosters . get ( self ) \n"
Original    (011): ['roster', '=', 'self', '.', 'rosters', '.', 'get', '(', 'self', ')', '\\n']
Tokenized   (015): ['[CLS]', 'roster', '=', 'self', '.', 'roster', '##s', '.', 'get', '(', 'self', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['roster', '=', 'self', '.', 'roster', '##s', '.', 'get', '(', 'self', ')', '\\', 'n']
Detokenized (011): ['roster', '=', 'self', '.', 'roster##s', '.', 'get', '(', 'self', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "PYTHON_VERSION = sys . version_info [ : 3 ] \n"
Original    (010): ['PYTHON_VERSION', '=', 'sys', '.', 'version_info', '[', ':', '3', ']', '\\n']
Tokenized   (018): ['[CLS]', 'python', '_', 'version', '=', 'sy', '##s', '.', 'version', '_', 'info', '[', ':', '3', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['python', '_', 'version', '=', 'sy', '##s', '.', 'version', '_', 'info', '[', ':', '3', ']', '\\', 'n']
Detokenized (010): ['python_version', '=', 'sy##s', '.', 'version_info', '[', ':', '3', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "PY2 = ( PYTHON_VERSION [ 0 ] == 2 ) \n"
Original    (011): ['PY2', '=', '(', 'PYTHON_VERSION', '[', '0', ']', '==', '2', ')', '\\n']
Tokenized   (019): ['[CLS]', 'p', '##y', '##2', '=', '(', 'python', '_', 'version', '[', '0', ']', '=', '=', '2', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['p', '##y', '##2', '=', '(', 'python', '_', 'version', '[', '0', ']', '=', '=', '2', ')', '\\', 'n']
Detokenized (011): ['p##y##2', '=', '(', 'python_version', '[', '0', ']', '==', '2', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "sp_desc , \n"
Original    (003): ['sp_desc', ',', '\\n']
Tokenized   (009): ['[CLS]', 'sp', '_', 'des', '##c', ',', '\\', 'n', '[SEP]']
Filtered   (007): ['sp', '_', 'des', '##c', ',', '\\', 'n']
Detokenized (003): ['sp_des##c', ',', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "con = hpov . connection ( args . host ) \n"
Original    (011): ['con', '=', 'hpov', '.', 'connection', '(', 'args', '.', 'host', ')', '\\n']
Tokenized   (016): ['[CLS]', 'con', '=', 'hp', '##ov', '.', 'connection', '(', 'ar', '##gs', '.', 'host', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['con', '=', 'hp', '##ov', '.', 'connection', '(', 'ar', '##gs', '.', 'host', ')', '\\', 'n']
Detokenized (011): ['con', '=', 'hp##ov', '.', 'connection', '(', 'ar##gs', '.', 'host', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "acceptEULA ( con ) \n"
Original    (005): ['acceptEULA', '(', 'con', ')', '\\n']
Tokenized   (010): ['[CLS]', 'accept', '##eu', '##la', '(', 'con', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['accept', '##eu', '##la', '(', 'con', ')', '\\', 'n']
Detokenized (005): ['accept##eu##la', '(', 'con', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "fw_settings = profile . make_firmware_dict ( sts , args . baseline ) \n"
Original    (013): ['fw_settings', '=', 'profile', '.', 'make_firmware_dict', '(', 'sts', ',', 'args', '.', 'baseline', ')', '\\n']
Tokenized   (026): ['[CLS]', 'f', '##w', '_', 'settings', '=', 'profile', '.', 'make', '_', 'firm', '##ware', '_', 'di', '##ct', '(', 'sts', ',', 'ar', '##gs', '.', 'baseline', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['f', '##w', '_', 'settings', '=', 'profile', '.', 'make', '_', 'firm', '##ware', '_', 'di', '##ct', '(', 'sts', ',', 'ar', '##gs', '.', 'baseline', ')', '\\', 'n']
Detokenized (013): ['f##w_settings', '=', 'profile', '.', 'make_firm##ware_di##ct', '(', 'sts', ',', 'ar##gs', '.', 'baseline', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "boot , bootmode = profile . make_boot_settings_dict ( srv , sht , args . disable_manage_boot , \n"
Original    (017): ['boot', ',', 'bootmode', '=', 'profile', '.', 'make_boot_settings_dict', '(', 'srv', ',', 'sht', ',', 'args', '.', 'disable_manage_boot', ',', '\\n']
Tokenized   (037): ['[CLS]', 'boot', ',', 'boot', '##mo', '##de', '=', 'profile', '.', 'make', '_', 'boot', '_', 'settings', '_', 'di', '##ct', '(', 'sr', '##v', ',', 'sh', '##t', ',', 'ar', '##gs', '.', 'di', '##sable', '_', 'manage', '_', 'boot', ',', '\\', 'n', '[SEP]']
Filtered   (035): ['boot', ',', 'boot', '##mo', '##de', '=', 'profile', '.', 'make', '_', 'boot', '_', 'settings', '_', 'di', '##ct', '(', 'sr', '##v', ',', 'sh', '##t', ',', 'ar', '##gs', '.', 'di', '##sable', '_', 'manage', '_', 'boot', ',', '\\', 'n']
Detokenized (017): ['boot', ',', 'boot##mo##de', '=', 'profile', '.', 'make_boot_settings_di##ct', '(', 'sr##v', ',', 'sh##t', ',', 'ar##gs', '.', 'di##sable_manage_boot', ',', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "define_profile_template ( srv , \n"
Original    (005): ['define_profile_template', '(', 'srv', ',', '\\n']
Tokenized   (013): ['[CLS]', 'define', '_', 'profile', '_', 'template', '(', 'sr', '##v', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['define', '_', 'profile', '_', 'template', '(', 'sr', '##v', ',', '\\', 'n']
Detokenized (005): ['define_profile_template', '(', 'sr##v', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "sht [ ] , \n"
Original    (005): ['sht', '[', ']', ',', '\\n']
Tokenized   (009): ['[CLS]', 'sh', '##t', '[', ']', ',', '\\', 'n', '[SEP]']
Filtered   (007): ['sh', '##t', '[', ']', ',', '\\', 'n']
Detokenized (005): ['sh##t', '[', ']', ',', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "credential = { : args . domain . upper ( ) , : args . user , : args . passwd } \n"
Original    (023): ['credential', '=', '{', ':', 'args', '.', 'domain', '.', 'upper', '(', ')', ',', ':', 'args', '.', 'user', ',', ':', 'args', '.', 'passwd', '}', '\\n']
Tokenized   (032): ['[CLS]', 'cr', '##ede', '##ntial', '=', '{', ':', 'ar', '##gs', '.', 'domain', '.', 'upper', '(', ')', ',', ':', 'ar', '##gs', '.', 'user', ',', ':', 'ar', '##gs', '.', 'pass', '##wd', '}', '\\', 'n', '[SEP]']
Filtered   (030): ['cr', '##ede', '##ntial', '=', '{', ':', 'ar', '##gs', '.', 'domain', '.', 'upper', '(', ')', ',', ':', 'ar', '##gs', '.', 'user', ',', ':', 'ar', '##gs', '.', 'pass', '##wd', '}', '\\', 'n']
Detokenized (023): ['cr##ede##ntial', '=', '{', ':', 'ar##gs', '.', 'domain', '.', 'upper', '(', ')', ',', ':', 'ar##gs', '.', 'user', ',', ':', 'ar##gs', '.', 'pass##wd', '}', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "get_address_pools ( con , srv , args . types ) \n"
Original    (011): ['get_address_pools', '(', 'con', ',', 'srv', ',', 'args', '.', 'types', ')', '\\n']
Tokenized   (020): ['[CLS]', 'get', '_', 'address', '_', 'pools', '(', 'con', ',', 'sr', '##v', ',', 'ar', '##gs', '.', 'types', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['get', '_', 'address', '_', 'pools', '(', 'con', ',', 'sr', '##v', ',', 'ar', '##gs', '.', 'types', ')', '\\', 'n']
Detokenized (011): ['get_address_pools', '(', 'con', ',', 'sr##v', ',', 'ar##gs', '.', 'types', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "enclosure_group = None , server_profile = None ) : \n"
Original    (010): ['enclosure_group', '=', 'None', ',', 'server_profile', '=', 'None', ')', ':', '\\n']
Tokenized   (017): ['[CLS]', 'enclosure', '_', 'group', '=', 'none', ',', 'server', '_', 'profile', '=', 'none', ')', ':', '\\', 'n', '[SEP]']
Filtered   (015): ['enclosure', '_', 'group', '=', 'none', ',', 'server', '_', 'profile', '=', 'none', ')', ':', '\\', 'n']
Detokenized (010): ['enclosure_group', '=', 'none', ',', 'server_profile', '=', 'none', ')', ':', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "biosSettings = None , \n"
Original    (005): ['biosSettings', '=', 'None', ',', '\\n']
Tokenized   (011): ['[CLS]', 'bio', '##sse', '##tting', '##s', '=', 'none', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['bio', '##sse', '##tting', '##s', '=', 'none', ',', '\\', 'n']
Detokenized (005): ['bio##sse##tting##s', '=', 'none', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "macType = , \n"
Original    (004): ['macType', '=', ',', '\\n']
Tokenized   (008): ['[CLS]', 'mac', '##type', '=', ',', '\\', 'n', '[SEP]']
Filtered   (006): ['mac', '##type', '=', ',', '\\', 'n']
Detokenized (004): ['mac##type', '=', ',', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "localStorageSettingsV3 , macType , name , \n"
Original    (007): ['localStorageSettingsV3', ',', 'macType', ',', 'name', ',', '\\n']
Tokenized   (018): ['[CLS]', 'locals', '##tor', '##ages', '##etti', '##ng', '##s', '##v', '##3', ',', 'mac', '##type', ',', 'name', ',', '\\', 'n', '[SEP]']
Filtered   (016): ['locals', '##tor', '##ages', '##etti', '##ng', '##s', '##v', '##3', ',', 'mac', '##type', ',', 'name', ',', '\\', 'n']
Detokenized (007): ['locals##tor##ages##etti##ng##s##v##3', ',', 'mac##type', ',', 'name', ',', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "sanStorageV3 , serialNumber , \n"
Original    (005): ['sanStorageV3', ',', 'serialNumber', ',', '\\n']
Tokenized   (014): ['[CLS]', 'sans', '##tor', '##age', '##v', '##3', ',', 'serial', '##num', '##ber', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['sans', '##tor', '##age', '##v', '##3', ',', 'serial', '##num', '##ber', ',', '\\', 'n']
Detokenized (005): ['sans##tor##age##v##3', ',', 'serial##num##ber', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "serverProfileTemplateUri , uuid , wwnType ) \n"
Original    (007): ['serverProfileTemplateUri', ',', 'uuid', ',', 'wwnType', ')', '\\n']
Tokenized   (019): ['[CLS]', 'server', '##pro', '##fi', '##lete', '##mp', '##late', '##uri', ',', 'u', '##uid', ',', 'w', '##wn', '##type', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['server', '##pro', '##fi', '##lete', '##mp', '##late', '##uri', ',', 'u', '##uid', ',', 'w', '##wn', '##type', ')', '\\', 'n']
Detokenized (007): ['server##pro##fi##lete##mp##late##uri', ',', 'u##uid', ',', 'w##wn##type', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "profile_template = self . _con . get ( entity [ ] ) \n"
Original    (013): ['profile_template', '=', 'self', '.', '_con', '.', 'get', '(', 'entity', '[', ']', ')', '\\n']
Tokenized   (019): ['[CLS]', 'profile', '_', 'template', '=', 'self', '.', '_', 'con', '.', 'get', '(', 'entity', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['profile', '_', 'template', '=', 'self', '.', '_', 'con', '.', 'get', '(', 'entity', '[', ']', ')', '\\', 'n']
Detokenized (013): ['profile_template', '=', 'self', '.', '_con', '.', 'get', '(', 'entity', '[', ']', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "powerMode = ) : \n"
Original    (005): ['powerMode', '=', ')', ':', '\\n']
Tokenized   (010): ['[CLS]', 'power', '##mo', '##de', '=', ')', ':', '\\', 'n', '[SEP]']
Filtered   (008): ['power', '##mo', '##de', '=', ')', ':', '\\', 'n']
Detokenized (005): ['power##mo##de', '=', ')', ':', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "egroup = make_EnclosureGroupV200 ( associatedLIGs , name , powerMode ) \n"
Original    (011): ['egroup', '=', 'make_EnclosureGroupV200', '(', 'associatedLIGs', ',', 'name', ',', 'powerMode', ')', '\\n']
Tokenized   (024): ['[CLS]', 'e', '##group', '=', 'make', '_', 'enclosure', '##group', '##v', '##200', '(', 'associated', '##li', '##gs', ',', 'name', ',', 'power', '##mo', '##de', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['e', '##group', '=', 'make', '_', 'enclosure', '##group', '##v', '##200', '(', 'associated', '##li', '##gs', ',', 'name', ',', 'power', '##mo', '##de', ')', '\\', 'n']
Detokenized (011): ['e##group', '=', 'make_enclosure##group##v##200', '(', 'associated##li##gs', ',', 'name', ',', 'power##mo##de', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "allocatorBody = { : count } \n"
Original    (007): ['allocatorBody', '=', '{', ':', 'count', '}', '\\n']
Tokenized   (013): ['[CLS]', 'all', '##oca', '##tor', '##body', '=', '{', ':', 'count', '}', '\\', 'n', '[SEP]']
Filtered   (011): ['all', '##oca', '##tor', '##body', '=', '{', ':', 'count', '}', '\\', 'n']
Detokenized (007): ['all##oca##tor##body', '=', '{', ':', 'count', '}', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "prange [ ] = False \n"
Original    (006): ['prange', '[', ']', '=', 'False', '\\n']
Tokenized   (010): ['[CLS]', 'pr', '##ange', '[', ']', '=', 'false', '\\', 'n', '[SEP]']
Filtered   (008): ['pr', '##ange', '[', ']', '=', 'false', '\\', 'n']
Detokenized (006): ['pr##ange', '[', ']', '=', 'false', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tempstr = "hp-rest-classes-bios-" + romfamily + "-" + biosversion \n"
Original    (010): ['tempstr', '=', '"hp-rest-classes-bios-"', '+', 'romfamily', '+', '"-"', '+', 'biosversion', '\\n']
Tokenized   (031): ['[CLS]', 'temps', '##tr', '=', '"', 'hp', '-', 'rest', '-', 'classes', '-', 'bio', '##s', '-', '"', '+', 'rom', '##fa', '##mi', '##ly', '+', '"', '-', '"', '+', 'bio', '##s', '##version', '\\', 'n', '[SEP]']
Filtered   (029): ['temps', '##tr', '=', '"', 'hp', '-', 'rest', '-', 'classes', '-', 'bio', '##s', '-', '"', '+', 'rom', '##fa', '##mi', '##ly', '+', '"', '-', '"', '+', 'bio', '##s', '##version', '\\', 'n']
Detokenized (010): ['temps##tr', '=', '"hp-rest-classes-bio##s-"', '+', 'rom##fa##mi##ly', '+', '"-"', '+', 'bio##s##version', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "monolith = None ) : \n"
Original    (006): ['monolith', '=', 'None', ')', ':', '\\n']
Tokenized   (011): ['[CLS]', 'mono', '##lit', '##h', '=', 'none', ')', ':', '\\', 'n', '[SEP]']
Filtered   (009): ['mono', '##lit', '##h', '=', 'none', ')', ':', '\\', 'n']
Detokenized (006): ['mono##lit##h', '=', 'none', ')', ':', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "pathjoinstr ) ) : \n"
Original    (005): ['pathjoinstr', ')', ')', ':', '\\n']
Tokenized   (011): ['[CLS]', 'path', '##jo', '##ins', '##tr', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (009): ['path', '##jo', '##ins', '##tr', ')', ')', ':', '\\', 'n']
Detokenized (005): ['path##jo##ins##tr', ')', ')', ':', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "newclass . set_root ( root ) \n"
Original    (007): ['newclass', '.', 'set_root', '(', 'root', ')', '\\n']
Tokenized   (013): ['[CLS]', 'new', '##class', '.', 'set', '_', 'root', '(', 'root', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['new', '##class', '.', 'set', '_', 'root', '(', 'root', ')', '\\', 'n']
Detokenized (007): ['new##class', '.', 'set_root', '(', 'root', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "folderentries = data [ "links" ] \n"
Original    (007): ['folderentries', '=', 'data', '[', '"links"', ']', '\\n']
Tokenized   (014): ['[CLS]', 'folder', '##ent', '##ries', '=', 'data', '[', '"', 'links', '"', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['folder', '##ent', '##ries', '=', 'data', '[', '"', 'links', '"', ']', '\\', 'n']
Detokenized (007): ['folder##ent##ries', '=', 'data', '[', '"links"', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "datareturn . append ( self . load_file ( fqpath , root = root , biossection = True , registries = True , datareturn = True ) ) \n"
Original    (028): ['datareturn', '.', 'append', '(', 'self', '.', 'load_file', '(', 'fqpath', ',', 'root', '=', 'root', ',', 'biossection', '=', 'True', ',', 'registries', '=', 'True', ',', 'datareturn', '=', 'True', ')', ')', '\\n']
Tokenized   (043): ['[CLS]', 'data', '##ret', '##urn', '.', 'app', '##end', '(', 'self', '.', 'load', '_', 'file', '(', 'f', '##q', '##path', ',', 'root', '=', 'root', ',', 'bio', '##sse', '##ction', '=', 'true', ',', 'regis', '##tries', '=', 'true', ',', 'data', '##ret', '##urn', '=', 'true', ')', ')', '\\', 'n', '[SEP]']
Filtered   (041): ['data', '##ret', '##urn', '.', 'app', '##end', '(', 'self', '.', 'load', '_', 'file', '(', 'f', '##q', '##path', ',', 'root', '=', 'root', ',', 'bio', '##sse', '##ction', '=', 'true', ',', 'regis', '##tries', '=', 'true', ',', 'data', '##ret', '##urn', '=', 'true', ')', ')', '\\', 'n']
Detokenized (028): ['data##ret##urn', '.', 'app##end', '(', 'self', '.', 'load_file', '(', 'f##q##path', ',', 'root', '=', 'root', ',', 'bio##sse##ction', '=', 'true', ',', 'regis##tries', '=', 'true', ',', 'data##ret##urn', '=', 'true', ')', ')', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "currdict = currdict , monolith = monolith , \n"
Original    (009): ['currdict', '=', 'currdict', ',', 'monolith', '=', 'monolith', ',', '\\n']
Tokenized   (020): ['[CLS]', 'cu', '##rr', '##dict', '=', 'cu', '##rr', '##dict', ',', 'mono', '##lit', '##h', '=', 'mono', '##lit', '##h', ',', '\\', 'n', '[SEP]']
Filtered   (018): ['cu', '##rr', '##dict', '=', 'cu', '##rr', '##dict', ',', 'mono', '##lit', '##h', '=', 'mono', '##lit', '##h', ',', '\\', 'n']
Detokenized (009): ['cu##rr##dict', '=', 'cu##rr##dict', ',', 'mono##lit##h', '=', 'mono##lit##h', ',', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newarg = newarg , checkall = checkall ) \n"
Original    (009): ['newarg', '=', 'newarg', ',', 'checkall', '=', 'checkall', ')', '\\n']
Tokenized   (018): ['[CLS]', 'new', '##ar', '##g', '=', 'new', '##ar', '##g', ',', 'check', '##all', '=', 'check', '##all', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['new', '##ar', '##g', '=', 'new', '##ar', '##g', ',', 'check', '##all', '=', 'check', '##all', ')', '\\', 'n']
Detokenized (009): ['new##ar##g', '=', 'new##ar##g', ',', 'check##all', '=', 'check##all', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "attrreg = self . find_bios_registry ( regname = regname ) \n"
Original    (011): ['attrreg', '=', 'self', '.', 'find_bios_registry', '(', 'regname', '=', 'regname', ')', '\\n']
Tokenized   (024): ['[CLS]', 'at', '##tr', '##re', '##g', '=', 'self', '.', 'find', '_', 'bio', '##s', '_', 'registry', '(', 'reg', '##name', '=', 'reg', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['at', '##tr', '##re', '##g', '=', 'self', '.', 'find', '_', 'bio', '##s', '_', 'registry', '(', 'reg', '##name', '=', 'reg', '##name', ')', '\\', 'n']
Detokenized (011): ['at##tr##re##g', '=', 'self', '.', 'find_bio##s_registry', '(', 'reg##name', '=', 'reg##name', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "schlink = schlink [ len ( schlink ) - 2 ] \n"
Original    (012): ['schlink', '=', 'schlink', '[', 'len', '(', 'schlink', ')', '-', '2', ']', '\\n']
Tokenized   (021): ['[CLS]', 'sc', '##hli', '##nk', '=', 'sc', '##hli', '##nk', '[', 'len', '(', 'sc', '##hli', '##nk', ')', '-', '2', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['sc', '##hli', '##nk', '=', 'sc', '##hli', '##nk', '[', 'len', '(', 'sc', '##hli', '##nk', ')', '-', '2', ']', '\\', 'n']
Detokenized (012): ['sc##hli##nk', '=', 'sc##hli##nk', '[', 'len', '(', 'sc##hli##nk', ')', '-', '2', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "schname . lower ( ) ) : \n"
Original    (008): ['schname', '.', 'lower', '(', ')', ')', ':', '\\n']
Tokenized   (013): ['[CLS]', 'sc', '##hn', '##ame', '.', 'lower', '(', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (011): ['sc', '##hn', '##ame', '.', 'lower', '(', ')', ')', ':', '\\', 'n']
Detokenized (008): ['sc##hn##ame', '.', 'lower', '(', ')', ')', ':', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "xref = os . path . normpath ( currloc . Uri . extref ) . lstrip ( os . path . sep ) \n"
Original    (024): ['xref', '=', 'os', '.', 'path', '.', 'normpath', '(', 'currloc', '.', 'Uri', '.', 'extref', ')', '.', 'lstrip', '(', 'os', '.', 'path', '.', 'sep', ')', '\\n']
Tokenized   (038): ['[CLS]', 'x', '##re', '##f', '=', 'os', '.', 'path', '.', 'norm', '##path', '(', 'cu', '##rr', '##lo', '##c', '.', 'ur', '##i', '.', 'ex', '##tre', '##f', ')', '.', 'l', '##st', '##rip', '(', 'os', '.', 'path', '.', 'sep', ')', '\\', 'n', '[SEP]']
Filtered   (036): ['x', '##re', '##f', '=', 'os', '.', 'path', '.', 'norm', '##path', '(', 'cu', '##rr', '##lo', '##c', '.', 'ur', '##i', '.', 'ex', '##tre', '##f', ')', '.', 'l', '##st', '##rip', '(', 'os', '.', 'path', '.', 'sep', ')', '\\', 'n']
Detokenized (024): ['x##re##f', '=', 'os', '.', 'path', '.', 'norm##path', '(', 'cu##rr##lo##c', '.', 'ur##i', '.', 'ex##tre##f', ')', '.', 'l##st##rip', '(', 'os', '.', 'path', '.', 'sep', ')', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "fqpath = os . path . join ( root , xref ) \n"
Original    (013): ['fqpath', '=', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'xref', ')', '\\n']
Tokenized   (020): ['[CLS]', 'f', '##q', '##path', '=', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'x', '##re', '##f', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['f', '##q', '##path', '=', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'x', '##re', '##f', ')', '\\', 'n']
Detokenized (013): ['f##q##path', '=', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'x##re##f', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "langcode = list ( locale . getdefaultlocale ( ) ) \n"
Original    (011): ['langcode', '=', 'list', '(', 'locale', '.', 'getdefaultlocale', '(', ')', ')', '\\n']
Tokenized   (022): ['[CLS]', 'lang', '##code', '=', 'list', '(', 'local', '##e', '.', 'get', '##de', '##fa', '##ult', '##lo', '##cal', '##e', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['lang', '##code', '=', 'list', '(', 'local', '##e', '.', 'get', '##de', '##fa', '##ult', '##lo', '##cal', '##e', '(', ')', ')', '\\', 'n']
Detokenized (011): ['lang##code', '=', 'list', '(', 'local##e', '.', 'get##de##fa##ult##lo##cal##e', '(', ')', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "locationlanguage = locationlanguage . replace ( "-" , "_" ) \n"
Original    (011): ['locationlanguage', '=', 'locationlanguage', '.', 'replace', '(', '"-"', ',', '"_"', ')', '\\n']
Tokenized   (024): ['[CLS]', 'location', '##lang', '##ua', '##ge', '=', 'location', '##lang', '##ua', '##ge', '.', 'replace', '(', '"', '-', '"', ',', '"', '_', '"', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['location', '##lang', '##ua', '##ge', '=', 'location', '##lang', '##ua', '##ge', '.', 'replace', '(', '"', '-', '"', ',', '"', '_', '"', ')', '\\', 'n']
Detokenized (011): ['location##lang##ua##ge', '=', 'location##lang##ua##ge', '.', 'replace', '(', '"-"', ',', '"_"', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "currtype = currtype . split ( ) [ 0 ] + \n"
Original    (012): ['currtype', '=', 'currtype', '.', 'split', '(', ')', '[', '0', ']', '+', '\\n']
Tokenized   (019): ['[CLS]', 'cu', '##rr', '##type', '=', 'cu', '##rr', '##type', '.', 'split', '(', ')', '[', '0', ']', '+', '\\', 'n', '[SEP]']
Filtered   (017): ['cu', '##rr', '##type', '=', 'cu', '##rr', '##type', '.', 'split', '(', ')', '[', '0', ']', '+', '\\', 'n']
Detokenized (012): ['cu##rr##type', '=', 'cu##rr##type', '.', 'split', '(', ')', '[', '0', ']', '+', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "insttype = instance . resp . dict [ "title" ] . split ( ) [ : 1 ] \n"
Original    (019): ['insttype', '=', 'instance', '.', 'resp', '.', 'dict', '[', '"title"', ']', '.', 'split', '(', ')', '[', ':', '1', ']', '\\n']
Tokenized   (028): ['[CLS]', 'ins', '##tty', '##pe', '=', 'instance', '.', 'res', '##p', '.', 'di', '##ct', '[', '"', 'title', '"', ']', '.', 'split', '(', ')', '[', ':', '1', ']', '\\', 'n', '[SEP]']
Filtered   (026): ['ins', '##tty', '##pe', '=', 'instance', '.', 'res', '##p', '.', 'di', '##ct', '[', '"', 'title', '"', ']', '.', 'split', '(', ')', '[', ':', '1', ']', '\\', 'n']
Detokenized (019): ['ins##tty##pe', '=', 'instance', '.', 'res##p', '.', 'di##ct', '[', '"title"', ']', '.', 'split', '(', ')', '[', ':', '1', ']', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "nextarg = newarg [ newarg . index ( arg ) + 1 ] \n"
Original    (014): ['nextarg', '=', 'newarg', '[', 'newarg', '.', 'index', '(', 'arg', ')', '+', '1', ']', '\\n']
Tokenized   (024): ['[CLS]', 'next', '##ar', '##g', '=', 'new', '##ar', '##g', '[', 'new', '##ar', '##g', '.', 'index', '(', 'ar', '##g', ')', '+', '1', ']', '\\', 'n', '[SEP]']
Filtered   (022): ['next', '##ar', '##g', '=', 'new', '##ar', '##g', '[', 'new', '##ar', '##g', '.', 'index', '(', 'ar', '##g', ')', '+', '1', ']', '\\', 'n']
Detokenized (014): ['next##ar##g', '=', 'new##ar##g', '[', 'new##ar##g', '.', 'index', '(', 'ar##g', ')', '+', '1', ']', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "regcopy [ nextarg ] = patterninfo \n"
Original    (007): ['regcopy', '[', 'nextarg', ']', '=', 'patterninfo', '\\n']
Tokenized   (016): ['[CLS]', 'reg', '##co', '##py', '[', 'next', '##ar', '##g', ']', '=', 'pattern', '##in', '##fo', '\\', 'n', '[SEP]']
Filtered   (014): ['reg', '##co', '##py', '[', 'next', '##ar', '##g', ']', '=', 'pattern', '##in', '##fo', '\\', 'n']
Detokenized (007): ['reg##co##py', '[', 'next##ar##g', ']', '=', 'pattern##in##fo', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "validictory . validate ( tdict , jsonsch ) \n"
Original    (009): ['validictory', '.', 'validate', '(', 'tdict', ',', 'jsonsch', ')', '\\n']
Tokenized   (019): ['[CLS]', 'valid', '##ic', '##tory', '.', 'valid', '##ate', '(', 'td', '##ic', '##t', ',', 'j', '##sons', '##ch', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['valid', '##ic', '##tory', '.', 'valid', '##ate', '(', 'td', '##ic', '##t', ',', 'j', '##sons', '##ch', ')', '\\', 'n']
Detokenized (009): ['valid##ic##tory', '.', 'valid##ate', '(', 'td##ic##t', ',', 'j##sons##ch', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "wrapper . subsequent_indent = * 4 \n"
Original    (007): ['wrapper', '.', 'subsequent_indent', '=', '*', '4', '\\n']
Tokenized   (014): ['[CLS]', 'wrap', '##per', '.', 'subsequent', '_', 'ind', '##ent', '=', '*', '4', '\\', 'n', '[SEP]']
Filtered   (012): ['wrap', '##per', '.', 'subsequent', '_', 'ind', '##ent', '=', '*', '4', '\\', 'n']
Detokenized (007): ['wrap##per', '.', 'subsequent_ind##ent', '=', '*', '4', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "RegistryValidationError ( \n"
Original    (003): ['RegistryValidationError', '(', '\\n']
Tokenized   (011): ['[CLS]', 'registry', '##val', '##ida', '##tion', '##er', '##ror', '(', '\\', 'n', '[SEP]']
Filtered   (009): ['registry', '##val', '##ida', '##tion', '##er', '##ror', '(', '\\', 'n']
Detokenized (003): ['registry##val##ida##tion##er##ror', '(', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "regentry = self \n"
Original    (004): ['regentry', '=', 'self', '\\n']
Tokenized   (008): ['[CLS]', 'regent', '##ry', '=', 'self', '\\', 'n', '[SEP]']
Filtered   (006): ['regent', '##ry', '=', 'self', '\\', 'n']
Detokenized (004): ['regent##ry', '=', 'self', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""\'%(ValueExpression)s\'" % ( self ) , regentry = self ) ) \n"
Original    (012): ['"\\\'%(ValueExpression)s\\\'"', '%', '(', 'self', ')', ',', 'regentry', '=', 'self', ')', ')', '\\n']
Tokenized   (029): ['[CLS]', '"', '\\', "'", '%', '(', 'value', '##ex', '##press', '##ion', ')', 's', '\\', "'", '"', '%', '(', 'self', ')', ',', 'regent', '##ry', '=', 'self', ')', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['"', '\\', "'", '%', '(', 'value', '##ex', '##press', '##ion', ')', 's', '\\', "'", '"', '%', '(', 'self', ')', ',', 'regent', '##ry', '=', 'self', ')', ')', '\\', 'n']
Detokenized (012): ['"\\\'%(value##ex##press##ion)s\\\'"', '%', '(', 'self', ')', ',', 'regent##ry', '=', 'self', ')', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "intval = int ( newval ) \n"
Original    (007): ['intval', '=', 'int', '(', 'newval', ')', '\\n']
Tokenized   (012): ['[CLS]', 'int', '##val', '=', 'int', '(', 'new', '##val', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['int', '##val', '=', 'int', '(', 'new', '##val', ')', '\\', 'n']
Detokenized (007): ['int##val', '=', 'int', '(', 'new##val', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "MICROS_TRANSLATIONS = ( \n"
Original    (004): ['MICROS_TRANSLATIONS', '=', '(', '\\n']
Tokenized   (010): ['[CLS]', 'micro', '##s', '_', 'translations', '=', '(', '\\', 'n', '[SEP]']
Filtered   (008): ['micro', '##s', '_', 'translations', '=', '(', '\\', 'n']
Detokenized (004): ['micro##s_translations', '=', '(', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "MICROS_TRANSLATION_HASH = dict ( ( alt , v ) for k , v in MICROS_TRANSLATIONS for alt in k ) \n"
Original    (021): ['MICROS_TRANSLATION_HASH', '=', 'dict', '(', '(', 'alt', ',', 'v', ')', 'for', 'k', ',', 'v', 'in', 'MICROS_TRANSLATIONS', 'for', 'alt', 'in', 'k', ')', '\\n']
Tokenized   (033): ['[CLS]', 'micro', '##s', '_', 'translation', '_', 'hash', '=', 'di', '##ct', '(', '(', 'alt', ',', 'v', ')', 'for', 'k', ',', 'v', 'in', 'micro', '##s', '_', 'translations', 'for', 'alt', 'in', 'k', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['micro', '##s', '_', 'translation', '_', 'hash', '=', 'di', '##ct', '(', '(', 'alt', ',', 'v', ')', 'for', 'k', ',', 'v', 'in', 'micro', '##s', '_', 'translations', 'for', 'alt', 'in', 'k', ')', '\\', 'n']
Detokenized (021): ['micro##s_translation_hash', '=', 'di##ct', '(', '(', 'alt', ',', 'v', ')', 'for', 'k', ',', 'v', 'in', 'micro##s_translations', 'for', 'alt', 'in', 'k', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "epoch_milliseconds = epoch_millis = milliseconds = millis = ms \n"
Original    (010): ['epoch_milliseconds', '=', 'epoch_millis', '=', 'milliseconds', '=', 'millis', '=', 'ms', '\\n']
Tokenized   (025): ['[CLS]', 'epoch', '_', 'mill', '##ise', '##con', '##ds', '=', 'epoch', '_', 'mill', '##is', '=', 'mill', '##ise', '##con', '##ds', '=', 'mill', '##is', '=', 'ms', '\\', 'n', '[SEP]']
Filtered   (023): ['epoch', '_', 'mill', '##ise', '##con', '##ds', '=', 'epoch', '_', 'mill', '##is', '=', 'mill', '##ise', '##con', '##ds', '=', 'mill', '##is', '=', 'ms', '\\', 'n']
Detokenized (010): ['epoch_mill##ise##con##ds', '=', 'epoch_mill##is', '=', 'mill##ise##con##ds', '=', 'mill##is', '=', 'ms', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "epoch_microseconds = epoch_micros = microseconds = micros \n"
Original    (008): ['epoch_microseconds', '=', 'epoch_micros', '=', 'microseconds', '=', 'micros', '\\n']
Tokenized   (023): ['[CLS]', 'epoch', '_', 'micro', '##se', '##con', '##ds', '=', 'epoch', '_', 'micro', '##s', '=', 'micro', '##se', '##con', '##ds', '=', 'micro', '##s', '\\', 'n', '[SEP]']
Filtered   (021): ['epoch', '_', 'micro', '##se', '##con', '##ds', '=', 'epoch', '_', 'micro', '##s', '=', 'micro', '##se', '##con', '##ds', '=', 'micro', '##s', '\\', 'n']
Detokenized (008): ['epoch_micro##se##con##ds', '=', 'epoch_micro##s', '=', 'micro##se##con##ds', '=', 'micro##s', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "micros = u".%06d" % dt . microsecond if dt . microsecond else \n"
Original    (013): ['micros', '=', 'u".%06d"', '%', 'dt', '.', 'microsecond', 'if', 'dt', '.', 'microsecond', 'else', '\\n']
Tokenized   (029): ['[CLS]', 'micro', '##s', '=', 'u', '"', '.', '%', '06', '##d', '"', '%', 'dt', '.', 'micro', '##se', '##con', '##d', 'if', 'dt', '.', 'micro', '##se', '##con', '##d', 'else', '\\', 'n', '[SEP]']
Filtered   (027): ['micro', '##s', '=', 'u', '"', '.', '%', '06', '##d', '"', '%', 'dt', '.', 'micro', '##se', '##con', '##d', 'if', 'dt', '.', 'micro', '##se', '##con', '##d', 'else', '\\', 'n']
Detokenized (013): ['micro##s', '=', 'u".%06##d"', '%', 'dt', '.', 'micro##se##con##d', 'if', 'dt', '.', 'micro##se##con##d', 'else', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "datastore_owner_uuid = request . REQUEST [ "datastore_owner__uuid" ] \n"
Original    (009): ['datastore_owner_uuid', '=', 'request', '.', 'REQUEST', '[', '"datastore_owner__uuid"', ']', '\\n']
Tokenized   (029): ['[CLS]', 'data', '##stor', '##e', '_', 'owner', '_', 'u', '##uid', '=', 'request', '.', 'request', '[', '"', 'data', '##stor', '##e', '_', 'owner', '_', '_', 'u', '##uid', '"', ']', '\\', 'n', '[SEP]']
Filtered   (027): ['data', '##stor', '##e', '_', 'owner', '_', 'u', '##uid', '=', 'request', '.', 'request', '[', '"', 'data', '##stor', '##e', '_', 'owner', '_', '_', 'u', '##uid', '"', ']', '\\', 'n']
Detokenized (009): ['data##stor##e_owner_u##uid', '=', 'request', '.', 'request', '[', '"data##stor##e_owner__u##uid"', ']', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "datastore_owner , ds_owner_created = Profile . objects . get_or_create ( uuid = datastore_owner_uuid ) \n"
Original    (015): ['datastore_owner', ',', 'ds_owner_created', '=', 'Profile', '.', 'objects', '.', 'get_or_create', '(', 'uuid', '=', 'datastore_owner_uuid', ')', '\\n']
Tokenized   (038): ['[CLS]', 'data', '##stor', '##e', '_', 'owner', ',', 'ds', '_', 'owner', '_', 'created', '=', 'profile', '.', 'objects', '.', 'get', '_', 'or', '_', 'create', '(', 'u', '##uid', '=', 'data', '##stor', '##e', '_', 'owner', '_', 'u', '##uid', ')', '\\', 'n', '[SEP]']
Filtered   (036): ['data', '##stor', '##e', '_', 'owner', ',', 'ds', '_', 'owner', '_', 'created', '=', 'profile', '.', 'objects', '.', 'get', '_', 'or', '_', 'create', '(', 'u', '##uid', '=', 'data', '##stor', '##e', '_', 'owner', '_', 'u', '##uid', ')', '\\', 'n']
Detokenized (015): ['data##stor##e_owner', ',', 'ds_owner_created', '=', 'profile', '.', 'objects', '.', 'get_or_create', '(', 'u##uid', '=', 'data##stor##e_owner_u##uid', ')', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "port = db . Column ( db . Integer , nullable = False ) \n"
Original    (015): ['port', '=', 'db', '.', 'Column', '(', 'db', '.', 'Integer', ',', 'nullable', '=', 'False', ')', '\\n']
Tokenized   (019): ['[CLS]', 'port', '=', 'db', '.', 'column', '(', 'db', '.', 'integer', ',', 'null', '##able', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['port', '=', 'db', '.', 'column', '(', 'db', '.', 'integer', ',', 'null', '##able', '=', 'false', ')', '\\', 'n']
Detokenized (015): ['port', '=', 'db', '.', 'column', '(', 'db', '.', 'integer', ',', 'null##able', '=', 'false', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "eru_container_id = db . Column ( db . String ( 64 ) , index = True ) \n"
Original    (018): ['eru_container_id', '=', 'db', '.', 'Column', '(', 'db', '.', 'String', '(', '64', ')', ',', 'index', '=', 'True', ')', '\\n']
Tokenized   (026): ['[CLS]', 'er', '##u', '_', 'container', '_', 'id', '=', 'db', '.', 'column', '(', 'db', '.', 'string', '(', '64', ')', ',', 'index', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['er', '##u', '_', 'container', '_', 'id', '=', 'db', '.', 'column', '(', 'db', '.', 'string', '(', '64', ')', ',', 'index', '=', 'true', ')', '\\', 'n']
Detokenized (018): ['er##u_container_id', '=', 'db', '.', 'column', '(', 'db', '.', 'string', '(', '64', ')', ',', 'index', '=', 'true', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "suppress_alert = db . Column ( db . Integer , nullable = False , default = 1 ) \n"
Original    (019): ['suppress_alert', '=', 'db', '.', 'Column', '(', 'db', '.', 'Integer', ',', 'nullable', '=', 'False', ',', 'default', '=', '1', ')', '\\n']
Tokenized   (025): ['[CLS]', 'suppress', '_', 'alert', '=', 'db', '.', 'column', '(', 'db', '.', 'integer', ',', 'null', '##able', '=', 'false', ',', 'default', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['suppress', '_', 'alert', '=', 'db', '.', 'column', '(', 'db', '.', 'integer', ',', 'null', '##able', '=', 'false', ',', 'default', '=', '1', ')', '\\', 'n']
Detokenized (019): ['suppress_alert', '=', 'db', '.', 'column', '(', 'db', '.', 'integer', ',', 'null##able', '=', 'false', ',', 'default', '=', '1', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "__table_args__ = ( db . Index ( , , , unique = True ) , ) \n"
Original    (017): ['__table_args__', '=', '(', 'db', '.', 'Index', '(', ',', ',', ',', 'unique', '=', 'True', ')', ',', ')', '\\n']
Tokenized   (027): ['[CLS]', '_', '_', 'table', '_', 'ar', '##gs', '_', '_', '=', '(', 'db', '.', 'index', '(', ',', ',', ',', 'unique', '=', 'true', ')', ',', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['_', '_', 'table', '_', 'ar', '##gs', '_', '_', '=', '(', 'db', '.', 'index', '(', ',', ',', ',', 'unique', '=', 'true', ')', ',', ')', '\\', 'n']
Detokenized (017): ['__table_ar##gs__', '=', '(', 'db', '.', 'index', '(', ',', ',', ',', 'unique', '=', 'true', ')', ',', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "cluster_id = cluster_id ) \n"
Original    (005): ['cluster_id', '=', 'cluster_id', ')', '\\n']
Tokenized   (012): ['[CLS]', 'cluster', '_', 'id', '=', 'cluster', '_', 'id', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['cluster', '_', 'id', '=', 'cluster', '_', 'id', ')', '\\', 'n']
Detokenized (005): ['cluster_id', '=', 'cluster_id', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "Proxy . id . desc ( ) ) . offset ( offset ) . limit ( limit ) . all ( ) \n"
Original    (023): ['Proxy', '.', 'id', '.', 'desc', '(', ')', ')', '.', 'offset', '(', 'offset', ')', '.', 'limit', '(', 'limit', ')', '.', 'all', '(', ')', '\\n']
Tokenized   (027): ['[CLS]', 'proxy', '.', 'id', '.', 'des', '##c', '(', ')', ')', '.', 'offset', '(', 'offset', ')', '.', 'limit', '(', 'limit', ')', '.', 'all', '(', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['proxy', '.', 'id', '.', 'des', '##c', '(', ')', ')', '.', 'offset', '(', 'offset', ')', '.', 'limit', '(', 'limit', ')', '.', 'all', '(', ')', '\\', 'n']
Detokenized (023): ['proxy', '.', 'id', '.', 'des##c', '(', ')', ')', '.', 'offset', '(', 'offset', ')', '.', 'limit', '(', 'limit', ')', '.', 'all', '(', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "iou_as_issuer . issue_funds ( amount_issued , ) \n"
Original    (008): ['iou_as_issuer', '.', 'issue_funds', '(', 'amount_issued', ',', ')', '\\n']
Tokenized   (021): ['[CLS]', 'io', '##u', '_', 'as', '_', 'issue', '##r', '.', 'issue', '_', 'funds', '(', 'amount', '_', 'issued', ',', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['io', '##u', '_', 'as', '_', 'issue', '##r', '.', 'issue', '_', 'funds', '(', 'amount', '_', 'issued', ',', ')', '\\', 'n']
Detokenized (008): ['io##u_as_issue##r', '.', 'issue_funds', '(', 'amount_issued', ',', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "github_info_json = urllib2 . urlopen ( latest ) . read ( ) \n"
Original    (013): ['github_info_json', '=', 'urllib2', '.', 'urlopen', '(', 'latest', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (028): ['[CLS]', 'gi', '##th', '##ub', '_', 'info', '_', 'j', '##son', '=', 'ur', '##lli', '##b', '##2', '.', 'ur', '##lo', '##pen', '(', 'latest', ')', '.', 'read', '(', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['gi', '##th', '##ub', '_', 'info', '_', 'j', '##son', '=', 'ur', '##lli', '##b', '##2', '.', 'ur', '##lo', '##pen', '(', 'latest', ')', '.', 'read', '(', ')', '\\', 'n']
Detokenized (013): ['gi##th##ub_info_j##son', '=', 'ur##lli##b##2', '.', 'ur##lo##pen', '(', 'latest', ')', '.', 'read', '(', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) , read_delay = opt . read_delay ) \n"
Original    (024): ['drawing_tool', '.', 'set_window_title', '(', 'update_notifier', ',', 'watching_player', '=', 'twitch_username', ',', 'updates_queued', '=', 'len', '(', 'new_states_queue', ')', ',', 'read_delay', '=', 'opt', '.', 'read_delay', ')', '\\n']
Tokenized   (052): ['[CLS]', 'drawing', '_', 'tool', '.', 'set', '_', 'window', '_', 'title', '(', 'update', '_', 'not', '##ifier', ',', 'watching', '_', 'player', '=', 'twitch', '_', 'user', '##name', ',', 'updates', '_', 'queue', '##d', '=', 'len', '(', 'new', '_', 'states', '_', 'queue', ')', ',', 'read', '_', 'delay', '=', 'opt', '.', 'read', '_', 'delay', ')', '\\', 'n', '[SEP]']
Filtered   (050): ['drawing', '_', 'tool', '.', 'set', '_', 'window', '_', 'title', '(', 'update', '_', 'not', '##ifier', ',', 'watching', '_', 'player', '=', 'twitch', '_', 'user', '##name', ',', 'updates', '_', 'queue', '##d', '=', 'len', '(', 'new', '_', 'states', '_', 'queue', ')', ',', 'read', '_', 'delay', '=', 'opt', '.', 'read', '_', 'delay', ')', '\\', 'n']
Detokenized (024): ['drawing_tool', '.', 'set_window_title', '(', 'update_not##ifier', ',', 'watching_player', '=', 'twitch_user##name', ',', 'updates_queue##d', '=', 'len', '(', 'new_states_queue', ')', ',', 'read_delay', '=', 'opt', '.', 'read_delay', ')', '\\n']
Counter: 50
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "put_url = opt . trackerserver_url + "/tracker/api/update/" + opt . trackerserver_authkey \n"
Original    (012): ['put_url', '=', 'opt', '.', 'trackerserver_url', '+', '"/tracker/api/update/"', '+', 'opt', '.', 'trackerserver_authkey', '\\n']
Tokenized   (037): ['[CLS]', 'put', '_', 'ur', '##l', '=', 'opt', '.', 'tracker', '##ser', '##ver', '_', 'ur', '##l', '+', '"', '/', 'tracker', '/', 'api', '/', 'update', '/', '"', '+', 'opt', '.', 'tracker', '##ser', '##ver', '_', 'au', '##th', '##key', '\\', 'n', '[SEP]']
Filtered   (035): ['put', '_', 'ur', '##l', '=', 'opt', '.', 'tracker', '##ser', '##ver', '_', 'ur', '##l', '+', '"', '/', 'tracker', '/', 'api', '/', 'update', '/', '"', '+', 'opt', '.', 'tracker', '##ser', '##ver', '_', 'au', '##th', '##key', '\\', 'n']
Detokenized (012): ['put_ur##l', '=', 'opt', '.', 'tracker##ser##ver_ur##l', '+', '"/tracker/api/update/"', '+', 'opt', '.', 'tracker##ser##ver_au##th##key', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "json_string = json . dumps ( state , cls = TrackerStateEncoder , sort_keys = True ) \n"
Original    (017): ['json_string', '=', 'json', '.', 'dumps', '(', 'state', ',', 'cls', '=', 'TrackerStateEncoder', ',', 'sort_keys', '=', 'True', ')', '\\n']
Tokenized   (032): ['[CLS]', 'j', '##son', '_', 'string', '=', 'j', '##son', '.', 'dump', '##s', '(', 'state', ',', 'cl', '##s', '=', 'tracker', '##sta', '##tee', '##nco', '##der', ',', 'sort', '_', 'keys', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['j', '##son', '_', 'string', '=', 'j', '##son', '.', 'dump', '##s', '(', 'state', ',', 'cl', '##s', '=', 'tracker', '##sta', '##tee', '##nco', '##der', ',', 'sort', '_', 'keys', '=', 'true', ')', '\\', 'n']
Detokenized (017): ['j##son_string', '=', 'j##son', '.', 'dump##s', '(', 'state', ',', 'cl##s', '=', 'tracker##sta##tee##nco##der', ',', 'sort_keys', '=', 'true', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "new_states_queue . pop ( 0 ) \n"
Original    (007): ['new_states_queue', '.', 'pop', '(', '0', ')', '\\n']
Tokenized   (014): ['[CLS]', 'new', '_', 'states', '_', 'queue', '.', 'pop', '(', '0', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['new', '_', 'states', '_', 'queue', '.', 'pop', '(', '0', ')', '\\', 'n']
Detokenized (007): ['new_states_queue', '.', 'pop', '(', '0', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "framecount += 1 \n"
Original    (004): ['framecount', '+=', '1', '\\n']
Tokenized   (010): ['[CLS]', 'frame', '##co', '##unt', '+', '=', '1', '\\', 'n', '[SEP]']
Filtered   (008): ['frame', '##co', '##unt', '+', '=', '1', '\\', 'n']
Detokenized (004): ['frame##co##unt', '+=', '1', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "decay = decay , \n"
Original    (005): ['decay', '=', 'decay', ',', '\\n']
Tokenized   (008): ['[CLS]', 'decay', '=', 'decay', ',', '\\', 'n', '[SEP]']
Filtered   (006): ['decay', '=', 'decay', ',', '\\', 'n']
Detokenized (005): ['decay', '=', 'decay', ',', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "expected_kwargs = { , } \n"
Original    (006): ['expected_kwargs', '=', '{', ',', '}', '\\n']
Tokenized   (013): ['[CLS]', 'expected', '_', 'kw', '##ar', '##gs', '=', '{', ',', '}', '\\', 'n', '[SEP]']
Filtered   (011): ['expected', '_', 'kw', '##ar', '##gs', '=', '{', ',', '}', '\\', 'n']
Detokenized (006): ['expected_kw##ar##gs', '=', '{', ',', '}', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "outputs [ ] = in_shapes [ ] \n"
Original    (008): ['outputs', '[', ']', '=', 'in_shapes', '[', ']', '\\n']
Tokenized   (013): ['[CLS]', 'outputs', '[', ']', '=', 'in', '_', 'shapes', '[', ']', '\\', 'n', '[SEP]']
Filtered   (011): ['outputs', '[', ']', '=', 'in', '_', 'shapes', '[', ']', '\\', 'n']
Detokenized (008): ['outputs', '[', ']', '=', 'in_shapes', '[', ']', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "buf = BufferStructure ( self . in_shapes [ ] . feature_shape [ - 1 ] ) \n"
Original    (017): ['buf', '=', 'BufferStructure', '(', 'self', '.', 'in_shapes', '[', ']', '.', 'feature_shape', '[', '-', '1', ']', ')', '\\n']
Tokenized   (028): ['[CLS]', 'bu', '##f', '=', 'buffer', '##st', '##ru', '##cture', '(', 'self', '.', 'in', '_', 'shapes', '[', ']', '.', 'feature', '_', 'shape', '[', '-', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['bu', '##f', '=', 'buffer', '##st', '##ru', '##cture', '(', 'self', '.', 'in', '_', 'shapes', '[', ']', '.', 'feature', '_', 'shape', '[', '-', '1', ']', ')', '\\', 'n']
Detokenized (017): ['bu##f', '=', 'buffer##st##ru##cture', '(', 'self', '.', 'in_shapes', '[', ']', '.', 'feature_shape', '[', '-', '1', ']', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "internals [ ] = self . in_shapes [ ] \n"
Original    (010): ['internals', '[', ']', '=', 'self', '.', 'in_shapes', '[', ']', '\\n']
Tokenized   (016): ['[CLS]', 'internal', '##s', '[', ']', '=', 'self', '.', 'in', '_', 'shapes', '[', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['internal', '##s', '[', ']', '=', 'self', '.', 'in', '_', 'shapes', '[', ']', '\\', 'n']
Detokenized (010): ['internal##s', '[', ']', '=', 'self', '.', 'in_shapes', '[', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sigma_b , centered , x_hat = buffers . internals \n"
Original    (010): ['sigma_b', ',', 'centered', ',', 'x_hat', '=', 'buffers', '.', 'internals', '\\n']
Tokenized   (019): ['[CLS]', 'sigma', '_', 'b', ',', 'centered', ',', 'x', '_', 'hat', '=', 'buffer', '##s', '.', 'internal', '##s', '\\', 'n', '[SEP]']
Filtered   (017): ['sigma', '_', 'b', ',', 'centered', ',', 'x', '_', 'hat', '=', 'buffer', '##s', '.', 'internal', '##s', '\\', 'n']
Detokenized (010): ['sigma_b', ',', 'centered', ',', 'x_hat', '=', 'buffer##s', '.', 'internal##s', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "dgamma = buffers . gradients . gamma \n"
Original    (008): ['dgamma', '=', 'buffers', '.', 'gradients', '.', 'gamma', '\\n']
Tokenized   (015): ['[CLS]', 'd', '##gam', '##ma', '=', 'buffer', '##s', '.', 'gradient', '##s', '.', 'gamma', '\\', 'n', '[SEP]']
Filtered   (013): ['d', '##gam', '##ma', '=', 'buffer', '##s', '.', 'gradient', '##s', '.', 'gamma', '\\', 'n']
Detokenized (008): ['d##gam##ma', '=', 'buffer##s', '.', 'gradient##s', '.', 'gamma', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "outdeltas = flatten_all_but_last ( buffers . output_deltas . default ) \n"
Original    (011): ['outdeltas', '=', 'flatten_all_but_last', '(', 'buffers', '.', 'output_deltas', '.', 'default', ')', '\\n']
Tokenized   (027): ['[CLS]', 'out', '##del', '##tas', '=', 'flat', '##ten', '_', 'all', '_', 'but', '_', 'last', '(', 'buffer', '##s', '.', 'output', '_', 'delta', '##s', '.', 'default', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['out', '##del', '##tas', '=', 'flat', '##ten', '_', 'all', '_', 'but', '_', 'last', '(', 'buffer', '##s', '.', 'output', '_', 'delta', '##s', '.', 'default', ')', '\\', 'n']
Detokenized (011): ['out##del##tas', '=', 'flat##ten_all_but_last', '(', 'buffer##s', '.', 'output_delta##s', '.', 'default', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_h . add_tt ( term4 , indeltas , indeltas ) \n"
Original    (011): ['_h', '.', 'add_tt', '(', 'term4', ',', 'indeltas', ',', 'indeltas', ')', '\\n']
Tokenized   (022): ['[CLS]', '_', 'h', '.', 'add', '_', 'tt', '(', 'term', '##4', ',', 'ind', '##elt', '##as', ',', 'ind', '##elt', '##as', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['_', 'h', '.', 'add', '_', 'tt', '(', 'term', '##4', ',', 'ind', '##elt', '##as', ',', 'ind', '##elt', '##as', ')', '\\', 'n']
Detokenized (011): ['_h', '.', 'add_tt', '(', 'term##4', ',', 'ind##elt##as', ',', 'ind##elt##as', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "targets_name = , mask_name = ) : \n"
Original    (008): ['targets_name', '=', ',', 'mask_name', '=', ')', ':', '\\n']
Tokenized   (015): ['[CLS]', 'targets', '_', 'name', '=', ',', 'mask', '_', 'name', '=', ')', ':', '\\', 'n', '[SEP]']
Filtered   (013): ['targets', '_', 'name', '=', ',', 'mask', '_', 'name', '=', ')', ':', '\\', 'n']
Detokenized (008): ['targets_name', '=', ',', 'mask_name', '=', ')', ':', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mask_name = , name = None ) : \n"
Original    (009): ['mask_name', '=', ',', 'name', '=', 'None', ')', ':', '\\n']
Tokenized   (014): ['[CLS]', 'mask', '_', 'name', '=', ',', 'name', '=', 'none', ')', ':', '\\', 'n', '[SEP]']
Filtered   (012): ['mask', '_', 'name', '=', ',', 'name', '=', 'none', ')', ':', '\\', 'n']
Detokenized (009): ['mask_name', '=', ',', 'name', '=', 'none', ')', ':', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "true_labels ) . astype ( np . float ) \n"
Original    (010): ['true_labels', ')', '.', 'astype', '(', 'np', '.', 'float', ')', '\\n']
Tokenized   (016): ['[CLS]', 'true', '_', 'labels', ')', '.', 'as', '##type', '(', 'np', '.', 'float', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['true', '_', 'labels', ')', '.', 'as', '##type', '(', 'np', '.', 'float', ')', '\\', 'n']
Detokenized (010): ['true_labels', ')', '.', 'as##type', '(', 'np', '.', 'float', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "epochs = [ 0 ] * 4 + [ 1 ] * 4 + [ 2 ] * 4 \n"
Original    (020): ['epochs', '=', '[', '0', ']', '*', '4', '+', '[', '1', ']', '*', '4', '+', '[', '2', ']', '*', '4', '\\n']
Tokenized   (024): ['[CLS]', 'epoch', '##s', '=', '[', '0', ']', '*', '4', '+', '[', '1', ']', '*', '4', '+', '[', '2', ']', '*', '4', '\\', 'n', '[SEP]']
Filtered   (022): ['epoch', '##s', '=', '[', '0', ']', '*', '4', '+', '[', '1', ']', '*', '4', '+', '[', '2', ']', '*', '4', '\\', 'n']
Detokenized (020): ['epoch##s', '=', '[', '0', ']', '*', '4', '+', '[', '1', ']', '*', '4', '+', '[', '2', ']', '*', '4', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "on_rtd = os . environ . get ( , None ) == \n"
Original    (013): ['on_rtd', '=', 'os', '.', 'environ', '.', 'get', '(', ',', 'None', ')', '==', '\\n']
Tokenized   (022): ['[CLS]', 'on', '_', 'rt', '##d', '=', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', ',', 'none', ')', '=', '=', '\\', 'n', '[SEP]']
Filtered   (020): ['on', '_', 'rt', '##d', '=', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', ',', 'none', ')', '=', '=', '\\', 'n']
Detokenized (013): ['on_rt##d', '=', 'os', '.', 'en##vir##on', '.', 'get', '(', ',', 'none', ')', '==', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "html_theme_path = [ sphinx_rtd_theme . get_html_theme_path ( ) ] \n"
Original    (010): ['html_theme_path', '=', '[', 'sphinx_rtd_theme', '.', 'get_html_theme_path', '(', ')', ']', '\\n']
Tokenized   (028): ['[CLS]', 'html', '_', 'theme', '_', 'path', '=', '[', 'sphinx', '_', 'rt', '##d', '_', 'theme', '.', 'get', '_', 'html', '_', 'theme', '_', 'path', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (026): ['html', '_', 'theme', '_', 'path', '=', '[', 'sphinx', '_', 'rt', '##d', '_', 'theme', '.', 'get', '_', 'html', '_', 'theme', '_', 'path', '(', ')', ']', '\\', 'n']
Detokenized (010): ['html_theme_path', '=', '[', 'sphinx_rt##d_theme', '.', 'get_html_theme_path', '(', ')', ']', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "latex_elements = { \n"
Original    (004): ['latex_elements', '=', '{', '\\n']
Tokenized   (010): ['[CLS]', 'late', '##x', '_', 'elements', '=', '{', '\\', 'n', '[SEP]']
Filtered   (008): ['late', '##x', '_', 'elements', '=', '{', '\\', 'n']
Detokenized (004): ['late##x_elements', '=', '{', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "latex_documents = [ \n"
Original    (004): ['latex_documents', '=', '[', '\\n']
Tokenized   (010): ['[CLS]', 'late', '##x', '_', 'documents', '=', '[', '\\', 'n', '[SEP]']
Filtered   (008): ['late', '##x', '_', 'documents', '=', '[', '\\', 'n']
Detokenized (004): ['late##x_documents', '=', '[', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "ignored_fallbacks = ( ) ) : \n"
Original    (007): ['ignored_fallbacks', '=', '(', ')', ')', ':', '\\n']
Tokenized   (013): ['[CLS]', 'ignored', '_', 'fall', '##backs', '=', '(', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (011): ['ignored', '_', 'fall', '##backs', '=', '(', ')', ')', ':', '\\', 'n']
Detokenized (007): ['ignored_fall##backs', '=', '(', ')', ')', ':', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""b" : 2.0 , \n"
Original    (005): ['"b"', ':', '2.0', ',', '\\n']
Tokenized   (012): ['[CLS]', '"', 'b', '"', ':', '2', '.', '0', ',', '\\', 'n', '[SEP]']
Filtered   (010): ['"', 'b', '"', ':', '2', '.', '0', ',', '\\', 'n']
Detokenized (005): ['"b"', ':', '2.0', ',', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""c" : True , \n"
Original    (005): ['"c"', ':', 'True', ',', '\\n']
Tokenized   (010): ['[CLS]', '"', 'c', '"', ':', 'true', ',', '\\', 'n', '[SEP]']
Filtered   (008): ['"', 'c', '"', ':', 'true', ',', '\\', 'n']
Detokenized (005): ['"c"', ':', 'true', ',', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""d" : , \n"
Original    (004): ['"d"', ':', ',', '\\n']
Tokenized   (009): ['[CLS]', '"', 'd', '"', ':', ',', '\\', 'n', '[SEP]']
Filtered   (007): ['"', 'd', '"', ':', ',', '\\', 'n']
Detokenized (004): ['"d"', ':', ',', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""e" : [ 1 , 2 , 3 ] , \n"
Original    (011): ['"e"', ':', '[', '1', ',', '2', ',', '3', ']', ',', '\\n']
Tokenized   (016): ['[CLS]', '"', 'e', '"', ':', '[', '1', ',', '2', ',', '3', ']', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['"', 'e', '"', ':', '[', '1', ',', '2', ',', '3', ']', ',', '\\', 'n']
Detokenized (011): ['"e"', ':', '[', '1', ',', '2', ',', '3', ']', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""f" : { : , : } , \n"
Original    (009): ['"f"', ':', '{', ':', ',', ':', '}', ',', '\\n']
Tokenized   (014): ['[CLS]', '"', 'f', '"', ':', '{', ':', ',', ':', '}', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['"', 'f', '"', ':', '{', ':', ',', ':', '}', ',', '\\', 'n']
Detokenized (009): ['"f"', ':', '{', ':', ',', ':', '}', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""answer" : 42 \n"
Original    (004): ['"answer"', ':', '42', '\\n']
Tokenized   (009): ['[CLS]', '"', 'answer', '"', ':', '42', '\\', 'n', '[SEP]']
Filtered   (007): ['"', 'answer', '"', ':', '42', '\\', 'n']
Detokenized (004): ['"answer"', ':', '42', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "p_error = self . kp * current_error \n"
Original    (008): ['p_error', '=', 'self', '.', 'kp', '*', 'current_error', '\\n']
Tokenized   (016): ['[CLS]', 'p', '_', 'error', '=', 'self', '.', 'k', '##p', '*', 'current', '_', 'error', '\\', 'n', '[SEP]']
Filtered   (014): ['p', '_', 'error', '=', 'self', '.', 'k', '##p', '*', 'current', '_', 'error', '\\', 'n']
Detokenized (008): ['p_error', '=', 'self', '.', 'k##p', '*', 'current_error', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "d_error = self . kd * ( current_error - self . previous_error ) / timestep \n"
Original    (016): ['d_error', '=', 'self', '.', 'kd', '*', '(', 'current_error', '-', 'self', '.', 'previous_error', ')', '/', 'timestep', '\\n']
Tokenized   (028): ['[CLS]', 'd', '_', 'error', '=', 'self', '.', 'k', '##d', '*', '(', 'current', '_', 'error', '-', 'self', '.', 'previous', '_', 'error', ')', '/', 'times', '##te', '##p', '\\', 'n', '[SEP]']
Filtered   (026): ['d', '_', 'error', '=', 'self', '.', 'k', '##d', '*', '(', 'current', '_', 'error', '-', 'self', '.', 'previous', '_', 'error', ')', '/', 'times', '##te', '##p', '\\', 'n']
Detokenized (016): ['d_error', '=', 'self', '.', 'k##d', '*', '(', 'current_error', '-', 'self', '.', 'previous_error', ')', '/', 'times##te##p', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "current_error + self . previous_error ) / 2 + self . integral_error \n"
Original    (013): ['current_error', '+', 'self', '.', 'previous_error', ')', '/', '2', '+', 'self', '.', 'integral_error', '\\n']
Tokenized   (022): ['[CLS]', 'current', '_', 'error', '+', 'self', '.', 'previous', '_', 'error', ')', '/', '2', '+', 'self', '.', 'integral', '_', 'error', '\\', 'n', '[SEP]']
Filtered   (020): ['current', '_', 'error', '+', 'self', '.', 'previous', '_', 'error', ')', '/', '2', '+', 'self', '.', 'integral', '_', 'error', '\\', 'n']
Detokenized (013): ['current_error', '+', 'self', '.', 'previous_error', ')', '/', '2', '+', 'self', '.', 'integral_error', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "i_error = self . ki * self . integral_error \n"
Original    (010): ['i_error', '=', 'self', '.', 'ki', '*', 'self', '.', 'integral_error', '\\n']
Tokenized   (017): ['[CLS]', 'i', '_', 'error', '=', 'self', '.', 'ki', '*', 'self', '.', 'integral', '_', 'error', '\\', 'n', '[SEP]']
Filtered   (015): ['i', '_', 'error', '=', 'self', '.', 'ki', '*', 'self', '.', 'integral', '_', 'error', '\\', 'n']
Detokenized (010): ['i_error', '=', 'self', '.', 'ki', '*', 'self', '.', 'integral_error', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "total_error = p_error + d_error + i_error \n"
Original    (008): ['total_error', '=', 'p_error', '+', 'd_error', '+', 'i_error', '\\n']
Tokenized   (019): ['[CLS]', 'total', '_', 'error', '=', 'p', '_', 'error', '+', 'd', '_', 'error', '+', 'i', '_', 'error', '\\', 'n', '[SEP]']
Filtered   (017): ['total', '_', 'error', '=', 'p', '_', 'error', '+', 'd', '_', 'error', '+', 'i', '_', 'error', '\\', 'n']
Detokenized (008): ['total_error', '=', 'p_error', '+', 'd_error', '+', 'i_error', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "cmd_match_names = cmd . Cmd . completenames ( self , text , * ignored ) \n"
Original    (016): ['cmd_match_names', '=', 'cmd', '.', 'Cmd', '.', 'completenames', '(', 'self', ',', 'text', ',', '*', 'ignored', ')', '\\n']
Tokenized   (028): ['[CLS]', 'cm', '##d', '_', 'match', '_', 'names', '=', 'cm', '##d', '.', 'cm', '##d', '.', 'complete', '##name', '##s', '(', 'self', ',', 'text', ',', '*', 'ignored', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['cm', '##d', '_', 'match', '_', 'names', '=', 'cm', '##d', '.', 'cm', '##d', '.', 'complete', '##name', '##s', '(', 'self', ',', 'text', ',', '*', 'ignored', ')', '\\', 'n']
Detokenized (016): ['cm##d_match_names', '=', 'cm##d', '.', 'cm##d', '.', 'complete##name##s', '(', 'self', ',', 'text', ',', '*', 'ignored', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "obj_names = self . ctrl_client . objects . keys ( ) \n"
Original    (012): ['obj_names', '=', 'self', '.', 'ctrl_client', '.', 'objects', '.', 'keys', '(', ')', '\\n']
Tokenized   (021): ['[CLS]', 'ob', '##j', '_', 'names', '=', 'self', '.', 'ct', '##rl', '_', 'client', '.', 'objects', '.', 'keys', '(', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['ob', '##j', '_', 'names', '=', 'self', '.', 'ct', '##rl', '_', 'client', '.', 'objects', '.', 'keys', '(', ')', '\\', 'n']
Detokenized (012): ['ob##j_names', '=', 'self', '.', 'ct##rl_client', '.', 'objects', '.', 'keys', '(', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "api_match_names = [ x for x in obj_names if x . startswith ( text ) ] \n"
Original    (017): ['api_match_names', '=', '[', 'x', 'for', 'x', 'in', 'obj_names', 'if', 'x', '.', 'startswith', '(', 'text', ')', ']', '\\n']
Tokenized   (028): ['[CLS]', 'api', '_', 'match', '_', 'names', '=', '[', 'x', 'for', 'x', 'in', 'ob', '##j', '_', 'names', 'if', 'x', '.', 'starts', '##with', '(', 'text', ')', ']', '\\', 'n', '[SEP]']
Filtered   (026): ['api', '_', 'match', '_', 'names', '=', '[', 'x', 'for', 'x', 'in', 'ob', '##j', '_', 'names', 'if', 'x', '.', 'starts', '##with', '(', 'text', ')', ']', '\\', 'n']
Detokenized (017): ['api_match_names', '=', '[', 'x', 'for', 'x', 'in', 'ob##j_names', 'if', 'x', '.', 'starts##with', '(', 'text', ')', ']', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "reply_time = self . ctrl_client . ping ( ) \n"
Original    (010): ['reply_time', '=', 'self', '.', 'ctrl_client', '.', 'ping', '(', ')', '\\n']
Tokenized   (018): ['[CLS]', 'reply', '_', 'time', '=', 'self', '.', 'ct', '##rl', '_', 'client', '.', 'ping', '(', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['reply', '_', 'time', '=', 'self', '.', 'ct', '##rl', '_', 'client', '.', 'ping', '(', ')', '\\', 'n']
Detokenized (010): ['reply_time', '=', 'self', '.', 'ct##rl_client', '.', 'ping', '(', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sub_addr = sys . argv [ 2 ] \n"
Original    (009): ['sub_addr', '=', 'sys', '.', 'argv', '[', '2', ']', '\\n']
Tokenized   (018): ['[CLS]', 'sub', '_', 'add', '##r', '=', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '2', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['sub', '_', 'add', '##r', '=', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '2', ']', '\\', 'n']
Detokenized (009): ['sub_add##r', '=', 'sy##s', '.', 'ar##g##v', '[', '2', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "CLI ( ctrl_addr , sub_addr ) . cmdloop ( ) \n"
Original    (011): ['CLI', '(', 'ctrl_addr', ',', 'sub_addr', ')', '.', 'cmdloop', '(', ')', '\\n']
Tokenized   (024): ['[CLS]', 'cl', '##i', '(', 'ct', '##rl', '_', 'add', '##r', ',', 'sub', '_', 'add', '##r', ')', '.', 'cm', '##dl', '##oop', '(', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['cl', '##i', '(', 'ct', '##rl', '_', 'add', '##r', ',', 'sub', '_', 'add', '##r', ')', '.', 'cm', '##dl', '##oop', '(', ')', '\\', 'n']
Detokenized (011): ['cl##i', '(', 'ct##rl_add##r', ',', 'sub_add##r', ')', '.', 'cm##dl##oop', '(', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "duty = int ( cur_pwm [ "duty_ns" ] ) \n"
Original    (010): ['duty', '=', 'int', '(', 'cur_pwm', '[', '"duty_ns"', ']', ')', '\\n']
Tokenized   (022): ['[CLS]', 'duty', '=', 'int', '(', 'cu', '##r', '_', 'p', '##w', '##m', '[', '"', 'duty', '_', 'ns', '"', ']', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['duty', '=', 'int', '(', 'cu', '##r', '_', 'p', '##w', '##m', '[', '"', 'duty', '_', 'ns', '"', ']', ')', '\\', 'n']
Detokenized (010): ['duty', '=', 'int', '(', 'cu##r_p##w##m', '[', '"duty_ns"', ']', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "read_pos = int ( round ( ( ( duty - 580000 ) / 2320000. ) * 180 ) ) \n"
Original    (020): ['read_pos', '=', 'int', '(', 'round', '(', '(', '(', 'duty', '-', '580000', ')', '/', '2320000.', ')', '*', '180', ')', ')', '\\n']
Tokenized   (031): ['[CLS]', 'read', '_', 'po', '##s', '=', 'int', '(', 'round', '(', '(', '(', 'duty', '-', '580', '##00', '##0', ')', '/', '232', '##00', '##00', '.', ')', '*', '180', ')', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['read', '_', 'po', '##s', '=', 'int', '(', 'round', '(', '(', '(', 'duty', '-', '580', '##00', '##0', ')', '/', '232', '##00', '##00', '.', ')', '*', '180', ')', ')', '\\', 'n']
Detokenized (020): ['read_po##s', '=', 'int', '(', 'round', '(', '(', '(', 'duty', '-', '580##00##0', ')', '/', '232##00##00.', ')', '*', '180', ')', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "create_login_url , create_logout_url \n"
Original    (004): ['create_login_url', ',', 'create_logout_url', '\\n']
Tokenized   (019): ['[CLS]', 'create', '_', 'log', '##in', '_', 'ur', '##l', ',', 'create', '_', 'logo', '##ut', '_', 'ur', '##l', '\\', 'n', '[SEP]']
Filtered   (017): ['create', '_', 'log', '##in', '_', 'ur', '##l', ',', 'create', '_', 'logo', '##ut', '_', 'ur', '##l', '\\', 'n']
Detokenized (004): ['create_log##in_ur##l', ',', 'create_logo##ut_ur##l', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "create_logout_url ( request . url ) \n"
Original    (007): ['create_logout_url', '(', 'request', '.', 'url', ')', '\\n']
Tokenized   (017): ['[CLS]', 'create', '_', 'logo', '##ut', '_', 'ur', '##l', '(', 'request', '.', 'ur', '##l', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['create', '_', 'logo', '##ut', '_', 'ur', '##l', '(', 'request', '.', 'ur', '##l', ')', '\\', 'n']
Detokenized (007): ['create_logo##ut_ur##l', '(', 'request', '.', 'ur##l', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_value = _options_header_vkw ( _value , kw ) \n"
Original    (009): ['_value', '=', '_options_header_vkw', '(', '_value', ',', 'kw', ')', '\\n']
Tokenized   (021): ['[CLS]', '_', 'value', '=', '_', 'options', '_', 'header', '_', 'v', '##k', '##w', '(', '_', 'value', ',', 'kw', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['_', 'value', '=', '_', 'options', '_', 'header', '_', 'v', '##k', '##w', '(', '_', 'value', ',', 'kw', ')', '\\', 'n']
Detokenized (009): ['_value', '=', '_options_header_v##k##w', '(', '_value', ',', 'kw', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "value_type == value_subtype == ) or \n"
Original    (007): ['value_type', '==', 'value_subtype', '==', ')', 'or', '\\n']
Tokenized   (017): ['[CLS]', 'value', '_', 'type', '=', '=', 'value', '_', 'sub', '##type', '=', '=', ')', 'or', '\\', 'n', '[SEP]']
Filtered   (015): ['value', '_', 'type', '=', '=', 'value', '_', 'sub', '##type', '=', '=', ')', 'or', '\\', 'n']
Detokenized (007): ['value_type', '==', 'value_sub##type', '==', ')', 'or', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "value_subtype == or \n"
Original    (004): ['value_subtype', '==', 'or', '\\n']
Tokenized   (011): ['[CLS]', 'value', '_', 'sub', '##type', '=', '=', 'or', '\\', 'n', '[SEP]']
Filtered   (009): ['value', '_', 'sub', '##type', '=', '=', 'or', '\\', 'n']
Detokenized (004): ['value_sub##type', '==', 'or', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "item_subtype == value_subtype ) ) \n"
Original    (006): ['item_subtype', '==', 'value_subtype', ')', ')', '\\n']
Tokenized   (016): ['[CLS]', 'item', '_', 'sub', '##type', '=', '=', 'value', '_', 'sub', '##type', ')', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['item', '_', 'sub', '##type', '=', '=', 'value', '_', 'sub', '##type', ')', ')', '\\', 'n']
Detokenized (006): ['item_sub##type', '==', 'value_sub##type', ')', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "no_cache = cache_property ( , , None ) \n"
Original    (009): ['no_cache', '=', 'cache_property', '(', ',', ',', 'None', ')', '\\n']
Tokenized   (016): ['[CLS]', 'no', '_', 'cache', '=', 'cache', '_', 'property', '(', ',', ',', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['no', '_', 'cache', '=', 'cache', '_', 'property', '(', ',', ',', 'none', ')', '\\', 'n']
Detokenized (009): ['no_cache', '=', 'cache_property', '(', ',', ',', 'none', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "no_store = cache_property ( , None , bool ) \n"
Original    (010): ['no_store', '=', 'cache_property', '(', ',', 'None', ',', 'bool', ')', '\\n']
Tokenized   (018): ['[CLS]', 'no', '_', 'store', '=', 'cache', '_', 'property', '(', ',', 'none', ',', 'boo', '##l', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['no', '_', 'store', '=', 'cache', '_', 'property', '(', ',', 'none', ',', 'boo', '##l', ')', '\\', 'n']
Detokenized (010): ['no_store', '=', 'cache_property', '(', ',', 'none', ',', 'boo##l', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "max_age = cache_property ( , - 1 , int ) \n"
Original    (011): ['max_age', '=', 'cache_property', '(', ',', '-', '1', ',', 'int', ')', '\\n']
Tokenized   (018): ['[CLS]', 'max', '_', 'age', '=', 'cache', '_', 'property', '(', ',', '-', '1', ',', 'int', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['max', '_', 'age', '=', 'cache', '_', 'property', '(', ',', '-', '1', ',', 'int', ')', '\\', 'n']
Detokenized (011): ['max_age', '=', 'cache_property', '(', ',', '-', '1', ',', 'int', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "no_transform = cache_property ( , None , None ) \n"
Original    (010): ['no_transform', '=', 'cache_property', '(', ',', 'None', ',', 'None', ')', '\\n']
Tokenized   (017): ['[CLS]', 'no', '_', 'transform', '=', 'cache', '_', 'property', '(', ',', 'none', ',', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['no', '_', 'transform', '=', 'cache', '_', 'property', '(', ',', 'none', ',', 'none', ')', '\\', 'n']
Detokenized (010): ['no_transform', '=', 'cache_property', '(', ',', 'none', ',', 'none', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "max_stale = cache_property ( , , int ) \n"
Original    (009): ['max_stale', '=', 'cache_property', '(', ',', ',', 'int', ')', '\\n']
Tokenized   (016): ['[CLS]', 'max', '_', 'stale', '=', 'cache', '_', 'property', '(', ',', ',', 'int', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['max', '_', 'stale', '=', 'cache', '_', 'property', '(', ',', ',', 'int', ')', '\\', 'n']
Detokenized (009): ['max_stale', '=', 'cache_property', '(', ',', ',', 'int', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "etag , weak = unquote_etag ( etag ) \n"
Original    (009): ['etag', ',', 'weak', '=', 'unquote_etag', '(', 'etag', ')', '\\n']
Tokenized   (019): ['[CLS]', 'eta', '##g', ',', 'weak', '=', 'un', '##qu', '##ote', '_', 'eta', '##g', '(', 'eta', '##g', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['eta', '##g', ',', 'weak', '=', 'un', '##qu', '##ote', '_', 'eta', '##g', '(', 'eta', '##g', ')', '\\', 'n']
Detokenized (009): ['eta##g', ',', 'weak', '=', 'un##qu##ote_eta##g', '(', 'eta##g', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "uri = property ( lambda x : x . get ( ) , doc = ) \n"
Original    (017): ['uri', '=', 'property', '(', 'lambda', 'x', ':', 'x', '.', 'get', '(', ')', ',', 'doc', '=', ')', '\\n']
Tokenized   (021): ['[CLS]', 'ur', '##i', '=', 'property', '(', 'lambda', 'x', ':', 'x', '.', 'get', '(', ')', ',', 'doc', '=', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['ur', '##i', '=', 'property', '(', 'lambda', 'x', ':', 'x', '.', 'get', '(', ')', ',', 'doc', '=', ')', '\\', 'n']
Detokenized (017): ['ur##i', '=', 'property', '(', 'lambda', 'x', ':', 'x', '.', 'get', '(', ')', ',', 'doc', '=', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "_require_quoting = frozenset ( [ , , , ] ) \n"
Original    (011): ['_require_quoting', '=', 'frozenset', '(', '[', ',', ',', ',', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', '_', 'require', '_', 'quoting', '=', 'frozen', '##set', '(', '[', ',', ',', ',', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['_', 'require', '_', 'quoting', '=', 'frozen', '##set', '(', '[', ',', ',', ',', ']', ')', '\\', 'n']
Detokenized (011): ['_require_quoting', '=', 'frozen##set', '(', '[', ',', ',', ',', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "auth_type = d . pop ( , None ) or \n"
Original    (011): ['auth_type', '=', 'd', '.', 'pop', '(', ',', 'None', ')', 'or', '\\n']
Tokenized   (017): ['[CLS]', 'au', '##th', '_', 'type', '=', 'd', '.', 'pop', '(', ',', 'none', ')', 'or', '\\', 'n', '[SEP]']
Filtered   (015): ['au', '##th', '_', 'type', '=', 'd', '.', 'pop', '(', ',', 'none', ')', 'or', '\\', 'n']
Detokenized (011): ['au##th_type', '=', 'd', '.', 'pop', '(', ',', 'none', ')', 'or', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "allow_token = key not in self . _require_quoting ) ) \n"
Original    (011): ['allow_token', '=', 'key', 'not', 'in', 'self', '.', '_require_quoting', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'allow', '_', 'token', '=', 'key', 'not', 'in', 'self', '.', '_', 'require', '_', 'quoting', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['allow', '_', 'token', '=', 'key', 'not', 'in', 'self', '.', '_', 'require', '_', 'quoting', ')', ')', '\\', 'n']
Detokenized (011): ['allow_token', '=', 'key', 'not', 'in', 'self', '.', '_require_quoting', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "realm = auth_property ( , doc = ) \n"
Original    (009): ['realm', '=', 'auth_property', '(', ',', 'doc', '=', ')', '\\n']
Tokenized   (015): ['[CLS]', 'realm', '=', 'au', '##th', '_', 'property', '(', ',', 'doc', '=', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['realm', '=', 'au', '##th', '_', 'property', '(', ',', 'doc', '=', ')', '\\', 'n']
Detokenized (009): ['realm', '=', 'au##th_property', '(', ',', 'doc', '=', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rshell , shell , clear_datastore , create_user , \n"
Original    (009): ['rshell', ',', 'shell', ',', 'clear_datastore', ',', 'create_user', ',', '\\n']
Tokenized   (019): ['[CLS]', 'rs', '##hell', ',', 'shell', ',', 'clear', '_', 'data', '##stor', '##e', ',', 'create', '_', 'user', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['rs', '##hell', ',', 'shell', ',', 'clear', '_', 'data', '##stor', '##e', ',', 'create', '_', 'user', ',', '\\', 'n']
Detokenized (009): ['rs##hell', ',', 'shell', ',', 'clear_data##stor##e', ',', 'create_user', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "Rule ( , endpoint = , \n"
Original    (007): ['Rule', '(', ',', 'endpoint', '=', ',', '\\n']
Tokenized   (011): ['[CLS]', 'rule', '(', ',', 'end', '##point', '=', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['rule', '(', ',', 'end', '##point', '=', ',', '\\', 'n']
Detokenized (007): ['rule', '(', ',', 'end##point', '=', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "data_field = db . StringProperty ( required = True , \n"
Original    (011): ['data_field', '=', 'db', '.', 'StringProperty', '(', 'required', '=', 'True', ',', '\\n']
Tokenized   (019): ['[CLS]', 'data', '_', 'field', '=', 'db', '.', 'string', '##pro', '##per', '##ty', '(', 'required', '=', 'true', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['data', '_', 'field', '=', 'db', '.', 'string', '##pro', '##per', '##ty', '(', 'required', '=', 'true', ',', '\\', 'n']
Detokenized (011): ['data_field', '=', 'db', '.', 'string##pro##per##ty', '(', 'required', '=', 'true', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dst_name = path . join ( dst_path , filename ) \n"
Original    (011): ['dst_name', '=', 'path', '.', 'join', '(', 'dst_path', ',', 'filename', ')', '\\n']
Tokenized   (021): ['[CLS]', 'ds', '##t', '_', 'name', '=', 'path', '.', 'join', '(', 'ds', '##t', '_', 'path', ',', 'file', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['ds', '##t', '_', 'name', '=', 'path', '.', 'join', '(', 'ds', '##t', '_', 'path', ',', 'file', '##name', ')', '\\', 'n']
Detokenized (011): ['ds##t_name', '=', 'path', '.', 'join', '(', 'ds##t_path', ',', 'file##name', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "modifiable_problem_fields = [ "description" ] \n"
Original    (006): ['modifiable_problem_fields', '=', '[', '"description"', ']', '\\n']
Tokenized   (017): ['[CLS]', 'mod', '##if', '##iable', '_', 'problem', '_', 'fields', '=', '[', '"', 'description', '"', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['mod', '##if', '##iable', '_', 'problem', '_', 'fields', '=', '[', '"', 'description', '"', ']', '\\', 'n']
Detokenized (006): ['mod##if##iable_problem_fields', '=', '[', '"description"', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "problem = api . problem . get_problem ( pid = pid ) \n"
Original    (013): ['problem', '=', 'api', '.', 'problem', '.', 'get_problem', '(', 'pid', '=', 'pid', ')', '\\n']
Tokenized   (020): ['[CLS]', 'problem', '=', 'api', '.', 'problem', '.', 'get', '_', 'problem', '(', 'pi', '##d', '=', 'pi', '##d', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['problem', '=', 'api', '.', 'problem', '.', 'get', '_', 'problem', '(', 'pi', '##d', '=', 'pi', '##d', ')', '\\', 'n']
Detokenized (013): ['problem', '=', 'api', '.', 'problem', '.', 'get_problem', '(', 'pi##d', '=', 'pi##d', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "build = get_generator ( pid ) . generate ( random , pid , api . autogen_tools , n ) \n"
Original    (020): ['build', '=', 'get_generator', '(', 'pid', ')', '.', 'generate', '(', 'random', ',', 'pid', ',', 'api', '.', 'autogen_tools', ',', 'n', ')', '\\n']
Tokenized   (030): ['[CLS]', 'build', '=', 'get', '_', 'generator', '(', 'pi', '##d', ')', '.', 'generate', '(', 'random', ',', 'pi', '##d', ',', 'api', '.', 'auto', '##gen', '_', 'tools', ',', 'n', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['build', '=', 'get', '_', 'generator', '(', 'pi', '##d', ')', '.', 'generate', '(', 'random', ',', 'pi', '##d', ',', 'api', '.', 'auto', '##gen', '_', 'tools', ',', 'n', ')', '\\', 'n']
Detokenized (020): ['build', '=', 'get_generator', '(', 'pi##d', ')', '.', 'generate', '(', 'random', ',', 'pi##d', ',', 'api', '.', 'auto##gen_tools', ',', 'n', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "autogen_instance_path = get_instance_path ( pid , n = n ) \n"
Original    (011): ['autogen_instance_path', '=', 'get_instance_path', '(', 'pid', ',', 'n', '=', 'n', ')', '\\n']
Tokenized   (024): ['[CLS]', 'auto', '##gen', '_', 'instance', '_', 'path', '=', 'get', '_', 'instance', '_', 'path', '(', 'pi', '##d', ',', 'n', '=', 'n', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['auto', '##gen', '_', 'instance', '_', 'path', '=', 'get', '_', 'instance', '_', 'path', '(', 'pi', '##d', ',', 'n', '=', 'n', ')', '\\', 'n']
Detokenized (011): ['auto##gen_instance_path', '=', 'get_instance_path', '(', 'pi##d', ',', 'n', '=', 'n', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""resource_files" : { \n"
Original    (004): ['"resource_files"', ':', '{', '\\n']
Tokenized   (011): ['[CLS]', '"', 'resource', '_', 'files', '"', ':', '{', '\\', 'n', '[SEP]']
Filtered   (009): ['"', 'resource', '_', 'files', '"', ':', '{', '\\', 'n']
Detokenized (004): ['"resource_files"', ':', '{', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "instance_path = path . join ( path . dirname ( generator_path ) , "instances" , name , str ( n ) ) \n"
Original    (023): ['instance_path', '=', 'path', '.', 'join', '(', 'path', '.', 'dirname', '(', 'generator_path', ')', ',', '"instances"', ',', 'name', ',', 'str', '(', 'n', ')', ')', '\\n']
Tokenized   (034): ['[CLS]', 'instance', '_', 'path', '=', 'path', '.', 'join', '(', 'path', '.', 'dir', '##name', '(', 'generator', '_', 'path', ')', ',', '"', 'instances', '"', ',', 'name', ',', 'st', '##r', '(', 'n', ')', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['instance', '_', 'path', '=', 'path', '.', 'join', '(', 'path', '.', 'dir', '##name', '(', 'generator', '_', 'path', ')', ',', '"', 'instances', '"', ',', 'name', ',', 'st', '##r', '(', 'n', ')', ')', '\\', 'n']
Detokenized (023): ['instance_path', '=', 'path', '.', 'join', '(', 'path', '.', 'dir##name', '(', 'generator_path', ')', ',', '"instances"', ',', 'name', ',', 'st##r', '(', 'n', ')', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : ""correct" : correct , \n"
Original    (005): ['"correct"', ':', 'correct', ',', '\\n']
Tokenized   (010): ['[CLS]', '"', 'correct', '"', ':', 'correct', ',', '\\', 'n', '[SEP]']
Filtered   (008): ['"', 'correct', '"', ':', 'correct', ',', '\\', 'n']
Detokenized (005): ['"correct"', ':', 'correct', ',', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""points" : problem [ "score" ] , \n"
Original    (008): ['"points"', ':', 'problem', '[', '"score"', ']', ',', '\\n']
Tokenized   (015): ['[CLS]', '"', 'points', '"', ':', 'problem', '[', '"', 'score', '"', ']', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['"', 'points', '"', ':', 'problem', '[', '"', 'score', '"', ']', ',', '\\', 'n']
Detokenized (008): ['"points"', ':', 'problem', '[', '"score"', ']', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""message" : message \n"
Original    (004): ['"message"', ':', 'message', '\\n']
Tokenized   (009): ['[CLS]', '"', 'message', '"', ':', 'message', '\\', 'n', '[SEP]']
Filtered   (007): ['"', 'message', '"', ':', 'message', '\\', 'n']
Detokenized (004): ['"message"', ':', 'message', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "k = str ( random . randint ( 0 , 1000 ) ) \n"
Original    (014): ['k', '=', 'str', '(', 'random', '.', 'randint', '(', '0', ',', '1000', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'k', '=', 'st', '##r', '(', 'random', '.', 'rand', '##int', '(', '0', ',', '1000', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['k', '=', 'st', '##r', '(', 'random', '.', 'rand', '##int', '(', '0', ',', '1000', ')', ')', '\\', 'n']
Detokenized (014): ['k', '=', 'st##r', '(', 'random', '.', 'rand##int', '(', '0', ',', '1000', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""public" : [ ( "/tmp/key" , "public_static" ) ] , \n"
Original    (011): ['"public"', ':', '[', '(', '"/tmp/key"', ',', '"public_static"', ')', ']', ',', '\\n']
Tokenized   (026): ['[CLS]', '"', 'public', '"', ':', '[', '(', '"', '/', 't', '##mp', '/', 'key', '"', ',', '"', 'public', '_', 'static', '"', ')', ']', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['"', 'public', '"', ':', '[', '(', '"', '/', 't', '##mp', '/', 'key', '"', ',', '"', 'public', '_', 'static', '"', ')', ']', ',', '\\', 'n']
Detokenized (011): ['"public"', ':', '[', '(', '"/t##mp/key"', ',', '"public_static"', ')', ']', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""private" : [ ( "/tmp/key" , "private_static" ) ] \n"
Original    (010): ['"private"', ':', '[', '(', '"/tmp/key"', ',', '"private_static"', ')', ']', '\\n']
Tokenized   (025): ['[CLS]', '"', 'private', '"', ':', '[', '(', '"', '/', 't', '##mp', '/', 'key', '"', ',', '"', 'private', '_', 'static', '"', ')', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['"', 'private', '"', ':', '[', '(', '"', '/', 't', '##mp', '/', 'key', '"', ',', '"', 'private', '_', 'static', '"', ')', ']', '\\', 'n']
Detokenized (010): ['"private"', ':', '[', '(', '"/t##mp/key"', ',', '"private_static"', ')', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "layout = eval ( scriptWindow . setLayout ( layout ) \n"
Original    (011): ['layout', '=', 'eval', '(', 'scriptWindow', '.', 'setLayout', '(', 'layout', ')', '\\n']
Tokenized   (019): ['[CLS]', 'layout', '=', 'eva', '##l', '(', 'script', '##wind', '##ow', '.', 'set', '##lay', '##out', '(', 'layout', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['layout', '=', 'eva', '##l', '(', 'script', '##wind', '##ow', '.', 'set', '##lay', '##out', '(', 'layout', ')', '\\', 'n']
Detokenized (011): ['layout', '=', 'eva##l', '(', 'script##wind##ow', '.', 'set##lay##out', '(', 'layout', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "scriptWindow . _Widget__qtWidget . resize ( 995 , 500 ) \n"
Original    (011): ['scriptWindow', '.', '_Widget__qtWidget', '.', 'resize', '(', '995', ',', '500', ')', '\\n']
Tokenized   (026): ['[CLS]', 'script', '##wind', '##ow', '.', '_', 'wi', '##dget', '_', '_', 'q', '##t', '##wi', '##dget', '.', 'res', '##ize', '(', '99', '##5', ',', '500', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['script', '##wind', '##ow', '.', '_', 'wi', '##dget', '_', '_', 'q', '##t', '##wi', '##dget', '.', 'res', '##ize', '(', '99', '##5', ',', '500', ')', '\\', 'n']
Detokenized (011): ['script##wind##ow', '.', '_wi##dget__q##t##wi##dget', '.', 'res##ize', '(', '99##5', ',', '500', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""inputSequence" , \n"
Original    (003): ['"inputSequence"', ',', '\\n']
Tokenized   (011): ['[CLS]', '"', 'inputs', '##e', '##que', '##nce', '"', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['"', 'inputs', '##e', '##que', '##nce', '"', ',', '\\', 'n']
Detokenized (003): ['"inputs##e##que##nce"', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "defaultValue = "" , \n"
Original    (005): ['defaultValue', '=', '""', ',', '\\n']
Tokenized   (011): ['[CLS]', 'default', '##val', '##ue', '=', '"', '"', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['default', '##val', '##ue', '=', '"', '"', ',', '\\', 'n']
Detokenized (005): ['default##val##ue', '=', '""', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "dc . write ( "-" + objectName , "bound" , b ) \n"
Original    (013): ['dc', '.', 'write', '(', '"-"', '+', 'objectName', ',', '"bound"', ',', 'b', ')', '\\n']
Tokenized   (021): ['[CLS]', 'dc', '.', 'write', '(', '"', '-', '"', '+', 'object', '##name', ',', '"', 'bound', '"', ',', 'b', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['dc', '.', 'write', '(', '"', '-', '"', '+', 'object', '##name', ',', '"', 'bound', '"', ',', 'b', ')', '\\', 'n']
Detokenized (013): ['dc', '.', 'write', '(', '"-"', '+', 'object##name', ',', '"bound"', ',', 'b', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "additionalTerminalPlugTypes = ( GafferScene . ScenePlug , ) \n"
Original    (009): ['additionalTerminalPlugTypes', '=', '(', 'GafferScene', '.', 'ScenePlug', ',', ')', '\\n']
Tokenized   (024): ['[CLS]', 'additional', '##ter', '##mina', '##lp', '##lu', '##gt', '##ype', '##s', '=', '(', 'ga', '##ffer', '##sc', '##ene', '.', 'scene', '##pl', '##ug', ',', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['additional', '##ter', '##mina', '##lp', '##lu', '##gt', '##ype', '##s', '=', '(', 'ga', '##ffer', '##sc', '##ene', '.', 'scene', '##pl', '##ug', ',', ')', '\\', 'n']
Detokenized (009): ['additional##ter##mina##lp##lu##gt##ype##s', '=', '(', 'ga##ffer##sc##ene', '.', 'scene##pl##ug', ',', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "replace = context . get ( "textWriter:replace" , IECore . StringVectorData ( ) ) \n"
Original    (015): ['replace', '=', 'context', '.', 'get', '(', '"textWriter:replace"', ',', 'IECore', '.', 'StringVectorData', '(', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'replace', '=', 'context', '.', 'get', '(', '"', 'text', '##writer', ':', 'replace', '"', ',', 'iec', '##ore', '.', 'string', '##ve', '##ctor', '##da', '##ta', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['replace', '=', 'context', '.', 'get', '(', '"', 'text', '##writer', ':', 'replace', '"', ',', 'iec', '##ore', '.', 'string', '##ve', '##ctor', '##da', '##ta', '(', ')', ')', '\\', 'n']
Detokenized (015): ['replace', '=', 'context', '.', 'get', '(', '"text##writer:replace"', ',', 'iec##ore', '.', 'string##ve##ctor##da##ta', '(', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "inMetadata = r [ "out" ] [ "metadata" ] . getValue ( ) \n"
Original    (014): ['inMetadata', '=', 'r', '[', '"out"', ']', '[', '"metadata"', ']', '.', 'getValue', '(', ')', '\\n']
Tokenized   (026): ['[CLS]', 'in', '##met', '##ada', '##ta', '=', 'r', '[', '"', 'out', '"', ']', '[', '"', 'metadata', '"', ']', '.', 'get', '##val', '##ue', '(', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['in', '##met', '##ada', '##ta', '=', 'r', '[', '"', 'out', '"', ']', '[', '"', 'metadata', '"', ']', '.', 'get', '##val', '##ue', '(', ')', '\\', 'n']
Detokenized (014): ['in##met##ada##ta', '=', 'r', '[', '"out"', ']', '[', '"metadata"', ']', '.', 'get##val##ue', '(', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "negFileName = os . path . expandvars ( "$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr" \n"
Original    (010): ['negFileName', '=', 'os', '.', 'path', '.', 'expandvars', '(', '"$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr"', '\\n']
Tokenized   (052): ['[CLS]', 'ne', '##gf', '##ile', '##name', '=', 'os', '.', 'path', '.', 'expand', '##var', '##s', '(', '"', '$', 'ga', '##ffer', '_', 'root', '/', 'python', '/', 'ga', '##ffer', '##ima', '##get', '##est', '/', 'images', '/', 'check', '##er', '##with', '##ne', '##gative', '##da', '##ta', '##wind', '##ow', '.', '200', '##x', '##15', '##0', '.', 'ex', '##r', '"', '\\', 'n', '[SEP]']
Filtered   (050): ['ne', '##gf', '##ile', '##name', '=', 'os', '.', 'path', '.', 'expand', '##var', '##s', '(', '"', '$', 'ga', '##ffer', '_', 'root', '/', 'python', '/', 'ga', '##ffer', '##ima', '##get', '##est', '/', 'images', '/', 'check', '##er', '##with', '##ne', '##gative', '##da', '##ta', '##wind', '##ow', '.', '200', '##x', '##15', '##0', '.', 'ex', '##r', '"', '\\', 'n']
Detokenized (010): ['ne##gf##ile##name', '=', 'os', '.', 'path', '.', 'expand##var##s', '(', '"$ga##ffer_root/python/ga##ffer##ima##get##est/images/check##er##with##ne##gative##da##ta##wind##ow.200##x##15##0.ex##r"', '\\n']
Counter: 50
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "GafferImage . Display , \n"
Original    (005): ['GafferImage', '.', 'Display', ',', '\\n']
Tokenized   (011): ['[CLS]', 'ga', '##ffer', '##ima', '##ge', '.', 'display', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['ga', '##ffer', '##ima', '##ge', '.', 'display', ',', '\\', 'n']
Detokenized (005): ['ga##ffer##ima##ge', '.', 'display', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""port" : [ \n"
Original    (004): ['"port"', ':', '[', '\\n']
Tokenized   (009): ['[CLS]', '"', 'port', '"', ':', '[', '\\', 'n', '[SEP]']
Filtered   (007): ['"', 'port', '"', ':', '[', '\\', 'n']
Detokenized (004): ['"port"', ':', '[', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "updateCountPlug . setValue ( updateCountPlug . getValue ( ) + 1 ) \n"
Original    (013): ['updateCountPlug', '.', 'setValue', '(', 'updateCountPlug', '.', 'getValue', '(', ')', '+', '1', ')', '\\n']
Tokenized   (028): ['[CLS]', 'update', '##co', '##unt', '##pl', '##ug', '.', 'set', '##val', '##ue', '(', 'update', '##co', '##unt', '##pl', '##ug', '.', 'get', '##val', '##ue', '(', ')', '+', '1', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['update', '##co', '##unt', '##pl', '##ug', '.', 'set', '##val', '##ue', '(', 'update', '##co', '##unt', '##pl', '##ug', '.', 'get', '##val', '##ue', '(', ')', '+', '1', ')', '\\', 'n']
Detokenized (013): ['update##co##unt##pl##ug', '.', 'set##val##ue', '(', 'update##co##unt##pl##ug', '.', 'get##val##ue', '(', ')', '+', '1', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "__import__ ( "IECore" ) . loadConfig ( "GAFFER_STARTUP_PATHS" , { } , subdirectory = "GafferImageUI" ) \n"
Original    (017): ['__import__', '(', '"IECore"', ')', '.', 'loadConfig', '(', '"GAFFER_STARTUP_PATHS"', ',', '{', '}', ',', 'subdirectory', '=', '"GafferImageUI"', ')', '\\n']
Tokenized   (047): ['[CLS]', '_', '_', 'import', '_', '_', '(', '"', 'iec', '##ore', '"', ')', '.', 'load', '##con', '##fi', '##g', '(', '"', 'ga', '##ffer', '_', 'startup', '_', 'paths', '"', ',', '{', '}', ',', 'sub', '##di', '##re', '##ctor', '##y', '=', '"', 'ga', '##ffer', '##ima', '##ge', '##ui', '"', ')', '\\', 'n', '[SEP]']
Filtered   (045): ['_', '_', 'import', '_', '_', '(', '"', 'iec', '##ore', '"', ')', '.', 'load', '##con', '##fi', '##g', '(', '"', 'ga', '##ffer', '_', 'startup', '_', 'paths', '"', ',', '{', '}', ',', 'sub', '##di', '##re', '##ctor', '##y', '=', '"', 'ga', '##ffer', '##ima', '##ge', '##ui', '"', ')', '\\', 'n']
Detokenized (017): ['__import__', '(', '"iec##ore"', ')', '.', 'load##con##fi##g', '(', '"ga##ffer_startup_paths"', ',', '{', '}', ',', 'sub##di##re##ctor##y', '=', '"ga##ffer##ima##ge##ui"', ')', '\\n']
Counter: 45
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n"
Original    (012): ['GafferRenderMan', '.', 'RenderManShader', '.', 'shaderLoader', '(', ')', '.', 'clear', '(', ')', '\\n']
Tokenized   (025): ['[CLS]', 'ga', '##ffer', '##ren', '##der', '##man', '.', 'render', '##mans', '##had', '##er', '.', 'shade', '##rl', '##oa', '##der', '(', ')', '.', 'clear', '(', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['ga', '##ffer', '##ren', '##der', '##man', '.', 'render', '##mans', '##had', '##er', '.', 'shade', '##rl', '##oa', '##der', '(', ')', '.', 'clear', '(', ')', '\\', 'n']
Detokenized (012): ['ga##ffer##ren##der##man', '.', 'render##mans##had##er', '.', 'shade##rl##oa##der', '(', ')', '.', 'clear', '(', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "coshader = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/coshader.sl" ) \n"
Original    (018): ['coshader', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/coshader.sl"', ')', '\\n']
Tokenized   (041): ['[CLS]', 'co', '##sha', '##der', '=', 'self', '.', 'com', '##pile', '##sha', '##der', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', '_', '_', 'file', '_', '_', ')', '+', '"', '/', 'shade', '##rs', '/', 'co', '##sha', '##der', '.', 'sl', '"', ')', '\\', 'n', '[SEP]']
Filtered   (039): ['co', '##sha', '##der', '=', 'self', '.', 'com', '##pile', '##sha', '##der', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', '_', '_', 'file', '_', '_', ')', '+', '"', '/', 'shade', '##rs', '/', 'co', '##sha', '##der', '.', 'sl', '"', ')', '\\', 'n']
Detokenized (018): ['co##sha##der', '=', 'self', '.', 'com##pile##sha##der', '(', 'os', '.', 'path', '.', 'dir##name', '(', '__file__', ')', '+', '"/shade##rs/co##sha##der.sl"', ')', '\\n']
Counter: 39
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "nn [ "outString" ] = Gaffer . StringPlug ( direction = Gaffer . Plug . Direction . Out ) \n"
Original    (020): ['nn', '[', '"outString"', ']', '=', 'Gaffer', '.', 'StringPlug', '(', 'direction', '=', 'Gaffer', '.', 'Plug', '.', 'Direction', '.', 'Out', ')', '\\n']
Tokenized   (032): ['[CLS]', 'n', '##n', '[', '"', 'outs', '##tri', '##ng', '"', ']', '=', 'ga', '##ffer', '.', 'string', '##pl', '##ug', '(', 'direction', '=', 'ga', '##ffer', '.', 'plug', '.', 'direction', '.', 'out', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['n', '##n', '[', '"', 'outs', '##tri', '##ng', '"', ']', '=', 'ga', '##ffer', '.', 'string', '##pl', '##ug', '(', 'direction', '=', 'ga', '##ffer', '.', 'plug', '.', 'direction', '.', 'out', ')', '\\', 'n']
Detokenized (020): ['n##n', '[', '"outs##tri##ng"', ']', '=', 'ga##ffer', '.', 'string##pl##ug', '(', 'direction', '=', 'ga##ffer', '.', 'plug', '.', 'direction', '.', 'out', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/version2.sl" , shaderName = "unversioned" \n"
Original    (021): ['shader2', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/version2.sl"', ',', 'shaderName', '=', '"unversioned"', '\\n']
Tokenized   (049): ['[CLS]', 'shade', '##r', '##2', '=', 'self', '.', 'com', '##pile', '##sha', '##der', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', '_', '_', 'file', '_', '_', ')', '+', '"', '/', 'shade', '##rs', '/', 'version', '##2', '.', 'sl', '"', ',', 'shade', '##rna', '##me', '=', '"', 'un', '##version', '##ed', '"', '\\', 'n', '[SEP]']
Filtered   (047): ['shade', '##r', '##2', '=', 'self', '.', 'com', '##pile', '##sha', '##der', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', '_', '_', 'file', '_', '_', ')', '+', '"', '/', 'shade', '##rs', '/', 'version', '##2', '.', 'sl', '"', ',', 'shade', '##rna', '##me', '=', '"', 'un', '##version', '##ed', '"', '\\', 'n']
Detokenized (021): ['shade##r##2', '=', 'self', '.', 'com##pile##sha##der', '(', 'os', '.', 'path', '.', 'dir##name', '(', '__file__', ')', '+', '"/shade##rs/version##2.sl"', ',', 'shade##rna##me', '=', '"un##version##ed"', '\\n']
Counter: 47
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "assignment [ "shader" ] . setInput ( shaderNode [ "out" ] ) \n"
Original    (013): ['assignment', '[', '"shader"', ']', '.', 'setInput', '(', 'shaderNode', '[', '"out"', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'assignment', '[', '"', 'shade', '##r', '"', ']', '.', 'set', '##in', '##put', '(', 'shade', '##rno', '##de', '[', '"', 'out', '"', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['assignment', '[', '"', 'shade', '##r', '"', ']', '.', 'set', '##in', '##put', '(', 'shade', '##rno', '##de', '[', '"', 'out', '"', ']', ')', '\\', 'n']
Detokenized (013): ['assignment', '[', '"shade##r"', ']', '.', 'set##in##put', '(', 'shade##rno##de', '[', '"out"', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "dirtiedNames = [ x [ 0 ] . fullName ( ) for x in cs ] \n"
Original    (017): ['dirtiedNames', '=', '[', 'x', '[', '0', ']', '.', 'fullName', '(', ')', 'for', 'x', 'in', 'cs', ']', '\\n']
Tokenized   (024): ['[CLS]', 'dirt', '##ied', '##name', '##s', '=', '[', 'x', '[', '0', ']', '.', 'full', '##name', '(', ')', 'for', 'x', 'in', 'cs', ']', '\\', 'n', '[SEP]']
Filtered   (022): ['dirt', '##ied', '##name', '##s', '=', '[', 'x', '[', '0', ']', '.', 'full', '##name', '(', ')', 'for', 'x', 'in', 'cs', ']', '\\', 'n']
Detokenized (017): ['dirt##ied##name##s', '=', '[', 'x', '[', '0', ']', '.', 'full##name', '(', ')', 'for', 'x', 'in', 'cs', ']', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : ""dynamicFloatArray" : IECore . FloatVectorData ( [ ] ) , \n"
Original    (011): ['"dynamicFloatArray"', ':', 'IECore', '.', 'FloatVectorData', '(', '[', ']', ')', ',', '\\n']
Tokenized   (025): ['[CLS]', '"', 'dynamic', '##fl', '##oat', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'float', '##ve', '##ctor', '##da', '##ta', '(', '[', ']', ')', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['"', 'dynamic', '##fl', '##oat', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'float', '##ve', '##ctor', '##da', '##ta', '(', '[', ']', ')', ',', '\\', 'n']
Detokenized (011): ['"dynamic##fl##oat##ar##ray"', ':', 'iec##ore', '.', 'float##ve##ctor##da##ta', '(', '[', ']', ')', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""fixedFloatArray" : IECore . FloatVectorData ( [ 1 , 2 , 3 , 4 ] ) , \n"
Original    (018): ['"fixedFloatArray"', ':', 'IECore', '.', 'FloatVectorData', '(', '[', '1', ',', '2', ',', '3', ',', '4', ']', ')', ',', '\\n']
Tokenized   (032): ['[CLS]', '"', 'fixed', '##fl', '##oat', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'float', '##ve', '##ctor', '##da', '##ta', '(', '[', '1', ',', '2', ',', '3', ',', '4', ']', ')', ',', '\\', 'n', '[SEP]']
Filtered   (030): ['"', 'fixed', '##fl', '##oat', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'float', '##ve', '##ctor', '##da', '##ta', '(', '[', '1', ',', '2', ',', '3', ',', '4', ']', ')', ',', '\\', 'n']
Detokenized (018): ['"fixed##fl##oat##ar##ray"', ':', 'iec##ore', '.', 'float##ve##ctor##da##ta', '(', '[', '1', ',', '2', ',', '3', ',', '4', ']', ')', ',', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : ""dynamicStringArray" : IECore . StringVectorData ( [ "dynamic" , "arrays" , "can" , "still" , "have" , "defaults" "fixedStringArray" : IECore . StringVectorData ( [ "hello" , "goodbye" ] ) , \n"
Original    (032): ['"dynamicStringArray"', ':', 'IECore', '.', 'StringVectorData', '(', '[', '"dynamic"', ',', '"arrays"', ',', '"can"', ',', '"still"', ',', '"have"', ',', '"defaults"', '"fixedStringArray"', ':', 'IECore', '.', 'StringVectorData', '(', '[', '"hello"', ',', '"goodbye"', ']', ')', ',', '\\n']
Tokenized   (074): ['[CLS]', '"', 'dynamics', '##tri', '##nga', '##rra', '##y', '"', ':', 'iec', '##ore', '.', 'string', '##ve', '##ctor', '##da', '##ta', '(', '[', '"', 'dynamic', '"', ',', '"', 'arrays', '"', ',', '"', 'can', '"', ',', '"', 'still', '"', ',', '"', 'have', '"', ',', '"', 'default', '##s', '"', '"', 'fixed', '##st', '##ring', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'string', '##ve', '##ctor', '##da', '##ta', '(', '[', '"', 'hello', '"', ',', '"', 'goodbye', '"', ']', ')', ',', '\\', 'n', '[SEP]']
Filtered   (072): ['"', 'dynamics', '##tri', '##nga', '##rra', '##y', '"', ':', 'iec', '##ore', '.', 'string', '##ve', '##ctor', '##da', '##ta', '(', '[', '"', 'dynamic', '"', ',', '"', 'arrays', '"', ',', '"', 'can', '"', ',', '"', 'still', '"', ',', '"', 'have', '"', ',', '"', 'default', '##s', '"', '"', 'fixed', '##st', '##ring', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'string', '##ve', '##ctor', '##da', '##ta', '(', '[', '"', 'hello', '"', ',', '"', 'goodbye', '"', ']', ')', ',', '\\', 'n']
Detokenized (032): ['"dynamics##tri##nga##rra##y"', ':', 'iec##ore', '.', 'string##ve##ctor##da##ta', '(', '[', '"dynamic"', ',', '"arrays"', ',', '"can"', ',', '"still"', ',', '"have"', ',', '"default##s"', '"fixed##st##ring##ar##ray"', ':', 'iec##ore', '.', 'string##ve##ctor##da##ta', '(', '[', '"hello"', ',', '"goodbye"', ']', ')', ',', '\\n']
Counter: 72
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : ""dynamicColorArray" : IECore . Color3fVectorData ( [ IECore . Color3f ( 1 ) , IECore . Color3f ( 2 ) ] ) , \n"
Original    (024): ['"dynamicColorArray"', ':', 'IECore', '.', 'Color3fVectorData', '(', '[', 'IECore', '.', 'Color3f', '(', '1', ')', ',', 'IECore', '.', 'Color3f', '(', '2', ')', ']', ')', ',', '\\n']
Tokenized   (045): ['[CLS]', '"', 'dynamic', '##color', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'color', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', 'iec', '##ore', '.', 'color', '##3', '##f', '(', '1', ')', ',', 'iec', '##ore', '.', 'color', '##3', '##f', '(', '2', ')', ']', ')', ',', '\\', 'n', '[SEP]']
Filtered   (043): ['"', 'dynamic', '##color', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'color', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', 'iec', '##ore', '.', 'color', '##3', '##f', '(', '1', ')', ',', 'iec', '##ore', '.', 'color', '##3', '##f', '(', '2', ')', ']', ')', ',', '\\', 'n']
Detokenized (024): ['"dynamic##color##ar##ray"', ':', 'iec##ore', '.', 'color##3##f##ve##ctor##da##ta', '(', '[', 'iec##ore', '.', 'color##3##f', '(', '1', ')', ',', 'iec##ore', '.', 'color##3##f', '(', '2', ')', ']', ')', ',', '\\n']
Counter: 43
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : ""dynamicVectorArray" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Vector ) , \n"
Original    (019): ['"dynamicVectorArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', ']', ',', 'IECore', '.', 'GeometricData', '.', 'Interpretation', '.', 'Vector', ')', ',', '\\n']
Tokenized   (038): ['[CLS]', '"', 'dynamic', '##ve', '##ctor', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '.', 'interpretation', '.', 'vector', ')', ',', '\\', 'n', '[SEP]']
Filtered   (036): ['"', 'dynamic', '##ve', '##ctor', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '.', 'interpretation', '.', 'vector', ')', ',', '\\', 'n']
Detokenized (019): ['"dynamic##ve##ctor##ar##ray"', ':', 'iec##ore', '.', 'v##3##f##ve##ctor##da##ta', '(', '[', ']', ',', 'iec##ore', '.', 'geometric##da##ta', '.', 'interpretation', '.', 'vector', ')', ',', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : ""fixedVectorArray" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( 1 , 6 ) ] , IECore . GeometricData "dynamicPointArray" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Point ) , \n"
Original    (046): ['"fixedVectorArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', 'IECore', '.', 'V3f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'IECore', '.', 'GeometricData', '"dynamicPointArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', ']', ',', 'IECore', '.', 'GeometricData', '.', 'Interpretation', '.', 'Point', ')', ',', '\\n']
Tokenized   (083): ['[CLS]', '"', 'fixed', '##ve', '##ctor', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', 'iec', '##ore', '.', 'v', '##3', '##f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '"', 'dynamic', '##point', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '.', 'interpretation', '.', 'point', ')', ',', '\\', 'n', '[SEP]']
Filtered   (081): ['"', 'fixed', '##ve', '##ctor', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', 'iec', '##ore', '.', 'v', '##3', '##f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '"', 'dynamic', '##point', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '.', 'interpretation', '.', 'point', ')', ',', '\\', 'n']
Detokenized (046): ['"fixed##ve##ctor##ar##ray"', ':', 'iec##ore', '.', 'v##3##f##ve##ctor##da##ta', '(', '[', 'iec##ore', '.', 'v##3##f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'iec##ore', '.', 'geometric##da##ta', '"dynamic##point##ar##ray"', ':', 'iec##ore', '.', 'v##3##f##ve##ctor##da##ta', '(', '[', ']', ',', 'iec##ore', '.', 'geometric##da##ta', '.', 'interpretation', '.', 'point', ')', ',', '\\n']
Counter: 81
===================================================================
Hidden states:  (13, 46, 768)
# Extracted words:  46
Sentence         : ""fixedNormalArray" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( 1 , 6 ) ] , IECore . GeometricData } \n"
Original    (029): ['"fixedNormalArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', 'IECore', '.', 'V3f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'IECore', '.', 'GeometricData', '}', '\\n']
Tokenized   (051): ['[CLS]', '"', 'fixed', '##nor', '##mal', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', 'iec', '##ore', '.', 'v', '##3', '##f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '}', '\\', 'n', '[SEP]']
Filtered   (049): ['"', 'fixed', '##nor', '##mal', '##ar', '##ray', '"', ':', 'iec', '##ore', '.', 'v', '##3', '##f', '##ve', '##ctor', '##da', '##ta', '(', '[', 'iec', '##ore', '.', 'v', '##3', '##f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'iec', '##ore', '.', 'geometric', '##da', '##ta', '}', '\\', 'n']
Detokenized (029): ['"fixed##nor##mal##ar##ray"', ':', 'iec##ore', '.', 'v##3##f##ve##ctor##da##ta', '(', '[', 'iec##ore', '.', 'v##3##f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'iec##ore', '.', 'geometric##da##ta', '}', '\\n']
Counter: 49
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "arrayShader = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/coshaderArrayParameters.sl" n4 = GafferRenderMan . RenderManShader ( ) \n"
Original    (024): ['arrayShader', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/coshaderArrayParameters.sl"', 'n4', '=', 'GafferRenderMan', '.', 'RenderManShader', '(', ')', '\\n']
Tokenized   (060): ['[CLS]', 'arrays', '##had', '##er', '=', 'self', '.', 'com', '##pile', '##sha', '##der', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', '_', '_', 'file', '_', '_', ')', '+', '"', '/', 'shade', '##rs', '/', 'co', '##sha', '##der', '##ar', '##ray', '##para', '##meter', '##s', '.', 'sl', '"', 'n', '##4', '=', 'ga', '##ffer', '##ren', '##der', '##man', '.', 'render', '##mans', '##had', '##er', '(', ')', '\\', 'n', '[SEP]']
Filtered   (058): ['arrays', '##had', '##er', '=', 'self', '.', 'com', '##pile', '##sha', '##der', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', '_', '_', 'file', '_', '_', ')', '+', '"', '/', 'shade', '##rs', '/', 'co', '##sha', '##der', '##ar', '##ray', '##para', '##meter', '##s', '.', 'sl', '"', 'n', '##4', '=', 'ga', '##ffer', '##ren', '##der', '##man', '.', 'render', '##mans', '##had', '##er', '(', ')', '\\', 'n']
Detokenized (024): ['arrays##had##er', '=', 'self', '.', 'com##pile##sha##der', '(', 'os', '.', 'path', '.', 'dir##name', '(', '__file__', ')', '+', '"/shade##rs/co##sha##der##ar##ray##para##meter##s.sl"', 'n##4', '=', 'ga##ffer##ren##der##man', '.', 'render##mans##had##er', '(', ')', '\\n']
Counter: 58
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "coshaderNode [ "enabled" ] . setValue ( False ) \n"
Original    (010): ['coshaderNode', '[', '"enabled"', ']', '.', 'setValue', '(', 'False', ')', '\\n']
Tokenized   (020): ['[CLS]', 'co', '##sha', '##dern', '##ode', '[', '"', 'enabled', '"', ']', '.', 'set', '##val', '##ue', '(', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['co', '##sha', '##dern', '##ode', '[', '"', 'enabled', '"', ']', '.', 'set', '##val', '##ue', '(', 'false', ')', '\\', 'n']
Detokenized (010): ['co##sha##dern##ode', '[', '"enabled"', ']', '.', 'set##val##ue', '(', 'false', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "floatValue = IECore . Splineff ( \n"
Original    (007): ['floatValue', '=', 'IECore', '.', 'Splineff', '(', '\\n']
Tokenized   (015): ['[CLS]', 'float', '##val', '##ue', '=', 'iec', '##ore', '.', 'sp', '##line', '##ff', '(', '\\', 'n', '[SEP]']
Filtered   (013): ['float', '##val', '##ue', '=', 'iec', '##ore', '.', 'sp', '##line', '##ff', '(', '\\', 'n']
Detokenized (007): ['float##val##ue', '=', 'iec##ore', '.', 'sp##line##ff', '(', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "S [ "parameters" ] [ "coshaderParameter" ] . setInput ( D2 [ "out" ] ) \n"
Original    (016): ['S', '[', '"parameters"', ']', '[', '"coshaderParameter"', ']', '.', 'setInput', '(', 'D2', '[', '"out"', ']', ')', '\\n']
Tokenized   (032): ['[CLS]', 's', '[', '"', 'parameters', '"', ']', '[', '"', 'co', '##sha', '##der', '##para', '##meter', '"', ']', '.', 'set', '##in', '##put', '(', 'd', '##2', '[', '"', 'out', '"', ']', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['s', '[', '"', 'parameters', '"', ']', '[', '"', 'co', '##sha', '##der', '##para', '##meter', '"', ']', '.', 'set', '##in', '##put', '(', 'd', '##2', '[', '"', 'out', '"', ']', ')', '\\', 'n']
Detokenized (016): ['s', '[', '"parameters"', ']', '[', '"co##sha##der##para##meter"', ']', '.', 'set##in##put', '(', 'd##2', '[', '"out"', ']', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "coshaderNode0 [ "parameters" ] [ "floatParameter" ] . setValue ( 0 ) \n"
Original    (013): ['coshaderNode0', '[', '"parameters"', ']', '[', '"floatParameter"', ']', '.', 'setValue', '(', '0', ')', '\\n']
Tokenized   (028): ['[CLS]', 'co', '##sha', '##dern', '##ode', '##0', '[', '"', 'parameters', '"', ']', '[', '"', 'float', '##para', '##meter', '"', ']', '.', 'set', '##val', '##ue', '(', '0', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['co', '##sha', '##dern', '##ode', '##0', '[', '"', 'parameters', '"', ']', '[', '"', 'float', '##para', '##meter', '"', ']', '.', 'set', '##val', '##ue', '(', '0', ')', '\\', 'n']
Detokenized (013): ['co##sha##dern##ode##0', '[', '"parameters"', ']', '[', '"float##para##meter"', ']', '.', 'set##val##ue', '(', '0', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sn1 = GafferRenderMan . RenderManShader ( "Shader1" ) \n"
Original    (009): ['sn1', '=', 'GafferRenderMan', '.', 'RenderManShader', '(', '"Shader1"', ')', '\\n']
Tokenized   (025): ['[CLS]', 's', '##n', '##1', '=', 'ga', '##ffer', '##ren', '##der', '##man', '.', 'render', '##mans', '##had', '##er', '(', '"', 'shade', '##r', '##1', '"', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['s', '##n', '##1', '=', 'ga', '##ffer', '##ren', '##der', '##man', '.', 'render', '##mans', '##had', '##er', '(', '"', 'shade', '##r', '##1', '"', ')', '\\', 'n']
Detokenized (009): ['s##n##1', '=', 'ga##ffer##ren##der##man', '.', 'render##mans##had##er', '(', '"shade##r##1"', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "script [ "assignment" ] [ "shader" ] . setInput ( script [ "shader" ] [ "out" ] ) \n"
Original    (019): ['script', '[', '"assignment"', ']', '[', '"shader"', ']', '.', 'setInput', '(', 'script', '[', '"shader"', ']', '[', '"out"', ']', ')', '\\n']
Tokenized   (034): ['[CLS]', 'script', '[', '"', 'assignment', '"', ']', '[', '"', 'shade', '##r', '"', ']', '.', 'set', '##in', '##put', '(', 'script', '[', '"', 'shade', '##r', '"', ']', '[', '"', 'out', '"', ']', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['script', '[', '"', 'assignment', '"', ']', '[', '"', 'shade', '##r', '"', ']', '.', 'set', '##in', '##put', '(', 'script', '[', '"', 'shade', '##r', '"', ']', '[', '"', 'out', '"', ']', ')', '\\', 'n']
Detokenized (019): ['script', '[', '"assignment"', ']', '[', '"shade##r"', ']', '.', 'set##in##put', '(', 'script', '[', '"shade##r"', ']', '[', '"out"', ']', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "traverseConnection = Gaffer . ScopedConnection ( GafferSceneTest . connectTraverseSceneToPlugDirtiedSignal script [ "shader" ] . loadShader ( "matte" ) \n"
Original    (019): ['traverseConnection', '=', 'Gaffer', '.', 'ScopedConnection', '(', 'GafferSceneTest', '.', 'connectTraverseSceneToPlugDirtiedSignal', 'script', '[', '"shader"', ']', '.', 'loadShader', '(', '"matte"', ')', '\\n']
Tokenized   (054): ['[CLS]', 'traverse', '##con', '##ne', '##ction', '=', 'ga', '##ffer', '.', 'scope', '##dc', '##onne', '##ction', '(', 'ga', '##ffer', '##sc', '##ene', '##test', '.', 'connect', '##tra', '##verse', '##sc', '##ene', '##top', '##lu', '##g', '##di', '##rti', '##ed', '##si', '##gna', '##l', 'script', '[', '"', 'shade', '##r', '"', ']', '.', 'loads', '##had', '##er', '(', '"', 'matt', '##e', '"', ')', '\\', 'n', '[SEP]']
Filtered   (052): ['traverse', '##con', '##ne', '##ction', '=', 'ga', '##ffer', '.', 'scope', '##dc', '##onne', '##ction', '(', 'ga', '##ffer', '##sc', '##ene', '##test', '.', 'connect', '##tra', '##verse', '##sc', '##ene', '##top', '##lu', '##g', '##di', '##rti', '##ed', '##si', '##gna', '##l', 'script', '[', '"', 'shade', '##r', '"', ']', '.', 'loads', '##had', '##er', '(', '"', 'matt', '##e', '"', ')', '\\', 'n']
Detokenized (019): ['traverse##con##ne##ction', '=', 'ga##ffer', '.', 'scope##dc##onne##ction', '(', 'ga##ffer##sc##ene##test', '.', 'connect##tra##verse##sc##ene##top##lu##g##di##rti##ed##si##gna##l', 'script', '[', '"shade##r"', ']', '.', 'loads##had##er', '(', '"matt##e"', ')', '\\n']
Counter: 52
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "current = s [ "render" ] . hash ( c ) \n"
Original    (012): ['current', '=', 's', '[', '"render"', ']', '.', 'hash', '(', 'c', ')', '\\n']
Tokenized   (017): ['[CLS]', 'current', '=', 's', '[', '"', 'render', '"', ']', '.', 'hash', '(', 'c', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['current', '=', 's', '[', '"', 'render', '"', ']', '.', 'hash', '(', 'c', ')', '\\', 'n']
Detokenized (012): ['current', '=', 's', '[', '"render"', ']', '.', 'hash', '(', 'c', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""layout:section" , "Transform" , \n"
Original    (005): ['"layout:section"', ',', '"Transform"', ',', '\\n']
Tokenized   (014): ['[CLS]', '"', 'layout', ':', 'section', '"', ',', '"', 'transform', '"', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['"', 'layout', ':', 'section', '"', ',', '"', 'transform', '"', ',', '\\', 'n']
Detokenized (005): ['"layout:section"', ',', '"transform"', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""toolbarLayout:index" , 2 , \n"
Original    (005): ['"toolbarLayout:index"', ',', '2', ',', '\\n']
Tokenized   (015): ['[CLS]', '"', 'tool', '##bar', '##lay', '##out', ':', 'index', '"', ',', '2', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['"', 'tool', '##bar', '##lay', '##out', ':', 'index', '"', ',', '2', ',', '\\', 'n']
Detokenized (005): ['"tool##bar##lay##out:index"', ',', '2', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""toolbarLayout:divider" , True , \n"
Original    (005): ['"toolbarLayout:divider"', ',', 'True', ',', '\\n']
Tokenized   (016): ['[CLS]', '"', 'tool', '##bar', '##lay', '##out', ':', 'divide', '##r', '"', ',', 'true', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['"', 'tool', '##bar', '##lay', '##out', ':', 'divide', '##r', '"', ',', 'true', ',', '\\', 'n']
Detokenized (005): ['"tool##bar##lay##out:divide##r"', ',', 'true', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "currentName = self . getPlug ( ) . getValue ( ) \n"
Original    (012): ['currentName', '=', 'self', '.', 'getPlug', '(', ')', '.', 'getValue', '(', ')', '\\n']
Tokenized   (020): ['[CLS]', 'current', '##name', '=', 'self', '.', 'get', '##pl', '##ug', '(', ')', '.', 'get', '##val', '##ue', '(', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['current', '##name', '=', 'self', '.', 'get', '##pl', '##ug', '(', ')', '.', 'get', '##val', '##ue', '(', ')', '\\', 'n']
Detokenized (012): ['current##name', '=', 'self', '.', 'get##pl##ug', '(', ')', '.', 'get##val##ue', '(', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "menuButton = GafferUI . MenuButton ( menu = menu , image = "grid.png" , hasFrame = False ) \n"
Original    (019): ['menuButton', '=', 'GafferUI', '.', 'MenuButton', '(', 'menu', '=', 'menu', ',', 'image', '=', '"grid.png"', ',', 'hasFrame', '=', 'False', ')', '\\n']
Tokenized   (034): ['[CLS]', 'menu', '##bu', '##tton', '=', 'ga', '##ffer', '##ui', '.', 'menu', '##bu', '##tton', '(', 'menu', '=', 'menu', ',', 'image', '=', '"', 'grid', '.', 'p', '##ng', '"', ',', 'has', '##frame', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['menu', '##bu', '##tton', '=', 'ga', '##ffer', '##ui', '.', 'menu', '##bu', '##tton', '(', 'menu', '=', 'menu', ',', 'image', '=', '"', 'grid', '.', 'p', '##ng', '"', ',', 'has', '##frame', '=', 'false', ')', '\\', 'n']
Detokenized (019): ['menu##bu##tton', '=', 'ga##ffer##ui', '.', 'menu##bu##tton', '(', 'menu', '=', 'menu', ',', 'image', '=', '"grid.p##ng"', ',', 'has##frame', '=', 'false', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "p3 = Gaffer . IntPlug ( "sum" , Gaffer . Plug . Direction . Out ) \n"
Original    (017): ['p3', '=', 'Gaffer', '.', 'IntPlug', '(', '"sum"', ',', 'Gaffer', '.', 'Plug', '.', 'Direction', '.', 'Out', ')', '\\n']
Tokenized   (027): ['[CLS]', 'p', '##3', '=', 'ga', '##ffer', '.', 'int', '##pl', '##ug', '(', '"', 'sum', '"', ',', 'ga', '##ffer', '.', 'plug', '.', 'direction', '.', 'out', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['p', '##3', '=', 'ga', '##ffer', '.', 'int', '##pl', '##ug', '(', '"', 'sum', '"', ',', 'ga', '##ffer', '.', 'plug', '.', 'direction', '.', 'out', ')', '\\', 'n']
Detokenized (017): ['p##3', '=', 'ga##ffer', '.', 'int##pl##ug', '(', '"sum"', ',', 'ga##ffer', '.', 'plug', '.', 'direction', '.', 'out', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "childrenStrings = [ str ( c ) for c in children ] \n"
Original    (013): ['childrenStrings', '=', '[', 'str', '(', 'c', ')', 'for', 'c', 'in', 'children', ']', '\\n']
Tokenized   (020): ['[CLS]', 'children', '##st', '##ring', '##s', '=', '[', 'st', '##r', '(', 'c', ')', 'for', 'c', 'in', 'children', ']', '\\', 'n', '[SEP]']
Filtered   (018): ['children', '##st', '##ring', '##s', '=', '[', 'st', '##r', '(', 'c', ')', 'for', 'c', 'in', 'children', ']', '\\', 'n']
Detokenized (013): ['children##st##ring##s', '=', '[', 'st##r', '(', 'c', ')', 'for', 'c', 'in', 'children', ']', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "c2 = [ str ( p ) for p in path2 . children ( ) ] \n"
Original    (017): ['c2', '=', '[', 'str', '(', 'p', ')', 'for', 'p', 'in', 'path2', '.', 'children', '(', ')', ']', '\\n']
Tokenized   (022): ['[CLS]', 'c2', '=', '[', 'st', '##r', '(', 'p', ')', 'for', 'p', 'in', 'path', '##2', '.', 'children', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (020): ['c2', '=', '[', 'st', '##r', '(', 'p', ')', 'for', 'p', 'in', 'path', '##2', '.', 'children', '(', ')', ']', '\\', 'n']
Detokenized (017): ['c2', '=', '[', 'st##r', '(', 'p', ')', 'for', 'p', 'in', 'path##2', '.', 'children', '(', ')', ']', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "horizontalAlignment = GafferUI . Label . HorizontalAlignment . Right , \n"
Original    (011): ['horizontalAlignment', '=', 'GafferUI', '.', 'Label', '.', 'HorizontalAlignment', '.', 'Right', ',', '\\n']
Tokenized   (022): ['[CLS]', 'horizontal', '##ali', '##gn', '##ment', '=', 'ga', '##ffer', '##ui', '.', 'label', '.', 'horizontal', '##ali', '##gn', '##ment', '.', 'right', ',', '\\', 'n', '[SEP]']
Filtered   (020): ['horizontal', '##ali', '##gn', '##ment', '=', 'ga', '##ffer', '##ui', '.', 'label', '.', 'horizontal', '##ali', '##gn', '##ment', '.', 'right', ',', '\\', 'n']
Detokenized (011): ['horizontal##ali##gn##ment', '=', 'ga##ffer##ui', '.', 'label', '.', 'horizontal##ali##gn##ment', '.', 'right', ',', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "nameWidget . textWidget ( ) . _qtWidget ( ) . setFixedWidth ( GafferUI . PlugWidget . labelWidth ( ) ) \n"
Original    (021): ['nameWidget', '.', 'textWidget', '(', ')', '.', '_qtWidget', '(', ')', '.', 'setFixedWidth', '(', 'GafferUI', '.', 'PlugWidget', '.', 'labelWidth', '(', ')', ')', '\\n']
Tokenized   (043): ['[CLS]', 'name', '##wi', '##dget', '.', 'text', '##wi', '##dget', '(', ')', '.', '_', 'q', '##t', '##wi', '##dget', '(', ')', '.', 'set', '##fixed', '##wi', '##dt', '##h', '(', 'ga', '##ffer', '##ui', '.', 'plug', '##wi', '##dget', '.', 'label', '##wi', '##dt', '##h', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (041): ['name', '##wi', '##dget', '.', 'text', '##wi', '##dget', '(', ')', '.', '_', 'q', '##t', '##wi', '##dget', '(', ')', '.', 'set', '##fixed', '##wi', '##dt', '##h', '(', 'ga', '##ffer', '##ui', '.', 'plug', '##wi', '##dget', '.', 'label', '##wi', '##dt', '##h', '(', ')', ')', '\\', 'n']
Detokenized (021): ['name##wi##dget', '.', 'text##wi##dget', '(', ')', '.', '_q##t##wi##dget', '(', ')', '.', 'set##fixed##wi##dt##h', '(', 'ga##ffer##ui', '.', 'plug##wi##dget', '.', 'label##wi##dt##h', '(', ')', ')', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "childPlug [ "enabled" ] , \n"
Original    (006): ['childPlug', '[', '"enabled"', ']', ',', '\\n']
Tokenized   (013): ['[CLS]', 'child', '##pl', '##ug', '[', '"', 'enabled', '"', ']', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['child', '##pl', '##ug', '[', '"', 'enabled', '"', ']', ',', '\\', 'n']
Detokenized (006): ['child##pl##ug', '[', '"enabled"', ']', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "memberPlug = memberPlug if memberPlug is not None else plug . ancestor ( Gaffer . CompoundDataPlug . MemberPlug if memberPlug is None : \n"
Original    (024): ['memberPlug', '=', 'memberPlug', 'if', 'memberPlug', 'is', 'not', 'None', 'else', 'plug', '.', 'ancestor', '(', 'Gaffer', '.', 'CompoundDataPlug', '.', 'MemberPlug', 'if', 'memberPlug', 'is', 'None', ':', '\\n']
Tokenized   (042): ['[CLS]', 'member', '##pl', '##ug', '=', 'member', '##pl', '##ug', 'if', 'member', '##pl', '##ug', 'is', 'not', 'none', 'else', 'plug', '.', 'ancestor', '(', 'ga', '##ffer', '.', 'compound', '##da', '##ta', '##pl', '##ug', '.', 'member', '##pl', '##ug', 'if', 'member', '##pl', '##ug', 'is', 'none', ':', '\\', 'n', '[SEP]']
Filtered   (040): ['member', '##pl', '##ug', '=', 'member', '##pl', '##ug', 'if', 'member', '##pl', '##ug', 'is', 'not', 'none', 'else', 'plug', '.', 'ancestor', '(', 'ga', '##ffer', '.', 'compound', '##da', '##ta', '##pl', '##ug', '.', 'member', '##pl', '##ug', 'if', 'member', '##pl', '##ug', 'is', 'none', ':', '\\', 'n']
Detokenized (024): ['member##pl##ug', '=', 'member##pl##ug', 'if', 'member##pl##ug', 'is', 'not', 'none', 'else', 'plug', '.', 'ancestor', '(', 'ga##ffer', '.', 'compound##da##ta##pl##ug', '.', 'member##pl##ug', 'if', 'member##pl##ug', 'is', 'none', ':', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "menuDefinition . append ( "/Delete" , { "command" : IECore . curry ( __deletePlug , memberPlug ) , "active" \n"
Original    (020): ['menuDefinition', '.', 'append', '(', '"/Delete"', ',', '{', '"command"', ':', 'IECore', '.', 'curry', '(', '__deletePlug', ',', 'memberPlug', ')', ',', '"active"', '\\n']
Tokenized   (043): ['[CLS]', 'menu', '##de', '##fin', '##ition', '.', 'app', '##end', '(', '"', '/', 'del', '##ete', '"', ',', '{', '"', 'command', '"', ':', 'iec', '##ore', '.', 'curry', '(', '_', '_', 'del', '##ete', '##pl', '##ug', ',', 'member', '##pl', '##ug', ')', ',', '"', 'active', '"', '\\', 'n', '[SEP]']
Filtered   (041): ['menu', '##de', '##fin', '##ition', '.', 'app', '##end', '(', '"', '/', 'del', '##ete', '"', ',', '{', '"', 'command', '"', ':', 'iec', '##ore', '.', 'curry', '(', '_', '_', 'del', '##ete', '##pl', '##ug', ',', 'member', '##pl', '##ug', ')', ',', '"', 'active', '"', '\\', 'n']
Detokenized (020): ['menu##de##fin##ition', '.', 'app##end', '(', '"/del##ete"', ',', '{', '"command"', ':', 'iec##ore', '.', 'curry', '(', '__del##ete##pl##ug', ',', 'member##pl##ug', ')', ',', '"active"', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "includeSequences = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "fileSystemPathPlugValueWidget:includeSequences" \n"
Original    (016): ['includeSequences', '=', 'Gaffer', '.', 'Metadata', '.', 'plugValue', '(', 'self', '.', 'getPlug', '(', ')', ',', '"fileSystemPathPlugValueWidget:includeSequences"', '\\n']
Tokenized   (045): ['[CLS]', 'includes', '##e', '##que', '##nce', '##s', '=', 'ga', '##ffer', '.', 'metadata', '.', 'plug', '##val', '##ue', '(', 'self', '.', 'get', '##pl', '##ug', '(', ')', ',', '"', 'files', '##yst', '##em', '##path', '##pl', '##ug', '##val', '##ue', '##wi', '##dget', ':', 'includes', '##e', '##que', '##nce', '##s', '"', '\\', 'n', '[SEP]']
Filtered   (043): ['includes', '##e', '##que', '##nce', '##s', '=', 'ga', '##ffer', '.', 'metadata', '.', 'plug', '##val', '##ue', '(', 'self', '.', 'get', '##pl', '##ug', '(', ')', ',', '"', 'files', '##yst', '##em', '##path', '##pl', '##ug', '##val', '##ue', '##wi', '##dget', ':', 'includes', '##e', '##que', '##nce', '##s', '"', '\\', 'n']
Detokenized (016): ['includes##e##que##nce##s', '=', 'ga##ffer', '.', 'metadata', '.', 'plug##val##ue', '(', 'self', '.', 'get##pl##ug', '(', ')', ',', '"files##yst##em##path##pl##ug##val##ue##wi##dget:includes##e##que##nce##s"', '\\n']
Counter: 43
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "reuse = reuseUntil is not None \n"
Original    (007): ['reuse', '=', 'reuseUntil', 'is', 'not', 'None', '\\n']
Tokenized   (014): ['[CLS]', 're', '##use', '=', 're', '##use', '##unt', '##il', 'is', 'not', 'none', '\\', 'n', '[SEP]']
Filtered   (012): ['re', '##use', '=', 're', '##use', '##unt', '##il', 'is', 'not', 'none', '\\', 'n']
Detokenized (007): ['re##use', '=', 're##use##unt##il', 'is', 'not', 'none', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_MultiLineStringMetadataWidget ( key = "description" ) \n"
Original    (007): ['_MultiLineStringMetadataWidget', '(', 'key', '=', '"description"', ')', '\\n']
Tokenized   (021): ['[CLS]', '_', 'multi', '##lines', '##tri', '##ng', '##met', '##ada', '##ta', '##wi', '##dget', '(', 'key', '=', '"', 'description', '"', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['_', 'multi', '##lines', '##tri', '##ng', '##met', '##ada', '##ta', '##wi', '##dget', '(', 'key', '=', '"', 'description', '"', ')', '\\', 'n']
Detokenized (007): ['_multi##lines##tri##ng##met##ada##ta##wi##dget', '(', 'key', '=', '"description"', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""active" : isinstance ( node , Gaffer . Box ) or nodeEditor . nodeUI ( ) . plugValueWidget ( node [ "user" ] ) } \n"
Original    (026): ['"active"', ':', 'isinstance', '(', 'node', ',', 'Gaffer', '.', 'Box', ')', 'or', 'nodeEditor', '.', 'nodeUI', '(', ')', '.', 'plugValueWidget', '(', 'node', '[', '"user"', ']', ')', '}', '\\n']
Tokenized   (043): ['[CLS]', '"', 'active', '"', ':', 'is', '##ins', '##tance', '(', 'node', ',', 'ga', '##ffer', '.', 'box', ')', 'or', 'node', '##ed', '##itor', '.', 'node', '##ui', '(', ')', '.', 'plug', '##val', '##ue', '##wi', '##dget', '(', 'node', '[', '"', 'user', '"', ']', ')', '}', '\\', 'n', '[SEP]']
Filtered   (041): ['"', 'active', '"', ':', 'is', '##ins', '##tance', '(', 'node', ',', 'ga', '##ffer', '.', 'box', ')', 'or', 'node', '##ed', '##itor', '.', 'node', '##ui', '(', ')', '.', 'plug', '##val', '##ue', '##wi', '##dget', '(', 'node', '[', '"', 'user', '"', ']', ')', '}', '\\', 'n']
Detokenized (026): ['"active"', ':', 'is##ins##tance', '(', 'node', ',', 'ga##ffer', '.', 'box', ')', 'or', 'node##ed##itor', '.', 'node##ui', '(', ')', '.', 'plug##val##ue##wi##dget', '(', 'node', '[', '"user"', ']', ')', '}', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "dialogue = GafferUI . ColorChooserDialogue ( color = color , useDisplayTransform = False ) \n"
Original    (015): ['dialogue', '=', 'GafferUI', '.', 'ColorChooserDialogue', '(', 'color', '=', 'color', ',', 'useDisplayTransform', '=', 'False', ')', '\\n']
Tokenized   (030): ['[CLS]', 'dialogue', '=', 'ga', '##ffer', '##ui', '.', 'color', '##cho', '##ose', '##rdial', '##og', '##ue', '(', 'color', '=', 'color', ',', 'used', '##is', '##play', '##tra', '##ns', '##form', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['dialogue', '=', 'ga', '##ffer', '##ui', '.', 'color', '##cho', '##ose', '##rdial', '##og', '##ue', '(', 'color', '=', 'color', ',', 'used', '##is', '##play', '##tra', '##ns', '##form', '=', 'false', ')', '\\', 'n']
Detokenized (015): ['dialogue', '=', 'ga##ffer##ui', '.', 'color##cho##ose##rdial##og##ue', '(', 'color', '=', 'color', ',', 'used##is##play##tra##ns##form', '=', 'false', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "editor . plugEditor ( ) . reveal ( ) \n"
Original    (010): ['editor', '.', 'plugEditor', '(', ')', '.', 'reveal', '(', ')', '\\n']
Tokenized   (015): ['[CLS]', 'editor', '.', 'plug', '##ed', '##itor', '(', ')', '.', 'reveal', '(', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['editor', '.', 'plug', '##ed', '##itor', '(', ')', '.', 'reveal', '(', ')', '\\', 'n']
Detokenized (010): ['editor', '.', 'plug##ed##itor', '(', ')', '.', 'reveal', '(', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_MetadataWidget . __init__ ( self , self . __menuButton , key , target , parenting = parenting ) \n"
Original    (019): ['_MetadataWidget', '.', '__init__', '(', 'self', ',', 'self', '.', '__menuButton', ',', 'key', ',', 'target', ',', 'parenting', '=', 'parenting', ')', '\\n']
Tokenized   (034): ['[CLS]', '_', 'metadata', '##wi', '##dget', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', 'self', '.', '_', '_', 'menu', '##bu', '##tton', ',', 'key', ',', 'target', ',', 'parenting', '=', 'parenting', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['_', 'metadata', '##wi', '##dget', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', 'self', '.', '_', '_', 'menu', '##bu', '##tton', ',', 'key', ',', 'target', ',', 'parenting', '=', 'parenting', ')', '\\', 'n']
Detokenized (019): ['_metadata##wi##dget', '.', '__in##it__', '(', 'self', ',', 'self', '.', '__menu##bu##tton', ',', 'key', ',', 'target', ',', 'parenting', '=', 'parenting', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : ""checkBox" : value == self . __currentValue \n"
Original    (008): ['"checkBox"', ':', 'value', '==', 'self', '.', '__currentValue', '\\n']
Tokenized   (019): ['[CLS]', '"', 'check', '##box', '"', ':', 'value', '=', '=', 'self', '.', '_', '_', 'current', '##val', '##ue', '\\', 'n', '[SEP]']
Filtered   (017): ['"', 'check', '##box', '"', ':', 'value', '=', '=', 'self', '.', '_', '_', 'current', '##val', '##ue', '\\', 'n']
Detokenized (008): ['"check##box"', ':', 'value', '==', 'self', '.', '__current##val##ue', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "child . __parent = None \n"
Original    (006): ['child', '.', '__parent', '=', 'None', '\\n']
Tokenized   (011): ['[CLS]', 'child', '.', '_', '_', 'parent', '=', 'none', '\\', 'n', '[SEP]']
Filtered   (009): ['child', '.', '_', '_', 'parent', '=', 'none', '\\', 'n']
Detokenized (006): ['child', '.', '__parent', '=', 'none', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "columns = ( GafferUI . PathListingWidget . defaultNameColumn , ) , \n"
Original    (012): ['columns', '=', '(', 'GafferUI', '.', 'PathListingWidget', '.', 'defaultNameColumn', ',', ')', ',', '\\n']
Tokenized   (025): ['[CLS]', 'columns', '=', '(', 'ga', '##ffer', '##ui', '.', 'path', '##list', '##ing', '##wi', '##dget', '.', 'default', '##name', '##col', '##um', '##n', ',', ')', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['columns', '=', '(', 'ga', '##ffer', '##ui', '.', 'path', '##list', '##ing', '##wi', '##dget', '.', 'default', '##name', '##col', '##um', '##n', ',', ')', ',', '\\', 'n']
Detokenized (012): ['columns', '=', '(', 'ga##ffer##ui', '.', 'path##list##ing##wi##dget', '.', 'default##name##col##um##n', ',', ')', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "definition = Gaffer . WeakMethod ( self . __addMenuDefinition ) \n"
Original    (011): ['definition', '=', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__addMenuDefinition', ')', '\\n']
Tokenized   (024): ['[CLS]', 'definition', '=', 'ga', '##ffer', '.', 'weak', '##met', '##ho', '##d', '(', 'self', '.', '_', '_', 'add', '##men', '##ude', '##fin', '##ition', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['definition', '=', 'ga', '##ffer', '.', 'weak', '##met', '##ho', '##d', '(', 'self', '.', '_', '_', 'add', '##men', '##ude', '##fin', '##ition', ')', '\\', 'n']
Detokenized (011): ['definition', '=', 'ga##ffer', '.', 'weak##met##ho##d', '(', 'self', '.', '__add##men##ude##fin##ition', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "newIndex = 0 if event . line . p0 . y < 1 else len ( newParent ) \n"
Original    (019): ['newIndex', '=', '0', 'if', 'event', '.', 'line', '.', 'p0', '.', 'y', '<', '1', 'else', 'len', '(', 'newParent', ')', '\\n']
Tokenized   (027): ['[CLS]', 'new', '##ind', '##ex', '=', '0', 'if', 'event', '.', 'line', '.', 'p', '##0', '.', 'y', '<', '1', 'else', 'len', '(', 'new', '##par', '##ent', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['new', '##ind', '##ex', '=', '0', 'if', 'event', '.', 'line', '.', 'p', '##0', '.', 'y', '<', '1', 'else', 'len', '(', 'new', '##par', '##ent', ')', '\\', 'n']
Detokenized (019): ['new##ind##ex', '=', '0', 'if', 'event', '.', 'line', '.', 'p##0', '.', 'y', '<', '1', 'else', 'len', '(', 'new##par##ent', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "newParent . insert ( newIndex , self . __dragItem ) \n"
Original    (011): ['newParent', '.', 'insert', '(', 'newIndex', ',', 'self', '.', '__dragItem', ')', '\\n']
Tokenized   (022): ['[CLS]', 'new', '##par', '##ent', '.', 'insert', '(', 'new', '##ind', '##ex', ',', 'self', '.', '_', '_', 'drag', '##ite', '##m', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['new', '##par', '##ent', '.', 'insert', '(', 'new', '##ind', '##ex', ',', 'self', '.', '_', '_', 'drag', '##ite', '##m', ')', '\\', 'n']
Detokenized (011): ['new##par##ent', '.', 'insert', '(', 'new##ind##ex', ',', 'self', '.', '__drag##ite##m', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "selection [ : ] = self . __dragItem . fullName ( ) . split ( "." ) \n"
Original    (018): ['selection', '[', ':', ']', '=', 'self', '.', '__dragItem', '.', 'fullName', '(', ')', '.', 'split', '(', '"."', ')', '\\n']
Tokenized   (028): ['[CLS]', 'selection', '[', ':', ']', '=', 'self', '.', '_', '_', 'drag', '##ite', '##m', '.', 'full', '##name', '(', ')', '.', 'split', '(', '"', '.', '"', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['selection', '[', ':', ']', '=', 'self', '.', '_', '_', 'drag', '##ite', '##m', '.', 'full', '##name', '(', ')', '.', 'split', '(', '"', '.', '"', ')', '\\', 'n']
Detokenized (018): ['selection', '[', ':', ']', '=', 'self', '.', '__drag##ite##m', '.', 'full##name', '(', ')', '.', 'split', '(', '"."', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "_registerMetadata ( plug , "nodule:type" , "" ) \n"
Original    (009): ['_registerMetadata', '(', 'plug', ',', '"nodule:type"', ',', '""', ')', '\\n']
Tokenized   (022): ['[CLS]', '_', 'register', '##met', '##ada', '##ta', '(', 'plug', ',', '"', 'nod', '##ule', ':', 'type', '"', ',', '"', '"', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['_', 'register', '##met', '##ada', '##ta', '(', 'plug', ',', '"', 'nod', '##ule', ':', 'type', '"', ',', '"', '"', ')', '\\', 'n']
Detokenized (009): ['_register##met##ada##ta', '(', 'plug', ',', '"nod##ule:type"', ',', '""', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "parentItem \n"
Original    (002): ['parentItem', '\\n']
Tokenized   (007): ['[CLS]', 'parent', '##ite', '##m', '\\', 'n', '[SEP]']
Filtered   (005): ['parent', '##ite', '##m', '\\', 'n']
Detokenized (002): ['parent##ite##m', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "existingSectionNames = set ( c . name ( ) for c in rootItem if isinstance ( c , _SectionLayoutItem ) ) \n"
Original    (022): ['existingSectionNames', '=', 'set', '(', 'c', '.', 'name', '(', ')', 'for', 'c', 'in', 'rootItem', 'if', 'isinstance', '(', 'c', ',', '_SectionLayoutItem', ')', ')', '\\n']
Tokenized   (037): ['[CLS]', 'existing', '##section', '##name', '##s', '=', 'set', '(', 'c', '.', 'name', '(', ')', 'for', 'c', 'in', 'root', '##ite', '##m', 'if', 'is', '##ins', '##tance', '(', 'c', ',', '_', 'section', '##lay', '##out', '##ite', '##m', ')', ')', '\\', 'n', '[SEP]']
Filtered   (035): ['existing', '##section', '##name', '##s', '=', 'set', '(', 'c', '.', 'name', '(', ')', 'for', 'c', 'in', 'root', '##ite', '##m', 'if', 'is', '##ins', '##tance', '(', 'c', ',', '_', 'section', '##lay', '##out', '##ite', '##m', ')', ')', '\\', 'n']
Detokenized (022): ['existing##section##name##s', '=', 'set', '(', 'c', '.', 'name', '(', ')', 'for', 'c', 'in', 'root##ite##m', 'if', 'is##ins##tance', '(', 'c', ',', '_section##lay##out##ite##m', ')', ')', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "Gaffer . Metadata . plugValue ( self . getPlug ( ) , "preset:" + selectedPaths [ 0 ] [ 0 ] ) \n"
Original    (023): ['Gaffer', '.', 'Metadata', '.', 'plugValue', '(', 'self', '.', 'getPlug', '(', ')', ',', '"preset:"', '+', 'selectedPaths', '[', '0', ']', '[', '0', ']', ')', '\\n']
Tokenized   (037): ['[CLS]', 'ga', '##ffer', '.', 'metadata', '.', 'plug', '##val', '##ue', '(', 'self', '.', 'get', '##pl', '##ug', '(', ')', ',', '"', 'pre', '##set', ':', '"', '+', 'selected', '##path', '##s', '[', '0', ']', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (035): ['ga', '##ffer', '.', 'metadata', '.', 'plug', '##val', '##ue', '(', 'self', '.', 'get', '##pl', '##ug', '(', ')', ',', '"', 'pre', '##set', ':', '"', '+', 'selected', '##path', '##s', '[', '0', ']', '[', '0', ']', ')', '\\', 'n']
Detokenized (023): ['ga##ffer', '.', 'metadata', '.', 'plug##val##ue', '(', 'self', '.', 'get##pl##ug', '(', ')', ',', '"pre##set:"', '+', 'selected##path##s', '[', '0', ']', '[', '0', ']', ')', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "srcPath = self . __pathListing . getPath ( ) . copy ( ) . setFromString ( event . data [ 0 ] ) \n"
Original    (024): ['srcPath', '=', 'self', '.', '__pathListing', '.', 'getPath', '(', ')', '.', 'copy', '(', ')', '.', 'setFromString', '(', 'event', '.', 'data', '[', '0', ']', ')', '\\n']
Tokenized   (038): ['[CLS]', 'sr', '##cp', '##ath', '=', 'self', '.', '_', '_', 'path', '##list', '##ing', '.', 'get', '##path', '(', ')', '.', 'copy', '(', ')', '.', 'set', '##fr', '##oms', '##tri', '##ng', '(', 'event', '.', 'data', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (036): ['sr', '##cp', '##ath', '=', 'self', '.', '_', '_', 'path', '##list', '##ing', '.', 'get', '##path', '(', ')', '.', 'copy', '(', ')', '.', 'set', '##fr', '##oms', '##tri', '##ng', '(', 'event', '.', 'data', '[', '0', ']', ')', '\\', 'n']
Detokenized (024): ['sr##cp##ath', '=', 'self', '.', '__path##list##ing', '.', 'get##path', '(', ')', '.', 'copy', '(', ')', '.', 'set##fr##oms##tri##ng', '(', 'event', '.', 'data', '[', '0', ']', ')', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "srcIndex = d . keys ( ) . index ( srcPath [ 0 ] ) \n"
Original    (016): ['srcIndex', '=', 'd', '.', 'keys', '(', ')', '.', 'index', '(', 'srcPath', '[', '0', ']', ')', '\\n']
Tokenized   (024): ['[CLS]', 'sr', '##cin', '##de', '##x', '=', 'd', '.', 'keys', '(', ')', '.', 'index', '(', 'sr', '##cp', '##ath', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['sr', '##cin', '##de', '##x', '=', 'd', '.', 'keys', '(', ')', '.', 'index', '(', 'sr', '##cp', '##ath', '[', '0', ']', ')', '\\', 'n']
Detokenized (016): ['sr##cin##de##x', '=', 'd', '.', 'keys', '(', ')', '.', 'index', '(', 'sr##cp##ath', '[', '0', ']', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "targetPath = self . __pathListing . pathAt ( event . line . p0 ) \n"
Original    (015): ['targetPath', '=', 'self', '.', '__pathListing', '.', 'pathAt', '(', 'event', '.', 'line', '.', 'p0', ')', '\\n']
Tokenized   (025): ['[CLS]', 'target', '##path', '=', 'self', '.', '_', '_', 'path', '##list', '##ing', '.', 'path', '##at', '(', 'event', '.', 'line', '.', 'p', '##0', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['target', '##path', '=', 'self', '.', '_', '_', 'path', '##list', '##ing', '.', 'path', '##at', '(', 'event', '.', 'line', '.', 'p', '##0', ')', '\\', 'n']
Detokenized (015): ['target##path', '=', 'self', '.', '__path##list##ing', '.', 'path##at', '(', 'event', '.', 'line', '.', 'p##0', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "item = items [ srcIndex ] \n"
Original    (007): ['item', '=', 'items', '[', 'srcIndex', ']', '\\n']
Tokenized   (013): ['[CLS]', 'item', '=', 'items', '[', 'sr', '##cin', '##de', '##x', ']', '\\', 'n', '[SEP]']
Filtered   (011): ['item', '=', 'items', '[', 'sr', '##cin', '##de', '##x', ']', '\\', 'n']
Detokenized (007): ['item', '=', 'items', '[', 'sr##cin##de##x', ']', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "selectedPreset = self . __pathListing . getSelectedPaths ( ) [ 0 ] [ 0 ] \n"
Original    (016): ['selectedPreset', '=', 'self', '.', '__pathListing', '.', 'getSelectedPaths', '(', ')', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (029): ['[CLS]', 'selected', '##pres', '##et', '=', 'self', '.', '_', '_', 'path', '##list', '##ing', '.', 'gets', '##ele', '##cted', '##path', '##s', '(', ')', '[', '0', ']', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (027): ['selected', '##pres', '##et', '=', 'self', '.', '_', '_', 'path', '##list', '##ing', '.', 'gets', '##ele', '##cted', '##path', '##s', '(', ')', '[', '0', ']', '[', '0', ']', '\\', 'n']
Detokenized (016): ['selected##pres##et', '=', 'self', '.', '__path##list##ing', '.', 'gets##ele##cted##path##s', '(', ')', '[', '0', ']', '[', '0', ']', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "selectedIndex = [ p [ 0 ] for p in paths ] . index ( selectedPreset ) \n"
Original    (018): ['selectedIndex', '=', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'paths', ']', '.', 'index', '(', 'selectedPreset', ')', '\\n']
Tokenized   (025): ['[CLS]', 'selected', '##ind', '##ex', '=', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'paths', ']', '.', 'index', '(', 'selected', '##pres', '##et', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['selected', '##ind', '##ex', '=', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'paths', ']', '.', 'index', '(', 'selected', '##pres', '##et', ')', '\\', 'n']
Detokenized (018): ['selected##ind##ex', '=', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'paths', ']', '.', 'index', '(', 'selected##pres##et', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "preset = selectedPaths [ 0 ] [ 0 ] \n"
Original    (010): ['preset', '=', 'selectedPaths', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (016): ['[CLS]', 'pre', '##set', '=', 'selected', '##path', '##s', '[', '0', ']', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['pre', '##set', '=', 'selected', '##path', '##s', '[', '0', ']', '[', '0', ']', '\\', 'n']
Detokenized (010): ['pre##set', '=', 'selected##path##s', '[', '0', ']', '[', '0', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "scrolledContainer . setChild ( GafferUI . ListContainer ( spacing = 4 ) ) \n"
Original    (014): ['scrolledContainer', '.', 'setChild', '(', 'GafferUI', '.', 'ListContainer', '(', 'spacing', '=', '4', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'scroll', '##ed', '##con', '##tain', '##er', '.', 'set', '##child', '(', 'ga', '##ffer', '##ui', '.', 'list', '##con', '##tain', '##er', '(', 'spa', '##cing', '=', '4', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['scroll', '##ed', '##con', '##tain', '##er', '.', 'set', '##child', '(', 'ga', '##ffer', '##ui', '.', 'list', '##con', '##tain', '##er', '(', 'spa', '##cing', '=', '4', ')', ')', '\\', 'n']
Detokenized (014): ['scroll##ed##con##tain##er', '.', 'set##child', '(', 'ga##ffer##ui', '.', 'list##con##tain##er', '(', 'spa##cing', '=', '4', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __gadgetMenuDefinition ) ) \n"
Original    (016): ['menu', '=', 'GafferUI', '.', 'Menu', '(', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__gadgetMenuDefinition', ')', ')', '\\n']
Tokenized   (032): ['[CLS]', 'menu', '=', 'ga', '##ffer', '##ui', '.', 'menu', '(', 'ga', '##ffer', '.', 'weak', '##met', '##ho', '##d', '(', 'self', '.', '_', '_', 'ga', '##dget', '##men', '##ude', '##fin', '##ition', ')', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['menu', '=', 'ga', '##ffer', '##ui', '.', 'menu', '(', 'ga', '##ffer', '.', 'weak', '##met', '##ho', '##d', '(', 'self', '.', '_', '_', 'ga', '##dget', '##men', '##ude', '##fin', '##ition', ')', ')', '\\', 'n']
Detokenized (016): ['menu', '=', 'ga##ffer##ui', '.', 'menu', '(', 'ga##ffer', '.', 'weak##met##ho##d', '(', 'self', '.', '__ga##dget##men##ude##fin##ition', ')', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""/" + g . label , \n"
Original    (007): ['"/"', '+', 'g', '.', 'label', ',', '\\n']
Tokenized   (012): ['[CLS]', '"', '/', '"', '+', 'g', '.', 'label', ',', '\\', 'n', '[SEP]']
Filtered   (010): ['"', '/', '"', '+', 'g', '.', 'label', ',', '\\', 'n']
Detokenized (007): ['"/"', '+', 'g', '.', 'label', ',', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""command" : functools . partial ( Gaffer . WeakMethod ( self . __registerOrDeregisterMetadata ) , key = "checkBox" : metadata == g . metadata , \n"
Original    (026): ['"command"', ':', 'functools', '.', 'partial', '(', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__registerOrDeregisterMetadata', ')', ',', 'key', '=', '"checkBox"', ':', 'metadata', '==', 'g', '.', 'metadata', ',', '\\n']
Tokenized   (051): ['[CLS]', '"', 'command', '"', ':', 'fun', '##ct', '##ool', '##s', '.', 'partial', '(', 'ga', '##ffer', '.', 'weak', '##met', '##ho', '##d', '(', 'self', '.', '_', '_', 'register', '##ord', '##ere', '##gist', '##er', '##met', '##ada', '##ta', ')', ',', 'key', '=', '"', 'check', '##box', '"', ':', 'metadata', '=', '=', 'g', '.', 'metadata', ',', '\\', 'n', '[SEP]']
Filtered   (049): ['"', 'command', '"', ':', 'fun', '##ct', '##ool', '##s', '.', 'partial', '(', 'ga', '##ffer', '.', 'weak', '##met', '##ho', '##d', '(', 'self', '.', '_', '_', 'register', '##ord', '##ere', '##gist', '##er', '##met', '##ada', '##ta', ')', ',', 'key', '=', '"', 'check', '##box', '"', ':', 'metadata', '=', '=', 'g', '.', 'metadata', ',', '\\', 'n']
Detokenized (026): ['"command"', ':', 'fun##ct##ool##s', '.', 'partial', '(', 'ga##ffer', '.', 'weak##met##ho##d', '(', 'self', '.', '__register##ord##ere##gist##er##met##ada##ta', ')', ',', 'key', '=', '"check##box"', ':', 'metadata', '==', 'g', '.', 'metadata', ',', '\\n']
Counter: 49
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "__WidgetDefinition ( "None" , Gaffer . Plug , "" ) , \n"
Original    (012): ['__WidgetDefinition', '(', '"None"', ',', 'Gaffer', '.', 'Plug', ',', '""', ')', ',', '\\n']
Tokenized   (025): ['[CLS]', '_', '_', 'wi', '##dget', '##de', '##fin', '##ition', '(', '"', 'none', '"', ',', 'ga', '##ffer', '.', 'plug', ',', '"', '"', ')', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['_', '_', 'wi', '##dget', '##de', '##fin', '##ition', '(', '"', 'none', '"', ',', 'ga', '##ffer', '.', 'plug', ',', '"', '"', ')', ',', '\\', 'n']
Detokenized (012): ['__wi##dget##de##fin##ition', '(', '"none"', ',', 'ga##ffer', '.', 'plug', ',', '""', ')', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "__MetadataDefinition = collections . namedtuple ( "MetadataDefinition" , ( "key" , "label" , "metadataWidgetType" __metadataDefinitions = ( \n"
Original    (018): ['__MetadataDefinition', '=', 'collections', '.', 'namedtuple', '(', '"MetadataDefinition"', ',', '(', '"key"', ',', '"label"', ',', '"metadataWidgetType"', '__metadataDefinitions', '=', '(', '\\n']
Tokenized   (048): ['[CLS]', '_', '_', 'metadata', '##de', '##fin', '##ition', '=', 'collections', '.', 'named', '##tu', '##ple', '(', '"', 'metadata', '##de', '##fin', '##ition', '"', ',', '(', '"', 'key', '"', ',', '"', 'label', '"', ',', '"', 'metadata', '##wi', '##dget', '##type', '"', '_', '_', 'metadata', '##de', '##fin', '##ition', '##s', '=', '(', '\\', 'n', '[SEP]']
Filtered   (046): ['_', '_', 'metadata', '##de', '##fin', '##ition', '=', 'collections', '.', 'named', '##tu', '##ple', '(', '"', 'metadata', '##de', '##fin', '##ition', '"', ',', '(', '"', 'key', '"', ',', '"', 'label', '"', ',', '"', 'metadata', '##wi', '##dget', '##type', '"', '_', '_', 'metadata', '##de', '##fin', '##ition', '##s', '=', '(', '\\', 'n']
Detokenized (018): ['__metadata##de##fin##ition', '=', 'collections', '.', 'named##tu##ple', '(', '"metadata##de##fin##ition"', ',', '(', '"key"', ',', '"label"', ',', '"metadata##wi##dget##type"', '__metadata##de##fin##ition##s', '=', '(', '\\n']
Counter: 46
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "newSectionPath [ - 1 ] = nameWidget . getText ( ) . replace ( "." , "" ) \n"
Original    (019): ['newSectionPath', '[', '-', '1', ']', '=', 'nameWidget', '.', 'getText', '(', ')', '.', 'replace', '(', '"."', ',', '""', ')', '\\n']
Tokenized   (030): ['[CLS]', 'news', '##ection', '##path', '[', '-', '1', ']', '=', 'name', '##wi', '##dget', '.', 'get', '##text', '(', ')', '.', 'replace', '(', '"', '.', '"', ',', '"', '"', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['news', '##ection', '##path', '[', '-', '1', ']', '=', 'name', '##wi', '##dget', '.', 'get', '##text', '(', ')', '.', 'replace', '(', '"', '.', '"', ',', '"', '"', ')', '\\', 'n']
Detokenized (019): ['news##ection##path', '[', '-', '1', ']', '=', 'name##wi##dget', '.', 'get##text', '(', ')', '.', 'replace', '(', '"."', ',', '""', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "_metadata ( self . getPlugParent ( ) , name ) \n"
Original    (011): ['_metadata', '(', 'self', '.', 'getPlugParent', '(', ')', ',', 'name', ')', '\\n']
Tokenized   (019): ['[CLS]', '_', 'metadata', '(', 'self', '.', 'get', '##pl', '##ug', '##par', '##ent', '(', ')', ',', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['_', 'metadata', '(', 'self', '.', 'get', '##pl', '##ug', '##par', '##ent', '(', ')', ',', 'name', ')', '\\', 'n']
Detokenized (011): ['_metadata', '(', 'self', '.', 'get##pl##ug##par##ent', '(', ')', ',', 'name', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_deregisterMetadata ( self . getPlugParent ( ) , name ) \n"
Original    (011): ['_deregisterMetadata', '(', 'self', '.', 'getPlugParent', '(', ')', ',', 'name', ')', '\\n']
Tokenized   (024): ['[CLS]', '_', 'der', '##eg', '##ister', '##met', '##ada', '##ta', '(', 'self', '.', 'get', '##pl', '##ug', '##par', '##ent', '(', ')', ',', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['_', 'der', '##eg', '##ister', '##met', '##ada', '##ta', '(', 'self', '.', 'get', '##pl', '##ug', '##par', '##ent', '(', ')', ',', 'name', ')', '\\', 'n']
Detokenized (011): ['_der##eg##ister##met##ada##ta', '(', 'self', '.', 'get##pl##ug##par##ent', '(', ')', ',', 'name', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "wr2 = weakref . ref ( w . _qtWidget ( ) ) \n"
Original    (013): ['wr2', '=', 'weakref', '.', 'ref', '(', 'w', '.', '_qtWidget', '(', ')', ')', '\\n']
Tokenized   (023): ['[CLS]', 'wr', '##2', '=', 'weak', '##re', '##f', '.', 'ref', '(', 'w', '.', '_', 'q', '##t', '##wi', '##dget', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['wr', '##2', '=', 'weak', '##re', '##f', '.', 'ref', '(', 'w', '.', '_', 'q', '##t', '##wi', '##dget', '(', ')', ')', '\\', 'n']
Detokenized (013): ['wr##2', '=', 'weak##re##f', '.', 'ref', '(', 'w', '.', '_q##t##wi##dget', '(', ')', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "WidgetTest . signalsEmitted = 0 \n"
Original    (006): ['WidgetTest', '.', 'signalsEmitted', '=', '0', '\\n']
Tokenized   (013): ['[CLS]', 'wi', '##dget', '##test', '.', 'signals', '##emi', '##tted', '=', '0', '\\', 'n', '[SEP]']
Filtered   (011): ['wi', '##dget', '##test', '.', 'signals', '##emi', '##tted', '=', '0', '\\', 'n']
Detokenized (006): ['wi##dget##test', '.', 'signals##emi##tted', '=', '0', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) \n"
Original    (019): ['QtGui', '.', 'QApplication', '.', 'instance', '(', ')', '.', 'sendEvent', '(', 'w', '.', '_qtWidget', '(', ')', ',', 'event', ')', '\\n']
Tokenized   (033): ['[CLS]', 'q', '##t', '##gui', '.', 'q', '##app', '##lica', '##tion', '.', 'instance', '(', ')', '.', 'send', '##eve', '##nt', '(', 'w', '.', '_', 'q', '##t', '##wi', '##dget', '(', ')', ',', 'event', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['q', '##t', '##gui', '.', 'q', '##app', '##lica', '##tion', '.', 'instance', '(', ')', '.', 'send', '##eve', '##nt', '(', 'w', '.', '_', 'q', '##t', '##wi', '##dget', '(', ')', ',', 'event', ')', '\\', 'n']
Detokenized (019): ['q##t##gui', '.', 'q##app##lica##tion', '.', 'instance', '(', ')', '.', 'send##eve##nt', '(', 'w', '.', '_q##t##wi##dget', '(', ')', ',', 'event', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "GafferUI . BoxUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) \n"
Original    (013): ['GafferUI', '.', 'BoxUI', '.', 'appendNodeEditorToolMenuDefinitions', '(', 'nodeEditor', ',', 'node', ',', 'menuDefinition', ')', '\\n']
Tokenized   (035): ['[CLS]', 'ga', '##ffer', '##ui', '.', 'box', '##ui', '.', 'app', '##end', '##no', '##dee', '##dit', '##ort', '##ool', '##men', '##ude', '##fin', '##ition', '##s', '(', 'node', '##ed', '##itor', ',', 'node', ',', 'menu', '##de', '##fin', '##ition', ')', '\\', 'n', '[SEP]']
Filtered   (033): ['ga', '##ffer', '##ui', '.', 'box', '##ui', '.', 'app', '##end', '##no', '##dee', '##dit', '##ort', '##ool', '##men', '##ude', '##fin', '##ition', '##s', '(', 'node', '##ed', '##itor', ',', 'node', ',', 'menu', '##de', '##fin', '##ition', ')', '\\', 'n']
Detokenized (013): ['ga##ffer##ui', '.', 'box##ui', '.', 'app##end##no##dee##dit##ort##ool##men##ude##fin##ition##s', '(', 'node##ed##itor', ',', 'node', ',', 'menu##de##fin##ition', ')', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "GafferSceneUI . FilteredSceneProcessorUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition \n"
Original    (012): ['GafferSceneUI', '.', 'FilteredSceneProcessorUI', '.', 'appendNodeEditorToolMenuDefinitions', '(', 'nodeEditor', ',', 'node', ',', 'menuDefinition', '\\n']
Tokenized   (041): ['[CLS]', 'ga', '##ffer', '##sc', '##ene', '##ui', '.', 'filtered', '##sc', '##ene', '##pro', '##ces', '##sor', '##ui', '.', 'app', '##end', '##no', '##dee', '##dit', '##ort', '##ool', '##men', '##ude', '##fin', '##ition', '##s', '(', 'node', '##ed', '##itor', ',', 'node', ',', 'menu', '##de', '##fin', '##ition', '\\', 'n', '[SEP]']
Filtered   (039): ['ga', '##ffer', '##sc', '##ene', '##ui', '.', 'filtered', '##sc', '##ene', '##pro', '##ces', '##sor', '##ui', '.', 'app', '##end', '##no', '##dee', '##dit', '##ort', '##ool', '##men', '##ude', '##fin', '##ition', '##s', '(', 'node', '##ed', '##itor', ',', 'node', ',', 'menu', '##de', '##fin', '##ition', '\\', 'n']
Detokenized (012): ['ga##ffer##sc##ene##ui', '.', 'filtered##sc##ene##pro##ces##sor##ui', '.', 'app##end##no##dee##dit##ort##ool##men##ude##fin##ition##s', '(', 'node##ed##itor', ',', 'node', ',', 'menu##de##fin##ition', '\\n']
Counter: 39
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "yappi . print_stats ( sort_type = yappi . SORTTYPE_TTOT , limit = 30 , thread_stats_on = False ) \n"
Original    (019): ['yappi', '.', 'print_stats', '(', 'sort_type', '=', 'yappi', '.', 'SORTTYPE_TTOT', ',', 'limit', '=', '30', ',', 'thread_stats_on', '=', 'False', ')', '\\n']
Tokenized   (038): ['[CLS]', 'ya', '##pp', '##i', '.', 'print', '_', 'stats', '(', 'sort', '_', 'type', '=', 'ya', '##pp', '##i', '.', 'sort', '##type', '_', 'tt', '##ot', ',', 'limit', '=', '30', ',', 'thread', '_', 'stats', '_', 'on', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (036): ['ya', '##pp', '##i', '.', 'print', '_', 'stats', '(', 'sort', '_', 'type', '=', 'ya', '##pp', '##i', '.', 'sort', '##type', '_', 'tt', '##ot', ',', 'limit', '=', '30', ',', 'thread', '_', 'stats', '_', 'on', '=', 'false', ')', '\\', 'n']
Detokenized (019): ['ya##pp##i', '.', 'print_stats', '(', 'sort_type', '=', 'ya##pp##i', '.', 'sort##type_tt##ot', ',', 'limit', '=', '30', ',', 'thread_stats_on', '=', 'false', ')', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "SAMPLE_EXTRACT_METRICS_PAGE = os . path . join ( datadir , "monthly_download" ) \n"
Original    (013): ['SAMPLE_EXTRACT_METRICS_PAGE', '=', 'os', '.', 'path', '.', 'join', '(', 'datadir', ',', '"monthly_download"', ')', '\\n']
Tokenized   (029): ['[CLS]', 'sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', '=', 'os', '.', 'path', '.', 'join', '(', 'data', '##di', '##r', ',', '"', 'monthly', '_', 'download', '"', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', '=', 'os', '.', 'path', '.', 'join', '(', 'data', '##di', '##r', ',', '"', 'monthly', '_', 'download', '"', ')', '\\', 'n']
Detokenized (013): ['sample_extract_metric##s_page', '=', 'os', '.', 'path', '.', 'join', '(', 'data##di##r', ',', '"monthly_download"', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH = os . path . join ( datadir , "monthly_download_different_month" \n"
Original    (012): ['SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', '=', 'os', '.', 'path', '.', 'join', '(', 'datadir', ',', '"monthly_download_different_month"', '\\n']
Tokenized   (036): ['[CLS]', 'sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', '_', 'different', '_', 'month', '=', 'os', '.', 'path', '.', 'join', '(', 'data', '##di', '##r', ',', '"', 'monthly', '_', 'download', '_', 'different', '_', 'month', '"', '\\', 'n', '[SEP]']
Filtered   (034): ['sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', '_', 'different', '_', 'month', '=', 'os', '.', 'path', '.', 'join', '(', 'data', '##di', '##r', ',', '"', 'monthly', '_', 'download', '_', 'different', '_', 'month', '"', '\\', 'n']
Detokenized (012): ['sample_extract_metric##s_page_different_month', '=', 'os', '.', 'path', '.', 'join', '(', 'data##di##r', ',', '"monthly_download_different_month"', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "testitem_aliases = ( "pmid" , TEST_PMID ) \n"
Original    (008): ['testitem_aliases', '=', '(', '"pmid"', ',', 'TEST_PMID', ')', '\\n']
Tokenized   (020): ['[CLS]', 'test', '##ite', '##m', '_', 'alias', '##es', '=', '(', '"', 'pmid', '"', ',', 'test', '_', 'pmid', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['test', '##ite', '##m', '_', 'alias', '##es', '=', '(', '"', 'pmid', '"', ',', 'test', '_', 'pmid', ')', '\\', 'n']
Detokenized (008): ['test##ite##m_alias##es', '=', '(', '"pmid"', ',', 'test_pmid', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sample_data_dump = open ( SAMPLE_EXTRACT_METRICS_PAGE , "r" ) . read ( ) \n"
Original    (013): ['sample_data_dump', '=', 'open', '(', 'SAMPLE_EXTRACT_METRICS_PAGE', ',', '"r"', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (029): ['[CLS]', 'sample', '_', 'data', '_', 'dump', '=', 'open', '(', 'sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', ',', '"', 'r', '"', ')', '.', 'read', '(', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['sample', '_', 'data', '_', 'dump', '=', 'open', '(', 'sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', ',', '"', 'r', '"', ')', '.', 'read', '(', ')', '\\', 'n']
Detokenized (013): ['sample_data_dump', '=', 'open', '(', 'sample_extract_metric##s_page', ',', '"r"', ')', '.', 'read', '(', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sample_data_dump_different_month = open ( SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH , "r" ) . read \n"
Original    (011): ['sample_data_dump_different_month', '=', 'open', '(', 'SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', ',', '"r"', ')', '.', 'read', '\\n']
Tokenized   (035): ['[CLS]', 'sample', '_', 'data', '_', 'dump', '_', 'different', '_', 'month', '=', 'open', '(', 'sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', '_', 'different', '_', 'month', ',', '"', 'r', '"', ')', '.', 'read', '\\', 'n', '[SEP]']
Filtered   (033): ['sample', '_', 'data', '_', 'dump', '_', 'different', '_', 'month', '=', 'open', '(', 'sample', '_', 'extract', '_', 'metric', '##s', '_', 'page', '_', 'different', '_', 'month', ',', '"', 'r', '"', ')', '.', 'read', '\\', 'n']
Detokenized (011): ['sample_data_dump_different_month', '=', 'open', '(', 'sample_extract_metric##s_page_different_month', ',', '"r"', ')', '.', 'read', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""max_event_date" : "2012-01-31T07:34:01.126892" \n"
Original    (004): ['"max_event_date"', ':', '"2012-01-31T07:34:01.126892"', '\\n']
Tokenized   (031): ['[CLS]', '"', 'max', '_', 'event', '_', 'date', '"', ':', '"', '2012', '-', '01', '-', '31', '##t', '##0', '##7', ':', '34', ':', '01', '.', '126', '##8', '##9', '##2', '"', '\\', 'n', '[SEP]']
Filtered   (029): ['"', 'max', '_', 'event', '_', 'date', '"', ':', '"', '2012', '-', '01', '-', '31', '##t', '##0', '##7', ':', '34', ':', '01', '.', '126', '##8', '##9', '##2', '"', '\\', 'n']
Detokenized (004): ['"max_event_date"', ':', '"2012-01-31##t##0##7:34:01.126##8##9##2"', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""_id" : "abc123" , \n"
Original    (005): ['"_id"', ':', '"abc123"', ',', '\\n']
Tokenized   (015): ['[CLS]', '"', '_', 'id', '"', ':', '"', 'abc', '##12', '##3', '"', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['"', '_', 'id', '"', ':', '"', 'abc', '##12', '##3', '"', ',', '\\', 'n']
Detokenized (005): ['"_id"', ':', '"abc##12##3"', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""raw" : "max_event_date" : "2012-10-31T07:34:01.126892" , \n"
Original    (007): ['"raw"', ':', '"max_event_date"', ':', '"2012-10-31T07:34:01.126892"', ',', '\\n']
Tokenized   (036): ['[CLS]', '"', 'raw', '"', ':', '"', 'max', '_', 'event', '_', 'date', '"', ':', '"', '2012', '-', '10', '-', '31', '##t', '##0', '##7', ':', '34', ':', '01', '.', '126', '##8', '##9', '##2', '"', ',', '\\', 'n', '[SEP]']
Filtered   (034): ['"', 'raw', '"', ':', '"', 'max', '_', 'event', '_', 'date', '"', ':', '"', '2012', '-', '10', '-', '31', '##t', '##0', '##7', ':', '34', ':', '01', '.', '126', '##8', '##9', '##2', '"', ',', '\\', 'n']
Detokenized (007): ['"raw"', ':', '"max_event_date"', ':', '"2012-10-31##t##0##7:34:01.126##8##9##2"', ',', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""23110252" \n"
Original    (002): ['"23110252"', '\\n']
Tokenized   (010): ['[CLS]', '"', '231', '##10', '##25', '##2', '"', '\\', 'n', '[SEP]']
Filtered   (008): ['"', '231', '##10', '##25', '##2', '"', '\\', 'n']
Detokenized (002): ['"231##10##25##2"', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "cache_client = redis . from_url ( os . getenv ( "REDIS_URL" ) , REDIS_CACHE_DATABASE_NUMBER ) \n"
Original    (016): ['cache_client', '=', 'redis', '.', 'from_url', '(', 'os', '.', 'getenv', '(', '"REDIS_URL"', ')', ',', 'REDIS_CACHE_DATABASE_NUMBER', ')', '\\n']
Tokenized   (040): ['[CLS]', 'cache', '_', 'client', '=', 'red', '##is', '.', 'from', '_', 'ur', '##l', '(', 'os', '.', 'get', '##en', '##v', '(', '"', 'red', '##is', '_', 'ur', '##l', '"', ')', ',', 'red', '##is', '_', 'cache', '_', 'database', '_', 'number', ')', '\\', 'n', '[SEP]']
Filtered   (038): ['cache', '_', 'client', '=', 'red', '##is', '.', 'from', '_', 'ur', '##l', '(', 'os', '.', 'get', '##en', '##v', '(', '"', 'red', '##is', '_', 'ur', '##l', '"', ')', ',', 'red', '##is', '_', 'cache', '_', 'database', '_', 'number', ')', '\\', 'n']
Detokenized (016): ['cache_client', '=', 'red##is', '.', 'from_ur##l', '(', 'os', '.', 'get##en##v', '(', '"red##is_ur##l"', ')', ',', 'red##is_cache_database_number', ')', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "MAX_CACHE_SIZE_BYTES = 100 * 1000 * 1000 #100mb \n"
Original    (009): ['MAX_CACHE_SIZE_BYTES', '=', '100', '*', '1000', '*', '1000', '#100mb', '\\n']
Tokenized   (020): ['[CLS]', 'max', '_', 'cache', '_', 'size', '_', 'bytes', '=', '100', '*', '1000', '*', '1000', '#', '100', '##mb', '\\', 'n', '[SEP]']
Filtered   (018): ['max', '_', 'cache', '_', 'size', '_', 'bytes', '=', '100', '*', '1000', '*', '1000', '#', '100', '##mb', '\\', 'n']
Detokenized (009): ['max_cache_size_bytes', '=', '100', '*', '1000', '*', '1000', '#100##mb', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "set_response = mc . set ( hash_key , json . dumps ( data ) ) \n"
Original    (016): ['set_response', '=', 'mc', '.', 'set', '(', 'hash_key', ',', 'json', '.', 'dumps', '(', 'data', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'set', '_', 'response', '=', 'mc', '.', 'set', '(', 'hash', '_', 'key', ',', 'j', '##son', '.', 'dump', '##s', '(', 'data', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['set', '_', 'response', '=', 'mc', '.', 'set', '(', 'hash', '_', 'key', ',', 'j', '##son', '.', 'dump', '##s', '(', 'data', ')', ')', '\\', 'n']
Detokenized (016): ['set_response', '=', 'mc', '.', 'set', '(', 'hash_key', ',', 'j##son', '.', 'dump##s', '(', 'data', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "metrics_url_template = "http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key=" provenance_url_template = "http://dx.doi.org/%s" \n"
Original    (007): ['metrics_url_template', '=', '"http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key="', 'provenance_url_template', '=', '"http://dx.doi.org/%s"', '\\n']
Tokenized   (072): ['[CLS]', 'metric', '##s', '_', 'ur', '##l', '_', 'template', '=', '"', 'http', ':', '/', '/', 'al', '##m', '.', 'pl', '##os', '.', 'org', '/', 'api', '/', 'v', '##3', '/', 'articles', '?', 'id', '##s', '=', '%', 's', '&', 'source', '=', 'citations', ',', 'counter', '&', 'api', '_', 'key', '=', '"', 'proven', '##ance', '_', 'ur', '##l', '_', 'template', '=', '"', 'http', ':', '/', '/', 'd', '##x', '.', 'doi', '.', 'org', '/', '%', 's', '"', '\\', 'n', '[SEP]']
Filtered   (070): ['metric', '##s', '_', 'ur', '##l', '_', 'template', '=', '"', 'http', ':', '/', '/', 'al', '##m', '.', 'pl', '##os', '.', 'org', '/', 'api', '/', 'v', '##3', '/', 'articles', '?', 'id', '##s', '=', '%', 's', '&', 'source', '=', 'citations', ',', 'counter', '&', 'api', '_', 'key', '=', '"', 'proven', '##ance', '_', 'ur', '##l', '_', 'template', '=', '"', 'http', ':', '/', '/', 'd', '##x', '.', 'doi', '.', 'org', '/', '%', 's', '"', '\\', 'n']
Detokenized (007): ['metric##s_ur##l_template', '=', '"http://al##m.pl##os.org/api/v##3/articles?id##s=%s&source=citations,counter&api_key="', 'proven##ance_ur##l_template', '=', '"http://d##x.doi.org/%s"', '\\n']
Counter: 70
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "relevant = ( ( "doi" == namespace ) and ( "10.1371/" in nid ) ) \n"
Original    (016): ['relevant', '=', '(', '(', '"doi"', '==', 'namespace', ')', 'and', '(', '"10.1371/"', 'in', 'nid', ')', ')', '\\n']
Tokenized   (030): ['[CLS]', 'relevant', '=', '(', '(', '"', 'doi', '"', '=', '=', 'names', '##pace', ')', 'and', '(', '"', '10', '.', '137', '##1', '/', '"', 'in', 'ni', '##d', ')', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['relevant', '=', '(', '(', '"', 'doi', '"', '=', '=', 'names', '##pace', ')', 'and', '(', '"', '10', '.', '137', '##1', '/', '"', 'in', 'ni', '##d', ')', ')', '\\', 'n']
Detokenized (016): ['relevant', '=', '(', '(', '"doi"', '==', 'names##pace', ')', 'and', '(', '"10.137##1/"', 'in', 'ni##d', ')', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "this_article = json_response [ 0 ] [ "sources" ] [ 0 ] [ "metrics" ] \n"
Original    (016): ['this_article', '=', 'json_response', '[', '0', ']', '[', '"sources"', ']', '[', '0', ']', '[', '"metrics"', ']', '\\n']
Tokenized   (029): ['[CLS]', 'this', '_', 'article', '=', 'j', '##son', '_', 'response', '[', '0', ']', '[', '"', 'sources', '"', ']', '[', '0', ']', '[', '"', 'metric', '##s', '"', ']', '\\', 'n', '[SEP]']
Filtered   (027): ['this', '_', 'article', '=', 'j', '##son', '_', 'response', '[', '0', ']', '[', '"', 'sources', '"', ']', '[', '0', ']', '[', '"', 'metric', '##s', '"', ']', '\\', 'n']
Detokenized (016): ['this_article', '=', 'j##son_response', '[', '0', ']', '[', '"sources"', ']', '[', '0', ']', '[', '"metric##s"', ']', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "redis_url = os . environ . get ( , "redis://127.0.0.1:6379/" ) \n"
Original    (012): ['redis_url', '=', 'os', '.', 'environ', '.', 'get', '(', ',', '"redis://127.0.0.1:6379/"', ')', '\\n']
Tokenized   (039): ['[CLS]', 'red', '##is', '_', 'ur', '##l', '=', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', ',', '"', 'red', '##is', ':', '/', '/', '127', '.', '0', '.', '0', '.', '1', ':', '63', '##7', '##9', '/', '"', ')', '\\', 'n', '[SEP]']
Filtered   (037): ['red', '##is', '_', 'ur', '##l', '=', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', ',', '"', 'red', '##is', ':', '/', '/', '127', '.', '0', '.', '0', '.', '1', ':', '63', '##7', '##9', '/', '"', ')', '\\', 'n']
Detokenized (012): ['red##is_ur##l', '=', 'os', '.', 'en##vir##on', '.', 'get', '(', ',', '"red##is://127.0.0.1:63##7##9/"', ')', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Queue ( , routing_key = ) \n"
Original    (007): ['Queue', '(', ',', 'routing_key', '=', ')', '\\n']
Tokenized   (012): ['[CLS]', 'queue', '(', ',', 'routing', '_', 'key', '=', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['queue', '(', ',', 'routing', '_', 'key', '=', ')', '\\', 'n']
Detokenized (007): ['queue', '(', ',', 'routing_key', '=', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "CELERY_ACCEPT_CONTENT = [ , ] \n"
Original    (006): ['CELERY_ACCEPT_CONTENT', '=', '[', ',', ']', '\\n']
Tokenized   (015): ['[CLS]', 'ce', '##ler', '##y', '_', 'accept', '_', 'content', '=', '[', ',', ']', '\\', 'n', '[SEP]']
Filtered   (013): ['ce', '##ler', '##y', '_', 'accept', '_', 'content', '=', '[', ',', ']', '\\', 'n']
Detokenized (006): ['ce##ler##y_accept_content', '=', '[', ',', ']', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "CELERY_IMPORTS = ( "core_tasks" , ) \n"
Original    (007): ['CELERY_IMPORTS', '=', '(', '"core_tasks"', ',', ')', '\\n']
Tokenized   (018): ['[CLS]', 'ce', '##ler', '##y', '_', 'imports', '=', '(', '"', 'core', '_', 'tasks', '"', ',', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['ce', '##ler', '##y', '_', 'imports', '=', '(', '"', 'core', '_', 'tasks', '"', ',', ')', '\\', 'n']
Detokenized (007): ['ce##ler##y_imports', '=', '(', '"core_tasks"', ',', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "sampledir = os . path . join ( os . path . split ( __file__ ) [ 0 ] , "../../../extras/sample_provider_pages/" ) \n"
Original    (023): ['sampledir', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'split', '(', '__file__', ')', '[', '0', ']', ',', '"../../../extras/sample_provider_pages/"', ')', '\\n']
Tokenized   (049): ['[CLS]', 'sampled', '##ir', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'split', '(', '_', '_', 'file', '_', '_', ')', '[', '0', ']', ',', '"', '.', '.', '/', '.', '.', '/', '.', '.', '/', 'extras', '/', 'sample', '_', 'provider', '_', 'pages', '/', '"', ')', '\\', 'n', '[SEP]']
Filtered   (047): ['sampled', '##ir', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'split', '(', '_', '_', 'file', '_', '_', ')', '[', '0', ']', ',', '"', '.', '.', '/', '.', '.', '/', '.', '.', '/', 'extras', '/', 'sample', '_', 'provider', '_', 'pages', '/', '"', ')', '\\', 'n']
Detokenized (023): ['sampled##ir', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'split', '(', '__file__', ')', '[', '0', ']', ',', '"../../../extras/sample_provider_pages/"', ')', '\\n']
Counter: 47
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "TEST_XML = open ( os . path . join ( sampledir , "facebook" , "metrics" ) ) . read ( ) \n"
Original    (022): ['TEST_XML', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'sampledir', ',', '"facebook"', ',', '"metrics"', ')', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (033): ['[CLS]', 'test', '_', 'xml', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'sampled', '##ir', ',', '"', 'facebook', '"', ',', '"', 'metric', '##s', '"', ')', ')', '.', 'read', '(', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['test', '_', 'xml', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'sampled', '##ir', ',', '"', 'facebook', '"', ',', '"', 'metric', '##s', '"', ')', ')', '.', 'read', '(', ')', '\\', 'n']
Detokenized (022): ['test_xml', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'sampled##ir', ',', '"facebook"', ',', '"metric##s"', ')', ')', '.', 'read', '(', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "provider_names = [ provider . __class__ . __name__ for provider in providers ] \n"
Original    (014): ['provider_names', '=', '[', 'provider', '.', '__class__', '.', '__name__', 'for', 'provider', 'in', 'providers', ']', '\\n']
Tokenized   (027): ['[CLS]', 'provider', '_', 'names', '=', '[', 'provider', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', 'for', 'provider', 'in', 'providers', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['provider', '_', 'names', '=', '[', 'provider', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', 'for', 'provider', 'in', 'providers', ']', '\\', 'n']
Detokenized (014): ['provider_names', '=', '[', 'provider', '.', '__class__', '.', '__name__', 'for', 'provider', 'in', 'providers', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "assert_equals ( md [ "pubmed" ] [ ] , ) \n"
Original    (011): ['assert_equals', '(', 'md', '[', '"pubmed"', ']', '[', ']', ',', ')', '\\n']
Tokenized   (019): ['[CLS]', 'assert', '_', 'equals', '(', 'md', '[', '"', 'pub', '##med', '"', ']', '[', ']', ',', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['assert', '_', 'equals', '(', 'md', '[', '"', 'pub', '##med', '"', ']', '[', ']', ',', ')', '\\', 'n']
Detokenized (011): ['assert_equals', '(', 'md', '[', '"pub##med"', ']', '[', ']', ',', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tiid = db . Column ( db . Text , db . ForeignKey ( ) , primary_key = True ) \n"
Original    (021): ['tiid', '=', 'db', '.', 'Column', '(', 'db', '.', 'Text', ',', 'db', '.', 'ForeignKey', '(', ')', ',', 'primary_key', '=', 'True', ')', '\\n']
Tokenized   (028): ['[CLS]', 'ti', '##id', '=', 'db', '.', 'column', '(', 'db', '.', 'text', ',', 'db', '.', 'foreign', '##key', '(', ')', ',', 'primary', '_', 'key', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['ti', '##id', '=', 'db', '.', 'column', '(', 'db', '.', 'text', ',', 'db', '.', 'foreign', '##key', '(', ')', ',', 'primary', '_', 'key', '=', 'true', ')', '\\', 'n']
Detokenized (021): ['ti##id', '=', 'db', '.', 'column', '(', 'db', '.', 'text', ',', 'db', '.', 'foreign##key', '(', ')', ',', 'primary_key', '=', 'true', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "tweet_ids_with_response = [ tweet [ "id_str" ] for tweet in data ] \n"
Original    (013): ['tweet_ids_with_response', '=', '[', 'tweet', '[', '"id_str"', ']', 'for', 'tweet', 'in', 'data', ']', '\\n']
Tokenized   (034): ['[CLS]', 't', '##wee', '##t', '_', 'id', '##s', '_', 'with', '_', 'response', '=', '[', 't', '##wee', '##t', '[', '"', 'id', '_', 'st', '##r', '"', ']', 'for', 't', '##wee', '##t', 'in', 'data', ']', '\\', 'n', '[SEP]']
Filtered   (032): ['t', '##wee', '##t', '_', 'id', '##s', '_', 'with', '_', 'response', '=', '[', 't', '##wee', '##t', '[', '"', 'id', '_', 'st', '##r', '"', ']', 'for', 't', '##wee', '##t', 'in', 'data', ']', '\\', 'n']
Detokenized (013): ['t##wee##t_id##s_with_response', '=', '[', 't##wee##t', '[', '"id_st##r"', ']', 'for', 't##wee##t', 'in', 'data', ']', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "tweet_ids_without_response = [ tweet for tweet in tweet_ids if tweet not in tweet_ids_with_response flag_deleted_tweets ( tweet_ids_without_response ) \n"
Original    (018): ['tweet_ids_without_response', '=', '[', 'tweet', 'for', 'tweet', 'in', 'tweet_ids', 'if', 'tweet', 'not', 'in', 'tweet_ids_with_response', 'flag_deleted_tweets', '(', 'tweet_ids_without_response', ')', '\\n']
Tokenized   (065): ['[CLS]', 't', '##wee', '##t', '_', 'id', '##s', '_', 'without', '_', 'response', '=', '[', 't', '##wee', '##t', 'for', 't', '##wee', '##t', 'in', 't', '##wee', '##t', '_', 'id', '##s', 'if', 't', '##wee', '##t', 'not', 'in', 't', '##wee', '##t', '_', 'id', '##s', '_', 'with', '_', 'response', 'flag', '_', 'deleted', '_', 't', '##wee', '##ts', '(', 't', '##wee', '##t', '_', 'id', '##s', '_', 'without', '_', 'response', ')', '\\', 'n', '[SEP]']
Filtered   (063): ['t', '##wee', '##t', '_', 'id', '##s', '_', 'without', '_', 'response', '=', '[', 't', '##wee', '##t', 'for', 't', '##wee', '##t', 'in', 't', '##wee', '##t', '_', 'id', '##s', 'if', 't', '##wee', '##t', 'not', 'in', 't', '##wee', '##t', '_', 'id', '##s', '_', 'with', '_', 'response', 'flag', '_', 'deleted', '_', 't', '##wee', '##ts', '(', 't', '##wee', '##t', '_', 'id', '##s', '_', 'without', '_', 'response', ')', '\\', 'n']
Detokenized (018): ['t##wee##t_id##s_without_response', '=', '[', 't##wee##t', 'for', 't##wee##t', 'in', 't##wee##t_id##s', 'if', 't##wee##t', 'not', 'in', 't##wee##t_id##s_with_response', 'flag_deleted_t##wee##ts', '(', 't##wee##t_id##s_without_response', ')', '\\n']
Counter: 63
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "access_token = os . getenv ( "TWITTER_ACCESS_TOKEN" ) \n"
Original    (009): ['access_token', '=', 'os', '.', 'getenv', '(', '"TWITTER_ACCESS_TOKEN"', ')', '\\n']
Tokenized   (022): ['[CLS]', 'access', '_', 'token', '=', 'os', '.', 'get', '##en', '##v', '(', '"', 'twitter', '_', 'access', '_', 'token', '"', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['access', '_', 'token', '=', 'os', '.', 'get', '##en', '##v', '(', '"', 'twitter', '_', 'access', '_', 'token', '"', ')', '\\', 'n']
Detokenized (009): ['access_token', '=', 'os', '.', 'get##en##v', '(', '"twitter_access_token"', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "num = len ( tweets ) ) ) \n"
Original    (009): ['num', '=', 'len', '(', 'tweets', ')', ')', ')', '\\n']
Tokenized   (015): ['[CLS]', 'nu', '##m', '=', 'len', '(', 't', '##wee', '##ts', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['nu', '##m', '=', 'len', '(', 't', '##wee', '##ts', ')', ')', ')', '\\', 'n']
Detokenized (009): ['nu##m', '=', 'len', '(', 't##wee##ts', ')', ')', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "list_of_groups = [ tweets [ i : i + group_size ] for i in range ( 0 , len ( tweets ) , group_size ) ] \n"
Original    (027): ['list_of_groups', '=', '[', 'tweets', '[', 'i', ':', 'i', '+', 'group_size', ']', 'for', 'i', 'in', 'range', '(', '0', ',', 'len', '(', 'tweets', ')', ',', 'group_size', ')', ']', '\\n']
Tokenized   (042): ['[CLS]', 'list', '_', 'of', '_', 'groups', '=', '[', 't', '##wee', '##ts', '[', 'i', ':', 'i', '+', 'group', '_', 'size', ']', 'for', 'i', 'in', 'range', '(', '0', ',', 'len', '(', 't', '##wee', '##ts', ')', ',', 'group', '_', 'size', ')', ']', '\\', 'n', '[SEP]']
Filtered   (040): ['list', '_', 'of', '_', 'groups', '=', '[', 't', '##wee', '##ts', '[', 'i', ':', 'i', '+', 'group', '_', 'size', ']', 'for', 'i', 'in', 'range', '(', '0', ',', 'len', '(', 't', '##wee', '##ts', ')', ',', 'group', '_', 'size', ')', ']', '\\', 'n']
Detokenized (027): ['list_of_groups', '=', '[', 't##wee##ts', '[', 'i', ':', 'i', '+', 'group_size', ']', 'for', 'i', 'in', 'range', '(', '0', ',', 'len', '(', 't##wee##ts', ')', ',', 'group_size', ')', ']', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "handle_all_tweets ( response . data , tweet_subset ) \n"
Original    (009): ['handle_all_tweets', '(', 'response', '.', 'data', ',', 'tweet_subset', ')', '\\n']
Tokenized   (022): ['[CLS]', 'handle', '_', 'all', '_', 't', '##wee', '##ts', '(', 'response', '.', 'data', ',', 't', '##wee', '##t', '_', 'subset', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['handle', '_', 'all', '_', 't', '##wee', '##ts', '(', 'response', '.', 'data', ',', 't', '##wee', '##t', '_', 'subset', ')', '\\', 'n']
Detokenized (009): ['handle_all_t##wee##ts', '(', 'response', '.', 'data', ',', 't##wee##t_subset', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "tweets = Tweet . query . filter ( Tweet . profile_id == profile_id ) \n"
Original    (015): ['tweets', '=', 'Tweet', '.', 'query', '.', 'filter', '(', 'Tweet', '.', 'profile_id', '==', 'profile_id', ')', '\\n']
Tokenized   (029): ['[CLS]', 't', '##wee', '##ts', '=', 't', '##wee', '##t', '.', 'query', '.', 'filter', '(', 't', '##wee', '##t', '.', 'profile', '_', 'id', '=', '=', 'profile', '_', 'id', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['t', '##wee', '##ts', '=', 't', '##wee', '##t', '.', 'query', '.', 'filter', '(', 't', '##wee', '##t', '.', 'profile', '_', 'id', '=', '=', 'profile', '_', 'id', ')', '\\', 'n']
Detokenized (015): ['t##wee##ts', '=', 't##wee##t', '.', 'query', '.', 'filter', '(', 't##wee##t', '.', 'profile_id', '==', 'profile_id', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tweet_dict = dict ( [ ( ( tweet . tweet_id , tweet . tiid ) , tweet ) for tweet in tweets ] ) \n"
Original    (025): ['tweet_dict', '=', 'dict', '(', '[', '(', '(', 'tweet', '.', 'tweet_id', ',', 'tweet', '.', 'tiid', ')', ',', 'tweet', ')', 'for', 'tweet', 'in', 'tweets', ']', ')', '\\n']
Tokenized   (049): ['[CLS]', 't', '##wee', '##t', '_', 'di', '##ct', '=', 'di', '##ct', '(', '[', '(', '(', 't', '##wee', '##t', '.', 't', '##wee', '##t', '_', 'id', ',', 't', '##wee', '##t', '.', 'ti', '##id', ')', ',', 't', '##wee', '##t', ')', 'for', 't', '##wee', '##t', 'in', 't', '##wee', '##ts', ']', ')', '\\', 'n', '[SEP]']
Filtered   (047): ['t', '##wee', '##t', '_', 'di', '##ct', '=', 'di', '##ct', '(', '[', '(', '(', 't', '##wee', '##t', '.', 't', '##wee', '##t', '_', 'id', ',', 't', '##wee', '##t', '.', 'ti', '##id', ')', ',', 't', '##wee', '##t', ')', 'for', 't', '##wee', '##t', 'in', 't', '##wee', '##ts', ']', ')', '\\', 'n']
Detokenized (025): ['t##wee##t_di##ct', '=', 'di##ct', '(', '[', '(', '(', 't##wee##t', '.', 't##wee##t_id', ',', 't##wee##t', '.', 'ti##id', ')', ',', 't##wee##t', ')', 'for', 't##wee##t', 'in', 't##wee##ts', ']', ')', '\\n']
Counter: 47
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "tweet . profile_id = profile_id \n"
Original    (006): ['tweet', '.', 'profile_id', '=', 'profile_id', '\\n']
Tokenized   (015): ['[CLS]', 't', '##wee', '##t', '.', 'profile', '_', 'id', '=', 'profile', '_', 'id', '\\', 'n', '[SEP]']
Filtered   (013): ['t', '##wee', '##t', '.', 'profile', '_', 'id', '=', 'profile', '_', 'id', '\\', 'n']
Detokenized (006): ['t##wee##t', '.', 'profile_id', '=', 'profile_id', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tweet_ids = [ tweet . tweet_id for tweet in tweets_to_hydrate_from_twitter ] \n"
Original    (012): ['tweet_ids', '=', '[', 'tweet', '.', 'tweet_id', 'for', 'tweet', 'in', 'tweets_to_hydrate_from_twitter', ']', '\\n']
Tokenized   (039): ['[CLS]', 't', '##wee', '##t', '_', 'id', '##s', '=', '[', 't', '##wee', '##t', '.', 't', '##wee', '##t', '_', 'id', 'for', 't', '##wee', '##t', 'in', 't', '##wee', '##ts', '_', 'to', '_', 'hydra', '##te', '_', 'from', '_', 'twitter', ']', '\\', 'n', '[SEP]']
Filtered   (037): ['t', '##wee', '##t', '_', 'id', '##s', '=', '[', 't', '##wee', '##t', '.', 't', '##wee', '##t', '_', 'id', 'for', 't', '##wee', '##t', 'in', 't', '##wee', '##ts', '_', 'to', '_', 'hydra', '##te', '_', 'from', '_', 'twitter', ']', '\\', 'n']
Detokenized (012): ['t##wee##t_id##s', '=', '[', 't##wee##t', '.', 't##wee##t_id', 'for', 't##wee##t', 'in', 't##wee##ts_to_hydra##te_from_twitter', ']', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "display_url = url_info [ "display_url" ] \n"
Original    (007): ['display_url', '=', 'url_info', '[', '"display_url"', ']', '\\n']
Tokenized   (021): ['[CLS]', 'display', '_', 'ur', '##l', '=', 'ur', '##l', '_', 'info', '[', '"', 'display', '_', 'ur', '##l', '"', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['display', '_', 'ur', '##l', '=', 'ur', '##l', '_', 'info', '[', '"', 'display', '_', 'ur', '##l', '"', ']', '\\', 'n']
Detokenized (007): ['display_ur##l', '=', 'ur##l_info', '[', '"display_ur##l"', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "tweet_id = self . tweet_id , \n"
Original    (007): ['tweet_id', '=', 'self', '.', 'tweet_id', ',', '\\n']
Tokenized   (018): ['[CLS]', 't', '##wee', '##t', '_', 'id', '=', 'self', '.', 't', '##wee', '##t', '_', 'id', ',', '\\', 'n', '[SEP]']
Filtered   (016): ['t', '##wee', '##t', '_', 'id', '=', 'self', '.', 't', '##wee', '##t', '_', 'id', ',', '\\', 'n']
Detokenized (007): ['t##wee##t_id', '=', 'self', '.', 't##wee##t_id', ',', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "file_loc = os . path . dirname ( os . path . realpath ( __file__ ) ) \n"
Original    (018): ['file_loc', '=', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'realpath', '(', '__file__', ')', ')', '\\n']
Tokenized   (030): ['[CLS]', 'file', '_', 'lo', '##c', '=', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'real', '##path', '(', '_', '_', 'file', '_', '_', ')', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['file', '_', 'lo', '##c', '=', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'real', '##path', '(', '_', '_', 'file', '_', '_', ')', ')', '\\', 'n']
Detokenized (018): ['file_lo##c', '=', 'os', '.', 'path', '.', 'dir##name', '(', 'os', '.', 'path', '.', 'real##path', '(', '__file__', ')', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "urllib . urlretrieve ( url + fname , fname ) \n"
Original    (011): ['urllib', '.', 'urlretrieve', '(', 'url', '+', 'fname', ',', 'fname', ')', '\\n']
Tokenized   (023): ['[CLS]', 'ur', '##lli', '##b', '.', 'ur', '##lr', '##et', '##rie', '##ve', '(', 'ur', '##l', '+', 'f', '##name', ',', 'f', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['ur', '##lli', '##b', '.', 'ur', '##lr', '##et', '##rie', '##ve', '(', 'ur', '##l', '+', 'f', '##name', ',', 'f', '##name', ')', '\\', 'n']
Detokenized (011): ['ur##lli##b', '.', 'ur##lr##et##rie##ve', '(', 'ur##l', '+', 'f##name', ',', 'f##name', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) \n"
Original    (019): ['loaded', '=', 'np', '.', 'fromstring', '(', 'fd', '.', 'read', '(', ')', ',', 'dtype', '=', 'np', '.', 'uint8', ')', '\\n']
Tokenized   (028): ['[CLS]', 'loaded', '=', 'np', '.', 'from', '##st', '##ring', '(', 'f', '##d', '.', 'read', '(', ')', ',', 'dt', '##ype', '=', 'np', '.', 'ui', '##nt', '##8', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['loaded', '=', 'np', '.', 'from', '##st', '##ring', '(', 'f', '##d', '.', 'read', '(', ')', ',', 'dt', '##ype', '=', 'np', '.', 'ui', '##nt', '##8', ')', '\\', 'n']
Detokenized (019): ['loaded', '=', 'np', '.', 'from##st##ring', '(', 'f##d', '.', 'read', '(', ')', ',', 'dt##ype', '=', 'np', '.', 'ui##nt##8', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "fd = gzip . open ( os . path . join ( data_dir , ) ) \n"
Original    (017): ['fd', '=', 'gzip', '.', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'data_dir', ',', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'f', '##d', '=', 'g', '##zi', '##p', '.', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'data', '_', 'dir', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['f', '##d', '=', 'g', '##zi', '##p', '.', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'data', '_', 'dir', ',', ')', ')', '\\', 'n']
Detokenized (017): ['f##d', '=', 'g##zi##p', '.', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'data_dir', ',', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "trY = loaded [ 8 : ] . reshape ( ( 60000 ) ) \n"
Original    (015): ['trY', '=', 'loaded', '[', '8', ':', ']', '.', 'reshape', '(', '(', '60000', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'try', '=', 'loaded', '[', '8', ':', ']', '.', 'res', '##ha', '##pe', '(', '(', '6000', '##0', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['try', '=', 'loaded', '[', '8', ':', ']', '.', 'res', '##ha', '##pe', '(', '(', '6000', '##0', ')', ')', '\\', 'n']
Detokenized (015): ['try', '=', 'loaded', '[', '8', ':', ']', '.', 'res##ha##pe', '(', '(', '6000##0', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "trX = trX . reshape ( - 1 , 28 , 28 ) \n"
Original    (014): ['trX', '=', 'trX', '.', 'reshape', '(', '-', '1', ',', '28', ',', '28', ')', '\\n']
Tokenized   (021): ['[CLS]', 'tr', '##x', '=', 'tr', '##x', '.', 'res', '##ha', '##pe', '(', '-', '1', ',', '28', ',', '28', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['tr', '##x', '=', 'tr', '##x', '.', 'res', '##ha', '##pe', '(', '-', '1', ',', '28', ',', '28', ')', '\\', 'n']
Detokenized (014): ['tr##x', '=', 'tr##x', '.', 'res##ha##pe', '(', '-', '1', ',', '28', ',', '28', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dirpath = os . path . join ( self . repo . path , "unused_directory" ) \n"
Original    (017): ['dirpath', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'repo', '.', 'path', ',', '"unused_directory"', ')', '\\n']
Tokenized   (026): ['[CLS]', 'dir', '##path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'rep', '##o', '.', 'path', ',', '"', 'unused', '_', 'directory', '"', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['dir', '##path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'rep', '##o', '.', 'path', ',', '"', 'unused', '_', 'directory', '"', ')', '\\', 'n']
Detokenized (017): ['dir##path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'rep##o', '.', 'path', ',', '"unused_directory"', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "subpath = os . path . join ( self . repo . path , "a" , "b" , "c" ) \n"
Original    (021): ['subpath', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'repo', '.', 'path', ',', '"a"', ',', '"b"', ',', '"c"', ')', '\\n']
Tokenized   (032): ['[CLS]', 'sub', '##path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'rep', '##o', '.', 'path', ',', '"', 'a', '"', ',', '"', 'b', '"', ',', '"', 'c', '"', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['sub', '##path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'rep', '##o', '.', 'path', ',', '"', 'a', '"', ',', '"', 'b', '"', ',', '"', 'c', '"', ')', '\\', 'n']
Detokenized (021): ['sub##path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'rep##o', '.', 'path', ',', '"a"', ',', '"b"', ',', '"c"', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "handle = self . profile . username , \n"
Original    (009): ['handle', '=', 'self', '.', 'profile', '.', 'username', ',', '\\n']
Tokenized   (013): ['[CLS]', 'handle', '=', 'self', '.', 'profile', '.', 'user', '##name', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['handle', '=', 'self', '.', 'profile', '.', 'user', '##name', ',', '\\', 'n']
Detokenized (009): ['handle', '=', 'self', '.', 'profile', '.', 'user##name', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "id_key = ) \n"
Original    (004): ['id_key', '=', ')', '\\n']
Tokenized   (009): ['[CLS]', 'id', '_', 'key', '=', ')', '\\', 'n', '[SEP]']
Filtered   (007): ['id', '_', 'key', '=', ')', '\\', 'n']
Detokenized (004): ['id_key', '=', ')', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "message_thread = model . MessageThread ( okc_id = self . thread . id , \n"
Original    (015): ['message_thread', '=', 'model', '.', 'MessageThread', '(', 'okc_id', '=', 'self', '.', 'thread', '.', 'id', ',', '\\n']
Tokenized   (026): ['[CLS]', 'message', '_', 'thread', '=', 'model', '.', 'message', '##th', '##rea', '##d', '(', 'ok', '##c', '_', 'id', '=', 'self', '.', 'thread', '.', 'id', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['message', '_', 'thread', '=', 'model', '.', 'message', '##th', '##rea', '##d', '(', 'ok', '##c', '_', 'id', '=', 'self', '.', 'thread', '.', 'id', ',', '\\', 'n']
Detokenized (015): ['message_thread', '=', 'model', '.', 'message##th##rea##d', '(', 'ok##c_id', '=', 'self', '.', 'thread', '.', 'id', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "new_messages = [ message for message in self . thread . messages \n"
Original    (013): ['new_messages', '=', '[', 'message', 'for', 'message', 'in', 'self', '.', 'thread', '.', 'messages', '\\n']
Tokenized   (018): ['[CLS]', 'new', '_', 'messages', '=', '[', 'message', 'for', 'message', 'in', 'self', '.', 'thread', '.', 'messages', '\\', 'n', '[SEP]']
Filtered   (016): ['new', '_', 'messages', '=', '[', 'message', 'for', 'message', 'in', 'self', '.', 'thread', '.', 'messages', '\\', 'n']
Detokenized (013): ['new_messages', '=', '[', 'message', 'for', 'message', 'in', 'self', '.', 'thread', '.', 'messages', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "new_message_model = model . Message ( okc_id = new_message . id , \n"
Original    (013): ['new_message_model', '=', 'model', '.', 'Message', '(', 'okc_id', '=', 'new_message', '.', 'id', ',', '\\n']
Tokenized   (025): ['[CLS]', 'new', '_', 'message', '_', 'model', '=', 'model', '.', 'message', '(', 'ok', '##c', '_', 'id', '=', 'new', '_', 'message', '.', 'id', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['new', '_', 'message', '_', 'model', '=', 'model', '.', 'message', '(', 'ok', '##c', '_', 'id', '=', 'new', '_', 'message', '.', 'id', ',', '\\', 'n']
Detokenized (013): ['new_message_model', '=', 'model', '.', 'message', '(', 'ok##c_id', '=', 'new_message', '.', 'id', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "time_sent = new_message . time_sent ) \n"
Original    (007): ['time_sent', '=', 'new_message', '.', 'time_sent', ')', '\\n']
Tokenized   (016): ['[CLS]', 'time', '_', 'sent', '=', 'new', '_', 'message', '.', 'time', '_', 'sent', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['time', '_', 'sent', '=', 'new', '_', 'message', '.', 'time', '_', 'sent', ')', '\\', 'n']
Detokenized (007): ['time_sent', '=', 'new_message', '.', 'time_sent', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "mailbox . Sync ( user ) . all ( ) \n"
Original    (011): ['mailbox', '.', 'Sync', '(', 'user', ')', '.', 'all', '(', ')', '\\n']
Tokenized   (015): ['[CLS]', 'mail', '##box', '.', 'sync', '(', 'user', ')', '.', 'all', '(', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['mail', '##box', '.', 'sync', '(', 'user', ')', '.', 'all', '(', ')', '\\', 'n']
Detokenized (011): ['mail##box', '.', 'sync', '(', 'user', ')', '.', 'all', '(', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "user_model . upsert_model ( id_key = ) \n"
Original    (008): ['user_model', '.', 'upsert_model', '(', 'id_key', '=', ')', '\\n']
Tokenized   (018): ['[CLS]', 'user', '_', 'model', '.', 'ups', '##ert', '_', 'model', '(', 'id', '_', 'key', '=', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['user', '_', 'model', '.', 'ups', '##ert', '_', 'model', '(', 'id', '_', 'key', '=', ')', '\\', 'n']
Detokenized (008): ['user_model', '.', 'ups##ert_model', '(', 'id_key', '=', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "response_dict = user . photo . upload_and_confirm ( user . quickmatch ( ) . photo_infos [ 0 ] ) \n"
Original    (020): ['response_dict', '=', 'user', '.', 'photo', '.', 'upload_and_confirm', '(', 'user', '.', 'quickmatch', '(', ')', '.', 'photo_infos', '[', '0', ']', ')', '\\n']
Tokenized   (036): ['[CLS]', 'response', '_', 'di', '##ct', '=', 'user', '.', 'photo', '.', 'up', '##load', '_', 'and', '_', 'confirm', '(', 'user', '.', 'quick', '##mat', '##ch', '(', ')', '.', 'photo', '_', 'info', '##s', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['response', '_', 'di', '##ct', '=', 'user', '.', 'photo', '.', 'up', '##load', '_', 'and', '_', 'confirm', '(', 'user', '.', 'quick', '##mat', '##ch', '(', ')', '.', 'photo', '_', 'info', '##s', '[', '0', ']', ')', '\\', 'n']
Detokenized (020): ['response_di##ct', '=', 'user', '.', 'photo', '.', 'up##load_and_confirm', '(', 'user', '.', 'quick##mat##ch', '(', ')', '.', 'photo_info##s', '[', '0', ']', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "vcr_live_sleep ( 2 ) \n"
Original    (005): ['vcr_live_sleep', '(', '2', ')', '\\n']
Tokenized   (013): ['[CLS]', 'vc', '##r', '_', 'live', '_', 'sleep', '(', '2', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['vc', '##r', '_', 'live', '_', 'sleep', '(', '2', ')', '\\', 'n']
Detokenized (005): ['vc##r_live_sleep', '(', '2', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "b2_h = shared_zeros ( ( self . hp . batch_size , n_h ) ) \n"
Original    (015): ['b2_h', '=', 'shared_zeros', '(', '(', 'self', '.', 'hp', '.', 'batch_size', ',', 'n_h', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'b', '##2', '_', 'h', '=', 'shared', '_', 'zero', '##s', '(', '(', 'self', '.', 'hp', '.', 'batch', '_', 'size', ',', 'n', '_', 'h', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['b', '##2', '_', 'h', '=', 'shared', '_', 'zero', '##s', '(', '(', 'self', '.', 'hp', '.', 'batch', '_', 'size', ',', 'n', '_', 'h', ')', ')', '\\', 'n']
Detokenized (015): ['b##2_h', '=', 'shared_zero##s', '(', '(', 'self', '.', 'hp', '.', 'batch_size', ',', 'n_h', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "W1 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * 1.5 ) \n"
Original    (019): ['W1', '=', 'shared_normal', '(', '(', 'n_h', ',', 'n_h', '*', 'gates', ')', ',', 'scale', '=', 'scale', '*', '1.5', ')', '\\n']
Tokenized   (031): ['[CLS]', 'w', '##1', '=', 'shared', '_', 'normal', '(', '(', 'n', '_', 'h', ',', 'n', '_', 'h', '*', 'gates', ')', ',', 'scale', '=', 'scale', '*', '1', '.', '5', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['w', '##1', '=', 'shared', '_', 'normal', '(', '(', 'n', '_', 'h', ',', 'n', '_', 'h', '*', 'gates', ')', ',', 'scale', '=', 'scale', '*', '1', '.', '5', ')', '\\', 'n']
Detokenized (019): ['w##1', '=', 'shared_normal', '(', '(', 'n_h', ',', 'n_h', '*', 'gates', ')', ',', 'scale', '=', 'scale', '*', '1.5', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "b1 = shared_zeros ( ( n_h * gates ) ) \n"
Original    (011): ['b1', '=', 'shared_zeros', '(', '(', 'n_h', '*', 'gates', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'b1', '=', 'shared', '_', 'zero', '##s', '(', '(', 'n', '_', 'h', '*', 'gates', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['b1', '=', 'shared', '_', 'zero', '##s', '(', '(', 'n', '_', 'h', '*', 'gates', ')', ')', '\\', 'n']
Detokenized (011): ['b1', '=', 'shared_zero##s', '(', '(', 'n_h', '*', 'gates', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "b2 = shared_zeros ( ( n_h * gates , ) ) \n"
Original    (012): ['b2', '=', 'shared_zeros', '(', '(', 'n_h', '*', 'gates', ',', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'b', '##2', '=', 'shared', '_', 'zero', '##s', '(', '(', 'n', '_', 'h', '*', 'gates', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['b', '##2', '=', 'shared', '_', 'zero', '##s', '(', '(', 'n', '_', 'h', '*', 'gates', ',', ')', ')', '\\', 'n']
Detokenized (012): ['b##2', '=', 'shared_zero##s', '(', '(', 'n_h', '*', 'gates', ',', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "i_on = T . nnet . sigmoid ( g_on [ : , : n_h ] ) \n"
Original    (017): ['i_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', ':', 'n_h', ']', ')', '\\n']
Tokenized   (029): ['[CLS]', 'i', '_', 'on', '=', 't', '.', 'n', '##net', '.', 'si', '##gm', '##oid', '(', 'g', '_', 'on', '[', ':', ',', ':', 'n', '_', 'h', ']', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['i', '_', 'on', '=', 't', '.', 'n', '##net', '.', 'si', '##gm', '##oid', '(', 'g', '_', 'on', '[', ':', ',', ':', 'n', '_', 'h', ']', ')', '\\', 'n']
Detokenized (017): ['i_on', '=', 't', '.', 'n##net', '.', 'si##gm##oid', '(', 'g_on', '[', ':', ',', ':', 'n_h', ']', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "f_on = T . nnet . sigmoid ( g_on [ : , n_h : 2 * n_h ] ) \n"
Original    (020): ['f_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Tokenized   (034): ['[CLS]', 'f', '_', 'on', '=', 't', '.', 'n', '##net', '.', 'si', '##gm', '##oid', '(', 'g', '_', 'on', '[', ':', ',', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['f', '_', 'on', '=', 't', '.', 'n', '##net', '.', 'si', '##gm', '##oid', '(', 'g', '_', 'on', '[', ':', ',', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '\\', 'n']
Detokenized (020): ['f_on', '=', 't', '.', 'n##net', '.', 'si##gm##oid', '(', 'g_on', '[', ':', ',', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "o_on = T . nnet . sigmoid ( g_on [ : , 2 * n_h : 3 * n_h ] ) \n"
Original    (022): ['o_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', '2', '*', 'n_h', ':', '3', '*', 'n_h', ']', ')', '\\n']
Tokenized   (036): ['[CLS]', 'o', '_', 'on', '=', 't', '.', 'n', '##net', '.', 'si', '##gm', '##oid', '(', 'g', '_', 'on', '[', ':', ',', '2', '*', 'n', '_', 'h', ':', '3', '*', 'n', '_', 'h', ']', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['o', '_', 'on', '=', 't', '.', 'n', '##net', '.', 'si', '##gm', '##oid', '(', 'g', '_', 'on', '[', ':', ',', '2', '*', 'n', '_', 'h', ':', '3', '*', 'n', '_', 'h', ']', ')', '\\', 'n']
Detokenized (022): ['o_on', '=', 't', '.', 'n##net', '.', 'si##gm##oid', '(', 'g_on', '[', ':', ',', '2', '*', 'n_h', ':', '3', '*', 'n_h', ']', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "h_t = T . tanh ( T . dot ( X , W [ : , 1 * n_h : 2 * n_h ] ) + T . dot ( h , U [ : , 1 * n_h : 2 * n_h ] ) + b [ 1 * n_h : 2 * n_h ] ) \n"
Original    (058): ['h_t', '=', 'T', '.', 'tanh', '(', 'T', '.', 'dot', '(', 'X', ',', 'W', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 'T', '.', 'dot', '(', 'h', ',', 'U', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 'b', '[', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Tokenized   (076): ['[CLS]', 'h', '_', 't', '=', 't', '.', 'tan', '##h', '(', 't', '.', 'dot', '(', 'x', ',', 'w', '[', ':', ',', '1', '*', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '+', 't', '.', 'dot', '(', 'h', ',', 'u', '[', ':', ',', '1', '*', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '+', 'b', '[', '1', '*', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '\\', 'n', '[SEP]']
Filtered   (074): ['h', '_', 't', '=', 't', '.', 'tan', '##h', '(', 't', '.', 'dot', '(', 'x', ',', 'w', '[', ':', ',', '1', '*', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '+', 't', '.', 'dot', '(', 'h', ',', 'u', '[', ':', ',', '1', '*', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '+', 'b', '[', '1', '*', 'n', '_', 'h', ':', '2', '*', 'n', '_', 'h', ']', ')', '\\', 'n']
Detokenized (058): ['h_t', '=', 't', '.', 'tan##h', '(', 't', '.', 'dot', '(', 'x', ',', 'w', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 't', '.', 'dot', '(', 'h', ',', 'u', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 'b', '[', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Counter: 74
===================================================================
Hidden states:  (13, 58, 768)
# Extracted words:  58
Sentence         : "te_cost , te_h_updates = model ( self . X , self . params , 0. ) \n"
Original    (017): ['te_cost', ',', 'te_h_updates', '=', 'model', '(', 'self', '.', 'X', ',', 'self', '.', 'params', ',', '0.', ')', '\\n']
Tokenized   (028): ['[CLS]', 'te', '_', 'cost', ',', 'te', '_', 'h', '_', 'updates', '=', 'model', '(', 'self', '.', 'x', ',', 'self', '.', 'para', '##ms', ',', '0', '.', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['te', '_', 'cost', ',', 'te', '_', 'h', '_', 'updates', '=', 'model', '(', 'self', '.', 'x', ',', 'self', '.', 'para', '##ms', ',', '0', '.', ')', '\\', 'n']
Detokenized (017): ['te_cost', ',', 'te_h_updates', '=', 'model', '(', 'self', '.', 'x', ',', 'self', '.', 'para##ms', ',', '0.', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "csvWriter = csv . writer ( sys . stdout , delimiter = separator , quotechar = quote , \n"
Original    (019): ['csvWriter', '=', 'csv', '.', 'writer', '(', 'sys', '.', 'stdout', ',', 'delimiter', '=', 'separator', ',', 'quotechar', '=', 'quote', ',', '\\n']
Tokenized   (034): ['[CLS]', 'cs', '##v', '##writer', '=', 'cs', '##v', '.', 'writer', '(', 'sy', '##s', '.', 'st', '##dou', '##t', ',', 'del', '##imi', '##ter', '=', 'sep', '##arat', '##or', ',', 'quote', '##cha', '##r', '=', 'quote', ',', '\\', 'n', '[SEP]']
Filtered   (032): ['cs', '##v', '##writer', '=', 'cs', '##v', '.', 'writer', '(', 'sy', '##s', '.', 'st', '##dou', '##t', ',', 'del', '##imi', '##ter', '=', 'sep', '##arat', '##or', ',', 'quote', '##cha', '##r', '=', 'quote', ',', '\\', 'n']
Detokenized (019): ['cs##v##writer', '=', 'cs##v', '.', 'writer', '(', 'sy##s', '.', 'st##dou##t', ',', 'del##imi##ter', '=', 'sep##arat##or', ',', 'quote##cha##r', '=', 'quote', ',', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "IColumnProvider_Methods = IPersist_Methods + [ "Initialize" , "GetColumnInfo" , "GetItemData" ] \n"
Original    (012): ['IColumnProvider_Methods', '=', 'IPersist_Methods', '+', '[', '"Initialize"', ',', '"GetColumnInfo"', ',', '"GetItemData"', ']', '\\n']
Tokenized   (040): ['[CLS]', 'ic', '##ol', '##um', '##np', '##rov', '##ider', '_', 'methods', '=', 'ip', '##ers', '##ist', '_', 'methods', '+', '[', '"', 'initial', '##ize', '"', ',', '"', 'get', '##col', '##um', '##nin', '##fo', '"', ',', '"', 'get', '##ite', '##md', '##ata', '"', ']', '\\', 'n', '[SEP]']
Filtered   (038): ['ic', '##ol', '##um', '##np', '##rov', '##ider', '_', 'methods', '=', 'ip', '##ers', '##ist', '_', 'methods', '+', '[', '"', 'initial', '##ize', '"', ',', '"', 'get', '##col', '##um', '##nin', '##fo', '"', ',', '"', 'get', '##ite', '##md', '##ata', '"', ']', '\\', 'n']
Detokenized (012): ['ic##ol##um##np##rov##ider_methods', '=', 'ip##ers##ist_methods', '+', '[', '"initial##ize"', ',', '"get##col##um##nin##fo"', ',', '"get##ite##md##ata"', ']', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "_com_interfaces_ = [ pythoncom . IID_IPersist , \n"
Original    (008): ['_com_interfaces_', '=', '[', 'pythoncom', '.', 'IID_IPersist', ',', '\\n']
Tokenized   (021): ['[CLS]', '_', 'com', '_', 'interfaces', '_', '=', '[', 'python', '##com', '.', 'ii', '##d', '_', 'ip', '##ers', '##ist', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['_', 'com', '_', 'interfaces', '_', '=', '[', 'python', '##com', '.', 'ii', '##d', '_', 'ip', '##ers', '##ist', ',', '\\', 'n']
Detokenized (008): ['_com_interfaces_', '=', '[', 'python##com', '.', 'ii##d_ip##ers##ist', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "20 , #cChars \n"
Original    (004): ['20', ',', '#cChars', '\\n']
Tokenized   (010): ['[CLS]', '20', ',', '#', 'cc', '##har', '##s', '\\', 'n', '[SEP]']
Filtered   (008): ['20', ',', '#', 'cc', '##har', '##s', '\\', 'n']
Detokenized (004): ['20', ',', '#cc##har##s', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "fmt_id == self . _reg_clsid_ \n"
Original    (006): ['fmt_id', '==', 'self', '.', '_reg_clsid_', '\\n']
Tokenized   (019): ['[CLS]', 'fm', '##t', '_', 'id', '=', '=', 'self', '.', '_', 'reg', '_', 'cl', '##si', '##d', '_', '\\', 'n', '[SEP]']
Filtered   (017): ['fm', '##t', '_', 'id', '=', '=', 'self', '.', '_', 'reg', '_', 'cl', '##si', '##d', '_', '\\', 'n']
Detokenized (006): ['fm##t_id', '==', 'self', '.', '_reg_cl##si##d_', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : ""Folder\\\\ShellEx\\\\ColumnHandlers\\\\" + str ( ColumnProvider . _reg_clsid_ ) ) \n"
Original    (010): ['"Folder\\\\\\\\ShellEx\\\\\\\\ColumnHandlers\\\\\\\\"', '+', 'str', '(', 'ColumnProvider', '.', '_reg_clsid_', ')', ')', '\\n']
Tokenized   (042): ['[CLS]', '"', 'folder', '\\', '\\', '\\', '\\', 'shell', '##ex', '\\', '\\', '\\', '\\', 'column', '##hand', '##lers', '\\', '\\', '\\', '\\', '"', '+', 'st', '##r', '(', 'column', '##pro', '##vid', '##er', '.', '_', 'reg', '_', 'cl', '##si', '##d', '_', ')', ')', '\\', 'n', '[SEP]']
Filtered   (040): ['"', 'folder', '\\', '\\', '\\', '\\', 'shell', '##ex', '\\', '\\', '\\', '\\', 'column', '##hand', '##lers', '\\', '\\', '\\', '\\', '"', '+', 'st', '##r', '(', 'column', '##pro', '##vid', '##er', '.', '_', 'reg', '_', 'cl', '##si', '##d', '_', ')', ')', '\\', 'n']
Detokenized (010): ['"folder\\\\\\\\shell##ex\\\\\\\\column##hand##lers\\\\\\\\"', '+', 'st##r', '(', 'column##pro##vid##er', '.', '_reg_cl##si##d_', ')', ')', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_winreg . SetValueEx ( key , None , 0 , _winreg . REG_SZ , ColumnProvider . _reg_desc_ ) \n"
Original    (019): ['_winreg', '.', 'SetValueEx', '(', 'key', ',', 'None', ',', '0', ',', '_winreg', '.', 'REG_SZ', ',', 'ColumnProvider', '.', '_reg_desc_', ')', '\\n']
Tokenized   (042): ['[CLS]', '_', 'win', '##re', '##g', '.', 'set', '##val', '##ue', '##ex', '(', 'key', ',', 'none', ',', '0', ',', '_', 'win', '##re', '##g', '.', 'reg', '_', 's', '##z', ',', 'column', '##pro', '##vid', '##er', '.', '_', 'reg', '_', 'des', '##c', '_', ')', '\\', 'n', '[SEP]']
Filtered   (040): ['_', 'win', '##re', '##g', '.', 'set', '##val', '##ue', '##ex', '(', 'key', ',', 'none', ',', '0', ',', '_', 'win', '##re', '##g', '.', 'reg', '_', 's', '##z', ',', 'column', '##pro', '##vid', '##er', '.', '_', 'reg', '_', 'des', '##c', '_', ')', '\\', 'n']
Detokenized (019): ['_win##re##g', '.', 'set##val##ue##ex', '(', 'key', ',', 'none', ',', '0', ',', '_win##re##g', '.', 'reg_s##z', ',', 'column##pro##vid##er', '.', '_reg_des##c_', ')', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "register . UseCommandLine ( ColumnProvider , \n"
Original    (007): ['register', '.', 'UseCommandLine', '(', 'ColumnProvider', ',', '\\n']
Tokenized   (017): ['[CLS]', 'register', '.', 'use', '##com', '##man', '##dl', '##ine', '(', 'column', '##pro', '##vid', '##er', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['register', '.', 'use', '##com', '##man', '##dl', '##ine', '(', 'column', '##pro', '##vid', '##er', ',', '\\', 'n']
Detokenized (007): ['register', '.', 'use##com##man##dl##ine', '(', 'column##pro##vid##er', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "aliases = MultipleValueField ( required = False ) \n"
Original    (009): ['aliases', '=', 'MultipleValueField', '(', 'required', '=', 'False', ')', '\\n']
Tokenized   (016): ['[CLS]', 'alias', '##es', '=', 'multiple', '##val', '##ue', '##field', '(', 'required', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['alias', '##es', '=', 'multiple', '##val', '##ue', '##field', '(', 'required', '=', 'false', ')', '\\', 'n']
Detokenized (009): ['alias##es', '=', 'multiple##val##ue##field', '(', 'required', '=', 'false', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "StoredQueryParameter = namedtuple ( "StoredQueryParameter" , ( , , , , \n"
Original    (012): ['StoredQueryParameter', '=', 'namedtuple', '(', '"StoredQueryParameter"', ',', '(', ',', ',', ',', ',', '\\n']
Tokenized   (027): ['[CLS]', 'stored', '##que', '##ry', '##para', '##meter', '=', 'named', '##tu', '##ple', '(', '"', 'stored', '##que', '##ry', '##para', '##meter', '"', ',', '(', ',', ',', ',', ',', '\\', 'n', '[SEP]']
Filtered   (025): ['stored', '##que', '##ry', '##para', '##meter', '=', 'named', '##tu', '##ple', '(', '"', 'stored', '##que', '##ry', '##para', '##meter', '"', ',', '(', ',', ',', ',', ',', '\\', 'n']
Detokenized (012): ['stored##que##ry##para##meter', '=', 'named##tu##ple', '(', '"stored##que##ry##para##meter"', ',', '(', ',', ',', ',', ',', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fts = list ( self . models . keys ( ) ) \n"
Original    (013): ['fts', '=', 'list', '(', 'self', '.', 'models', '.', 'keys', '(', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 'ft', '##s', '=', 'list', '(', 'self', '.', 'models', '.', 'keys', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['ft', '##s', '=', 'list', '(', 'self', '.', 'models', '.', 'keys', '(', ')', ')', '\\', 'n']
Detokenized (013): ['ft##s', '=', 'list', '(', 'self', '.', 'models', '.', 'keys', '(', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sort_by = parms . cleaned_data [ ] \n"
Original    (008): ['sort_by', '=', 'parms', '.', 'cleaned_data', '[', ']', '\\n']
Tokenized   (016): ['[CLS]', 'sort', '_', 'by', '=', 'par', '##ms', '.', 'cleaned', '_', 'data', '[', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['sort', '_', 'by', '=', 'par', '##ms', '.', 'cleaned', '_', 'data', '[', ']', '\\', 'n']
Detokenized (008): ['sort_by', '=', 'par##ms', '.', 'cleaned_data', '[', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "geometry_field = self . geometries [ type_names [ 0 ] ] \n"
Original    (012): ['geometry_field', '=', 'self', '.', 'geometries', '[', 'type_names', '[', '0', ']', ']', '\\n']
Tokenized   (021): ['[CLS]', 'geometry', '_', 'field', '=', 'self', '.', 'geo', '##met', '##ries', '[', 'type', '_', 'names', '[', '0', ']', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['geometry', '_', 'field', '=', 'self', '.', 'geo', '##met', '##ries', '[', 'type', '_', 'names', '[', '0', ']', ']', '\\', 'n']
Detokenized (012): ['geometry_field', '=', 'self', '.', 'geo##met##ries', '[', 'type_names', '[', '0', ']', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mxy = mxy ) \n"
Original    (005): ['mxy', '=', 'mxy', ')', '\\n']
Tokenized   (010): ['[CLS]', 'mx', '##y', '=', 'mx', '##y', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['mx', '##y', '=', 'mx', '##y', ')', '\\', 'n']
Detokenized (005): ['mx##y', '=', 'mx##y', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "query_set = query_set . order_by ( * sort_by ) \n"
Original    (010): ['query_set', '=', 'query_set', '.', 'order_by', '(', '*', 'sort_by', ')', '\\n']
Tokenized   (021): ['[CLS]', 'query', '_', 'set', '=', 'query', '_', 'set', '.', 'order', '_', 'by', '(', '*', 'sort', '_', 'by', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['query', '_', 'set', '=', 'query', '_', 'set', '.', 'order', '_', 'by', '(', '*', 'sort', '_', 'by', ')', '\\', 'n']
Detokenized (010): ['query_set', '=', 'query_set', '.', 'order_by', '(', '*', 'sort_by', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "output_format = root . get ( , ) \n"
Original    (009): ['output_format', '=', 'root', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (014): ['[CLS]', 'output', '_', 'format', '=', 'root', '.', 'get', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['output', '_', 'format', '=', 'root', '.', 'get', '(', ',', ')', '\\', 'n']
Detokenized (009): ['output_format', '=', 'root', '.', 'get', '(', ',', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "type_names . append ( ( namespace , name ) ) \n"
Original    (011): ['type_names', '.', 'append', '(', '(', 'namespace', ',', 'name', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'type', '_', 'names', '.', 'app', '##end', '(', '(', 'names', '##pace', ',', 'name', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['type', '_', 'names', '.', 'app', '##end', '(', '(', 'names', '##pace', ',', 'name', ')', ')', '\\', 'n']
Detokenized (011): ['type_names', '.', 'app##end', '(', '(', 'names##pace', ',', 'name', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""schema" : feature_type . schema , \n"
Original    (007): ['"schema"', ':', 'feature_type', '.', 'schema', ',', '\\n']
Tokenized   (016): ['[CLS]', '"', 'sc', '##hema', '"', ':', 'feature', '_', 'type', '.', 'sc', '##hema', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['"', 'sc', '##hema', '"', ':', 'feature', '_', 'type', '.', 'sc', '##hema', ',', '\\', 'n']
Detokenized (007): ['"sc##hema"', ':', 'feature_type', '.', 'sc##hema', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""ns_name" : feature_type . ns_name \n"
Original    (006): ['"ns_name"', ':', 'feature_type', '.', 'ns_name', '\\n']
Tokenized   (017): ['[CLS]', '"', 'ns', '_', 'name', '"', ':', 'feature', '_', 'type', '.', 'ns', '_', 'name', '\\', 'n', '[SEP]']
Filtered   (015): ['"', 'ns', '_', 'name', '"', ':', 'feature', '_', 'type', '.', 'ns', '_', 'name', '\\', 'n']
Detokenized (006): ['"ns_name"', ':', 'feature_type', '.', 'ns_name', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "db_params = settings . DATABASES [ response . db ] \n"
Original    (011): ['db_params', '=', 'settings', '.', 'DATABASES', '[', 'response', '.', 'db', ']', '\\n']
Tokenized   (017): ['[CLS]', 'db', '_', 'para', '##ms', '=', 'settings', '.', 'databases', '[', 'response', '.', 'db', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['db', '_', 'para', '##ms', '=', 'settings', '.', 'databases', '[', 'response', '.', 'db', ']', '\\', 'n']
Detokenized (011): ['db_para##ms', '=', 'settings', '.', 'databases', '[', 'response', '.', 'db', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "parameters = tuple ( [ adapt ( p ) for p in parameters ] ) \n"
Original    (016): ['parameters', '=', 'tuple', '(', '[', 'adapt', '(', 'p', ')', 'for', 'p', 'in', 'parameters', ']', ')', '\\n']
Tokenized   (020): ['[CLS]', 'parameters', '=', 'tu', '##ple', '(', '[', 'adapt', '(', 'p', ')', 'for', 'p', 'in', 'parameters', ']', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['parameters', '=', 'tu', '##ple', '(', '[', 'adapt', '(', 'p', ')', 'for', 'p', 'in', 'parameters', ']', ')', '\\', 'n']
Detokenized (016): ['parameters', '=', 'tu##ple', '(', '[', 'adapt', '(', 'p', ')', 'for', 'p', 'in', 'parameters', ']', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "connection_string = "PG:dbname=\'{db}\'" . format ( db = db_params [ ] ) \n"
Original    (013): ['connection_string', '=', '"PG:dbname=\\\'{db}\\\'"', '.', 'format', '(', 'db', '=', 'db_params', '[', ']', ')', '\\n']
Tokenized   (034): ['[CLS]', 'connection', '_', 'string', '=', '"', 'pg', ':', 'db', '##name', '=', '\\', "'", '{', 'db', '}', '\\', "'", '"', '.', 'format', '(', 'db', '=', 'db', '_', 'para', '##ms', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['connection', '_', 'string', '=', '"', 'pg', ':', 'db', '##name', '=', '\\', "'", '{', 'db', '}', '\\', "'", '"', '.', 'format', '(', 'db', '=', 'db', '_', 'para', '##ms', '[', ']', ')', '\\', 'n']
Detokenized (013): ['connection_string', '=', '"pg:db##name=\\\'{db}\\\'"', '.', 'format', '(', 'db', '=', 'db_para##ms', '[', ']', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "etree . SubElement ( p , ) . text = parameter . abstractS \n"
Original    (014): ['etree', '.', 'SubElement', '(', 'p', ',', ')', '.', 'text', '=', 'parameter', '.', 'abstractS', '\\n']
Tokenized   (020): ['[CLS]', 'et', '##ree', '.', 'sub', '##ele', '##ment', '(', 'p', ',', ')', '.', 'text', '=', 'parameter', '.', 'abstracts', '\\', 'n', '[SEP]']
Filtered   (018): ['et', '##ree', '.', 'sub', '##ele', '##ment', '(', 'p', ',', ')', '.', 'text', '=', 'parameter', '.', 'abstracts', '\\', 'n']
Detokenized (014): ['et##ree', '.', 'sub##ele##ment', '(', 'p', ',', ')', '.', 'text', '=', 'parameter', '.', 'abstracts', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""isPrivate" : parameter . query_expression . private == True , \n"
Original    (011): ['"isPrivate"', ':', 'parameter', '.', 'query_expression', '.', 'private', '==', 'True', ',', '\\n']
Tokenized   (021): ['[CLS]', '"', 'is', '##pr', '##ivate', '"', ':', 'parameter', '.', 'query', '_', 'expression', '.', 'private', '=', '=', 'true', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['"', 'is', '##pr', '##ivate', '"', ':', 'parameter', '.', 'query', '_', 'expression', '.', 'private', '=', '=', 'true', ',', '\\', 'n']
Detokenized (011): ['"is##pr##ivate"', ':', 'parameter', '.', 'query_expression', '.', 'private', '==', 'true', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""language" : parameter . query_expression . language , \n"
Original    (009): ['"language"', ':', 'parameter', '.', 'query_expression', '.', 'language', ',', '\\n']
Tokenized   (016): ['[CLS]', '"', 'language', '"', ':', 'parameter', '.', 'query', '_', 'expression', '.', 'language', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['"', 'language', '"', ':', 'parameter', '.', 'query', '_', 'expression', '.', 'language', ',', '\\', 'n']
Detokenized (009): ['"language"', ':', 'parameter', '.', 'query_expression', '.', 'language', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""returnFeatureTypes" : . join ( parameter . query_expression . return_feature_types } ) . text = parameter . query_expression . text \n"
Original    (021): ['"returnFeatureTypes"', ':', '.', 'join', '(', 'parameter', '.', 'query_expression', '.', 'return_feature_types', '}', ')', '.', 'text', '=', 'parameter', '.', 'query_expression', '.', 'text', '\\n']
Tokenized   (039): ['[CLS]', '"', 'return', '##fe', '##at', '##ure', '##type', '##s', '"', ':', '.', 'join', '(', 'parameter', '.', 'query', '_', 'expression', '.', 'return', '_', 'feature', '_', 'types', '}', ')', '.', 'text', '=', 'parameter', '.', 'query', '_', 'expression', '.', 'text', '\\', 'n', '[SEP]']
Filtered   (037): ['"', 'return', '##fe', '##at', '##ure', '##type', '##s', '"', ':', '.', 'join', '(', 'parameter', '.', 'query', '_', 'expression', '.', 'return', '_', 'feature', '_', 'types', '}', ')', '.', 'text', '=', 'parameter', '.', 'query', '_', 'expression', '.', 'text', '\\', 'n']
Detokenized (021): ['"return##fe##at##ure##type##s"', ':', '.', 'join', '(', 'parameter', '.', 'query_expression', '.', 'return_feature_types', '}', ')', '.', 'text', '=', 'parameter', '.', 'query_expression', '.', 'text', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : ""endpoint" : request . build_absolute_uri ( ) . split ( ) [ 0 ] , \n"
Original    (016): ['"endpoint"', ':', 'request', '.', 'build_absolute_uri', '(', ')', '.', 'split', '(', ')', '[', '0', ']', ',', '\\n']
Tokenized   (027): ['[CLS]', '"', 'end', '##point', '"', ':', 'request', '.', 'build', '_', 'absolute', '_', 'ur', '##i', '(', ')', '.', 'split', '(', ')', '[', '0', ']', ',', '\\', 'n', '[SEP]']
Filtered   (025): ['"', 'end', '##point', '"', ':', 'request', '.', 'build', '_', 'absolute', '_', 'ur', '##i', '(', ')', '.', 'split', '(', ')', '[', '0', ']', ',', '\\', 'n']
Detokenized (016): ['"end##point"', ':', 'request', '.', 'build_absolute_ur##i', '(', ')', '.', 'split', '(', ')', '[', '0', ']', ',', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""output_formats" : [ ogr . GetDriver ( drv ) . GetName ( ) for drv in range ( ogr . GetDriverCount ( ) ) "addr_street" : self . addr_street , \n"
Original    (031): ['"output_formats"', ':', '[', 'ogr', '.', 'GetDriver', '(', 'drv', ')', '.', 'GetName', '(', ')', 'for', 'drv', 'in', 'range', '(', 'ogr', '.', 'GetDriverCount', '(', ')', ')', '"addr_street"', ':', 'self', '.', 'addr_street', ',', '\\n']
Tokenized   (056): ['[CLS]', '"', 'output', '_', 'formats', '"', ':', '[', 'og', '##r', '.', 'get', '##drive', '##r', '(', 'dr', '##v', ')', '.', 'get', '##name', '(', ')', 'for', 'dr', '##v', 'in', 'range', '(', 'og', '##r', '.', 'get', '##drive', '##rco', '##unt', '(', ')', ')', '"', 'add', '##r', '_', 'street', '"', ':', 'self', '.', 'add', '##r', '_', 'street', ',', '\\', 'n', '[SEP]']
Filtered   (054): ['"', 'output', '_', 'formats', '"', ':', '[', 'og', '##r', '.', 'get', '##drive', '##r', '(', 'dr', '##v', ')', '.', 'get', '##name', '(', ')', 'for', 'dr', '##v', 'in', 'range', '(', 'og', '##r', '.', 'get', '##drive', '##rco', '##unt', '(', ')', ')', '"', 'add', '##r', '_', 'street', '"', ':', 'self', '.', 'add', '##r', '_', 'street', ',', '\\', 'n']
Detokenized (031): ['"output_formats"', ':', '[', 'og##r', '.', 'get##drive##r', '(', 'dr##v', ')', '.', 'get##name', '(', ')', 'for', 'dr##v', 'in', 'range', '(', 'og##r', '.', 'get##drive##rco##unt', '(', ')', ')', '"add##r_street"', ':', 'self', '.', 'add##r_street', ',', '\\n']
Counter: 54
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : ""feature_versioning" : self . adapter . supports_feature_versioning ( ) , \n"
Original    (011): ['"feature_versioning"', ':', 'self', '.', 'adapter', '.', 'supports_feature_versioning', '(', ')', ',', '\\n']
Tokenized   (025): ['[CLS]', '"', 'feature', '_', 'version', '##ing', '"', ':', 'self', '.', 'adapt', '##er', '.', 'supports', '_', 'feature', '_', 'version', '##ing', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['"', 'feature', '_', 'version', '##ing', '"', ':', 'self', '.', 'adapt', '##er', '.', 'supports', '_', 'feature', '_', 'version', '##ing', '(', ')', ',', '\\', 'n']
Detokenized (011): ['"feature_version##ing"', ':', 'self', '.', 'adapt##er', '.', 'supports_feature_version##ing', '(', ')', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""date" : datetime . now ( ) , \n"
Original    (009): ['"date"', ':', 'datetime', '.', 'now', '(', ')', ',', '\\n']
Tokenized   (015): ['[CLS]', '"', 'date', '"', ':', 'date', '##time', '.', 'now', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['"', 'date', '"', ':', 'date', '##time', '.', 'now', '(', ')', ',', '\\', 'n']
Detokenized (009): ['"date"', ':', 'date##time', '.', 'now', '(', ')', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "matchItem . setText ( 3 , unicode ( self . data [ "Matches" ] ) ) \n"
Original    (017): ['matchItem', '.', 'setText', '(', '3', ',', 'unicode', '(', 'self', '.', 'data', '[', '"Matches"', ']', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'match', '##ite', '##m', '.', 'set', '##text', '(', '3', ',', 'unicode', '(', 'self', '.', 'data', '[', '"', 'matches', '"', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['match', '##ite', '##m', '.', 'set', '##text', '(', '3', ',', 'unicode', '(', 'self', '.', 'data', '[', '"', 'matches', '"', ']', ')', ')', '\\', 'n']
Detokenized (017): ['match##ite##m', '.', 'set##text', '(', '3', ',', 'unicode', '(', 'self', '.', 'data', '[', '"matches"', ']', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "roundItem . setText ( 3 , unicode ( opponent [ 2 ] ) ) \n"
Original    (015): ['roundItem', '.', 'setText', '(', '3', ',', 'unicode', '(', 'opponent', '[', '2', ']', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'round', '##ite', '##m', '.', 'set', '##text', '(', '3', ',', 'unicode', '(', 'opponent', '[', '2', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['round', '##ite', '##m', '.', 'set', '##text', '(', '3', ',', 'unicode', '(', 'opponent', '[', '2', ']', ')', ')', '\\', 'n']
Detokenized (015): ['round##ite##m', '.', 'set##text', '(', '3', ',', 'unicode', '(', 'opponent', '[', '2', ']', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "opponent [ 3 ] = roundItem \n"
Original    (007): ['opponent', '[', '3', ']', '=', 'roundItem', '\\n']
Tokenized   (012): ['[CLS]', 'opponent', '[', '3', ']', '=', 'round', '##ite', '##m', '\\', 'n', '[SEP]']
Filtered   (010): ['opponent', '[', '3', ']', '=', 'round', '##ite', '##m', '\\', 'n']
Detokenized (007): ['opponent', '[', '3', ']', '=', 'round##ite##m', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "M = np . matrix ( [ [ 2 , 3 , 4 ] , \n"
Original    (016): ['M', '=', 'np', '.', 'matrix', '(', '[', '[', '2', ',', '3', ',', '4', ']', ',', '\\n']
Tokenized   (019): ['[CLS]', 'm', '=', 'np', '.', 'matrix', '(', '[', '[', '2', ',', '3', ',', '4', ']', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['m', '=', 'np', '.', 'matrix', '(', '[', '[', '2', ',', '3', ',', '4', ']', ',', '\\', 'n']
Detokenized (016): ['m', '=', 'np', '.', 'matrix', '(', '[', '[', '2', ',', '3', ',', '4', ']', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "matrix = Matrix ( M , mtype = ) \n"
Original    (010): ['matrix', '=', 'Matrix', '(', 'M', ',', 'mtype', '=', ')', '\\n']
Tokenized   (014): ['[CLS]', 'matrix', '=', 'matrix', '(', 'm', ',', 'mt', '##ype', '=', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['matrix', '=', 'matrix', '(', 'm', ',', 'mt', '##ype', '=', ')', '\\', 'n']
Detokenized (010): ['matrix', '=', 'matrix', '(', 'm', ',', 'mt##ype', '=', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "math = Math ( data = [ , vec_name , , Matrix ( M * a ) ] ) \n"
Original    (020): ['math', '=', 'Math', '(', 'data', '=', '[', ',', 'vec_name', ',', ',', 'Matrix', '(', 'M', '*', 'a', ')', ']', ')', '\\n']
Tokenized   (026): ['[CLS]', 'math', '=', 'math', '(', 'data', '=', '[', ',', 've', '##c', '_', 'name', ',', ',', 'matrix', '(', 'm', '*', 'a', ')', ']', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['math', '=', 'math', '(', 'data', '=', '[', ',', 've', '##c', '_', 'name', ',', ',', 'matrix', '(', 'm', '*', 'a', ')', ']', ')', '\\', 'n']
Detokenized (020): ['math', '=', 'math', '(', 'data', '=', '[', ',', 've##c_name', ',', ',', 'matrix', '(', 'm', '*', 'a', ')', ']', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "q2 = Quantity ( v , format_cb = lambda x : str ( int ( x ) ) ) \n"
Original    (020): ['q2', '=', 'Quantity', '(', 'v', ',', 'format_cb', '=', 'lambda', 'x', ':', 'str', '(', 'int', '(', 'x', ')', ')', ')', '\\n']
Tokenized   (027): ['[CLS]', 'q', '##2', '=', 'quantity', '(', 'v', ',', 'format', '_', 'cb', '=', 'lambda', 'x', ':', 'st', '##r', '(', 'int', '(', 'x', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['q', '##2', '=', 'quantity', '(', 'v', ',', 'format', '_', 'cb', '=', 'lambda', 'x', ':', 'st', '##r', '(', 'int', '(', 'x', ')', ')', ')', '\\', 'n']
Detokenized (020): ['q##2', '=', 'quantity', '(', 'v', ',', 'format_cb', '=', 'lambda', 'x', ':', 'st##r', '(', 'int', '(', 'x', ')', ')', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "q3 = Quantity ( v , options = { : } ) \n"
Original    (013): ['q3', '=', 'Quantity', '(', 'v', ',', 'options', '=', '{', ':', '}', ')', '\\n']
Tokenized   (017): ['[CLS]', 'q', '##3', '=', 'quantity', '(', 'v', ',', 'options', '=', '{', ':', '}', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['q', '##3', '=', 'quantity', '(', 'v', ',', 'options', '=', '{', ':', '}', ')', '\\', 'n']
Detokenized (013): ['q##3', '=', 'quantity', '(', 'v', ',', 'options', '=', '{', ':', '}', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "test_dimensionality_to_siunitx ( ) \n"
Original    (004): ['test_dimensionality_to_siunitx', '(', ')', '\\n']
Tokenized   (017): ['[CLS]', 'test', '_', 'dimensional', '##ity', '_', 'to', '_', 'si', '##uni', '##t', '##x', '(', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['test', '_', 'dimensional', '##ity', '_', 'to', '_', 'si', '##uni', '##t', '##x', '(', ')', '\\', 'n']
Detokenized (004): ['test_dimensional##ity_to_si##uni##t##x', '(', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "ph = put_handler . put_handler ( fs , ) \n"
Original    (010): ['ph', '=', 'put_handler', '.', 'put_handler', '(', 'fs', ',', ')', '\\n']
Tokenized   (018): ['[CLS]', 'ph', '=', 'put', '_', 'handler', '.', 'put', '_', 'handler', '(', 'f', '##s', ',', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['ph', '=', 'put', '_', 'handler', '.', 'put', '_', 'handler', '(', 'f', '##s', ',', ')', '\\', 'n']
Detokenized (010): ['ph', '=', 'put_handler', '.', 'put_handler', '(', 'f##s', ',', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "hs = http_server . http_server ( ip = , port = 8080 ) \n"
Original    (014): ['hs', '=', 'http_server', '.', 'http_server', '(', 'ip', '=', ',', 'port', '=', '8080', ')', '\\n']
Tokenized   (022): ['[CLS]', 'hs', '=', 'http', '_', 'server', '.', 'http', '_', 'server', '(', 'ip', '=', ',', 'port', '=', '80', '##80', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['hs', '=', 'http', '_', 'server', '.', 'http', '_', 'server', '(', 'ip', '=', ',', 'port', '=', '80', '##80', ')', '\\', 'n']
Detokenized (014): ['hs', '=', 'http_server', '.', 'http_server', '(', 'ip', '=', ',', 'port', '=', '80##80', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "num_trans = num_requests * num_conns \n"
Original    (006): ['num_trans', '=', 'num_requests', '*', 'num_conns', '\\n']
Tokenized   (019): ['[CLS]', 'nu', '##m', '_', 'trans', '=', 'nu', '##m', '_', 'requests', '*', 'nu', '##m', '_', 'con', '##ns', '\\', 'n', '[SEP]']
Filtered   (017): ['nu', '##m', '_', 'trans', '=', 'nu', '##m', '_', 'requests', '*', 'nu', '##m', '_', 'con', '##ns', '\\', 'n']
Detokenized (006): ['nu##m_trans', '=', 'nu##m_requests', '*', 'nu##m_con##ns', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "trans_per_sec = num_trans / total_time \n"
Original    (006): ['trans_per_sec', '=', 'num_trans', '/', 'total_time', '\\n']
Tokenized   (018): ['[CLS]', 'trans', '_', 'per', '_', 'sec', '=', 'nu', '##m', '_', 'trans', '/', 'total', '_', 'time', '\\', 'n', '[SEP]']
Filtered   (016): ['trans', '_', 'per', '_', 'sec', '=', 'nu', '##m', '_', 'trans', '/', 'total', '_', 'time', '\\', 'n']
Detokenized (006): ['trans_per_sec', '=', 'nu##m_trans', '/', 'total_time', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "map ( str , ( num_conns , num_requests , request_size , throughput , trans_per_sec ) \n"
Original    (016): ['map', '(', 'str', ',', '(', 'num_conns', ',', 'num_requests', ',', 'request_size', ',', 'throughput', ',', 'trans_per_sec', ')', '\\n']
Tokenized   (034): ['[CLS]', 'map', '(', 'st', '##r', ',', '(', 'nu', '##m', '_', 'con', '##ns', ',', 'nu', '##m', '_', 'requests', ',', 'request', '_', 'size', ',', 'through', '##put', ',', 'trans', '_', 'per', '_', 'sec', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['map', '(', 'st', '##r', ',', '(', 'nu', '##m', '_', 'con', '##ns', ',', 'nu', '##m', '_', 'requests', ',', 'request', '_', 'size', ',', 'through', '##put', ',', 'trans', '_', 'per', '_', 'sec', ')', '\\', 'n']
Detokenized (016): ['map', '(', 'st##r', ',', '(', 'nu##m_con##ns', ',', 'nu##m_requests', ',', 'request_size', ',', 'through##put', ',', 'trans_per_sec', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "queue . add_task ( task , 3 ) \n"
Original    (009): ['queue', '.', 'add_task', '(', 'task', ',', '3', ')', '\\n']
Tokenized   (014): ['[CLS]', 'queue', '.', 'add', '_', 'task', '(', 'task', ',', '3', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['queue', '.', 'add', '_', 'task', '(', 'task', ',', '3', ')', '\\', 'n']
Detokenized (009): ['queue', '.', 'add_task', '(', 'task', ',', '3', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "futures . append ( queue . yield_task ( task , 3 ) ) \n"
Original    (014): ['futures', '.', 'append', '(', 'queue', '.', 'yield_task', '(', 'task', ',', '3', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'futures', '.', 'app', '##end', '(', 'queue', '.', 'yield', '_', 'task', '(', 'task', ',', '3', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['futures', '.', 'app', '##end', '(', 'queue', '.', 'yield', '_', 'task', '(', 'task', ',', '3', ')', ')', '\\', 'n']
Detokenized (014): ['futures', '.', 'app##end', '(', 'queue', '.', 'yield_task', '(', 'task', ',', '3', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "task_results [ : ] = res \n"
Original    (007): ['task_results', '[', ':', ']', '=', 'res', '\\n']
Tokenized   (012): ['[CLS]', 'task', '_', 'results', '[', ':', ']', '=', 'res', '\\', 'n', '[SEP]']
Filtered   (010): ['task', '_', 'results', '[', ':', ']', '=', 'res', '\\', 'n']
Detokenized (007): ['task_results', '[', ':', ']', '=', 'res', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "shuffle ( self . __queued_servers ) \n"
Original    (007): ['shuffle', '(', 'self', '.', '__queued_servers', ')', '\\n']
Tokenized   (015): ['[CLS]', 'shuffle', '(', 'self', '.', '_', '_', 'queue', '##d', '_', 'servers', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['shuffle', '(', 'self', '.', '_', '_', 'queue', '##d', '_', 'servers', ')', '\\', 'n']
Detokenized (007): ['shuffle', '(', 'self', '.', '__queue##d_servers', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "event_name = event [ ] \n"
Original    (006): ['event_name', '=', 'event', '[', ']', '\\n']
Tokenized   (011): ['[CLS]', 'event', '_', 'name', '=', 'event', '[', ']', '\\', 'n', '[SEP]']
Filtered   (009): ['event', '_', 'name', '=', 'event', '[', ']', '\\', 'n']
Detokenized (006): ['event_name', '=', 'event', '[', ']', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "event_data = zlib . compress ( pickle . dumps ( event ) ) \n"
Original    (014): ['event_data', '=', 'zlib', '.', 'compress', '(', 'pickle', '.', 'dumps', '(', 'event', ')', ')', '\\n']
Tokenized   (023): ['[CLS]', 'event', '_', 'data', '=', 'z', '##lib', '.', 'com', '##press', '(', 'pick', '##le', '.', 'dump', '##s', '(', 'event', ')', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['event', '_', 'data', '=', 'z', '##lib', '.', 'com', '##press', '(', 'pick', '##le', '.', 'dump', '##s', '(', 'event', ')', ')', '\\', 'n']
Detokenized (014): ['event_data', '=', 'z##lib', '.', 'com##press', '(', 'pick##le', '.', 'dump##s', '(', 'event', ')', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "path_only , query = self . _split_path ( path ) \n"
Original    (011): ['path_only', ',', 'query', '=', 'self', '.', '_split_path', '(', 'path', ')', '\\n']
Tokenized   (019): ['[CLS]', 'path', '_', 'only', ',', 'query', '=', 'self', '.', '_', 'split', '_', 'path', '(', 'path', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['path', '_', 'only', ',', 'query', '=', 'self', '.', '_', 'split', '_', 'path', '(', 'path', ')', '\\', 'n']
Detokenized (011): ['path_only', ',', 'query', '=', 'self', '.', '_split_path', '(', 'path', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "break ; \n"
Original    (003): ['break', ';', '\\n']
Tokenized   (006): ['[CLS]', 'break', ';', '\\', 'n', '[SEP]']
Filtered   (004): ['break', ';', '\\', 'n']
Detokenized (003): ['break', ';', '\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "u . email = user [ 2 ] \n"
Original    (009): ['u', '.', 'email', '=', 'user', '[', '2', ']', '\\n']
Tokenized   (012): ['[CLS]', 'u', '.', 'email', '=', 'user', '[', '2', ']', '\\', 'n', '[SEP]']
Filtered   (010): ['u', '.', 'email', '=', 'user', '[', '2', ']', '\\', 'n']
Detokenized (009): ['u', '.', 'email', '=', 'user', '[', '2', ']', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "trac_components = list ( [ ] ) \n"
Original    (008): ['trac_components', '=', 'list', '(', '[', ']', ')', '\\n']
Tokenized   (014): ['[CLS]', 'tr', '##ac', '_', 'components', '=', 'list', '(', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['tr', '##ac', '_', 'components', '=', 'list', '(', '[', ']', ')', '\\', 'n']
Detokenized (008): ['tr##ac_components', '=', 'list', '(', '[', ']', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "component . owner = self . _get_user_login ( component . owner ) \n"
Original    (013): ['component', '.', 'owner', '=', 'self', '.', '_get_user_login', '(', 'component', '.', 'owner', ')', '\\n']
Tokenized   (022): ['[CLS]', 'component', '.', 'owner', '=', 'self', '.', '_', 'get', '_', 'user', '_', 'log', '##in', '(', 'component', '.', 'owner', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['component', '.', 'owner', '=', 'self', '.', '_', 'get', '_', 'user', '_', 'log', '##in', '(', 'component', '.', 'owner', ')', '\\', 'n']
Detokenized (013): ['component', '.', 'owner', '=', 'self', '.', '_get_user_log##in', '(', 'component', '.', 'owner', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "networks [ pkt . pduSource ] . append ( pkt . wirtnNetwork ) \n"
Original    (014): ['networks', '[', 'pkt', '.', 'pduSource', ']', '.', 'append', '(', 'pkt', '.', 'wirtnNetwork', ')', '\\n']
Tokenized   (027): ['[CLS]', 'networks', '[', 'p', '##kt', '.', 'pd', '##uso', '##ur', '##ce', ']', '.', 'app', '##end', '(', 'p', '##kt', '.', 'wi', '##rt', '##nne', '##t', '##work', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['networks', '[', 'p', '##kt', '.', 'pd', '##uso', '##ur', '##ce', ']', '.', 'app', '##end', '(', 'p', '##kt', '.', 'wi', '##rt', '##nne', '##t', '##work', ')', '\\', 'n']
Detokenized (014): ['networks', '[', 'p##kt', '.', 'pd##uso##ur##ce', ']', '.', 'app##end', '(', 'p##kt', '.', 'wi##rt##nne##t##work', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "filterSource = Address ( sys . argv [ i + 1 ] ) \n"
Original    (014): ['filterSource', '=', 'Address', '(', 'sys', '.', 'argv', '[', 'i', '+', '1', ']', ')', '\\n']
Tokenized   (022): ['[CLS]', 'filters', '##our', '##ce', '=', 'address', '(', 'sy', '##s', '.', 'ar', '##g', '##v', '[', 'i', '+', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['filters', '##our', '##ce', '=', 'address', '(', 'sy', '##s', '.', 'ar', '##g', '##v', '[', 'i', '+', '1', ']', ')', '\\', 'n']
Detokenized (014): ['filters##our##ce', '=', 'address', '(', 'sy##s', '.', 'ar##g##v', '[', 'i', '+', '1', ']', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "net_count . sort ( lambda x , y : cmp ( y [ 1 ] , x [ 1 ] ) ) \n"
Original    (023): ['net_count', '.', 'sort', '(', 'lambda', 'x', ',', 'y', ':', 'cmp', '(', 'y', '[', '1', ']', ',', 'x', '[', '1', ']', ')', ')', '\\n']
Tokenized   (029): ['[CLS]', 'net', '_', 'count', '.', 'sort', '(', 'lambda', 'x', ',', 'y', ':', 'cm', '##p', '(', 'y', '[', '1', ']', ',', 'x', '[', '1', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['net', '_', 'count', '.', 'sort', '(', 'lambda', 'x', ',', 'y', ':', 'cm', '##p', '(', 'y', '[', '1', ']', ',', 'x', '[', '1', ']', ')', ')', '\\', 'n']
Detokenized (023): ['net_count', '.', 'sort', '(', 'lambda', 'x', ',', 'y', ':', 'cm##p', '(', 'y', '[', '1', ']', ',', 'x', '[', '1', ']', ')', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "strm = StringIO ( self . pickleBuffer ) \n"
Original    (009): ['strm', '=', 'StringIO', '(', 'self', '.', 'pickleBuffer', ')', '\\n']
Tokenized   (017): ['[CLS]', 'st', '##rm', '=', 'string', '##io', '(', 'self', '.', 'pick', '##le', '##bu', '##ffer', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['st', '##rm', '=', 'string', '##io', '(', 'self', '.', 'pick', '##le', '##bu', '##ffer', ')', '\\', 'n']
Detokenized (009): ['st##rm', '=', 'string##io', '(', 'self', '.', 'pick##le##bu##ffer', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pdu . pduSource = self . peer \n"
Original    (008): ['pdu', '.', 'pduSource', '=', 'self', '.', 'peer', '\\n']
Tokenized   (015): ['[CLS]', 'pd', '##u', '.', 'pd', '##uso', '##ur', '##ce', '=', 'self', '.', 'peer', '\\', 'n', '[SEP]']
Filtered   (013): ['pd', '##u', '.', 'pd', '##uso', '##ur', '##ce', '=', 'self', '.', 'peer', '\\', 'n']
Detokenized (008): ['pd##u', '.', 'pd##uso##ur##ce', '=', 'self', '.', 'peer', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "connect_task . install_task ( _time ( ) + self . reconnect [ actor . peer ] ) \n"
Original    (018): ['connect_task', '.', 'install_task', '(', '_time', '(', ')', '+', 'self', '.', 'reconnect', '[', 'actor', '.', 'peer', ']', ')', '\\n']
Tokenized   (028): ['[CLS]', 'connect', '_', 'task', '.', 'install', '_', 'task', '(', '_', 'time', '(', ')', '+', 'self', '.', 'rec', '##onne', '##ct', '[', 'actor', '.', 'peer', ']', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['connect', '_', 'task', '.', 'install', '_', 'task', '(', '_', 'time', '(', ')', '+', 'self', '.', 'rec', '##onne', '##ct', '[', 'actor', '.', 'peer', ']', ')', '\\', 'n']
Detokenized (018): ['connect_task', '.', 'install_task', '(', '_time', '(', ')', '+', 'self', '.', 'rec##onne##ct', '[', 'actor', '.', 'peer', ']', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "asyncore . dispatcher . __init__ ( self , sock ) \n"
Original    (011): ['asyncore', '.', 'dispatcher', '.', '__init__', '(', 'self', ',', 'sock', ')', '\\n']
Tokenized   (022): ['[CLS]', 'as', '##yn', '##core', '.', 'dispatch', '##er', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', 'sock', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['as', '##yn', '##core', '.', 'dispatch', '##er', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', 'sock', ')', '\\', 'n']
Detokenized (011): ['as##yn##core', '.', 'dispatch##er', '.', '__in##it__', '(', 'self', ',', 'sock', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "TCPServerDirector . _warning ( , err ) \n"
Original    (008): ['TCPServerDirector', '.', '_warning', '(', ',', 'err', ')', '\\n']
Tokenized   (019): ['[CLS]', 'tc', '##pse', '##r', '##ver', '##di', '##re', '##ctor', '.', '_', 'warning', '(', ',', 'er', '##r', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['tc', '##pse', '##r', '##ver', '##di', '##re', '##ctor', '.', '_', 'warning', '(', ',', 'er', '##r', ')', '\\', 'n']
Detokenized (008): ['tc##pse##r##ver##di##re##ctor', '.', '_warning', '(', ',', 'er##r', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "buff = packet [ 1 ] \n"
Original    (007): ['buff', '=', 'packet', '[', '1', ']', '\\n']
Tokenized   (010): ['[CLS]', 'buff', '=', 'packet', '[', '1', ']', '\\', 'n', '[SEP]']
Filtered   (008): ['buff', '=', 'packet', '[', '1', ']', '\\', 'n']
Detokenized (007): ['buff', '=', 'packet', '[', '1', ']', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "fileIdentifier = ( obj_type , obj_inst ) , \n"
Original    (009): ['fileIdentifier', '=', '(', 'obj_type', ',', 'obj_inst', ')', ',', '\\n']
Tokenized   (023): ['[CLS]', 'file', '##ide', '##nti', '##fi', '##er', '=', '(', 'ob', '##j', '_', 'type', ',', 'ob', '##j', '_', 'ins', '##t', ')', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['file', '##ide', '##nti', '##fi', '##er', '=', '(', 'ob', '##j', '_', 'type', ',', 'ob', '##j', '_', 'ins', '##t', ')', ',', '\\', 'n']
Detokenized (009): ['file##ide##nti##fi##er', '=', '(', 'ob##j_type', ',', 'ob##j_ins##t', ')', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "record_data = list ( args [ 4 : ] ) \n"
Original    (011): ['record_data', '=', 'list', '(', 'args', '[', '4', ':', ']', ')', '\\n']
Tokenized   (017): ['[CLS]', 'record', '_', 'data', '=', 'list', '(', 'ar', '##gs', '[', '4', ':', ']', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['record', '_', 'data', '=', 'list', '(', 'ar', '##gs', '[', '4', ':', ']', ')', '\\', 'n']
Detokenized (011): ['record_data', '=', 'list', '(', 'ar##gs', '[', '4', ':', ']', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "accessMethod = AtomicWriteFileRequestAccessMethodChoice ( \n"
Original    (005): ['accessMethod', '=', 'AtomicWriteFileRequestAccessMethodChoice', '(', '\\n']
Tokenized   (023): ['[CLS]', 'access', '##met', '##ho', '##d', '=', 'atomic', '##write', '##fi', '##ler', '##e', '##quest', '##ac', '##ces', '##sm', '##eth', '##od', '##cho', '##ice', '(', '\\', 'n', '[SEP]']
Filtered   (021): ['access', '##met', '##ho', '##d', '=', 'atomic', '##write', '##fi', '##ler', '##e', '##quest', '##ac', '##ces', '##sm', '##eth', '##od', '##cho', '##ice', '(', '\\', 'n']
Detokenized (005): ['access##met##ho##d', '=', 'atomic##write##fi##ler##e##quest##ac##ces##sm##eth##od##cho##ice', '(', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "objectIdentifier = int ( args . ini . objectidentifier ) , \n"
Original    (012): ['objectIdentifier', '=', 'int', '(', 'args', '.', 'ini', '.', 'objectidentifier', ')', ',', '\\n']
Tokenized   (025): ['[CLS]', 'object', '##ide', '##nti', '##fi', '##er', '=', 'int', '(', 'ar', '##gs', '.', 'in', '##i', '.', 'object', '##ide', '##nti', '##fi', '##er', ')', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['object', '##ide', '##nti', '##fi', '##er', '=', 'int', '(', 'ar', '##gs', '.', 'in', '##i', '.', 'object', '##ide', '##nti', '##fi', '##er', ')', ',', '\\', 'n']
Detokenized (012): ['object##ide##nti##fi##er', '=', 'int', '(', 'ar##gs', '.', 'in##i', '.', 'object##ide##nti##fi##er', ')', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "this_application = TestApplication ( this_device , args . ini . address ) \n"
Original    (013): ['this_application', '=', 'TestApplication', '(', 'this_device', ',', 'args', '.', 'ini', '.', 'address', ')', '\\n']
Tokenized   (025): ['[CLS]', 'this', '_', 'application', '=', 'test', '##app', '##lica', '##tion', '(', 'this', '_', 'device', ',', 'ar', '##gs', '.', 'in', '##i', '.', 'address', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['this', '_', 'application', '=', 'test', '##app', '##lica', '##tion', '(', 'this', '_', 'device', ',', 'ar', '##gs', '.', 'in', '##i', '.', 'address', ')', '\\', 'n']
Detokenized (013): ['this_application', '=', 'test##app##lica##tion', '(', 'this_device', ',', 'ar##gs', '.', 'in##i', '.', 'address', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_log . debug ( "running" ) \n"
Original    (007): ['_log', '.', 'debug', '(', '"running"', ')', '\\n']
Tokenized   (015): ['[CLS]', '_', 'log', '.', 'de', '##bu', '##g', '(', '"', 'running', '"', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['_', 'log', '.', 'de', '##bu', '##g', '(', '"', 'running', '"', ')', '\\', 'n']
Detokenized (007): ['_log', '.', 'de##bu##g', '(', '"running"', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Status . FAILED_TO_ADD_TO_CLIENT : % ( COLOR_FAILED_TO_ADD_TO_CLIENT , Color . ENDC ) , \n"
Original    (014): ['Status', '.', 'FAILED_TO_ADD_TO_CLIENT', ':', '%', '(', 'COLOR_FAILED_TO_ADD_TO_CLIENT', ',', 'Color', '.', 'ENDC', ')', ',', '\\n']
Tokenized   (036): ['[CLS]', 'status', '.', 'failed', '_', 'to', '_', 'add', '_', 'to', '_', 'client', ':', '%', '(', 'color', '_', 'failed', '_', 'to', '_', 'add', '_', 'to', '_', 'client', ',', 'color', '.', 'end', '##c', ')', ',', '\\', 'n', '[SEP]']
Filtered   (034): ['status', '.', 'failed', '_', 'to', '_', 'add', '_', 'to', '_', 'client', ':', '%', '(', 'color', '_', 'failed', '_', 'to', '_', 'add', '_', 'to', '_', 'client', ',', 'color', '.', 'end', '##c', ')', ',', '\\', 'n']
Detokenized (014): ['status', '.', 'failed_to_add_to_client', ':', '%', '(', 'color_failed_to_add_to_client', ',', 'color', '.', 'end##c', ')', ',', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "end_size += f [ ] \n"
Original    (006): ['end_size', '+=', 'f', '[', ']', '\\n']
Tokenized   (012): ['[CLS]', 'end', '_', 'size', '+', '=', 'f', '[', ']', '\\', 'n', '[SEP]']
Filtered   (010): ['end', '_', 'size', '+', '=', 'f', '[', ']', '\\', 'n']
Detokenized (006): ['end_size', '+=', 'f', '[', ']', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "files_to_check += self . db . find_hash_varying_size ( f [ ] ) \n"
Original    (013): ['files_to_check', '+=', 'self', '.', 'db', '.', 'find_hash_varying_size', '(', 'f', '[', ']', ')', '\\n']
Tokenized   (027): ['[CLS]', 'files', '_', 'to', '_', 'check', '+', '=', 'self', '.', 'db', '.', 'find', '_', 'hash', '_', 'varying', '_', 'size', '(', 'f', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['files', '_', 'to', '_', 'check', '+', '=', 'self', '.', 'db', '.', 'find', '_', 'hash', '_', 'varying', '_', 'size', '(', 'f', '[', ']', ')', '\\', 'n']
Detokenized (013): ['files_to_check', '+=', 'self', '.', 'db', '.', 'find_hash_varying_size', '(', 'f', '[', ']', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "match_start , match_end = pieces . match_file ( db_file , start_size , end_size ) \n"
Original    (015): ['match_start', ',', 'match_end', '=', 'pieces', '.', 'match_file', '(', 'db_file', ',', 'start_size', ',', 'end_size', ')', '\\n']
Tokenized   (030): ['[CLS]', 'match', '_', 'start', ',', 'match', '_', 'end', '=', 'pieces', '.', 'match', '_', 'file', '(', 'db', '_', 'file', ',', 'start', '_', 'size', ',', 'end', '_', 'size', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['match', '_', 'start', ',', 'match', '_', 'end', '=', 'pieces', '.', 'match', '_', 'file', '(', 'db', '_', 'file', ',', 'start', '_', 'size', ',', 'end', '_', 'size', ')', '\\', 'n']
Detokenized (015): ['match_start', ',', 'match_end', '=', 'pieces', '.', 'match_file', '(', 'db_file', ',', 'start_size', ',', 'end_size', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "path_files [ os . path . join ( * path ) ] . append ( { \n"
Original    (017): ['path_files', '[', 'os', '.', 'path', '.', 'join', '(', '*', 'path', ')', ']', '.', 'append', '(', '{', '\\n']
Tokenized   (023): ['[CLS]', 'path', '_', 'files', '[', 'os', '.', 'path', '.', 'join', '(', '*', 'path', ')', ']', '.', 'app', '##end', '(', '{', '\\', 'n', '[SEP]']
Filtered   (021): ['path', '_', 'files', '[', 'os', '.', 'path', '.', 'join', '(', '*', 'path', ')', ']', '.', 'app', '##end', '(', '{', '\\', 'n']
Detokenized (017): ['path_files', '[', 'os', '.', 'path', '.', 'join', '(', '*', 'path', ')', ']', '.', 'app##end', '(', '{', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "files_sorted [ . join ( orig_path ) ] = i \n"
Original    (011): ['files_sorted', '[', '.', 'join', '(', 'orig_path', ')', ']', '=', 'i', '\\n']
Tokenized   (019): ['[CLS]', 'files', '_', 'sorted', '[', '.', 'join', '(', 'or', '##ig', '_', 'path', ')', ']', '=', 'i', '\\', 'n', '[SEP]']
Filtered   (017): ['files', '_', 'sorted', '[', '.', 'join', '(', 'or', '##ig', '_', 'path', ')', ']', '=', 'i', '\\', 'n']
Detokenized (011): ['files_sorted', '[', '.', 'join', '(', 'or##ig_path', ')', ']', '=', 'i', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "found_size , missing_size = 0 , 0 \n"
Original    (008): ['found_size', ',', 'missing_size', '=', '0', ',', '0', '\\n']
Tokenized   (015): ['[CLS]', 'found', '_', 'size', ',', 'missing', '_', 'size', '=', '0', ',', '0', '\\', 'n', '[SEP]']
Filtered   (013): ['found', '_', 'size', ',', 'missing', '_', 'size', '=', '0', ',', '0', '\\', 'n']
Detokenized (008): ['found_size', ',', 'missing_size', '=', '0', ',', '0', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "output_fp . write ( * write_bytes ) \n"
Original    (008): ['output_fp', '.', 'write', '(', '*', 'write_bytes', ')', '\\n']
Tokenized   (016): ['[CLS]', 'output', '_', 'f', '##p', '.', 'write', '(', '*', 'write', '_', 'bytes', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['output', '_', 'f', '##p', '.', 'write', '(', '*', 'write', '_', 'bytes', ')', '\\', 'n']
Detokenized (008): ['output_f##p', '.', 'write', '(', '*', 'write_bytes', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bytes_written += read_bytes \n"
Original    (004): ['bytes_written', '+=', 'read_bytes', '\\n']
Tokenized   (012): ['[CLS]', 'bytes', '_', 'written', '+', '=', 'read', '_', 'bytes', '\\', 'n', '[SEP]']
Filtered   (010): ['bytes', '_', 'written', '+', '=', 'read', '_', 'bytes', '\\', 'n']
Detokenized (004): ['bytes_written', '+=', 'read_bytes', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "missing_percent = ( missing_size / ( found_size + missing_size ) ) * 100 \n"
Original    (014): ['missing_percent', '=', '(', 'missing_size', '/', '(', 'found_size', '+', 'missing_size', ')', ')', '*', '100', '\\n']
Tokenized   (025): ['[CLS]', 'missing', '_', 'percent', '=', '(', 'missing', '_', 'size', '/', '(', 'found', '_', 'size', '+', 'missing', '_', 'size', ')', ')', '*', '100', '\\', 'n', '[SEP]']
Filtered   (023): ['missing', '_', 'percent', '=', '(', 'missing', '_', 'size', '/', '(', 'found', '_', 'size', '+', 'missing', '_', 'size', ')', ')', '*', '100', '\\', 'n']
Detokenized (014): ['missing_percent', '=', '(', 'missing_size', '/', '(', 'found_size', '+', 'missing_size', ')', ')', '*', '100', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "found_percent = 100 - missing_percent \n"
Original    (006): ['found_percent', '=', '100', '-', 'missing_percent', '\\n']
Tokenized   (013): ['[CLS]', 'found', '_', 'percent', '=', '100', '-', 'missing', '_', 'percent', '\\', 'n', '[SEP]']
Filtered   (011): ['found', '_', 'percent', '=', '100', '-', 'missing', '_', 'percent', '\\', 'n']
Detokenized (006): ['found_percent', '=', '100', '-', 'missing_percent', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "would_not_add = missing_size and missing_percent > self . add_limit_percent or missing_size > \n"
Original    (013): ['would_not_add', '=', 'missing_size', 'and', 'missing_percent', '>', 'self', '.', 'add_limit_percent', 'or', 'missing_size', '>', '\\n']
Tokenized   (030): ['[CLS]', 'would', '_', 'not', '_', 'add', '=', 'missing', '_', 'size', 'and', 'missing', '_', 'percent', '>', 'self', '.', 'add', '_', 'limit', '_', 'percent', 'or', 'missing', '_', 'size', '>', '\\', 'n', '[SEP]']
Filtered   (028): ['would', '_', 'not', '_', 'add', '=', 'missing', '_', 'size', 'and', 'missing', '_', 'percent', '>', 'self', '.', 'add', '_', 'limit', '_', 'percent', 'or', 'missing', '_', 'size', '>', '\\', 'n']
Detokenized (013): ['would_not_add', '=', 'missing_size', 'and', 'missing_percent', '>', 'self', '.', 'add_limit_percent', 'or', 'missing_size', '>', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "LEGO_PALETTE = ( , , , , , , ) \n"
Original    (011): ['LEGO_PALETTE', '=', '(', ',', ',', ',', ',', ',', ',', ')', '\\n']
Tokenized   (016): ['[CLS]', 'lego', '_', 'palette', '=', '(', ',', ',', ',', ',', ',', ',', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['lego', '_', 'palette', '=', '(', ',', ',', ',', ',', ',', ',', ')', '\\', 'n']
Detokenized (011): ['lego_palette', '=', '(', ',', ',', ',', ',', ',', ',', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Draft4Validator , RefResolver , create , extend , validator_for , validate , \n"
Original    (013): ['Draft4Validator', ',', 'RefResolver', ',', 'create', ',', 'extend', ',', 'validator_for', ',', 'validate', ',', '\\n']
Tokenized   (027): ['[CLS]', 'draft', '##4', '##val', '##ida', '##tor', ',', 'ref', '##res', '##ol', '##ver', ',', 'create', ',', 'extend', ',', 'valid', '##ator', '_', 'for', ',', 'valid', '##ate', ',', '\\', 'n', '[SEP]']
Filtered   (025): ['draft', '##4', '##val', '##ida', '##tor', ',', 'ref', '##res', '##ol', '##ver', ',', 'create', ',', 'extend', ',', 'valid', '##ator', '_', 'for', ',', 'valid', '##ate', ',', '\\', 'n']
Detokenized (013): ['draft##4##val##ida##tor', ',', 'ref##res##ol##ver', ',', 'create', ',', 'extend', ',', 'valid##ator_for', ',', 'valid##ate', ',', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "u"enum" : [ [ "a" , "b" , "c" ] , [ "d" , "e" , "f" ] ] , \n"
Original    (021): ['u"enum"', ':', '[', '[', '"a"', ',', '"b"', ',', '"c"', ']', ',', '[', '"d"', ',', '"e"', ',', '"f"', ']', ']', ',', '\\n']
Tokenized   (040): ['[CLS]', 'u', '"', 'en', '##um', '"', ':', '[', '[', '"', 'a', '"', ',', '"', 'b', '"', ',', '"', 'c', '"', ']', ',', '[', '"', 'd', '"', ',', '"', 'e', '"', ',', '"', 'f', '"', ']', ']', ',', '\\', 'n', '[SEP]']
Filtered   (038): ['u', '"', 'en', '##um', '"', ':', '[', '[', '"', 'a', '"', ',', '"', 'b', '"', ',', '"', 'c', '"', ']', ',', '[', '"', 'd', '"', ',', '"', 'e', '"', ',', '"', 'f', '"', ']', ']', ',', '\\', 'n']
Detokenized (021): ['u"en##um"', ':', '[', '[', '"a"', ',', '"b"', ',', '"c"', ']', ',', '[', '"d"', ',', '"e"', ',', '"f"', ']', ']', ',', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "got = ( e . message for e in self . validator . iter_errors ( instance , schema ) ) \n"
Original    (021): ['got', '=', '(', 'e', '.', 'message', 'for', 'e', 'in', 'self', '.', 'validator', '.', 'iter_errors', '(', 'instance', ',', 'schema', ')', ')', '\\n']
Tokenized   (029): ['[CLS]', 'got', '=', '(', 'e', '.', 'message', 'for', 'e', 'in', 'self', '.', 'valid', '##ator', '.', 'it', '##er', '_', 'errors', '(', 'instance', ',', 'sc', '##hema', ')', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['got', '=', '(', 'e', '.', 'message', 'for', 'e', 'in', 'self', '.', 'valid', '##ator', '.', 'it', '##er', '_', 'errors', '(', 'instance', ',', 'sc', '##hema', ')', ')', '\\', 'n']
Detokenized (021): ['got', '=', '(', 'e', '.', 'message', 'for', 'e', 'in', 'self', '.', 'valid##ator', '.', 'it##er_errors', '(', 'instance', ',', 'sc##hema', ')', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "checker . checks ( u"thing" ) ( check_fn ) \n"
Original    (010): ['checker', '.', 'checks', '(', 'u"thing"', ')', '(', 'check_fn', ')', '\\n']
Tokenized   (020): ['[CLS]', 'check', '##er', '.', 'checks', '(', 'u', '"', 'thing', '"', ')', '(', 'check', '_', 'f', '##n', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['check', '##er', '.', 'checks', '(', 'u', '"', 'thing', '"', ')', '(', 'check', '_', 'f', '##n', ')', '\\', 'n']
Detokenized (010): ['check##er', '.', 'checks', '(', 'u"thing"', ')', '(', 'check_f##n', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "deque ( [ "type" , 1 , "properties" , "foo" , "enum" ] ) , \n"
Original    (016): ['deque', '(', '[', '"type"', ',', '1', ',', '"properties"', ',', '"foo"', ',', '"enum"', ']', ')', ',', '\\n']
Tokenized   (029): ['[CLS]', 'de', '##que', '(', '[', '"', 'type', '"', ',', '1', ',', '"', 'properties', '"', ',', '"', 'foo', '"', ',', '"', 'en', '##um', '"', ']', ')', ',', '\\', 'n', '[SEP]']
Filtered   (027): ['de', '##que', '(', '[', '"', 'type', '"', ',', '1', ',', '"', 'properties', '"', ',', '"', 'foo', '"', ',', '"', 'en', '##um', '"', ']', ')', ',', '\\', 'n']
Detokenized (016): ['de##que', '(', '[', '"type"', ',', '1', ',', '"properties"', ',', '"foo"', ',', '"en##um"', ']', ')', ',', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""baz" : { "minItems" : 2 } , \n"
Original    (009): ['"baz"', ':', '{', '"minItems"', ':', '2', '}', ',', '\\n']
Tokenized   (019): ['[CLS]', '"', 'ba', '##z', '"', ':', '{', '"', 'mini', '##tem', '##s', '"', ':', '2', '}', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['"', 'ba', '##z', '"', ':', '{', '"', 'mini', '##tem', '##s', '"', ':', '2', '}', ',', '\\', 'n']
Detokenized (009): ['"ba##z"', ':', '{', '"mini##tem##s"', ':', '2', '}', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""required" : [ "root" ] , \n"
Original    (007): ['"required"', ':', '[', '"root"', ']', ',', '\\n']
Tokenized   (014): ['[CLS]', '"', 'required', '"', ':', '[', '"', 'root', '"', ']', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['"', 'required', '"', ':', '[', '"', 'root', '"', ']', ',', '\\', 'n']
Detokenized (007): ['"required"', ':', '[', '"root"', ']', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "e2 . absolute_schema_path , deque ( \n"
Original    (007): ['e2', '.', 'absolute_schema_path', ',', 'deque', '(', '\\n']
Tokenized   (017): ['[CLS]', 'e', '##2', '.', 'absolute', '_', 'sc', '##hema', '_', 'path', ',', 'de', '##que', '(', '\\', 'n', '[SEP]']
Filtered   (015): ['e', '##2', '.', 'absolute', '_', 'sc', '##hema', '_', 'path', ',', 'de', '##que', '(', '\\', 'n']
Detokenized (007): ['e##2', '.', 'absolute_sc##hema_path', ',', 'de##que', '(', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""additionalProperties" : { "type" : "integer" , "minimum" : 5 } \n"
Original    (012): ['"additionalProperties"', ':', '{', '"type"', ':', '"integer"', ',', '"minimum"', ':', '5', '}', '\\n']
Tokenized   (026): ['[CLS]', '"', 'additional', '##pro', '##per', '##ties', '"', ':', '{', '"', 'type', '"', ':', '"', 'integer', '"', ',', '"', 'minimum', '"', ':', '5', '}', '\\', 'n', '[SEP]']
Filtered   (024): ['"', 'additional', '##pro', '##per', '##ties', '"', ':', '{', '"', 'type', '"', ':', '"', 'integer', '"', ',', '"', 'minimum', '"', ':', '5', '}', '\\', 'n']
Detokenized (012): ['"additional##pro##per##ties"', ':', '{', '"type"', ':', '"integer"', ',', '"minimum"', ':', '5', '}', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""bar" : { "type" : "string" } , \n"
Original    (009): ['"bar"', ':', '{', '"type"', ':', '"string"', '}', ',', '\\n']
Tokenized   (018): ['[CLS]', '"', 'bar', '"', ':', '{', '"', 'type', '"', ':', '"', 'string', '"', '}', ',', '\\', 'n', '[SEP]']
Filtered   (016): ['"', 'bar', '"', ':', '{', '"', 'type', '"', ':', '"', 'string', '"', '}', ',', '\\', 'n']
Detokenized (009): ['"bar"', ':', '{', '"type"', ':', '"string"', '}', ',', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""foo" : { "minimum" : 5 } \n"
Original    (008): ['"foo"', ':', '{', '"minimum"', ':', '5', '}', '\\n']
Tokenized   (015): ['[CLS]', '"', 'foo', '"', ':', '{', '"', 'minimum', '"', ':', '5', '}', '\\', 'n', '[SEP]']
Filtered   (013): ['"', 'foo', '"', ':', '{', '"', 'minimum', '"', ':', '5', '}', '\\', 'n']
Detokenized (008): ['"foo"', ':', '{', '"minimum"', ':', '5', '}', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""items" : [ { } ] , \n"
Original    (008): ['"items"', ':', '[', '{', '}', ']', ',', '\\n']
Tokenized   (013): ['[CLS]', '"', 'items', '"', ':', '[', '{', '}', ']', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['"', 'items', '"', ':', '[', '{', '}', ']', ',', '\\', 'n']
Detokenized (008): ['"items"', ':', '[', '{', '}', ']', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "validate ( instance = instance , schema = { my_property : my_value } ) \n"
Original    (015): ['validate', '(', 'instance', '=', 'instance', ',', 'schema', '=', '{', 'my_property', ':', 'my_value', '}', ')', '\\n']
Tokenized   (024): ['[CLS]', 'valid', '##ate', '(', 'instance', '=', 'instance', ',', 'sc', '##hema', '=', '{', 'my', '_', 'property', ':', 'my', '_', 'value', '}', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['valid', '##ate', '(', 'instance', '=', 'instance', ',', 'sc', '##hema', '=', '{', 'my', '_', 'property', ':', 'my', '_', 'value', '}', ')', '\\', 'n']
Detokenized (015): ['valid##ate', '(', 'instance', '=', 'instance', ',', 'sc##hema', '=', '{', 'my_property', ':', 'my_value', '}', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "chk_schema . assert_called_once_with ( { } ) \n"
Original    (008): ['chk_schema', '.', 'assert_called_once_with', '(', '{', '}', ')', '\\n']
Tokenized   (021): ['[CLS]', 'ch', '##k', '_', 'sc', '##hema', '.', 'assert', '_', 'called', '_', 'once', '_', 'with', '(', '{', '}', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['ch', '##k', '_', 'sc', '##hema', '.', 'assert', '_', 'called', '_', 'once', '_', 'with', '(', '{', '}', ')', '\\', 'n']
Detokenized (008): ['ch##k_sc##hema', '.', 'assert_called_once_with', '(', '{', '}', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "stored_schema = { "stored" : "schema" } \n"
Original    (008): ['stored_schema', '=', '{', '"stored"', ':', '"schema"', '}', '\\n']
Tokenized   (019): ['[CLS]', 'stored', '_', 'sc', '##hema', '=', '{', '"', 'stored', '"', ':', '"', 'sc', '##hema', '"', '}', '\\', 'n', '[SEP]']
Filtered   (017): ['stored', '_', 'sc', '##hema', '=', '{', '"', 'stored', '"', ':', '"', 'sc', '##hema', '"', '}', '\\', 'n']
Detokenized (008): ['stored_sc##hema', '=', '{', '"stored"', ':', '"sc##hema"', '}', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""ports" : \n"
Original    (003): ['"ports"', ':', '\\n']
Tokenized   (008): ['[CLS]', '"', 'ports', '"', ':', '\\', 'n', '[SEP]']
Filtered   (006): ['"', 'ports', '"', ':', '\\', 'n']
Detokenized (003): ['"ports"', ':', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "l2Report . generateReport ( pod . id , True , False ) \n"
Original    (013): ['l2Report', '.', 'generateReport', '(', 'pod', '.', 'id', ',', 'True', ',', 'False', ')', '\\n']
Tokenized   (021): ['[CLS]', 'l', '##2', '##re', '##port', '.', 'generate', '##re', '##port', '(', 'pod', '.', 'id', ',', 'true', ',', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['l', '##2', '##re', '##port', '.', 'generate', '##re', '##port', '(', 'pod', '.', 'id', ',', 'true', ',', 'false', ')', '\\', 'n']
Detokenized (013): ['l##2##re##port', '.', 'generate##re##port', '(', 'pod', '.', 'id', ',', 'true', ',', 'false', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_YAML_ = splitext ( __file__ ) [ 0 ] + \n"
Original    (011): ['_YAML_', '=', 'splitext', '(', '__file__', ')', '[', '0', ']', '+', '\\n']
Tokenized   (023): ['[CLS]', '_', 'ya', '##ml', '_', '=', 'split', '##ex', '##t', '(', '_', '_', 'file', '_', '_', ')', '[', '0', ']', '+', '\\', 'n', '[SEP]']
Filtered   (021): ['_', 'ya', '##ml', '_', '=', 'split', '##ex', '##t', '(', '_', '_', 'file', '_', '_', ')', '[', '0', ']', '+', '\\', 'n']
Detokenized (011): ['_ya##ml_', '=', 'split##ex##t', '(', '__file__', ')', '[', '0', ']', '+', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "globals ( ) . update ( loadyaml ( _YAML_ ) ) \n"
Original    (012): ['globals', '(', ')', '.', 'update', '(', 'loadyaml', '(', '_YAML_', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'global', '##s', '(', ')', '.', 'update', '(', 'load', '##yam', '##l', '(', '_', 'ya', '##ml', '_', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['global', '##s', '(', ')', '.', 'update', '(', 'load', '##yam', '##l', '(', '_', 'ya', '##ml', '_', ')', ')', '\\', 'n']
Detokenized (012): ['global##s', '(', ')', '.', 'update', '(', 'load##yam##l', '(', '_ya##ml_', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "gather_facts = False ) \n"
Original    (005): ['gather_facts', '=', 'False', ')', '\\n']
Tokenized   (010): ['[CLS]', 'gather', '_', 'facts', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['gather', '_', 'facts', '=', 'false', ')', '\\', 'n']
Detokenized (005): ['gather_facts', '=', 'false', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "DEFAULT_API_URLS = ( , \n"
Original    (005): ['DEFAULT_API_URLS', '=', '(', ',', '\\n']
Tokenized   (013): ['[CLS]', 'default', '_', 'api', '_', 'ur', '##ls', '=', '(', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['default', '_', 'api', '_', 'ur', '##ls', '=', '(', ',', '\\', 'n']
Detokenized (005): ['default_api_ur##ls', '=', '(', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "BAD_STATUS_CODES = [ , , , \n"
Original    (007): ['BAD_STATUS_CODES', '=', '[', ',', ',', ',', '\\n']
Tokenized   (014): ['[CLS]', 'bad', '_', 'status', '_', 'codes', '=', '[', ',', ',', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['bad', '_', 'status', '_', 'codes', '=', '[', ',', ',', ',', '\\', 'n']
Detokenized (007): ['bad_status_codes', '=', '[', ',', ',', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "translate_otp = True , api_urls = DEFAULT_API_URLS , \n"
Original    (009): ['translate_otp', '=', 'True', ',', 'api_urls', '=', 'DEFAULT_API_URLS', ',', '\\n']
Tokenized   (023): ['[CLS]', 'translate', '_', 'ot', '##p', '=', 'true', ',', 'api', '_', 'ur', '##ls', '=', 'default', '_', 'api', '_', 'ur', '##ls', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['translate', '_', 'ot', '##p', '=', 'true', ',', 'api', '_', 'ur', '##ls', '=', 'default', '_', 'api', '_', 'ur', '##ls', ',', '\\', 'n']
Detokenized (009): ['translate_ot##p', '=', 'true', ',', 'api_ur##ls', '=', 'default_api_ur##ls', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rand_str = b ( os . urandom ( 30 ) ) \n"
Original    (012): ['rand_str', '=', 'b', '(', 'os', '.', 'urandom', '(', '30', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'rand', '_', 'st', '##r', '=', 'b', '(', 'os', '.', 'ur', '##ando', '##m', '(', '30', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['rand', '_', 'st', '##r', '=', 'b', '(', 'os', '.', 'ur', '##ando', '##m', '(', '30', ')', ')', '\\', 'n']
Detokenized (012): ['rand_st##r', '=', 'b', '(', 'os', '.', 'ur##ando##m', '(', '30', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "nonce = base64 . b64encode ( rand_str , b ( ) ) [ : 25 ] . decode ( ) \n"
Original    (021): ['nonce', '=', 'base64', '.', 'b64encode', '(', 'rand_str', ',', 'b', '(', ')', ')', '[', ':', '25', ']', '.', 'decode', '(', ')', '\\n']
Tokenized   (033): ['[CLS]', 'non', '##ce', '=', 'base', '##64', '.', 'b', '##64', '##en', '##code', '(', 'rand', '_', 'st', '##r', ',', 'b', '(', ')', ')', '[', ':', '25', ']', '.', 'deco', '##de', '(', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['non', '##ce', '=', 'base', '##64', '.', 'b', '##64', '##en', '##code', '(', 'rand', '_', 'st', '##r', ',', 'b', '(', ')', ')', '[', ':', '25', ']', '.', 'deco', '##de', '(', ')', '\\', 'n']
Detokenized (021): ['non##ce', '=', 'base##64', '.', 'b##64##en##code', '(', 'rand_st##r', ',', 'b', '(', ')', ')', '[', ':', '25', ']', '.', 'deco##de', '(', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "otp . otp , nonce , \n"
Original    (007): ['otp', '.', 'otp', ',', 'nonce', ',', '\\n']
Tokenized   (013): ['[CLS]', 'ot', '##p', '.', 'ot', '##p', ',', 'non', '##ce', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['ot', '##p', '.', 'ot', '##p', ',', 'non', '##ce', ',', '\\', 'n']
Detokenized (007): ['ot##p', '.', 'ot##p', ',', 'non##ce', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "pairs_string = . join ( [ . join ( pair ) for pair in pairs_sorted ] ) \n"
Original    (018): ['pairs_string', '=', '.', 'join', '(', '[', '.', 'join', '(', 'pair', ')', 'for', 'pair', 'in', 'pairs_sorted', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'pairs', '_', 'string', '=', '.', 'join', '(', '[', '.', 'join', '(', 'pair', ')', 'for', 'pair', 'in', 'pairs', '_', 'sorted', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['pairs', '_', 'string', '=', '.', 'join', '(', '[', '.', 'join', '(', 'pair', ')', 'for', 'pair', 'in', 'pairs', '_', 'sorted', ']', ')', '\\', 'n']
Detokenized (018): ['pairs_string', '=', '.', 'join', '(', '[', '.', 'join', '(', 'pair', ')', 'for', 'pair', 'in', 'pairs_sorted', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "digest = hmac . new ( self . key , b ( pairs_string ) , hashlib . sha1 ) . digest ( ) \n"
Original    (024): ['digest', '=', 'hmac', '.', 'new', '(', 'self', '.', 'key', ',', 'b', '(', 'pairs_string', ')', ',', 'hashlib', '.', 'sha1', ')', '.', 'digest', '(', ')', '\\n']
Tokenized   (032): ['[CLS]', 'digest', '=', 'hm', '##ac', '.', 'new', '(', 'self', '.', 'key', ',', 'b', '(', 'pairs', '_', 'string', ')', ',', 'hash', '##lib', '.', 'sha', '##1', ')', '.', 'digest', '(', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['digest', '=', 'hm', '##ac', '.', 'new', '(', 'self', '.', 'key', ',', 'b', '(', 'pairs', '_', 'string', ')', ',', 'hash', '##lib', '.', 'sha', '##1', ')', '.', 'digest', '(', ')', '\\', 'n']
Detokenized (024): ['digest', '=', 'hm##ac', '.', 'new', '(', 'self', '.', 'key', ',', 'b', '(', 'pairs_string', ')', ',', 'hash##lib', '.', 'sha##1', ')', '.', 'digest', '(', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "signature = ( [ unquote ( v ) for k , v in pairs if k == ] or [ None ] ) [ 0 ] \n"
Original    (027): ['signature', '=', '(', '[', 'unquote', '(', 'v', ')', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '==', ']', 'or', '[', 'None', ']', ')', '[', '0', ']', '\\n']
Tokenized   (033): ['[CLS]', 'signature', '=', '(', '[', 'un', '##qu', '##ote', '(', 'v', ')', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '=', '=', ']', 'or', '[', 'none', ']', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (031): ['signature', '=', '(', '[', 'un', '##qu', '##ote', '(', 'v', ')', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '=', '=', ']', 'or', '[', 'none', ']', ')', '[', '0', ']', '\\', 'n']
Detokenized (027): ['signature', '=', '(', '[', 'un##qu##ote', '(', 'v', ')', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '==', ']', 'or', '[', 'none', ']', ')', '[', '0', ']', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "query_string = . join ( [ k + + v for k , v in pairs if k != ] ) \n"
Original    (022): ['query_string', '=', '.', 'join', '(', '[', 'k', '+', '+', 'v', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '!=', ']', ')', '\\n']
Tokenized   (028): ['[CLS]', 'query', '_', 'string', '=', '.', 'join', '(', '[', 'k', '+', '+', 'v', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '!', '=', ']', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['query', '_', 'string', '=', '.', 'join', '(', '[', 'k', '+', '+', 'v', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '!', '=', ']', ')', '\\', 'n']
Detokenized (022): ['query_string', '=', '.', 'join', '(', '[', 'k', '+', '+', 'v', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '!=', ']', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "pairs = ( x . split ( , 1 ) for x in query_string . split ( ) ) \n"
Original    (020): ['pairs', '=', '(', 'x', '.', 'split', '(', ',', '1', ')', 'for', 'x', 'in', 'query_string', '.', 'split', '(', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'pairs', '=', '(', 'x', '.', 'split', '(', ',', '1', ')', 'for', 'x', 'in', 'query', '_', 'string', '.', 'split', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['pairs', '=', '(', 'x', '.', 'split', '(', ',', '1', ')', 'for', 'x', 'in', 'query', '_', 'string', '.', 'split', '(', ')', ')', '\\', 'n']
Detokenized (020): ['pairs', '=', '(', 'x', '.', 'split', '(', ',', '1', ')', 'for', 'x', 'in', 'query_string', '.', 'split', '(', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "py_modules = [ ] , \n"
Original    (006): ['py_modules', '=', '[', ']', ',', '\\n']
Tokenized   (012): ['[CLS]', 'p', '##y', '_', 'modules', '=', '[', ']', ',', '\\', 'n', '[SEP]']
Filtered   (010): ['p', '##y', '_', 'modules', '=', '[', ']', ',', '\\', 'n']
Detokenized (006): ['p##y_modules', '=', '[', ']', ',', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "submitter , msg = result [ 0 ] \n"
Original    (009): ['submitter', ',', 'msg', '=', 'result', '[', '0', ']', '\\n']
Tokenized   (014): ['[CLS]', 'submit', '##ter', ',', 'ms', '##g', '=', 'result', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['submit', '##ter', ',', 'ms', '##g', '=', 'result', '[', '0', ']', '\\', 'n']
Detokenized (009): ['submit##ter', ',', 'ms##g', '=', 'result', '[', '0', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "contact = self . line_interface . _get_contact_by_id ( me . id ) \n"
Original    (013): ['contact', '=', 'self', '.', 'line_interface', '.', '_get_contact_by_id', '(', 'me', '.', 'id', ')', '\\n']
Tokenized   (025): ['[CLS]', 'contact', '=', 'self', '.', 'line', '_', 'interface', '.', '_', 'get', '_', 'contact', '_', 'by', '_', 'id', '(', 'me', '.', 'id', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['contact', '=', 'self', '.', 'line', '_', 'interface', '.', '_', 'get', '_', 'contact', '_', 'by', '_', 'id', '(', 'me', '.', 'id', ')', '\\', 'n']
Detokenized (013): ['contact', '=', 'self', '.', 'line_interface', '.', '_get_contact_by_id', '(', 'me', '.', 'id', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ok_ ( me_display_name == me . name ) \n"
Original    (009): ['ok_', '(', 'me_display_name', '==', 'me', '.', 'name', ')', '\\n']
Tokenized   (018): ['[CLS]', 'ok', '_', '(', 'me', '_', 'display', '_', 'name', '=', '=', 'me', '.', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['ok', '_', '(', 'me', '_', 'display', '_', 'name', '=', '=', 'me', '.', 'name', ')', '\\', 'n']
Detokenized (009): ['ok_', '(', 'me_display_name', '==', 'me', '.', 'name', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "transport . get_extra_info . return_value = None \n"
Original    (008): ['transport', '.', 'get_extra_info', '.', 'return_value', '=', 'None', '\\n']
Tokenized   (017): ['[CLS]', 'transport', '.', 'get', '_', 'extra', '_', 'info', '.', 'return', '_', 'value', '=', 'none', '\\', 'n', '[SEP]']
Filtered   (015): ['transport', '.', 'get', '_', 'extra', '_', 'info', '.', 'return', '_', 'value', '=', 'none', '\\', 'n']
Detokenized (008): ['transport', '.', 'get_extra_info', '.', 'return_value', '=', 'none', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ShortenerSettings = namedtuple ( , [ \n"
Original    (007): ['ShortenerSettings', '=', 'namedtuple', '(', ',', '[', '\\n']
Tokenized   (015): ['[CLS]', 'short', '##ener', '##sett', '##ings', '=', 'named', '##tu', '##ple', '(', ',', '[', '\\', 'n', '[SEP]']
Filtered   (013): ['short', '##ener', '##sett', '##ings', '=', 'named', '##tu', '##ple', '(', ',', '[', '\\', 'n']
Detokenized (007): ['short##ener##sett##ings', '=', 'named##tu##ple', '(', ',', '[', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "right_to_left = [ , ] , \n"
Original    (007): ['right_to_left', '=', '[', ',', ']', ',', '\\n']
Tokenized   (014): ['[CLS]', 'right', '_', 'to', '_', 'left', '=', '[', ',', ']', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['right', '_', 'to', '_', 'left', '=', '[', ',', ']', ',', '\\', 'n']
Detokenized (007): ['right_to_left', '=', '[', ',', ']', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "shortener = { } , \n"
Original    (006): ['shortener', '=', '{', '}', ',', '\\n']
Tokenized   (010): ['[CLS]', 'short', '##ener', '=', '{', '}', ',', '\\', 'n', '[SEP]']
Filtered   (008): ['short', '##ener', '=', '{', '}', ',', '\\', 'n']
Detokenized (006): ['short##ener', '=', '{', '}', ',', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "workers_pool = 10 , \n"
Original    (005): ['workers_pool', '=', '10', ',', '\\n']
Tokenized   (010): ['[CLS]', 'workers', '_', 'pool', '=', '10', ',', '\\', 'n', '[SEP]']
Filtered   (008): ['workers', '_', 'pool', '=', '10', ',', '\\', 'n']
Detokenized (005): ['workers_pool', '=', '10', ',', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "cms_service_host = "http://localhost:5001" \n"
Original    (004): ['cms_service_host', '=', '"http://localhost:5001"', '\\n']
Tokenized   (023): ['[CLS]', 'cm', '##s', '_', 'service', '_', 'host', '=', '"', 'http', ':', '/', '/', 'local', '##hos', '##t', ':', '500', '##1', '"', '\\', 'n', '[SEP]']
Filtered   (021): ['cm', '##s', '_', 'service', '_', 'host', '=', '"', 'http', ':', '/', '/', 'local', '##hos', '##t', ':', '500', '##1', '"', '\\', 'n']
Detokenized (004): ['cm##s_service_host', '=', '"http://local##hos##t:500##1"', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "subparsers = args . add_subparsers ( help = , dest = ) \n"
Original    (013): ['subparsers', '=', 'args', '.', 'add_subparsers', '(', 'help', '=', ',', 'dest', '=', ')', '\\n']
Tokenized   (026): ['[CLS]', 'sub', '##par', '##ser', '##s', '=', 'ar', '##gs', '.', 'add', '_', 'sub', '##par', '##ser', '##s', '(', 'help', '=', ',', 'des', '##t', '=', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['sub', '##par', '##ser', '##s', '=', 'ar', '##gs', '.', 'add', '_', 'sub', '##par', '##ser', '##s', '(', 'help', '=', ',', 'des', '##t', '=', ')', '\\', 'n']
Detokenized (013): ['sub##par##ser##s', '=', 'ar##gs', '.', 'add_sub##par##ser##s', '(', 'help', '=', ',', 'des##t', '=', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "template_parser . add_argument ( , \n"
Original    (006): ['template_parser', '.', 'add_argument', '(', ',', '\\n']
Tokenized   (014): ['[CLS]', 'template', '_', 'par', '##ser', '.', 'add', '_', 'argument', '(', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['template', '_', 'par', '##ser', '.', 'add', '_', 'argument', '(', ',', '\\', 'n']
Detokenized (006): ['template_par##ser', '.', 'add_argument', '(', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "config_parser . add_argument ( , help = ) \n"
Original    (009): ['config_parser', '.', 'add_argument', '(', ',', 'help', '=', ')', '\\n']
Tokenized   (019): ['[CLS]', 'con', '##fi', '##g', '_', 'par', '##ser', '.', 'add', '_', 'argument', '(', ',', 'help', '=', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['con', '##fi', '##g', '_', 'par', '##ser', '.', 'add', '_', 'argument', '(', ',', 'help', '=', ')', '\\', 'n']
Detokenized (009): ['con##fi##g_par##ser', '.', 'add_argument', '(', ',', 'help', '=', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "gui_parser . add_argument ( , , type = str , help = ) \n"
Original    (014): ['gui_parser', '.', 'add_argument', '(', ',', ',', 'type', '=', 'str', ',', 'help', '=', ')', '\\n']
Tokenized   (023): ['[CLS]', 'gui', '_', 'par', '##ser', '.', 'add', '_', 'argument', '(', ',', ',', 'type', '=', 'st', '##r', ',', 'help', '=', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['gui', '_', 'par', '##ser', '.', 'add', '_', 'argument', '(', ',', ',', 'type', '=', 'st', '##r', ',', 'help', '=', ')', '\\', 'n']
Detokenized (014): ['gui_par##ser', '.', 'add_argument', '(', ',', ',', 'type', '=', 'st##r', ',', 'help', '=', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "changePwdResult = conn . extend . microsoft . modify_password ( user_dn , newpassword ) \n"
Original    (015): ['changePwdResult', '=', 'conn', '.', 'extend', '.', 'microsoft', '.', 'modify_password', '(', 'user_dn', ',', 'newpassword', ')', '\\n']
Tokenized   (030): ['[CLS]', 'change', '##pw', '##dre', '##sul', '##t', '=', 'con', '##n', '.', 'extend', '.', 'microsoft', '.', 'modify', '_', 'password', '(', 'user', '_', 'd', '##n', ',', 'new', '##pass', '##word', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['change', '##pw', '##dre', '##sul', '##t', '=', 'con', '##n', '.', 'extend', '.', 'microsoft', '.', 'modify', '_', 'password', '(', 'user', '_', 'd', '##n', ',', 'new', '##pass', '##word', ')', '\\', 'n']
Detokenized (015): ['change##pw##dre##sul##t', '=', 'con##n', '.', 'extend', '.', 'microsoft', '.', 'modify_password', '(', 'user_d##n', ',', 'new##pass##word', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "cap_path = os . path . join ( caps_directory , ) \n"
Original    (012): ['cap_path', '=', 'os', '.', 'path', '.', 'join', '(', 'caps_directory', ',', ')', '\\n']
Tokenized   (019): ['[CLS]', 'cap', '_', 'path', '=', 'os', '.', 'path', '.', 'join', '(', 'caps', '_', 'directory', ',', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['cap', '_', 'path', '=', 'os', '.', 'path', '.', 'join', '(', 'caps', '_', 'directory', ',', ')', '\\', 'n']
Detokenized (012): ['cap_path', '=', 'os', '.', 'path', '.', 'join', '(', 'caps_directory', ',', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "cap . eventloop . stop ( ) \n"
Original    (008): ['cap', '.', 'eventloop', '.', 'stop', '(', ')', '\\n']
Tokenized   (013): ['[CLS]', 'cap', '.', 'event', '##lo', '##op', '.', 'stop', '(', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['cap', '.', 'event', '##lo', '##op', '.', 'stop', '(', ')', '\\', 'n']
Detokenized (008): ['cap', '.', 'event##lo##op', '.', 'stop', '(', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "flush = Service ( name = , \n"
Original    (008): ['flush', '=', 'Service', '(', 'name', '=', ',', '\\n']
Tokenized   (011): ['[CLS]', 'flush', '=', 'service', '(', 'name', '=', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['flush', '=', 'service', '(', 'name', '=', ',', '\\', 'n']
Detokenized (008): ['flush', '=', 'service', '(', 'name', '=', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sourceIds = [ d [ ] for d in response . json ] \n"
Original    (014): ['sourceIds', '=', '[', 'd', '[', ']', 'for', 'd', 'in', 'response', '.', 'json', ']', '\\n']
Tokenized   (019): ['[CLS]', 'source', '##ids', '=', '[', 'd', '[', ']', 'for', 'd', 'in', 'response', '.', 'j', '##son', ']', '\\', 'n', '[SEP]']
Filtered   (017): ['source', '##ids', '=', '[', 'd', '[', ']', 'for', 'd', 'in', 'response', '.', 'j', '##son', ']', '\\', 'n']
Detokenized (014): ['source##ids', '=', '[', 'd', '[', ']', 'for', 'd', 'in', 'response', '.', 'j##son', ']', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""folder." ) \n"
Original    (003): ['"folder."', ')', '\\n']
Tokenized   (009): ['[CLS]', '"', 'folder', '.', '"', ')', '\\', 'n', '[SEP]']
Filtered   (007): ['"', 'folder', '.', '"', ')', '\\', 'n']
Detokenized (003): ['"folder."', ')', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "minerva_metadata [ ] = { \n"
Original    (006): ['minerva_metadata', '[', ']', '=', '{', '\\n']
Tokenized   (011): ['[CLS]', 'minerva', '_', 'metadata', '[', ']', '=', '{', '\\', 'n', '[SEP]']
Filtered   (009): ['minerva', '_', 'metadata', '[', ']', '=', '{', '\\', 'n']
Detokenized (006): ['minerva_metadata', '[', ']', '=', '{', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "Description ( ) \n"
Original    (004): ['Description', '(', ')', '\\n']
Tokenized   (007): ['[CLS]', 'description', '(', ')', '\\', 'n', '[SEP]']
Filtered   (005): ['description', '(', ')', '\\', 'n']
Detokenized (004): ['description', '(', ')', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "matches = re . findall ( "(\'|\\")(\\S+)(\'|\\")" , text ) \n"
Original    (011): ['matches', '=', 're', '.', 'findall', '(', '"(\\\'|\\\\")(\\\\S+)(\\\'|\\\\")"', ',', 'text', ')', '\\n']
Tokenized   (038): ['[CLS]', 'matches', '=', 're', '.', 'find', '##all', '(', '"', '(', '\\', "'", '|', '\\', '\\', '"', ')', '(', '\\', '\\', 's', '+', ')', '(', '\\', "'", '|', '\\', '\\', '"', ')', '"', ',', 'text', ')', '\\', 'n', '[SEP]']
Filtered   (036): ['matches', '=', 're', '.', 'find', '##all', '(', '"', '(', '\\', "'", '|', '\\', '\\', '"', ')', '(', '\\', '\\', 's', '+', ')', '(', '\\', "'", '|', '\\', '\\', '"', ')', '"', ',', 'text', ')', '\\', 'n']
Detokenized (011): ['matches', '=', 're', '.', 'find##all', '(', '"(\\\'|\\\\")(\\\\s+)(\\\'|\\\\")"', ',', 'text', ')', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "package_data = { : [ ] } , \n"
Original    (009): ['package_data', '=', '{', ':', '[', ']', '}', ',', '\\n']
Tokenized   (014): ['[CLS]', 'package', '_', 'data', '=', '{', ':', '[', ']', '}', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['package', '_', 'data', '=', '{', ':', '[', ']', '}', ',', '\\', 'n']
Detokenized (009): ['package_data', '=', '{', ':', '[', ']', '}', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "list_permissions = [ , , , ] \n"
Original    (008): ['list_permissions', '=', '[', ',', ',', ',', ']', '\\n']
Tokenized   (014): ['[CLS]', 'list', '_', 'permission', '##s', '=', '[', ',', ',', ',', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['list', '_', 'permission', '##s', '=', '[', ',', ',', ',', ']', '\\', 'n']
Detokenized (008): ['list_permission##s', '=', '[', ',', ',', ',', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "option_list = BaseCommand . option_list + ( \n"
Original    (008): ['option_list', '=', 'BaseCommand', '.', 'option_list', '+', '(', '\\n']
Tokenized   (018): ['[CLS]', 'option', '_', 'list', '=', 'base', '##com', '##man', '##d', '.', 'option', '_', 'list', '+', '(', '\\', 'n', '[SEP]']
Filtered   (016): ['option', '_', 'list', '=', 'base', '##com', '##man', '##d', '.', 'option', '_', 'list', '+', '(', '\\', 'n']
Detokenized (008): ['option_list', '=', 'base##com##man##d', '.', 'option_list', '+', '(', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "make_option ( , \n"
Original    (004): ['make_option', '(', ',', '\\n']
Tokenized   (009): ['[CLS]', 'make', '_', 'option', '(', ',', '\\', 'n', '[SEP]']
Filtered   (007): ['make', '_', 'option', '(', ',', '\\', 'n']
Detokenized (004): ['make_option', '(', ',', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "confirm_token = Column ( Unicode ( 100 ) ) \n"
Original    (010): ['confirm_token', '=', 'Column', '(', 'Unicode', '(', '100', ')', ')', '\\n']
Tokenized   (015): ['[CLS]', 'confirm', '_', 'token', '=', 'column', '(', 'unicode', '(', '100', ')', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['confirm', '_', 'token', '=', 'column', '(', 'unicode', '(', '100', ')', ')', '\\', 'n']
Detokenized (010): ['confirm_token', '=', 'column', '(', 'unicode', '(', '100', ')', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "creation_date = Column ( DateTime ( ) , nullable = False ) \n"
Original    (013): ['creation_date', '=', 'Column', '(', 'DateTime', '(', ')', ',', 'nullable', '=', 'False', ')', '\\n']
Tokenized   (020): ['[CLS]', 'creation', '_', 'date', '=', 'column', '(', 'date', '##time', '(', ')', ',', 'null', '##able', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['creation', '_', 'date', '=', 'column', '(', 'date', '##time', '(', ')', ',', 'null', '##able', '=', 'false', ')', '\\', 'n']
Detokenized (013): ['creation_date', '=', 'column', '(', 'date##time', '(', ')', ',', 'null##able', '=', 'false', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "last_login_date = Column ( DateTime ( ) ) \n"
Original    (009): ['last_login_date', '=', 'Column', '(', 'DateTime', '(', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'last', '_', 'log', '##in', '_', 'date', '=', 'column', '(', 'date', '##time', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['last', '_', 'log', '##in', '_', 'date', '=', 'column', '(', 'date', '##time', '(', ')', ')', '\\', 'n']
Detokenized (009): ['last_log##in_date', '=', 'column', '(', 'date##time', '(', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "SHARING_ROLES = [ , , ] \n"
Original    (007): ['SHARING_ROLES', '=', '[', ',', ',', ']', '\\n']
Tokenized   (012): ['[CLS]', 'sharing', '_', 'roles', '=', '[', ',', ',', ']', '\\', 'n', '[SEP]']
Filtered   (010): ['sharing', '_', 'roles', '=', '[', ',', ',', ']', '\\', 'n']
Detokenized (007): ['sharing_roles', '=', '[', ',', ',', ']', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "USER_MANAGEMENT_ROLES = SHARING_ROLES + [ ] \n"
Original    (007): ['USER_MANAGEMENT_ROLES', '=', 'SHARING_ROLES', '+', '[', ']', '\\n']
Tokenized   (016): ['[CLS]', 'user', '_', 'management', '_', 'roles', '=', 'sharing', '_', 'roles', '+', '[', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['user', '_', 'management', '_', 'roles', '=', 'sharing', '_', 'roles', '+', '[', ']', '\\', 'n']
Detokenized (007): ['user_management_roles', '=', 'sharing_roles', '+', '[', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_DEFAULT_SHARING_ROLES = SHARING_ROLES [ : ] \n"
Original    (007): ['_DEFAULT_SHARING_ROLES', '=', 'SHARING_ROLES', '[', ':', ']', '\\n']
Tokenized   (017): ['[CLS]', '_', 'default', '_', 'sharing', '_', 'roles', '=', 'sharing', '_', 'roles', '[', ':', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['_', 'default', '_', 'sharing', '_', 'roles', '=', 'sharing', '_', 'roles', '[', ':', ']', '\\', 'n']
Detokenized (007): ['_default_sharing_roles', '=', 'sharing_roles', '[', ':', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "principal = get_principals ( ) . get ( name ) \n"
Original    (011): ['principal', '=', 'get_principals', '(', ')', '.', 'get', '(', 'name', ')', '\\n']
Tokenized   (016): ['[CLS]', 'principal', '=', 'get', '_', 'principals', '(', ')', '.', 'get', '(', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['principal', '=', 'get', '_', 'principals', '(', ')', '.', 'get', '(', 'name', ')', '\\', 'n']
Detokenized (011): ['principal', '=', 'get_principals', '(', ')', '.', 'get', '(', 'name', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "lg for lg in context . local_groups \n"
Original    (008): ['lg', 'for', 'lg', 'in', 'context', '.', 'local_groups', '\\n']
Tokenized   (015): ['[CLS]', 'l', '##g', 'for', 'l', '##g', 'in', 'context', '.', 'local', '_', 'groups', '\\', 'n', '[SEP]']
Filtered   (013): ['l', '##g', 'for', 'l', '##g', 'in', 'context', '.', 'local', '_', 'groups', '\\', 'n']
Detokenized (008): ['l##g', 'for', 'l##g', 'in', 'context', '.', 'local_groups', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "LocalGroup ( context , name , unicode ( group_name ) ) \n"
Original    (012): ['LocalGroup', '(', 'context', ',', 'name', ',', 'unicode', '(', 'group_name', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'local', '##group', '(', 'context', ',', 'name', ',', 'unicode', '(', 'group', '_', 'name', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['local', '##group', '(', 'context', ',', 'name', ',', 'unicode', '(', 'group', '_', 'name', ')', ')', '\\', 'n']
Detokenized (012): ['local##group', '(', 'context', ',', 'name', ',', 'unicode', '(', 'group_name', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "filters . append ( func . lower ( col ) . like ( value ) ) \n"
Original    (017): ['filters', '.', 'append', '(', 'func', '.', 'lower', '(', 'col', ')', '.', 'like', '(', 'value', ')', ')', '\\n']
Tokenized   (022): ['[CLS]', 'filters', '.', 'app', '##end', '(', 'fun', '##c', '.', 'lower', '(', 'col', ')', '.', 'like', '(', 'value', ')', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['filters', '.', 'app', '##end', '(', 'fun', '##c', '.', 'lower', '(', 'col', ')', '.', 'like', '(', 'value', ')', ')', '\\', 'n']
Detokenized (017): ['filters', '.', 'app##end', '(', 'fun##c', '.', 'lower', '(', 'col', ')', '.', 'like', '(', 'value', ')', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "bcrypt . hashpw ( password . encode ( ) , hashed . encode ( ) ) ) \n"
Original    (018): ['bcrypt', '.', 'hashpw', '(', 'password', '.', 'encode', '(', ')', ',', 'hashed', '.', 'encode', '(', ')', ')', ')', '\\n']
Tokenized   (027): ['[CLS]', 'bc', '##ry', '##pt', '.', 'hash', '##pw', '(', 'password', '.', 'en', '##code', '(', ')', ',', 'hash', '##ed', '.', 'en', '##code', '(', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['bc', '##ry', '##pt', '.', 'hash', '##pw', '(', 'password', '.', 'en', '##code', '(', ')', ',', 'hash', '##ed', '.', 'en', '##code', '(', ')', ')', ')', '\\', 'n']
Detokenized (018): ['bc##ry##pt', '.', 'hash##pw', '(', 'password', '.', 'en##code', '(', ')', ',', 'hash##ed', '.', 'en##code', '(', ')', ')', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "browser . open ( . format ( BASE_URL ) ) \n"
Original    (011): ['browser', '.', 'open', '(', '.', 'format', '(', 'BASE_URL', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 'browser', '.', 'open', '(', '.', 'format', '(', 'base', '_', 'ur', '##l', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['browser', '.', 'open', '(', '.', 'format', '(', 'base', '_', 'ur', '##l', ')', ')', '\\', 'n']
Detokenized (011): ['browser', '.', 'open', '(', '.', 'format', '(', 'base_ur##l', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "AUTHORS = open ( os . path . join ( here , ) ) . read ( ) \n"
Original    (019): ['AUTHORS', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (022): ['[CLS]', 'authors', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ')', '.', 'read', '(', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['authors', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ')', '.', 'read', '(', ')', '\\', 'n']
Detokenized (019): ['authors', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ')', '.', 'read', '(', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "fixed_boxes ) : \n"
Original    (004): ['fixed_boxes', ')', ':', '\\n']
Tokenized   (009): ['[CLS]', 'fixed', '_', 'boxes', ')', ':', '\\', 'n', '[SEP]']
Filtered   (007): ['fixed', '_', 'boxes', ')', ':', '\\', 'n']
Detokenized (004): ['fixed_boxes', ')', ':', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "resolve_percentages ( box , ( containing_block . width , containing_block . height ) ) \n"
Original    (015): ['resolve_percentages', '(', 'box', ',', '(', 'containing_block', '.', 'width', ',', 'containing_block', '.', 'height', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'resolve', '_', 'percentage', '##s', '(', 'box', ',', '(', 'containing', '_', 'block', '.', 'width', ',', 'containing', '_', 'block', '.', 'height', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['resolve', '_', 'percentage', '##s', '(', 'box', ',', '(', 'containing', '_', 'block', '.', 'width', ',', 'containing', '_', 'block', '.', 'height', ')', ')', '\\', 'n']
Detokenized (015): ['resolve_percentage##s', '(', 'box', ',', '(', 'containing_block', '.', 'width', ',', 'containing_block', '.', 'height', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "box , _ , _ , _ , _ = block_container_layout ( \n"
Original    (013): ['box', ',', '_', ',', '_', ',', '_', ',', '_', '=', 'block_container_layout', '(', '\\n']
Tokenized   (020): ['[CLS]', 'box', ',', '_', ',', '_', ',', '_', ',', '_', '=', 'block', '_', 'container', '_', 'layout', '(', '\\', 'n', '[SEP]']
Filtered   (018): ['box', ',', '_', ',', '_', ',', '_', ',', '_', '=', 'block', '_', 'container', '_', 'layout', '(', '\\', 'n']
Detokenized (013): ['box', ',', '_', ',', '_', ',', '_', ',', '_', '=', 'block_container_layout', '(', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "skip_stack = None , device_size = device_size , page_is_empty = False , \n"
Original    (013): ['skip_stack', '=', 'None', ',', 'device_size', '=', 'device_size', ',', 'page_is_empty', '=', 'False', ',', '\\n']
Tokenized   (026): ['[CLS]', 'skip', '_', 'stack', '=', 'none', ',', 'device', '_', 'size', '=', 'device', '_', 'size', ',', 'page', '_', 'is', '_', 'empty', '=', 'false', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['skip', '_', 'stack', '=', 'none', ',', 'device', '_', 'size', '=', 'device', '_', 'size', ',', 'page', '_', 'is', '_', 'empty', '=', 'false', ',', '\\', 'n']
Detokenized (013): ['skip_stack', '=', 'none', ',', 'device_size', '=', 'device_size', ',', 'page_is_empty', '=', 'false', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "list_marker_layout ( context , box ) \n"
Original    (007): ['list_marker_layout', '(', 'context', ',', 'box', ')', '\\n']
Tokenized   (014): ['[CLS]', 'list', '_', 'marker', '_', 'layout', '(', 'context', ',', 'box', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['list', '_', 'marker', '_', 'layout', '(', 'context', ',', 'box', ')', '\\', 'n']
Detokenized (007): ['list_marker_layout', '(', 'context', ',', 'box', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "hypothetical_position = box . position_y + collapsed_margin \n"
Original    (008): ['hypothetical_position', '=', 'box', '.', 'position_y', '+', 'collapsed_margin', '\\n']
Tokenized   (017): ['[CLS]', 'hypothetical', '_', 'position', '=', 'box', '.', 'position', '_', 'y', '+', 'collapsed', '_', 'margin', '\\', 'n', '[SEP]']
Filtered   (015): ['hypothetical', '_', 'position', '=', 'box', '.', 'position', '_', 'y', '+', 'collapsed', '_', 'margin', '\\', 'n']
Detokenized (008): ['hypothetical_position', '=', 'box', '.', 'position_y', '+', 'collapsed_margin', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "box_width = box . margin_width ( ) if outer else box . border_width ( ) \n"
Original    (016): ['box_width', '=', 'box', '.', 'margin_width', '(', ')', 'if', 'outer', 'else', 'box', '.', 'border_width', '(', ')', '\\n']
Tokenized   (025): ['[CLS]', 'box', '_', 'width', '=', 'box', '.', 'margin', '_', 'width', '(', ')', 'if', 'outer', 'else', 'box', '.', 'border', '_', 'width', '(', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['box', '_', 'width', '=', 'box', '.', 'margin', '_', 'width', '(', ')', 'if', 'outer', 'else', 'box', '.', 'border', '_', 'width', '(', ')', '\\', 'n']
Detokenized (016): ['box_width', '=', 'box', '.', 'margin_width', '(', ')', 'if', 'outer', 'else', 'box', '.', 'border_width', '(', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "max_right_bound -= box . margin_right \n"
Original    (006): ['max_right_bound', '-=', 'box', '.', 'margin_right', '\\n']
Tokenized   (016): ['[CLS]', 'max', '_', 'right', '_', 'bound', '-', '=', 'box', '.', 'margin', '_', 'right', '\\', 'n', '[SEP]']
Filtered   (014): ['max', '_', 'right', '_', 'bound', '-', '=', 'box', '.', 'margin', '_', 'right', '\\', 'n']
Detokenized (006): ['max_right_bound', '-=', 'box', '.', 'margin_right', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "shape . position_y + shape . margin_height ( ) \n"
Original    (010): ['shape', '.', 'position_y', '+', 'shape', '.', 'margin_height', '(', ')', '\\n']
Tokenized   (017): ['[CLS]', 'shape', '.', 'position', '_', 'y', '+', 'shape', '.', 'margin', '_', 'height', '(', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['shape', '.', 'position', '_', 'y', '+', 'shape', '.', 'margin', '_', 'height', '(', ')', '\\', 'n']
Detokenized (010): ['shape', '.', 'position_y', '+', 'shape', '.', 'margin_height', '(', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "urlpatterns = patterns ( , \n"
Original    (006): ['urlpatterns', '=', 'patterns', '(', ',', '\\n']
Tokenized   (012): ['[CLS]', 'ur', '##lp', '##atter', '##ns', '=', 'patterns', '(', ',', '\\', 'n', '[SEP]']
Filtered   (010): ['ur', '##lp', '##atter', '##ns', '=', 'patterns', '(', ',', '\\', 'n']
Detokenized (006): ['ur##lp##atter##ns', '=', 'patterns', '(', ',', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "obj1 , obj2 = qs \n"
Original    (006): ['obj1', ',', 'obj2', '=', 'qs', '\\n']
Tokenized   (014): ['[CLS]', 'ob', '##j', '##1', ',', 'ob', '##j', '##2', '=', 'q', '##s', '\\', 'n', '[SEP]']
Filtered   (012): ['ob', '##j', '##1', ',', 'ob', '##j', '##2', '=', 'q', '##s', '\\', 'n']
Detokenized (006): ['ob##j##1', ',', 'ob##j##2', '=', 'q##s', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "n1 = Normal . objects . language ( ) . get ( pk = self . normal_id [ 1 ] ) \n"
Original    (022): ['n1', '=', 'Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'pk', '=', 'self', '.', 'normal_id', '[', '1', ']', ')', '\\n']
Tokenized   (029): ['[CLS]', 'n', '##1', '=', 'normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'p', '##k', '=', 'self', '.', 'normal', '_', 'id', '[', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['n', '##1', '=', 'normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'p', '##k', '=', 'self', '.', 'normal', '_', 'id', '[', '1', ']', ')', '\\', 'n']
Detokenized (022): ['n##1', '=', 'normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'p##k', '=', 'self', '.', 'normal_id', '[', '1', ']', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "shared_field = NEW_SHARED , translated_field = NEW_TRANSLATED \n"
Original    (008): ['shared_field', '=', 'NEW_SHARED', ',', 'translated_field', '=', 'NEW_TRANSLATED', '\\n']
Tokenized   (019): ['[CLS]', 'shared', '_', 'field', '=', 'new', '_', 'shared', ',', 'translated', '_', 'field', '=', 'new', '_', 'translated', '\\', 'n', '[SEP]']
Filtered   (017): ['shared', '_', 'field', '=', 'new', '_', 'shared', ',', 'translated', '_', 'field', '=', 'new', '_', 'translated', '\\', 'n']
Detokenized (008): ['shared_field', '=', 'new_shared', ',', 'translated_field', '=', 'new_translated', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "NORMAL [ 2 ] . shared_field ] ) \n"
Original    (009): ['NORMAL', '[', '2', ']', '.', 'shared_field', ']', ')', '\\n']
Tokenized   (014): ['[CLS]', 'normal', '[', '2', ']', '.', 'shared', '_', 'field', ']', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['normal', '[', '2', ']', '.', 'shared', '_', 'field', ']', ')', '\\', 'n']
Detokenized (009): ['normal', '[', '2', ']', '.', 'shared_field', ']', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "ja = Normal . objects . language ( ) . get ( pk = en . pk ) \n"
Original    (019): ['ja', '=', 'Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'pk', '=', 'en', '.', 'pk', ')', '\\n']
Tokenized   (024): ['[CLS]', 'ja', '=', 'normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'p', '##k', '=', 'en', '.', 'p', '##k', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['ja', '=', 'normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'p', '##k', '=', 'en', '.', 'p', '##k', ')', '\\', 'n']
Detokenized (019): ['ja', '=', 'normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'p##k', '=', 'en', '.', 'p##k', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "AggregateModel . objects . language ( "en" ) . create ( number = 0 , translated_number = 0 ) \n"
Original    (020): ['AggregateModel', '.', 'objects', '.', 'language', '(', '"en"', ')', '.', 'create', '(', 'number', '=', '0', ',', 'translated_number', '=', '0', ')', '\\n']
Tokenized   (029): ['[CLS]', 'aggregate', '##mo', '##del', '.', 'objects', '.', 'language', '(', '"', 'en', '"', ')', '.', 'create', '(', 'number', '=', '0', ',', 'translated', '_', 'number', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['aggregate', '##mo', '##del', '.', 'objects', '.', 'language', '(', '"', 'en', '"', ')', '.', 'create', '(', 'number', '=', '0', ',', 'translated', '_', 'number', '=', '0', ')', '\\', 'n']
Detokenized (020): ['aggregate##mo##del', '.', 'objects', '.', 'language', '(', '"en"', ')', '.', 'create', '(', 'number', '=', '0', ',', 'translated_number', '=', '0', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "shared_contains_two = Q ( shared_field__contains = ) \n"
Original    (008): ['shared_contains_two', '=', 'Q', '(', 'shared_field__contains', '=', ')', '\\n']
Tokenized   (020): ['[CLS]', 'shared', '_', 'contains', '_', 'two', '=', 'q', '(', 'shared', '_', 'field', '_', '_', 'contains', '=', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['shared', '_', 'contains', '_', 'two', '=', 'q', '(', 'shared', '_', 'field', '_', '_', 'contains', '=', ')', '\\', 'n']
Detokenized (008): ['shared_contains_two', '=', 'q', '(', 'shared_field__contains', '=', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "normal_one = Q ( normal_field = STANDARD [ 1 ] . normal_field ) \n"
Original    (014): ['normal_one', '=', 'Q', '(', 'normal_field', '=', 'STANDARD', '[', '1', ']', '.', 'normal_field', ')', '\\n']
Tokenized   (023): ['[CLS]', 'normal', '_', 'one', '=', 'q', '(', 'normal', '_', 'field', '=', 'standard', '[', '1', ']', '.', 'normal', '_', 'field', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['normal', '_', 'one', '=', 'q', '(', 'normal', '_', 'field', '=', 'standard', '[', '1', ']', '.', 'normal', '_', 'field', ')', '\\', 'n']
Detokenized (014): ['normal_one', '=', 'q', '(', 'normal_field', '=', 'standard', '[', '1', ']', '.', 'normal_field', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "shared_one = Q ( normal__shared_field = NORMAL [ STANDARD [ 1 ] . normal ] . shared_field ) \n"
Original    (019): ['shared_one', '=', 'Q', '(', 'normal__shared_field', '=', 'NORMAL', '[', 'STANDARD', '[', '1', ']', '.', 'normal', ']', '.', 'shared_field', ')', '\\n']
Tokenized   (031): ['[CLS]', 'shared', '_', 'one', '=', 'q', '(', 'normal', '_', '_', 'shared', '_', 'field', '=', 'normal', '[', 'standard', '[', '1', ']', '.', 'normal', ']', '.', 'shared', '_', 'field', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['shared', '_', 'one', '=', 'q', '(', 'normal', '_', '_', 'shared', '_', 'field', '=', 'normal', '[', 'standard', '[', '1', ']', '.', 'normal', ']', '.', 'shared', '_', 'field', ')', '\\', 'n']
Detokenized (019): ['shared_one', '=', 'q', '(', 'normal__shared_field', '=', 'normal', '[', 'standard', '[', '1', ']', '.', 'normal', ']', '.', 'shared_field', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "translated_one_en = Q ( normal__translated_field = NORMAL [ STANDARD [ 1 ] . normal ] . translated_field [ translated_two_en = Q ( normal__translated_field = NORMAL [ STANDARD [ 2 ] . normal ] . translated_field [ \n"
Original    (037): ['translated_one_en', '=', 'Q', '(', 'normal__translated_field', '=', 'NORMAL', '[', 'STANDARD', '[', '1', ']', '.', 'normal', ']', '.', 'translated_field', '[', 'translated_two_en', '=', 'Q', '(', 'normal__translated_field', '=', 'NORMAL', '[', 'STANDARD', '[', '2', ']', '.', 'normal', ']', '.', 'translated_field', '[', '\\n']
Tokenized   (062): ['[CLS]', 'translated', '_', 'one', '_', 'en', '=', 'q', '(', 'normal', '_', '_', 'translated', '_', 'field', '=', 'normal', '[', 'standard', '[', '1', ']', '.', 'normal', ']', '.', 'translated', '_', 'field', '[', 'translated', '_', 'two', '_', 'en', '=', 'q', '(', 'normal', '_', '_', 'translated', '_', 'field', '=', 'normal', '[', 'standard', '[', '2', ']', '.', 'normal', ']', '.', 'translated', '_', 'field', '[', '\\', 'n', '[SEP]']
Filtered   (060): ['translated', '_', 'one', '_', 'en', '=', 'q', '(', 'normal', '_', '_', 'translated', '_', 'field', '=', 'normal', '[', 'standard', '[', '1', ']', '.', 'normal', ']', '.', 'translated', '_', 'field', '[', 'translated', '_', 'two', '_', 'en', '=', 'q', '(', 'normal', '_', '_', 'translated', '_', 'field', '=', 'normal', '[', 'standard', '[', '2', ']', '.', 'normal', ']', '.', 'translated', '_', 'field', '[', '\\', 'n']
Detokenized (037): ['translated_one_en', '=', 'q', '(', 'normal__translated_field', '=', 'normal', '[', 'standard', '[', '1', ']', '.', 'normal', ']', '.', 'translated_field', '[', 'translated_two_en', '=', 'q', '(', 'normal__translated_field', '=', 'normal', '[', 'standard', '[', '2', ']', '.', 'normal', ']', '.', 'translated_field', '[', '\\n']
Counter: 60
===================================================================
Hidden states:  (13, 37, 768)
# Extracted words:  37
Sentence         : "qs = manager . filter ( shared_one & ~ translated_two_en ) \n"
Original    (012): ['qs', '=', 'manager', '.', 'filter', '(', 'shared_one', '&', '~', 'translated_two_en', ')', '\\n']
Tokenized   (022): ['[CLS]', 'q', '##s', '=', 'manager', '.', 'filter', '(', 'shared', '_', 'one', '&', '~', 'translated', '_', 'two', '_', 'en', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['q', '##s', '=', 'manager', '.', 'filter', '(', 'shared', '_', 'one', '&', '~', 'translated', '_', 'two', '_', 'en', ')', '\\', 'n']
Detokenized (012): ['q##s', '=', 'manager', '.', 'filter', '(', 'shared_one', '&', '~', 'translated_two_en', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Normal . objects . language ( ) . complex_filter , \n"
Original    (011): ['Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'complex_filter', ',', '\\n']
Tokenized   (016): ['[CLS]', 'normal', '.', 'objects', '.', 'language', '(', ')', '.', 'complex', '_', 'filter', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['normal', '.', 'objects', '.', 'language', '(', ')', '.', 'complex', '_', 'filter', ',', '\\', 'n']
Detokenized (011): ['normal', '.', 'objects', '.', 'language', '(', ')', '.', 'complex_filter', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "analytics . track ( user_id , "Activate" , { \n"
Original    (010): ['analytics', '.', 'track', '(', 'user_id', ',', '"Activate"', ',', '{', '\\n']
Tokenized   (017): ['[CLS]', 'analytics', '.', 'track', '(', 'user', '_', 'id', ',', '"', 'activate', '"', ',', '{', '\\', 'n', '[SEP]']
Filtered   (015): ['analytics', '.', 'track', '(', 'user', '_', 'id', ',', '"', 'activate', '"', ',', '{', '\\', 'n']
Detokenized (010): ['analytics', '.', 'track', '(', 'user_id', ',', '"activate"', ',', '{', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sublime_plugin . WindowCommand . __init__ ( self , * args , ** kwargs ) \n"
Original    (015): ['sublime_plugin', '.', 'WindowCommand', '.', '__init__', '(', 'self', ',', '*', 'args', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (033): ['[CLS]', 'sublime', '_', 'plug', '##in', '.', 'window', '##com', '##man', '##d', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', '*', 'ar', '##gs', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['sublime', '_', 'plug', '##in', '.', 'window', '##com', '##man', '##d', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', '*', 'ar', '##gs', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n']
Detokenized (015): ['sublime_plug##in', '.', 'window##com##man##d', '.', '__in##it__', '(', 'self', ',', '*', 'ar##gs', ',', '**', 'kw##ar##gs', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : ""show_response" , { "title" : title , "text" : text } ) \n"
Original    (013): ['"show_response"', ',', '{', '"title"', ':', 'title', ',', '"text"', ':', 'text', '}', ')', '\\n']
Tokenized   (024): ['[CLS]', '"', 'show', '_', 'response', '"', ',', '{', '"', 'title', '"', ':', 'title', ',', '"', 'text', '"', ':', 'text', '}', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['"', 'show', '_', 'response', '"', ',', '{', '"', 'title', '"', ':', 'title', ',', '"', 'text', '"', ':', 'text', '}', ')', '\\', 'n']
Detokenized (013): ['"show_response"', ',', '{', '"title"', ':', 'title', ',', '"text"', ':', 'text', '}', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ensure_ascii = False \n"
Original    (004): ['ensure_ascii', '=', 'False', '\\n']
Tokenized   (011): ['[CLS]', 'ensure', '_', 'as', '##ci', '##i', '=', 'false', '\\', 'n', '[SEP]']
Filtered   (009): ['ensure', '_', 'as', '##ci', '##i', '=', 'false', '\\', 'n']
Detokenized (004): ['ensure_as##ci##i', '=', 'false', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "syntax = "Packages/JavaScript/JSON.tmLanguage" ) \n"
Original    (005): ['syntax', '=', '"Packages/JavaScript/JSON.tmLanguage"', ')', '\\n']
Tokenized   (022): ['[CLS]', 'syntax', '=', '"', 'packages', '/', 'java', '##script', '/', 'j', '##son', '.', 't', '##ml', '##ang', '##ua', '##ge', '"', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['syntax', '=', '"', 'packages', '/', 'java', '##script', '/', 'j', '##son', '.', 't', '##ml', '##ang', '##ua', '##ge', '"', ')', '\\', 'n']
Detokenized (005): ['syntax', '=', '"packages/java##script/j##son.t##ml##ang##ua##ge"', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "scroll = self . settings . scroll_size \n"
Original    (008): ['scroll', '=', 'self', '.', 'settings', '.', 'scroll_size', '\\n']
Tokenized   (013): ['[CLS]', 'scroll', '=', 'self', '.', 'settings', '.', 'scroll', '_', 'size', '\\', 'n', '[SEP]']
Filtered   (011): ['scroll', '=', 'self', '.', 'settings', '.', 'scroll', '_', 'size', '\\', 'n']
Detokenized (008): ['scroll', '=', 'self', '.', 'settings', '.', 'scroll_size', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""show_panel" , { "panel" : "output.elasticsearch" } ) \n"
Original    (009): ['"show_panel"', ',', '{', '"panel"', ':', '"output.elasticsearch"', '}', ')', '\\n']
Tokenized   (024): ['[CLS]', '"', 'show', '_', 'panel', '"', ',', '{', '"', 'panel', '"', ':', '"', 'output', '.', 'elastic', '##sea', '##rch', '"', '}', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['"', 'show', '_', 'panel', '"', ',', '{', '"', 'panel', '"', ':', '"', 'output', '.', 'elastic', '##sea', '##rch', '"', '}', ')', '\\', 'n']
Detokenized (009): ['"show_panel"', ',', '{', '"panel"', ':', '"output.elastic##sea##rch"', '}', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "panel . set_read_only ( True ) \n"
Original    (007): ['panel', '.', 'set_read_only', '(', 'True', ')', '\\n']
Tokenized   (014): ['[CLS]', 'panel', '.', 'set', '_', 'read', '_', 'only', '(', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['panel', '.', 'set', '_', 'read', '_', 'only', '(', 'true', ')', '\\', 'n']
Detokenized (007): ['panel', '.', 'set_read_only', '(', 'true', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "400 : RequestError , \n"
Original    (005): ['400', ':', 'RequestError', ',', '\\n']
Tokenized   (010): ['[CLS]', '400', ':', 'request', '##er', '##ror', ',', '\\', 'n', '[SEP]']
Filtered   (008): ['400', ':', 'request', '##er', '##ror', ',', '\\', 'n']
Detokenized (005): ['400', ':', 'request##er##ror', ',', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "TestConfigFileSource . ConcreteConfigFileSource ) \n"
Original    (005): ['TestConfigFileSource', '.', 'ConcreteConfigFileSource', ')', '\\n']
Tokenized   (022): ['[CLS]', 'test', '##con', '##fi', '##gf', '##ile', '##so', '##ur', '##ce', '.', 'concrete', '##con', '##fi', '##gf', '##ile', '##so', '##ur', '##ce', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['test', '##con', '##fi', '##gf', '##ile', '##so', '##ur', '##ce', '.', 'concrete', '##con', '##fi', '##gf', '##ile', '##so', '##ur', '##ce', ')', '\\', 'n']
Detokenized (005): ['test##con##fi##gf##ile##so##ur##ce', '.', 'concrete##con##fi##gf##ile##so##ur##ce', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "ReferenceReachabilityTester . TwoWayScopeReferenceAttacher . attach ( self . _scope_tree ) \n"
Original    (011): ['ReferenceReachabilityTester', '.', 'TwoWayScopeReferenceAttacher', '.', 'attach', '(', 'self', '.', '_scope_tree', ')', '\\n']
Tokenized   (029): ['[CLS]', 'reference', '##rea', '##cha', '##bility', '##test', '##er', '.', 'two', '##ways', '##cope', '##re', '##ference', '##att', '##ache', '##r', '.', 'attach', '(', 'self', '.', '_', 'scope', '_', 'tree', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['reference', '##rea', '##cha', '##bility', '##test', '##er', '.', 'two', '##ways', '##cope', '##re', '##ference', '##att', '##ache', '##r', '.', 'attach', '(', 'self', '.', '_', 'scope', '_', 'tree', ')', '\\', 'n']
Detokenized (011): ['reference##rea##cha##bility##test##er', '.', 'two##ways##cope##re##ference##att##ache##r', '.', 'attach', '(', 'self', '.', '_scope_tree', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "declaring_id_node [ REFERECED_FLAG ] = True \n"
Original    (007): ['declaring_id_node', '[', 'REFERECED_FLAG', ']', '=', 'True', '\\n']
Tokenized   (018): ['[CLS]', 'declaring', '_', 'id', '_', 'node', '[', 'refer', '##ece', '##d', '_', 'flag', ']', '=', 'true', '\\', 'n', '[SEP]']
Filtered   (016): ['declaring', '_', 'id', '_', 'node', '[', 'refer', '##ece', '##d', '_', 'flag', ']', '=', 'true', '\\', 'n']
Detokenized (007): ['declaring_id_node', '[', 'refer##ece##d_flag', ']', '=', 'true', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "node_type = NodeType ( node [ ] ) \n"
Original    (009): ['node_type', '=', 'NodeType', '(', 'node', '[', ']', ')', '\\n']
Tokenized   (015): ['[CLS]', 'node', '_', 'type', '=', 'node', '##type', '(', 'node', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['node', '_', 'type', '=', 'node', '##type', '(', 'node', '[', ']', ')', '\\', 'n']
Detokenized (009): ['node_type', '=', 'node##type', '(', 'node', '[', ']', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "is_set_cmd = excmd_node [ ] [ ] . get ( ) in SetCommandFamily \n"
Original    (014): ['is_set_cmd', '=', 'excmd_node', '[', ']', '[', ']', '.', 'get', '(', ')', 'in', 'SetCommandFamily', '\\n']
Tokenized   (031): ['[CLS]', 'is', '_', 'set', '_', 'cm', '##d', '=', 'ex', '##cm', '##d', '_', 'node', '[', ']', '[', ']', '.', 'get', '(', ')', 'in', 'set', '##com', '##man', '##df', '##ami', '##ly', '\\', 'n', '[SEP]']
Filtered   (029): ['is', '_', 'set', '_', 'cm', '##d', '=', 'ex', '##cm', '##d', '_', 'node', '[', ']', '[', ']', '.', 'get', '(', ')', 'in', 'set', '##com', '##man', '##df', '##ami', '##ly', '\\', 'n']
Detokenized (014): ['is_set_cm##d', '=', 'ex##cm##d_node', '[', ']', '[', ']', '.', 'get', '(', ')', 'in', 'set##com##man##df##ami##ly', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "option_name = re . match ( , option_expr ) . group ( 0 ) \n"
Original    (015): ['option_name', '=', 're', '.', 'match', '(', ',', 'option_expr', ')', '.', 'group', '(', '0', ')', '\\n']
Tokenized   (023): ['[CLS]', 'option', '_', 'name', '=', 're', '.', 'match', '(', ',', 'option', '_', 'ex', '##pr', ')', '.', 'group', '(', '0', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['option', '_', 'name', '=', 're', '.', 'match', '(', ',', 'option', '_', 'ex', '##pr', ')', '.', 'group', '(', '0', ')', '\\', 'n']
Detokenized (015): ['option_name', '=', 're', '.', 'match', '(', ',', 'option_ex##pr', ')', '.', 'group', '(', '0', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "is_valid = option_name not in AbbreviationsIncludingInvertPrefix \n"
Original    (007): ['is_valid', '=', 'option_name', 'not', 'in', 'AbbreviationsIncludingInvertPrefix', '\\n']
Tokenized   (022): ['[CLS]', 'is', '_', 'valid', '=', 'option', '_', 'name', 'not', 'in', 'abbreviation', '##sin', '##cl', '##uding', '##in', '##vert', '##pre', '##fi', '##x', '\\', 'n', '[SEP]']
Filtered   (020): ['is', '_', 'valid', '=', 'option', '_', 'name', 'not', 'in', 'abbreviation', '##sin', '##cl', '##uding', '##in', '##vert', '##pre', '##fi', '##x', '\\', 'n']
Detokenized (007): ['is_valid', '=', 'option_name', 'not', 'in', 'abbreviation##sin##cl##uding##in##vert##pre##fi##x', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "stderr . setFormatter ( logging . Formatter ( \n"
Original    (009): ['stderr', '.', 'setFormatter', '(', 'logging', '.', 'Formatter', '(', '\\n']
Tokenized   (017): ['[CLS]', 'st', '##der', '##r', '.', 'set', '##form', '##atter', '(', 'logging', '.', 'format', '##ter', '(', '\\', 'n', '[SEP]']
Filtered   (015): ['st', '##der', '##r', '.', 'set', '##form', '##atter', '(', 'logging', '.', 'format', '##ter', '(', '\\', 'n']
Detokenized (009): ['st##der##r', '.', 'set##form##atter', '(', 'logging', '.', 'format##ter', '(', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "level = level if level else os . environ . get ( , ) \n"
Original    (015): ['level', '=', 'level', 'if', 'level', 'else', 'os', '.', 'environ', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (020): ['[CLS]', 'level', '=', 'level', 'if', 'level', 'else', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['level', '=', 'level', 'if', 'level', 'else', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', ',', ')', '\\', 'n']
Detokenized (015): ['level', '=', 'level', 'if', 'level', 'else', 'os', '.', 'en##vir##on', '.', 'get', '(', ',', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "g_s = g0 * g_c * g_R * g_D * g_T * g_M \n"
Original    (014): ['g_s', '=', 'g0', '*', 'g_c', '*', 'g_R', '*', 'g_D', '*', 'g_T', '*', 'g_M', '\\n']
Tokenized   (030): ['[CLS]', 'g', '_', 's', '=', 'g', '##0', '*', 'g', '_', 'c', '*', 'g', '_', 'r', '*', 'g', '_', 'd', '*', 'g', '_', 't', '*', 'g', '_', 'm', '\\', 'n', '[SEP]']
Filtered   (028): ['g', '_', 's', '=', 'g', '##0', '*', 'g', '_', 'c', '*', 'g', '_', 'r', '*', 'g', '_', 'd', '*', 'g', '_', 't', '*', 'g', '_', 'm', '\\', 'n']
Detokenized (014): ['g_s', '=', 'g##0', '*', 'g_c', '*', 'g_r', '*', 'g_d', '*', 'g_t', '*', 'g_m', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "g_T = ( ( TK - TL ) * ( TH - TK ) ** alpha_T ) / ( ( T0 - TL ) * ( TH - T0 ) ** alpha_T ) \n"
Original    (034): ['g_T', '=', '(', '(', 'TK', '-', 'TL', ')', '*', '(', 'TH', '-', 'TK', ')', '**', 'alpha_T', ')', '/', '(', '(', 'T0', '-', 'TL', ')', '*', '(', 'TH', '-', 'T0', ')', '**', 'alpha_T', ')', '\\n']
Tokenized   (051): ['[CLS]', 'g', '_', 't', '=', '(', '(', 't', '##k', '-', 't', '##l', ')', '*', '(', 'th', '-', 't', '##k', ')', '*', '*', 'alpha', '_', 't', ')', '/', '(', '(', 't', '##0', '-', 't', '##l', ')', '*', '(', 'th', '-', 't', '##0', ')', '*', '*', 'alpha', '_', 't', ')', '\\', 'n', '[SEP]']
Filtered   (049): ['g', '_', 't', '=', '(', '(', 't', '##k', '-', 't', '##l', ')', '*', '(', 'th', '-', 't', '##k', ')', '*', '*', 'alpha', '_', 't', ')', '/', '(', '(', 't', '##0', '-', 't', '##l', ')', '*', '(', 'th', '-', 't', '##0', ')', '*', '*', 'alpha', '_', 't', ')', '\\', 'n']
Detokenized (034): ['g_t', '=', '(', '(', 't##k', '-', 't##l', ')', '*', '(', 'th', '-', 't##k', ')', '**', 'alpha_t', ')', '/', '(', '(', 't##0', '-', 't##l', ')', '*', '(', 'th', '-', 't##0', ')', '**', 'alpha_t', ')', '\\n']
Counter: 49
===================================================================
Hidden states:  (13, 34, 768)
# Extracted words:  34
Sentence         : "r_a = AeroReist ( um , zm , z0 , d ) \n"
Original    (013): ['r_a', '=', 'AeroReist', '(', 'um', ',', 'zm', ',', 'z0', ',', 'd', ')', '\\n']
Tokenized   (022): ['[CLS]', 'r', '_', 'a', '=', 'aero', '##re', '##ist', '(', 'um', ',', 'z', '##m', ',', 'z', '##0', ',', 'd', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['r', '_', 'a', '=', 'aero', '##re', '##ist', '(', 'um', ',', 'z', '##m', ',', 'z', '##0', ',', 'd', ')', '\\', 'n']
Detokenized (013): ['r_a', '=', 'aero##re##ist', '(', 'um', ',', 'z##m', ',', 'z##0', ',', 'd', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "r_s = SurfResist ( g0 , S , D , Tc , SM , SM0 ) \n"
Original    (017): ['r_s', '=', 'SurfResist', '(', 'g0', ',', 'S', ',', 'D', ',', 'Tc', ',', 'SM', ',', 'SM0', ')', '\\n']
Tokenized   (026): ['[CLS]', 'r', '_', 's', '=', 'surf', '##res', '##ist', '(', 'g', '##0', ',', 's', ',', 'd', ',', 'tc', ',', 'sm', ',', 'sm', '##0', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['r', '_', 's', '=', 'surf', '##res', '##ist', '(', 'g', '##0', ',', 's', ',', 'd', ',', 'tc', ',', 'sm', ',', 'sm', '##0', ')', '\\', 'n']
Detokenized (017): ['r_s', '=', 'surf##res##ist', '(', 'g##0', ',', 's', ',', 'd', ',', 'tc', ',', 'sm', ',', 'sm##0', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "LE = ( delta * Rn + ( rho_a * cP * D ) / r_a ) / ( delta + gamma * ( 1.0 + r_s / r_a ) ) \n"
Original    (032): ['LE', '=', '(', 'delta', '*', 'Rn', '+', '(', 'rho_a', '*', 'cP', '*', 'D', ')', '/', 'r_a', ')', '/', '(', 'delta', '+', 'gamma', '*', '(', '1.0', '+', 'r_s', '/', 'r_a', ')', ')', '\\n']
Tokenized   (046): ['[CLS]', 'le', '=', '(', 'delta', '*', 'rn', '+', '(', 'r', '##ho', '_', 'a', '*', 'cp', '*', 'd', ')', '/', 'r', '_', 'a', ')', '/', '(', 'delta', '+', 'gamma', '*', '(', '1', '.', '0', '+', 'r', '_', 's', '/', 'r', '_', 'a', ')', ')', '\\', 'n', '[SEP]']
Filtered   (044): ['le', '=', '(', 'delta', '*', 'rn', '+', '(', 'r', '##ho', '_', 'a', '*', 'cp', '*', 'd', ')', '/', 'r', '_', 'a', ')', '/', '(', 'delta', '+', 'gamma', '*', '(', '1', '.', '0', '+', 'r', '_', 's', '/', 'r', '_', 'a', ')', ')', '\\', 'n']
Detokenized (032): ['le', '=', '(', 'delta', '*', 'rn', '+', '(', 'r##ho_a', '*', 'cp', '*', 'd', ')', '/', 'r_a', ')', '/', '(', 'delta', '+', 'gamma', '*', '(', '1.0', '+', 'r_s', '/', 'r_a', ')', ')', '\\n']
Counter: 44
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "glClearColor ( * background_color ) \n"
Original    (006): ['glClearColor', '(', '*', 'background_color', ')', '\\n']
Tokenized   (015): ['[CLS]', 'g', '##lc', '##lea', '##rco', '##lor', '(', '*', 'background', '_', 'color', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['g', '##lc', '##lea', '##rco', '##lor', '(', '*', 'background', '_', 'color', ')', '\\', 'n']
Detokenized (006): ['g##lc##lea##rco##lor', '(', '*', 'background_color', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "glScissor ( x , y , width , height ) \n"
Original    (011): ['glScissor', '(', 'x', ',', 'y', ',', 'width', ',', 'height', ')', '\\n']
Tokenized   (017): ['[CLS]', 'g', '##ls', '##cis', '##sor', '(', 'x', ',', 'y', ',', 'width', ',', 'height', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['g', '##ls', '##cis', '##sor', '(', 'x', ',', 'y', ',', 'width', ',', 'height', ')', '\\', 'n']
Detokenized (011): ['g##ls##cis##sor', '(', 'x', ',', 'y', ',', 'width', ',', 'height', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "glOrtho ( x , x + width , y , y + height , - 1 , 1 ) \n"
Original    (020): ['glOrtho', '(', 'x', ',', 'x', '+', 'width', ',', 'y', ',', 'y', '+', 'height', ',', '-', '1', ',', '1', ')', '\\n']
Tokenized   (026): ['[CLS]', 'g', '##lor', '##th', '##o', '(', 'x', ',', 'x', '+', 'width', ',', 'y', ',', 'y', '+', 'height', ',', '-', '1', ',', '1', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['g', '##lor', '##th', '##o', '(', 'x', ',', 'x', '+', 'width', ',', 'y', ',', 'y', '+', 'height', ',', '-', '1', ',', '1', ')', '\\', 'n']
Detokenized (020): ['g##lor##th##o', '(', 'x', ',', 'x', '+', 'width', ',', 'y', ',', 'y', '+', 'height', ',', '-', '1', ',', '1', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "glNormal3f ( 0 , 1. , 0 ) \n"
Original    (009): ['glNormal3f', '(', '0', ',', '1.', ',', '0', ')', '\\n']
Tokenized   (018): ['[CLS]', 'g', '##ln', '##or', '##mal', '##3', '##f', '(', '0', ',', '1', '.', ',', '0', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['g', '##ln', '##or', '##mal', '##3', '##f', '(', '0', ',', '1', '.', ',', '0', ')', '\\', 'n']
Detokenized (009): ['g##ln##or##mal##3##f', '(', '0', ',', '1.', ',', '0', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "glVertex ( n , n , p ) \n"
Original    (009): ['glVertex', '(', 'n', ',', 'n', ',', 'p', ')', '\\n']
Tokenized   (015): ['[CLS]', 'g', '##lver', '##te', '##x', '(', 'n', ',', 'n', ',', 'p', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['g', '##lver', '##te', '##x', '(', 'n', ',', 'n', ',', 'p', ')', '\\', 'n']
Detokenized (009): ['g##lver##te##x', '(', 'n', ',', 'n', ',', 'p', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "companies = [ path for path in paths \n"
Original    (009): ['companies', '=', '[', 'path', 'for', 'path', 'in', 'paths', '\\n']
Tokenized   (012): ['[CLS]', 'companies', '=', '[', 'path', 'for', 'path', 'in', 'paths', '\\', 'n', '[SEP]']
Filtered   (010): ['companies', '=', '[', 'path', 'for', 'path', 'in', 'paths', '\\', 'n']
Detokenized (009): ['companies', '=', '[', 'path', 'for', 'path', 'in', 'paths', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "and os . path . exists ( os . path . join ( folder , path , ) ) ] \n"
Original    (021): ['and', 'os', '.', 'path', '.', 'exists', '(', 'os', '.', 'path', '.', 'join', '(', 'folder', ',', 'path', ',', ')', ')', ']', '\\n']
Tokenized   (024): ['[CLS]', 'and', 'os', '.', 'path', '.', 'exists', '(', 'os', '.', 'path', '.', 'join', '(', 'folder', ',', 'path', ',', ')', ')', ']', '\\', 'n', '[SEP]']
Filtered   (022): ['and', 'os', '.', 'path', '.', 'exists', '(', 'os', '.', 'path', '.', 'join', '(', 'folder', ',', 'path', ',', ')', ')', ']', '\\', 'n']
Detokenized (021): ['and', 'os', '.', 'path', '.', 'exists', '(', 'os', '.', 'path', '.', 'join', '(', 'folder', ',', 'path', ',', ')', ')', ']', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "folder = os . path . join ( root_folder , , , ) \n"
Original    (014): ['folder', '=', 'os', '.', 'path', '.', 'join', '(', 'root_folder', ',', ',', ',', ')', '\\n']
Tokenized   (019): ['[CLS]', 'folder', '=', 'os', '.', 'path', '.', 'join', '(', 'root', '_', 'folder', ',', ',', ',', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['folder', '=', 'os', '.', 'path', '.', 'join', '(', 'root', '_', 'folder', ',', ',', ',', ')', '\\', 'n']
Detokenized (014): ['folder', '=', 'os', '.', 'path', '.', 'join', '(', 'root_folder', ',', ',', ',', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "scripts = [ , \n"
Original    (005): ['scripts', '=', '[', ',', '\\n']
Tokenized   (008): ['[CLS]', 'scripts', '=', '[', ',', '\\', 'n', '[SEP]']
Filtered   (006): ['scripts', '=', '[', ',', '\\', 'n']
Detokenized (005): ['scripts', '=', '[', ',', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "pro2 . predict ( ) from collections import OrderedDict \n"
Original    (010): ['pro2', '.', 'predict', '(', ')', 'from', 'collections', 'import', 'OrderedDict', '\\n']
Tokenized   (015): ['[CLS]', 'pro', '##2', '.', 'predict', '(', ')', 'from', 'collections', 'import', 'ordered', '##dict', '\\', 'n', '[SEP]']
Filtered   (013): ['pro', '##2', '.', 'predict', '(', ')', 'from', 'collections', 'import', 'ordered', '##dict', '\\', 'n']
Detokenized (010): ['pro##2', '.', 'predict', '(', ')', 'from', 'collections', 'import', 'ordered##dict', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : ""dimensions." % ( self . __class__ . __name__ , shape ) ) \n"
Original    (013): ['"dimensions."', '%', '(', 'self', '.', '__class__', '.', '__name__', ',', 'shape', ')', ')', '\\n']
Tokenized   (027): ['[CLS]', '"', 'dimensions', '.', '"', '%', '(', 'self', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', ',', 'shape', ')', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['"', 'dimensions', '.', '"', '%', '(', 'self', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', ',', 'shape', ')', ')', '\\', 'n']
Detokenized (013): ['"dimensions."', '%', '(', 'self', '.', '__class__', '.', '__name__', ',', 'shape', ')', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "only = set ( tag for tag , value in tags . items ( ) if value ) \n"
Original    (019): ['only', '=', 'set', '(', 'tag', 'for', 'tag', ',', 'value', 'in', 'tags', '.', 'items', '(', ')', 'if', 'value', ')', '\\n']
Tokenized   (022): ['[CLS]', 'only', '=', 'set', '(', 'tag', 'for', 'tag', ',', 'value', 'in', 'tags', '.', 'items', '(', ')', 'if', 'value', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['only', '=', 'set', '(', 'tag', 'for', 'tag', ',', 'value', 'in', 'tags', '.', 'items', '(', ')', 'if', 'value', ')', '\\', 'n']
Detokenized (019): ['only', '=', 'set', '(', 'tag', 'for', 'tag', ',', 'value', 'in', 'tags', '.', 'items', '(', ')', 'if', 'value', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "crop1 = [ None , , , ] \n"
Original    (009): ['crop1', '=', '[', 'None', ',', ',', ',', ']', '\\n']
Tokenized   (013): ['[CLS]', 'crop', '##1', '=', '[', 'none', ',', ',', ',', ']', '\\', 'n', '[SEP]']
Filtered   (011): ['crop', '##1', '=', '[', 'none', ',', ',', ',', ']', '\\', 'n']
Detokenized (009): ['crop##1', '=', '[', 'none', ',', ',', ',', ']', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "outs = [ o . eval ( ) for o in outs ] \n"
Original    (014): ['outs', '=', '[', 'o', '.', 'eval', '(', ')', 'for', 'o', 'in', 'outs', ']', '\\n']
Tokenized   (018): ['[CLS]', 'outs', '=', '[', 'o', '.', 'eva', '##l', '(', ')', 'for', 'o', 'in', 'outs', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['outs', '=', '[', 'o', '.', 'eva', '##l', '(', ')', 'for', 'o', 'in', 'outs', ']', '\\', 'n']
Detokenized (014): ['outs', '=', '[', 'o', '.', 'eva##l', '(', ')', 'for', 'o', 'in', 'outs', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "crop_test ( crop_x , [ x0 , x1 , x2 , x0 , x1 , x2 ] , \n"
Original    (019): ['crop_test', '(', 'crop_x', ',', '[', 'x0', ',', 'x1', ',', 'x2', ',', 'x0', ',', 'x1', ',', 'x2', ']', ',', '\\n']
Tokenized   (032): ['[CLS]', 'crop', '_', 'test', '(', 'crop', '_', 'x', ',', '[', 'x', '##0', ',', 'x', '##1', ',', 'x', '##2', ',', 'x', '##0', ',', 'x', '##1', ',', 'x', '##2', ']', ',', '\\', 'n', '[SEP]']
Filtered   (030): ['crop', '_', 'test', '(', 'crop', '_', 'x', ',', '[', 'x', '##0', ',', 'x', '##1', ',', 'x', '##2', ',', 'x', '##0', ',', 'x', '##1', ',', 'x', '##2', ']', ',', '\\', 'n']
Detokenized (019): ['crop_test', '(', 'crop_x', ',', '[', 'x##0', ',', 'x##1', ',', 'x##2', ',', 'x##0', ',', 'x##1', ',', 'x##2', ']', ',', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "cropping = [ ] * 2 ) \n"
Original    (008): ['cropping', '=', '[', ']', '*', '2', ')', '\\n']
Tokenized   (012): ['[CLS]', 'crop', '##ping', '=', '[', ']', '*', '2', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['crop', '##ping', '=', '[', ']', '*', '2', ')', '\\', 'n']
Detokenized (008): ['crop##ping', '=', '[', ']', '*', '2', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "desired_result_0 = numpy . concatenate ( [ x0 [ : , : 2 ] , x1 [ : , : 2 ] ] , axis = 0 ) \n"
Original    (029): ['desired_result_0', '=', 'numpy', '.', 'concatenate', '(', '[', 'x0', '[', ':', ',', ':', '2', ']', ',', 'x1', '[', ':', ',', ':', '2', ']', ']', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (042): ['[CLS]', 'desired', '_', 'result', '_', '0', '=', 'nu', '##mp', '##y', '.', 'con', '##cate', '##nate', '(', '[', 'x', '##0', '[', ':', ',', ':', '2', ']', ',', 'x', '##1', '[', ':', ',', ':', '2', ']', ']', ',', 'axis', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (040): ['desired', '_', 'result', '_', '0', '=', 'nu', '##mp', '##y', '.', 'con', '##cate', '##nate', '(', '[', 'x', '##0', '[', ':', ',', ':', '2', ']', ',', 'x', '##1', '[', ':', ',', ':', '2', ']', ']', ',', 'axis', '=', '0', ')', '\\', 'n']
Detokenized (029): ['desired_result_0', '=', 'nu##mp##y', '.', 'con##cate##nate', '(', '[', 'x##0', '[', ':', ',', ':', '2', ']', ',', 'x##1', '[', ':', ',', ':', '2', ']', ']', ',', 'axis', '=', '0', ')', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "desired_result_1 = numpy . concatenate ( [ x0 [ : 4 , : ] , x1 [ : 4 , : ] ] , axis = 1 ) \n"
Original    (029): ['desired_result_1', '=', 'numpy', '.', 'concatenate', '(', '[', 'x0', '[', ':', '4', ',', ':', ']', ',', 'x1', '[', ':', '4', ',', ':', ']', ']', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (042): ['[CLS]', 'desired', '_', 'result', '_', '1', '=', 'nu', '##mp', '##y', '.', 'con', '##cate', '##nate', '(', '[', 'x', '##0', '[', ':', '4', ',', ':', ']', ',', 'x', '##1', '[', ':', '4', ',', ':', ']', ']', ',', 'axis', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (040): ['desired', '_', 'result', '_', '1', '=', 'nu', '##mp', '##y', '.', 'con', '##cate', '##nate', '(', '[', 'x', '##0', '[', ':', '4', ',', ':', ']', ',', 'x', '##1', '[', ':', '4', ',', ':', ']', ']', ',', 'axis', '=', '1', ')', '\\', 'n']
Detokenized (029): ['desired_result_1', '=', 'nu##mp##y', '.', 'con##cate##nate', '(', '[', 'x##0', '[', ':', '4', ',', ':', ']', ',', 'x##1', '[', ':', '4', ',', ':', ']', ']', ',', 'axis', '=', '1', ')', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "inputs = [ theano . shared ( a ) , \n"
Original    (011): ['inputs', '=', '[', 'theano', '.', 'shared', '(', 'a', ')', ',', '\\n']
Tokenized   (015): ['[CLS]', 'inputs', '=', '[', 'the', '##ano', '.', 'shared', '(', 'a', ')', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['inputs', '=', '[', 'the', '##ano', '.', 'shared', '(', 'a', ')', ',', '\\', 'n']
Detokenized (011): ['inputs', '=', '[', 'the##ano', '.', 'shared', '(', 'a', ')', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "theano . shared ( b ) ] \n"
Original    (008): ['theano', '.', 'shared', '(', 'b', ')', ']', '\\n']
Tokenized   (012): ['[CLS]', 'the', '##ano', '.', 'shared', '(', 'b', ')', ']', '\\', 'n', '[SEP]']
Filtered   (010): ['the', '##ano', '.', 'shared', '(', 'b', ')', ']', '\\', 'n']
Detokenized (008): ['the##ano', '.', 'shared', '(', 'b', ')', ']', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mask = os . urandom ( 4 ) if mask else None \n"
Original    (013): ['mask', '=', 'os', '.', 'urandom', '(', '4', ')', 'if', 'mask', 'else', 'None', '\\n']
Tokenized   (018): ['[CLS]', 'mask', '=', 'os', '.', 'ur', '##ando', '##m', '(', '4', ')', 'if', 'mask', 'else', 'none', '\\', 'n', '[SEP]']
Filtered   (016): ['mask', '=', 'os', '.', 'ur', '##ando', '##m', '(', '4', ')', 'if', 'mask', 'else', 'none', '\\', 'n']
Detokenized (013): ['mask', '=', 'os', '.', 'ur##ando##m', '(', '4', ')', 'if', 'mask', 'else', 'none', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "masking_key = mask , fin = 1 ) . build ( ) \n"
Original    (013): ['masking_key', '=', 'mask', ',', 'fin', '=', '1', ')', '.', 'build', '(', ')', '\\n']
Tokenized   (019): ['[CLS]', 'mask', '##ing', '_', 'key', '=', 'mask', ',', 'fin', '=', '1', ')', '.', 'build', '(', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['mask', '##ing', '_', 'key', '=', 'mask', ',', 'fin', '=', '1', ')', '.', 'build', '(', ')', '\\', 'n']
Detokenized (013): ['mask##ing_key', '=', 'mask', ',', 'fin', '=', '1', ')', '.', 'build', '(', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "fin = fin ) . build ( ) \n"
Original    (009): ['fin', '=', 'fin', ')', '.', 'build', '(', ')', '\\n']
Tokenized   (012): ['[CLS]', 'fin', '=', 'fin', ')', '.', 'build', '(', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['fin', '=', 'fin', ')', '.', 'build', '(', ')', '\\', 'n']
Detokenized (009): ['fin', '=', 'fin', ')', '.', 'build', '(', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "flags = unpack ( , msg [ idx : idx + 4 ] ) [ 0 ] \n"
Original    (018): ['flags', '=', 'unpack', '(', ',', 'msg', '[', 'idx', ':', 'idx', '+', '4', ']', ')', '[', '0', ']', '\\n']
Tokenized   (025): ['[CLS]', 'flags', '=', 'un', '##pack', '(', ',', 'ms', '##g', '[', 'id', '##x', ':', 'id', '##x', '+', '4', ']', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['flags', '=', 'un', '##pack', '(', ',', 'ms', '##g', '[', 'id', '##x', ':', 'id', '##x', '+', '4', ']', ')', '[', '0', ']', '\\', 'n']
Detokenized (018): ['flags', '=', 'un##pack', '(', ',', 'ms##g', '[', 'id##x', ':', 'id##x', '+', '4', ']', ')', '[', '0', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "pdc = req . get_options ( ) [ ] \n"
Original    (010): ['pdc', '=', 'req', '.', 'get_options', '(', ')', '[', ']', '\\n']
Tokenized   (017): ['[CLS]', 'pd', '##c', '=', 're', '##q', '.', 'get', '_', 'options', '(', ')', '[', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['pd', '##c', '=', 're', '##q', '.', 'get', '_', 'options', '(', ')', '[', ']', '\\', 'n']
Detokenized (010): ['pd##c', '=', 're##q', '.', 'get_options', '(', ')', '[', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "bdc = req . get_options ( ) . get ( , False ) \n"
Original    (014): ['bdc', '=', 'req', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 'False', ')', '\\n']
Tokenized   (021): ['[CLS]', 'b', '##dc', '=', 're', '##q', '.', 'get', '_', 'options', '(', ')', '.', 'get', '(', ',', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['b', '##dc', '=', 're', '##q', '.', 'get', '_', 'options', '(', ')', '.', 'get', '(', ',', 'false', ')', '\\', 'n']
Detokenized (014): ['b##dc', '=', 're##q', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 'false', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "decoded_path = urllib . unquote ( url . path ) [ 1 : ] \n"
Original    (015): ['decoded_path', '=', 'urllib', '.', 'unquote', '(', 'url', '.', 'path', ')', '[', '1', ':', ']', '\\n']
Tokenized   (026): ['[CLS]', 'deco', '##ded', '_', 'path', '=', 'ur', '##lli', '##b', '.', 'un', '##qu', '##ote', '(', 'ur', '##l', '.', 'path', ')', '[', '1', ':', ']', '\\', 'n', '[SEP]']
Filtered   (024): ['deco', '##ded', '_', 'path', '=', 'ur', '##lli', '##b', '.', 'un', '##qu', '##ote', '(', 'ur', '##l', '.', 'path', ')', '[', '1', ':', ']', '\\', 'n']
Detokenized (015): ['deco##ded_path', '=', 'ur##lli##b', '.', 'un##qu##ote', '(', 'ur##l', '.', 'path', ')', '[', '1', ':', ']', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rules = . join ( req . requires ( ) ) . strip ( ) \n"
Original    (016): ['rules', '=', '.', 'join', '(', 'req', '.', 'requires', '(', ')', ')', '.', 'strip', '(', ')', '\\n']
Tokenized   (020): ['[CLS]', 'rules', '=', '.', 'join', '(', 're', '##q', '.', 'requires', '(', ')', ')', '.', 'strip', '(', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['rules', '=', '.', 'join', '(', 're', '##q', '.', 'requires', '(', ')', ')', '.', 'strip', '(', ')', '\\', 'n']
Detokenized (016): ['rules', '=', '.', 'join', '(', 're##q', '.', 'requires', '(', ')', ')', '.', 'strip', '(', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "domain = req . get_options ( ) . get ( , req . auth_name ( ) ) \n"
Original    (018): ['domain', '=', 'req', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 'req', '.', 'auth_name', '(', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'domain', '=', 're', '##q', '.', 'get', '_', 'options', '(', ')', '.', 'get', '(', ',', 're', '##q', '.', 'au', '##th', '_', 'name', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['domain', '=', 're', '##q', '.', 'get', '_', 'options', '(', ')', '.', 'get', '(', ',', 're', '##q', '.', 'au', '##th', '_', 'name', '(', ')', ')', '\\', 'n']
Detokenized (018): ['domain', '=', 're##q', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 're##q', '.', 'au##th_name', '(', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "auth_headers = req . headers_in . get ( , [ ] ) \n"
Original    (013): ['auth_headers', '=', 'req', '.', 'headers_in', '.', 'get', '(', ',', '[', ']', ')', '\\n']
Tokenized   (024): ['[CLS]', 'au', '##th', '_', 'header', '##s', '=', 're', '##q', '.', 'header', '##s', '_', 'in', '.', 'get', '(', ',', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['au', '##th', '_', 'header', '##s', '=', 're', '##q', '.', 'header', '##s', '_', 'in', '.', 'get', '(', ',', '[', ']', ')', '\\', 'n']
Detokenized (013): ['au##th_header##s', '=', 're##q', '.', 'header##s_in', '.', 'get', '(', ',', '[', ']', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "set_remote_user ( req , ah_data [ 1 ] , domain ) \n"
Original    (012): ['set_remote_user', '(', 'req', ',', 'ah_data', '[', '1', ']', ',', 'domain', ')', '\\n']
Tokenized   (022): ['[CLS]', 'set', '_', 'remote', '_', 'user', '(', 're', '##q', ',', 'ah', '_', 'data', '[', '1', ']', ',', 'domain', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['set', '_', 'remote', '_', 'user', '(', 're', '##q', ',', 'ah', '_', 'data', '[', '1', ']', ',', 'domain', ')', '\\', 'n']
Detokenized (012): ['set_remote_user', '(', 're##q', ',', 'ah_data', '[', '1', ']', ',', 'domain', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "dict = json . loads ( request . data . decode ( ) ) \n"
Original    (015): ['dict', '=', 'json', '.', 'loads', '(', 'request', '.', 'data', '.', 'decode', '(', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'di', '##ct', '=', 'j', '##son', '.', 'loads', '(', 'request', '.', 'data', '.', 'deco', '##de', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['di', '##ct', '=', 'j', '##son', '.', 'loads', '(', 'request', '.', 'data', '.', 'deco', '##de', '(', ')', ')', '\\', 'n']
Detokenized (015): ['di##ct', '=', 'j##son', '.', 'loads', '(', 'request', '.', 'data', '.', 'deco##de', '(', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rv = self . app . delete ( . format ( id ) ) \n"
Original    (015): ['rv', '=', 'self', '.', 'app', '.', 'delete', '(', '.', 'format', '(', 'id', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'rv', '=', 'self', '.', 'app', '.', 'del', '##ete', '(', '.', 'format', '(', 'id', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['rv', '=', 'self', '.', 'app', '.', 'del', '##ete', '(', '.', 'format', '(', 'id', ')', ')', '\\', 'n']
Detokenized (015): ['rv', '=', 'self', '.', 'app', '.', 'del##ete', '(', '.', 'format', '(', 'id', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "configure_logging ( "index_pages_logging.config" , "index_pages.log" ) \n"
Original    (007): ['configure_logging', '(', '"index_pages_logging.config"', ',', '"index_pages.log"', ')', '\\n']
Tokenized   (031): ['[CLS]', 'con', '##fi', '##gur', '##e', '_', 'logging', '(', '"', 'index', '_', 'pages', '_', 'logging', '.', 'con', '##fi', '##g', '"', ',', '"', 'index', '_', 'pages', '.', 'log', '"', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['con', '##fi', '##gur', '##e', '_', 'logging', '(', '"', 'index', '_', 'pages', '_', 'logging', '.', 'con', '##fi', '##g', '"', ',', '"', 'index', '_', 'pages', '.', 'log', '"', ')', '\\', 'n']
Detokenized (007): ['con##fi##gur##e_logging', '(', '"index_pages_logging.con##fi##g"', ',', '"index_pages.log"', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ocr_file = join ( dir , ) \n"
Original    (008): ['ocr_file', '=', 'join', '(', 'dir', ',', ')', '\\n']
Tokenized   (014): ['[CLS]', 'o', '##cr', '_', 'file', '=', 'join', '(', 'dir', ',', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['o', '##cr', '_', 'file', '=', 'join', '(', 'dir', ',', ')', '\\', 'n']
Detokenized (008): ['o##cr_file', '=', 'join', '(', 'dir', ',', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "expected_text = { "eng" : file ( join ( dir , ) ) . read ( ) . decode ( ) } \n"
Original    (023): ['expected_text', '=', '{', '"eng"', ':', 'file', '(', 'join', '(', 'dir', ',', ')', ')', '.', 'read', '(', ')', '.', 'decode', '(', ')', '}', '\\n']
Tokenized   (031): ['[CLS]', 'expected', '_', 'text', '=', '{', '"', 'eng', '"', ':', 'file', '(', 'join', '(', 'dir', ',', ')', ')', '.', 'read', '(', ')', '.', 'deco', '##de', '(', ')', '}', '\\', 'n', '[SEP]']
Filtered   (029): ['expected', '_', 'text', '=', '{', '"', 'eng', '"', ':', 'file', '(', 'join', '(', 'dir', ',', ')', ')', '.', 'read', '(', ')', '.', 'deco', '##de', '(', ')', '}', '\\', 'n']
Detokenized (023): ['expected_text', '=', '{', '"eng"', ':', 'file', '(', 'join', '(', 'dir', ',', ')', ')', '.', 'read', '(', ')', '.', 'deco##de', '(', ')', '}', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "tuples . append ( ( os . path . join ( root , pair [ 0 ] ) , np . int32 ( pair [ 1 ] ) ) ) \n"
Original    (031): ['tuples', '.', 'append', '(', '(', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'pair', '[', '0', ']', ')', ',', 'np', '.', 'int32', '(', 'pair', '[', '1', ']', ')', ')', ')', '\\n']
Tokenized   (037): ['[CLS]', 'tu', '##ples', '.', 'app', '##end', '(', '(', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'pair', '[', '0', ']', ')', ',', 'np', '.', 'int', '##32', '(', 'pair', '[', '1', ']', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (035): ['tu', '##ples', '.', 'app', '##end', '(', '(', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'pair', '[', '0', ']', ')', ',', 'np', '.', 'int', '##32', '(', 'pair', '[', '1', ']', ')', ')', ')', '\\', 'n']
Detokenized (031): ['tu##ples', '.', 'app##end', '(', '(', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'pair', '[', '0', ']', ')', ',', 'np', '.', 'int##32', '(', 'pair', '[', '1', ']', ')', ')', ')', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "val_list = load_image_list ( args . val , args . root ) \n"
Original    (013): ['val_list', '=', 'load_image_list', '(', 'args', '.', 'val', ',', 'args', '.', 'root', ')', '\\n']
Tokenized   (024): ['[CLS]', 'val', '_', 'list', '=', 'load', '_', 'image', '_', 'list', '(', 'ar', '##gs', '.', 'val', ',', 'ar', '##gs', '.', 'root', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['val', '_', 'list', '=', 'load', '_', 'image', '_', 'list', '(', 'ar', '##gs', '.', 'val', ',', 'ar', '##gs', '.', 'root', ')', '\\', 'n']
Detokenized (013): ['val_list', '=', 'load_image_list', '(', 'ar##gs', '.', 'val', ',', 'ar##gs', '.', 'root', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "mean_image = pickle . load ( open ( args . mean , ) ) \n"
Original    (015): ['mean_image', '=', 'pickle', '.', 'load', '(', 'open', '(', 'args', '.', 'mean', ',', ')', ')', '\\n']
Tokenized   (022): ['[CLS]', 'mean', '_', 'image', '=', 'pick', '##le', '.', 'load', '(', 'open', '(', 'ar', '##gs', '.', 'mean', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['mean', '_', 'image', '=', 'pick', '##le', '.', 'load', '(', 'open', '(', 'ar', '##gs', '.', 'mean', ',', ')', ')', '\\', 'n']
Detokenized (015): ['mean_image', '=', 'pick##le', '.', 'load', '(', 'open', '(', 'ar##gs', '.', 'mean', ',', ')', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "cropwidth = 256 - model . insize \n"
Original    (008): ['cropwidth', '=', '256', '-', 'model', '.', 'insize', '\\n']
Tokenized   (015): ['[CLS]', 'crop', '##wi', '##dt', '##h', '=', '256', '-', 'model', '.', 'ins', '##ize', '\\', 'n', '[SEP]']
Filtered   (013): ['crop', '##wi', '##dt', '##h', '=', '256', '-', 'model', '.', 'ins', '##ize', '\\', 'n']
Detokenized (008): ['crop##wi##dt##h', '=', '256', '-', 'model', '.', 'ins##ize', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "left = random . randint ( 0 , cropwidth - 1 ) \n"
Original    (013): ['left', '=', 'random', '.', 'randint', '(', '0', ',', 'cropwidth', '-', '1', ')', '\\n']
Tokenized   (020): ['[CLS]', 'left', '=', 'random', '.', 'rand', '##int', '(', '0', ',', 'crop', '##wi', '##dt', '##h', '-', '1', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['left', '=', 'random', '.', 'rand', '##int', '(', '0', ',', 'crop', '##wi', '##dt', '##h', '-', '1', ')', '\\', 'n']
Detokenized (013): ['left', '=', 'random', '.', 'rand##int', '(', '0', ',', 'crop##wi##dt##h', '-', '1', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "image /= 255 \n"
Original    (004): ['image', '/=', '255', '\\n']
Tokenized   (008): ['[CLS]', 'image', '/', '=', '255', '\\', 'n', '[SEP]']
Filtered   (006): ['image', '/', '=', '255', '\\', 'n']
Detokenized (004): ['image', '/=', '255', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "val_batch_pool = [ None ] * args . val_batchsize \n"
Original    (010): ['val_batch_pool', '=', '[', 'None', ']', '*', 'args', '.', 'val_batchsize', '\\n']
Tokenized   (022): ['[CLS]', 'val', '_', 'batch', '_', 'pool', '=', '[', 'none', ']', '*', 'ar', '##gs', '.', 'val', '_', 'batch', '##si', '##ze', '\\', 'n', '[SEP]']
Filtered   (020): ['val', '_', 'batch', '_', 'pool', '=', '[', 'none', ']', '*', 'ar', '##gs', '.', 'val', '_', 'batch', '##si', '##ze', '\\', 'n']
Detokenized (010): ['val_batch_pool', '=', '[', 'none', ']', '*', 'ar##gs', '.', 'val_batch##si##ze', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "perm = np . random . permutation ( len ( train_list ) ) \n"
Original    (014): ['perm', '=', 'np', '.', 'random', '.', 'permutation', '(', 'len', '(', 'train_list', ')', ')', '\\n']
Tokenized   (022): ['[CLS]', 'per', '##m', '=', 'np', '.', 'random', '.', 'per', '##mut', '##ation', '(', 'len', '(', 'train', '_', 'list', ')', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['per', '##m', '=', 'np', '.', 'random', '.', 'per', '##mut', '##ation', '(', 'len', '(', 'train', '_', 'list', ')', ')', '\\', 'n']
Detokenized (014): ['per##m', '=', 'np', '.', 'random', '.', 'per##mut##ation', '(', 'len', '(', 'train_list', ')', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "batch_pool [ i ] = pool . apply_async ( read_image , ( path , False , True ) ) \n"
Original    (020): ['batch_pool', '[', 'i', ']', '=', 'pool', '.', 'apply_async', '(', 'read_image', ',', '(', 'path', ',', 'False', ',', 'True', ')', ')', '\\n']
Tokenized   (031): ['[CLS]', 'batch', '_', 'pool', '[', 'i', ']', '=', 'pool', '.', 'apply', '_', 'as', '##yn', '##c', '(', 'read', '_', 'image', ',', '(', 'path', ',', 'false', ',', 'true', ')', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['batch', '_', 'pool', '[', 'i', ']', '=', 'pool', '.', 'apply', '_', 'as', '##yn', '##c', '(', 'read', '_', 'image', ',', '(', 'path', ',', 'false', ',', 'true', ')', ')', '\\', 'n']
Detokenized (020): ['batch_pool', '[', 'i', ']', '=', 'pool', '.', 'apply_as##yn##c', '(', 'read_image', ',', '(', 'path', ',', 'false', ',', 'true', ')', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "read_image , ( path , True , False ) ) \n"
Original    (011): ['read_image', ',', '(', 'path', ',', 'True', ',', 'False', ')', ')', '\\n']
Tokenized   (016): ['[CLS]', 'read', '_', 'image', ',', '(', 'path', ',', 'true', ',', 'false', ')', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['read', '_', 'image', ',', '(', 'path', ',', 'true', ',', 'false', ')', ')', '\\', 'n']
Detokenized (011): ['read_image', ',', '(', 'path', ',', 'true', ',', 'false', ')', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "val_count = val_loss = val_accuracy = 0 \n"
Original    (008): ['val_count', '=', 'val_loss', '=', 'val_accuracy', '=', '0', '\\n']
Tokenized   (017): ['[CLS]', 'val', '_', 'count', '=', 'val', '_', 'loss', '=', 'val', '_', 'accuracy', '=', '0', '\\', 'n', '[SEP]']
Filtered   (015): ['val', '_', 'count', '=', 'val', '_', 'loss', '=', 'val', '_', 'accuracy', '=', '0', '\\', 'n']
Detokenized (008): ['val_count', '=', 'val_loss', '=', 'val_accuracy', '=', '0', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "duration = time . time ( ) - val_begin_at \n"
Original    (010): ['duration', '=', 'time', '.', 'time', '(', ')', '-', 'val_begin_at', '\\n']
Tokenized   (017): ['[CLS]', 'duration', '=', 'time', '.', 'time', '(', ')', '-', 'val', '_', 'begin', '_', 'at', '\\', 'n', '[SEP]']
Filtered   (015): ['duration', '=', 'time', '.', 'time', '(', ')', '-', 'val', '_', 'begin', '_', 'at', '\\', 'n']
Detokenized (010): ['duration', '=', 'time', '.', 'time', '(', ')', '-', 'val_begin_at', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "mean_error = 1 - val_accuracy * args . val_batchsize / 50000 \n"
Original    (012): ['mean_error', '=', '1', '-', 'val_accuracy', '*', 'args', '.', 'val_batchsize', '/', '50000', '\\n']
Tokenized   (025): ['[CLS]', 'mean', '_', 'error', '=', '1', '-', 'val', '_', 'accuracy', '*', 'ar', '##gs', '.', 'val', '_', 'batch', '##si', '##ze', '/', '5000', '##0', '\\', 'n', '[SEP]']
Filtered   (023): ['mean', '_', 'error', '=', '1', '-', 'val', '_', 'accuracy', '*', 'ar', '##gs', '.', 'val', '_', 'batch', '##si', '##ze', '/', '5000', '##0', '\\', 'n']
Detokenized (012): ['mean_error', '=', '1', '-', 'val_accuracy', '*', 'ar##gs', '.', 'val_batch##si##ze', '/', '5000##0', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "serializers . save_hdf5 ( args . outstate , optimizer ) \n"
Original    (011): ['serializers', '.', 'save_hdf5', '(', 'args', '.', 'outstate', ',', 'optimizer', ')', '\\n']
Tokenized   (024): ['[CLS]', 'serial', '##izer', '##s', '.', 'save', '_', 'hd', '##f', '##5', '(', 'ar', '##gs', '.', 'outs', '##tate', ',', 'opt', '##imi', '##zer', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['serial', '##izer', '##s', '.', 'save', '_', 'hd', '##f', '##5', '(', 'ar', '##gs', '.', 'outs', '##tate', ',', 'opt', '##imi', '##zer', ')', '\\', 'n']
Detokenized (011): ['serial##izer##s', '.', 'save_hd##f##5', '(', 'ar##gs', '.', 'outs##tate', ',', 'opt##imi##zer', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "boards_name = [ slugify ( b [ ] ) for b in SETTINGS . get ( , { } ) . values ( ) ] \n"
Original    (026): ['boards_name', '=', '[', 'slugify', '(', 'b', '[', ']', ')', 'for', 'b', 'in', 'SETTINGS', '.', 'get', '(', ',', '{', '}', ')', '.', 'values', '(', ')', ']', '\\n']
Tokenized   (032): ['[CLS]', 'boards', '_', 'name', '=', '[', 'slug', '##ify', '(', 'b', '[', ']', ')', 'for', 'b', 'in', 'settings', '.', 'get', '(', ',', '{', '}', ')', '.', 'values', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (030): ['boards', '_', 'name', '=', '[', 'slug', '##ify', '(', 'b', '[', ']', ')', 'for', 'b', 'in', 'settings', '.', 'get', '(', ',', '{', '}', ')', '.', 'values', '(', ')', ']', '\\', 'n']
Detokenized (026): ['boards_name', '=', '[', 'slug##ify', '(', 'b', '[', ']', ')', 'for', 'b', 'in', 'settings', '.', 'get', '(', ',', '{', '}', ')', '.', 'values', '(', ')', ']', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "LOGGING . info ( . format ( board_name , result ) ) \n"
Original    (013): ['LOGGING', '.', 'info', '(', '.', 'format', '(', 'board_name', ',', 'result', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'logging', '.', 'info', '(', '.', 'format', '(', 'board', '_', 'name', ',', 'result', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['logging', '.', 'info', '(', '.', 'format', '(', 'board', '_', 'name', ',', 'result', ')', ')', '\\', 'n']
Detokenized (013): ['logging', '.', 'info', '(', '.', 'format', '(', 'board_name', ',', 'result', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_py2 = _ver [ 0 ] == 2 \n"
Original    (009): ['is_py2', '=', '_ver', '[', '0', ']', '==', '2', '\\n']
Tokenized   (019): ['[CLS]', 'is', '_', 'p', '##y', '##2', '=', '_', 've', '##r', '[', '0', ']', '=', '=', '2', '\\', 'n', '[SEP]']
Filtered   (017): ['is', '_', 'p', '##y', '##2', '=', '_', 've', '##r', '[', '0', ']', '=', '=', '2', '\\', 'n']
Detokenized (009): ['is_p##y##2', '=', '_ve##r', '[', '0', ']', '==', '2', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "is_py2_7_9_or_later = _ver [ 0 ] >= 2 and _ver [ 1 ] >= 7 and _ver [ 2 ] >= 9 \n"
Original    (023): ['is_py2_7_9_or_later', '=', '_ver', '[', '0', ']', '>=', '2', 'and', '_ver', '[', '1', ']', '>=', '7', 'and', '_ver', '[', '2', ']', '>=', '9', '\\n']
Tokenized   (047): ['[CLS]', 'is', '_', 'p', '##y', '##2', '_', '7', '_', '9', '_', 'or', '_', 'later', '=', '_', 've', '##r', '[', '0', ']', '>', '=', '2', 'and', '_', 've', '##r', '[', '1', ']', '>', '=', '7', 'and', '_', 've', '##r', '[', '2', ']', '>', '=', '9', '\\', 'n', '[SEP]']
Filtered   (045): ['is', '_', 'p', '##y', '##2', '_', '7', '_', '9', '_', 'or', '_', 'later', '=', '_', 've', '##r', '[', '0', ']', '>', '=', '2', 'and', '_', 've', '##r', '[', '1', ']', '>', '=', '7', 'and', '_', 've', '##r', '[', '2', ']', '>', '=', '9', '\\', 'n']
Detokenized (023): ['is_p##y##2_7_9_or_later', '=', '_ve##r', '[', '0', ']', '>=', '2', 'and', '_ve##r', '[', '1', ']', '>=', '7', 'and', '_ve##r', '[', '2', ']', '>=', '9', '\\n']
Counter: 45
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "is_py3_3 = is_py3 and _ver [ 1 ] == 3 \n"
Original    (011): ['is_py3_3', '=', 'is_py3', 'and', '_ver', '[', '1', ']', '==', '3', '\\n']
Tokenized   (027): ['[CLS]', 'is', '_', 'p', '##y', '##3', '_', '3', '=', 'is', '_', 'p', '##y', '##3', 'and', '_', 've', '##r', '[', '1', ']', '=', '=', '3', '\\', 'n', '[SEP]']
Filtered   (025): ['is', '_', 'p', '##y', '##3', '_', '3', '=', 'is', '_', 'p', '##y', '##3', 'and', '_', 've', '##r', '[', '1', ']', '=', '=', '3', '\\', 'n']
Detokenized (011): ['is_p##y##3_3', '=', 'is_p##y##3', 'and', '_ve##r', '[', '1', ']', '==', '3', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "strategy = zlib . Z_DEFAULT_STRATEGY ) : \n"
Original    (008): ['strategy', '=', 'zlib', '.', 'Z_DEFAULT_STRATEGY', ')', ':', '\\n']
Tokenized   (016): ['[CLS]', 'strategy', '=', 'z', '##lib', '.', 'z', '_', 'default', '_', 'strategy', ')', ':', '\\', 'n', '[SEP]']
Filtered   (014): ['strategy', '=', 'z', '##lib', '.', 'z', '_', 'default', '_', 'strategy', ')', ':', '\\', 'n']
Detokenized (008): ['strategy', '=', 'z##lib', '.', 'z_default_strategy', ')', ':', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "secure = self . secure \n"
Original    (006): ['secure', '=', 'self', '.', 'secure', '\\n']
Tokenized   (009): ['[CLS]', 'secure', '=', 'self', '.', 'secure', '\\', 'n', '[SEP]']
Filtered   (007): ['secure', '=', 'self', '.', 'secure', '\\', 'n']
Detokenized (006): ['secure', '=', 'self', '.', 'secure', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "e . huffman_coder = HuffmanEncoder ( REQUEST_CODES , REQUEST_CODES_LENGTH ) \n"
Original    (011): ['e', '.', 'huffman_coder', '=', 'HuffmanEncoder', '(', 'REQUEST_CODES', ',', 'REQUEST_CODES_LENGTH', ')', '\\n']
Tokenized   (028): ['[CLS]', 'e', '.', 'huff', '##man', '_', 'code', '##r', '=', 'huff', '##man', '##en', '##code', '##r', '(', 'request', '_', 'codes', ',', 'request', '_', 'codes', '_', 'length', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['e', '.', 'huff', '##man', '_', 'code', '##r', '=', 'huff', '##man', '##en', '##code', '##r', '(', 'request', '_', 'codes', ',', 'request', '_', 'codes', '_', 'length', ')', '\\', 'n']
Detokenized (011): ['e', '.', 'huff##man_code##r', '=', 'huff##man##en##code##r', '(', 'request_codes', ',', 'request_codes_length', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "train_seq = corpus . read_sequence_list_conll ( input_data , max_sent_len = 15 , max_nr_sent = 1000 ) \n"
Original    (017): ['train_seq', '=', 'corpus', '.', 'read_sequence_list_conll', '(', 'input_data', ',', 'max_sent_len', '=', '15', ',', 'max_nr_sent', '=', '1000', ')', '\\n']
Tokenized   (040): ['[CLS]', 'train', '_', 'se', '##q', '=', 'corpus', '.', 'read', '_', 'sequence', '_', 'list', '_', 'con', '##ll', '(', 'input', '_', 'data', ',', 'max', '_', 'sent', '_', 'len', '=', '15', ',', 'max', '_', 'nr', '_', 'sent', '=', '1000', ')', '\\', 'n', '[SEP]']
Filtered   (038): ['train', '_', 'se', '##q', '=', 'corpus', '.', 'read', '_', 'sequence', '_', 'list', '_', 'con', '##ll', '(', 'input', '_', 'data', ',', 'max', '_', 'sent', '_', 'len', '=', '15', ',', 'max', '_', 'nr', '_', 'sent', '=', '1000', ')', '\\', 'n']
Detokenized (017): ['train_se##q', '=', 'corpus', '.', 'read_sequence_list_con##ll', '(', 'input_data', ',', 'max_sent_len', '=', '15', ',', 'max_nr_sent', '=', '1000', ')', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "pickle . dump ( ( corpus . word_dict , corpus . tag_dict ) , open ( , ) ) \n"
Original    (020): ['pickle', '.', 'dump', '(', '(', 'corpus', '.', 'word_dict', ',', 'corpus', '.', 'tag_dict', ')', ',', 'open', '(', ',', ')', ')', '\\n']
Tokenized   (030): ['[CLS]', 'pick', '##le', '.', 'dump', '(', '(', 'corpus', '.', 'word', '_', 'di', '##ct', ',', 'corpus', '.', 'tag', '_', 'di', '##ct', ')', ',', 'open', '(', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['pick', '##le', '.', 'dump', '(', '(', 'corpus', '.', 'word', '_', 'di', '##ct', ',', 'corpus', '.', 'tag', '_', 'di', '##ct', ')', ',', 'open', '(', ',', ')', ')', '\\', 'n']
Detokenized (020): ['pick##le', '.', 'dump', '(', '(', 'corpus', '.', 'word_di##ct', ',', 'corpus', '.', 'tag_di##ct', ')', ',', 'open', '(', ',', ')', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "total = np . zeros ( self . features . n_feats ) \n"
Original    (013): ['total', '=', 'np', '.', 'zeros', '(', 'self', '.', 'features', '.', 'n_feats', ')', '\\n']
Tokenized   (020): ['[CLS]', 'total', '=', 'np', '.', 'zero', '##s', '(', 'self', '.', 'features', '.', 'n', '_', 'feat', '##s', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['total', '=', 'np', '.', 'zero', '##s', '(', 'self', '.', 'features', '.', 'n', '_', 'feat', '##s', ')', '\\', 'n']
Detokenized (013): ['total', '=', 'np', '.', 'zero##s', '(', 'self', '.', 'features', '.', 'n_feat##s', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "scores = self . features . compute_scores ( feats , self . weights ) \n"
Original    (015): ['scores', '=', 'self', '.', 'features', '.', 'compute_scores', '(', 'feats', ',', 'self', '.', 'weights', ')', '\\n']
Tokenized   (021): ['[CLS]', 'scores', '=', 'self', '.', 'features', '.', 'compute', '_', 'scores', '(', 'feat', '##s', ',', 'self', '.', 'weights', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['scores', '=', 'self', '.', 'features', '.', 'compute', '_', 'scores', '(', 'feat', '##s', ',', 'self', '.', 'weights', ')', '\\', 'n']
Detokenized (015): ['scores', '=', 'self', '.', 'features', '.', 'compute_scores', '(', 'feat##s', ',', 'self', '.', 'weights', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "t0 = 1.0 / ( sigma * eta0 ) \n"
Original    (010): ['t0', '=', '1.0', '/', '(', 'sigma', '*', 'eta0', ')', '\\n']
Tokenized   (017): ['[CLS]', 't', '##0', '=', '1', '.', '0', '/', '(', 'sigma', '*', 'eta', '##0', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['t', '##0', '=', '1', '.', '0', '/', '(', 'sigma', '*', 'eta', '##0', ')', '\\', 'n']
Detokenized (010): ['t##0', '=', '1.0', '/', '(', 'sigma', '*', 'eta##0', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "marginals , logZ = self . decoder . parse_marginals_nonproj ( scores ) \n"
Original    (013): ['marginals', ',', 'logZ', '=', 'self', '.', 'decoder', '.', 'parse_marginals_nonproj', '(', 'scores', ')', '\\n']
Tokenized   (027): ['[CLS]', 'marginal', '##s', ',', 'log', '##z', '=', 'self', '.', 'deco', '##der', '.', 'par', '##se', '_', 'marginal', '##s', '_', 'non', '##pro', '##j', '(', 'scores', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['marginal', '##s', ',', 'log', '##z', '=', 'self', '.', 'deco', '##der', '.', 'par', '##se', '_', 'marginal', '##s', '_', 'non', '##pro', '##j', '(', 'scores', ')', '\\', 'n']
Detokenized (013): ['marginal##s', ',', 'log##z', '=', 'self', '.', 'deco##der', '.', 'par##se_marginal##s_non##pro##j', '(', 'scores', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "score_corr += scores [ h , m ] \n"
Original    (009): ['score_corr', '+=', 'scores', '[', 'h', ',', 'm', ']', '\\n']
Tokenized   (016): ['[CLS]', 'score', '_', 'co', '##rr', '+', '=', 'scores', '[', 'h', ',', 'm', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['score', '_', 'co', '##rr', '+', '=', 'scores', '[', 'h', ',', 'm', ']', '\\', 'n']
Detokenized (009): ['score_co##rr', '+=', 'scores', '[', 'h', ',', 'm', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "features = self . add_final_features ( sequence , sequence . y [ - 1 ] , features ) \n"
Original    (019): ['features', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'sequence', '.', 'y', '[', '-', '1', ']', ',', 'features', ')', '\\n']
Tokenized   (026): ['[CLS]', 'features', '=', 'self', '.', 'add', '_', 'final', '_', 'features', '(', 'sequence', ',', 'sequence', '.', 'y', '[', '-', '1', ']', ',', 'features', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['features', '=', 'self', '.', 'add', '_', 'final', '_', 'features', '(', 'sequence', ',', 'sequence', '.', 'y', '[', '-', '1', ']', ',', 'features', ')', '\\', 'n']
Detokenized (019): ['features', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'sequence', '.', 'y', '[', '-', '1', ']', ',', 'features', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "node_idx = self . add_emission_features ( sequence , pos , y , node_idx ) \n"
Original    (015): ['node_idx', '=', 'self', '.', 'add_emission_features', '(', 'sequence', ',', 'pos', ',', 'y', ',', 'node_idx', ')', '\\n']
Tokenized   (029): ['[CLS]', 'node', '_', 'id', '##x', '=', 'self', '.', 'add', '_', 'emission', '_', 'features', '(', 'sequence', ',', 'po', '##s', ',', 'y', ',', 'node', '_', 'id', '##x', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['node', '_', 'id', '##x', '=', 'self', '.', 'add', '_', 'emission', '_', 'features', '(', 'sequence', ',', 'po', '##s', ',', 'y', ',', 'node', '_', 'id', '##x', ')', '\\', 'n']
Detokenized (015): ['node_id##x', '=', 'self', '.', 'add_emission_features', '(', 'sequence', ',', 'po##s', ',', 'y', ',', 'node_id##x', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "edge_idx = self . add_final_features ( sequence , y_prev , edge_idx ) \n"
Original    (013): ['edge_idx', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'y_prev', ',', 'edge_idx', ')', '\\n']
Tokenized   (029): ['[CLS]', 'edge', '_', 'id', '##x', '=', 'self', '.', 'add', '_', 'final', '_', 'features', '(', 'sequence', ',', 'y', '_', 'pre', '##v', ',', 'edge', '_', 'id', '##x', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['edge', '_', 'id', '##x', '=', 'self', '.', 'add', '_', 'final', '_', 'features', '(', 'sequence', ',', 'y', '_', 'pre', '##v', ',', 'edge', '_', 'id', '##x', ')', '\\', 'n']
Detokenized (013): ['edge_id##x', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'y_pre##v', ',', 'edge_id##x', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "y_name = self . dataset . y_dict . get_label_name ( y ) \n"
Original    (013): ['y_name', '=', 'self', '.', 'dataset', '.', 'y_dict', '.', 'get_label_name', '(', 'y', ')', '\\n']
Tokenized   (026): ['[CLS]', 'y', '_', 'name', '=', 'self', '.', 'data', '##set', '.', 'y', '_', 'di', '##ct', '.', 'get', '_', 'label', '_', 'name', '(', 'y', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['y', '_', 'name', '=', 'self', '.', 'data', '##set', '.', 'y', '_', 'di', '##ct', '.', 'get', '_', 'label', '_', 'name', '(', 'y', ')', '\\', 'n']
Detokenized (013): ['y_name', '=', 'self', '.', 'data##set', '.', 'y_di##ct', '.', 'get_label_name', '(', 'y', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "feat_name = "prev_tag:%s::%s" % ( y_prev_name , y_name ) \n"
Original    (010): ['feat_name', '=', '"prev_tag:%s::%s"', '%', '(', 'y_prev_name', ',', 'y_name', ')', '\\n']
Tokenized   (034): ['[CLS]', 'feat', '_', 'name', '=', '"', 'pre', '##v', '_', 'tag', ':', '%', 's', ':', ':', '%', 's', '"', '%', '(', 'y', '_', 'pre', '##v', '_', 'name', ',', 'y', '_', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['feat', '_', 'name', '=', '"', 'pre', '##v', '_', 'tag', ':', '%', 's', ':', ':', '%', 's', '"', '%', '(', 'y', '_', 'pre', '##v', '_', 'name', ',', 'y', '_', 'name', ')', '\\', 'n']
Detokenized (010): ['feat_name', '=', '"pre##v_tag:%s::%s"', '%', '(', 'y_pre##v_name', ',', 'y_name', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "point_geom . AddPoint ( point [ 0 ] , point [ 1 ] ) \n"
Original    (015): ['point_geom', '.', 'AddPoint', '(', 'point', '[', '0', ']', ',', 'point', '[', '1', ']', ')', '\\n']
Tokenized   (022): ['[CLS]', 'point', '_', 'geo', '##m', '.', 'add', '##point', '(', 'point', '[', '0', ']', ',', 'point', '[', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['point', '_', 'geo', '##m', '.', 'add', '##point', '(', 'point', '[', '0', ']', ',', 'point', '[', '1', ']', ')', '\\', 'n']
Detokenized (015): ['point_geo##m', '.', 'add##point', '(', 'point', '[', '0', ']', ',', 'point', '[', '1', ']', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "longitudes = [ 100 , 110 , 120 , 130 , 140 ] \n"
Original    (014): ['longitudes', '=', '[', '100', ',', '110', ',', '120', ',', '130', ',', '140', ']', '\\n']
Tokenized   (018): ['[CLS]', 'longitude', '##s', '=', '[', '100', ',', '110', ',', '120', ',', '130', ',', '140', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['longitude', '##s', '=', '[', '100', ',', '110', ',', '120', ',', '130', ',', '140', ']', '\\', 'n']
Detokenized (014): ['longitude##s', '=', '[', '100', ',', '110', ',', '120', ',', '130', ',', '140', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "point_1 . AddPoint ( longitudes [ 0 ] , latitudes [ 0 ] , elevation ) \n"
Original    (017): ['point_1', '.', 'AddPoint', '(', 'longitudes', '[', '0', ']', ',', 'latitudes', '[', '0', ']', ',', 'elevation', ')', '\\n']
Tokenized   (025): ['[CLS]', 'point', '_', '1', '.', 'add', '##point', '(', 'longitude', '##s', '[', '0', ']', ',', 'latitude', '##s', '[', '0', ']', ',', 'elevation', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['point', '_', '1', '.', 'add', '##point', '(', 'longitude', '##s', '[', '0', ']', ',', 'latitude', '##s', '[', '0', ']', ',', 'elevation', ')', '\\', 'n']
Detokenized (017): ['point_1', '.', 'add##point', '(', 'longitude##s', '[', '0', ']', ',', 'latitude##s', '[', '0', ']', ',', 'elevation', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "di = np . array ( [ x for x in range ( projected_X . shape [ 1 ] ) ] ) \n"
Original    (023): ['di', '=', 'np', '.', 'array', '(', '[', 'x', 'for', 'x', 'in', 'range', '(', 'projected_X', '.', 'shape', '[', '1', ']', ')', ']', ')', '\\n']
Tokenized   (028): ['[CLS]', 'di', '=', 'np', '.', 'array', '(', '[', 'x', 'for', 'x', 'in', 'range', '(', 'projected', '_', 'x', '.', 'shape', '[', '1', ']', ')', ']', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['di', '=', 'np', '.', 'array', '(', '[', 'x', 'for', 'x', 'in', 'range', '(', 'projected', '_', 'x', '.', 'shape', '[', '1', ']', ')', ']', ')', '\\', 'n']
Detokenized (023): ['di', '=', 'np', '.', 'array', '(', '[', 'x', 'for', 'x', 'in', 'range', '(', 'projected_x', '.', 'shape', '[', '1', ']', ')', ']', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "projected_X = np . c_ [ ids , projected_X ] \n"
Original    (011): ['projected_X', '=', 'np', '.', 'c_', '[', 'ids', ',', 'projected_X', ']', '\\n']
Tokenized   (020): ['[CLS]', 'projected', '_', 'x', '=', 'np', '.', 'c', '_', '[', 'id', '##s', ',', 'projected', '_', 'x', ']', '\\', 'n', '[SEP]']
Filtered   (018): ['projected', '_', 'x', '=', 'np', '.', 'c', '_', '[', 'id', '##s', ',', 'projected', '_', 'x', ']', '\\', 'n']
Detokenized (011): ['projected_x', '=', 'np', '.', 'c_', '[', 'id##s', ',', 'projected_x', ']', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "clusterer . fit ( inverse_x [ : , 1 : ] ) \n"
Original    (013): ['clusterer', '.', 'fit', '(', 'inverse_x', '[', ':', ',', '1', ':', ']', ')', '\\n']
Tokenized   (019): ['[CLS]', 'cluster', '##er', '.', 'fit', '(', 'inverse', '_', 'x', '[', ':', ',', '1', ':', ']', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['cluster', '##er', '.', 'fit', '(', 'inverse', '_', 'x', '[', ':', ',', '1', ':', ']', ')', '\\', 'n']
Detokenized (013): ['cluster##er', '.', 'fit', '(', 'inverse_x', '[', ':', ',', '1', ':', ']', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "complex [ "meta" ] = self . projection \n"
Original    (009): ['complex', '[', '"meta"', ']', '=', 'self', '.', 'projection', '\\n']
Tokenized   (014): ['[CLS]', 'complex', '[', '"', 'meta', '"', ']', '=', 'self', '.', 'projection', '\\', 'n', '[SEP]']
Filtered   (012): ['complex', '[', '"', 'meta', '"', ']', '=', 'self', '.', 'projection', '\\', 'n']
Detokenized (009): ['complex', '[', '"meta"', ']', '=', 'self', '.', 'projection', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "json_s [ "nodes" ] . append ( { "name" : str ( k ) , "tooltip" : tooltip_s , "group" : 2 * int ( np . log ( len ( complex ~~ k2e [ k ] = e \n"
Original    (040): ['json_s', '[', '"nodes"', ']', '.', 'append', '(', '{', '"name"', ':', 'str', '(', 'k', ')', ',', '"tooltip"', ':', 'tooltip_s', ',', '"group"', ':', '2', '*', 'int', '(', 'np', '.', 'log', '(', 'len', '(', 'complex', '~~', 'k2e', '[', 'k', ']', '=', 'e', '\\n']
Tokenized   (063): ['[CLS]', 'j', '##son', '_', 's', '[', '"', 'nodes', '"', ']', '.', 'app', '##end', '(', '{', '"', 'name', '"', ':', 'st', '##r', '(', 'k', ')', ',', '"', 'tool', '##tip', '"', ':', 'tool', '##tip', '_', 's', ',', '"', 'group', '"', ':', '2', '*', 'int', '(', 'np', '.', 'log', '(', 'len', '(', 'complex', '~', '~', 'k', '##2', '##e', '[', 'k', ']', '=', 'e', '\\', 'n', '[SEP]']
Filtered   (061): ['j', '##son', '_', 's', '[', '"', 'nodes', '"', ']', '.', 'app', '##end', '(', '{', '"', 'name', '"', ':', 'st', '##r', '(', 'k', ')', ',', '"', 'tool', '##tip', '"', ':', 'tool', '##tip', '_', 's', ',', '"', 'group', '"', ':', '2', '*', 'int', '(', 'np', '.', 'log', '(', 'len', '(', 'complex', '~', '~', 'k', '##2', '##e', '[', 'k', ']', '=', 'e', '\\', 'n']
Detokenized (040): ['j##son_s', '[', '"nodes"', ']', '.', 'app##end', '(', '{', '"name"', ':', 'st##r', '(', 'k', ')', ',', '"tool##tip"', ':', 'tool##tip_s', ',', '"group"', ':', '2', '*', 'int', '(', 'np', '.', 'log', '(', 'len', '(', 'complex', '~~', 'k##2##e', '[', 'k', ']', '=', 'e', '\\n']
Counter: 61
===================================================================
Hidden states:  (13, 40, 768)
# Extracted words:  40
Sentence         : "width_js = "%s" % width_html \n"
Original    (006): ['width_js', '=', '"%s"', '%', 'width_html', '\\n']
Tokenized   (017): ['[CLS]', 'width', '_', 'j', '##s', '=', '"', '%', 's', '"', '%', 'width', '_', 'html', '\\', 'n', '[SEP]']
Filtered   (015): ['width', '_', 'j', '##s', '=', '"', '%', 's', '"', '%', 'width', '_', 'html', '\\', 'n']
Detokenized (006): ['width_j##s', '=', '"%s"', '%', 'width_html', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "new_settings [ interface ] [ ] [ % protocol ] = server \n"
Original    (013): ['new_settings', '[', 'interface', ']', '[', ']', '[', '%', 'protocol', ']', '=', 'server', '\\n']
Tokenized   (018): ['[CLS]', 'new', '_', 'settings', '[', 'interface', ']', '[', ']', '[', '%', 'protocol', ']', '=', 'server', '\\', 'n', '[SEP]']
Filtered   (016): ['new', '_', 'settings', '[', 'interface', ']', '[', ']', '[', '%', 'protocol', ']', '=', 'server', '\\', 'n']
Detokenized (013): ['new_settings', '[', 'interface', ']', '[', ']', '[', '%', 'protocol', ']', '=', 'server', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "setups = ( less_setup , sass_setup , stylus_setup , sass_erb_setup ) \n"
Original    (012): ['setups', '=', '(', 'less_setup', ',', 'sass_setup', ',', 'stylus_setup', ',', 'sass_erb_setup', ')', '\\n']
Tokenized   (030): ['[CLS]', 'setup', '##s', '=', '(', 'less', '_', 'setup', ',', 'sas', '##s', '_', 'setup', ',', 'st', '##ylus', '_', 'setup', ',', 'sas', '##s', '_', 'er', '##b', '_', 'setup', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['setup', '##s', '=', '(', 'less', '_', 'setup', ',', 'sas', '##s', '_', 'setup', ',', 'st', '##ylus', '_', 'setup', ',', 'sas', '##s', '_', 'er', '##b', '_', 'setup', ')', '\\', 'n']
Detokenized (012): ['setup##s', '=', '(', 'less_setup', ',', 'sas##s_setup', ',', 'st##ylus_setup', ',', 'sas##s_er##b_setup', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fn = self . view . file_name ( ) . encode ( "utf_8" ) \n"
Original    (015): ['fn', '=', 'self', '.', 'view', '.', 'file_name', '(', ')', '.', 'encode', '(', '"utf_8"', ')', '\\n']
Tokenized   (027): ['[CLS]', 'f', '##n', '=', 'self', '.', 'view', '.', 'file', '_', 'name', '(', ')', '.', 'en', '##code', '(', '"', 'ut', '##f', '_', '8', '"', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['f', '##n', '=', 'self', '.', 'view', '.', 'file', '_', 'name', '(', ')', '.', 'en', '##code', '(', '"', 'ut', '##f', '_', '8', '"', ')', '\\', 'n']
Detokenized (015): ['f##n', '=', 'self', '.', 'view', '.', 'file_name', '(', ')', '.', 'en##code', '(', '"ut##f_8"', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "compiled_regex = re . compile ( chosen_setup . regex , re . MULTILINE ) \n"
Original    (015): ['compiled_regex', '=', 're', '.', 'compile', '(', 'chosen_setup', '.', 'regex', ',', 're', '.', 'MULTILINE', ')', '\\n']
Tokenized   (026): ['[CLS]', 'compiled', '_', 'reg', '##ex', '=', 're', '.', 'com', '##pile', '(', 'chosen', '_', 'setup', '.', 'reg', '##ex', ',', 're', '.', 'multi', '##line', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['compiled', '_', 'reg', '##ex', '=', 're', '.', 'com', '##pile', '(', 'chosen', '_', 'setup', '.', 'reg', '##ex', ',', 're', '.', 'multi', '##line', ')', '\\', 'n']
Detokenized (015): ['compiled_reg##ex', '=', 're', '.', 'com##pile', '(', 'chosen_setup', '.', 'reg##ex', ',', 're', '.', 'multi##line', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "file_dir = os . path . dirname ( fn ) . decode ( "utf-8" ) \n"
Original    (016): ['file_dir', '=', 'os', '.', 'path', '.', 'dirname', '(', 'fn', ')', '.', 'decode', '(', '"utf-8"', ')', '\\n']
Tokenized   (029): ['[CLS]', 'file', '_', 'dir', '=', 'os', '.', 'path', '.', 'dir', '##name', '(', 'f', '##n', ')', '.', 'deco', '##de', '(', '"', 'ut', '##f', '-', '8', '"', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['file', '_', 'dir', '=', 'os', '.', 'path', '.', 'dir', '##name', '(', 'f', '##n', ')', '.', 'deco', '##de', '(', '"', 'ut', '##f', '-', '8', '"', ')', '\\', 'n']
Detokenized (016): ['file_dir', '=', 'os', '.', 'path', '.', 'dir##name', '(', 'f##n', ')', '.', 'deco##de', '(', '"ut##f-8"', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "partial_filename = fn_split [ 0 ] + "/_" + fn_split [ 1 ] \n"
Original    (014): ['partial_filename', '=', 'fn_split', '[', '0', ']', '+', '"/_"', '+', 'fn_split', '[', '1', ']', '\\n']
Tokenized   (029): ['[CLS]', 'partial', '_', 'file', '##name', '=', 'f', '##n', '_', 'split', '[', '0', ']', '+', '"', '/', '_', '"', '+', 'f', '##n', '_', 'split', '[', '1', ']', '\\', 'n', '[SEP]']
Filtered   (027): ['partial', '_', 'file', '##name', '=', 'f', '##n', '_', 'split', '[', '0', ']', '+', '"', '/', '_', '"', '+', 'f', '##n', '_', 'split', '[', '1', ']', '\\', 'n']
Detokenized (014): ['partial_file##name', '=', 'f##n_split', '[', '0', ']', '+', '"/_"', '+', 'f##n_split', '[', '1', ']', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "imported_vars = imported_vars + m \n"
Original    (006): ['imported_vars', '=', 'imported_vars', '+', 'm', '\\n']
Tokenized   (015): ['[CLS]', 'imported', '_', 'var', '##s', '=', 'imported', '_', 'var', '##s', '+', 'm', '\\', 'n', '[SEP]']
Filtered   (013): ['imported', '_', 'var', '##s', '=', 'imported', '_', 'var', '##s', '+', 'm', '\\', 'n']
Detokenized (006): ['imported_var##s', '=', 'imported_var##s', '+', 'm', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : ""params" : [ { \n"
Original    (005): ['"params"', ':', '[', '{', '\\n']
Tokenized   (011): ['[CLS]', '"', 'para', '##ms', '"', ':', '[', '{', '\\', 'n', '[SEP]']
Filtered   (009): ['"', 'para', '##ms', '"', ':', '[', '{', '\\', 'n']
Detokenized (005): ['"para##ms"', ':', '[', '{', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "LAT_MAX = + 90.0 \n"
Original    (005): ['LAT_MAX', '=', '+', '90.0', '\\n']
Tokenized   (013): ['[CLS]', 'la', '##t', '_', 'max', '=', '+', '90', '.', '0', '\\', 'n', '[SEP]']
Filtered   (011): ['la', '##t', '_', 'max', '=', '+', '90', '.', '0', '\\', 'n']
Detokenized (005): ['la##t_max', '=', '+', '90.0', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""purple" , "teal" , "lightgray" ] \n"
Original    (007): ['"purple"', ',', '"teal"', ',', '"lightgray"', ']', '\\n']
Tokenized   (019): ['[CLS]', '"', 'purple', '"', ',', '"', 'tea', '##l', '"', ',', '"', 'light', '##gra', '##y', '"', ']', '\\', 'n', '[SEP]']
Filtered   (017): ['"', 'purple', '"', ',', '"', 'tea', '##l', '"', ',', '"', 'light', '##gra', '##y', '"', ']', '\\', 'n']
Detokenized (007): ['"purple"', ',', '"tea##l"', ',', '"light##gra##y"', ']', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "numrange = None , default = None , max_width = 72 ) : \n"
Original    (014): ['numrange', '=', 'None', ',', 'default', '=', 'None', ',', 'max_width', '=', '72', ')', ':', '\\n']
Tokenized   (022): ['[CLS]', 'nu', '##m', '##rang', '##e', '=', 'none', ',', 'default', '=', 'none', ',', 'max', '_', 'width', '=', '72', ')', ':', '\\', 'n', '[SEP]']
Filtered   (020): ['nu', '##m', '##rang', '##e', '=', 'none', ',', 'default', '=', 'none', ',', 'max', '_', 'width', '=', '72', ')', ':', '\\', 'n']
Detokenized (014): ['nu##m##rang##e', '=', 'none', ',', 'default', '=', 'none', ',', 'max_width', '=', '72', ')', ':', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "found_letter . lower ( ) == default . lower ( ) ) ) : \n"
Original    (015): ['found_letter', '.', 'lower', '(', ')', '==', 'default', '.', 'lower', '(', ')', ')', ')', ':', '\\n']
Tokenized   (021): ['[CLS]', 'found', '_', 'letter', '.', 'lower', '(', ')', '=', '=', 'default', '.', 'lower', '(', ')', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (019): ['found', '_', 'letter', '.', 'lower', '(', ')', '=', '=', 'default', '.', 'lower', '(', ')', ')', ')', ':', '\\', 'n']
Detokenized (015): ['found_letter', '.', 'lower', '(', ')', '==', 'default', '.', 'lower', '(', ')', ')', ')', ':', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "option [ : index ] + show_letter + option [ index + 1 : ] \n"
Original    (016): ['option', '[', ':', 'index', ']', '+', 'show_letter', '+', 'option', '[', 'index', '+', '1', ':', ']', '\\n']
Tokenized   (021): ['[CLS]', 'option', '[', ':', 'index', ']', '+', 'show', '_', 'letter', '+', 'option', '[', 'index', '+', '1', ':', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['option', '[', ':', 'index', ']', '+', 'show', '_', 'letter', '+', 'option', '[', 'index', '+', '1', ':', ']', '\\', 'n']
Detokenized (016): ['option', '[', ':', 'index', ']', '+', 'show_letter', '+', 'option', '[', 'index', '+', '1', ':', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "display_letters . append ( found_letter . upper ( ) ) \n"
Original    (011): ['display_letters', '.', 'append', '(', 'found_letter', '.', 'upper', '(', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'display', '_', 'letters', '.', 'app', '##end', '(', 'found', '_', 'letter', '.', 'upper', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['display', '_', 'letters', '.', 'app', '##end', '(', 'found', '_', 'letter', '.', 'upper', '(', ')', ')', '\\', 'n']
Detokenized (011): ['display_letters', '.', 'app##end', '(', 'found_letter', '.', 'upper', '(', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "default_name = self . colorize ( , default_name ) \n"
Original    (010): ['default_name', '=', 'self', '.', 'colorize', '(', ',', 'default_name', ')', '\\n']
Tokenized   (018): ['[CLS]', 'default', '_', 'name', '=', 'self', '.', 'color', '##ize', '(', ',', 'default', '_', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['default', '_', 'name', '=', 'self', '.', 'color', '##ize', '(', ',', 'default', '_', 'name', ')', '\\', 'n']
Detokenized (010): ['default_name', '=', 'self', '.', 'color##ize', '(', ',', 'default_name', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "prompt_parts . append ( tmpl % default_name ) \n"
Original    (009): ['prompt_parts', '.', 'append', '(', 'tmpl', '%', 'default_name', ')', '\\n']
Tokenized   (019): ['[CLS]', 'prompt', '_', 'parts', '.', 'app', '##end', '(', 't', '##mp', '##l', '%', 'default', '_', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['prompt', '_', 'parts', '.', 'app', '##end', '(', 't', '##mp', '##l', '%', 'default', '_', 'name', ')', '\\', 'n']
Detokenized (009): ['prompt_parts', '.', 'app##end', '(', 't##mp##l', '%', 'default_name', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "matcher = SequenceMatcher ( lambda x : False , a , b ) \n"
Original    (014): ['matcher', '=', 'SequenceMatcher', '(', 'lambda', 'x', ':', 'False', ',', 'a', ',', 'b', ')', '\\n']
Tokenized   (020): ['[CLS]', 'match', '##er', '=', 'sequence', '##mat', '##cher', '(', 'lambda', 'x', ':', 'false', ',', 'a', ',', 'b', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['match', '##er', '=', 'sequence', '##mat', '##cher', '(', 'lambda', 'x', ':', 'false', ',', 'a', ',', 'b', ')', '\\', 'n']
Detokenized (014): ['match##er', '=', 'sequence##mat##cher', '(', 'lambda', 'x', ':', 'false', ',', 'a', ',', 'b', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "b_out . append ( self . colorize ( color , b [ b_start : b_end ] ) ) \n"
Original    (019): ['b_out', '.', 'append', '(', 'self', '.', 'colorize', '(', 'color', ',', 'b', '[', 'b_start', ':', 'b_end', ']', ')', ')', '\\n']
Tokenized   (030): ['[CLS]', 'b', '_', 'out', '.', 'app', '##end', '(', 'self', '.', 'color', '##ize', '(', 'color', ',', 'b', '[', 'b', '_', 'start', ':', 'b', '_', 'end', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['b', '_', 'out', '.', 'app', '##end', '(', 'self', '.', 'color', '##ize', '(', 'color', ',', 'b', '[', 'b', '_', 'start', ':', 'b', '_', 'end', ']', ')', ')', '\\', 'n']
Detokenized (019): ['b_out', '.', 'app##end', '(', 'self', '.', 'color##ize', '(', 'color', ',', 'b', '[', 'b_start', ':', 'b_end', ']', ')', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "variable = % varname \n"
Original    (005): ['variable', '=', '%', 'varname', '\\n']
Tokenized   (009): ['[CLS]', 'variable', '=', '%', 'var', '##name', '\\', 'n', '[SEP]']
Filtered   (007): ['variable', '=', '%', 'var', '##name', '\\', 'n']
Detokenized (005): ['variable', '=', '%', 'var##name', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "62 : , \n"
Original    (004): ['62', ':', ',', '\\n']
Tokenized   (007): ['[CLS]', '62', ':', ',', '\\', 'n', '[SEP]']
Filtered   (005): ['62', ':', ',', '\\', 'n']
Detokenized (004): ['62', ':', ',', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "_push . update ( { \n"
Original    (006): ['_push', '.', 'update', '(', '{', '\\n']
Tokenized   (010): ['[CLS]', '_', 'push', '.', 'update', '(', '{', '\\', 'n', '[SEP]']
Filtered   (008): ['_', 'push', '.', 'update', '(', '{', '\\', 'n']
Detokenized (006): ['_push', '.', 'update', '(', '{', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_readonly = Entity . _readonly | { , } \n"
Original    (010): ['_readonly', '=', 'Entity', '.', '_readonly', '|', '{', ',', '}', '\\n']
Tokenized   (019): ['[CLS]', '_', 'read', '##on', '##ly', '=', 'entity', '.', '_', 'read', '##on', '##ly', '|', '{', ',', '}', '\\', 'n', '[SEP]']
Filtered   (017): ['_', 'read', '##on', '##ly', '=', 'entity', '.', '_', 'read', '##on', '##ly', '|', '{', ',', '}', '\\', 'n']
Detokenized (010): ['_read##on##ly', '=', 'entity', '.', '_read##on##ly', '|', '{', ',', '}', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "remove_ids = [ 6 , 7 ] \n"
Original    (008): ['remove_ids', '=', '[', '6', ',', '7', ']', '\\n']
Tokenized   (014): ['[CLS]', 'remove', '_', 'id', '##s', '=', '[', '6', ',', '7', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['remove', '_', 'id', '##s', '=', '[', '6', ',', '7', ']', '\\', 'n']
Detokenized (008): ['remove_id##s', '=', '[', '6', ',', '7', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "remove_advertiser_ids = [ 8 , 9 , 10 ] \n"
Original    (010): ['remove_advertiser_ids', '=', '[', '8', ',', '9', ',', '10', ']', '\\n']
Tokenized   (020): ['[CLS]', 'remove', '_', 'ad', '##vert', '##iser', '_', 'id', '##s', '=', '[', '8', ',', '9', ',', '10', ']', '\\', 'n', '[SEP]']
Filtered   (018): ['remove', '_', 'ad', '##vert', '##iser', '_', 'id', '##s', '=', '[', '8', ',', '9', ',', '10', ']', '\\', 'n']
Detokenized (010): ['remove_ad##vert##iser_id##s', '=', '[', '8', ',', '9', ',', '10', ']', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "num_users , num_items = dataset . shape \n"
Original    (008): ['num_users', ',', 'num_items', '=', 'dataset', '.', 'shape', '\\n']
Tokenized   (018): ['[CLS]', 'nu', '##m', '_', 'users', ',', 'nu', '##m', '_', 'items', '=', 'data', '##set', '.', 'shape', '\\', 'n', '[SEP]']
Filtered   (016): ['nu', '##m', '_', 'users', ',', 'nu', '##m', '_', 'items', '=', 'data', '##set', '.', 'shape', '\\', 'n']
Detokenized (008): ['nu##m_users', ',', 'nu##m_items', '=', 'data##set', '.', 'shape', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "async_job = view . map_async ( process , tasks , retries = 2 ) \n"
Original    (015): ['async_job', '=', 'view', '.', 'map_async', '(', 'process', ',', 'tasks', ',', 'retries', '=', '2', ')', '\\n']
Tokenized   (027): ['[CLS]', 'as', '##yn', '##c', '_', 'job', '=', 'view', '.', 'map', '_', 'as', '##yn', '##c', '(', 'process', ',', 'tasks', ',', 're', '##tries', '=', '2', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['as', '##yn', '##c', '_', 'job', '=', 'view', '.', 'map', '_', 'as', '##yn', '##c', '(', 'process', ',', 'tasks', ',', 're', '##tries', '=', '2', ')', '\\', 'n']
Detokenized (015): ['as##yn##c_job', '=', 'view', '.', 'map_as##yn##c', '(', 'process', ',', 'tasks', ',', 're##tries', '=', '2', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "remaining = len ( tasks ) - len ( done ) \n"
Original    (012): ['remaining', '=', 'len', '(', 'tasks', ')', '-', 'len', '(', 'done', ')', '\\n']
Tokenized   (015): ['[CLS]', 'remaining', '=', 'len', '(', 'tasks', ')', '-', 'len', '(', 'done', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['remaining', '=', 'len', '(', 'tasks', ')', '-', 'len', '(', 'done', ')', '\\', 'n']
Detokenized (012): ['remaining', '=', 'len', '(', 'tasks', ')', '-', 'len', '(', 'done', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "num_items , type ( model ) . __name__ , simsfile ) \n"
Original    (012): ['num_items', ',', 'type', '(', 'model', ')', '.', '__name__', ',', 'simsfile', ')', '\\n']
Tokenized   (024): ['[CLS]', 'nu', '##m', '_', 'items', ',', 'type', '(', 'model', ')', '.', '_', '_', 'name', '_', '_', ',', 'sims', '##fi', '##le', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['nu', '##m', '_', 'items', ',', 'type', '(', 'model', ')', '.', '_', '_', 'name', '_', '_', ',', 'sims', '##fi', '##le', ')', '\\', 'n']
Detokenized (012): ['nu##m_items', ',', 'type', '(', 'model', ')', '.', '__name__', ',', 'sims##fi##le', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "before = text [ : len ( text ) - len ( like ) ] \n"
Original    (016): ['before', '=', 'text', '[', ':', 'len', '(', 'text', ')', '-', 'len', '(', 'like', ')', ']', '\\n']
Tokenized   (019): ['[CLS]', 'before', '=', 'text', '[', ':', 'len', '(', 'text', ')', '-', 'len', '(', 'like', ')', ']', '\\', 'n', '[SEP]']
Filtered   (017): ['before', '=', 'text', '[', ':', 'len', '(', 'text', ')', '-', 'len', '(', 'like', ')', ']', '\\', 'n']
Detokenized (016): ['before', '=', 'text', '[', ':', 'len', '(', 'text', ')', '-', 'len', '(', 'like', ')', ']', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "Version = namedtuple ( , ) \n"
Original    (007): ['Version', '=', 'namedtuple', '(', ',', ')', '\\n']
Tokenized   (012): ['[CLS]', 'version', '=', 'named', '##tu', '##ple', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['version', '=', 'named', '##tu', '##ple', '(', ',', ')', '\\', 'n']
Detokenized (007): ['version', '=', 'named##tu##ple', '(', ',', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_defaults = collections . OrderedDict ( [ \n"
Original    (008): ['_defaults', '=', 'collections', '.', 'OrderedDict', '(', '[', '\\n']
Tokenized   (014): ['[CLS]', '_', 'default', '##s', '=', 'collections', '.', 'ordered', '##dict', '(', '[', '\\', 'n', '[SEP]']
Filtered   (012): ['_', 'default', '##s', '=', 'collections', '.', 'ordered', '##dict', '(', '[', '\\', 'n']
Detokenized (008): ['_default##s', '=', 'collections', '.', 'ordered##dict', '(', '[', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "rootDirectory = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ ) ) , , ) \n"
Original    (027): ['rootDirectory', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'realpath', '(', '__file__', ')', ')', ',', ',', ')', '\\n']
Tokenized   (040): ['[CLS]', 'root', '##di', '##re', '##ctor', '##y', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'real', '##path', '(', '_', '_', 'file', '_', '_', ')', ')', ',', ',', ')', '\\', 'n', '[SEP]']
Filtered   (038): ['root', '##di', '##re', '##ctor', '##y', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'real', '##path', '(', '_', '_', 'file', '_', '_', ')', ')', ',', ',', ')', '\\', 'n']
Detokenized (027): ['root##di##re##ctor##y', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dir##name', '(', 'os', '.', 'path', '.', 'real##path', '(', '__file__', ')', ')', ',', ',', ')', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "httpd . handle_request ( ) from . import TestEnable # \n"
Original    (011): ['httpd', '.', 'handle_request', '(', ')', 'from', '.', 'import', 'TestEnable', '#', '\\n']
Tokenized   (019): ['[CLS]', 'http', '##d', '.', 'handle', '_', 'request', '(', ')', 'from', '.', 'import', 'test', '##ena', '##ble', '#', '\\', 'n', '[SEP]']
Filtered   (017): ['http', '##d', '.', 'handle', '_', 'request', '(', ')', 'from', '.', 'import', 'test', '##ena', '##ble', '#', '\\', 'n']
Detokenized (011): ['http##d', '.', 'handle_request', '(', ')', 'from', '.', 'import', 'test##ena##ble', '#', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "field_names = tuple ( field_names ) , \n"
Original    (008): ['field_names', '=', 'tuple', '(', 'field_names', ')', ',', '\\n']
Tokenized   (016): ['[CLS]', 'field', '_', 'names', '=', 'tu', '##ple', '(', 'field', '_', 'names', ')', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['field', '_', 'names', '=', 'tu', '##ple', '(', 'field', '_', 'names', ')', ',', '\\', 'n']
Detokenized (008): ['field_names', '=', 'tu##ple', '(', 'field_names', ')', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "arg_list = repr ( tuple ( field_names ) ) . replace ( "\'" , "" ) [ 1 : - 1 ] , \n"
Original    (024): ['arg_list', '=', 'repr', '(', 'tuple', '(', 'field_names', ')', ')', '.', 'replace', '(', '"\\\'"', ',', '""', ')', '[', '1', ':', '-', '1', ']', ',', '\\n']
Tokenized   (038): ['[CLS]', 'ar', '##g', '_', 'list', '=', 'rep', '##r', '(', 'tu', '##ple', '(', 'field', '_', 'names', ')', ')', '.', 'replace', '(', '"', '\\', "'", '"', ',', '"', '"', ')', '[', '1', ':', '-', '1', ']', ',', '\\', 'n', '[SEP]']
Filtered   (036): ['ar', '##g', '_', 'list', '=', 'rep', '##r', '(', 'tu', '##ple', '(', 'field', '_', 'names', ')', ')', '.', 'replace', '(', '"', '\\', "'", '"', ',', '"', '"', ')', '[', '1', ':', '-', '1', ']', ',', '\\', 'n']
Detokenized (024): ['ar##g_list', '=', 'rep##r', '(', 'tu##ple', '(', 'field_names', ')', ')', '.', 'replace', '(', '"\\\'"', ',', '""', ')', '[', '1', ':', '-', '1', ']', ',', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "repr_fmt = . join ( _repr_template . format ( name = name ) \n"
Original    (014): ['repr_fmt', '=', '.', 'join', '(', '_repr_template', '.', 'format', '(', 'name', '=', 'name', ')', '\\n']
Tokenized   (025): ['[CLS]', 'rep', '##r', '_', 'fm', '##t', '=', '.', 'join', '(', '_', 'rep', '##r', '_', 'template', '.', 'format', '(', 'name', '=', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['rep', '##r', '_', 'fm', '##t', '=', '.', 'join', '(', '_', 'rep', '##r', '_', 'template', '.', 'format', '(', 'name', '=', 'name', ')', '\\', 'n']
Detokenized (014): ['rep##r_fm##t', '=', '.', 'join', '(', '_rep##r_template', '.', 'format', '(', 'name', '=', 'name', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "field_defs = . join ( _field_template . format ( index = index , name = name ) \n"
Original    (018): ['field_defs', '=', '.', 'join', '(', '_field_template', '.', 'format', '(', 'index', '=', 'index', ',', 'name', '=', 'name', ')', '\\n']
Tokenized   (027): ['[CLS]', 'field', '_', 'def', '##s', '=', '.', 'join', '(', '_', 'field', '_', 'template', '.', 'format', '(', 'index', '=', 'index', ',', 'name', '=', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['field', '_', 'def', '##s', '=', '.', 'join', '(', '_', 'field', '_', 'template', '.', 'format', '(', 'index', '=', 'index', ',', 'name', '=', 'name', ')', '\\', 'n']
Detokenized (018): ['field_def##s', '=', '.', 'join', '(', '_field_template', '.', 'format', '(', 'index', '=', 'index', ',', 'name', '=', 'name', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "OrderedDict = OrderedDict , _property = property , _tuple = tuple ) \n"
Original    (013): ['OrderedDict', '=', 'OrderedDict', ',', '_property', '=', 'property', ',', '_tuple', '=', 'tuple', ')', '\\n']
Tokenized   (022): ['[CLS]', 'ordered', '##dict', '=', 'ordered', '##dict', ',', '_', 'property', '=', 'property', ',', '_', 'tu', '##ple', '=', 'tu', '##ple', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['ordered', '##dict', '=', 'ordered', '##dict', ',', '_', 'property', '=', 'property', ',', '_', 'tu', '##ple', '=', 'tu', '##ple', ')', '\\', 'n']
Detokenized (013): ['ordered##dict', '=', 'ordered##dict', ',', '_property', '=', 'property', ',', '_tu##ple', '=', 'tu##ple', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "xx = Xdf [ ] . values \n"
Original    (008): ['xx', '=', 'Xdf', '[', ']', '.', 'values', '\\n']
Tokenized   (012): ['[CLS]', 'xx', '=', 'x', '##df', '[', ']', '.', 'values', '\\', 'n', '[SEP]']
Filtered   (010): ['xx', '=', 'x', '##df', '[', ']', '.', 'values', '\\', 'n']
Detokenized (008): ['xx', '=', 'x##df', '[', ']', '.', 'values', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "X_CD13 , Y_CD13 = util . get_data ( cd13 , y_names = [ , ] ) \n"
Original    (017): ['X_CD13', ',', 'Y_CD13', '=', 'util', '.', 'get_data', '(', 'cd13', ',', 'y_names', '=', '[', ',', ']', ')', '\\n']
Tokenized   (032): ['[CLS]', 'x', '_', 'cd', '##13', ',', 'y', '_', 'cd', '##13', '=', 'ut', '##il', '.', 'get', '_', 'data', '(', 'cd', '##13', ',', 'y', '_', 'names', '=', '[', ',', ']', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['x', '_', 'cd', '##13', ',', 'y', '_', 'cd', '##13', '=', 'ut', '##il', '.', 'get', '_', 'data', '(', 'cd', '##13', ',', 'y', '_', 'names', '=', '[', ',', ']', ')', '\\', 'n']
Detokenized (017): ['x_cd##13', ',', 'y_cd##13', '=', 'ut##il', '.', 'get_data', '(', 'cd##13', ',', 'y_names', '=', '[', ',', ']', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "cd33 = human_data . xs ( , level = , drop_level = False ) \n"
Original    (015): ['cd33', '=', 'human_data', '.', 'xs', '(', ',', 'level', '=', ',', 'drop_level', '=', 'False', ')', '\\n']
Tokenized   (024): ['[CLS]', 'cd', '##33', '=', 'human', '_', 'data', '.', 'x', '##s', '(', ',', 'level', '=', ',', 'drop', '_', 'level', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['cd', '##33', '=', 'human', '_', 'data', '.', 'x', '##s', '(', ',', 'level', '=', ',', 'drop', '_', 'level', '=', 'false', ')', '\\', 'n']
Detokenized (015): ['cd##33', '=', 'human_data', '.', 'x##s', '(', ',', 'level', '=', ',', 'drop_level', '=', 'false', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "X_CD33 , Y_CD33 = util . get_data ( cd33 , y_names = [ , , ] ) \n"
Original    (018): ['X_CD33', ',', 'Y_CD33', '=', 'util', '.', 'get_data', '(', 'cd33', ',', 'y_names', '=', '[', ',', ',', ']', ')', '\\n']
Tokenized   (033): ['[CLS]', 'x', '_', 'cd', '##33', ',', 'y', '_', 'cd', '##33', '=', 'ut', '##il', '.', 'get', '_', 'data', '(', 'cd', '##33', ',', 'y', '_', 'names', '=', '[', ',', ',', ']', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['x', '_', 'cd', '##33', ',', 'y', '_', 'cd', '##33', '=', 'ut', '##il', '.', 'get', '_', 'data', '(', 'cd', '##33', ',', 'y', '_', 'names', '=', '[', ',', ',', ']', ')', '\\', 'n']
Detokenized (018): ['x_cd##33', ',', 'y_cd##33', '=', 'ut##il', '.', 'get_data', '(', 'cd##33', ',', 'y_names', '=', '[', ',', ',', ']', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "X_CD15 , Y_CD15 = util . get_data ( cd15 , y_names = [ ] ) \n"
Original    (016): ['X_CD15', ',', 'Y_CD15', '=', 'util', '.', 'get_data', '(', 'cd15', ',', 'y_names', '=', '[', ']', ')', '\\n']
Tokenized   (031): ['[CLS]', 'x', '_', 'cd', '##15', ',', 'y', '_', 'cd', '##15', '=', 'ut', '##il', '.', 'get', '_', 'data', '(', 'cd', '##15', ',', 'y', '_', 'names', '=', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['x', '_', 'cd', '##15', ',', 'y', '_', 'cd', '##15', '=', 'ut', '##il', '.', 'get', '_', 'data', '(', 'cd', '##15', ',', 'y', '_', 'names', '=', '[', ']', ')', '\\', 'n']
Detokenized (016): ['x_cd##15', ',', 'y_cd##15', '=', 'ut##il', '.', 'get_data', '(', 'cd##15', ',', 'y_names', '=', '[', ']', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "mouse_Y = pandas . concat ( [ mouse_Y , Y ] , axis = 0 ) \n"
Original    (017): ['mouse_Y', '=', 'pandas', '.', 'concat', '(', '[', 'mouse_Y', ',', 'Y', ']', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (026): ['[CLS]', 'mouse', '_', 'y', '=', 'panda', '##s', '.', 'con', '##cat', '(', '[', 'mouse', '_', 'y', ',', 'y', ']', ',', 'axis', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['mouse', '_', 'y', '=', 'panda', '##s', '.', 'con', '##cat', '(', '[', 'mouse', '_', 'y', ',', 'y', ']', ',', 'axis', '=', '0', ')', '\\', 'n']
Detokenized (017): ['mouse_y', '=', 'panda##s', '.', 'con##cat', '(', '[', 'mouse_y', ',', 'y', ']', ',', 'axis', '=', '0', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "mouse_data = pandas . read_excel ( data_file , sheetname = 1 , index_col = [ 0 , 1 ] ) \n"
Original    (021): ['mouse_data', '=', 'pandas', '.', 'read_excel', '(', 'data_file', ',', 'sheetname', '=', '1', ',', 'index_col', '=', '[', '0', ',', '1', ']', ')', '\\n']
Tokenized   (034): ['[CLS]', 'mouse', '_', 'data', '=', 'panda', '##s', '.', 'read', '_', 'excel', '(', 'data', '_', 'file', ',', 'sheet', '##name', '=', '1', ',', 'index', '_', 'col', '=', '[', '0', ',', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['mouse', '_', 'data', '=', 'panda', '##s', '.', 'read', '_', 'excel', '(', 'data', '_', 'file', ',', 'sheet', '##name', '=', '1', ',', 'index', '_', 'col', '=', '[', '0', ',', '1', ']', ')', '\\', 'n']
Detokenized (021): ['mouse_data', '=', 'panda##s', '.', 'read_excel', '(', 'data_file', ',', 'sheet##name', '=', '1', ',', 'index_col', '=', '[', '0', ',', '1', ']', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "data_efficient [ ] = 1. \n"
Original    (006): ['data_efficient', '[', ']', '=', '1.', '\\n']
Tokenized   (012): ['[CLS]', 'data', '_', 'efficient', '[', ']', '=', '1', '.', '\\', 'n', '[SEP]']
Filtered   (010): ['data', '_', 'efficient', '[', ']', '=', '1', '.', '\\', 'n']
Detokenized (006): ['data_efficient', '[', ']', '=', '1.', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "exp_data [ ] = exp_data . groupby ( ) [ ] . transform ( exp_data [ ] = exp_data . groupby ( ) [ ] . transform ( \n"
Original    (029): ['exp_data', '[', ']', '=', 'exp_data', '.', 'groupby', '(', ')', '[', ']', '.', 'transform', '(', 'exp_data', '[', ']', '=', 'exp_data', '.', 'groupby', '(', ')', '[', ']', '.', 'transform', '(', '\\n']
Tokenized   (046): ['[CLS]', 'ex', '##p', '_', 'data', '[', ']', '=', 'ex', '##p', '_', 'data', '.', 'group', '##by', '(', ')', '[', ']', '.', 'transform', '(', 'ex', '##p', '_', 'data', '[', ']', '=', 'ex', '##p', '_', 'data', '.', 'group', '##by', '(', ')', '[', ']', '.', 'transform', '(', '\\', 'n', '[SEP]']
Filtered   (044): ['ex', '##p', '_', 'data', '[', ']', '=', 'ex', '##p', '_', 'data', '.', 'group', '##by', '(', ')', '[', ']', '.', 'transform', '(', 'ex', '##p', '_', 'data', '[', ']', '=', 'ex', '##p', '_', 'data', '.', 'group', '##by', '(', ')', '[', ']', '.', 'transform', '(', '\\', 'n']
Detokenized (029): ['ex##p_data', '[', ']', '=', 'ex##p_data', '.', 'group##by', '(', ')', '[', ']', '.', 'transform', '(', 'ex##p_data', '[', ']', '=', 'ex##p_data', '.', 'group##by', '(', ')', '[', ']', '.', 'transform', '(', '\\n']
Counter: 44
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "aggregated [ ] = aggregated [ [ , ] ] . mean ( axis = 1 ) \n"
Original    (018): ['aggregated', '[', ']', '=', 'aggregated', '[', '[', ',', ']', ']', '.', 'mean', '(', 'axis', '=', '1', ')', '\\n']
Tokenized   (023): ['[CLS]', 'aggregate', '##d', '[', ']', '=', 'aggregate', '##d', '[', '[', ',', ']', ']', '.', 'mean', '(', 'axis', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['aggregate', '##d', '[', ']', '=', 'aggregate', '##d', '[', '[', ',', ']', ']', '.', 'mean', '(', 'axis', '=', '1', ')', '\\', 'n']
Detokenized (018): ['aggregate##d', '[', ']', '=', 'aggregate##d', '[', '[', ',', ']', ']', '.', 'mean', '(', 'axis', '=', '1', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "known_pairs = { : [ , , , ] , \n"
Original    (011): ['known_pairs', '=', '{', ':', '[', ',', ',', ',', ']', ',', '\\n']
Tokenized   (016): ['[CLS]', 'known', '_', 'pairs', '=', '{', ':', '[', ',', ',', ',', ']', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['known', '_', 'pairs', '=', '{', ':', '[', ',', ',', ',', ']', ',', '\\', 'n']
Detokenized (011): ['known_pairs', '=', '{', ':', '[', ',', ',', ',', ']', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "drugs_to_genes [ ] . extend ( [ , , , , , \n"
Original    (013): ['drugs_to_genes', '[', ']', '.', 'extend', '(', '[', ',', ',', ',', ',', ',', '\\n']
Tokenized   (020): ['[CLS]', 'drugs', '_', 'to', '_', 'genes', '[', ']', '.', 'extend', '(', '[', ',', ',', ',', ',', ',', '\\', 'n', '[SEP]']
Filtered   (018): ['drugs', '_', 'to', '_', 'genes', '[', ']', '.', 'extend', '(', '[', ',', ',', ',', ',', ',', '\\', 'n']
Detokenized (013): ['drugs_to_genes', '[', ']', '.', 'extend', '(', '[', ',', ',', ',', ',', ',', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Xtmp [ ] = drug \n"
Original    (006): ['Xtmp', '[', ']', '=', 'drug', '\\n']
Tokenized   (011): ['[CLS]', 'x', '##tm', '##p', '[', ']', '=', 'drug', '\\', 'n', '[SEP]']
Filtered   (009): ['x', '##tm', '##p', '[', ']', '=', 'drug', '\\', 'n']
Detokenized (006): ['x##tm##p', '[', ']', '=', 'drug', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "y_rank = pandas . concat ( ( y_rank , y_ranktmp ) , axis = 0 ) \n"
Original    (017): ['y_rank', '=', 'pandas', '.', 'concat', '(', '(', 'y_rank', ',', 'y_ranktmp', ')', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (030): ['[CLS]', 'y', '_', 'rank', '=', 'panda', '##s', '.', 'con', '##cat', '(', '(', 'y', '_', 'rank', ',', 'y', '_', 'rank', '##tm', '##p', ')', ',', 'axis', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['y', '_', 'rank', '=', 'panda', '##s', '.', 'con', '##cat', '(', '(', 'y', '_', 'rank', ',', 'y', '_', 'rank', '##tm', '##p', ')', ',', 'axis', '=', '0', ')', '\\', 'n']
Detokenized (017): ['y_rank', '=', 'panda##s', '.', 'con##cat', '(', '(', 'y_rank', ',', 'y_rank##tm##p', ')', ',', 'axis', '=', '0', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "experiments [ ] = [ , , , ] \n"
Original    (010): ['experiments', '[', ']', '=', '[', ',', ',', ',', ']', '\\n']
Tokenized   (013): ['[CLS]', 'experiments', '[', ']', '=', '[', ',', ',', ',', ']', '\\', 'n', '[SEP]']
Filtered   (011): ['experiments', '[', ']', '=', '[', ',', ',', ',', ']', '\\', 'n']
Detokenized (010): ['experiments', '[', ']', '=', '[', ',', ',', ',', ']', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "data_tmp [ "variance" ] = np . var ( data_tmp . values , axis = 1 ) \n"
Original    (018): ['data_tmp', '[', '"variance"', ']', '=', 'np', '.', 'var', '(', 'data_tmp', '.', 'values', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (029): ['[CLS]', 'data', '_', 't', '##mp', '[', '"', 'variance', '"', ']', '=', 'np', '.', 'var', '(', 'data', '_', 't', '##mp', '.', 'values', ',', 'axis', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['data', '_', 't', '##mp', '[', '"', 'variance', '"', ']', '=', 'np', '.', 'var', '(', 'data', '_', 't', '##mp', '.', 'values', ',', 'axis', '=', '1', ')', '\\', 'n']
Detokenized (018): ['data_t##mp', '[', '"variance"', ']', '=', 'np', '.', 'var', '(', 'data_t##mp', '.', 'values', ',', 'axis', '=', '1', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "gene_position_xu , target_genes_xu , Xdf_xu , Y_xu = read_xu_et_al ( data_file3 , learn_options ) \n"
Original    (015): ['gene_position_xu', ',', 'target_genes_xu', ',', 'Xdf_xu', ',', 'Y_xu', '=', 'read_xu_et_al', '(', 'data_file3', ',', 'learn_options', ')', '\\n']
Tokenized   (042): ['[CLS]', 'gene', '_', 'position', '_', 'xu', ',', 'target', '_', 'genes', '_', 'xu', ',', 'x', '##df', '_', 'xu', ',', 'y', '_', 'xu', '=', 'read', '_', 'xu', '_', 'et', '_', 'al', '(', 'data', '_', 'file', '##3', ',', 'learn', '_', 'options', ')', '\\', 'n', '[SEP]']
Filtered   (040): ['gene', '_', 'position', '_', 'xu', ',', 'target', '_', 'genes', '_', 'xu', ',', 'x', '##df', '_', 'xu', ',', 'y', '_', 'xu', '=', 'read', '_', 'xu', '_', 'et', '_', 'al', '(', 'data', '_', 'file', '##3', ',', 'learn', '_', 'options', ')', '\\', 'n']
Detokenized (015): ['gene_position_xu', ',', 'target_genes_xu', ',', 'x##df_xu', ',', 'y_xu', '=', 'read_xu_et_al', '(', 'data_file##3', ',', 'learn_options', ')', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "annotations , gene_position1 , target_genes1 , Xdf1 , Y1 = read_V1_data ( data_file , learn_options ) \n"
Original    (017): ['annotations', ',', 'gene_position1', ',', 'target_genes1', ',', 'Xdf1', ',', 'Y1', '=', 'read_V1_data', '(', 'data_file', ',', 'learn_options', ')', '\\n']
Tokenized   (040): ['[CLS]', 'ann', '##ota', '##tions', ',', 'gene', '_', 'position', '##1', ',', 'target', '_', 'genes', '##1', ',', 'x', '##df', '##1', ',', 'y', '##1', '=', 'read', '_', 'v', '##1', '_', 'data', '(', 'data', '_', 'file', ',', 'learn', '_', 'options', ')', '\\', 'n', '[SEP]']
Filtered   (038): ['ann', '##ota', '##tions', ',', 'gene', '_', 'position', '##1', ',', 'target', '_', 'genes', '##1', ',', 'x', '##df', '##1', ',', 'y', '##1', '=', 'read', '_', 'v', '##1', '_', 'data', '(', 'data', '_', 'file', ',', 'learn', '_', 'options', ')', '\\', 'n']
Detokenized (017): ['ann##ota##tions', ',', 'gene_position##1', ',', 'target_genes##1', ',', 'x##df##1', ',', 'y##1', '=', 'read_v##1_data', '(', 'data_file', ',', 'learn_options', ')', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "Y_cols_to_keep = np . unique ( [ , , , \n"
Original    (011): ['Y_cols_to_keep', '=', 'np', '.', 'unique', '(', '[', ',', ',', ',', '\\n']
Tokenized   (021): ['[CLS]', 'y', '_', 'col', '##s', '_', 'to', '_', 'keep', '=', 'np', '.', 'unique', '(', '[', ',', ',', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['y', '_', 'col', '##s', '_', 'to', '_', 'keep', '=', 'np', '.', 'unique', '(', '[', ',', ',', ',', '\\', 'n']
Detokenized (011): ['y_col##s_to_keep', '=', 'np', '.', 'unique', '(', '[', ',', ',', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "gene_position = pandas . concat ( ( gene_position1 , gene_position2 ) ) \n"
Original    (013): ['gene_position', '=', 'pandas', '.', 'concat', '(', '(', 'gene_position1', ',', 'gene_position2', ')', ')', '\\n']
Tokenized   (026): ['[CLS]', 'gene', '_', 'position', '=', 'panda', '##s', '.', 'con', '##cat', '(', '(', 'gene', '_', 'position', '##1', ',', 'gene', '_', 'position', '##2', ')', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['gene', '_', 'position', '=', 'panda', '##s', '.', 'con', '##cat', '(', '(', 'gene', '_', 'position', '##1', ',', 'gene', '_', 'position', '##2', ')', ')', '\\', 'n']
Detokenized (013): ['gene_position', '=', 'panda##s', '.', 'con##cat', '(', '(', 'gene_position##1', ',', 'gene_position##2', ')', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "onedupind = np . where ( Y . index . duplicated ( ) ) [ 0 ] [ 0 ] \n"
Original    (021): ['onedupind', '=', 'np', '.', 'where', '(', 'Y', '.', 'index', '.', 'duplicated', '(', ')', ')', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (028): ['[CLS]', 'one', '##du', '##pin', '##d', '=', 'np', '.', 'where', '(', 'y', '.', 'index', '.', 'duplicate', '##d', '(', ')', ')', '[', '0', ']', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (026): ['one', '##du', '##pin', '##d', '=', 'np', '.', 'where', '(', 'y', '.', 'index', '.', 'duplicate', '##d', '(', ')', ')', '[', '0', ']', '[', '0', ']', '\\', 'n']
Detokenized (021): ['one##du##pin##d', '=', 'np', '.', 'where', '(', 'y', '.', 'index', '.', 'duplicate##d', '(', ')', ')', '[', '0', ']', '[', '0', ']', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "alldupind = np . where ( Y . index . get_level_values ( 0 ) . values == Y . index [ onedupind ] [ 0 ] ) [ 0 ] \n"
Original    (031): ['alldupind', '=', 'np', '.', 'where', '(', 'Y', '.', 'index', '.', 'get_level_values', '(', '0', ')', '.', 'values', '==', 'Y', '.', 'index', '[', 'onedupind', ']', '[', '0', ']', ')', '[', '0', ']', '\\n']
Tokenized   (045): ['[CLS]', 'all', '##du', '##pin', '##d', '=', 'np', '.', 'where', '(', 'y', '.', 'index', '.', 'get', '_', 'level', '_', 'values', '(', '0', ')', '.', 'values', '=', '=', 'y', '.', 'index', '[', 'one', '##du', '##pin', '##d', ']', '[', '0', ']', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (043): ['all', '##du', '##pin', '##d', '=', 'np', '.', 'where', '(', 'y', '.', 'index', '.', 'get', '_', 'level', '_', 'values', '(', '0', ')', '.', 'values', '=', '=', 'y', '.', 'index', '[', 'one', '##du', '##pin', '##d', ']', '[', '0', ']', ')', '[', '0', ']', '\\', 'n']
Detokenized (031): ['all##du##pin##d', '=', 'np', '.', 'where', '(', 'y', '.', 'index', '.', 'get_level_values', '(', '0', ')', '.', 'values', '==', 'y', '.', 'index', '[', 'one##du##pin##d', ']', '[', '0', ']', ')', '[', '0', ']', '\\n']
Counter: 43
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "newindex [ onedupind ] = ( newindex [ onedupind ] [ 0 ] , newindex [ onedupind ] [ 1 ] , "nodrug2" ) \n"
Original    (025): ['newindex', '[', 'onedupind', ']', '=', '(', 'newindex', '[', 'onedupind', ']', '[', '0', ']', ',', 'newindex', '[', 'onedupind', ']', '[', '1', ']', ',', '"nodrug2"', ')', '\\n']
Tokenized   (047): ['[CLS]', 'new', '##ind', '##ex', '[', 'one', '##du', '##pin', '##d', ']', '=', '(', 'new', '##ind', '##ex', '[', 'one', '##du', '##pin', '##d', ']', '[', '0', ']', ',', 'new', '##ind', '##ex', '[', 'one', '##du', '##pin', '##d', ']', '[', '1', ']', ',', '"', 'nod', '##rug', '##2', '"', ')', '\\', 'n', '[SEP]']
Filtered   (045): ['new', '##ind', '##ex', '[', 'one', '##du', '##pin', '##d', ']', '=', '(', 'new', '##ind', '##ex', '[', 'one', '##du', '##pin', '##d', ']', '[', '0', ']', ',', 'new', '##ind', '##ex', '[', 'one', '##du', '##pin', '##d', ']', '[', '1', ']', ',', '"', 'nod', '##rug', '##2', '"', ')', '\\', 'n']
Detokenized (025): ['new##ind##ex', '[', 'one##du##pin##d', ']', '=', '(', 'new##ind##ex', '[', 'one##du##pin##d', ']', '[', '0', ']', ',', 'new##ind##ex', '[', 'one##du##pin##d', ']', '[', '1', ']', ',', '"nod##rug##2"', ')', '\\n']
Counter: 45
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "Xdf . index = pandas . MultiIndex . from_tuples ( newindex , names = Y . index . names ) \n"
Original    (021): ['Xdf', '.', 'index', '=', 'pandas', '.', 'MultiIndex', '.', 'from_tuples', '(', 'newindex', ',', 'names', '=', 'Y', '.', 'index', '.', 'names', ')', '\\n']
Tokenized   (033): ['[CLS]', 'x', '##df', '.', 'index', '=', 'panda', '##s', '.', 'multi', '##ind', '##ex', '.', 'from', '_', 'tu', '##ples', '(', 'new', '##ind', '##ex', ',', 'names', '=', 'y', '.', 'index', '.', 'names', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['x', '##df', '.', 'index', '=', 'panda', '##s', '.', 'multi', '##ind', '##ex', '.', 'from', '_', 'tu', '##ples', '(', 'new', '##ind', '##ex', ',', 'names', '=', 'y', '.', 'index', '.', 'names', ')', '\\', 'n']
Detokenized (021): ['x##df', '.', 'index', '=', 'panda##s', '.', 'multi##ind##ex', '.', 'from_tu##ples', '(', 'new##ind##ex', ',', 'names', '=', 'y', '.', 'index', '.', 'names', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "mouse_genes = Xdf [ Xdf [ ] == ] [ ] . unique ( ) \n"
Original    (016): ['mouse_genes', '=', 'Xdf', '[', 'Xdf', '[', ']', '==', ']', '[', ']', '.', 'unique', '(', ')', '\\n']
Tokenized   (024): ['[CLS]', 'mouse', '_', 'genes', '=', 'x', '##df', '[', 'x', '##df', '[', ']', '=', '=', ']', '[', ']', '.', 'unique', '(', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['mouse', '_', 'genes', '=', 'x', '##df', '[', 'x', '##df', '[', ']', '=', '=', ']', '[', ']', '.', 'unique', '(', ')', '\\', 'n']
Detokenized (016): ['mouse_genes', '=', 'x##df', '[', 'x##df', '[', ']', '==', ']', '[', ']', '.', 'unique', '(', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "all_genes = get_V3_genes ( None , None ) return np . setdiff1d ( all_genes , mouse_genes ) \n"
Original    (018): ['all_genes', '=', 'get_V3_genes', '(', 'None', ',', 'None', ')', 'return', 'np', '.', 'setdiff1d', '(', 'all_genes', ',', 'mouse_genes', ')', '\\n']
Tokenized   (036): ['[CLS]', 'all', '_', 'genes', '=', 'get', '_', 'v', '##3', '_', 'genes', '(', 'none', ',', 'none', ')', 'return', 'np', '.', 'set', '##di', '##ff', '##1', '##d', '(', 'all', '_', 'genes', ',', 'mouse', '_', 'genes', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['all', '_', 'genes', '=', 'get', '_', 'v', '##3', '_', 'genes', '(', 'none', ',', 'none', ')', 'return', 'np', '.', 'set', '##di', '##ff', '##1', '##d', '(', 'all', '_', 'genes', ',', 'mouse', '_', 'genes', ')', '\\', 'n']
Detokenized (018): ['all_genes', '=', 'get_v##3_genes', '(', 'none', ',', 'none', ')', 'return', 'np', '.', 'set##di##ff##1##d', '(', 'all_genes', ',', 'mouse_genes', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "option_value = self . cfg . migrate [ self . option_name ] \n"
Original    (013): ['option_value', '=', 'self', '.', 'cfg', '.', 'migrate', '[', 'self', '.', 'option_name', ']', '\\n']
Tokenized   (021): ['[CLS]', 'option', '_', 'value', '=', 'self', '.', 'cf', '##g', '.', 'migrate', '[', 'self', '.', 'option', '_', 'name', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['option', '_', 'value', '=', 'self', '.', 'cf', '##g', '.', 'migrate', '[', 'self', '.', 'option', '_', 'name', ']', '\\', 'n']
Detokenized (013): ['option_value', '=', 'self', '.', 'cf##g', '.', 'migrate', '[', 'self', '.', 'option_name', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "search_opts_tenant = kwargs . get ( , { } ) \n"
Original    (011): ['search_opts_tenant', '=', 'kwargs', '.', 'get', '(', ',', '{', '}', ')', '\\n']
Tokenized   (021): ['[CLS]', 'search', '_', 'opt', '##s', '_', 'tenant', '=', 'kw', '##ar', '##gs', '.', 'get', '(', ',', '{', '}', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['search', '_', 'opt', '##s', '_', 'tenant', '=', 'kw', '##ar', '##gs', '.', 'get', '(', ',', '{', '}', ')', '\\', 'n']
Detokenized (011): ['search_opt##s_tenant', '=', 'kw##ar##gs', '.', 'get', '(', ',', '{', '}', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tenants_without_quotas = self . get_tenants_without_quotas ( tenants_src , \n"
Original    (009): ['tenants_without_quotas', '=', 'self', '.', 'get_tenants_without_quotas', '(', 'tenants_src', ',', '\\n']
Tokenized   (027): ['[CLS]', 'tenants', '_', 'without', '_', 'quota', '##s', '=', 'self', '.', 'get', '_', 'tenants', '_', 'without', '_', 'quota', '##s', '(', 'tenants', '_', 'sr', '##c', ',', '\\', 'n', '[SEP]']
Filtered   (025): ['tenants', '_', 'without', '_', 'quota', '##s', '=', 'self', '.', 'get', '_', 'tenants', '_', 'without', '_', 'quota', '##s', '(', 'tenants', '_', 'sr', '##c', ',', '\\', 'n']
Detokenized (009): ['tenants_without_quota##s', '=', 'self', '.', 'get_tenants_without_quota##s', '(', 'tenants_sr##c', ',', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "quot = network_src . show_quota ( tenants_without_quotas [ 0 ] ) \n"
Original    (012): ['quot', '=', 'network_src', '.', 'show_quota', '(', 'tenants_without_quotas', '[', '0', ']', ')', '\\n']
Tokenized   (026): ['[CLS]', 'quo', '##t', '=', 'network', '_', 'sr', '##c', '.', 'show', '_', 'quota', '(', 'tenants', '_', 'without', '_', 'quota', '##s', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['quo', '##t', '=', 'network', '_', 'sr', '##c', '.', 'show', '_', 'quota', '(', 'tenants', '_', 'without', '_', 'quota', '##s', '[', '0', ']', ')', '\\', 'n']
Detokenized (012): ['quo##t', '=', 'network_sr##c', '.', 'show_quota', '(', 'tenants_without_quota##s', '[', '0', ']', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "quot_default_dst [ item_quot ] ) \n"
Original    (006): ['quot_default_dst', '[', 'item_quot', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'quo', '##t', '_', 'default', '_', 'ds', '##t', '[', 'item', '_', 'quo', '##t', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['quo', '##t', '_', 'default', '_', 'ds', '##t', '[', 'item', '_', 'quo', '##t', ']', ')', '\\', 'n']
Detokenized (006): ['quo##t_default_ds##t', '[', 'item_quo##t', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tenants = [ identity_src . keystone_client . tenants . find ( id = tnt_id ) for \n"
Original    (017): ['tenants', '=', '[', 'identity_src', '.', 'keystone_client', '.', 'tenants', '.', 'find', '(', 'id', '=', 'tnt_id', ')', 'for', '\\n']
Tokenized   (027): ['[CLS]', 'tenants', '=', '[', 'identity', '_', 'sr', '##c', '.', 'keystone', '_', 'client', '.', 'tenants', '.', 'find', '(', 'id', '=', 'tnt', '_', 'id', ')', 'for', '\\', 'n', '[SEP]']
Filtered   (025): ['tenants', '=', '[', 'identity', '_', 'sr', '##c', '.', 'keystone', '_', 'client', '.', 'tenants', '.', 'find', '(', 'id', '=', 'tnt', '_', 'id', ')', 'for', '\\', 'n']
Detokenized (017): ['tenants', '=', '[', 'identity_sr##c', '.', 'keystone_client', '.', 'tenants', '.', 'find', '(', 'id', '=', 'tnt_id', ')', 'for', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "tnt_id in filter_tenants_ids_list ] \n"
Original    (005): ['tnt_id', 'in', 'filter_tenants_ids_list', ']', '\\n']
Tokenized   (017): ['[CLS]', 'tnt', '_', 'id', 'in', 'filter', '_', 'tenants', '_', 'id', '##s', '_', 'list', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['tnt', '_', 'id', 'in', 'filter', '_', 'tenants', '_', 'id', '##s', '_', 'list', ']', '\\', 'n']
Detokenized (005): ['tnt_id', 'in', 'filter_tenants_id##s_list', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "instance [ ] [ ] , instance [ ] [ ] ) \n"
Original    (013): ['instance', '[', ']', '[', ']', ',', 'instance', '[', ']', '[', ']', ')', '\\n']
Tokenized   (016): ['[CLS]', 'instance', '[', ']', '[', ']', ',', 'instance', '[', ']', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['instance', '[', ']', '[', ']', ',', 'instance', '[', ']', '[', ']', ')', '\\', 'n']
Detokenized (013): ['instance', '[', ']', '[', ']', ',', 'instance', '[', ']', '[', ']', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "vol [ ] , storage_resource . get_status , , \n"
Original    (010): ['vol', '[', ']', ',', 'storage_resource', '.', 'get_status', ',', ',', '\\n']
Tokenized   (017): ['[CLS]', 'vol', '[', ']', ',', 'storage', '_', 'resource', '.', 'get', '_', 'status', ',', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['vol', '[', ']', ',', 'storage', '_', 'resource', '.', 'get', '_', 'status', ',', ',', '\\', 'n']
Detokenized (010): ['vol', '[', ']', ',', 'storage_resource', '.', 'get_status', ',', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "inst_name = libvirt_instance_name ) ) \n"
Original    (006): ['inst_name', '=', 'libvirt_instance_name', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'ins', '##t', '_', 'name', '=', 'li', '##b', '##vir', '##t', '_', 'instance', '_', 'name', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['ins', '##t', '_', 'name', '=', 'li', '##b', '##vir', '##t', '_', 'instance', '_', 'name', ')', ')', '\\', 'n']
Detokenized (006): ['ins##t_name', '=', 'li##b##vir##t_instance_name', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "dst = instance_image_path ( instance_id ) ) \n"
Original    (008): ['dst', '=', 'instance_image_path', '(', 'instance_id', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'ds', '##t', '=', 'instance', '_', 'image', '_', 'path', '(', 'instance', '_', 'id', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['ds', '##t', '=', 'instance', '_', 'image', '_', 'path', '(', 'instance', '_', 'id', ')', ')', '\\', 'n']
Detokenized (008): ['ds##t', '=', 'instance_image_path', '(', 'instance_id', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "interface . find ( ) ) \n"
Original    (007): ['interface', '.', 'find', '(', ')', ')', '\\n']
Tokenized   (010): ['[CLS]', 'interface', '.', 'find', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['interface', '.', 'find', '(', ')', ')', '\\', 'n']
Detokenized (007): ['interface', '.', 'find', '(', ')', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "mac = self . mac , src = self . source_iface , dst = self . target_iface ) \n"
Original    (019): ['mac', '=', 'self', '.', 'mac', ',', 'src', '=', 'self', '.', 'source_iface', ',', 'dst', '=', 'self', '.', 'target_iface', ')', '\\n']
Tokenized   (030): ['[CLS]', 'mac', '=', 'self', '.', 'mac', ',', 'sr', '##c', '=', 'self', '.', 'source', '_', 'if', '##ace', ',', 'ds', '##t', '=', 'self', '.', 'target', '_', 'if', '##ace', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['mac', '=', 'self', '.', 'mac', ',', 'sr', '##c', '=', 'self', '.', 'source', '_', 'if', '##ace', ',', 'ds', '##t', '=', 'self', '.', 'target', '_', 'if', '##ace', ')', '\\', 'n']
Detokenized (019): ['mac', '=', 'self', '.', 'mac', ',', 'sr##c', '=', 'self', '.', 'source_if##ace', ',', 'ds##t', '=', 'self', '.', 'target_if##ace', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "element . attrib = { attr : value } \n"
Original    (010): ['element', '.', 'attrib', '=', '{', 'attr', ':', 'value', '}', '\\n']
Tokenized   (016): ['[CLS]', 'element', '.', 'at', '##tri', '##b', '=', '{', 'at', '##tr', ':', 'value', '}', '\\', 'n', '[SEP]']
Filtered   (014): ['element', '.', 'at', '##tri', '##b', '=', '{', 'at', '##tr', ':', 'value', '}', '\\', 'n']
Detokenized (010): ['element', '.', 'at##tri##b', '=', '{', 'at##tr', ':', 'value', '}', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "rr . run ( copy . format ( src_file = source_object . path , \n"
Original    (015): ['rr', '.', 'run', '(', 'copy', '.', 'format', '(', 'src_file', '=', 'source_object', '.', 'path', ',', '\\n']
Tokenized   (023): ['[CLS]', 'rr', '.', 'run', '(', 'copy', '.', 'format', '(', 'sr', '##c', '_', 'file', '=', 'source', '_', 'object', '.', 'path', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['rr', '.', 'run', '(', 'copy', '.', 'format', '(', 'sr', '##c', '_', 'file', '=', 'source', '_', 'object', '.', 'path', ',', '\\', 'n']
Detokenized (015): ['rr', '.', 'run', '(', 'copy', '.', 'format', '(', 'sr##c_file', '=', 'source_object', '.', 'path', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "max_bytes = sizeof_format . parse_size ( kwargs . pop ( , 0 ) ) \n"
Original    (015): ['max_bytes', '=', 'sizeof_format', '.', 'parse_size', '(', 'kwargs', '.', 'pop', '(', ',', '0', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'max', '_', 'bytes', '=', 'size', '##of', '_', 'format', '.', 'par', '##se', '_', 'size', '(', 'kw', '##ar', '##gs', '.', 'pop', '(', ',', '0', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['max', '_', 'bytes', '=', 'size', '##of', '_', 'format', '.', 'par', '##se', '_', 'size', '(', 'kw', '##ar', '##gs', '.', 'pop', '(', ',', '0', ')', ')', '\\', 'n']
Detokenized (015): ['max_bytes', '=', 'size##of_format', '.', 'par##se_size', '(', 'kw##ar##gs', '.', 'pop', '(', ',', '0', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "scenario = os . path . splitext ( scenario_filename ) [ 0 ] \n"
Original    (014): ['scenario', '=', 'os', '.', 'path', '.', 'splitext', '(', 'scenario_filename', ')', '[', '0', ']', '\\n']
Tokenized   (022): ['[CLS]', 'scenario', '=', 'os', '.', 'path', '.', 'split', '##ex', '##t', '(', 'scenario', '_', 'file', '##name', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (020): ['scenario', '=', 'os', '.', 'path', '.', 'split', '##ex', '##t', '(', 'scenario', '_', 'file', '##name', ')', '[', '0', ']', '\\', 'n']
Detokenized (014): ['scenario', '=', 'os', '.', 'path', '.', 'split##ex##t', '(', 'scenario_file##name', ')', '[', '0', ']', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "file_name = config . rollback_params [ ] [ ] \n"
Original    (010): ['file_name', '=', 'config', '.', 'rollback_params', '[', ']', '[', ']', '\\n']
Tokenized   (021): ['[CLS]', 'file', '_', 'name', '=', 'con', '##fi', '##g', '.', 'roll', '##back', '_', 'para', '##ms', '[', ']', '[', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['file', '_', 'name', '=', 'con', '##fi', '##g', '.', 'roll', '##back', '_', 'para', '##ms', '[', ']', '[', ']', '\\', 'n']
Detokenized (010): ['file_name', '=', 'con##fi##g', '.', 'roll##back_para##ms', '[', ']', '[', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "pre_file_path = os . path . join ( self . cloudferry_dir , file_name ) \n"
Original    (015): ['pre_file_path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'cloudferry_dir', ',', 'file_name', ')', '\\n']
Tokenized   (028): ['[CLS]', 'pre', '_', 'file', '_', 'path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'cloud', '##fer', '##ry', '_', 'dir', ',', 'file', '_', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['pre', '_', 'file', '_', 'path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'cloud', '##fer', '##ry', '_', 'dir', ',', 'file', '_', 'name', ')', '\\', 'n']
Detokenized (015): ['pre_file_path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'cloud##fer##ry_dir', ',', 'file_name', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "o2 = C ( 2 ) \n"
Original    (007): ['o2', '=', 'C', '(', '2', ')', '\\n']
Tokenized   (011): ['[CLS]', 'o', '##2', '=', 'c', '(', '2', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['o', '##2', '=', 'c', '(', '2', ')', '\\', 'n']
Detokenized (007): ['o##2', '=', 'c', '(', '2', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "org_tag = request . user . get_profile ( ) . org_tag \n"
Original    (012): ['org_tag', '=', 'request', '.', 'user', '.', 'get_profile', '(', ')', '.', 'org_tag', '\\n']
Tokenized   (021): ['[CLS]', 'org', '_', 'tag', '=', 'request', '.', 'user', '.', 'get', '_', 'profile', '(', ')', '.', 'org', '_', 'tag', '\\', 'n', '[SEP]']
Filtered   (019): ['org', '_', 'tag', '=', 'request', '.', 'user', '.', 'get', '_', 'profile', '(', ')', '.', 'org', '_', 'tag', '\\', 'n']
Detokenized (012): ['org_tag', '=', 'request', '.', 'user', '.', 'get_profile', '(', ')', '.', 'org_tag', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "featureset = Recording . objects . filter ( lat__lt = ne_lat , lat__gt = sw_lat , lon__lt = ne_lon , lon__gt = sw_lon \n"
Original    (024): ['featureset', '=', 'Recording', '.', 'objects', '.', 'filter', '(', 'lat__lt', '=', 'ne_lat', ',', 'lat__gt', '=', 'sw_lat', ',', 'lon__lt', '=', 'ne_lon', ',', 'lon__gt', '=', 'sw_lon', '\\n']
Tokenized   (056): ['[CLS]', 'features', '##et', '=', 'recording', '.', 'objects', '.', 'filter', '(', 'la', '##t', '_', '_', 'lt', '=', 'ne', '_', 'la', '##t', ',', 'la', '##t', '_', '_', 'gt', '=', 'sw', '_', 'la', '##t', ',', 'lo', '##n', '_', '_', 'lt', '=', 'ne', '_', 'lo', '##n', ',', 'lo', '##n', '_', '_', 'gt', '=', 'sw', '_', 'lo', '##n', '\\', 'n', '[SEP]']
Filtered   (054): ['features', '##et', '=', 'recording', '.', 'objects', '.', 'filter', '(', 'la', '##t', '_', '_', 'lt', '=', 'ne', '_', 'la', '##t', ',', 'la', '##t', '_', '_', 'gt', '=', 'sw', '_', 'la', '##t', ',', 'lo', '##n', '_', '_', 'lt', '=', 'ne', '_', 'lo', '##n', ',', 'lo', '##n', '_', '_', 'gt', '=', 'sw', '_', 'lo', '##n', '\\', 'n']
Detokenized (024): ['features##et', '=', 'recording', '.', 'objects', '.', 'filter', '(', 'la##t__lt', '=', 'ne_la##t', ',', 'la##t__gt', '=', 'sw_la##t', ',', 'lo##n__lt', '=', 'ne_lo##n', ',', 'lo##n__gt', '=', 'sw_lo##n', '\\n']
Counter: 54
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "httpresponse_kwargs = { : kwargs . pop ( , None ) } \n"
Original    (013): ['httpresponse_kwargs', '=', '{', ':', 'kwargs', '.', 'pop', '(', ',', 'None', ')', '}', '\\n']
Tokenized   (025): ['[CLS]', 'http', '##res', '##pon', '##se', '_', 'kw', '##ar', '##gs', '=', '{', ':', 'kw', '##ar', '##gs', '.', 'pop', '(', ',', 'none', ')', '}', '\\', 'n', '[SEP]']
Filtered   (023): ['http', '##res', '##pon', '##se', '_', 'kw', '##ar', '##gs', '=', '{', ':', 'kw', '##ar', '##gs', '.', 'pop', '(', ',', 'none', ')', '}', '\\', 'n']
Detokenized (013): ['http##res##pon##se_kw##ar##gs', '=', '{', ':', 'kw##ar##gs', '.', 'pop', '(', ',', 'none', ')', '}', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_testing = in sys . argv \n"
Original    (007): ['is_testing', '=', 'in', 'sys', '.', 'argv', '\\n']
Tokenized   (015): ['[CLS]', 'is', '_', 'testing', '=', 'in', 'sy', '##s', '.', 'ar', '##g', '##v', '\\', 'n', '[SEP]']
Filtered   (013): ['is', '_', 'testing', '=', 'in', 'sy', '##s', '.', 'ar', '##g', '##v', '\\', 'n']
Detokenized (007): ['is_testing', '=', 'in', 'sy##s', '.', 'ar##g##v', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "up_time = end_time - self . start_time \n"
Original    (008): ['up_time', '=', 'end_time', '-', 'self', '.', 'start_time', '\\n']
Tokenized   (017): ['[CLS]', 'up', '_', 'time', '=', 'end', '_', 'time', '-', 'self', '.', 'start', '_', 'time', '\\', 'n', '[SEP]']
Filtered   (015): ['up', '_', 'time', '=', 'end', '_', 'time', '-', 'self', '.', 'start', '_', 'time', '\\', 'n']
Detokenized (008): ['up_time', '=', 'end_time', '-', 'self', '.', 'start_time', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "remaining_time = self . count_down_total - datetime . timedelta ( seconds = ( int ( up_time ) ) ) \n"
Original    (020): ['remaining_time', '=', 'self', '.', 'count_down_total', '-', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '(', 'int', '(', 'up_time', ')', ')', ')', '\\n']
Tokenized   (034): ['[CLS]', 'remaining', '_', 'time', '=', 'self', '.', 'count', '_', 'down', '_', 'total', '-', 'date', '##time', '.', 'timed', '##elt', '##a', '(', 'seconds', '=', '(', 'int', '(', 'up', '_', 'time', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['remaining', '_', 'time', '=', 'self', '.', 'count', '_', 'down', '_', 'total', '-', 'date', '##time', '.', 'timed', '##elt', '##a', '(', 'seconds', '=', '(', 'int', '(', 'up', '_', 'time', ')', ')', ')', '\\', 'n']
Detokenized (020): ['remaining_time', '=', 'self', '.', 'count_down_total', '-', 'date##time', '.', 'timed##elt##a', '(', 'seconds', '=', '(', 'int', '(', 'up_time', ')', ')', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "abort_time = time . time ( ) + timeout \n"
Original    (010): ['abort_time', '=', 'time', '.', 'time', '(', ')', '+', 'timeout', '\\n']
Tokenized   (017): ['[CLS]', 'ab', '##ort', '_', 'time', '=', 'time', '.', 'time', '(', ')', '+', 'time', '##out', '\\', 'n', '[SEP]']
Filtered   (015): ['ab', '##ort', '_', 'time', '=', 'time', '.', 'time', '(', ')', '+', 'time', '##out', '\\', 'n']
Detokenized (010): ['ab##ort_time', '=', 'time', '.', 'time', '(', ')', '+', 'time##out', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "elif not stanza . getID ( ) : \n"
Original    (009): ['elif', 'not', 'stanza', '.', 'getID', '(', ')', ':', '\\n']
Tokenized   (014): ['[CLS]', 'eli', '##f', 'not', 'stanza', '.', 'get', '##id', '(', ')', ':', '\\', 'n', '[SEP]']
Filtered   (012): ['eli', '##f', 'not', 'stanza', '.', 'get', '##id', '(', ')', ':', '\\', 'n']
Detokenized (009): ['eli##f', 'not', 'stanza', '.', 'get##id', '(', ')', ':', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_ID = ` ID ` \n"
Original    (006): ['_ID', '=', '`', 'ID', '`', '\\n']
Tokenized   (010): ['[CLS]', '_', 'id', '=', '`', 'id', '`', '\\', 'n', '[SEP]']
Filtered   (008): ['_', 'id', '=', '`', 'id', '`', '\\', 'n']
Detokenized (006): ['_id', '=', '`', 'id', '`', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "__description__ = , \n"
Original    (004): ['__description__', '=', ',', '\\n']
Tokenized   (011): ['[CLS]', '_', '_', 'description', '_', '_', '=', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['_', '_', 'description', '_', '_', '=', ',', '\\', 'n']
Detokenized (004): ['__description__', '=', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "REQUIRES = [ i . strip ( ) for i in open ( "requirements.txt" ) . readlines ( ) ] \n"
Original    (021): ['REQUIRES', '=', '[', 'i', '.', 'strip', '(', ')', 'for', 'i', 'in', 'open', '(', '"requirements.txt"', ')', '.', 'readlines', '(', ')', ']', '\\n']
Tokenized   (030): ['[CLS]', 'requires', '=', '[', 'i', '.', 'strip', '(', ')', 'for', 'i', 'in', 'open', '(', '"', 'requirements', '.', 'tx', '##t', '"', ')', '.', 'read', '##lines', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (028): ['requires', '=', '[', 'i', '.', 'strip', '(', ')', 'for', 'i', 'in', 'open', '(', '"', 'requirements', '.', 'tx', '##t', '"', ')', '.', 'read', '##lines', '(', ')', ']', '\\', 'n']
Detokenized (021): ['requires', '=', '[', 'i', '.', 'strip', '(', ')', 'for', 'i', 'in', 'open', '(', '"requirements.tx##t"', ')', '.', 'read##lines', '(', ')', ']', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "BaseField . __init__ ( self , ** kwargs ) \n"
Original    (010): ['BaseField', '.', '__init__', '(', 'self', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (022): ['[CLS]', 'base', '##field', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['base', '##field', '.', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n']
Detokenized (010): ['base##field', '.', '__in##it__', '(', 'self', ',', '**', 'kw##ar##gs', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "is_list = not hasattr ( items , ) \n"
Original    (009): ['is_list', '=', 'not', 'hasattr', '(', 'items', ',', ')', '\\n']
Tokenized   (016): ['[CLS]', 'is', '_', 'list', '=', 'not', 'has', '##att', '##r', '(', 'items', ',', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['is', '_', 'list', '=', 'not', 'has', '##att', '##r', '(', 'items', ',', ')', '\\', 'n']
Detokenized (009): ['is_list', '=', 'not', 'has##att##r', '(', 'items', ',', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "object_map [ ( collection , doc . id ) ] = doc \n"
Original    (013): ['object_map', '[', '(', 'collection', ',', 'doc', '.', 'id', ')', ']', '=', 'doc', '\\n']
Tokenized   (018): ['[CLS]', 'object', '_', 'map', '[', '(', 'collection', ',', 'doc', '.', 'id', ')', ']', '=', 'doc', '\\', 'n', '[SEP]']
Filtered   (016): ['object', '_', 'map', '[', '(', 'collection', ',', 'doc', '.', 'id', ')', ']', '=', 'doc', '\\', 'n']
Detokenized (013): ['object_map', '[', '(', 'collection', ',', 'doc', '.', 'id', ')', ']', '=', 'doc', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_cls = doc . _data . pop ( , None ) \n"
Original    (012): ['_cls', '=', 'doc', '.', '_data', '.', 'pop', '(', ',', 'None', ')', '\\n']
Tokenized   (018): ['[CLS]', '_', 'cl', '##s', '=', 'doc', '.', '_', 'data', '.', 'pop', '(', ',', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['_', 'cl', '##s', '=', 'doc', '.', '_', 'data', '.', 'pop', '(', ',', 'none', ')', '\\', 'n']
Detokenized (012): ['_cl##s', '=', 'doc', '.', '_data', '.', 'pop', '(', ',', 'none', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "81.4471435546875 , \n"
Original    (003): ['81.4471435546875', ',', '\\n']
Tokenized   (015): ['[CLS]', '81', '.', '44', '##7', '##14', '##35', '##54', '##6', '##8', '##75', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['81', '.', '44', '##7', '##14', '##35', '##54', '##6', '##8', '##75', ',', '\\', 'n']
Detokenized (003): ['81.44##7##14##35##54##6##8##75', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "23.61432859499169 \n"
Original    (002): ['23.61432859499169', '\\n']
Tokenized   (014): ['[CLS]', '23', '.', '61', '##43', '##28', '##59', '##49', '##9', '##16', '##9', '\\', 'n', '[SEP]']
Filtered   (012): ['23', '.', '61', '##43', '##28', '##59', '##49', '##9', '##16', '##9', '\\', 'n']
Detokenized (002): ['23.61##43##28##59##49##9##16##9', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "invalid_coords = [ [ [ [ 1 , 2 ] , [ 3 , 4 ] ] ] ] \n"
Original    (020): ['invalid_coords', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ']', ']', ']', '\\n']
Tokenized   (027): ['[CLS]', 'invalid', '_', 'co', '##ord', '##s', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ']', ']', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['invalid', '_', 'co', '##ord', '##s', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ']', ']', ']', '\\', 'n']
Detokenized (020): ['invalid_co##ord##s', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ']', ']', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "Location ( loc = [ [ [ [ 1 , 2 ] , [ 3 , 4 ] , [ 5 , 6 ] , [ 1 , 2 ] ] ] ] ) . validate ( ) \n"
Original    (039): ['Location', '(', 'loc', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ',', '[', '5', ',', '6', ']', ',', '[', '1', ',', '2', ']', ']', ']', ']', ')', '.', 'validate', '(', ')', '\\n']
Tokenized   (044): ['[CLS]', 'location', '(', 'lo', '##c', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ',', '[', '5', ',', '6', ']', ',', '[', '1', ',', '2', ']', ']', ']', ']', ')', '.', 'valid', '##ate', '(', ')', '\\', 'n', '[SEP]']
Filtered   (042): ['location', '(', 'lo', '##c', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ',', '[', '5', ',', '6', ']', ',', '[', '1', ',', '2', ']', ']', ']', ']', ')', '.', 'valid', '##ate', '(', ')', '\\', 'n']
Detokenized (039): ['location', '(', 'lo##c', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ',', '[', '5', ',', '6', ']', ',', '[', '1', ',', '2', ']', ']', ']', ']', ')', '.', 'valid##ate', '(', ')', '\\n']
Counter: 42
===================================================================
Hidden states:  (13, 39, 768)
# Extracted words:  39
Sentence         : "Parent ( name = ) . save ( ) \n"
Original    (010): ['Parent', '(', 'name', '=', ')', '.', 'save', '(', ')', '\\n']
Tokenized   (013): ['[CLS]', 'parent', '(', 'name', '=', ')', '.', 'save', '(', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['parent', '(', 'name', '=', ')', '.', 'save', '(', ')', '\\', 'n']
Detokenized (010): ['parent', '(', 'name', '=', ')', '.', 'save', '(', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "echo_payload = Struct ( "echo_payload" , \n"
Original    (007): ['echo_payload', '=', 'Struct', '(', '"echo_payload"', ',', '\\n']
Tokenized   (018): ['[CLS]', 'echo', '_', 'payload', '=', 'st', '##ru', '##ct', '(', '"', 'echo', '_', 'payload', '"', ',', '\\', 'n', '[SEP]']
Filtered   (016): ['echo', '_', 'payload', '=', 'st', '##ru', '##ct', '(', '"', 'echo', '_', 'payload', '"', ',', '\\', 'n']
Detokenized (007): ['echo_payload', '=', 'st##ru##ct', '(', '"echo_payload"', ',', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Padding ( 2 ) , \n"
Original    (006): ['Padding', '(', '2', ')', ',', '\\n']
Tokenized   (010): ['[CLS]', 'pad', '##ding', '(', '2', ')', ',', '\\', 'n', '[SEP]']
Filtered   (008): ['pad', '##ding', '(', '2', ')', ',', '\\', 'n']
Detokenized (006): ['pad##ding', '(', '2', ')', ',', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "IpAddress ( "host" ) , \n"
Original    (006): ['IpAddress', '(', '"host"', ')', ',', '\\n']
Tokenized   (013): ['[CLS]', 'ipad', '##dre', '##ss', '(', '"', 'host', '"', ')', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['ipad', '##dre', '##ss', '(', '"', 'host', '"', ')', ',', '\\', 'n']
Detokenized (006): ['ipad##dre##ss', '(', '"host"', ')', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "Bytes ( "echo" , 8 ) , \n"
Original    (008): ['Bytes', '(', '"echo"', ',', '8', ')', ',', '\\n']
Tokenized   (013): ['[CLS]', 'bytes', '(', '"', 'echo', '"', ',', '8', ')', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['bytes', '(', '"', 'echo', '"', ',', '8', ')', ',', '\\', 'n']
Detokenized (008): ['bytes', '(', '"echo"', ',', '8', ')', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "dest_unreachable_code = Enum ( Byte ( "code" ) , \n"
Original    (010): ['dest_unreachable_code', '=', 'Enum', '(', 'Byte', '(', '"code"', ')', ',', '\\n']
Tokenized   (024): ['[CLS]', 'des', '##t', '_', 'un', '##rea', '##cha', '##ble', '_', 'code', '=', 'en', '##um', '(', 'byte', '(', '"', 'code', '"', ')', ',', '\\', 'n', '[SEP]']
Filtered   (022): ['des', '##t', '_', 'un', '##rea', '##cha', '##ble', '_', 'code', '=', 'en', '##um', '(', 'byte', '(', '"', 'code', '"', ')', ',', '\\', 'n']
Detokenized (010): ['des##t_un##rea##cha##ble_code', '=', 'en##um', '(', 'byte', '(', '"code"', ')', ',', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "Enum ( Byte ( "type" ) , \n"
Original    (008): ['Enum', '(', 'Byte', '(', '"type"', ')', ',', '\\n']
Tokenized   (014): ['[CLS]', 'en', '##um', '(', 'byte', '(', '"', 'type', '"', ')', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['en', '##um', '(', 'byte', '(', '"', 'type', '"', ')', ',', '\\', 'n']
Detokenized (008): ['en##um', '(', 'byte', '(', '"type"', ')', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Switch ( "payload" , lambda ctx : ctx . type , \n"
Original    (012): ['Switch', '(', '"payload"', ',', 'lambda', 'ctx', ':', 'ctx', '.', 'type', ',', '\\n']
Tokenized   (019): ['[CLS]', 'switch', '(', '"', 'payload', '"', ',', 'lambda', 'ct', '##x', ':', 'ct', '##x', '.', 'type', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['switch', '(', '"', 'payload', '"', ',', 'lambda', 'ct', '##x', ':', 'ct', '##x', '.', 'type', ',', '\\', 'n']
Detokenized (012): ['switch', '(', '"payload"', ',', 'lambda', 'ct##x', ':', 'ct##x', '.', 'type', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""63646566676869" ) . decode ( "hex" ) \n"
Original    (008): ['"63646566676869"', ')', '.', 'decode', '(', '"hex"', ')', '\\n']
Tokenized   (025): ['[CLS]', '"', '63', '##64', '##65', '##66', '##6', '##7', '##6', '##86', '##9', '"', ')', '.', 'deco', '##de', '(', '"', 'he', '##x', '"', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['"', '63', '##64', '##65', '##66', '##6', '##7', '##6', '##86', '##9', '"', ')', '.', 'deco', '##de', '(', '"', 'he', '##x', '"', ')', '\\', 'n']
Detokenized (008): ['"63##64##65##66##6##7##6##86##9"', ')', '.', 'deco##de', '(', '"he##x"', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "cap2 = ( "0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162" \n"
Original    (005): ['cap2', '=', '(', '"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', '\\n']
Tokenized   (056): ['[CLS]', 'cap', '##2', '=', '(', '"', '000', '##0', '##38', '##5', '##c', '##0', '##200', '##1', '##b', '##00', '##6', '##16', '##26', '##36', '##46', '##56', '##66', '##7', '##6', '##86', '##9', '##6', '##a', '##6', '##b', '##6', '##c', '##6', '##d', '##6', '##e', '##6', '##f', '##70', '##7', '##17', '##27', '##37', '##47', '##57', '##6', '##7', '##7', '##6', '##16', '##2', '"', '\\', 'n', '[SEP]']
Filtered   (054): ['cap', '##2', '=', '(', '"', '000', '##0', '##38', '##5', '##c', '##0', '##200', '##1', '##b', '##00', '##6', '##16', '##26', '##36', '##46', '##56', '##66', '##7', '##6', '##86', '##9', '##6', '##a', '##6', '##b', '##6', '##c', '##6', '##d', '##6', '##e', '##6', '##f', '##70', '##7', '##17', '##27', '##37', '##47', '##57', '##6', '##7', '##7', '##6', '##16', '##2', '"', '\\', 'n']
Detokenized (005): ['cap##2', '=', '(', '"000##0##38##5##c##0##200##1##b##00##6##16##26##36##46##56##66##7##6##86##9##6##a##6##b##6##c##6##d##6##e##6##f##70##7##17##27##37##47##57##6##7##7##6##16##2"', '\\n']
Counter: 54
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "cap3 = ( "0301000000001122aabbccdd0102030405060708" ) . decode ( "hex" ) \n"
Original    (011): ['cap3', '=', '(', '"0301000000001122aabbccdd0102030405060708"', ')', '.', 'decode', '(', '"hex"', ')', '\\n']
Tokenized   (041): ['[CLS]', 'cap', '##3', '=', '(', '"', '03', '##01', '##00', '##00', '##00', '##00', '##11', '##22', '##aa', '##bb', '##cc', '##dd', '##01', '##0', '##20', '##30', '##40', '##50', '##60', '##70', '##8', '"', ')', '.', 'deco', '##de', '(', '"', 'he', '##x', '"', ')', '\\', 'n', '[SEP]']
Filtered   (039): ['cap', '##3', '=', '(', '"', '03', '##01', '##00', '##00', '##00', '##00', '##11', '##22', '##aa', '##bb', '##cc', '##dd', '##01', '##0', '##20', '##30', '##40', '##50', '##60', '##70', '##8', '"', ')', '.', 'deco', '##de', '(', '"', 'he', '##x', '"', ')', '\\', 'n']
Detokenized (011): ['cap##3', '=', '(', '"03##01##00##00##00##00##11##22##aa##bb##cc##dd##01##0##20##30##40##50##60##70##8"', ')', '.', 'deco##de', '(', '"he##x"', ')', '\\n']
Counter: 39
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "intps [ ] = dest_target . vlan \n"
Original    (008): ['intps', '[', ']', '=', 'dest_target', '.', 'vlan', '\\n']
Tokenized   (016): ['[CLS]', 'int', '##ps', '[', ']', '=', 'des', '##t', '_', 'target', '.', 'v', '##lan', '\\', 'n', '[SEP]']
Filtered   (014): ['int', '##ps', '[', ']', '=', 'des', '##t', '_', 'target', '.', 'v', '##lan', '\\', 'n']
Detokenized (008): ['int##ps', '[', ']', '=', 'des##t_target', '.', 'v##lan', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "router , interface = ri . split ( ) \n"
Original    (010): ['router', ',', 'interface', '=', 'ri', '.', 'split', '(', ')', '\\n']
Tokenized   (014): ['[CLS]', 'route', '##r', ',', 'interface', '=', 'ri', '.', 'split', '(', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['route', '##r', ',', 'interface', '=', 'ri', '.', 'split', '(', ')', '\\', 'n']
Detokenized (010): ['route##r', ',', 'interface', '=', 'ri', '.', 'split', '(', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "cm = NCSVPNConnectionManager ( ncs_services_url , user , password , port_map , name ) \n"
Original    (015): ['cm', '=', 'NCSVPNConnectionManager', '(', 'ncs_services_url', ',', 'user', ',', 'password', ',', 'port_map', ',', 'name', ')', '\\n']
Tokenized   (034): ['[CLS]', 'cm', '=', 'nc', '##s', '##v', '##p', '##nco', '##nne', '##ction', '##mana', '##ger', '(', 'nc', '##s', '_', 'services', '_', 'ur', '##l', ',', 'user', ',', 'password', ',', 'port', '_', 'map', ',', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['cm', '=', 'nc', '##s', '##v', '##p', '##nco', '##nne', '##ction', '##mana', '##ger', '(', 'nc', '##s', '_', 'services', '_', 'ur', '##l', ',', 'user', ',', 'password', ',', 'port', '_', 'map', ',', 'name', ')', '\\', 'n']
Detokenized (015): ['cm', '=', 'nc##s##v##p##nco##nne##ction##mana##ger', '(', 'nc##s_services_ur##l', ',', 'user', ',', 'password', ',', 'port_map', ',', 'name', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "soap_resource . registerDecoder ( actions . QUERY_RECURSIVE , self . queryRecursive ) \n"
Original    (013): ['soap_resource', '.', 'registerDecoder', '(', 'actions', '.', 'QUERY_RECURSIVE', ',', 'self', '.', 'queryRecursive', ')', '\\n']
Tokenized   (029): ['[CLS]', 'soap', '_', 'resource', '.', 'register', '##de', '##code', '##r', '(', 'actions', '.', 'query', '_', 'rec', '##urs', '##ive', ',', 'self', '.', 'query', '##re', '##cu', '##rs', '##ive', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['soap', '_', 'resource', '.', 'register', '##de', '##code', '##r', '(', 'actions', '.', 'query', '_', 'rec', '##urs', '##ive', ',', 'self', '.', 'query', '##re', '##cu', '##rs', '##ive', ')', '\\', 'n']
Detokenized (013): ['soap_resource', '.', 'register##de##code##r', '(', 'actions', '.', 'query_rec##urs##ive', ',', 'self', '.', 'query##re##cu##rs##ive', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "soap_fault = soapresource . SOAPFault ( err . getErrorMessage ( ) , ex_element ) \n"
Original    (015): ['soap_fault', '=', 'soapresource', '.', 'SOAPFault', '(', 'err', '.', 'getErrorMessage', '(', ')', ',', 'ex_element', ')', '\\n']
Tokenized   (033): ['[CLS]', 'soap', '_', 'fault', '=', 'soap', '##res', '##our', '##ce', '.', 'soap', '##fa', '##ult', '(', 'er', '##r', '.', 'get', '##er', '##ror', '##mes', '##sa', '##ge', '(', ')', ',', 'ex', '_', 'element', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['soap', '_', 'fault', '=', 'soap', '##res', '##our', '##ce', '.', 'soap', '##fa', '##ult', '(', 'er', '##r', '.', 'get', '##er', '##ror', '##mes', '##sa', '##ge', '(', ')', ',', 'ex', '_', 'element', ')', '\\', 'n']
Detokenized (015): ['soap_fault', '=', 'soap##res##our##ce', '.', 'soap##fa##ult', '(', 'er##r', '.', 'get##er##ror##mes##sa##ge', '(', ')', ',', 'ex_element', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "symmetric = p2ps . symmetricPath or False sd = nsa . Point2PointService ( src_stp , dst_stp , p2ps . capacity , p2ps . directionality , symmetric , \n"
Original    (028): ['symmetric', '=', 'p2ps', '.', 'symmetricPath', 'or', 'False', 'sd', '=', 'nsa', '.', 'Point2PointService', '(', 'src_stp', ',', 'dst_stp', ',', 'p2ps', '.', 'capacity', ',', 'p2ps', '.', 'directionality', ',', 'symmetric', ',', '\\n']
Tokenized   (052): ['[CLS]', 'symmetric', '=', 'p', '##2', '##ps', '.', 'symmetric', '##path', 'or', 'false', 'sd', '=', 'nsa', '.', 'point', '##2', '##points', '##er', '##vic', '##e', '(', 'sr', '##c', '_', 'st', '##p', ',', 'ds', '##t', '_', 'st', '##p', ',', 'p', '##2', '##ps', '.', 'capacity', ',', 'p', '##2', '##ps', '.', 'directional', '##ity', ',', 'symmetric', ',', '\\', 'n', '[SEP]']
Filtered   (050): ['symmetric', '=', 'p', '##2', '##ps', '.', 'symmetric', '##path', 'or', 'false', 'sd', '=', 'nsa', '.', 'point', '##2', '##points', '##er', '##vic', '##e', '(', 'sr', '##c', '_', 'st', '##p', ',', 'ds', '##t', '_', 'st', '##p', ',', 'p', '##2', '##ps', '.', 'capacity', ',', 'p', '##2', '##ps', '.', 'directional', '##ity', ',', 'symmetric', ',', '\\', 'n']
Detokenized (028): ['symmetric', '=', 'p##2##ps', '.', 'symmetric##path', 'or', 'false', 'sd', '=', 'nsa', '.', 'point##2##points##er##vic##e', '(', 'sr##c_st##p', ',', 'ds##t_st##p', ',', 'p##2##ps', '.', 'capacity', ',', 'p##2##ps', '.', 'directional##ity', ',', 'symmetric', ',', '\\n']
Counter: 50
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "crt = nsa . Criteria ( criteria . version , schedule , sd ) \n"
Original    (015): ['crt', '=', 'nsa', '.', 'Criteria', '(', 'criteria', '.', 'version', ',', 'schedule', ',', 'sd', ')', '\\n']
Tokenized   (019): ['[CLS]', 'cr', '##t', '=', 'nsa', '.', 'criteria', '(', 'criteria', '.', 'version', ',', 'schedule', ',', 'sd', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['cr', '##t', '=', 'nsa', '.', 'criteria', '(', 'criteria', '.', 'version', ',', 'schedule', ',', 'sd', ')', '\\', 'n']
Detokenized (015): ['cr##t', '=', 'nsa', '.', 'criteria', '(', 'criteria', '.', 'version', ',', 'schedule', ',', 'sd', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tc = json . load ( open ( tcf ) ) \n"
Original    (012): ['tc', '=', 'json', '.', 'load', '(', 'open', '(', 'tcf', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 'tc', '=', 'j', '##son', '.', 'load', '(', 'open', '(', 'tc', '##f', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['tc', '=', 'j', '##son', '.', 'load', '(', 'open', '(', 'tc', '##f', ')', ')', '\\', 'n']
Detokenized (012): ['tc', '=', 'j##son', '.', 'load', '(', 'open', '(', 'tc##f', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "source_stp = nsa . STP ( , , labels = [ nsa . Label ( nml . ETHERNET_VLAN , dest_stp = nsa . STP ( , , labels = [ nsa . Label ( nml . ETHERNET_VLAN , start_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = 2 ) \n"
Original    (057): ['source_stp', '=', 'nsa', '.', 'STP', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'Label', '(', 'nml', '.', 'ETHERNET_VLAN', ',', 'dest_stp', '=', 'nsa', '.', 'STP', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'Label', '(', 'nml', '.', 'ETHERNET_VLAN', ',', 'start_time', '=', 'datetime', '.', 'datetime', '.', 'utcnow', '(', ')', '+', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '2', ')', '\\n']
Tokenized   (085): ['[CLS]', 'source', '_', 'st', '##p', '=', 'nsa', '.', 'st', '##p', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'label', '(', 'nm', '##l', '.', 'ethernet', '_', 'v', '##lan', ',', 'des', '##t', '_', 'st', '##p', '=', 'nsa', '.', 'st', '##p', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'label', '(', 'nm', '##l', '.', 'ethernet', '_', 'v', '##lan', ',', 'start', '_', 'time', '=', 'date', '##time', '.', 'date', '##time', '.', 'utc', '##now', '(', ')', '+', 'date', '##time', '.', 'timed', '##elt', '##a', '(', 'seconds', '=', '2', ')', '\\', 'n', '[SEP]']
Filtered   (083): ['source', '_', 'st', '##p', '=', 'nsa', '.', 'st', '##p', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'label', '(', 'nm', '##l', '.', 'ethernet', '_', 'v', '##lan', ',', 'des', '##t', '_', 'st', '##p', '=', 'nsa', '.', 'st', '##p', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'label', '(', 'nm', '##l', '.', 'ethernet', '_', 'v', '##lan', ',', 'start', '_', 'time', '=', 'date', '##time', '.', 'date', '##time', '.', 'utc', '##now', '(', ')', '+', 'date', '##time', '.', 'timed', '##elt', '##a', '(', 'seconds', '=', '2', ')', '\\', 'n']
Detokenized (057): ['source_st##p', '=', 'nsa', '.', 'st##p', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'label', '(', 'nm##l', '.', 'ethernet_v##lan', ',', 'des##t_st##p', '=', 'nsa', '.', 'st##p', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'label', '(', 'nm##l', '.', 'ethernet_v##lan', ',', 'start_time', '=', 'date##time', '.', 'date##time', '.', 'utc##now', '(', ')', '+', 'date##time', '.', 'timed##elt##a', '(', 'seconds', '=', '2', ')', '\\n']
Counter: 83
===================================================================
Hidden states:  (13, 57, 768)
# Extracted words:  57
Sentence         : "end_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = 30 ) \n"
Original    (019): ['end_time', '=', 'datetime', '.', 'datetime', '.', 'utcnow', '(', ')', '+', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '30', ')', '\\n']
Tokenized   (030): ['[CLS]', 'end', '_', 'time', '=', 'date', '##time', '.', 'date', '##time', '.', 'utc', '##now', '(', ')', '+', 'date', '##time', '.', 'timed', '##elt', '##a', '(', 'seconds', '=', '30', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['end', '_', 'time', '=', 'date', '##time', '.', 'date', '##time', '.', 'utc', '##now', '(', ')', '+', 'date', '##time', '.', 'timed', '##elt', '##a', '(', 'seconds', '=', '30', ')', '\\', 'n']
Detokenized (019): ['end_time', '=', 'date##time', '.', 'date##time', '.', 'utc##now', '(', ')', '+', 'date##time', '.', 'timed##elt##a', '(', 'seconds', '=', '30', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "connection_id , active , version_consistent , version , timestamp = yield d_down \n"
Original    (013): ['connection_id', ',', 'active', ',', 'version_consistent', ',', 'version', ',', 'timestamp', '=', 'yield', 'd_down', '\\n']
Tokenized   (024): ['[CLS]', 'connection', '_', 'id', ',', 'active', ',', 'version', '_', 'consistent', ',', 'version', ',', 'times', '##tam', '##p', '=', 'yield', 'd', '_', 'down', '\\', 'n', '[SEP]']
Filtered   (022): ['connection', '_', 'id', ',', 'active', ',', 'version', '_', 'consistent', ',', 'version', ',', 'times', '##tam', '##p', '=', 'yield', 'd', '_', 'down', '\\', 'n']
Detokenized (013): ['connection_id', ',', 'active', ',', 'version_consistent', ',', 'version', ',', 'times##tam##p', '=', 'yield', 'd_down', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "scheduler = digits . scheduler . Scheduler ( config_value ( ) , True ) \n"
Original    (015): ['scheduler', '=', 'digits', '.', 'scheduler', '.', 'Scheduler', '(', 'config_value', '(', ')', ',', 'True', ')', '\\n']
Tokenized   (025): ['[CLS]', 'schedule', '##r', '=', 'digits', '.', 'schedule', '##r', '.', 'schedule', '##r', '(', 'con', '##fi', '##g', '_', 'value', '(', ')', ',', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['schedule', '##r', '=', 'digits', '.', 'schedule', '##r', '.', 'schedule', '##r', '(', 'con', '##fi', '##g', '_', 'value', '(', ')', ',', 'true', ')', '\\', 'n']
Detokenized (015): ['schedule##r', '=', 'digits', '.', 'schedule##r', '.', 'schedule##r', '(', 'con##fi##g_value', '(', ')', ',', 'true', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "row_index = int ( params [ ] [ 0 ] ) \n"
Original    (012): ['row_index', '=', 'int', '(', 'params', '[', ']', '[', '0', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'row', '_', 'index', '=', 'int', '(', 'para', '##ms', '[', ']', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['row', '_', 'index', '=', 'int', '(', 'para', '##ms', '[', ']', '[', '0', ']', ')', '\\', 'n']
Detokenized (012): ['row_index', '=', 'int', '(', 'para##ms', '[', ']', '[', '0', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "char_index = int ( params [ ] [ 0 ] ) - 1 \n"
Original    (014): ['char_index', '=', 'int', '(', 'params', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Tokenized   (020): ['[CLS]', 'char', '_', 'index', '=', 'int', '(', 'para', '##ms', '[', ']', '[', '0', ']', ')', '-', '1', '\\', 'n', '[SEP]']
Filtered   (018): ['char', '_', 'index', '=', 'int', '(', 'para', '##ms', '[', ']', '[', '0', ']', ')', '-', '1', '\\', 'n']
Detokenized (014): ['char_index', '=', 'int', '(', 'para##ms', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "comparator = comparators . index ( params [ ] [ 0 ] ) - 1 \n"
Original    (016): ['comparator', '=', 'comparators', '.', 'index', '(', 'params', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Tokenized   (024): ['[CLS]', 'com', '##para', '##tor', '=', 'com', '##para', '##tors', '.', 'index', '(', 'para', '##ms', '[', ']', '[', '0', ']', ')', '-', '1', '\\', 'n', '[SEP]']
Filtered   (022): ['com', '##para', '##tor', '=', 'com', '##para', '##tors', '.', 'index', '(', 'para', '##ms', '[', ']', '[', '0', ']', ')', '-', '1', '\\', 'n']
Detokenized (016): ['com##para##tor', '=', 'com##para##tors', '.', 'index', '(', 'para##ms', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "truth = ( cmp ( ord ( current_character ) , test_char ) == comparator ) \n"
Original    (016): ['truth', '=', '(', 'cmp', '(', 'ord', '(', 'current_character', ')', ',', 'test_char', ')', '==', 'comparator', ')', '\\n']
Tokenized   (028): ['[CLS]', 'truth', '=', '(', 'cm', '##p', '(', 'or', '##d', '(', 'current', '_', 'character', ')', ',', 'test', '_', 'char', ')', '=', '=', 'com', '##para', '##tor', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['truth', '=', '(', 'cm', '##p', '(', 'or', '##d', '(', 'current', '_', 'character', ')', ',', 'test', '_', 'char', ')', '=', '=', 'com', '##para', '##tor', ')', '\\', 'n']
Detokenized (016): ['truth', '=', '(', 'cm##p', '(', 'or##d', '(', 'current_character', ')', ',', 'test_char', ')', '==', 'com##para##tor', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "start_response ( , [ ( , ) ] ) \n"
Original    (010): ['start_response', '(', ',', '[', '(', ',', ')', ']', ')', '\\n']
Tokenized   (015): ['[CLS]', 'start', '_', 'response', '(', ',', '[', '(', ',', ')', ']', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['start', '_', 'response', '(', ',', '[', '(', ',', ')', ']', ')', '\\', 'n']
Detokenized (010): ['start_response', '(', ',', '[', '(', ',', ')', ']', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "CHARSET = [ chr ( x ) for x in xrange ( 32 , 127 ) ] \n"
Original    (018): ['CHARSET', '=', '[', 'chr', '(', 'x', ')', 'for', 'x', 'in', 'xrange', '(', '32', ',', '127', ')', ']', '\\n']
Tokenized   (025): ['[CLS]', 'char', '##set', '=', '[', 'ch', '##r', '(', 'x', ')', 'for', 'x', 'in', 'x', '##rang', '##e', '(', '32', ',', '127', ')', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['char', '##set', '=', '[', 'ch', '##r', '(', 'x', ')', 'for', 'x', 'in', 'x', '##rang', '##e', '(', '32', ',', '127', ')', ']', '\\', 'n']
Detokenized (018): ['char##set', '=', '[', 'ch##r', '(', 'x', ')', 'for', 'x', 'in', 'x##rang##e', '(', '32', ',', '127', ')', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "obj_struct [ ] = [ int ( bbox . find ( ) . text ) , \n"
Original    (017): ['obj_struct', '[', ']', '=', '[', 'int', '(', 'bbox', '.', 'find', '(', ')', '.', 'text', ')', ',', '\\n']
Tokenized   (026): ['[CLS]', 'ob', '##j', '_', 'st', '##ru', '##ct', '[', ']', '=', '[', 'int', '(', 'bb', '##ox', '.', 'find', '(', ')', '.', 'text', ')', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['ob', '##j', '_', 'st', '##ru', '##ct', '[', ']', '=', '[', 'int', '(', 'bb', '##ox', '.', 'find', '(', ')', '.', 'text', ')', ',', '\\', 'n']
Detokenized (017): ['ob##j_st##ru##ct', '[', ']', '=', '[', 'int', '(', 'bb##ox', '.', 'find', '(', ')', '.', 'text', ')', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "int ( bbox . find ( ) . text ) ] \n"
Original    (012): ['int', '(', 'bbox', '.', 'find', '(', ')', '.', 'text', ')', ']', '\\n']
Tokenized   (016): ['[CLS]', 'int', '(', 'bb', '##ox', '.', 'find', '(', ')', '.', 'text', ')', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['int', '(', 'bb', '##ox', '.', 'find', '(', ')', '.', 'text', ')', ']', '\\', 'n']
Detokenized (012): ['int', '(', 'bb##ox', '.', 'find', '(', ')', '.', 'text', ')', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mpre = np . concatenate ( ( [ 0. ] , prec , [ 0. ] ) ) \n"
Original    (019): ['mpre', '=', 'np', '.', 'concatenate', '(', '(', '[', '0.', ']', ',', 'prec', ',', '[', '0.', ']', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'mp', '##re', '=', 'np', '.', 'con', '##cate', '##nate', '(', '(', '[', '0', '.', ']', ',', 'pre', '##c', ',', '[', '0', '.', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['mp', '##re', '=', 'np', '.', 'con', '##cate', '##nate', '(', '(', '[', '0', '.', ']', ',', 'pre', '##c', ',', '[', '0', '.', ']', ')', ')', '\\', 'n']
Detokenized (019): ['mp##re', '=', 'np', '.', 'con##cate##nate', '(', '(', '[', '0.', ']', ',', 'pre##c', ',', '[', '0.', ']', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "difficult = np . array ( [ x [ ] for x in R ] ) . astype ( np . bool ) \n"
Original    (024): ['difficult', '=', 'np', '.', 'array', '(', '[', 'x', '[', ']', 'for', 'x', 'in', 'R', ']', ')', '.', 'astype', '(', 'np', '.', 'bool', ')', '\\n']
Tokenized   (029): ['[CLS]', 'difficult', '=', 'np', '.', 'array', '(', '[', 'x', '[', ']', 'for', 'x', 'in', 'r', ']', ')', '.', 'as', '##type', '(', 'np', '.', 'boo', '##l', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['difficult', '=', 'np', '.', 'array', '(', '[', 'x', '[', ']', 'for', 'x', 'in', 'r', ']', ')', '.', 'as', '##type', '(', 'np', '.', 'boo', '##l', ')', '\\', 'n']
Detokenized (024): ['difficult', '=', 'np', '.', 'array', '(', '[', 'x', '[', ']', 'for', 'x', 'in', 'r', ']', ')', '.', 'as##type', '(', 'np', '.', 'boo##l', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "det = [ False ] * len ( R ) \n"
Original    (011): ['det', '=', '[', 'False', ']', '*', 'len', '(', 'R', ')', '\\n']
Tokenized   (014): ['[CLS]', 'det', '=', '[', 'false', ']', '*', 'len', '(', 'r', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['det', '=', '[', 'false', ']', '*', 'len', '(', 'r', ')', '\\', 'n']
Detokenized (011): ['det', '=', '[', 'false', ']', '*', 'len', '(', 'r', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "npos = npos + sum ( ~ difficult ) \n"
Original    (010): ['npos', '=', 'npos', '+', 'sum', '(', '~', 'difficult', ')', '\\n']
Tokenized   (015): ['[CLS]', 'np', '##os', '=', 'np', '##os', '+', 'sum', '(', '~', 'difficult', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['np', '##os', '=', 'np', '##os', '+', 'sum', '(', '~', 'difficult', ')', '\\', 'n']
Detokenized (010): ['np##os', '=', 'np##os', '+', 'sum', '(', '~', 'difficult', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "class_recs [ imagename ] = { : bbox , \n"
Original    (010): ['class_recs', '[', 'imagename', ']', '=', '{', ':', 'bbox', ',', '\\n']
Tokenized   (018): ['[CLS]', 'class', '_', 'rec', '##s', '[', 'image', '##name', ']', '=', '{', ':', 'bb', '##ox', ',', '\\', 'n', '[SEP]']
Filtered   (016): ['class', '_', 'rec', '##s', '[', 'image', '##name', ']', '=', '{', ':', 'bb', '##ox', ',', '\\', 'n']
Detokenized (010): ['class_rec##s', '[', 'image##name', ']', '=', '{', ':', 'bb##ox', ',', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "confidence = np . array ( [ float ( x [ 1 ] ) for x in splitlines ] ) \n"
Original    (021): ['confidence', '=', 'np', '.', 'array', '(', '[', 'float', '(', 'x', '[', '1', ']', ')', 'for', 'x', 'in', 'splitlines', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'confidence', '=', 'np', '.', 'array', '(', '[', 'float', '(', 'x', '[', '1', ']', ')', 'for', 'x', 'in', 'split', '##lines', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['confidence', '=', 'np', '.', 'array', '(', '[', 'float', '(', 'x', '[', '1', ']', ')', 'for', 'x', 'in', 'split', '##lines', ']', ')', '\\', 'n']
Detokenized (021): ['confidence', '=', 'np', '.', 'array', '(', '[', 'float', '(', 'x', '[', '1', ']', ')', 'for', 'x', 'in', 'split##lines', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "sorted_ind = np . argsort ( - confidence ) \n"
Original    (010): ['sorted_ind', '=', 'np', '.', 'argsort', '(', '-', 'confidence', ')', '\\n']
Tokenized   (017): ['[CLS]', 'sorted', '_', 'ind', '=', 'np', '.', 'ar', '##gs', '##ort', '(', '-', 'confidence', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['sorted', '_', 'ind', '=', 'np', '.', 'ar', '##gs', '##ort', '(', '-', 'confidence', ')', '\\', 'n']
Detokenized (010): ['sorted_ind', '=', 'np', '.', 'ar##gs##ort', '(', '-', 'confidence', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "BB = BB [ sorted_ind , : ] \n"
Original    (009): ['BB', '=', 'BB', '[', 'sorted_ind', ',', ':', ']', '\\n']
Tokenized   (014): ['[CLS]', 'bb', '=', 'bb', '[', 'sorted', '_', 'ind', ',', ':', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['bb', '=', 'bb', '[', 'sorted', '_', 'ind', ',', ':', ']', '\\', 'n']
Detokenized (009): ['bb', '=', 'bb', '[', 'sorted_ind', ',', ':', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "image_ids = [ image_ids [ x ] for x in sorted_ind ] \n"
Original    (013): ['image_ids', '=', '[', 'image_ids', '[', 'x', ']', 'for', 'x', 'in', 'sorted_ind', ']', '\\n']
Tokenized   (024): ['[CLS]', 'image', '_', 'id', '##s', '=', '[', 'image', '_', 'id', '##s', '[', 'x', ']', 'for', 'x', 'in', 'sorted', '_', 'ind', ']', '\\', 'n', '[SEP]']
Filtered   (022): ['image', '_', 'id', '##s', '=', '[', 'image', '_', 'id', '##s', '[', 'x', ']', 'for', 'x', 'in', 'sorted', '_', 'ind', ']', '\\', 'n']
Detokenized (013): ['image_id##s', '=', '[', 'image_id##s', '[', 'x', ']', 'for', 'x', 'in', 'sorted_ind', ']', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "bb = BB [ d , : ] . astype ( float ) \n"
Original    (014): ['bb', '=', 'BB', '[', 'd', ',', ':', ']', '.', 'astype', '(', 'float', ')', '\\n']
Tokenized   (018): ['[CLS]', 'bb', '=', 'bb', '[', 'd', ',', ':', ']', '.', 'as', '##type', '(', 'float', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['bb', '=', 'bb', '[', 'd', ',', ':', ']', '.', 'as', '##type', '(', 'float', ')', '\\', 'n']
Detokenized (014): ['bb', '=', 'bb', '[', 'd', ',', ':', ']', '.', 'as##type', '(', 'float', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "BBGT = R [ ] . astype ( float ) \n"
Original    (011): ['BBGT', '=', 'R', '[', ']', '.', 'astype', '(', 'float', ')', '\\n']
Tokenized   (016): ['[CLS]', 'bb', '##gt', '=', 'r', '[', ']', '.', 'as', '##type', '(', 'float', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['bb', '##gt', '=', 'r', '[', ']', '.', 'as', '##type', '(', 'float', ')', '\\', 'n']
Detokenized (011): ['bb##gt', '=', 'r', '[', ']', '.', 'as##type', '(', 'float', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "iymin = np . maximum ( BBGT [ : , 1 ] , bb [ 1 ] ) \n"
Original    (019): ['iymin', '=', 'np', '.', 'maximum', '(', 'BBGT', '[', ':', ',', '1', ']', ',', 'bb', '[', '1', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'i', '##ym', '##in', '=', 'np', '.', 'maximum', '(', 'bb', '##gt', '[', ':', ',', '1', ']', ',', 'bb', '[', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['i', '##ym', '##in', '=', 'np', '.', 'maximum', '(', 'bb', '##gt', '[', ':', ',', '1', ']', ',', 'bb', '[', '1', ']', ')', '\\', 'n']
Detokenized (019): ['i##ym##in', '=', 'np', '.', 'maximum', '(', 'bb##gt', '[', ':', ',', '1', ']', ',', 'bb', '[', '1', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "iw = np . maximum ( ixmax - ixmin + 1. , 0. ) \n"
Original    (015): ['iw', '=', 'np', '.', 'maximum', '(', 'ixmax', '-', 'ixmin', '+', '1.', ',', '0.', ')', '\\n']
Tokenized   (023): ['[CLS]', 'i', '##w', '=', 'np', '.', 'maximum', '(', 'ix', '##max', '-', 'ix', '##min', '+', '1', '.', ',', '0', '.', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['i', '##w', '=', 'np', '.', 'maximum', '(', 'ix', '##max', '-', 'ix', '##min', '+', '1', '.', ',', '0', '.', ')', '\\', 'n']
Detokenized (015): ['i##w', '=', 'np', '.', 'maximum', '(', 'ix##max', '-', 'ix##min', '+', '1.', ',', '0.', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "uni = ( ( bb [ 2 ] - bb [ 0 ] + 1. ) * ( bb [ 3 ] - bb [ 1 ] + 1. ) + \n"
Original    (032): ['uni', '=', '(', '(', 'bb', '[', '2', ']', '-', 'bb', '[', '0', ']', '+', '1.', ')', '*', '(', 'bb', '[', '3', ']', '-', 'bb', '[', '1', ']', '+', '1.', ')', '+', '\\n']
Tokenized   (038): ['[CLS]', 'un', '##i', '=', '(', '(', 'bb', '[', '2', ']', '-', 'bb', '[', '0', ']', '+', '1', '.', ')', '*', '(', 'bb', '[', '3', ']', '-', 'bb', '[', '1', ']', '+', '1', '.', ')', '+', '\\', 'n', '[SEP]']
Filtered   (036): ['un', '##i', '=', '(', '(', 'bb', '[', '2', ']', '-', 'bb', '[', '0', ']', '+', '1', '.', ')', '*', '(', 'bb', '[', '3', ']', '-', 'bb', '[', '1', ']', '+', '1', '.', ')', '+', '\\', 'n']
Detokenized (032): ['un##i', '=', '(', '(', 'bb', '[', '2', ']', '-', 'bb', '[', '0', ']', '+', '1.', ')', '*', '(', 'bb', '[', '3', ']', '-', 'bb', '[', '1', ']', '+', '1.', ')', '+', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "rec = tp / float ( npos ) \n"
Original    (009): ['rec', '=', 'tp', '/', 'float', '(', 'npos', ')', '\\n']
Tokenized   (014): ['[CLS]', 'rec', '=', 't', '##p', '/', 'float', '(', 'np', '##os', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['rec', '=', 't', '##p', '/', 'float', '(', 'np', '##os', ')', '\\', 'n']
Detokenized (009): ['rec', '=', 't##p', '/', 'float', '(', 'np##os', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "prec = tp / ( tp + fp + 1e-10 ) \n"
Original    (012): ['prec', '=', 'tp', '/', '(', 'tp', '+', 'fp', '+', '1e-10', ')', '\\n']
Tokenized   (022): ['[CLS]', 'pre', '##c', '=', 't', '##p', '/', '(', 't', '##p', '+', 'f', '##p', '+', '1', '##e', '-', '10', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['pre', '##c', '=', 't', '##p', '/', '(', 't', '##p', '+', 'f', '##p', '+', '1', '##e', '-', '10', ')', '\\', 'n']
Detokenized (012): ['pre##c', '=', 't##p', '/', '(', 't##p', '+', 'f##p', '+', '1##e-10', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "scale = strip_mantissa ( maxval ) / float ( 1 << ( bits - sign - 1 ) ) \n"
Original    (020): ['scale', '=', 'strip_mantissa', '(', 'maxval', ')', '/', 'float', '(', '1', '<<', '(', 'bits', '-', 'sign', '-', '1', ')', ')', '\\n']
Tokenized   (029): ['[CLS]', 'scale', '=', 'strip', '_', 'man', '##tis', '##sa', '(', 'max', '##val', ')', '/', 'float', '(', '1', '<', '<', '(', 'bits', '-', 'sign', '-', '1', ')', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['scale', '=', 'strip', '_', 'man', '##tis', '##sa', '(', 'max', '##val', ')', '/', 'float', '(', '1', '<', '<', '(', 'bits', '-', 'sign', '-', '1', ')', ')', '\\', 'n']
Detokenized (020): ['scale', '=', 'strip_man##tis##sa', '(', 'max##val', ')', '/', 'float', '(', '1', '<<', '(', 'bits', '-', 'sign', '-', '1', ')', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "ary = np . around ( ary * ( 1.0 / scale ) ) . astype ( np . int64 ) \n"
Original    (022): ['ary', '=', 'np', '.', 'around', '(', 'ary', '*', '(', '1.0', '/', 'scale', ')', ')', '.', 'astype', '(', 'np', '.', 'int64', ')', '\\n']
Tokenized   (031): ['[CLS]', 'ar', '##y', '=', 'np', '.', 'around', '(', 'ar', '##y', '*', '(', '1', '.', '0', '/', 'scale', ')', ')', '.', 'as', '##type', '(', 'np', '.', 'int', '##64', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['ar', '##y', '=', 'np', '.', 'around', '(', 'ar', '##y', '*', '(', '1', '.', '0', '/', 'scale', ')', ')', '.', 'as', '##type', '(', 'np', '.', 'int', '##64', ')', '\\', 'n']
Detokenized (022): ['ar##y', '=', 'np', '.', 'around', '(', 'ar##y', '*', '(', '1.0', '/', 'scale', ')', ')', '.', 'as##type', '(', 'np', '.', 'int##64', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "f2 -= dif \n"
Original    (004): ['f2', '-=', 'dif', '\\n']
Tokenized   (010): ['[CLS]', 'f', '##2', '-', '=', 'di', '##f', '\\', 'n', '[SEP]']
Filtered   (008): ['f', '##2', '-', '=', 'di', '##f', '\\', 'n']
Detokenized (004): ['f##2', '-=', 'di##f', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "slicedF = F [ : , sliceR , sliceS , : ] . reshape ( ( - 1 , K ) ) \n"
Original    (023): ['slicedF', '=', 'F', '[', ':', ',', 'sliceR', ',', 'sliceS', ',', ':', ']', '.', 'reshape', '(', '(', '-', '1', ',', 'K', ')', ')', '\\n']
Tokenized   (030): ['[CLS]', 'sliced', '##f', '=', 'f', '[', ':', ',', 'slice', '##r', ',', 'slices', ',', ':', ']', '.', 'res', '##ha', '##pe', '(', '(', '-', '1', ',', 'k', ')', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['sliced', '##f', '=', 'f', '[', ':', ',', 'slice', '##r', ',', 'slices', ',', ':', ']', '.', 'res', '##ha', '##pe', '(', '(', '-', '1', ',', 'k', ')', ')', '\\', 'n']
Detokenized (023): ['sliced##f', '=', 'f', '[', ':', ',', 'slice##r', ',', 'slices', ',', ':', ']', '.', 'res##ha##pe', '(', '(', '-', '1', ',', 'k', ')', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "K , P , Q , N = E . shape \n"
Original    (012): ['K', ',', 'P', ',', 'Q', ',', 'N', '=', 'E', '.', 'shape', '\\n']
Tokenized   (015): ['[CLS]', 'k', ',', 'p', ',', 'q', ',', 'n', '=', 'e', '.', 'shape', '\\', 'n', '[SEP]']
Filtered   (013): ['k', ',', 'p', ',', 'q', ',', 'n', '=', 'e', '.', 'shape', '\\', 'n']
Detokenized (012): ['k', ',', 'p', ',', 'q', ',', 'n', '=', 'e', '.', 'shape', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "qSlice = [ fconv_slice ( q , S , X , padding [ 0 ] , strides [ 0 ] ) for q in range ( Q ) ] \n"
Original    (030): ['qSlice', '=', '[', 'fconv_slice', '(', 'q', ',', 'S', ',', 'X', ',', 'padding', '[', '0', ']', ',', 'strides', '[', '0', ']', ')', 'for', 'q', 'in', 'range', '(', 'Q', ')', ']', '\\n']
Tokenized   (040): ['[CLS]', 'q', '##sl', '##ice', '=', '[', 'fc', '##on', '##v', '_', 'slice', '(', 'q', ',', 's', ',', 'x', ',', 'pad', '##ding', '[', '0', ']', ',', 'strides', '[', '0', ']', ')', 'for', 'q', 'in', 'range', '(', 'q', ')', ']', '\\', 'n', '[SEP]']
Filtered   (038): ['q', '##sl', '##ice', '=', '[', 'fc', '##on', '##v', '_', 'slice', '(', 'q', ',', 's', ',', 'x', ',', 'pad', '##ding', '[', '0', ']', ',', 'strides', '[', '0', ']', ')', 'for', 'q', 'in', 'range', '(', 'q', ')', ']', '\\', 'n']
Detokenized (030): ['q##sl##ice', '=', '[', 'fc##on##v_slice', '(', 'q', ',', 's', ',', 'x', ',', 'pad##ding', '[', '0', ']', ',', 'strides', '[', '0', ']', ')', 'for', 'q', 'in', 'range', '(', 'q', ')', ']', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 30, 768)
# Extracted words:  30
Sentence         : "slicedE = E [ : , p , q , : ] \n"
Original    (013): ['slicedE', '=', 'E', '[', ':', ',', 'p', ',', 'q', ',', ':', ']', '\\n']
Tokenized   (017): ['[CLS]', 'sliced', '##e', '=', 'e', '[', ':', ',', 'p', ',', 'q', ',', ':', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['sliced', '##e', '=', 'e', '[', ':', ',', 'p', ',', 'q', ',', ':', ']', '\\', 'n']
Detokenized (013): ['sliced##e', '=', 'e', '[', ':', ',', 'p', ',', 'q', ',', ':', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "rcp3 = 1.0 / 3.0 \n"
Original    (006): ['rcp3', '=', '1.0', '/', '3.0', '\\n']
Tokenized   (015): ['[CLS]', 'rc', '##p', '##3', '=', '1', '.', '0', '/', '3', '.', '0', '\\', 'n', '[SEP]']
Filtered   (013): ['rc', '##p', '##3', '=', '1', '.', '0', '/', '3', '.', '0', '\\', 'n']
Detokenized (006): ['rc##p##3', '=', '1.0', '/', '3.0', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "t3 = I [ 1 , : ] + I [ 3 , : ] * 4.0 \n"
Original    (018): ['t3', '=', 'I', '[', '1', ',', ':', ']', '+', 'I', '[', '3', ',', ':', ']', '*', '4.0', '\\n']
Tokenized   (024): ['[CLS]', 't', '##3', '=', 'i', '[', '1', ',', ':', ']', '+', 'i', '[', '3', ',', ':', ']', '*', '4', '.', '0', '\\', 'n', '[SEP]']
Filtered   (022): ['t', '##3', '=', 'i', '[', '1', ',', ':', ']', '+', 'i', '[', '3', ',', ':', ']', '*', '4', '.', '0', '\\', 'n']
Detokenized (018): ['t##3', '=', 'i', '[', '1', ',', ':', ']', '+', 'i', '[', '3', ',', ':', ']', '*', '4.0', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "T1 = np . empty ( ( 3 , 3 ) ) \n"
Original    (013): ['T1', '=', 'np', '.', 'empty', '(', '(', '3', ',', '3', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 't', '##1', '=', 'np', '.', 'empty', '(', '(', '3', ',', '3', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['t', '##1', '=', 'np', '.', 'empty', '(', '(', '3', ',', '3', ')', ')', '\\', 'n']
Detokenized (013): ['t##1', '=', 'np', '.', 'empty', '(', '(', '3', ',', '3', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Fw = np . empty ( ( D , D , C , K ) ) \n"
Original    (017): ['Fw', '=', 'np', '.', 'empty', '(', '(', 'D', ',', 'D', ',', 'C', ',', 'K', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'f', '##w', '=', 'np', '.', 'empty', '(', '(', 'd', ',', 'd', ',', 'c', ',', 'k', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['f', '##w', '=', 'np', '.', 'empty', '(', '(', 'd', ',', 'd', ',', 'c', ',', 'k', ')', ')', '\\', 'n']
Detokenized (017): ['f##w', '=', 'np', '.', 'empty', '(', '(', 'd', ',', 'd', ',', 'c', ',', 'k', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sliceI = I [ : , start_y : stop_y , start_x : stop_x , : ] \n"
Original    (017): ['sliceI', '=', 'I', '[', ':', ',', 'start_y', ':', 'stop_y', ',', 'start_x', ':', 'stop_x', ',', ':', ']', '\\n']
Tokenized   (029): ['[CLS]', 'slice', '##i', '=', 'i', '[', ':', ',', 'start', '_', 'y', ':', 'stop', '_', 'y', ',', 'start', '_', 'x', ':', 'stop', '_', 'x', ',', ':', ']', '\\', 'n', '[SEP]']
Filtered   (027): ['slice', '##i', '=', 'i', '[', ':', ',', 'start', '_', 'y', ':', 'stop', '_', 'y', ',', 'start', '_', 'x', ':', 'stop', '_', 'x', ',', ':', ']', '\\', 'n']
Detokenized (017): ['slice##i', '=', 'i', '[', ':', ',', 'start_y', ':', 'stop_y', ',', 'start_x', ':', 'stop_x', ',', ':', ']', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "O [ k , p0 : p1 , q0 : q1 , n ] = Out [ 0 : plen , 0 : qlen ] \n"
Original    (026): ['O', '[', 'k', ',', 'p0', ':', 'p1', ',', 'q0', ':', 'q1', ',', 'n', ']', '=', 'Out', '[', '0', ':', 'plen', ',', '0', ':', 'qlen', ']', '\\n']
Tokenized   (035): ['[CLS]', 'o', '[', 'k', ',', 'p', '##0', ':', 'p', '##1', ',', 'q', '##0', ':', 'q', '##1', ',', 'n', ']', '=', 'out', '[', '0', ':', 'pl', '##en', ',', '0', ':', 'q', '##len', ']', '\\', 'n', '[SEP]']
Filtered   (033): ['o', '[', 'k', ',', 'p', '##0', ':', 'p', '##1', ',', 'q', '##0', ':', 'q', '##1', ',', 'n', ']', '=', 'out', '[', '0', ':', 'pl', '##en', ',', '0', ':', 'q', '##len', ']', '\\', 'n']
Detokenized (026): ['o', '[', 'k', ',', 'p##0', ':', 'p##1', ',', 'q##0', ':', 'q##1', ',', 'n', ']', '=', 'out', '[', '0', ':', 'pl##en', ',', '0', ':', 'q##len', ']', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "start_p , stop_p , pad_p = image_slice ( y , P , B , B ) \n"
Original    (017): ['start_p', ',', 'stop_p', ',', 'pad_p', '=', 'image_slice', '(', 'y', ',', 'P', ',', 'B', ',', 'B', ')', '\\n']
Tokenized   (028): ['[CLS]', 'start', '_', 'p', ',', 'stop', '_', 'p', ',', 'pad', '_', 'p', '=', 'image', '_', 'slice', '(', 'y', ',', 'p', ',', 'b', ',', 'b', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['start', '_', 'p', ',', 'stop', '_', 'p', ',', 'pad', '_', 'p', '=', 'image', '_', 'slice', '(', 'y', ',', 'p', ',', 'b', ',', 'b', ')', '\\', 'n']
Detokenized (017): ['start_p', ',', 'stop_p', ',', 'pad_p', '=', 'image_slice', '(', 'y', ',', 'p', ',', 'b', ',', 'b', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "trans = ( 2 , 2 ) \n"
Original    (008): ['trans', '=', '(', '2', ',', '2', ')', '\\n']
Tokenized   (011): ['[CLS]', 'trans', '=', '(', '2', ',', '2', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['trans', '=', '(', '2', ',', '2', ')', '\\', 'n']
Detokenized (008): ['trans', '=', '(', '2', ',', '2', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "E = np . random . uniform ( - 1.0 , 1.0 , dimO ) \n"
Original    (016): ['E', '=', 'np', '.', 'random', '.', 'uniform', '(', '-', '1.0', ',', '1.0', ',', 'dimO', ')', '\\n']
Tokenized   (024): ['[CLS]', 'e', '=', 'np', '.', 'random', '.', 'uniform', '(', '-', '1', '.', '0', ',', '1', '.', '0', ',', 'dim', '##o', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['e', '=', 'np', '.', 'random', '.', 'uniform', '(', '-', '1', '.', '0', ',', '1', '.', '0', ',', 'dim', '##o', ')', '\\', 'n']
Detokenized (016): ['e', '=', 'np', '.', 'random', '.', 'uniform', '(', '-', '1.0', ',', '1.0', ',', 'dim##o', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "xprop_direct ( E , F , Bd , padding , strides , backward = True ) \n"
Original    (017): ['xprop_direct', '(', 'E', ',', 'F', ',', 'Bd', ',', 'padding', ',', 'strides', ',', 'backward', '=', 'True', ')', '\\n']
Tokenized   (025): ['[CLS]', 'xp', '##rop', '_', 'direct', '(', 'e', ',', 'f', ',', 'b', '##d', ',', 'pad', '##ding', ',', 'strides', ',', 'backward', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['xp', '##rop', '_', 'direct', '(', 'e', ',', 'f', ',', 'b', '##d', ',', 'pad', '##ding', ',', 'strides', ',', 'backward', '=', 'true', ')', '\\', 'n']
Detokenized (017): ['xp##rop_direct', '(', 'e', ',', 'f', ',', 'b##d', ',', 'pad##ding', ',', 'strides', ',', 'backward', '=', 'true', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "xprop_winograd ( E , F , Bw , padding , minimal = minimal , trans = trans , backward = True ) \n"
Original    (023): ['xprop_winograd', '(', 'E', ',', 'F', ',', 'Bw', ',', 'padding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ',', 'backward', '=', 'True', ')', '\\n']
Tokenized   (033): ['[CLS]', 'xp', '##rop', '_', 'win', '##og', '##rad', '(', 'e', ',', 'f', ',', 'b', '##w', ',', 'pad', '##ding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ',', 'backward', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['xp', '##rop', '_', 'win', '##og', '##rad', '(', 'e', ',', 'f', ',', 'b', '##w', ',', 'pad', '##ding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ',', 'backward', '=', 'true', ')', '\\', 'n']
Detokenized (023): ['xp##rop_win##og##rad', '(', 'e', ',', 'f', ',', 'b##w', ',', 'pad##ding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ',', 'backward', '=', 'true', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "updat_direct ( I , E , Ud , padding , strides ) \n"
Original    (013): ['updat_direct', '(', 'I', ',', 'E', ',', 'Ud', ',', 'padding', ',', 'strides', ')', '\\n']
Tokenized   (021): ['[CLS]', 'up', '##da', '##t', '_', 'direct', '(', 'i', ',', 'e', ',', 'ud', ',', 'pad', '##ding', ',', 'strides', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['up', '##da', '##t', '_', 'direct', '(', 'i', ',', 'e', ',', 'ud', ',', 'pad', '##ding', ',', 'strides', ')', '\\', 'n']
Detokenized (013): ['up##da##t_direct', '(', 'i', ',', 'e', ',', 'ud', ',', 'pad##ding', ',', 'strides', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "updat_winograd ( I , E , Uw , padding , minimal = minimal , trans = trans ) \n"
Original    (019): ['updat_winograd', '(', 'I', ',', 'E', ',', 'Uw', ',', 'padding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ')', '\\n']
Tokenized   (030): ['[CLS]', 'up', '##da', '##t', '_', 'win', '##og', '##rad', '(', 'i', ',', 'e', ',', 'u', '##w', ',', 'pad', '##ding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['up', '##da', '##t', '_', 'win', '##og', '##rad', '(', 'i', ',', 'e', ',', 'u', '##w', ',', 'pad', '##ding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ')', '\\', 'n']
Detokenized (019): ['up##da##t_win##og##rad', '(', 'i', ',', 'e', ',', 'u##w', ',', 'pad##ding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "BranchNode , SkipNode , LRN , ColorNoise ) \n"
Original    (009): ['BranchNode', ',', 'SkipNode', ',', 'LRN', ',', 'ColorNoise', ')', '\\n']
Tokenized   (019): ['[CLS]', 'branch', '##no', '##de', ',', 'skip', '##no', '##de', ',', 'l', '##rn', ',', 'color', '##no', '##ise', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['branch', '##no', '##de', ',', 'skip', '##no', '##de', ',', 'l', '##rn', ',', 'color', '##no', '##ise', ')', '\\', 'n']
Detokenized (009): ['branch##no##de', ',', 'skip##no##de', ',', 'l##rn', ',', 'color##no##ise', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "img_set_options = dict ( repo_dir = args . data_dir , \n"
Original    (011): ['img_set_options', '=', 'dict', '(', 'repo_dir', '=', 'args', '.', 'data_dir', ',', '\\n']
Tokenized   (026): ['[CLS]', 'im', '##g', '_', 'set', '_', 'options', '=', 'di', '##ct', '(', 'rep', '##o', '_', 'dir', '=', 'ar', '##gs', '.', 'data', '_', 'dir', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['im', '##g', '_', 'set', '_', 'options', '=', 'di', '##ct', '(', 'rep', '##o', '_', 'dir', '=', 'ar', '##gs', '.', 'data', '_', 'dir', ',', '\\', 'n']
Detokenized (011): ['im##g_set_options', '=', 'di##ct', '(', 'rep##o_dir', '=', 'ar##gs', '.', 'data_dir', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "subset_pct = 0.09990891117239205 ) \n"
Original    (005): ['subset_pct', '=', '0.09990891117239205', ')', '\\n']
Tokenized   (023): ['[CLS]', 'subset', '_', 'pc', '##t', '=', '0', '.', '09', '##9', '##90', '##8', '##9', '##11', '##17', '##23', '##9', '##20', '##5', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['subset', '_', 'pc', '##t', '=', '0', '.', '09', '##9', '##90', '##8', '##9', '##11', '##17', '##23', '##9', '##20', '##5', ')', '\\', 'n']
Detokenized (005): ['subset_pc##t', '=', '0.09##9##90##8##9##11##17##23##9##20##5', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "do_transforms = False , ** img_set_options ) \n"
Original    (008): ['do_transforms', '=', 'False', ',', '**', 'img_set_options', ')', '\\n']
Tokenized   (019): ['[CLS]', 'do', '_', 'transforms', '=', 'false', ',', '*', '*', 'im', '##g', '_', 'set', '_', 'options', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['do', '_', 'transforms', '=', 'false', ',', '*', '*', 'im', '##g', '_', 'set', '_', 'options', ')', '\\', 'n']
Detokenized (008): ['do_transforms', '=', 'false', ',', '**', 'im##g_set_options', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "test = ImageLoader ( set_name = , scale_range = ( 256 , 384 ) , shuffle = False , \n"
Original    (020): ['test', '=', 'ImageLoader', '(', 'set_name', '=', ',', 'scale_range', '=', '(', '256', ',', '384', ')', ',', 'shuffle', '=', 'False', ',', '\\n']
Tokenized   (030): ['[CLS]', 'test', '=', 'image', '##load', '##er', '(', 'set', '_', 'name', '=', ',', 'scale', '_', 'range', '=', '(', '256', ',', '38', '##4', ')', ',', 'shuffle', '=', 'false', ',', '\\', 'n', '[SEP]']
Filtered   (028): ['test', '=', 'image', '##load', '##er', '(', 'set', '_', 'name', '=', ',', 'scale', '_', 'range', '=', '(', '256', ',', '38', '##4', ')', ',', 'shuffle', '=', 'false', ',', '\\', 'n']
Detokenized (020): ['test', '=', 'image##load##er', '(', 'set_name', '=', ',', 'scale_range', '=', '(', '256', ',', '38##4', ')', ',', 'shuffle', '=', 'false', ',', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "Pooling ( 3 , strides = 2 ) , \n"
Original    (010): ['Pooling', '(', '3', ',', 'strides', '=', '2', ')', ',', '\\n']
Tokenized   (014): ['[CLS]', 'pool', '##ing', '(', '3', ',', 'strides', '=', '2', ')', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['pool', '##ing', '(', '3', ',', 'strides', '=', '2', ')', ',', '\\', 'n']
Detokenized (010): ['pool##ing', '(', '3', ',', 'strides', '=', '2', ')', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "activation = Rectlin ( ) , padding = 1 ) , \n"
Original    (012): ['activation', '=', 'Rectlin', '(', ')', ',', 'padding', '=', '1', ')', ',', '\\n']
Tokenized   (018): ['[CLS]', 'activation', '=', 'rec', '##tl', '##in', '(', ')', ',', 'pad', '##ding', '=', '1', ')', ',', '\\', 'n', '[SEP]']
Filtered   (016): ['activation', '=', 'rec', '##tl', '##in', '(', ')', ',', 'pad', '##ding', '=', '1', ')', ',', '\\', 'n']
Detokenized (012): ['activation', '=', 'rec##tl##in', '(', ')', ',', 'pad##ding', '=', '1', ')', ',', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Conv ( ( 3 , 3 , 256 ) , init = Gaussian ( scale = 0.03 ) , bias = Constant ( 1 ) , \n"
Original    (027): ['Conv', '(', '(', '3', ',', '3', ',', '256', ')', ',', 'init', '=', 'Gaussian', '(', 'scale', '=', '0.03', ')', ',', 'bias', '=', 'Constant', '(', '1', ')', ',', '\\n']
Tokenized   (036): ['[CLS]', 'con', '##v', '(', '(', '3', ',', '3', ',', '256', ')', ',', 'in', '##it', '=', 'ga', '##uss', '##ian', '(', 'scale', '=', '0', '.', '03', ')', ',', 'bias', '=', 'constant', '(', '1', ')', ',', '\\', 'n', '[SEP]']
Filtered   (034): ['con', '##v', '(', '(', '3', ',', '3', ',', '256', ')', ',', 'in', '##it', '=', 'ga', '##uss', '##ian', '(', 'scale', '=', '0', '.', '03', ')', ',', 'bias', '=', 'constant', '(', '1', ')', ',', '\\', 'n']
Detokenized (027): ['con##v', '(', '(', '3', ',', '3', ',', '256', ')', ',', 'in##it', '=', 'ga##uss##ian', '(', 'scale', '=', '0.03', ')', ',', 'bias', '=', 'constant', '(', '1', ')', ',', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "Dropout ( keep = 1.0 ) , \n"
Original    (008): ['Dropout', '(', 'keep', '=', '1.0', ')', ',', '\\n']
Tokenized   (014): ['[CLS]', 'drop', '##out', '(', 'keep', '=', '1', '.', '0', ')', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['drop', '##out', '(', 'keep', '=', '1', '.', '0', ')', ',', '\\', 'n']
Detokenized (008): ['drop##out', '(', 'keep', '=', '1.0', ')', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Affine ( nout = 1000 , init = Gaussian ( scale = 0.01 ) , bias = Constant ( - 7 ) , activation = Softmax ( ) ) ] \n"
Original    (031): ['Affine', '(', 'nout', '=', '1000', ',', 'init', '=', 'Gaussian', '(', 'scale', '=', '0.01', ')', ',', 'bias', '=', 'Constant', '(', '-', '7', ')', ',', 'activation', '=', 'Softmax', '(', ')', ')', ']', '\\n']
Tokenized   (042): ['[CLS]', 'af', '##fine', '(', 'no', '##ut', '=', '1000', ',', 'in', '##it', '=', 'ga', '##uss', '##ian', '(', 'scale', '=', '0', '.', '01', ')', ',', 'bias', '=', 'constant', '(', '-', '7', ')', ',', 'activation', '=', 'soft', '##max', '(', ')', ')', ']', '\\', 'n', '[SEP]']
Filtered   (040): ['af', '##fine', '(', 'no', '##ut', '=', '1000', ',', 'in', '##it', '=', 'ga', '##uss', '##ian', '(', 'scale', '=', '0', '.', '01', ')', ',', 'bias', '=', 'constant', '(', '-', '7', ')', ',', 'activation', '=', 'soft', '##max', '(', ')', ')', ']', '\\', 'n']
Detokenized (031): ['af##fine', '(', 'no##ut', '=', '1000', ',', 'in##it', '=', 'ga##uss##ian', '(', 'scale', '=', '0.01', ')', ',', 'bias', '=', 'constant', '(', '-', '7', ')', ',', 'activation', '=', 'soft##max', '(', ')', ')', ']', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "weight_sched = Schedule ( [ 22 , 44 , 65 ] , ( 1 / 250. ) ** ( 1 / 3. ) ) \n"
Original    (025): ['weight_sched', '=', 'Schedule', '(', '[', '22', ',', '44', ',', '65', ']', ',', '(', '1', '/', '250.', ')', '**', '(', '1', '/', '3.', ')', ')', '\\n']
Tokenized   (034): ['[CLS]', 'weight', '_', 'sc', '##hed', '=', 'schedule', '(', '[', '22', ',', '44', ',', '65', ']', ',', '(', '1', '/', '250', '.', ')', '*', '*', '(', '1', '/', '3', '.', ')', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['weight', '_', 'sc', '##hed', '=', 'schedule', '(', '[', '22', ',', '44', ',', '65', ']', ',', '(', '1', '/', '250', '.', ')', '*', '*', '(', '1', '/', '3', '.', ')', ')', '\\', 'n']
Detokenized (025): ['weight_sc##hed', '=', 'schedule', '(', '[', '22', ',', '44', ',', '65', ']', ',', '(', '1', '/', '250.', ')', '**', '(', '1', '/', '3.', ')', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "opt_gdm = GradientDescentMomentum ( 0.01 / 10 , 0.9 , wdecay = 0.0005 , schedule = weight_sched , \n"
Original    (019): ['opt_gdm', '=', 'GradientDescentMomentum', '(', '0.01', '/', '10', ',', '0.9', ',', 'wdecay', '=', '0.0005', ',', 'schedule', '=', 'weight_sched', ',', '\\n']
Tokenized   (043): ['[CLS]', 'opt', '_', 'g', '##dm', '=', 'gradient', '##des', '##cent', '##mo', '##ment', '##um', '(', '0', '.', '01', '/', '10', ',', '0', '.', '9', ',', 'w', '##de', '##ca', '##y', '=', '0', '.', '000', '##5', ',', 'schedule', '=', 'weight', '_', 'sc', '##hed', ',', '\\', 'n', '[SEP]']
Filtered   (041): ['opt', '_', 'g', '##dm', '=', 'gradient', '##des', '##cent', '##mo', '##ment', '##um', '(', '0', '.', '01', '/', '10', ',', '0', '.', '9', ',', 'w', '##de', '##ca', '##y', '=', '0', '.', '000', '##5', ',', 'schedule', '=', 'weight', '_', 'sc', '##hed', ',', '\\', 'n']
Detokenized (019): ['opt_g##dm', '=', 'gradient##des##cent##mo##ment##um', '(', '0.01', '/', '10', ',', '0.9', ',', 'w##de##ca##y', '=', '0.000##5', ',', 'schedule', '=', 'weight_sc##hed', ',', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "opt_biases = GradientDescentMomentum ( 0.02 / 10 , 0.9 , schedule = Schedule ( [ 44 ] , 0.1 ) , \n"
Original    (022): ['opt_biases', '=', 'GradientDescentMomentum', '(', '0.02', '/', '10', ',', '0.9', ',', 'schedule', '=', 'Schedule', '(', '[', '44', ']', ',', '0.1', ')', ',', '\\n']
Tokenized   (039): ['[CLS]', 'opt', '_', 'bias', '##es', '=', 'gradient', '##des', '##cent', '##mo', '##ment', '##um', '(', '0', '.', '02', '/', '10', ',', '0', '.', '9', ',', 'schedule', '=', 'schedule', '(', '[', '44', ']', ',', '0', '.', '1', ')', ',', '\\', 'n', '[SEP]']
Filtered   (037): ['opt', '_', 'bias', '##es', '=', 'gradient', '##des', '##cent', '##mo', '##ment', '##um', '(', '0', '.', '02', '/', '10', ',', '0', '.', '9', ',', 'schedule', '=', 'schedule', '(', '[', '44', ']', ',', '0', '.', '1', ')', ',', '\\', 'n']
Detokenized (022): ['opt_bias##es', '=', 'gradient##des##cent##mo##ment##um', '(', '0.02', '/', '10', ',', '0.9', ',', 'schedule', '=', 'schedule', '(', '[', '44', ']', ',', '0.1', ')', ',', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "valmetric = TopKMisclassification ( k = 5 ) \n"
Original    (009): ['valmetric', '=', 'TopKMisclassification', '(', 'k', '=', '5', ')', '\\n']
Tokenized   (017): ['[CLS]', 'val', '##metric', '=', 'top', '##km', '##is', '##class', '##ification', '(', 'k', '=', '5', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['val', '##metric', '=', 'top', '##km', '##is', '##class', '##ification', '(', 'k', '=', '5', ')', '\\', 'n']
Detokenized (009): ['val##metric', '=', 'top##km##is##class##ification', '(', 'k', '=', '5', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "nifm_rng = [ 8 ] \n"
Original    (006): ['nifm_rng', '=', '[', '8', ']', '\\n']
Tokenized   (013): ['[CLS]', 'ni', '##fm', '_', 'rn', '##g', '=', '[', '8', ']', '\\', 'n', '[SEP]']
Filtered   (011): ['ni', '##fm', '_', 'rn', '##g', '=', '[', '8', ']', '\\', 'n']
Detokenized (006): ['ni##fm_rn##g', '=', '[', '8', ']', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "fargs_ . append ( itt . product ( fs_rng , nifm_rng , pad_rng , stride_rng , in_sz_rng , bsz_rng ) ) \n"
Original    (022): ['fargs_', '.', 'append', '(', 'itt', '.', 'product', '(', 'fs_rng', ',', 'nifm_rng', ',', 'pad_rng', ',', 'stride_rng', ',', 'in_sz_rng', ',', 'bsz_rng', ')', ')', '\\n']
Tokenized   (053): ['[CLS]', 'far', '##gs', '_', '.', 'app', '##end', '(', 'it', '##t', '.', 'product', '(', 'f', '##s', '_', 'rn', '##g', ',', 'ni', '##fm', '_', 'rn', '##g', ',', 'pad', '_', 'rn', '##g', ',', 'stride', '_', 'rn', '##g', ',', 'in', '_', 's', '##z', '_', 'rn', '##g', ',', 'bs', '##z', '_', 'rn', '##g', ')', ')', '\\', 'n', '[SEP]']
Filtered   (051): ['far', '##gs', '_', '.', 'app', '##end', '(', 'it', '##t', '.', 'product', '(', 'f', '##s', '_', 'rn', '##g', ',', 'ni', '##fm', '_', 'rn', '##g', ',', 'pad', '_', 'rn', '##g', ',', 'stride', '_', 'rn', '##g', ',', 'in', '_', 's', '##z', '_', 'rn', '##g', ',', 'bs', '##z', '_', 'rn', '##g', ')', ')', '\\', 'n']
Detokenized (022): ['far##gs_', '.', 'app##end', '(', 'it##t', '.', 'product', '(', 'f##s_rn##g', ',', 'ni##fm_rn##g', ',', 'pad_rn##g', ',', 'stride_rn##g', ',', 'in_s##z_rn##g', ',', 'bs##z_rn##g', ')', ')', '\\n']
Counter: 51
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "bsz = inp . shape [ - 1 ] \n"
Original    (010): ['bsz', '=', 'inp', '.', 'shape', '[', '-', '1', ']', '\\n']
Tokenized   (015): ['[CLS]', 'bs', '##z', '=', 'in', '##p', '.', 'shape', '[', '-', '1', ']', '\\', 'n', '[SEP]']
Filtered   (013): ['bs', '##z', '=', 'in', '##p', '.', 'shape', '[', '-', '1', ']', '\\', 'n']
Detokenized (010): ['bs##z', '=', 'in##p', '.', 'shape', '[', '-', '1', ']', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "check_inds = check_inds [ 0 : ncheck ] \n"
Original    (009): ['check_inds', '=', 'check_inds', '[', '0', ':', 'ncheck', ']', '\\n']
Tokenized   (020): ['[CLS]', 'check', '_', 'ind', '##s', '=', 'check', '_', 'ind', '##s', '[', '0', ':', 'nc', '##he', '##ck', ']', '\\', 'n', '[SEP]']
Filtered   (018): ['check', '_', 'ind', '##s', '=', 'check', '_', 'ind', '##s', '[', '0', ':', 'nc', '##he', '##ck', ']', '\\', 'n']
Detokenized (009): ['check_ind##s', '=', 'check_ind##s', '[', '0', ':', 'nc##he##ck', ']', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "inpa = inp . get ( ) . reshape ( inp_lshape ) \n"
Original    (013): ['inpa', '=', 'inp', '.', 'get', '(', ')', '.', 'reshape', '(', 'inp_lshape', ')', '\\n']
Tokenized   (025): ['[CLS]', 'in', '##pa', '=', 'in', '##p', '.', 'get', '(', ')', '.', 'res', '##ha', '##pe', '(', 'in', '##p', '_', 'l', '##sha', '##pe', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['in', '##pa', '=', 'in', '##p', '.', 'get', '(', ')', '.', 'res', '##ha', '##pe', '(', 'in', '##p', '_', 'l', '##sha', '##pe', ')', '\\', 'n']
Detokenized (013): ['in##pa', '=', 'in##p', '.', 'get', '(', ')', '.', 'res##ha##pe', '(', 'in##p_l##sha##pe', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "outshape = ( inp_lshape [ 0 ] , \n"
Original    (009): ['outshape', '=', '(', 'inp_lshape', '[', '0', ']', ',', '\\n']
Tokenized   (019): ['[CLS]', 'outs', '##ha', '##pe', '=', '(', 'in', '##p', '_', 'l', '##sha', '##pe', '[', '0', ']', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['outs', '##ha', '##pe', '=', '(', 'in', '##p', '_', 'l', '##sha', '##pe', '[', '0', ']', ',', '\\', 'n']
Detokenized (009): ['outs##ha##pe', '=', '(', 'in##p_l##sha##pe', '[', '0', ']', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "be . output_dim ( inp_lshape [ 2 ] , fshape [ 1 ] , padding , strides [ 1 ] , pooling = True ) , \n"
Original    (027): ['be', '.', 'output_dim', '(', 'inp_lshape', '[', '2', ']', ',', 'fshape', '[', '1', ']', ',', 'padding', ',', 'strides', '[', '1', ']', ',', 'pooling', '=', 'True', ')', ',', '\\n']
Tokenized   (041): ['[CLS]', 'be', '.', 'output', '_', 'dim', '(', 'in', '##p', '_', 'l', '##sha', '##pe', '[', '2', ']', ',', 'f', '##sha', '##pe', '[', '1', ']', ',', 'pad', '##ding', ',', 'strides', '[', '1', ']', ',', 'pool', '##ing', '=', 'true', ')', ',', '\\', 'n', '[SEP]']
Filtered   (039): ['be', '.', 'output', '_', 'dim', '(', 'in', '##p', '_', 'l', '##sha', '##pe', '[', '2', ']', ',', 'f', '##sha', '##pe', '[', '1', ']', ',', 'pad', '##ding', ',', 'strides', '[', '1', ']', ',', 'pool', '##ing', '=', 'true', ')', ',', '\\', 'n']
Detokenized (027): ['be', '.', 'output_dim', '(', 'in##p_l##sha##pe', '[', '2', ']', ',', 'f##sha##pe', '[', '1', ']', ',', 'pad##ding', ',', 'strides', '[', '1', ']', ',', 'pool##ing', '=', 'true', ')', ',', '\\n']
Counter: 39
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "inp_lshape [ - 1 ] ) \n"
Original    (007): ['inp_lshape', '[', '-', '1', ']', ')', '\\n']
Tokenized   (015): ['[CLS]', 'in', '##p', '_', 'l', '##sha', '##pe', '[', '-', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['in', '##p', '_', 'l', '##sha', '##pe', '[', '-', '1', ']', ')', '\\', 'n']
Detokenized (007): ['in##p_l##sha##pe', '[', '-', '1', ']', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "inp_pad [ : , padding : - padding , padding : - padding , : ] = inpa [ : , 0 : , 0 : , : ] \n"
Original    (030): ['inp_pad', '[', ':', ',', 'padding', ':', '-', 'padding', ',', 'padding', ':', '-', 'padding', ',', ':', ']', '=', 'inpa', '[', ':', ',', '0', ':', ',', '0', ':', ',', ':', ']', '\\n']
Tokenized   (041): ['[CLS]', 'in', '##p', '_', 'pad', '[', ':', ',', 'pad', '##ding', ':', '-', 'pad', '##ding', ',', 'pad', '##ding', ':', '-', 'pad', '##ding', ',', ':', ']', '=', 'in', '##pa', '[', ':', ',', '0', ':', ',', '0', ':', ',', ':', ']', '\\', 'n', '[SEP]']
Filtered   (039): ['in', '##p', '_', 'pad', '[', ':', ',', 'pad', '##ding', ':', '-', 'pad', '##ding', ',', 'pad', '##ding', ':', '-', 'pad', '##ding', ',', ':', ']', '=', 'in', '##pa', '[', ':', ',', '0', ':', ',', '0', ':', ',', ':', ']', '\\', 'n']
Detokenized (030): ['in##p_pad', '[', ':', ',', 'pad##ding', ':', '-', 'pad##ding', ',', 'pad##ding', ':', '-', 'pad##ding', ',', ':', ']', '=', 'in##pa', '[', ':', ',', '0', ':', ',', '0', ':', ',', ':', ']', '\\n']
Counter: 39
===================================================================
Hidden states:  (13, 30, 768)
# Extracted words:  30
Sentence         : "out_exp [ indC , indh , indw , cnt ] = np . max ( inp_check ) \n"
Original    (018): ['out_exp', '[', 'indC', ',', 'indh', ',', 'indw', ',', 'cnt', ']', '=', 'np', '.', 'max', '(', 'inp_check', ')', '\\n']
Tokenized   (031): ['[CLS]', 'out', '_', 'ex', '##p', '[', 'ind', '##c', ',', 'ind', '##h', ',', 'ind', '##w', ',', 'cn', '##t', ']', '=', 'np', '.', 'max', '(', 'in', '##p', '_', 'check', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['out', '_', 'ex', '##p', '[', 'ind', '##c', ',', 'ind', '##h', ',', 'ind', '##w', ',', 'cn', '##t', ']', '=', 'np', '.', 'max', '(', 'in', '##p', '_', 'check', ')', '\\', 'n']
Detokenized (018): ['out_ex##p', '[', 'ind##c', ',', 'ind##h', ',', 'ind##w', ',', 'cn##t', ']', '=', 'np', '.', 'max', '(', 'in##p_check', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "NervanaObject . be . bsz = batch_size \n"
Original    (008): ['NervanaObject', '.', 'be', '.', 'bsz', '=', 'batch_size', '\\n']
Tokenized   (018): ['[CLS]', 'ne', '##rva', '##na', '##ob', '##ject', '.', 'be', '.', 'bs', '##z', '=', 'batch', '_', 'size', '\\', 'n', '[SEP]']
Filtered   (016): ['ne', '##rva', '##na', '##ob', '##ject', '.', 'be', '.', 'bs', '##z', '=', 'batch', '_', 'size', '\\', 'n']
Detokenized (008): ['ne##rva##na##ob##ject', '.', 'be', '.', 'bs##z', '=', 'batch_size', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "inshape = ( nifm , in_sz , in_sz ) \n"
Original    (010): ['inshape', '=', '(', 'nifm', ',', 'in_sz', ',', 'in_sz', ')', '\\n']
Tokenized   (022): ['[CLS]', 'ins', '##ha', '##pe', '=', '(', 'ni', '##fm', ',', 'in', '_', 's', '##z', ',', 'in', '_', 's', '##z', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['ins', '##ha', '##pe', '=', '(', 'ni', '##fm', ',', 'in', '_', 's', '##z', ',', 'in', '_', 's', '##z', ')', '\\', 'n']
Detokenized (010): ['ins##ha##pe', '=', '(', 'ni##fm', ',', 'in_s##z', ',', 'in_s##z', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "src = "img/file-icon.jpg" , ** kw ) ] \n"
Original    (009): ['src', '=', '"img/file-icon.jpg"', ',', '**', 'kw', ')', ']', '\\n']
Tokenized   (024): ['[CLS]', 'sr', '##c', '=', '"', 'im', '##g', '/', 'file', '-', 'icon', '.', 'jp', '##g', '"', ',', '*', '*', 'kw', ')', ']', '\\', 'n', '[SEP]']
Filtered   (022): ['sr', '##c', '=', '"', 'im', '##g', '/', 'file', '-', 'icon', '.', 'jp', '##g', '"', ',', '*', '*', 'kw', ')', ']', '\\', 'n']
Detokenized (009): ['sr##c', '=', '"im##g/file-icon.jp##g"', ',', '**', 'kw', ')', ']', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "render = lambda r : r . div ( comp . render ( r , model = None ) , r . script ( component_to_update = + self . comp_id , \n"
Original    (032): ['render', '=', 'lambda', 'r', ':', 'r', '.', 'div', '(', 'comp', '.', 'render', '(', 'r', ',', 'model', '=', 'None', ')', ',', 'r', '.', 'script', '(', 'component_to_update', '=', '+', 'self', '.', 'comp_id', ',', '\\n']
Tokenized   (044): ['[CLS]', 'render', '=', 'lambda', 'r', ':', 'r', '.', 'di', '##v', '(', 'com', '##p', '.', 'render', '(', 'r', ',', 'model', '=', 'none', ')', ',', 'r', '.', 'script', '(', 'component', '_', 'to', '_', 'update', '=', '+', 'self', '.', 'com', '##p', '_', 'id', ',', '\\', 'n', '[SEP]']
Filtered   (042): ['render', '=', 'lambda', 'r', ':', 'r', '.', 'di', '##v', '(', 'com', '##p', '.', 'render', '(', 'r', ',', 'model', '=', 'none', ')', ',', 'r', '.', 'script', '(', 'component', '_', 'to', '_', 'update', '=', '+', 'self', '.', 'com', '##p', '_', 'id', ',', '\\', 'n']
Detokenized (032): ['render', '=', 'lambda', 'r', ':', 'r', '.', 'di##v', '(', 'com##p', '.', 'render', '(', 'r', ',', 'model', '=', 'none', ')', ',', 'r', '.', 'script', '(', 'component_to_update', '=', '+', 'self', '.', 'com##p_id', ',', '\\n']
Counter: 42
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "ajax . py2js ( self . crop_height ( ) ) \n"
Original    (011): ['ajax', '.', 'py2js', '(', 'self', '.', 'crop_height', '(', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'ajax', '.', 'p', '##y', '##2', '##js', '(', 'self', '.', 'crop', '_', 'height', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['ajax', '.', 'p', '##y', '##2', '##js', '(', 'self', '.', 'crop', '_', 'height', '(', ')', ')', '\\', 'n']
Detokenized (011): ['ajax', '.', 'p##y##2##js', '(', 'self', '.', 'crop_height', '(', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "local_handler = getattr ( self , , None ) \n"
Original    (010): ['local_handler', '=', 'getattr', '(', 'self', ',', ',', 'None', ')', '\\n']
Tokenized   (017): ['[CLS]', 'local', '_', 'handler', '=', 'get', '##att', '##r', '(', 'self', ',', ',', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['local', '_', 'handler', '=', 'get', '##att', '##r', '(', 'self', ',', ',', 'none', ')', '\\', 'n']
Detokenized (010): ['local_handler', '=', 'get##att##r', '(', 'self', ',', ',', 'none', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "genie2 . client . wrapper . RetryPolicy ( \n"
Original    (009): ['genie2', '.', 'client', '.', 'wrapper', '.', 'RetryPolicy', '(', '\\n']
Tokenized   (018): ['[CLS]', 'genie', '##2', '.', 'client', '.', 'wrap', '##per', '.', 're', '##try', '##pol', '##ic', '##y', '(', '\\', 'n', '[SEP]']
Filtered   (016): ['genie', '##2', '.', 'client', '.', 'wrap', '##per', '.', 're', '##try', '##pol', '##ic', '##y', '(', '\\', 'n']
Detokenized (009): ['genie##2', '.', 'client', '.', 'wrap##per', '.', 're##try##pol##ic##y', '(', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "tries = 8 , none_on_404 = True , no_retry_http_codes = range ( 400 , 500 ) ) \n"
Original    (018): ['tries', '=', '8', ',', 'none_on_404', '=', 'True', ',', 'no_retry_http_codes', '=', 'range', '(', '400', ',', '500', ')', ')', '\\n']
Tokenized   (032): ['[CLS]', 'tries', '=', '8', ',', 'none', '_', 'on', '_', '404', '=', 'true', ',', 'no', '_', 're', '##try', '_', 'http', '_', 'codes', '=', 'range', '(', '400', ',', '500', ')', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['tries', '=', '8', ',', 'none', '_', 'on', '_', '404', '=', 'true', ',', 'no', '_', 're', '##try', '_', 'http', '_', 'codes', '=', 'range', '(', '400', ',', '500', ')', ')', '\\', 'n']
Detokenized (018): ['tries', '=', '8', ',', 'none_on_404', '=', 'true', ',', 'no_re##try_http_codes', '=', 'range', '(', '400', ',', '500', ')', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "tagging . add_argument ( , , dest = , action = conf_action ( context . ami ) , help = \n"
Original    (021): ['tagging', '.', 'add_argument', '(', ',', ',', 'dest', '=', ',', 'action', '=', 'conf_action', '(', 'context', '.', 'ami', ')', ',', 'help', '=', '\\n']
Tokenized   (031): ['[CLS]', 'tag', '##ging', '.', 'add', '_', 'argument', '(', ',', ',', 'des', '##t', '=', ',', 'action', '=', 'con', '##f', '_', 'action', '(', 'context', '.', 'ami', ')', ',', 'help', '=', '\\', 'n', '[SEP]']
Filtered   (029): ['tag', '##ging', '.', 'add', '_', 'argument', '(', ',', ',', 'des', '##t', '=', ',', 'action', '=', 'con', '##f', '_', 'action', '(', 'context', '.', 'ami', ')', ',', 'help', '=', '\\', 'n']
Detokenized (021): ['tag##ging', '.', 'add_argument', '(', ',', ',', 'des##t', '=', ',', 'action', '=', 'con##f_action', '(', 'context', '.', 'ami', ')', ',', 'help', '=', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "BASE_URL = . format ( FQDN ) \n"
Original    (008): ['BASE_URL', '=', '.', 'format', '(', 'FQDN', ')', '\\n']
Tokenized   (017): ['[CLS]', 'base', '_', 'ur', '##l', '=', '.', 'format', '(', 'f', '##q', '##d', '##n', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['base', '_', 'ur', '##l', '=', '.', 'format', '(', 'f', '##q', '##d', '##n', ')', '\\', 'n']
Detokenized (008): ['base_ur##l', '=', '.', 'format', '(', 'f##q##d##n', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test" , config ElasticSearchServiceItem ( region = "us-west-2" , account = "TEST_ACCOUNT" , name = "es_test_2" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_3" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_4" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_5" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_6" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_7" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_8" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_9" , config ] \n"
Original    (137): ['ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-west-2"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_2"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_3"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_4"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_5"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_6"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_7"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_8"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_9"', ',', 'config', ']', '\\n']
Tokenized   (354): ['[CLS]', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'west', '-', '2', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '2', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '3', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '4', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '5', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '6', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '7', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '8', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '9', '"', ',', 'con', '##fi', '##g', ']', '\\', 'n', '[SEP]']
Filtered   (352): ['elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'west', '-', '2', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '2', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '3', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '4', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '5', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '6', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '7', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'eu', '-', 'west', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '8', '"', ',', 'con', '##fi', '##g', 'elastic', '##sea', '##rch', '##ser', '##vic', '##eit', '##em', '(', 'region', '=', '"', 'us', '-', 'east', '-', '1', '"', ',', 'account', '=', '"', 'test', '_', 'account', '"', ',', 'name', '=', '"', 'es', '_', 'test', '_', '9', '"', ',', 'con', '##fi', '##g', ']', '\\', 'n']
Detokenized (137): ['elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"us-west-2"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_2"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_3"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_4"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_5"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_6"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_7"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_8"', ',', 'con##fi##g', 'elastic##sea##rch##ser##vic##eit##em', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"test_account"', ',', 'name', '=', '"es_test_9"', ',', 'con##fi##g', ']', '\\n']
Counter: 352
===================================================================
Hidden states:  (13, 137, 768)
# Extracted words:  137
Sentence         : "test_account . role_name = "TEST_ACCOUNT" \n"
Original    (006): ['test_account', '.', 'role_name', '=', '"TEST_ACCOUNT"', '\\n']
Tokenized   (017): ['[CLS]', 'test', '_', 'account', '.', 'role', '_', 'name', '=', '"', 'test', '_', 'account', '"', '\\', 'n', '[SEP]']
Filtered   (015): ['test', '_', 'account', '.', 'role', '_', 'name', '=', '"', 'test', '_', 'account', '"', '\\', 'n']
Detokenized (006): ['test_account', '.', 'role_name', '=', '"test_account"', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "all_clusters . extend ( response [ ] [ if response [ ] [ ] [ ] ~~~ marker = response [ ] [ ] [ ~~ else : \n"
Original    (029): ['all_clusters', '.', 'extend', '(', 'response', '[', ']', '[', 'if', 'response', '[', ']', '[', ']', '[', ']', '~~~', 'marker', '=', 'response', '[', ']', '[', ']', '[', '~~', 'else', ':', '\\n']
Tokenized   (037): ['[CLS]', 'all', '_', 'clusters', '.', 'extend', '(', 'response', '[', ']', '[', 'if', 'response', '[', ']', '[', ']', '[', ']', '~', '~', '~', 'marker', '=', 'response', '[', ']', '[', ']', '[', '~', '~', 'else', ':', '\\', 'n', '[SEP]']
Filtered   (035): ['all', '_', 'clusters', '.', 'extend', '(', 'response', '[', ']', '[', 'if', 'response', '[', ']', '[', ']', '[', ']', '~', '~', '~', 'marker', '=', 'response', '[', ']', '[', ']', '[', '~', '~', 'else', ':', '\\', 'n']
Detokenized (029): ['all_clusters', '.', 'extend', '(', 'response', '[', ']', '[', 'if', 'response', '[', ']', '[', ']', '[', ']', '~~~', 'marker', '=', 'response', '[', ']', '[', ']', '[', '~~', 'else', ':', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "_container_child_objects = ( , ) \n"
Original    (006): ['_container_child_objects', '=', '(', ',', ')', '\\n']
Tokenized   (014): ['[CLS]', '_', 'container', '_', 'child', '_', 'objects', '=', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['_', 'container', '_', 'child', '_', 'objects', '=', '(', ',', ')', '\\', 'n']
Detokenized (006): ['_container_child_objects', '=', '(', ',', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_recommended_attrs = ( ( ( , np . ndarray , 1 , np . dtype ( ) ) , \n"
Original    (020): ['_recommended_attrs', '=', '(', '(', '(', ',', 'np', '.', 'ndarray', ',', '1', ',', 'np', '.', 'dtype', '(', ')', ')', ',', '\\n']
Tokenized   (031): ['[CLS]', '_', 'recommended', '_', 'at', '##tr', '##s', '=', '(', '(', '(', ',', 'np', '.', 'n', '##dar', '##ray', ',', '1', ',', 'np', '.', 'dt', '##ype', '(', ')', ')', ',', '\\', 'n', '[SEP]']
Filtered   (029): ['_', 'recommended', '_', 'at', '##tr', '##s', '=', '(', '(', '(', ',', 'np', '.', 'n', '##dar', '##ray', ',', '1', ',', 'np', '.', 'dt', '##ype', '(', ')', ')', ',', '\\', 'n']
Detokenized (020): ['_recommended_at##tr##s', '=', '(', '(', '(', ',', 'np', '.', 'n##dar##ray', ',', '1', ',', 'np', '.', 'dt##ype', '(', ')', ')', ',', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "errstr = . format ( errno , pszMsgBuffer . value ) \n"
Original    (012): ['errstr', '=', '.', 'format', '(', 'errno', ',', 'pszMsgBuffer', '.', 'value', ')', '\\n']
Tokenized   (023): ['[CLS]', 'er', '##rst', '##r', '=', '.', 'format', '(', 'er', '##rno', ',', 'ps', '##z', '##ms', '##gb', '##uf', '##fer', '.', 'value', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['er', '##rst', '##r', '=', '.', 'format', '(', 'er', '##rno', ',', 'ps', '##z', '##ms', '##gb', '##uf', '##fer', '.', 'value', ')', '\\', 'n']
Detokenized (012): ['er##rst##r', '=', '.', 'format', '(', 'er##rno', ',', 'ps##z##ms##gb##uf##fer', '.', 'value', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "supported_objects = [ Segment , AnalogSignal , EventArray , SpikeTrain ] \n"
Original    (012): ['supported_objects', '=', '[', 'Segment', ',', 'AnalogSignal', ',', 'EventArray', ',', 'SpikeTrain', ']', '\\n']
Tokenized   (023): ['[CLS]', 'supported', '_', 'objects', '=', '[', 'segment', ',', 'analog', '##si', '##gna', '##l', ',', 'event', '##ar', '##ray', ',', 'spike', '##train', ']', '\\', 'n', '[SEP]']
Filtered   (021): ['supported', '_', 'objects', '=', '[', 'segment', ',', 'analog', '##si', '##gna', '##l', ',', 'event', '##ar', '##ray', ',', 'spike', '##train', ']', '\\', 'n']
Detokenized (012): ['supported_objects', '=', '[', 'segment', ',', 'analog##si##gna##l', ',', 'event##ar##ray', ',', 'spike##train', ']', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "readable_objects = [ Segment ] \n"
Original    (006): ['readable_objects', '=', '[', 'Segment', ']', '\\n']
Tokenized   (012): ['[CLS]', 'read', '##able', '_', 'objects', '=', '[', 'segment', ']', '\\', 'n', '[SEP]']
Filtered   (010): ['read', '##able', '_', 'objects', '=', '[', 'segment', ']', '\\', 'n']
Detokenized (006): ['read##able_objects', '=', '[', 'segment', ']', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "read_params = { Segment : [ ] } \n"
Original    (009): ['read_params', '=', '{', 'Segment', ':', '[', ']', '}', '\\n']
Tokenized   (015): ['[CLS]', 'read', '_', 'para', '##ms', '=', '{', 'segment', ':', '[', ']', '}', '\\', 'n', '[SEP]']
Filtered   (013): ['read', '_', 'para', '##ms', '=', '{', 'segment', ':', '[', ']', '}', '\\', 'n']
Detokenized (009): ['read_para##ms', '=', '{', 'segment', ':', '[', ']', '}', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "labels . append ( str ( pData . value ) ) \n"
Original    (012): ['labels', '.', 'append', '(', 'str', '(', 'pData', '.', 'value', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'labels', '.', 'app', '##end', '(', 'st', '##r', '(', 'pd', '##ata', '.', 'value', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['labels', '.', 'app', '##end', '(', 'st', '##r', '(', 'pd', '##ata', '.', 'value', ')', ')', '\\', 'n']
Detokenized (012): ['labels', '.', 'app##end', '(', 'st##r', '(', 'pd##ata', '.', 'value', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ea . labels = np . array ( labels , dtype = ) \n"
Original    (014): ['ea', '.', 'labels', '=', 'np', '.', 'array', '(', 'labels', ',', 'dtype', '=', ')', '\\n']
Tokenized   (018): ['[CLS]', 'ea', '.', 'labels', '=', 'np', '.', 'array', '(', 'labels', ',', 'dt', '##ype', '=', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['ea', '.', 'labels', '=', 'np', '.', 'array', '(', 'labels', ',', 'dt', '##ype', '=', ')', '\\', 'n']
Detokenized (014): ['ea', '.', 'labels', '=', 'np', '.', 'array', '(', 'labels', ',', 'dt##ype', '=', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dwStopIndex , ctypes . byref ( pdwContCount ) , pData [ total_read : ] . ctypes total_read += pdwContCount . value \n"
Original    (022): ['dwStopIndex', ',', 'ctypes', '.', 'byref', '(', 'pdwContCount', ')', ',', 'pData', '[', 'total_read', ':', ']', '.', 'ctypes', 'total_read', '+=', 'pdwContCount', '.', 'value', '\\n']
Tokenized   (049): ['[CLS]', 'd', '##ws', '##top', '##ind', '##ex', ',', 'ct', '##ype', '##s', '.', 'by', '##re', '##f', '(', 'pd', '##wc', '##ont', '##co', '##unt', ')', ',', 'pd', '##ata', '[', 'total', '_', 'read', ':', ']', '.', 'ct', '##ype', '##s', 'total', '_', 'read', '+', '=', 'pd', '##wc', '##ont', '##co', '##unt', '.', 'value', '\\', 'n', '[SEP]']
Filtered   (047): ['d', '##ws', '##top', '##ind', '##ex', ',', 'ct', '##ype', '##s', '.', 'by', '##re', '##f', '(', 'pd', '##wc', '##ont', '##co', '##unt', ')', ',', 'pd', '##ata', '[', 'total', '_', 'read', ':', ']', '.', 'ct', '##ype', '##s', 'total', '_', 'read', '+', '=', 'pd', '##wc', '##ont', '##co', '##unt', '.', 'value', '\\', 'n']
Detokenized (022): ['d##ws##top##ind##ex', ',', 'ct##ype##s', '.', 'by##re##f', '(', 'pd##wc##ont##co##unt', ')', ',', 'pd##ata', '[', 'total_read', ':', ']', '.', 'ct##ype##s', 'total_read', '+=', 'pd##wc##ont##co##unt', '.', 'value', '\\n']
Counter: 47
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "anaSig . annotate ( probe_info = str ( pAnalogInfo . szProbeInfo ) ) \n"
Original    (014): ['anaSig', '.', 'annotate', '(', 'probe_info', '=', 'str', '(', 'pAnalogInfo', '.', 'szProbeInfo', ')', ')', '\\n']
Tokenized   (032): ['[CLS]', 'ana', '##si', '##g', '.', 'ann', '##ota', '##te', '(', 'probe', '_', 'info', '=', 'st', '##r', '(', 'pan', '##alo', '##gin', '##fo', '.', 's', '##z', '##pro', '##bei', '##n', '##fo', ')', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['ana', '##si', '##g', '.', 'ann', '##ota', '##te', '(', 'probe', '_', 'info', '=', 'st', '##r', '(', 'pan', '##alo', '##gin', '##fo', '.', 's', '##z', '##pro', '##bei', '##n', '##fo', ')', ')', '\\', 'n']
Detokenized (014): ['ana##si##g', '.', 'ann##ota##te', '(', 'probe_info', '=', 'st##r', '(', 'pan##alo##gin##fo', '.', 's##z##pro##bei##n##fo', ')', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pData = np . zeros ( ( dwDataBufferSize ) , dtype = ) \n"
Original    (014): ['pData', '=', 'np', '.', 'zeros', '(', '(', 'dwDataBufferSize', ')', ',', 'dtype', '=', ')', '\\n']
Tokenized   (026): ['[CLS]', 'pd', '##ata', '=', 'np', '.', 'zero', '##s', '(', '(', 'd', '##wd', '##ata', '##bu', '##ffer', '##si', '##ze', ')', ',', 'dt', '##ype', '=', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['pd', '##ata', '=', 'np', '.', 'zero', '##s', '(', '(', 'd', '##wd', '##ata', '##bu', '##ffer', '##si', '##ze', ')', ',', 'dt', '##ype', '=', ')', '\\', 'n']
Detokenized (014): ['pd##ata', '=', 'np', '.', 'zero##s', '(', '(', 'd##wd##ata##bu##ffer##si##ze', ')', ',', 'dt##ype', '=', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "waveforms = pq . Quantity ( waveforms , units = str ( pdwSegmentInfo left_sweep = nsample / 2. / float ( pdwSegmentInfo . dSampleRate ) * pq sampling_rate = float ( pdwSegmentInfo . dSampleRate ) * pq . Hz , \n"
Original    (041): ['waveforms', '=', 'pq', '.', 'Quantity', '(', 'waveforms', ',', 'units', '=', 'str', '(', 'pdwSegmentInfo', 'left_sweep', '=', 'nsample', '/', '2.', '/', 'float', '(', 'pdwSegmentInfo', '.', 'dSampleRate', ')', '*', 'pq', 'sampling_rate', '=', 'float', '(', 'pdwSegmentInfo', '.', 'dSampleRate', ')', '*', 'pq', '.', 'Hz', ',', '\\n']
Tokenized   (077): ['[CLS]', 'wave', '##forms', '=', 'p', '##q', '.', 'quantity', '(', 'wave', '##forms', ',', 'units', '=', 'st', '##r', '(', 'pd', '##ws', '##eg', '##ment', '##in', '##fo', 'left', '_', 'sweep', '=', 'nsa', '##mple', '/', '2', '.', '/', 'float', '(', 'pd', '##ws', '##eg', '##ment', '##in', '##fo', '.', 'ds', '##amp', '##ler', '##ate', ')', '*', 'p', '##q', 'sampling', '_', 'rate', '=', 'float', '(', 'pd', '##ws', '##eg', '##ment', '##in', '##fo', '.', 'ds', '##amp', '##ler', '##ate', ')', '*', 'p', '##q', '.', 'hz', ',', '\\', 'n', '[SEP]']
Filtered   (075): ['wave', '##forms', '=', 'p', '##q', '.', 'quantity', '(', 'wave', '##forms', ',', 'units', '=', 'st', '##r', '(', 'pd', '##ws', '##eg', '##ment', '##in', '##fo', 'left', '_', 'sweep', '=', 'nsa', '##mple', '/', '2', '.', '/', 'float', '(', 'pd', '##ws', '##eg', '##ment', '##in', '##fo', '.', 'ds', '##amp', '##ler', '##ate', ')', '*', 'p', '##q', 'sampling', '_', 'rate', '=', 'float', '(', 'pd', '##ws', '##eg', '##ment', '##in', '##fo', '.', 'ds', '##amp', '##ler', '##ate', ')', '*', 'p', '##q', '.', 'hz', ',', '\\', 'n']
Detokenized (041): ['wave##forms', '=', 'p##q', '.', 'quantity', '(', 'wave##forms', ',', 'units', '=', 'st##r', '(', 'pd##ws##eg##ment##in##fo', 'left_sweep', '=', 'nsa##mple', '/', '2.', '/', 'float', '(', 'pd##ws##eg##ment##in##fo', '.', 'ds##amp##ler##ate', ')', '*', 'p##q', 'sampling_rate', '=', 'float', '(', 'pd##ws##eg##ment##in##fo', '.', 'ds##amp##ler##ate', ')', '*', 'p##q', '.', 'hz', ',', '\\n']
Counter: 75
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "ctypes . byref ( pNeuralInfo ) , ctypes . sizeof ( pNeuralInfo ) ) \n"
Original    (015): ['ctypes', '.', 'byref', '(', 'pNeuralInfo', ')', ',', 'ctypes', '.', 'sizeof', '(', 'pNeuralInfo', ')', ')', '\\n']
Tokenized   (033): ['[CLS]', 'ct', '##ype', '##s', '.', 'by', '##re', '##f', '(', 'p', '##ne', '##ural', '##in', '##fo', ')', ',', 'ct', '##ype', '##s', '.', 'size', '##of', '(', 'p', '##ne', '##ural', '##in', '##fo', ')', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['ct', '##ype', '##s', '.', 'by', '##re', '##f', '(', 'p', '##ne', '##ural', '##in', '##fo', ')', ',', 'ct', '##ype', '##s', '.', 'size', '##of', '(', 'p', '##ne', '##ural', '##in', '##fo', ')', ')', '\\', 'n']
Detokenized (015): ['ct##ype##s', '.', 'by##re##f', '(', 'p##ne##ural##in##fo', ')', ',', 'ct##ype##s', '.', 'size##of', '(', 'p##ne##ural##in##fo', ')', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "neuroshare . ns_GetNeuralData ( hFile , dwEntityID , dwStartIndex , \n"
Original    (011): ['neuroshare', '.', 'ns_GetNeuralData', '(', 'hFile', ',', 'dwEntityID', ',', 'dwStartIndex', ',', '\\n']
Tokenized   (034): ['[CLS]', 'ne', '##uro', '##sha', '##re', '.', 'ns', '_', 'get', '##ne', '##ural', '##da', '##ta', '(', 'h', '##fi', '##le', ',', 'd', '##wen', '##ti', '##ty', '##id', ',', 'd', '##ws', '##tar', '##tin', '##de', '##x', ',', '\\', 'n', '[SEP]']
Filtered   (032): ['ne', '##uro', '##sha', '##re', '.', 'ns', '_', 'get', '##ne', '##ural', '##da', '##ta', '(', 'h', '##fi', '##le', ',', 'd', '##wen', '##ti', '##ty', '##id', ',', 'd', '##ws', '##tar', '##tin', '##de', '##x', ',', '\\', 'n']
Detokenized (011): ['ne##uro##sha##re', '.', 'ns_get##ne##ural##da##ta', '(', 'h##fi##le', ',', 'd##wen##ti##ty##id', ',', 'd##ws##tar##tin##de##x', ',', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dwIndexCount , pData . ctypes . data_as ( ctypes . POINTER ( ctypes . c_double ) ) ) \n"
Original    (019): ['dwIndexCount', ',', 'pData', '.', 'ctypes', '.', 'data_as', '(', 'ctypes', '.', 'POINTER', '(', 'ctypes', '.', 'c_double', ')', ')', ')', '\\n']
Tokenized   (037): ['[CLS]', 'd', '##wind', '##ex', '##co', '##unt', ',', 'pd', '##ata', '.', 'ct', '##ype', '##s', '.', 'data', '_', 'as', '(', 'ct', '##ype', '##s', '.', 'pointer', '(', 'ct', '##ype', '##s', '.', 'c', '_', 'double', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (035): ['d', '##wind', '##ex', '##co', '##unt', ',', 'pd', '##ata', '.', 'ct', '##ype', '##s', '.', 'data', '_', 'as', '(', 'ct', '##ype', '##s', '.', 'pointer', '(', 'ct', '##ype', '##s', '.', 'c', '_', 'double', ')', ')', ')', '\\', 'n']
Detokenized (019): ['d##wind##ex##co##unt', ',', 'pd##ata', '.', 'ct##ype##s', '.', 'data_as', '(', 'ct##ype##s', '.', 'pointer', '(', 'ct##ype##s', '.', 'c_double', ')', ')', ')', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "times = pData * pq . s \n"
Original    (008): ['times', '=', 'pData', '*', 'pq', '.', 's', '\\n']
Tokenized   (013): ['[CLS]', 'times', '=', 'pd', '##ata', '*', 'p', '##q', '.', 's', '\\', 'n', '[SEP]']
Filtered   (011): ['times', '=', 'pd', '##ata', '*', 'p', '##q', '.', 's', '\\', 'n']
Detokenized (008): ['times', '=', 'pd##ata', '*', 'p##q', '.', 's', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "clone_object , TEST_ANNOTATIONS ) \n"
Original    (005): ['clone_object', ',', 'TEST_ANNOTATIONS', ')', '\\n']
Tokenized   (014): ['[CLS]', 'clone', '_', 'object', ',', 'test', '_', 'ann', '##ota', '##tions', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['clone', '_', 'object', ',', 'test', '_', 'ann', '##ota', '##tions', ')', '\\', 'n']
Detokenized (005): ['clone_object', ',', 'test_ann##ota##tions', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "range ( len ( TEST_ANNOTATIONS ) ) ] ) \n"
Original    (010): ['range', '(', 'len', '(', 'TEST_ANNOTATIONS', ')', ')', ']', ')', '\\n']
Tokenized   (017): ['[CLS]', 'range', '(', 'len', '(', 'test', '_', 'ann', '##ota', '##tions', ')', ')', ']', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['range', '(', 'len', '(', 'test', '_', 'ann', '##ota', '##tions', ')', ')', ']', ')', '\\', 'n']
Detokenized (010): ['range', '(', 'len', '(', 'test_ann##ota##tions', ')', ')', ']', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "file_datetime = get_fake_value ( , datetime , seed = 0 ) \n"
Original    (012): ['file_datetime', '=', 'get_fake_value', '(', ',', 'datetime', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (023): ['[CLS]', 'file', '_', 'date', '##time', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'date', '##time', ',', 'seed', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['file', '_', 'date', '##time', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'date', '##time', ',', 'seed', '=', '0', ')', '\\', 'n']
Detokenized (012): ['file_date##time', '=', 'get_fake_value', '(', ',', 'date##time', ',', 'seed', '=', '0', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "file_origin = get_fake_value ( , str ) \n"
Original    (008): ['file_origin', '=', 'get_fake_value', '(', ',', 'str', ')', '\\n']
Tokenized   (018): ['[CLS]', 'file', '_', 'origin', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'st', '##r', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['file', '_', 'origin', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'st', '##r', ')', '\\', 'n']
Detokenized (008): ['file_origin', '=', 'get_fake_value', '(', ',', 'st##r', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "attrs1 = { : file_datetime , \n"
Original    (007): ['attrs1', '=', '{', ':', 'file_datetime', ',', '\\n']
Tokenized   (016): ['[CLS]', 'at', '##tr', '##s', '##1', '=', '{', ':', 'file', '_', 'date', '##time', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['at', '##tr', '##s', '##1', '=', '{', ':', 'file', '_', 'date', '##time', ',', '\\', 'n']
Detokenized (007): ['at##tr##s##1', '=', '{', ':', 'file_date##time', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "res21 = get_fake_values ( Segment , annotate = True , seed = 0 ) \n"
Original    (015): ['res21', '=', 'get_fake_values', '(', 'Segment', ',', 'annotate', '=', 'True', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (025): ['[CLS]', 'res', '##21', '=', 'get', '_', 'fake', '_', 'values', '(', 'segment', ',', 'ann', '##ota', '##te', '=', 'true', ',', 'seed', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['res', '##21', '=', 'get', '_', 'fake', '_', 'values', '(', 'segment', ',', 'ann', '##ota', '##te', '=', 'true', ',', 'seed', '=', '0', ')', '\\', 'n']
Detokenized (015): ['res##21', '=', 'get_fake_values', '(', 'segment', ',', 'ann##ota##te', '=', 'true', ',', 'seed', '=', '0', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "res22 = get_fake_values ( , annotate = True , seed = 0 ) \n"
Original    (014): ['res22', '=', 'get_fake_values', '(', ',', 'annotate', '=', 'True', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (024): ['[CLS]', 'res', '##22', '=', 'get', '_', 'fake', '_', 'values', '(', ',', 'ann', '##ota', '##te', '=', 'true', ',', 'seed', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['res', '##22', '=', 'get', '_', 'fake', '_', 'values', '(', ',', 'ann', '##ota', '##te', '=', 'true', ',', 'seed', '=', '0', ')', '\\', 'n']
Detokenized (014): ['res##22', '=', 'get_fake_values', '(', ',', 'ann##ota##te', '=', 'true', ',', 'seed', '=', '0', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "targ0 = get_fake_value ( , datetime , seed = seed + 0 ) \n"
Original    (014): ['targ0', '=', 'get_fake_value', '(', ',', 'datetime', ',', 'seed', '=', 'seed', '+', '0', ')', '\\n']
Tokenized   (024): ['[CLS]', 'tar', '##g', '##0', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'date', '##time', ',', 'seed', '=', 'seed', '+', '0', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['tar', '##g', '##0', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'date', '##time', ',', 'seed', '=', 'seed', '+', '0', ')', '\\', 'n']
Detokenized (014): ['tar##g##0', '=', 'get_fake_value', '(', ',', 'date##time', ',', 'seed', '=', 'seed', '+', '0', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "targ4 = get_fake_value ( , str , \n"
Original    (008): ['targ4', '=', 'get_fake_value', '(', ',', 'str', ',', '\\n']
Tokenized   (018): ['[CLS]', 'tar', '##g', '##4', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'st', '##r', ',', '\\', 'n', '[SEP]']
Filtered   (016): ['tar', '##g', '##4', '=', 'get', '_', 'fake', '_', 'value', '(', ',', 'st', '##r', ',', '\\', 'n']
Detokenized (008): ['tar##g##4', '=', 'get_fake_value', '(', ',', 'st##r', ',', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "seed = seed + 4 , obj = Segment ) \n"
Original    (011): ['seed', '=', 'seed', '+', '4', ',', 'obj', '=', 'Segment', ')', '\\n']
Tokenized   (015): ['[CLS]', 'seed', '=', 'seed', '+', '4', ',', 'ob', '##j', '=', 'segment', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['seed', '=', 'seed', '+', '4', ',', 'ob', '##j', '=', 'segment', ')', '\\', 'n']
Detokenized (011): ['seed', '=', 'seed', '+', '4', ',', 'ob##j', '=', 'segment', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "childobjs = ( , , \n"
Original    (006): ['childobjs', '=', '(', ',', ',', '\\n']
Tokenized   (011): ['[CLS]', 'child', '##ob', '##js', '=', '(', ',', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['child', '##ob', '##js', '=', '(', ',', ',', '\\', 'n']
Detokenized (006): ['child##ob##js', '=', '(', ',', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "children = ( self . sigs1a + self . sigarrs1a + \n"
Original    (012): ['children', '=', '(', 'self', '.', 'sigs1a', '+', 'self', '.', 'sigarrs1a', '+', '\\n']
Tokenized   (022): ['[CLS]', 'children', '=', '(', 'self', '.', 'si', '##gs', '##1', '##a', '+', 'self', '.', 'si', '##gar', '##rs', '##1', '##a', '+', '\\', 'n', '[SEP]']
Filtered   (020): ['children', '=', '(', 'self', '.', 'si', '##gs', '##1', '##a', '+', 'self', '.', 'si', '##gar', '##rs', '##1', '##a', '+', '\\', 'n']
Detokenized (012): ['children', '=', '(', 'self', '.', 'si##gs##1##a', '+', 'self', '.', 'si##gar##rs##1##a', '+', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""analogsignals" : self . nchildren ** 2 , \n"
Original    (009): ['"analogsignals"', ':', 'self', '.', 'nchildren', '**', '2', ',', '\\n']
Tokenized   (021): ['[CLS]', '"', 'analog', '##si', '##gna', '##ls', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', '*', '*', '2', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['"', 'analog', '##si', '##gna', '##ls', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', '*', '*', '2', ',', '\\', 'n']
Detokenized (009): ['"analog##si##gna##ls"', ':', 'self', '.', 'nc##hil##dre##n', '**', '2', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""epocharrays" : self . nchildren , "eventarrays" : self . nchildren , \n"
Original    (013): ['"epocharrays"', ':', 'self', '.', 'nchildren', ',', '"eventarrays"', ':', 'self', '.', 'nchildren', ',', '\\n']
Tokenized   (032): ['[CLS]', '"', 'epoch', '##ar', '##ray', '##s', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', ',', '"', 'event', '##ar', '##ray', '##s', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', ',', '\\', 'n', '[SEP]']
Filtered   (030): ['"', 'epoch', '##ar', '##ray', '##s', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', ',', '"', 'event', '##ar', '##ray', '##s', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', ',', '\\', 'n']
Detokenized (013): ['"epoch##ar##ray##s"', ':', 'self', '.', 'nc##hil##dre##n', ',', '"event##ar##ray##s"', ':', 'self', '.', 'nc##hil##dre##n', ',', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : ""analogsignalarrays" : self . nchildren } \n"
Original    (007): ['"analogsignalarrays"', ':', 'self', '.', 'nchildren', '}', '\\n']
Tokenized   (020): ['[CLS]', '"', 'analog', '##si', '##gna', '##lar', '##ray', '##s', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', '}', '\\', 'n', '[SEP]']
Filtered   (018): ['"', 'analog', '##si', '##gna', '##lar', '##ray', '##s', '"', ':', 'self', '.', 'nc', '##hil', '##dre', '##n', '}', '\\', 'n']
Detokenized (007): ['"analog##si##gna##lar##ray##s"', ':', 'self', '.', 'nc##hil##dre##n', '}', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "targdict = { : 5 } ) \n"
Original    (008): ['targdict', '=', '{', ':', '5', '}', ')', '\\n']
Tokenized   (013): ['[CLS]', 'tar', '##g', '##dict', '=', '{', ':', '5', '}', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['tar', '##g', '##dict', '=', '{', ':', '5', '}', ')', '\\', 'n']
Detokenized (008): ['tar##g##dict', '=', '{', ':', '5', '}', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "res6 = filterdata ( data , name = self . epcs2 [ 0 ] . name , j = 5 ) \n"
Original    (022): ['res6', '=', 'filterdata', '(', 'data', ',', 'name', '=', 'self', '.', 'epcs2', '[', '0', ']', '.', 'name', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (030): ['[CLS]', 'res', '##6', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'name', '=', 'self', '.', 'ep', '##cs', '##2', '[', '0', ']', '.', 'name', ',', 'j', '=', '5', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['res', '##6', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'name', '=', 'self', '.', 'ep', '##cs', '##2', '[', '0', ']', '.', 'name', ',', 'j', '=', '5', ')', '\\', 'n']
Detokenized (022): ['res##6', '=', 'filter##da##ta', '(', 'data', ',', 'name', '=', 'self', '.', 'ep##cs##2', '[', '0', ']', '.', 'name', ',', 'j', '=', '5', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "res7 = filterdata ( data , { : self . epcs2 [ 1 ] . name , : 5 } ) \n"
Original    (022): ['res7', '=', 'filterdata', '(', 'data', ',', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Tokenized   (030): ['[CLS]', 'res', '##7', '=', 'filter', '##da', '##ta', '(', 'data', ',', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['res', '##7', '=', 'filter', '##da', '##ta', '(', 'data', ',', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\', 'n']
Detokenized (022): ['res##7', '=', 'filter##da##ta', '(', 'data', ',', '{', ':', 'self', '.', 'ep##cs##2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "res8 = filterdata ( data , targdict = { : self . epcs2 [ 1 ] . name , : 5 } ) \n"
Original    (024): ['res8', '=', 'filterdata', '(', 'data', ',', 'targdict', '=', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Tokenized   (034): ['[CLS]', 'res', '##8', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'tar', '##g', '##dict', '=', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['res', '##8', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'tar', '##g', '##dict', '=', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\', 'n']
Detokenized (024): ['res##8', '=', 'filter##da##ta', '(', 'data', ',', 'tar##g##dict', '=', '{', ':', 'self', '.', 'ep##cs##2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "res9 = filterdata ( data , { : self . epcs2 [ 1 ] . name } , j = 5 ) \n"
Original    (023): ['res9', '=', 'filterdata', '(', 'data', ',', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (031): ['[CLS]', 'res', '##9', '=', 'filter', '##da', '##ta', '(', 'data', ',', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['res', '##9', '=', 'filter', '##da', '##ta', '(', 'data', ',', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\', 'n']
Detokenized (023): ['res##9', '=', 'filter##da##ta', '(', 'data', ',', '{', ':', 'self', '.', 'ep##cs##2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "res10 = filterdata ( data , targdict = { : self . epcs2 [ 1 ] . name } , j = 5 ) \n"
Original    (025): ['res10', '=', 'filterdata', '(', 'data', ',', 'targdict', '=', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (035): ['[CLS]', 'res', '##10', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'tar', '##g', '##dict', '=', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\', 'n', '[SEP]']
Filtered   (033): ['res', '##10', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'tar', '##g', '##dict', '=', '{', ':', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\', 'n']
Detokenized (025): ['res##10', '=', 'filter##da##ta', '(', 'data', ',', 'tar##g##dict', '=', '{', ':', 'self', '.', 'ep##cs##2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "res11 = filterdata ( data , name = self . epcs2 [ 1 ] . name , targdict = { : 5 } ) \n"
Original    (025): ['res11', '=', 'filterdata', '(', 'data', ',', 'name', '=', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', 'targdict', '=', '{', ':', '5', '}', ')', '\\n']
Tokenized   (035): ['[CLS]', 'res', '##11', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'name', '=', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', ',', 'tar', '##g', '##dict', '=', '{', ':', '5', '}', ')', '\\', 'n', '[SEP]']
Filtered   (033): ['res', '##11', '=', 'filter', '##da', '##ta', '(', 'data', ',', 'name', '=', 'self', '.', 'ep', '##cs', '##2', '[', '1', ']', '.', 'name', ',', 'tar', '##g', '##dict', '=', '{', ':', '5', '}', ')', '\\', 'n']
Detokenized (025): ['res##11', '=', 'filter##da##ta', '(', 'data', ',', 'name', '=', 'self', '.', 'ep##cs##2', '[', '1', ']', '.', 'name', ',', 'tar##g##dict', '=', '{', ':', '5', '}', ')', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "targ = [ self . epcs1a [ 1 ] ] \n"
Original    (011): ['targ', '=', '[', 'self', '.', 'epcs1a', '[', '1', ']', ']', '\\n']
Tokenized   (018): ['[CLS]', 'tar', '##g', '=', '[', 'self', '.', 'ep', '##cs', '##1', '##a', '[', '1', ']', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['tar', '##g', '=', '[', 'self', '.', 'ep', '##cs', '##1', '##a', '[', '1', ']', ']', '\\', 'n']
Detokenized (011): ['tar##g', '=', '[', 'self', '.', 'ep##cs##1##a', '[', '1', ']', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "res3 = filterdata ( data , [ { : 1 } , { : 2 } ] ) \n"
Original    (019): ['res3', '=', 'filterdata', '(', 'data', ',', '[', '{', ':', '1', '}', ',', '{', ':', '2', '}', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'res', '##3', '=', 'filter', '##da', '##ta', '(', 'data', ',', '[', '{', ':', '1', '}', ',', '{', ':', '2', '}', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['res', '##3', '=', 'filter', '##da', '##ta', '(', 'data', ',', '[', '{', ':', '1', '}', ',', '{', ':', '2', '}', ']', ')', '\\', 'n']
Detokenized (019): ['res##3', '=', 'filter##da##ta', '(', 'data', ',', '[', '{', ':', '1', '}', ',', '{', ':', '2', '}', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "res4 = filterdata ( data , { : 1 } , i = 2 ) \n"
Original    (016): ['res4', '=', 'filterdata', '(', 'data', ',', '{', ':', '1', '}', ',', 'i', '=', '2', ')', '\\n']
Tokenized   (022): ['[CLS]', 'res', '##4', '=', 'filter', '##da', '##ta', '(', 'data', ',', '{', ':', '1', '}', ',', 'i', '=', '2', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['res', '##4', '=', 'filter', '##da', '##ta', '(', 'data', ',', '{', ':', '1', '}', ',', 'i', '=', '2', ')', '\\', 'n']
Detokenized (016): ['res##4', '=', 'filter##da##ta', '(', 'data', ',', '{', ':', '1', '}', ',', 'i', '=', '2', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "res5 = filterdata ( data , [ { : 1 } ] , i = 2 ) \n"
Original    (018): ['res5', '=', 'filterdata', '(', 'data', ',', '[', '{', ':', '1', '}', ']', ',', 'i', '=', '2', ')', '\\n']
Tokenized   (024): ['[CLS]', 'res', '##5', '=', 'filter', '##da', '##ta', '(', 'data', ',', '[', '{', ':', '1', '}', ']', ',', 'i', '=', '2', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['res', '##5', '=', 'filter', '##da', '##ta', '(', 'data', ',', '[', '{', ':', '1', '}', ']', ',', 'i', '=', '2', ')', '\\', 'n']
Detokenized (018): ['res##5', '=', 'filter##da##ta', '(', 'data', ',', '[', '{', ':', '1', '}', ']', ',', 'i', '=', '2', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "ann = pretty ( ann ) . replace ( , ) \n"
Original    (012): ['ann', '=', 'pretty', '(', 'ann', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (015): ['[CLS]', 'ann', '=', 'pretty', '(', 'ann', ')', '.', 'replace', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['ann', '=', 'pretty', '(', 'ann', ')', '.', 'replace', '(', ',', ')', '\\', 'n']
Detokenized (012): ['ann', '=', 'pretty', '(', 'ann', ')', '.', 'replace', '(', ',', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "unit_with_sig = np . array ( [ 0 , 2 , 5 ] ) \n"
Original    (015): ['unit_with_sig', '=', 'np', '.', 'array', '(', '[', '0', ',', '2', ',', '5', ']', ')', '\\n']
Tokenized   (023): ['[CLS]', 'unit', '_', 'with', '_', 'si', '##g', '=', 'np', '.', 'array', '(', '[', '0', ',', '2', ',', '5', ']', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['unit', '_', 'with', '_', 'si', '##g', '=', 'np', '.', 'array', '(', '[', '0', ',', '2', ',', '5', ']', ')', '\\', 'n']
Detokenized (015): ['unit_with_si##g', '=', 'np', '.', 'array', '(', '[', '0', ',', '2', ',', '5', ']', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rcgs = [ RecordingChannelGroup ( name = , \n"
Original    (009): ['rcgs', '=', '[', 'RecordingChannelGroup', '(', 'name', '=', ',', '\\n']
Tokenized   (015): ['[CLS]', 'rc', '##gs', '=', '[', 'recording', '##channel', '##group', '(', 'name', '=', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['rc', '##gs', '=', '[', 'recording', '##channel', '##group', '(', 'name', '=', ',', '\\', 'n']
Detokenized (009): ['rc##gs', '=', '[', 'recording##channel##group', '(', 'name', '=', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "RecordingChannelGroup ( name = , \n"
Original    (006): ['RecordingChannelGroup', '(', 'name', '=', ',', '\\n']
Tokenized   (011): ['[CLS]', 'recording', '##channel', '##group', '(', 'name', '=', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['recording', '##channel', '##group', '(', 'name', '=', ',', '\\', 'n']
Detokenized (006): ['recording##channel##group', '(', 'name', '=', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "t_start = 0. , t_stop = 10 ) \n"
Original    (009): ['t_start', '=', '0.', ',', 't_stop', '=', '10', ')', '\\n']
Tokenized   (017): ['[CLS]', 't', '_', 'start', '=', '0', '.', ',', 't', '_', 'stop', '=', '10', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['t', '_', 'start', '=', '0', '.', ',', 't', '_', 'stop', '=', '10', ')', '\\', 'n']
Detokenized (009): ['t_start', '=', '0.', ',', 't_stop', '=', '10', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "st . unit = all_unit [ j ] \n"
Original    (009): ['st', '.', 'unit', '=', 'all_unit', '[', 'j', ']', '\\n']
Tokenized   (014): ['[CLS]', 'st', '.', 'unit', '=', 'all', '_', 'unit', '[', 'j', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['st', '.', 'unit', '=', 'all', '_', 'unit', '[', 'j', ']', '\\', 'n']
Detokenized (009): ['st', '.', 'unit', '=', 'all_unit', '[', 'j', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "sampling_rate = 1000. * pq . Hz , \n"
Original    (009): ['sampling_rate', '=', '1000.', '*', 'pq', '.', 'Hz', ',', '\\n']
Tokenized   (016): ['[CLS]', 'sampling', '_', 'rate', '=', '1000', '.', '*', 'p', '##q', '.', 'hz', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['sampling', '_', 'rate', '=', '1000', '.', '*', 'p', '##q', '.', 'hz', ',', '\\', 'n']
Detokenized (009): ['sampling_rate', '=', '1000.', '*', 'p##q', '.', 'hz', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newseg = seg . construct_subsegment_by_unit ( all_unit [ : 4 ] ) \n"
Original    (013): ['newseg', '=', 'seg', '.', 'construct_subsegment_by_unit', '(', 'all_unit', '[', ':', '4', ']', ')', '\\n']
Tokenized   (029): ['[CLS]', 'news', '##eg', '=', 'se', '##g', '.', 'construct', '_', 'sub', '##se', '##gm', '##ent', '_', 'by', '_', 'unit', '(', 'all', '_', 'unit', '[', ':', '4', ']', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['news', '##eg', '=', 'se', '##g', '.', 'construct', '_', 'sub', '##se', '##gm', '##ent', '_', 'by', '_', 'unit', '(', 'all', '_', 'unit', '[', ':', '4', ']', ')', '\\', 'n']
Detokenized (013): ['news##eg', '=', 'se##g', '.', 'construct_sub##se##gm##ent_by_unit', '(', 'all_unit', '[', ':', '4', ']', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ind2 = self . unit2 . channel_indexes [ 0 ] \n"
Original    (011): ['ind2', '=', 'self', '.', 'unit2', '.', 'channel_indexes', '[', '0', ']', '\\n']
Tokenized   (019): ['[CLS]', 'ind', '##2', '=', 'self', '.', 'unit', '##2', '.', 'channel', '_', 'index', '##es', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (017): ['ind', '##2', '=', 'self', '.', 'unit', '##2', '.', 'channel', '_', 'index', '##es', '[', '0', ']', '\\', 'n']
Detokenized (011): ['ind##2', '=', 'self', '.', 'unit##2', '.', 'channel_index##es', '[', '0', ']', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "result22 = self . seg1 . take_analogsignal_by_channelindex ( [ ind2 ] ) \n"
Original    (013): ['result22', '=', 'self', '.', 'seg1', '.', 'take_analogsignal_by_channelindex', '(', '[', 'ind2', ']', ')', '\\n']
Tokenized   (031): ['[CLS]', 'result', '##22', '=', 'self', '.', 'se', '##g', '##1', '.', 'take', '_', 'analog', '##si', '##gna', '##l', '_', 'by', '_', 'channel', '##ind', '##ex', '(', '[', 'ind', '##2', ']', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['result', '##22', '=', 'self', '.', 'se', '##g', '##1', '.', 'take', '_', 'analog', '##si', '##gna', '##l', '_', 'by', '_', 'channel', '##ind', '##ex', '(', '[', 'ind', '##2', ']', ')', '\\', 'n']
Detokenized (013): ['result##22', '=', 'self', '.', 'se##g##1', '.', 'take_analog##si##gna##l_by_channel##ind##ex', '(', '[', 'ind##2', ']', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "targ1 = [ self . sigarrs1a [ 0 ] [ : , np . array ( [ True ] ) ] , \n"
Original    (023): ['targ1', '=', '[', 'self', '.', 'sigarrs1a', '[', '0', ']', '[', ':', ',', 'np', '.', 'array', '(', '[', 'True', ']', ')', ']', ',', '\\n']
Tokenized   (032): ['[CLS]', 'tar', '##g', '##1', '=', '[', 'self', '.', 'si', '##gar', '##rs', '##1', '##a', '[', '0', ']', '[', ':', ',', 'np', '.', 'array', '(', '[', 'true', ']', ')', ']', ',', '\\', 'n', '[SEP]']
Filtered   (030): ['tar', '##g', '##1', '=', '[', 'self', '.', 'si', '##gar', '##rs', '##1', '##a', '[', '0', ']', '[', ':', ',', 'np', '.', 'array', '(', '[', 'true', ']', ')', ']', ',', '\\', 'n']
Detokenized (023): ['tar##g##1', '=', '[', 'self', '.', 'si##gar##rs##1##a', '[', '0', ']', '[', ':', ',', 'np', '.', 'array', '(', '[', 'true', ']', ')', ']', ',', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "result21 = seg . take_slice_of_analogsignalarray_by_channelindex ( [ ind1 ] ) \n"
Original    (011): ['result21', '=', 'seg', '.', 'take_slice_of_analogsignalarray_by_channelindex', '(', '[', 'ind1', ']', ')', '\\n']
Tokenized   (033): ['[CLS]', 'result', '##21', '=', 'se', '##g', '.', 'take', '_', 'slice', '_', 'of', '_', 'analog', '##si', '##gna', '##lar', '##ray', '_', 'by', '_', 'channel', '##ind', '##ex', '(', '[', 'ind', '##1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['result', '##21', '=', 'se', '##g', '.', 'take', '_', 'slice', '_', 'of', '_', 'analog', '##si', '##gna', '##lar', '##ray', '_', 'by', '_', 'channel', '##ind', '##ex', '(', '[', 'ind', '##1', ']', ')', '\\', 'n']
Detokenized (011): ['result##21', '=', 'se##g', '.', 'take_slice_of_analog##si##gna##lar##ray_by_channel##ind##ex', '(', '[', 'ind##1', ']', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "json_content = json_content . decode ( "utf-8" ) . replace ( , ) \n"
Original    (014): ['json_content', '=', 'json_content', '.', 'decode', '(', '"utf-8"', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (029): ['[CLS]', 'j', '##son', '_', 'content', '=', 'j', '##son', '_', 'content', '.', 'deco', '##de', '(', '"', 'ut', '##f', '-', '8', '"', ')', '.', 'replace', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['j', '##son', '_', 'content', '=', 'j', '##son', '_', 'content', '.', 'deco', '##de', '(', '"', 'ut', '##f', '-', '8', '"', ')', '.', 'replace', '(', ',', ')', '\\', 'n']
Detokenized (014): ['j##son_content', '=', 'j##son_content', '.', 'deco##de', '(', '"ut##f-8"', ')', '.', 'replace', '(', ',', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "Image1 = StatisticMap ( name = , collection = self . Collection1 , file = , Image1 . file = SimpleUploadedFile ( , file ( os . path . join ( self . test_path , Image1 . save ( ) \n"
Original    (041): ['Image1', '=', 'StatisticMap', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'Collection1', ',', 'file', '=', ',', 'Image1', '.', 'file', '=', 'SimpleUploadedFile', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'Image1', '.', 'save', '(', ')', '\\n']
Tokenized   (057): ['[CLS]', 'image', '##1', '=', 'stat', '##istic', '##ma', '##p', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'collection', '##1', ',', 'file', '=', ',', 'image', '##1', '.', 'file', '=', 'simple', '##up', '##loaded', '##fi', '##le', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test', '_', 'path', ',', 'image', '##1', '.', 'save', '(', ')', '\\', 'n', '[SEP]']
Filtered   (055): ['image', '##1', '=', 'stat', '##istic', '##ma', '##p', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'collection', '##1', ',', 'file', '=', ',', 'image', '##1', '.', 'file', '=', 'simple', '##up', '##loaded', '##fi', '##le', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test', '_', 'path', ',', 'image', '##1', '.', 'save', '(', ')', '\\', 'n']
Detokenized (041): ['image##1', '=', 'stat##istic##ma##p', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'collection##1', ',', 'file', '=', ',', 'image##1', '.', 'file', '=', 'simple##up##loaded##fi##le', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'image##1', '.', 'save', '(', ')', '\\n']
Counter: 55
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "fname = os . path . basename ( os . path . join ( self . test_path , ) ) file_dict = { : SimpleUploadedFile ( fname , zip_file . read ( ) ) } \n"
Original    (036): ['fname', '=', 'os', '.', 'path', '.', 'basename', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', ')', ')', 'file_dict', '=', '{', ':', 'SimpleUploadedFile', '(', 'fname', ',', 'zip_file', '.', 'read', '(', ')', ')', '}', '\\n']
Tokenized   (053): ['[CLS]', 'f', '##name', '=', 'os', '.', 'path', '.', 'base', '##name', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test', '_', 'path', ',', ')', ')', 'file', '_', 'di', '##ct', '=', '{', ':', 'simple', '##up', '##loaded', '##fi', '##le', '(', 'f', '##name', ',', 'zip', '_', 'file', '.', 'read', '(', ')', ')', '}', '\\', 'n', '[SEP]']
Filtered   (051): ['f', '##name', '=', 'os', '.', 'path', '.', 'base', '##name', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test', '_', 'path', ',', ')', ')', 'file', '_', 'di', '##ct', '=', '{', ':', 'simple', '##up', '##loaded', '##fi', '##le', '(', 'f', '##name', ',', 'zip', '_', 'file', '.', 'read', '(', ')', ')', '}', '\\', 'n']
Detokenized (036): ['f##name', '=', 'os', '.', 'path', '.', 'base##name', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', ')', ')', 'file_di##ct', '=', '{', ':', 'simple##up##loaded##fi##le', '(', 'f##name', ',', 'zip_file', '.', 'read', '(', ')', ')', '}', '\\n']
Counter: 51
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "Image2ss = StatisticMap ( name = , collection = self . Collection3 , file = Image2ss . file = SimpleUploadedFile ( , file ( os . path . join ( self . test_path , Image2ss . save ( ) \n"
Original    (040): ['Image2ss', '=', 'StatisticMap', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'Collection3', ',', 'file', '=', 'Image2ss', '.', 'file', '=', 'SimpleUploadedFile', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'Image2ss', '.', 'save', '(', ')', '\\n']
Tokenized   (059): ['[CLS]', 'image', '##2', '##ss', '=', 'stat', '##istic', '##ma', '##p', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'collection', '##3', ',', 'file', '=', 'image', '##2', '##ss', '.', 'file', '=', 'simple', '##up', '##loaded', '##fi', '##le', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test', '_', 'path', ',', 'image', '##2', '##ss', '.', 'save', '(', ')', '\\', 'n', '[SEP]']
Filtered   (057): ['image', '##2', '##ss', '=', 'stat', '##istic', '##ma', '##p', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'collection', '##3', ',', 'file', '=', 'image', '##2', '##ss', '.', 'file', '=', 'simple', '##up', '##loaded', '##fi', '##le', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test', '_', 'path', ',', 'image', '##2', '##ss', '.', 'save', '(', ')', '\\', 'n']
Detokenized (040): ['image##2##ss', '=', 'stat##istic##ma##p', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'collection##3', ',', 'file', '=', 'image##2##ss', '.', 'file', '=', 'simple##up##loaded##fi##le', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'image##2##ss', '.', 'save', '(', ')', '\\n']
Counter: 57
===================================================================
Hidden states:  (13, 40, 768)
# Extracted words:  40
Sentence         : "acc_new = rho * acc + ( 1 - rho ) * g ** 2 \n"
Original    (016): ['acc_new', '=', 'rho', '*', 'acc', '+', '(', '1', '-', 'rho', ')', '*', 'g', '**', '2', '\\n']
Tokenized   (024): ['[CLS]', 'acc', '_', 'new', '=', 'r', '##ho', '*', 'acc', '+', '(', '1', '-', 'r', '##ho', ')', '*', 'g', '*', '*', '2', '\\', 'n', '[SEP]']
Filtered   (022): ['acc', '_', 'new', '=', 'r', '##ho', '*', 'acc', '+', '(', '1', '-', 'r', '##ho', ')', '*', 'g', '*', '*', '2', '\\', 'n']
Detokenized (016): ['acc_new', '=', 'r##ho', '*', 'acc', '+', '(', '1', '-', 'r##ho', ')', '*', 'g', '**', '2', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "gradient_scaling = T . sqrt ( acc_new + epsilon ) \n"
Original    (011): ['gradient_scaling', '=', 'T', '.', 'sqrt', '(', 'acc_new', '+', 'epsilon', ')', '\\n']
Tokenized   (019): ['[CLS]', 'gradient', '_', 'scaling', '=', 't', '.', 'sq', '##rt', '(', 'acc', '_', 'new', '+', 'epsilon', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['gradient', '_', 'scaling', '=', 't', '.', 'sq', '##rt', '(', 'acc', '_', 'new', '+', 'epsilon', ')', '\\', 'n']
Detokenized (011): ['gradient_scaling', '=', 't', '.', 'sq##rt', '(', 'acc_new', '+', 'epsilon', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "py_x = softmax ( T . dot ( h2 , w_o ) ) \n"
Original    (014): ['py_x', '=', 'softmax', '(', 'T', '.', 'dot', '(', 'h2', ',', 'w_o', ')', ')', '\\n']
Tokenized   (024): ['[CLS]', 'p', '##y', '_', 'x', '=', 'soft', '##max', '(', 't', '.', 'dot', '(', 'h', '##2', ',', 'w', '_', 'o', ')', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['p', '##y', '_', 'x', '=', 'soft', '##max', '(', 't', '.', 'dot', '(', 'h', '##2', ',', 'w', '_', 'o', ')', ')', '\\', 'n']
Detokenized (014): ['p##y_x', '=', 'soft##max', '(', 't', '.', 'dot', '(', 'h##2', ',', 'w_o', ')', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "w_h = init_weights ( ( 784 , 625 ) ) \n"
Original    (011): ['w_h', '=', 'init_weights', '(', '(', '784', ',', '625', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'w', '_', 'h', '=', 'in', '##it', '_', 'weights', '(', '(', '78', '##4', ',', '625', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['w', '_', 'h', '=', 'in', '##it', '_', 'weights', '(', '(', '78', '##4', ',', '625', ')', ')', '\\', 'n']
Detokenized (011): ['w_h', '=', 'in##it_weights', '(', '(', '78##4', ',', '625', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "noise_h , noise_h2 , noise_py_x = model ( X , w_h , w_h2 , w_o , 0.2 , 0.5 ) \n"
Original    (021): ['noise_h', ',', 'noise_h2', ',', 'noise_py_x', '=', 'model', '(', 'X', ',', 'w_h', ',', 'w_h2', ',', 'w_o', ',', '0.2', ',', '0.5', ')', '\\n']
Tokenized   (045): ['[CLS]', 'noise', '_', 'h', ',', 'noise', '_', 'h', '##2', ',', 'noise', '_', 'p', '##y', '_', 'x', '=', 'model', '(', 'x', ',', 'w', '_', 'h', ',', 'w', '_', 'h', '##2', ',', 'w', '_', 'o', ',', '0', '.', '2', ',', '0', '.', '5', ')', '\\', 'n', '[SEP]']
Filtered   (043): ['noise', '_', 'h', ',', 'noise', '_', 'h', '##2', ',', 'noise', '_', 'p', '##y', '_', 'x', '=', 'model', '(', 'x', ',', 'w', '_', 'h', ',', 'w', '_', 'h', '##2', ',', 'w', '_', 'o', ',', '0', '.', '2', ',', '0', '.', '5', ')', '\\', 'n']
Detokenized (021): ['noise_h', ',', 'noise_h##2', ',', 'noise_p##y_x', '=', 'model', '(', 'x', ',', 'w_h', ',', 'w_h##2', ',', 'w_o', ',', '0.2', ',', '0.5', ')', '\\n']
Counter: 43
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "y_x = T . argmax ( py_x , axis = 1 ) \n"
Original    (013): ['y_x', '=', 'T', '.', 'argmax', '(', 'py_x', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (023): ['[CLS]', 'y', '_', 'x', '=', 't', '.', 'ar', '##gm', '##ax', '(', 'p', '##y', '_', 'x', ',', 'axis', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['y', '_', 'x', '=', 't', '.', 'ar', '##gm', '##ax', '(', 'p', '##y', '_', 'x', ',', 'axis', '=', '1', ')', '\\', 'n']
Detokenized (013): ['y_x', '=', 't', '.', 'ar##gm##ax', '(', 'p##y_x', ',', 'axis', '=', '1', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "cost = T . mean ( T . nnet . categorical_crossentropy ( noise_py_x , Y ) ) \n"
Original    (018): ['cost', '=', 'T', '.', 'mean', '(', 'T', '.', 'nnet', '.', 'categorical_crossentropy', '(', 'noise_py_x', ',', 'Y', ')', ')', '\\n']
Tokenized   (033): ['[CLS]', 'cost', '=', 't', '.', 'mean', '(', 't', '.', 'n', '##net', '.', 'cat', '##egorical', '_', 'cross', '##ent', '##rop', '##y', '(', 'noise', '_', 'p', '##y', '_', 'x', ',', 'y', ')', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['cost', '=', 't', '.', 'mean', '(', 't', '.', 'n', '##net', '.', 'cat', '##egorical', '_', 'cross', '##ent', '##rop', '##y', '(', 'noise', '_', 'p', '##y', '_', 'x', ',', 'y', ')', ')', '\\', 'n']
Detokenized (018): ['cost', '=', 't', '.', 'mean', '(', 't', '.', 'n##net', '.', 'cat##egorical_cross##ent##rop##y', '(', 'noise_p##y_x', ',', 'y', ')', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "updates = RMSprop ( cost , params , lr = 0.001 ) \n"
Original    (013): ['updates', '=', 'RMSprop', '(', 'cost', ',', 'params', ',', 'lr', '=', '0.001', ')', '\\n']
Tokenized   (022): ['[CLS]', 'updates', '=', 'rms', '##pro', '##p', '(', 'cost', ',', 'para', '##ms', ',', 'l', '##r', '=', '0', '.', '001', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['updates', '=', 'rms', '##pro', '##p', '(', 'cost', ',', 'para', '##ms', ',', 'l', '##r', '=', '0', '.', '001', ')', '\\', 'n']
Detokenized (013): ['updates', '=', 'rms##pro##p', '(', 'cost', ',', 'para##ms', ',', 'l##r', '=', '0.001', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "train = theano . function ( inputs = [ X , Y ] , outputs = cost , updates = updates , allow_input_downcast = True ) \n"
Original    (027): ['train', '=', 'theano', '.', 'function', '(', 'inputs', '=', '[', 'X', ',', 'Y', ']', ',', 'outputs', '=', 'cost', ',', 'updates', '=', 'updates', ',', 'allow_input_downcast', '=', 'True', ')', '\\n']
Tokenized   (036): ['[CLS]', 'train', '=', 'the', '##ano', '.', 'function', '(', 'inputs', '=', '[', 'x', ',', 'y', ']', ',', 'outputs', '=', 'cost', ',', 'updates', '=', 'updates', ',', 'allow', '_', 'input', '_', 'down', '##cast', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['train', '=', 'the', '##ano', '.', 'function', '(', 'inputs', '=', '[', 'x', ',', 'y', ']', ',', 'outputs', '=', 'cost', ',', 'updates', '=', 'updates', ',', 'allow', '_', 'input', '_', 'down', '##cast', '=', 'true', ')', '\\', 'n']
Detokenized (027): ['train', '=', 'the##ano', '.', 'function', '(', 'inputs', '=', '[', 'x', ',', 'y', ']', ',', 'outputs', '=', 'cost', ',', 'updates', '=', 'updates', ',', 'allow_input_down##cast', '=', 'true', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "predict = theano . function ( inputs = [ X ] , outputs = y_x , allow_input_downcast = True ) \n"
Original    (021): ['predict', '=', 'theano', '.', 'function', '(', 'inputs', '=', '[', 'X', ']', ',', 'outputs', '=', 'y_x', ',', 'allow_input_downcast', '=', 'True', ')', '\\n']
Tokenized   (032): ['[CLS]', 'predict', '=', 'the', '##ano', '.', 'function', '(', 'inputs', '=', '[', 'x', ']', ',', 'outputs', '=', 'y', '_', 'x', ',', 'allow', '_', 'input', '_', 'down', '##cast', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['predict', '=', 'the', '##ano', '.', 'function', '(', 'inputs', '=', '[', 'x', ']', ',', 'outputs', '=', 'y', '_', 'x', ',', 'allow', '_', 'input', '_', 'down', '##cast', '=', 'true', ')', '\\', 'n']
Detokenized (021): ['predict', '=', 'the##ano', '.', 'function', '(', 'inputs', '=', '[', 'x', ']', ',', 'outputs', '=', 'y_x', ',', 'allow_input_down##cast', '=', 'true', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "settings . DATABASE_CONFIG_DICT [ ] ) \n"
Original    (007): ['settings', '.', 'DATABASE_CONFIG_DICT', '[', ']', ')', '\\n']
Tokenized   (017): ['[CLS]', 'settings', '.', 'database', '_', 'con', '##fi', '##g', '_', 'di', '##ct', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['settings', '.', 'database', '_', 'con', '##fi', '##g', '_', 'di', '##ct', '[', ']', ')', '\\', 'n']
Detokenized (007): ['settings', '.', 'database_con##fi##g_di##ct', '[', ']', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "TEMPLATES [ 0 ] [ ] [ ] = DEBUG \n"
Original    (011): ['TEMPLATES', '[', '0', ']', '[', ']', '[', ']', '=', 'DEBUG', '\\n']
Tokenized   (017): ['[CLS]', 'template', '##s', '[', '0', ']', '[', ']', '[', ']', '=', 'de', '##bu', '##g', '\\', 'n', '[SEP]']
Filtered   (015): ['template', '##s', '[', '0', ']', '[', ']', '[', ']', '=', 'de', '##bu', '##g', '\\', 'n']
Detokenized (011): ['template##s', '[', '0', ']', '[', ']', '[', ']', '=', 'de##bu##g', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "SECRET_KEY = env ( "DJANGO_SECRET_KEY" , default = ) \n"
Original    (010): ['SECRET_KEY', '=', 'env', '(', '"DJANGO_SECRET_KEY"', ',', 'default', '=', ')', '\\n']
Tokenized   (023): ['[CLS]', 'secret', '_', 'key', '=', 'en', '##v', '(', '"', 'dj', '##ango', '_', 'secret', '_', 'key', '"', ',', 'default', '=', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['secret', '_', 'key', '=', 'en', '##v', '(', '"', 'dj', '##ango', '_', 'secret', '_', 'key', '"', ',', 'default', '=', ')', '\\', 'n']
Detokenized (010): ['secret_key', '=', 'en##v', '(', '"dj##ango_secret_key"', ',', 'default', '=', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "MIDDLEWARE_CLASSES += ( , ) \n"
Original    (006): ['MIDDLEWARE_CLASSES', '+=', '(', ',', ')', '\\n']
Tokenized   (013): ['[CLS]', 'middle', '##ware', '_', 'classes', '+', '=', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['middle', '##ware', '_', 'classes', '+', '=', '(', ',', ')', '\\', 'n']
Detokenized (006): ['middle##ware_classes', '+=', '(', ',', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "INTERNAL_IPS = ( , , ) \n"
Original    (007): ['INTERNAL_IPS', '=', '(', ',', ',', ')', '\\n']
Tokenized   (013): ['[CLS]', 'internal', '_', 'ip', '##s', '=', '(', ',', ',', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['internal', '_', 'ip', '##s', '=', '(', ',', ',', ')', '\\', 'n']
Detokenized (007): ['internal_ip##s', '=', '(', ',', ',', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "redirect_url = request . POST . get ( ) or \n"
Original    (011): ['redirect_url', '=', 'request', '.', 'POST', '.', 'get', '(', ')', 'or', '\\n']
Tokenized   (019): ['[CLS]', 'red', '##ire', '##ct', '_', 'ur', '##l', '=', 'request', '.', 'post', '.', 'get', '(', ')', 'or', '\\', 'n', '[SEP]']
Filtered   (017): ['red', '##ire', '##ct', '_', 'ur', '##l', '=', 'request', '.', 'post', '.', 'get', '(', ')', 'or', '\\', 'n']
Detokenized (011): ['red##ire##ct_ur##l', '=', 'request', '.', 'post', '.', 'get', '(', ')', 'or', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "icon = self . get_plugin_icon ( ) , \n"
Original    (009): ['icon', '=', 'self', '.', 'get_plugin_icon', '(', ')', ',', '\\n']
Tokenized   (017): ['[CLS]', 'icon', '=', 'self', '.', 'get', '_', 'plug', '##in', '_', 'icon', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['icon', '=', 'self', '.', 'get', '_', 'plug', '##in', '_', 'icon', '(', ')', ',', '\\', 'n']
Detokenized (009): ['icon', '=', 'self', '.', 'get_plug##in_icon', '(', ')', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "memoryprofiler_act . setEnabled ( is_memoryprofiler_installed ( ) ) \n"
Original    (009): ['memoryprofiler_act', '.', 'setEnabled', '(', 'is_memoryprofiler_installed', '(', ')', ')', '\\n']
Tokenized   (026): ['[CLS]', 'memory', '##pro', '##fi', '##ler', '_', 'act', '.', 'set', '##ena', '##bled', '(', 'is', '_', 'memory', '##pro', '##fi', '##ler', '_', 'installed', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['memory', '##pro', '##fi', '##ler', '_', 'act', '.', 'set', '##ena', '##bled', '(', 'is', '_', 'memory', '##pro', '##fi', '##ler', '_', 'installed', '(', ')', ')', '\\', 'n']
Detokenized (009): ['memory##pro##fi##ler_act', '.', 'set##ena##bled', '(', 'is_memory##pro##fi##ler_installed', '(', ')', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "wdir , args = None , None \n"
Original    (008): ['wdir', ',', 'args', '=', 'None', ',', 'None', '\\n']
Tokenized   (014): ['[CLS]', 'w', '##di', '##r', ',', 'ar', '##gs', '=', 'none', ',', 'none', '\\', 'n', '[SEP]']
Filtered   (012): ['w', '##di', '##r', ',', 'ar', '##gs', '=', 'none', ',', 'none', '\\', 'n']
Detokenized (008): ['w##di##r', ',', 'ar##gs', '=', 'none', ',', 'none', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "use_colors = self . get_option ( , True ) ) \n"
Original    (011): ['use_colors', '=', 'self', '.', 'get_option', '(', ',', 'True', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'use', '_', 'colors', '=', 'self', '.', 'get', '_', 'option', '(', ',', 'true', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['use', '_', 'colors', '=', 'self', '.', 'get', '_', 'option', '(', ',', 'true', ')', ')', '\\', 'n']
Detokenized (011): ['use_colors', '=', 'self', '.', 'get_option', '(', ',', 'true', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "message_type = None , enum_type = None , containing_type = None , \n"
Original    (013): ['message_type', '=', 'None', ',', 'enum_type', '=', 'None', ',', 'containing_type', '=', 'None', ',', '\\n']
Tokenized   (023): ['[CLS]', 'message', '_', 'type', '=', 'none', ',', 'en', '##um', '_', 'type', '=', 'none', ',', 'containing', '_', 'type', '=', 'none', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['message', '_', 'type', '=', 'none', ',', 'en', '##um', '_', 'type', '=', 'none', ',', 'containing', '_', 'type', '=', 'none', ',', '\\', 'n']
Detokenized (013): ['message_type', '=', 'none', ',', 'en##um_type', '=', 'none', ',', 'containing_type', '=', 'none', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_extension = False , extension_scope = None , \n"
Original    (009): ['is_extension', '=', 'False', ',', 'extension_scope', '=', 'None', ',', '\\n']
Tokenized   (016): ['[CLS]', 'is', '_', 'extension', '=', 'false', ',', 'extension', '_', 'scope', '=', 'none', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['is', '_', 'extension', '=', 'false', ',', 'extension', '_', 'scope', '=', 'none', ',', '\\', 'n']
Detokenized (009): ['is_extension', '=', 'false', ',', 'extension_scope', '=', 'none', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_BATCHNOTIFICATIONREQUEST . fields_by_name [ ] . message_type = _PUSHNOTIFICATION \n"
Original    (010): ['_BATCHNOTIFICATIONREQUEST', '.', 'fields_by_name', '[', ']', '.', 'message_type', '=', '_PUSHNOTIFICATION', '\\n']
Tokenized   (027): ['[CLS]', '_', 'batch', '##not', '##ification', '##re', '##quest', '.', 'fields', '_', 'by', '_', 'name', '[', ']', '.', 'message', '_', 'type', '=', '_', 'push', '##not', '##ification', '\\', 'n', '[SEP]']
Filtered   (025): ['_', 'batch', '##not', '##ification', '##re', '##quest', '.', 'fields', '_', 'by', '_', 'name', '[', ']', '.', 'message', '_', 'type', '=', '_', 'push', '##not', '##ification', '\\', 'n']
Detokenized (010): ['_batch##not##ification##re##quest', '.', 'fields_by_name', '[', ']', '.', 'message_type', '=', '_push##not##ification', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "expected_zip_content = [ "manifest.json" , "sd_bl.bin" , "sd_bl.dat" ] \n"
Original    (010): ['expected_zip_content', '=', '[', '"manifest.json"', ',', '"sd_bl.bin"', ',', '"sd_bl.dat"', ']', '\\n']
Tokenized   (036): ['[CLS]', 'expected', '_', 'zip', '_', 'content', '=', '[', '"', 'manifest', '.', 'j', '##son', '"', ',', '"', 'sd', '_', 'b', '##l', '.', 'bin', '"', ',', '"', 'sd', '_', 'b', '##l', '.', 'dat', '"', ']', '\\', 'n', '[SEP]']
Filtered   (034): ['expected', '_', 'zip', '_', 'content', '=', '[', '"', 'manifest', '.', 'j', '##son', '"', ',', '"', 'sd', '_', 'b', '##l', '.', 'bin', '"', ',', '"', 'sd', '_', 'b', '##l', '.', 'dat', '"', ']', '\\', 'n']
Detokenized (010): ['expected_zip_content', '=', '[', '"manifest.j##son"', ',', '"sd_b##l.bin"', ',', '"sd_b##l.dat"', ']', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sd_req = [ 0x1000 , 0xffff ] , \n"
Original    (009): ['sd_req', '=', '[', '0x1000', ',', '0xffff', ']', ',', '\\n']
Tokenized   (021): ['[CLS]', 'sd', '_', 're', '##q', '=', '[', '0', '##x', '##100', '##0', ',', '0', '##x', '##ff', '##ff', ']', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['sd', '_', 're', '##q', '=', '[', '0', '##x', '##100', '##0', ',', '0', '##x', '##ff', '##ff', ']', ',', '\\', 'n']
Detokenized (009): ['sd_re##q', '=', '[', '0##x##100##0', ',', '0##x##ff##ff', ']', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pkg_name = os . path . join ( self . work_directory , "mypackage.zip" ) \n"
Original    (015): ['pkg_name', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', '"mypackage.zip"', ')', '\\n']
Tokenized   (030): ['[CLS]', 'p', '##k', '##g', '_', 'name', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work', '_', 'directory', ',', '"', 'my', '##pack', '##age', '.', 'zip', '"', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['p', '##k', '##g', '_', 'name', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work', '_', 'directory', ',', '"', 'my', '##pack', '##age', '.', 'zip', '"', ')', '\\', 'n']
Detokenized (015): ['p##k##g_name', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', '"my##pack##age.zip"', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "manifest = self . p . unpack_package ( os . path . join ( self . work_directory , pkg_name ) , unpacked_dir ) \n"
Original    (024): ['manifest', '=', 'self', '.', 'p', '.', 'unpack_package', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', 'pkg_name', ')', ',', 'unpacked_dir', ')', '\\n']
Tokenized   (040): ['[CLS]', 'manifest', '=', 'self', '.', 'p', '.', 'un', '##pack', '_', 'package', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work', '_', 'directory', ',', 'p', '##k', '##g', '_', 'name', ')', ',', 'un', '##pack', '##ed', '_', 'dir', ')', '\\', 'n', '[SEP]']
Filtered   (038): ['manifest', '=', 'self', '.', 'p', '.', 'un', '##pack', '_', 'package', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work', '_', 'directory', ',', 'p', '##k', '##g', '_', 'name', ')', ',', 'un', '##pack', '##ed', '_', 'dir', ')', '\\', 'n']
Detokenized (024): ['manifest', '=', 'self', '.', 'p', '.', 'un##pack_package', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', 'p##k##g_name', ')', ',', 'un##pack##ed_dir', ')', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "style = wx . richtext . RE_MULTILINE , value = ) \n"
Original    (012): ['style', '=', 'wx', '.', 'richtext', '.', 'RE_MULTILINE', ',', 'value', '=', ')', '\\n']
Tokenized   (020): ['[CLS]', 'style', '=', 'w', '##x', '.', 'rich', '##text', '.', 're', '_', 'multi', '##line', ',', 'value', '=', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['style', '=', 'w', '##x', '.', 'rich', '##text', '.', 're', '_', 'multi', '##line', ',', 'value', '=', ')', '\\', 'n']
Detokenized (012): ['style', '=', 'w##x', '.', 'rich##text', '.', 're_multi##line', ',', 'value', '=', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fgSizer1 . Add ( self . lblChangelt , 0 , wx . ALL , 5 ) \n"
Original    (017): ['fgSizer1', '.', 'Add', '(', 'self', '.', 'lblChangelt', ',', '0', ',', 'wx', '.', 'ALL', ',', '5', ')', '\\n']
Tokenized   (027): ['[CLS]', 'f', '##gs', '##izer', '##1', '.', 'add', '(', 'self', '.', 'lb', '##lch', '##ange', '##lt', ',', '0', ',', 'w', '##x', '.', 'all', ',', '5', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['f', '##gs', '##izer', '##1', '.', 'add', '(', 'self', '.', 'lb', '##lch', '##ange', '##lt', ',', '0', ',', 'w', '##x', '.', 'all', ',', '5', ')', '\\', 'n']
Detokenized (017): ['f##gs##izer##1', '.', 'add', '(', 'self', '.', 'lb##lch##ange##lt', ',', '0', ',', 'w##x', '.', 'all', ',', '5', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sbThreshold . Add ( fgSizer1 , 0 , wx . EXPAND , 5 ) \n"
Original    (015): ['sbThreshold', '.', 'Add', '(', 'fgSizer1', ',', '0', ',', 'wx', '.', 'EXPAND', ',', '5', ')', '\\n']
Tokenized   (025): ['[CLS]', 'sb', '##th', '##resh', '##old', '.', 'add', '(', 'f', '##gs', '##izer', '##1', ',', '0', ',', 'w', '##x', '.', 'expand', ',', '5', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['sb', '##th', '##resh', '##old', '.', 'add', '(', 'f', '##gs', '##izer', '##1', ',', '0', ',', 'w', '##x', '.', 'expand', ',', '5', ')', '\\', 'n']
Detokenized (015): ['sb##th##resh##old', '.', 'add', '(', 'f##gs##izer##1', ',', '0', ',', 'w##x', '.', 'expand', ',', '5', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "bsValueThresh . Add ( sbThreshold , 1 , 0 , 5 ) \n"
Original    (013): ['bsValueThresh', '.', 'Add', '(', 'sbThreshold', ',', '1', ',', '0', ',', '5', ')', '\\n']
Tokenized   (023): ['[CLS]', 'bs', '##val', '##uet', '##hre', '##sh', '.', 'add', '(', 'sb', '##th', '##resh', '##old', ',', '1', ',', '0', ',', '5', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['bs', '##val', '##uet', '##hre', '##sh', '.', 'add', '(', 'sb', '##th', '##resh', '##old', ',', '1', ',', '0', ',', '5', ')', '\\', 'n']
Detokenized (013): ['bs##val##uet##hre##sh', '.', 'add', '(', 'sb##th##resh##old', ',', '1', ',', '0', ',', '5', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "cbGapTimeChoices = [ u"second" , u"minute" , u"hour" , u"day" ] \n"
Original    (012): ['cbGapTimeChoices', '=', '[', 'u"second"', ',', 'u"minute"', ',', 'u"hour"', ',', 'u"day"', ']', '\\n']
Tokenized   (032): ['[CLS]', 'cb', '##ga', '##pt', '##ime', '##cho', '##ices', '=', '[', 'u', '"', 'second', '"', ',', 'u', '"', 'minute', '"', ',', 'u', '"', 'hour', '"', ',', 'u', '"', 'day', '"', ']', '\\', 'n', '[SEP]']
Filtered   (030): ['cb', '##ga', '##pt', '##ime', '##cho', '##ices', '=', '[', 'u', '"', 'second', '"', ',', 'u', '"', 'minute', '"', ',', 'u', '"', 'hour', '"', ',', 'u', '"', 'day', '"', ']', '\\', 'n']
Detokenized (012): ['cb##ga##pt##ime##cho##ices', '=', '[', 'u"second"', ',', 'u"minute"', ',', 'u"hour"', ',', 'u"day"', ']', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fmt24hr = True , spinButton = self . sbBefore , oob_color = ) \n"
Original    (014): ['fmt24hr', '=', 'True', ',', 'spinButton', '=', 'self', '.', 'sbBefore', ',', 'oob_color', '=', ')', '\\n']
Tokenized   (028): ['[CLS]', 'fm', '##t', '##24', '##hr', '=', 'true', ',', 'spin', '##bu', '##tton', '=', 'self', '.', 'sb', '##be', '##for', '##e', ',', 'o', '##ob', '_', 'color', '=', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['fm', '##t', '##24', '##hr', '=', 'true', ',', 'spin', '##bu', '##tton', '=', 'self', '.', 'sb', '##be', '##for', '##e', ',', 'o', '##ob', '_', 'color', '=', ')', '\\', 'n']
Detokenized (014): ['fm##t##24##hr', '=', 'true', ',', 'spin##bu##tton', '=', 'self', '.', 'sb##be##for##e', ',', 'o##ob_color', '=', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "bsButtons . Add ( self . btnOK , 1 , wx . ALL | wx . EXPAND , 5 ) \n"
Original    (021): ['bsButtons', '.', 'Add', '(', 'self', '.', 'btnOK', ',', '1', ',', 'wx', '.', 'ALL', '|', 'wx', '.', 'EXPAND', ',', '5', ')', '\\n']
Tokenized   (031): ['[CLS]', 'bs', '##bu', '##tton', '##s', '.', 'add', '(', 'self', '.', 'bt', '##no', '##k', ',', '1', ',', 'w', '##x', '.', 'all', '|', 'w', '##x', '.', 'expand', ',', '5', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['bs', '##bu', '##tton', '##s', '.', 'add', '(', 'self', '.', 'bt', '##no', '##k', ',', '1', ',', 'w', '##x', '.', 'all', '|', 'w', '##x', '.', 'expand', ',', '5', ')', '\\', 'n']
Detokenized (021): ['bs##bu##tton##s', '.', 'add', '(', 'self', '.', 'bt##no##k', ',', '1', ',', 'w##x', '.', 'all', '|', 'w##x', '.', 'expand', ',', '5', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "mat ( op2 . INC , ( elem_node [ op2 . i [ 0 ] ] , \n"
Original    (018): ['mat', '(', 'op2', '.', 'INC', ',', '(', 'elem_node', '[', 'op2', '.', 'i', '[', '0', ']', ']', ',', '\\n']
Tokenized   (026): ['[CLS]', 'mat', '(', 'op', '##2', '.', 'inc', ',', '(', 'el', '##em', '_', 'node', '[', 'op', '##2', '.', 'i', '[', '0', ']', ']', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['mat', '(', 'op', '##2', '.', 'inc', ',', '(', 'el', '##em', '_', 'node', '[', 'op', '##2', '.', 'i', '[', '0', ']', ']', ',', '\\', 'n']
Detokenized (018): ['mat', '(', 'op##2', '.', 'inc', ',', '(', 'el##em_node', '[', 'op##2', '.', 'i', '[', '0', ']', ']', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "elem_node [ op2 . i [ 1 ] ] ) ) , \n"
Original    (013): ['elem_node', '[', 'op2', '.', 'i', '[', '1', ']', ']', ')', ')', ',', '\\n']
Tokenized   (020): ['[CLS]', 'el', '##em', '_', 'node', '[', 'op', '##2', '.', 'i', '[', '1', ']', ']', ')', ')', ',', '\\', 'n', '[SEP]']
Filtered   (018): ['el', '##em', '_', 'node', '[', 'op', '##2', '.', 'i', '[', '1', ']', ']', ')', ')', ',', '\\', 'n']
Detokenized (013): ['el##em_node', '[', 'op##2', '.', 'i', '[', '1', ']', ']', ')', ')', ',', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "partition_size = NUM_ELE / 2 , \n"
Original    (007): ['partition_size', '=', 'NUM_ELE', '/', '2', ',', '\\n']
Tokenized   (016): ['[CLS]', 'partition', '_', 'size', '=', 'nu', '##m', '_', 'el', '##e', '/', '2', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['partition', '_', 'size', '=', 'nu', '##m', '_', 'el', '##e', '/', '2', ',', '\\', 'n']
Detokenized (007): ['partition_size', '=', 'nu##m_el##e', '/', '2', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "statusBarAx . barh ( [ 0 ] , [ 100.0 * expNumber / len ( data . getPaths ( ) ) ] , \n"
Original    (024): ['statusBarAx', '.', 'barh', '(', '[', '0', ']', ',', '[', '100.0', '*', 'expNumber', '/', 'len', '(', 'data', '.', 'getPaths', '(', ')', ')', ']', ',', '\\n']
Tokenized   (037): ['[CLS]', 'status', '##bara', '##x', '.', 'bar', '##h', '(', '[', '0', ']', ',', '[', '100', '.', '0', '*', 'ex', '##p', '##num', '##ber', '/', 'len', '(', 'data', '.', 'get', '##path', '##s', '(', ')', ')', ']', ',', '\\', 'n', '[SEP]']
Filtered   (035): ['status', '##bara', '##x', '.', 'bar', '##h', '(', '[', '0', ']', ',', '[', '100', '.', '0', '*', 'ex', '##p', '##num', '##ber', '/', 'len', '(', 'data', '.', 'get', '##path', '##s', '(', ')', ')', ']', ',', '\\', 'n']
Detokenized (024): ['status##bara##x', '.', 'bar##h', '(', '[', '0', ']', ',', '[', '100.0', '*', 'ex##p##num##ber', '/', 'len', '(', 'data', '.', 'get##path##s', '(', ')', ')', ']', ',', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "fluxes , errors , photFlags = photometry . multirad ( image , x , y , \n"
Original    (017): ['fluxes', ',', 'errors', ',', 'photFlags', '=', 'photometry', '.', 'multirad', '(', 'image', ',', 'x', ',', 'y', ',', '\\n']
Tokenized   (026): ['[CLS]', 'flux', '##es', ',', 'errors', ',', 'ph', '##ot', '##fl', '##ags', '=', 'photo', '##metry', '.', 'multi', '##rad', '(', 'image', ',', 'x', ',', 'y', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['flux', '##es', ',', 'errors', ',', 'ph', '##ot', '##fl', '##ags', '=', 'photo', '##metry', '.', 'multi', '##rad', '(', 'image', ',', 'x', ',', 'y', ',', '\\', 'n']
Detokenized (017): ['flux##es', ',', 'errors', ',', 'ph##ot##fl##ags', '=', 'photo##metry', '.', 'multi##rad', '(', 'image', ',', 'x', ',', 'y', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "meanComparisonStars , meanComparisonStarErrors = data . calcMeanComparison_multirad ( ccdGain = data . ccdGain ) \n"
Original    (015): ['meanComparisonStars', ',', 'meanComparisonStarErrors', '=', 'data', '.', 'calcMeanComparison_multirad', '(', 'ccdGain', '=', 'data', '.', 'ccdGain', ')', '\\n']
Tokenized   (044): ['[CLS]', 'mean', '##com', '##par', '##ison', '##star', '##s', ',', 'mean', '##com', '##par', '##ison', '##star', '##er', '##ror', '##s', '=', 'data', '.', 'cal', '##cm', '##ean', '##com', '##par', '##ison', '_', 'multi', '##rad', '(', 'cc', '##d', '##gai', '##n', '=', 'data', '.', 'cc', '##d', '##gai', '##n', ')', '\\', 'n', '[SEP]']
Filtered   (042): ['mean', '##com', '##par', '##ison', '##star', '##s', ',', 'mean', '##com', '##par', '##ison', '##star', '##er', '##ror', '##s', '=', 'data', '.', 'cal', '##cm', '##ean', '##com', '##par', '##ison', '_', 'multi', '##rad', '(', 'cc', '##d', '##gai', '##n', '=', 'data', '.', 'cc', '##d', '##gai', '##n', ')', '\\', 'n']
Detokenized (015): ['mean##com##par##ison##star##s', ',', 'mean##com##par##ison##star##er##ror##s', '=', 'data', '.', 'cal##cm##ean##com##par##ison_multi##rad', '(', 'cc##d##gai##n', '=', 'data', '.', 'cc##d##gai##n', ')', '\\n']
Counter: 42
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "lightCurves , lightCurveErrors = data . computeLightCurve_multirad ( meanComparisonStars , \n"
Original    (011): ['lightCurves', ',', 'lightCurveErrors', '=', 'data', '.', 'computeLightCurve_multirad', '(', 'meanComparisonStars', ',', '\\n']
Tokenized   (035): ['[CLS]', 'light', '##cu', '##r', '##ves', ',', 'light', '##cu', '##r', '##ve', '##er', '##ror', '##s', '=', 'data', '.', 'compute', '##light', '##cu', '##r', '##ve', '_', 'multi', '##rad', '(', 'mean', '##com', '##par', '##ison', '##star', '##s', ',', '\\', 'n', '[SEP]']
Filtered   (033): ['light', '##cu', '##r', '##ves', ',', 'light', '##cu', '##r', '##ve', '##er', '##ror', '##s', '=', 'data', '.', 'compute', '##light', '##cu', '##r', '##ve', '_', 'multi', '##rad', '(', 'mean', '##com', '##par', '##ison', '##star', '##s', ',', '\\', 'n']
Detokenized (011): ['light##cu##r##ves', ',', 'light##cu##r##ve##er##ror##s', '=', 'data', '.', 'compute##light##cu##r##ve_multi##rad', '(', 'mean##com##par##ison##star##s', ',', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "json_data = self . _send_request ( , url , params = params ) \n"
Original    (014): ['json_data', '=', 'self', '.', '_send_request', '(', ',', 'url', ',', 'params', '=', 'params', ')', '\\n']
Tokenized   (026): ['[CLS]', 'j', '##son', '_', 'data', '=', 'self', '.', '_', 'send', '_', 'request', '(', ',', 'ur', '##l', ',', 'para', '##ms', '=', 'para', '##ms', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['j', '##son', '_', 'data', '=', 'self', '.', '_', 'send', '_', 'request', '(', ',', 'ur', '##l', ',', 'para', '##ms', '=', 'para', '##ms', ')', '\\', 'n']
Detokenized (014): ['j##son_data', '=', 'self', '.', '_send_request', '(', ',', 'ur##l', ',', 'para##ms', '=', 'para##ms', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "mkdir ( env . hosts_data . log_path ( ) ) \n"
Original    (011): ['mkdir', '(', 'env', '.', 'hosts_data', '.', 'log_path', '(', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'mk', '##di', '##r', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'log', '_', 'path', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['mk', '##di', '##r', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'log', '_', 'path', '(', ')', ')', '\\', 'n']
Detokenized (011): ['mk##di##r', '(', 'en##v', '.', 'hosts_data', '.', 'log_path', '(', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "StringIO ( env . hosts_data . celery_supervisor_config ( ) ) , \n"
Original    (012): ['StringIO', '(', 'env', '.', 'hosts_data', '.', 'celery_supervisor_config', '(', ')', ')', ',', '\\n']
Tokenized   (027): ['[CLS]', 'string', '##io', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'ce', '##ler', '##y', '_', 'supervisor', '_', 'con', '##fi', '##g', '(', ')', ')', ',', '\\', 'n', '[SEP]']
Filtered   (025): ['string', '##io', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'ce', '##ler', '##y', '_', 'supervisor', '_', 'con', '##fi', '##g', '(', ')', ')', ',', '\\', 'n']
Detokenized (012): ['string##io', '(', 'en##v', '.', 'hosts_data', '.', 'ce##ler##y_supervisor_con##fi##g', '(', ')', ')', ',', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "env . hosts_data . celery_supervisor_config_path ( ) , \n"
Original    (009): ['env', '.', 'hosts_data', '.', 'celery_supervisor_config_path', '(', ')', ',', '\\n']
Tokenized   (025): ['[CLS]', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'ce', '##ler', '##y', '_', 'supervisor', '_', 'con', '##fi', '##g', '_', 'path', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['en', '##v', '.', 'hosts', '_', 'data', '.', 'ce', '##ler', '##y', '_', 'supervisor', '_', 'con', '##fi', '##g', '_', 'path', '(', ')', ',', '\\', 'n']
Detokenized (009): ['en##v', '.', 'hosts_data', '.', 'ce##ler##y_supervisor_con##fi##g_path', '(', ')', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rmdir ( env . hosts_data . celery_supervisor_config_path ( ) , sudo_access = True ) \n"
Original    (015): ['rmdir', '(', 'env', '.', 'hosts_data', '.', 'celery_supervisor_config_path', '(', ')', ',', 'sudo_access', '=', 'True', ')', '\\n']
Tokenized   (036): ['[CLS]', 'rm', '##di', '##r', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'ce', '##ler', '##y', '_', 'supervisor', '_', 'con', '##fi', '##g', '_', 'path', '(', ')', ',', 'sud', '##o', '_', 'access', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['rm', '##di', '##r', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'ce', '##ler', '##y', '_', 'supervisor', '_', 'con', '##fi', '##g', '_', 'path', '(', ')', ',', 'sud', '##o', '_', 'access', '=', 'true', ')', '\\', 'n']
Detokenized (015): ['rm##di##r', '(', 'en##v', '.', 'hosts_data', '.', 'ce##ler##y_supervisor_con##fi##g_path', '(', ')', ',', 'sud##o_access', '=', 'true', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "sudo ( . format ( env . hosts_data . application_name ( ) ) ) \n"
Original    (015): ['sudo', '(', '.', 'format', '(', 'env', '.', 'hosts_data', '.', 'application_name', '(', ')', ')', ')', '\\n']
Tokenized   (024): ['[CLS]', 'sud', '##o', '(', '.', 'format', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'application', '_', 'name', '(', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['sud', '##o', '(', '.', 'format', '(', 'en', '##v', '.', 'hosts', '_', 'data', '.', 'application', '_', 'name', '(', ')', ')', ')', '\\', 'n']
Detokenized (015): ['sud##o', '(', '.', 'format', '(', 'en##v', '.', 'hosts_data', '.', 'application_name', '(', ')', ')', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "collection_response = SharedCollectionResponse ( json . loads ( self . send ( ) . content ) ) \n"
Original    (018): ['collection_response', '=', 'SharedCollectionResponse', '(', 'json', '.', 'loads', '(', 'self', '.', 'send', '(', ')', '.', 'content', ')', ')', '\\n']
Tokenized   (029): ['[CLS]', 'collection', '_', 'response', '=', 'shared', '##coll', '##ection', '##res', '##pon', '##se', '(', 'j', '##son', '.', 'loads', '(', 'self', '.', 'send', '(', ')', '.', 'content', ')', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['collection', '_', 'response', '=', 'shared', '##coll', '##ection', '##res', '##pon', '##se', '(', 'j', '##son', '.', 'loads', '(', 'self', '.', 'send', '(', ')', '.', 'content', ')', ')', '\\', 'n']
Detokenized (018): ['collection_response', '=', 'shared##coll##ection##res##pon##se', '(', 'j##son', '.', 'loads', '(', 'self', '.', 'send', '(', ')', '.', 'content', ')', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "libraries = [ "sodium" ] , \n"
Original    (007): ['libraries', '=', '[', '"sodium"', ']', ',', '\\n']
Tokenized   (012): ['[CLS]', 'libraries', '=', '[', '"', 'sodium', '"', ']', ',', '\\', 'n', '[SEP]']
Filtered   (010): ['libraries', '=', '[', '"', 'sodium', '"', ']', ',', '\\', 'n']
Detokenized (007): ['libraries', '=', '[', '"sodium"', ']', ',', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "number = 2 , type = 12 , cpp_type = 9 , label = 2 , \n"
Original    (017): ['number', '=', '2', ',', 'type', '=', '12', ',', 'cpp_type', '=', '9', ',', 'label', '=', '2', ',', '\\n']
Tokenized   (023): ['[CLS]', 'number', '=', '2', ',', 'type', '=', '12', ',', 'cp', '##p', '_', 'type', '=', '9', ',', 'label', '=', '2', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['number', '=', '2', ',', 'type', '=', '12', ',', 'cp', '##p', '_', 'type', '=', '9', ',', 'label', '=', '2', ',', '\\', 'n']
Detokenized (017): ['number', '=', '2', ',', 'type', '=', '12', ',', 'cp##p_type', '=', '9', ',', 'label', '=', '2', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "has_default_value = False , default_value = _b ( "" ) , \n"
Original    (012): ['has_default_value', '=', 'False', ',', 'default_value', '=', '_b', '(', '""', ')', ',', '\\n']
Tokenized   (023): ['[CLS]', 'has', '_', 'default', '_', 'value', '=', 'false', ',', 'default', '_', 'value', '=', '_', 'b', '(', '"', '"', ')', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['has', '_', 'default', '_', 'value', '=', 'false', ',', 'default', '_', 'value', '=', '_', 'b', '(', '"', '"', ')', ',', '\\', 'n']
Detokenized (012): ['has_default_value', '=', 'false', ',', 'default_value', '=', '_b', '(', '""', ')', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "PeerSeeds = _reflection . GeneratedProtocolMessageType ( , ( _message . Message , ) , dict ( \n"
Original    (017): ['PeerSeeds', '=', '_reflection', '.', 'GeneratedProtocolMessageType', '(', ',', '(', '_message', '.', 'Message', ',', ')', ',', 'dict', '(', '\\n']
Tokenized   (032): ['[CLS]', 'peers', '##eed', '##s', '=', '_', 'reflection', '.', 'generated', '##pro', '##to', '##col', '##mes', '##sa', '##get', '##ype', '(', ',', '(', '_', 'message', '.', 'message', ',', ')', ',', 'di', '##ct', '(', '\\', 'n', '[SEP]']
Filtered   (030): ['peers', '##eed', '##s', '=', '_', 'reflection', '.', 'generated', '##pro', '##to', '##col', '##mes', '##sa', '##get', '##ype', '(', ',', '(', '_', 'message', '.', 'message', ',', ')', ',', 'di', '##ct', '(', '\\', 'n']
Detokenized (017): ['peers##eed##s', '=', '_reflection', '.', 'generated##pro##to##col##mes##sa##get##ype', '(', ',', '(', '_message', '.', 'message', ',', ')', ',', 'di##ct', '(', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "__module__ = \n"
Original    (003): ['__module__', '=', '\\n']
Tokenized   (010): ['[CLS]', '_', '_', 'module', '_', '_', '=', '\\', 'n', '[SEP]']
Filtered   (008): ['_', '_', 'module', '_', '_', '=', '\\', 'n']
Detokenized (003): ['__module__', '=', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "tstream = BytearrayStream ( istream . read ( self . length ) ) \n"
Original    (014): ['tstream', '=', 'BytearrayStream', '(', 'istream', '.', 'read', '(', 'self', '.', 'length', ')', ')', '\\n']
Tokenized   (023): ['[CLS]', 'ts', '##tream', '=', 'byte', '##ar', '##ray', '##stream', '(', 'ist', '##rea', '##m', '.', 'read', '(', 'self', '.', 'length', ')', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['ts', '##tream', '=', 'byte', '##ar', '##ray', '##stream', '(', 'ist', '##rea', '##m', '.', 'read', '(', 'self', '.', 'length', ')', ')', '\\', 'n']
Detokenized (014): ['ts##tream', '=', 'byte##ar##ray##stream', '(', 'ist##rea##m', '.', 'read', '(', 'self', '.', 'length', ')', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "opts , args = parser . parse_args ( sys . argv [ 1 : ] ) \n"
Original    (017): ['opts', ',', 'args', '=', 'parser', '.', 'parse_args', '(', 'sys', '.', 'argv', '[', '1', ':', ']', ')', '\\n']
Tokenized   (030): ['[CLS]', 'opt', '##s', ',', 'ar', '##gs', '=', 'par', '##ser', '.', 'par', '##se', '_', 'ar', '##gs', '(', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '1', ':', ']', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['opt', '##s', ',', 'ar', '##gs', '=', 'par', '##ser', '.', 'par', '##se', '_', 'ar', '##gs', '(', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '1', ':', ']', ')', '\\', 'n']
Detokenized (017): ['opt##s', ',', 'ar##gs', '=', 'par##ser', '.', 'par##se_ar##gs', '(', 'sy##s', '.', 'ar##g##v', '[', '1', ':', ']', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : ""{0}" . format ( uid ) ) \n"
Original    (008): ['"{0}"', '.', 'format', '(', 'uid', ')', ')', '\\n']
Tokenized   (016): ['[CLS]', '"', '{', '0', '}', '"', '.', 'format', '(', 'ui', '##d', ')', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['"', '{', '0', '}', '"', '.', 'format', '(', 'ui', '##d', ')', ')', '\\', 'n']
Detokenized (008): ['"{0}"', '.', 'format', '(', 'ui##d', ')', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""located." . format ( path ) \n"
Original    (007): ['"located."', '.', 'format', '(', 'path', ')', '\\n']
Tokenized   (013): ['[CLS]', '"', 'located', '.', '"', '.', 'format', '(', 'path', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['"', 'located', '.', '"', '.', 'format', '(', 'path', ')', '\\', 'n']
Detokenized (007): ['"located."', '.', 'format', '(', 'path', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "discover_versions . DiscoverVersionsResponsePayload , ** kwargs ) \n"
Original    (008): ['discover_versions', '.', 'DiscoverVersionsResponsePayload', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (025): ['[CLS]', 'discover', '_', 'versions', '.', 'discover', '##version', '##sr', '##es', '##pon', '##se', '##pa', '##yl', '##oa', '##d', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['discover', '_', 'versions', '.', 'discover', '##version', '##sr', '##es', '##pon', '##se', '##pa', '##yl', '##oa', '##d', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n']
Detokenized (008): ['discover_versions', '.', 'discover##version##sr##es##pon##se##pa##yl##oa##d', ',', '**', 'kw##ar##gs', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sqltypes . Base . metadata . create_all ( self . engine ) \n"
Original    (013): ['sqltypes', '.', 'Base', '.', 'metadata', '.', 'create_all', '(', 'self', '.', 'engine', ')', '\\n']
Tokenized   (020): ['[CLS]', 'sql', '##type', '##s', '.', 'base', '.', 'metadata', '.', 'create', '_', 'all', '(', 'self', '.', 'engine', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['sql', '##type', '##s', '.', 'base', '.', 'metadata', '.', 'create', '_', 'all', '(', 'self', '.', 'engine', ')', '\\', 'n']
Detokenized (013): ['sql##type##s', '.', 'base', '.', 'metadata', '.', 'create_all', '(', 'self', '.', 'engine', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "enums . OpaqueDataType . NONE , \n"
Original    (007): ['enums', '.', 'OpaqueDataType', '.', 'NONE', ',', '\\n']
Tokenized   (014): ['[CLS]', 'en', '##ums', '.', 'opaque', '##da', '##tat', '##ype', '.', 'none', ',', '\\', 'n', '[SEP]']
Filtered   (012): ['en', '##ums', '.', 'opaque', '##da', '##tat', '##ype', '.', 'none', ',', '\\', 'n']
Detokenized (007): ['en##ums', '.', 'opaque##da##tat##ype', '.', 'none', ',', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "binascii . hexlify ( self . bytes_a ) , enums . OpaqueDataType . NONE ) \n"
Original    (016): ['binascii', '.', 'hexlify', '(', 'self', '.', 'bytes_a', ')', ',', 'enums', '.', 'OpaqueDataType', '.', 'NONE', ')', '\\n']
Tokenized   (031): ['[CLS]', 'bin', '##as', '##ci', '##i', '.', 'he', '##x', '##li', '##fy', '(', 'self', '.', 'bytes', '_', 'a', ')', ',', 'en', '##ums', '.', 'opaque', '##da', '##tat', '##ype', '.', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['bin', '##as', '##ci', '##i', '.', 'he', '##x', '##li', '##fy', '(', 'self', '.', 'bytes', '_', 'a', ')', ',', 'en', '##ums', '.', 'opaque', '##da', '##tat', '##ype', '.', 'none', ')', '\\', 'n']
Detokenized (016): ['bin##as##ci##i', '.', 'he##x##li##fy', '(', 'self', '.', 'bytes_a', ')', ',', 'en##ums', '.', 'opaque##da##tat##ype', '.', 'none', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "Session = sessionmaker ( bind = self . engine ) \n"
Original    (011): ['Session', '=', 'sessionmaker', '(', 'bind', '=', 'self', '.', 'engine', ')', '\\n']
Tokenized   (015): ['[CLS]', 'session', '=', 'session', '##maker', '(', 'bind', '=', 'self', '.', 'engine', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['session', '=', 'session', '##maker', '(', 'bind', '=', 'self', '.', 'engine', ')', '\\', 'n']
Detokenized (011): ['session', '=', 'session##maker', '(', 'bind', '=', 'self', '.', 'engine', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "get_obj = session . query ( OpaqueObject ) . filter ( \n"
Original    (012): ['get_obj', '=', 'session', '.', 'query', '(', 'OpaqueObject', ')', '.', 'filter', '(', '\\n']
Tokenized   (020): ['[CLS]', 'get', '_', 'ob', '##j', '=', 'session', '.', 'query', '(', 'opaque', '##ob', '##ject', ')', '.', 'filter', '(', '\\', 'n', '[SEP]']
Filtered   (018): ['get', '_', 'ob', '##j', '=', 'session', '.', 'query', '(', 'opaque', '##ob', '##ject', ')', '.', 'filter', '(', '\\', 'n']
Detokenized (012): ['get_ob##j', '=', 'session', '.', 'query', '(', 'opaque##ob##ject', ')', '.', 'filter', '(', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ManagedObject . unique_identifier == obj . unique_identifier \n"
Original    (008): ['ManagedObject', '.', 'unique_identifier', '==', 'obj', '.', 'unique_identifier', '\\n']
Tokenized   (023): ['[CLS]', 'managed', '##ob', '##ject', '.', 'unique', '_', 'id', '##ent', '##ifier', '=', '=', 'ob', '##j', '.', 'unique', '_', 'id', '##ent', '##ifier', '\\', 'n', '[SEP]']
Filtered   (021): ['managed', '##ob', '##ject', '.', 'unique', '_', 'id', '##ent', '##ifier', '=', '=', 'ob', '##j', '.', 'unique', '_', 'id', '##ent', '##ifier', '\\', 'n']
Detokenized (008): ['managed##ob##ject', '.', 'unique_id##ent##ifier', '==', 'ob##j', '.', 'unique_id##ent##ifier', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "0 ) ) \n"
Original    (004): ['0', ')', ')', '\\n']
Tokenized   (007): ['[CLS]', '0', ')', ')', '\\', 'n', '[SEP]']
Filtered   (005): ['0', ')', ')', '\\', 'n']
Detokenized (004): ['0', ')', ')', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "expected_mo_names . append ( sqltypes . ManagedObjectName ( expected_names [ 1 ] , \n"
Original    (014): ['expected_mo_names', '.', 'append', '(', 'sqltypes', '.', 'ManagedObjectName', '(', 'expected_names', '[', '1', ']', ',', '\\n']
Tokenized   (029): ['[CLS]', 'expected', '_', 'mo', '_', 'names', '.', 'app', '##end', '(', 'sql', '##type', '##s', '.', 'managed', '##ob', '##ject', '##name', '(', 'expected', '_', 'names', '[', '1', ']', ',', '\\', 'n', '[SEP]']
Filtered   (027): ['expected', '_', 'mo', '_', 'names', '.', 'app', '##end', '(', 'sql', '##type', '##s', '.', 'managed', '##ob', '##ject', '##name', '(', 'expected', '_', 'names', '[', '1', ']', ',', '\\', 'n']
Detokenized (014): ['expected_mo_names', '.', 'app##end', '(', 'sql##type##s', '.', 'managed##ob##ject##name', '(', 'expected_names', '[', '1', ']', ',', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "expected_names = [ first_name , added_name ] \n"
Original    (008): ['expected_names', '=', '[', 'first_name', ',', 'added_name', ']', '\\n']
Tokenized   (017): ['[CLS]', 'expected', '_', 'names', '=', '[', 'first', '_', 'name', ',', 'added', '_', 'name', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['expected', '_', 'names', '=', '[', 'first', '_', 'name', ',', 'added', '_', 'name', ']', '\\', 'n']
Detokenized (008): ['expected_names', '=', '[', 'first_name', ',', 'added_name', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "] } , \n"
Original    (004): [']', '}', ',', '\\n']
Tokenized   (007): ['[CLS]', ']', '}', ',', '\\', 'n', '[SEP]']
Filtered   (005): [']', '}', ',', '\\', 'n']
Detokenized (004): [']', '}', ',', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "types . MethodType ( _lib_dir_option , None , MSVCCompiler ) ) \n"
Original    (012): ['types', '.', 'MethodType', '(', '_lib_dir_option', ',', 'None', ',', 'MSVCCompiler', ')', ')', '\\n']
Tokenized   (026): ['[CLS]', 'types', '.', 'method', '##type', '(', '_', 'li', '##b', '_', 'dir', '_', 'option', ',', 'none', ',', 'ms', '##vc', '##com', '##pile', '##r', ')', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['types', '.', 'method', '##type', '(', '_', 'li', '##b', '_', 'dir', '_', 'option', ',', 'none', ',', 'ms', '##vc', '##com', '##pile', '##r', ')', ')', '\\', 'n']
Detokenized (012): ['types', '.', 'method##type', '(', '_li##b_dir_option', ',', 'none', ',', 'ms##vc##com##pile##r', ')', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "setup ( ** kwds ) \n"
Original    (006): ['setup', '(', '**', 'kwds', ')', '\\n']
Tokenized   (011): ['[CLS]', 'setup', '(', '*', '*', 'kw', '##ds', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['setup', '(', '*', '*', 'kw', '##ds', ')', '\\', 'n']
Detokenized (006): ['setup', '(', '**', 'kw##ds', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "intersphinx_mapping = { : None } \n"
Original    (007): ['intersphinx_mapping', '=', '{', ':', 'None', '}', '\\n']
Tokenized   (015): ['[CLS]', 'inter', '##sp', '##hin', '##x', '_', 'mapping', '=', '{', ':', 'none', '}', '\\', 'n', '[SEP]']
Filtered   (013): ['inter', '##sp', '##hin', '##x', '_', 'mapping', '=', '{', ':', 'none', '}', '\\', 'n']
Detokenized (007): ['inter##sp##hin##x_mapping', '=', '{', ':', 'none', '}', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "new_w = int ( width * wrat ) \n"
Original    (009): ['new_w', '=', 'int', '(', 'width', '*', 'wrat', ')', '\\n']
Tokenized   (015): ['[CLS]', 'new', '_', 'w', '=', 'int', '(', 'width', '*', 'wr', '##at', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['new', '_', 'w', '=', 'int', '(', 'width', '*', 'wr', '##at', ')', '\\', 'n']
Detokenized (009): ['new_w', '=', 'int', '(', 'width', '*', 'wr##at', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "im . getbbox ( ) , Image . BICUBIC ) \n"
Original    (011): ['im', '.', 'getbbox', '(', ')', ',', 'Image', '.', 'BICUBIC', ')', '\\n']
Tokenized   (018): ['[CLS]', 'im', '.', 'get', '##bb', '##ox', '(', ')', ',', 'image', '.', 'bi', '##cu', '##bic', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['im', '.', 'get', '##bb', '##ox', '(', ')', ',', 'image', '.', 'bi', '##cu', '##bic', ')', '\\', 'n']
Detokenized (011): ['im', '.', 'get##bb##ox', '(', ')', ',', 'image', '.', 'bi##cu##bic', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "resize_image ( os . path . abspath ( os . path . join ( , dest + ) ) ) \n"
Original    (021): ['resize_image', '(', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'join', '(', ',', 'dest', '+', ')', ')', ')', '\\n']
Tokenized   (029): ['[CLS]', 'res', '##ize', '_', 'image', '(', 'os', '.', 'path', '.', 'abs', '##path', '(', 'os', '.', 'path', '.', 'join', '(', ',', 'des', '##t', '+', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['res', '##ize', '_', 'image', '(', 'os', '.', 'path', '.', 'abs', '##path', '(', 'os', '.', 'path', '.', 'join', '(', ',', 'des', '##t', '+', ')', ')', ')', '\\', 'n']
Detokenized (021): ['res##ize_image', '(', 'os', '.', 'path', '.', 'abs##path', '(', 'os', '.', 'path', '.', 'join', '(', ',', 'des##t', '+', ')', ')', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "f_x = Float ( 0.0 , iotype = "out" ) \n"
Original    (011): ['f_x', '=', 'Float', '(', '0.0', ',', 'iotype', '=', '"out"', ')', '\\n']
Tokenized   (021): ['[CLS]', 'f', '_', 'x', '=', 'float', '(', '0', '.', '0', ',', 'io', '##type', '=', '"', 'out', '"', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['f', '_', 'x', '=', 'float', '(', '0', '.', '0', ',', 'io', '##type', '=', '"', 'out', '"', ')', '\\', 'n']
Detokenized (011): ['f_x', '=', 'float', '(', '0.0', ',', 'io##type', '=', '"out"', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "doe_c = [ 0.1 , 0.2 , 0.3 , 0.5 , 0.7 , 0.8 , 0.9 ] + doe_e \n"
Original    (020): ['doe_c', '=', '[', '0.1', ',', '0.2', ',', '0.3', ',', '0.5', ',', '0.7', ',', '0.8', ',', '0.9', ']', '+', 'doe_e', '\\n']
Tokenized   (041): ['[CLS]', 'doe', '_', 'c', '=', '[', '0', '.', '1', ',', '0', '.', '2', ',', '0', '.', '3', ',', '0', '.', '5', ',', '0', '.', '7', ',', '0', '.', '8', ',', '0', '.', '9', ']', '+', 'doe', '_', 'e', '\\', 'n', '[SEP]']
Filtered   (039): ['doe', '_', 'c', '=', '[', '0', '.', '1', ',', '0', '.', '2', ',', '0', '.', '3', ',', '0', '.', '5', ',', '0', '.', '7', ',', '0', '.', '8', ',', '0', '.', '9', ']', '+', 'doe', '_', 'e', '\\', 'n']
Detokenized (020): ['doe_c', '=', '[', '0.1', ',', '0.2', ',', '0.3', ',', '0.5', ',', '0.7', ',', '0.8', ',', '0.9', ']', '+', 'doe_e', '\\n']
Counter: 39
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "responses = ( , ) , nfi = self . nfi ) ) \n"
Original    (014): ['responses', '=', '(', ',', ')', ',', 'nfi', '=', 'self', '.', 'nfi', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'responses', '=', '(', ',', ')', ',', 'n', '##fi', '=', 'self', '.', 'n', '##fi', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['responses', '=', '(', ',', ')', ',', 'n', '##fi', '=', 'self', '.', 'n', '##fi', ')', ')', '\\', 'n']
Detokenized (014): ['responses', '=', '(', ',', ')', ',', 'n##fi', '=', 'self', '.', 'n##fi', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "sigma_cok = np . array ( [ d . sigma for d in sim_cok . mm_checker . case_outputs . meta_model . f_x ] ) \n"
Original    (025): ['sigma_cok', '=', 'np', '.', 'array', '(', '[', 'd', '.', 'sigma', 'for', 'd', 'in', 'sim_cok', '.', 'mm_checker', '.', 'case_outputs', '.', 'meta_model', '.', 'f_x', ']', ')', '\\n']
Tokenized   (043): ['[CLS]', 'sigma', '_', 'co', '##k', '=', 'np', '.', 'array', '(', '[', 'd', '.', 'sigma', 'for', 'd', 'in', 'sim', '_', 'co', '##k', '.', 'mm', '_', 'check', '##er', '.', 'case', '_', 'outputs', '.', 'meta', '_', 'model', '.', 'f', '_', 'x', ']', ')', '\\', 'n', '[SEP]']
Filtered   (041): ['sigma', '_', 'co', '##k', '=', 'np', '.', 'array', '(', '[', 'd', '.', 'sigma', 'for', 'd', 'in', 'sim', '_', 'co', '##k', '.', 'mm', '_', 'check', '##er', '.', 'case', '_', 'outputs', '.', 'meta', '_', 'model', '.', 'f', '_', 'x', ']', ')', '\\', 'n']
Detokenized (025): ['sigma_co##k', '=', 'np', '.', 'array', '(', '[', 'd', '.', 'sigma', 'for', 'd', 'in', 'sim_co##k', '.', 'mm_check##er', '.', 'case_outputs', '.', 'meta_model', '.', 'f_x', ']', ')', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "actual = sim_k . mm_checker . case_outputs . model . f_x \n"
Original    (012): ['actual', '=', 'sim_k', '.', 'mm_checker', '.', 'case_outputs', '.', 'model', '.', 'f_x', '\\n']
Tokenized   (024): ['[CLS]', 'actual', '=', 'sim', '_', 'k', '.', 'mm', '_', 'check', '##er', '.', 'case', '_', 'outputs', '.', 'model', '.', 'f', '_', 'x', '\\', 'n', '[SEP]']
Filtered   (022): ['actual', '=', 'sim', '_', 'k', '.', 'mm', '_', 'check', '##er', '.', 'case', '_', 'outputs', '.', 'model', '.', 'f', '_', 'x', '\\', 'n']
Detokenized (012): ['actual', '=', 'sim_k', '.', 'mm_check##er', '.', 'case_outputs', '.', 'model', '.', 'f_x', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "predicted_cok - 2 * sigma_cok , facecolor = , alpha = 0.2 ) \n"
Original    (014): ['predicted_cok', '-', '2', '*', 'sigma_cok', ',', 'facecolor', '=', ',', 'alpha', '=', '0.2', ')', '\\n']
Tokenized   (026): ['[CLS]', 'predicted', '_', 'co', '##k', '-', '2', '*', 'sigma', '_', 'co', '##k', ',', 'face', '##color', '=', ',', 'alpha', '=', '0', '.', '2', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['predicted', '_', 'co', '##k', '-', '2', '*', 'sigma', '_', 'co', '##k', ',', 'face', '##color', '=', ',', 'alpha', '=', '0', '.', '2', ')', '\\', 'n']
Detokenized (014): ['predicted_co##k', '-', '2', '*', 'sigma_co##k', ',', 'face##color', '=', ',', 'alpha', '=', '0.2', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "newsetupfile = os . path . join ( os . path . dirname ( setupfile ) , \n"
Original    (018): ['newsetupfile', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dirname', '(', 'setupfile', ')', ',', '\\n']
Tokenized   (028): ['[CLS]', 'news', '##et', '##up', '##fi', '##le', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'setup', '##fi', '##le', ')', ',', '\\', 'n', '[SEP]']
Filtered   (026): ['news', '##et', '##up', '##fi', '##le', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'setup', '##fi', '##le', ')', ',', '\\', 'n']
Detokenized (018): ['news##et##up##fi##le', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dir##name', '(', 'setup##fi##le', ')', ',', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "srcdir = os . path . abspath ( os . path . expanduser ( srcdir ) ) . replace ( , ) \n"
Original    (023): ['srcdir', '=', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'expanduser', '(', 'srcdir', ')', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (032): ['[CLS]', 'sr', '##cd', '##ir', '=', 'os', '.', 'path', '.', 'abs', '##path', '(', 'os', '.', 'path', '.', 'expand', '##user', '(', 'sr', '##cd', '##ir', ')', ')', '.', 'replace', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['sr', '##cd', '##ir', '=', 'os', '.', 'path', '.', 'abs', '##path', '(', 'os', '.', 'path', '.', 'expand', '##user', '(', 'sr', '##cd', '##ir', ')', ')', '.', 'replace', '(', ',', ')', '\\', 'n']
Detokenized (023): ['sr##cd##ir', '=', 'os', '.', 'path', '.', 'abs##path', '(', 'os', '.', 'path', '.', 'expand##user', '(', 'sr##cd##ir', ')', ')', '.', 'replace', '(', ',', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "cmd . extend ( [ , destdir ] ) \n"
Original    (010): ['cmd', '.', 'extend', '(', '[', ',', 'destdir', ']', ')', '\\n']
Tokenized   (017): ['[CLS]', 'cm', '##d', '.', 'extend', '(', '[', ',', 'des', '##t', '##di', '##r', ']', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['cm', '##d', '.', 'extend', '(', '[', ',', 'des', '##t', '##di', '##r', ']', ')', '\\', 'n']
Detokenized (010): ['cm##d', '.', 'extend', '(', '[', ',', 'des##t##di##r', ']', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "list ( newfiles ) ) \n"
Original    (006): ['list', '(', 'newfiles', ')', ')', '\\n']
Tokenized   (011): ['[CLS]', 'list', '(', 'new', '##fi', '##les', ')', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['list', '(', 'new', '##fi', '##les', ')', ')', '\\', 'n']
Detokenized (006): ['list', '(', 'new##fi##les', ')', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "destdir = os . path . abspath ( os . path . expanduser ( options . destdir ) ) \n"
Original    (020): ['destdir', '=', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'expanduser', '(', 'options', '.', 'destdir', ')', ')', '\\n']
Tokenized   (031): ['[CLS]', 'des', '##t', '##di', '##r', '=', 'os', '.', 'path', '.', 'abs', '##path', '(', 'os', '.', 'path', '.', 'expand', '##user', '(', 'options', '.', 'des', '##t', '##di', '##r', ')', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['des', '##t', '##di', '##r', '=', 'os', '.', 'path', '.', 'abs', '##path', '(', 'os', '.', 'path', '.', 'expand', '##user', '(', 'options', '.', 'des', '##t', '##di', '##r', ')', ')', '\\', 'n']
Detokenized (020): ['des##t##di##r', '=', 'os', '.', 'path', '.', 'abs##path', '(', 'os', '.', 'path', '.', 'expand##user', '(', 'options', '.', 'des##t##di##r', ')', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "all_names . extend ( [ prefix + name \n"
Original    (009): ['all_names', '.', 'extend', '(', '[', 'prefix', '+', 'name', '\\n']
Tokenized   (014): ['[CLS]', 'all', '_', 'names', '.', 'extend', '(', '[', 'prefix', '+', 'name', '\\', 'n', '[SEP]']
Filtered   (012): ['all', '_', 'names', '.', 'extend', '(', '[', 'prefix', '+', 'name', '\\', 'n']
Detokenized (009): ['all_names', '.', 'extend', '(', '[', 'prefix', '+', 'name', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "lnames = [ prefix + rec for rec in driver [ ] ] \n"
Original    (014): ['lnames', '=', '[', 'prefix', '+', 'rec', 'for', 'rec', 'in', 'driver', '[', ']', ']', '\\n']
Tokenized   (019): ['[CLS]', 'l', '##name', '##s', '=', '[', 'prefix', '+', 'rec', 'for', 'rec', 'in', 'driver', '[', ']', ']', '\\', 'n', '[SEP]']
Filtered   (017): ['l', '##name', '##s', '=', '[', 'prefix', '+', 'rec', 'for', 'rec', 'in', 'driver', '[', ']', ']', '\\', 'n']
Detokenized (014): ['l##name##s', '=', '[', 'prefix', '+', 'rec', 'for', 'rec', 'in', 'driver', '[', ']', ']', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "driver_grp = self . _inp [ ] [ driver_name ] \n"
Original    (011): ['driver_grp', '=', 'self', '.', '_inp', '[', ']', '[', 'driver_name', ']', '\\n']
Tokenized   (021): ['[CLS]', 'driver', '_', 'gr', '##p', '=', 'self', '.', '_', 'in', '##p', '[', ']', '[', 'driver', '_', 'name', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['driver', '_', 'gr', '##p', '=', 'self', '.', '_', 'in', '##p', '[', ']', '[', 'driver', '_', 'name', ']', '\\', 'n']
Detokenized (011): ['driver_gr##p', '=', 'self', '.', '_in##p', '[', ']', '[', 'driver_name', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "iteration_grp = self . _inp [ ] [ driver_name ] [ iteration_case_name ] \n"
Original    (014): ['iteration_grp', '=', 'self', '.', '_inp', '[', ']', '[', 'driver_name', ']', '[', 'iteration_case_name', ']', '\\n']
Tokenized   (028): ['[CLS]', 'iteration', '_', 'gr', '##p', '=', 'self', '.', '_', 'in', '##p', '[', ']', '[', 'driver', '_', 'name', ']', '[', 'iteration', '_', 'case', '_', 'name', ']', '\\', 'n', '[SEP]']
Filtered   (026): ['iteration', '_', 'gr', '##p', '=', 'self', '.', '_', 'in', '##p', '[', ']', '[', 'driver', '_', 'name', ']', '[', 'iteration', '_', 'case', '_', 'name', ']', '\\', 'n']
Detokenized (014): ['iteration_gr##p', '=', 'self', '.', '_in##p', '[', ']', '[', 'driver_name', ']', '[', 'iteration_case_name', ']', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "info = self . read_iteration_case_from_hdf5 ( self . _inp , driver_name , iteration_case_name ) yield info \n"
Original    (017): ['info', '=', 'self', '.', 'read_iteration_case_from_hdf5', '(', 'self', '.', '_inp', ',', 'driver_name', ',', 'iteration_case_name', ')', 'yield', 'info', '\\n']
Tokenized   (038): ['[CLS]', 'info', '=', 'self', '.', 'read', '_', 'iteration', '_', 'case', '_', 'from', '_', 'hd', '##f', '##5', '(', 'self', '.', '_', 'in', '##p', ',', 'driver', '_', 'name', ',', 'iteration', '_', 'case', '_', 'name', ')', 'yield', 'info', '\\', 'n', '[SEP]']
Filtered   (036): ['info', '=', 'self', '.', 'read', '_', 'iteration', '_', 'case', '_', 'from', '_', 'hd', '##f', '##5', '(', 'self', '.', '_', 'in', '##p', ',', 'driver', '_', 'name', ',', 'iteration', '_', 'case', '_', 'name', ')', 'yield', 'info', '\\', 'n']
Detokenized (017): ['info', '=', 'self', '.', 'read_iteration_case_from_hd##f##5', '(', 'self', '.', '_in##p', ',', 'driver_name', ',', 'iteration_case_name', ')', 'yield', 'info', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sleep_time = Float ( 0.0 , iotype = , desc = ) \n"
Original    (013): ['sleep_time', '=', 'Float', '(', '0.0', ',', 'iotype', '=', ',', 'desc', '=', ')', '\\n']
Tokenized   (022): ['[CLS]', 'sleep', '_', 'time', '=', 'float', '(', '0', '.', '0', ',', 'io', '##type', '=', ',', 'des', '##c', '=', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['sleep', '_', 'time', '=', 'float', '(', '0', '.', '0', ',', 'io', '##type', '=', ',', 'des', '##c', '=', ')', '\\', 'n']
Detokenized (013): ['sleep_time', '=', 'float', '(', '0.0', ',', 'io##type', '=', ',', 'des##c', '=', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "accuracy = Float ( 1.0e-6 , iotype = , \n"
Original    (010): ['accuracy', '=', 'Float', '(', '1.0e-6', ',', 'iotype', '=', ',', '\\n']
Tokenized   (019): ['[CLS]', 'accuracy', '=', 'float', '(', '1', '.', '0', '##e', '-', '6', ',', 'io', '##type', '=', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['accuracy', '=', 'float', '(', '1', '.', '0', '##e', '-', '6', ',', 'io', '##type', '=', ',', '\\', 'n']
Detokenized (010): ['accuracy', '=', 'float', '(', '1.0##e-6', ',', 'io##type', '=', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "iprint = Enum ( 0 , [ 0 , 1 , 2 , 3 ] , iotype = , \n"
Original    (020): ['iprint', '=', 'Enum', '(', '0', ',', '[', '0', ',', '1', ',', '2', ',', '3', ']', ',', 'iotype', '=', ',', '\\n']
Tokenized   (027): ['[CLS]', 'ip', '##rin', '##t', '=', 'en', '##um', '(', '0', ',', '[', '0', ',', '1', ',', '2', ',', '3', ']', ',', 'io', '##type', '=', ',', '\\', 'n', '[SEP]']
Filtered   (025): ['ip', '##rin', '##t', '=', 'en', '##um', '(', '0', ',', '[', '0', ',', '1', ',', '2', ',', '3', ']', ',', 'io', '##type', '=', ',', '\\', 'n']
Detokenized (020): ['ip##rin##t', '=', 'en##um', '(', '0', ',', '[', '0', ',', '1', ',', '2', ',', '3', ']', ',', 'io##type', '=', ',', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "output_filename = Str ( , iotype = , \n"
Original    (009): ['output_filename', '=', 'Str', '(', ',', 'iotype', '=', ',', '\\n']
Tokenized   (017): ['[CLS]', 'output', '_', 'file', '##name', '=', 'st', '##r', '(', ',', 'io', '##type', '=', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['output', '_', 'file', '##name', '=', 'st', '##r', '(', ',', 'io', '##type', '=', ',', '\\', 'n']
Detokenized (009): ['output_file##name', '=', 'st##r', '(', ',', 'io##type', '=', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "la = max ( m , 1 ) \n"
Original    (009): ['la', '=', 'max', '(', 'm', ',', '1', ')', '\\n']
Tokenized   (012): ['[CLS]', 'la', '=', 'max', '(', 'm', ',', '1', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['la', '=', 'max', '(', 'm', ',', '1', ')', '\\', 'n']
Detokenized (009): ['la', '=', 'max', '(', 'm', ',', '1', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "gg = zeros ( [ la ] , ) \n"
Original    (010): ['gg', '=', 'zeros', '(', '[', 'la', ']', ',', ')', '\\n']
Tokenized   (015): ['[CLS]', 'g', '##g', '=', 'zero', '##s', '(', '[', 'la', ']', ',', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['g', '##g', '=', 'zero', '##s', '(', '[', 'la', ']', ',', ')', '\\', 'n']
Detokenized (010): ['g##g', '=', 'zero##s', '(', '[', 'la', ']', ',', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "dg = zeros ( [ la , n + 1 ] , ) \n"
Original    (014): ['dg', '=', 'zeros', '(', '[', 'la', ',', 'n', '+', '1', ']', ',', ')', '\\n']
Tokenized   (019): ['[CLS]', 'd', '##g', '=', 'zero', '##s', '(', '[', 'la', ',', 'n', '+', '1', ']', ',', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['d', '##g', '=', 'zero', '##s', '(', '[', 'la', ',', 'n', '+', '1', ']', ',', ')', '\\', 'n']
Detokenized (014): ['d##g', '=', 'zero##s', '(', '[', 'la', ',', 'n', '+', '1', ']', ',', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "mineq = m - meq + 2 * ( n + 1 ) \n"
Original    (014): ['mineq', '=', 'm', '-', 'meq', '+', '2', '*', '(', 'n', '+', '1', ')', '\\n']
Tokenized   (019): ['[CLS]', 'mine', '##q', '=', 'm', '-', 'me', '##q', '+', '2', '*', '(', 'n', '+', '1', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['mine', '##q', '=', 'm', '-', 'me', '##q', '+', '2', '*', '(', 'n', '+', '1', ')', '\\', 'n']
Detokenized (014): ['mine##q', '=', 'm', '-', 'me##q', '+', '2', '*', '(', 'n', '+', '1', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "lsq = ( n + 1 ) * ( ( n + 1 ) + 1 ) + meq * ( ( n + 1 ) + 1 ) + mineq * ( ( n + 1 ) + 1 ) \n"
Original    (042): ['lsq', '=', '(', 'n', '+', '1', ')', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'meq', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'mineq', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '\\n']
Tokenized   (049): ['[CLS]', 'l', '##s', '##q', '=', '(', 'n', '+', '1', ')', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'me', '##q', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'mine', '##q', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '\\', 'n', '[SEP]']
Filtered   (047): ['l', '##s', '##q', '=', '(', 'n', '+', '1', ')', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'me', '##q', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'mine', '##q', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '\\', 'n']
Detokenized (042): ['l##s##q', '=', '(', 'n', '+', '1', ')', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'me##q', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'mine##q', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '\\n']
Counter: 47
===================================================================
Hidden states:  (13, 42, 768)
# Extracted words:  42
Sentence         : "lsi = ( ( n + 1 ) - meq + 1 ) * ( mineq + 2 ) + 2 * mineq \n"
Original    (024): ['lsi', '=', '(', '(', 'n', '+', '1', ')', '-', 'meq', '+', '1', ')', '*', '(', 'mineq', '+', '2', ')', '+', '2', '*', 'mineq', '\\n']
Tokenized   (031): ['[CLS]', 'l', '##si', '=', '(', '(', 'n', '+', '1', ')', '-', 'me', '##q', '+', '1', ')', '*', '(', 'mine', '##q', '+', '2', ')', '+', '2', '*', 'mine', '##q', '\\', 'n', '[SEP]']
Filtered   (029): ['l', '##si', '=', '(', '(', 'n', '+', '1', ')', '-', 'me', '##q', '+', '1', ')', '*', '(', 'mine', '##q', '+', '2', ')', '+', '2', '*', 'mine', '##q', '\\', 'n']
Detokenized (024): ['l##si', '=', '(', '(', 'n', '+', '1', ')', '-', 'me##q', '+', '1', ')', '*', '(', 'mine##q', '+', '2', ')', '+', '2', '*', 'mine##q', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "lsei = ( ( n + 1 ) + mineq ) * ( ( n + 1 ) - meq ) + 2 * meq + ( n + 1 ) \n"
Original    (032): ['lsei', '=', '(', '(', 'n', '+', '1', ')', '+', 'mineq', ')', '*', '(', '(', 'n', '+', '1', ')', '-', 'meq', ')', '+', '2', '*', 'meq', '+', '(', 'n', '+', '1', ')', '\\n']
Tokenized   (039): ['[CLS]', 'l', '##sei', '=', '(', '(', 'n', '+', '1', ')', '+', 'mine', '##q', ')', '*', '(', '(', 'n', '+', '1', ')', '-', 'me', '##q', ')', '+', '2', '*', 'me', '##q', '+', '(', 'n', '+', '1', ')', '\\', 'n', '[SEP]']
Filtered   (037): ['l', '##sei', '=', '(', '(', 'n', '+', '1', ')', '+', 'mine', '##q', ')', '*', '(', '(', 'n', '+', '1', ')', '-', 'me', '##q', ')', '+', '2', '*', 'me', '##q', '+', '(', 'n', '+', '1', ')', '\\', 'n']
Detokenized (032): ['l##sei', '=', '(', '(', 'n', '+', '1', ')', '+', 'mine##q', ')', '*', '(', '(', 'n', '+', '1', ')', '-', 'me##q', ')', '+', '2', '*', 'me##q', '+', '(', 'n', '+', '1', ')', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "slsqpb = ( n + 1 ) * ( n / 2 ) + 2 * m + 3 * n + 3 * ( n + 1 ) + 1 \n"
Original    (032): ['slsqpb', '=', '(', 'n', '+', '1', ')', '*', '(', 'n', '/', '2', ')', '+', '2', '*', 'm', '+', '3', '*', 'n', '+', '3', '*', '(', 'n', '+', '1', ')', '+', '1', '\\n']
Tokenized   (039): ['[CLS]', 'sl', '##s', '##q', '##p', '##b', '=', '(', 'n', '+', '1', ')', '*', '(', 'n', '/', '2', ')', '+', '2', '*', 'm', '+', '3', '*', 'n', '+', '3', '*', '(', 'n', '+', '1', ')', '+', '1', '\\', 'n', '[SEP]']
Filtered   (037): ['sl', '##s', '##q', '##p', '##b', '=', '(', 'n', '+', '1', ')', '*', '(', 'n', '/', '2', ')', '+', '2', '*', 'm', '+', '3', '*', 'n', '+', '3', '*', '(', 'n', '+', '1', ')', '+', '1', '\\', 'n']
Detokenized (032): ['sl##s##q##p##b', '=', '(', 'n', '+', '1', ')', '*', '(', 'n', '/', '2', ')', '+', '2', '*', 'm', '+', '3', '*', 'n', '+', '3', '*', '(', 'n', '+', '1', ')', '+', '1', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "lw = lsq + lsi + lsei + slsqpb + n + m \n"
Original    (014): ['lw', '=', 'lsq', '+', 'lsi', '+', 'lsei', '+', 'slsqpb', '+', 'n', '+', 'm', '\\n']
Tokenized   (026): ['[CLS]', 'l', '##w', '=', 'l', '##s', '##q', '+', 'l', '##si', '+', 'l', '##sei', '+', 'sl', '##s', '##q', '##p', '##b', '+', 'n', '+', 'm', '\\', 'n', '[SEP]']
Filtered   (024): ['l', '##w', '=', 'l', '##s', '##q', '+', 'l', '##si', '+', 'l', '##sei', '+', 'sl', '##s', '##q', '##p', '##b', '+', 'n', '+', 'm', '\\', 'n']
Detokenized (014): ['l##w', '=', 'l##s##q', '+', 'l##si', '+', 'l##sei', '+', 'sl##s##q##p##b', '+', 'n', '+', 'm', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "ljw = max ( mineq , ( n + 1 ) - meq ) \n"
Original    (015): ['ljw', '=', 'max', '(', 'mineq', ',', '(', 'n', '+', '1', ')', '-', 'meq', ')', '\\n']
Tokenized   (022): ['[CLS]', 'l', '##j', '##w', '=', 'max', '(', 'mine', '##q', ',', '(', 'n', '+', '1', ')', '-', 'me', '##q', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['l', '##j', '##w', '=', 'max', '(', 'mine', '##q', ',', '(', 'n', '+', '1', ')', '-', 'me', '##q', ')', '\\', 'n']
Detokenized (015): ['l##j##w', '=', 'max', '(', 'mine##q', ',', '(', 'n', '+', '1', ')', '-', 'me##q', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "_iodict = { : , : } \n"
Original    (008): ['_iodict', '=', '{', ':', ',', ':', '}', '\\n']
Tokenized   (013): ['[CLS]', '_', 'io', '##dict', '=', '{', ':', ',', ':', '}', '\\', 'n', '[SEP]']
Filtered   (011): ['_', 'io', '##dict', '=', '{', ':', ',', ':', '}', '\\', 'n']
Detokenized (008): ['_io##dict', '=', '{', ':', ',', ':', '}', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "state [ ] = { } \n"
Original    (007): ['state', '[', ']', '=', '{', '}', '\\n']
Tokenized   (010): ['[CLS]', 'state', '[', ']', '=', '{', '}', '\\', 'n', '[SEP]']
Filtered   (008): ['state', '[', ']', '=', '{', '}', '\\', 'n']
Detokenized (007): ['state', '[', ']', '=', '{', '}', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "key = ( addr_type , addr , proxy . _authkey ) \n"
Original    (012): ['key', '=', '(', 'addr_type', ',', 'addr', ',', 'proxy', '.', '_authkey', ')', '\\n']
Tokenized   (022): ['[CLS]', 'key', '=', '(', 'add', '##r', '_', 'type', ',', 'add', '##r', ',', 'proxy', '.', '_', 'au', '##th', '##key', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['key', '=', '(', 'add', '##r', '_', 'type', ',', 'add', '##r', ',', 'proxy', '.', '_', 'au', '##th', '##key', ')', '\\', 'n']
Detokenized (012): ['key', '=', '(', 'add##r_type', ',', 'add##r', ',', 'proxy', '.', '_au##th##key', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "address = ( ip_addr , 0 ) \n"
Original    (008): ['address', '=', '(', 'ip_addr', ',', '0', ')', '\\n']
Tokenized   (014): ['[CLS]', 'address', '=', '(', 'ip', '_', 'add', '##r', ',', '0', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['address', '=', '(', 'ip', '_', 'add', '##r', ',', '0', ')', '\\', 'n']
Detokenized (008): ['address', '=', '(', 'ip_add##r', ',', '0', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "access = addr if addr_type == else addr_type \n"
Original    (009): ['access', '=', 'addr', 'if', 'addr_type', '==', 'else', 'addr_type', '\\n']
Tokenized   (020): ['[CLS]', 'access', '=', 'add', '##r', 'if', 'add', '##r', '_', 'type', '=', '=', 'else', 'add', '##r', '_', 'type', '\\', 'n', '[SEP]']
Filtered   (018): ['access', '=', 'add', '##r', 'if', 'add', '##r', '_', 'type', '=', '=', 'else', 'add', '##r', '_', 'type', '\\', 'n']
Detokenized (009): ['access', '=', 'add##r', 'if', 'add##r_type', '==', 'else', 'add##r_type', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "manager = ObjectManager ( self , address , authkey = proxy . _authkey , \n"
Original    (015): ['manager', '=', 'ObjectManager', '(', 'self', ',', 'address', ',', 'authkey', '=', 'proxy', '.', '_authkey', ',', '\\n']
Tokenized   (025): ['[CLS]', 'manager', '=', 'object', '##mana', '##ger', '(', 'self', ',', 'address', ',', 'au', '##th', '##key', '=', 'proxy', '.', '_', 'au', '##th', '##key', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['manager', '=', 'object', '##mana', '##ger', '(', 'self', ',', 'address', ',', 'au', '##th', '##key', '=', 'proxy', '.', '_', 'au', '##th', '##key', ',', '\\', 'n']
Detokenized (015): ['manager', '=', 'object##mana##ger', '(', 'self', ',', 'address', ',', 'au##th##key', '=', 'proxy', '.', '_au##th##key', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "match_dict = self . _alltraits ( ** metadata ) \n"
Original    (010): ['match_dict', '=', 'self', '.', '_alltraits', '(', '**', 'metadata', ')', '\\n']
Tokenized   (020): ['[CLS]', 'match', '_', 'di', '##ct', '=', 'self', '.', '_', 'all', '##tra', '##its', '(', '*', '*', 'metadata', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['match', '_', 'di', '##ct', '=', 'self', '.', '_', 'all', '##tra', '##its', '(', '*', '*', 'metadata', ')', '\\', 'n']
Detokenized (010): ['match_di##ct', '=', 'self', '.', '_all##tra##its', '(', '**', 'metadata', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "childname , _ , restofpath = traitpath . partition ( ) \n"
Original    (012): ['childname', ',', '_', ',', 'restofpath', '=', 'traitpath', '.', 'partition', '(', ')', '\\n']
Tokenized   (019): ['[CLS]', 'child', '##name', ',', '_', ',', 'rest', '##of', '##path', '=', 'trait', '##path', '.', 'partition', '(', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['child', '##name', ',', '_', ',', 'rest', '##of', '##path', '=', 'trait', '##path', '.', 'partition', '(', ')', '\\', 'n']
Detokenized (012): ['child##name', ',', '_', ',', 'rest##of##path', '=', 'trait##path', '.', 'partition', '(', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mdict . setdefault ( , t . __class__ . __name__ ) \n"
Original    (012): ['mdict', '.', 'setdefault', '(', ',', 't', '.', '__class__', '.', '__name__', ')', '\\n']
Tokenized   (028): ['[CLS]', 'md', '##ic', '##t', '.', 'set', '##de', '##fa', '##ult', '(', ',', 't', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['md', '##ic', '##t', '.', 'set', '##de', '##fa', '##ult', '(', ',', 't', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', ')', '\\', 'n']
Detokenized (012): ['md##ic##t', '.', 'set##de##fa##ult', '(', ',', 't', '.', '__class__', '.', '__name__', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "expr = compile ( assign , assign , mode = ) \n"
Original    (012): ['expr', '=', 'compile', '(', 'assign', ',', 'assign', ',', 'mode', '=', ')', '\\n']
Tokenized   (017): ['[CLS]', 'ex', '##pr', '=', 'com', '##pile', '(', 'assign', ',', 'assign', ',', 'mode', '=', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['ex', '##pr', '=', 'com', '##pile', '(', 'assign', ',', 'assign', ',', 'mode', '=', ')', '\\', 'n']
Detokenized (012): ['ex##pr', '=', 'com##pile', '(', 'assign', ',', 'assign', ',', 'mode', '=', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "tstamp = % ( now . year , now . month , now . day , now . hour , now . minute ) \n"
Original    (025): ['tstamp', '=', '%', '(', 'now', '.', 'year', ',', 'now', '.', 'month', ',', 'now', '.', 'day', ',', 'now', '.', 'hour', ',', 'now', '.', 'minute', ')', '\\n']
Tokenized   (030): ['[CLS]', 'ts', '##tam', '##p', '=', '%', '(', 'now', '.', 'year', ',', 'now', '.', 'month', ',', 'now', '.', 'day', ',', 'now', '.', 'hour', ',', 'now', '.', 'minute', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['ts', '##tam', '##p', '=', '%', '(', 'now', '.', 'year', ',', 'now', '.', 'month', ',', 'now', '.', 'day', ',', 'now', '.', 'hour', ',', 'now', '.', 'minute', ')', '\\', 'n']
Detokenized (025): ['ts##tam##p', '=', '%', '(', 'now', '.', 'year', ',', 'now', '.', 'month', ',', 'now', '.', 'day', ',', 'now', '.', 'hour', ',', 'now', '.', 'minute', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "entry_pts = [ ( self , name , _get_entry_group ( self ) ) ] \n"
Original    (015): ['entry_pts', '=', '[', '(', 'self', ',', 'name', ',', '_get_entry_group', '(', 'self', ')', ')', ']', '\\n']
Tokenized   (025): ['[CLS]', 'entry', '_', 'pts', '=', '[', '(', 'self', ',', 'name', ',', '_', 'get', '_', 'entry', '_', 'group', '(', 'self', ')', ')', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['entry', '_', 'pts', '=', '[', '(', 'self', ',', 'name', ',', '_', 'get', '_', 'entry', '_', 'group', '(', 'self', ')', ')', ']', '\\', 'n']
Detokenized (015): ['entry_pts', '=', '[', '(', 'self', ',', 'name', ',', '_get_entry_group', '(', 'self', ')', ')', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "root_start = root_start + 1 if root_start >= 0 else 0 \n"
Original    (012): ['root_start', '=', 'root_start', '+', '1', 'if', 'root_start', '>=', '0', 'else', '0', '\\n']
Tokenized   (022): ['[CLS]', 'root', '_', 'start', '=', 'root', '_', 'start', '+', '1', 'if', 'root', '_', 'start', '>', '=', '0', 'else', '0', '\\', 'n', '[SEP]']
Filtered   (020): ['root', '_', 'start', '=', 'root', '_', 'start', '+', '1', 'if', 'root', '_', 'start', '>', '=', '0', 'else', '0', '\\', 'n']
Detokenized (012): ['root_start', '=', 'root_start', '+', '1', 'if', 'root_start', '>=', '0', 'else', '0', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "root_pathname += \n"
Original    (003): ['root_pathname', '+=', '\\n']
Tokenized   (010): ['[CLS]', 'root', '_', 'path', '##name', '+', '=', '\\', 'n', '[SEP]']
Filtered   (008): ['root', '_', 'path', '##name', '+', '=', '\\', 'n']
Detokenized (003): ['root_path##name', '+=', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "Container . _bases ( type ( obj ) , names ) \n"
Original    (012): ['Container', '.', '_bases', '(', 'type', '(', 'obj', ')', ',', 'names', ')', '\\n']
Tokenized   (017): ['[CLS]', 'container', '.', '_', 'bases', '(', 'type', '(', 'ob', '##j', ')', ',', 'names', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['container', '.', '_', 'bases', '(', 'type', '(', 'ob', '##j', ')', ',', 'names', ')', '\\', 'n']
Detokenized (012): ['container', '.', '_bases', '(', 'type', '(', 'ob##j', ')', ',', 'names', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "names . append ( % ( cls . __module__ , cls . __name__ ) ) \n"
Original    (016): ['names', '.', 'append', '(', '%', '(', 'cls', '.', '__module__', ',', 'cls', '.', '__name__', ')', ')', '\\n']
Tokenized   (030): ['[CLS]', 'names', '.', 'app', '##end', '(', '%', '(', 'cl', '##s', '.', '_', '_', 'module', '_', '_', ',', 'cl', '##s', '.', '_', '_', 'name', '_', '_', ')', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['names', '.', 'app', '##end', '(', '%', '(', 'cl', '##s', '.', '_', '_', 'module', '_', '_', ',', 'cl', '##s', '.', '_', '_', 'name', '_', '_', ')', ')', '\\', 'n']
Detokenized (016): ['names', '.', 'app##end', '(', '%', '(', 'cl##s', '.', '__module__', ',', 'cl##s', '.', '__name__', ')', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "_get_entry_group . group_map = [ \n"
Original    (006): ['_get_entry_group', '.', 'group_map', '=', '[', '\\n']
Tokenized   (016): ['[CLS]', '_', 'get', '_', 'entry', '_', 'group', '.', 'group', '_', 'map', '=', '[', '\\', 'n', '[SEP]']
Filtered   (014): ['_', 'get', '_', 'entry', '_', 'group', '.', 'group', '_', 'map', '=', '[', '\\', 'n']
Detokenized (006): ['_get_entry_group', '.', 'group_map', '=', '[', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "pprint . pprint ( dict ( [ ( n , str ( v ) ) \n"
Original    (016): ['pprint', '.', 'pprint', '(', 'dict', '(', '[', '(', 'n', ',', 'str', '(', 'v', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'pp', '##rin', '##t', '.', 'pp', '##rin', '##t', '(', 'di', '##ct', '(', '[', '(', 'n', ',', 'st', '##r', '(', 'v', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['pp', '##rin', '##t', '.', 'pp', '##rin', '##t', '(', 'di', '##ct', '(', '[', '(', 'n', ',', 'st', '##r', '(', 'v', ')', ')', '\\', 'n']
Detokenized (016): ['pp##rin##t', '.', 'pp##rin##t', '(', 'di##ct', '(', '[', '(', 'n', ',', 'st##r', '(', 'v', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "** metadata ) ] ) , \n"
Original    (007): ['**', 'metadata', ')', ']', ')', ',', '\\n']
Tokenized   (011): ['[CLS]', '*', '*', 'metadata', ')', ']', ')', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['*', '*', 'metadata', ')', ']', ')', ',', '\\', 'n']
Detokenized (007): ['**', 'metadata', ')', ']', ')', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "io_attr [ ] = \n"
Original    (005): ['io_attr', '[', ']', '=', '\\n']
Tokenized   (011): ['[CLS]', 'io', '_', 'at', '##tr', '[', ']', '=', '\\', 'n', '[SEP]']
Filtered   (009): ['io', '_', 'at', '##tr', '[', ']', '=', '\\', 'n']
Detokenized (005): ['io_at##tr', '[', ']', '=', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "_redirect_streams ( ofile . fileno ( ) ) \n"
Original    (009): ['_redirect_streams', '(', 'ofile', '.', 'fileno', '(', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', '_', 'red', '##ire', '##ct', '_', 'streams', '(', 'of', '##ile', '.', 'file', '##no', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['_', 'red', '##ire', '##ct', '_', 'streams', '(', 'of', '##ile', '.', 'file', '##no', '(', ')', ')', '\\', 'n']
Detokenized (009): ['_red##ire##ct_streams', '(', 'of##ile', '.', 'file##no', '(', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "leftover = arr_size % num_divisions \n"
Original    (006): ['leftover', '=', 'arr_size', '%', 'num_divisions', '\\n']
Tokenized   (016): ['[CLS]', 'left', '##over', '=', 'ar', '##r', '_', 'size', '%', 'nu', '##m', '_', 'divisions', '\\', 'n', '[SEP]']
Filtered   (014): ['left', '##over', '=', 'ar', '##r', '_', 'size', '%', 'nu', '##m', '_', 'divisions', '\\', 'n']
Detokenized (006): ['left##over', '=', 'ar##r_size', '%', 'nu##m_divisions', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "sizes [ : leftover ] += 1 \n"
Original    (008): ['sizes', '[', ':', 'leftover', ']', '+=', '1', '\\n']
Tokenized   (013): ['[CLS]', 'sizes', '[', ':', 'left', '##over', ']', '+', '=', '1', '\\', 'n', '[SEP]']
Filtered   (011): ['sizes', '[', ':', 'left', '##over', ']', '+', '=', '1', '\\', 'n']
Detokenized (008): ['sizes', '[', ':', 'left##over', ']', '+=', '1', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "offsets [ 1 : ] = numpy . cumsum ( sizes ) [ : - 1 ] \n"
Original    (018): ['offsets', '[', '1', ':', ']', '=', 'numpy', '.', 'cumsum', '(', 'sizes', ')', '[', ':', '-', '1', ']', '\\n']
Tokenized   (025): ['[CLS]', 'offset', '##s', '[', '1', ':', ']', '=', 'nu', '##mp', '##y', '.', 'cum', '##sum', '(', 'sizes', ')', '[', ':', '-', '1', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['offset', '##s', '[', '1', ':', ']', '=', 'nu', '##mp', '##y', '.', 'cum', '##sum', '(', 'sizes', ')', '[', ':', '-', '1', ']', '\\', 'n']
Detokenized (018): ['offset##s', '[', '1', ':', ']', '=', 'nu##mp##y', '.', 'cum##sum', '(', 'sizes', ')', '[', ':', '-', '1', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "z1 = Float ( 0. , iotype = ) \n"
Original    (010): ['z1', '=', 'Float', '(', '0.', ',', 'iotype', '=', ')', '\\n']
Tokenized   (016): ['[CLS]', 'z', '##1', '=', 'float', '(', '0', '.', ',', 'io', '##type', '=', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['z', '##1', '=', 'float', '(', '0', '.', ',', 'io', '##type', '=', ')', '\\', 'n']
Detokenized (010): ['z##1', '=', 'float', '(', '0.', ',', 'io##type', '=', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "z_store = Array ( [ 0. , 0. ] , iotype = ) \n"
Original    (014): ['z_store', '=', 'Array', '(', '[', '0.', ',', '0.', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (022): ['[CLS]', 'z', '_', 'store', '=', 'array', '(', '[', '0', '.', ',', '0', '.', ']', ',', 'io', '##type', '=', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['z', '_', 'store', '=', 'array', '(', '[', '0', '.', ',', '0', '.', ']', ',', 'io', '##type', '=', ')', '\\', 'n']
Detokenized (014): ['z_store', '=', 'array', '(', '[', '0.', ',', '0.', ']', ',', 'io##type', '=', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "ssa_F = Array ( [ 0.0 ] , iotype = ) \n"
Original    (012): ['ssa_F', '=', 'Array', '(', '[', '0.0', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (021): ['[CLS]', 'ss', '##a', '_', 'f', '=', 'array', '(', '[', '0', '.', '0', ']', ',', 'io', '##type', '=', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['ss', '##a', '_', 'f', '=', 'array', '(', '[', '0', '.', '0', ']', ',', 'io', '##type', '=', ')', '\\', 'n']
Detokenized (012): ['ss##a_f', '=', 'array', '(', '[', '0.0', ']', ',', 'io##type', '=', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ssa_dG = Array ( [ [ 0.0 , 0.0 ] , [ 0.0 , 0.0 ] ] , iotype = ) \n"
Original    (022): ['ssa_dG', '=', 'Array', '(', '[', '[', '0.0', ',', '0.0', ']', ',', '[', '0.0', ',', '0.0', ']', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (038): ['[CLS]', 'ss', '##a', '_', 'd', '##g', '=', 'array', '(', '[', '[', '0', '.', '0', ',', '0', '.', '0', ']', ',', '[', '0', '.', '0', ',', '0', '.', '0', ']', ']', ',', 'io', '##type', '=', ')', '\\', 'n', '[SEP]']
Filtered   (036): ['ss', '##a', '_', 'd', '##g', '=', 'array', '(', '[', '[', '0', '.', '0', ',', '0', '.', '0', ']', ',', '[', '0', '.', '0', ',', '0', '.', '0', ']', ']', ',', 'io', '##type', '=', ')', '\\', 'n']
Detokenized (022): ['ss##a_d##g', '=', 'array', '(', '[', '[', '0.0', ',', '0.0', ']', ',', '[', '0.0', ',', '0.0', ']', ']', ',', 'io##type', '=', ')', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "arr_out = Array ( [ 1. , 2. , 3. ] , iotype = , units = ) \n"
Original    (019): ['arr_out', '=', 'Array', '(', '[', '1.', ',', '2.', ',', '3.', ']', ',', 'iotype', '=', ',', 'units', '=', ')', '\\n']
Tokenized   (029): ['[CLS]', 'ar', '##r', '_', 'out', '=', 'array', '(', '[', '1', '.', ',', '2', '.', ',', '3', '.', ']', ',', 'io', '##type', '=', ',', 'units', '=', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['ar', '##r', '_', 'out', '=', 'array', '(', '[', '1', '.', ',', '2', '.', ',', '3', '.', ']', ',', 'io', '##type', '=', ',', 'units', '=', ')', '\\', 'n']
Detokenized (019): ['ar##r_out', '=', 'array', '(', '[', '1.', ',', '2.', ',', '3.', ']', ',', 'io##type', '=', ',', 'units', '=', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "arg [ ] = np . array ( [ 3.1 ] ) \n"
Original    (013): ['arg', '[', ']', '=', 'np', '.', 'array', '(', '[', '3.1', ']', ')', '\\n']
Tokenized   (019): ['[CLS]', 'ar', '##g', '[', ']', '=', 'np', '.', 'array', '(', '[', '3', '.', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['ar', '##g', '[', ']', '=', 'np', '.', 'array', '(', '[', '3', '.', '1', ']', ')', '\\', 'n']
Detokenized (013): ['ar##g', '[', ']', '=', 'np', '.', 'array', '(', '[', '3.1', ']', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "jacs [ ] = np . array ( [ [ 100.0 , 101 , 102 , 103 ] , \n"
Original    (020): ['jacs', '[', ']', '=', 'np', '.', 'array', '(', '[', '[', '100.0', ',', '101', ',', '102', ',', '103', ']', ',', '\\n']
Tokenized   (026): ['[CLS]', 'ja', '##cs', '[', ']', '=', 'np', '.', 'array', '(', '[', '[', '100', '.', '0', ',', '101', ',', '102', ',', '103', ']', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['ja', '##cs', '[', ']', '=', 'np', '.', 'array', '(', '[', '[', '100', '.', '0', ',', '101', ',', '102', ',', '103', ']', ',', '\\', 'n']
Detokenized (020): ['ja##cs', '[', ']', '=', 'np', '.', 'array', '(', '[', '[', '100.0', ',', '101', ',', '102', ',', '103', ']', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "assert_rel_error ( self , J [ 3 ] [ 0 ] , 3.0 , 1e-5 ) \n"
Original    (017): ['assert_rel_error', '(', 'self', ',', 'J', '[', '3', ']', '[', '0', ']', ',', '3.0', ',', '1e-5', ')', '\\n']
Tokenized   (030): ['[CLS]', 'assert', '_', 're', '##l', '_', 'error', '(', 'self', ',', 'j', '[', '3', ']', '[', '0', ']', ',', '3', '.', '0', ',', '1', '##e', '-', '5', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['assert', '_', 're', '##l', '_', 'error', '(', 'self', ',', 'j', '[', '3', ']', '[', '0', ']', ',', '3', '.', '0', ',', '1', '##e', '-', '5', ')', '\\', 'n']
Detokenized (017): ['assert_re##l_error', '(', 'self', ',', 'j', '[', '3', ']', '[', '0', ']', ',', '3.0', ',', '1##e-5', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "newval = _getformat ( val ) % val \n"
Original    (009): ['newval', '=', '_getformat', '(', 'val', ')', '%', 'val', '\\n']
Tokenized   (016): ['[CLS]', 'new', '##val', '=', '_', 'get', '##form', '##at', '(', 'val', ')', '%', 'val', '\\', 'n', '[SEP]']
Filtered   (014): ['new', '##val', '=', '_', 'get', '##form', '##at', '(', 'val', ')', '%', 'val', '\\', 'n']
Detokenized (009): ['new##val', '=', '_get##form##at', '(', 'val', ')', '%', 'val', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newline = re . sub ( self . reg , sub . replace_array , line ) \n"
Original    (017): ['newline', '=', 're', '.', 'sub', '(', 'self', '.', 'reg', ',', 'sub', '.', 'replace_array', ',', 'line', ')', '\\n']
Tokenized   (023): ['[CLS]', 'new', '##line', '=', 're', '.', 'sub', '(', 'self', '.', 'reg', ',', 'sub', '.', 'replace', '_', 'array', ',', 'line', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['new', '##line', '=', 're', '.', 'sub', '(', 'self', '.', 'reg', ',', 'sub', '.', 'replace', '_', 'array', ',', 'line', ')', '\\', 'n']
Detokenized (017): ['new##line', '=', 're', '.', 'sub', '(', 'self', '.', 'reg', ',', 'sub', '.', 'replace_array', ',', 'line', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "fields = self . _parse_line ( ) . parseString ( line . replace ( key , "KeyField" ) ) \n"
Original    (020): ['fields', '=', 'self', '.', '_parse_line', '(', ')', '.', 'parseString', '(', 'line', '.', 'replace', '(', 'key', ',', '"KeyField"', ')', ')', '\\n']
Tokenized   (033): ['[CLS]', 'fields', '=', 'self', '.', '_', 'par', '##se', '_', 'line', '(', ')', '.', 'par', '##ses', '##tri', '##ng', '(', 'line', '.', 'replace', '(', 'key', ',', '"', 'key', '##field', '"', ')', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['fields', '=', 'self', '.', '_', 'par', '##se', '_', 'line', '(', ')', '.', 'par', '##ses', '##tri', '##ng', '(', 'line', '.', 'replace', '(', 'key', ',', '"', 'key', '##field', '"', ')', ')', '\\', 'n']
Detokenized (020): ['fields', '=', 'self', '.', '_par##se_line', '(', ')', '.', 'par##ses##tri##ng', '(', 'line', '.', 'replace', '(', 'key', ',', '"key##field"', ')', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "j2 = self . current_row + rowend + 1 \n"
Original    (010): ['j2', '=', 'self', '.', 'current_row', '+', 'rowend', '+', '1', '\\n']
Tokenized   (017): ['[CLS]', 'j', '##2', '=', 'self', '.', 'current', '_', 'row', '+', 'rowe', '##nd', '+', '1', '\\', 'n', '[SEP]']
Filtered   (015): ['j', '##2', '=', 'self', '.', 'current', '_', 'row', '+', 'rowe', '##nd', '+', '1', '\\', 'n']
Detokenized (010): ['j##2', '=', 'self', '.', 'current_row', '+', 'rowe##nd', '+', '1', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ee = CaselessLiteral ( ) | CaselessLiteral ( ) \n"
Original    (010): ['ee', '=', 'CaselessLiteral', '(', ')', '|', 'CaselessLiteral', '(', ')', '\\n']
Tokenized   (019): ['[CLS]', 'ee', '=', 'case', '##less', '##lite', '##ral', '(', ')', '|', 'case', '##less', '##lite', '##ral', '(', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['ee', '=', 'case', '##less', '##lite', '##ral', '(', ')', '|', 'case', '##less', '##lite', '##ral', '(', ')', '\\', 'n']
Detokenized (010): ['ee', '=', 'case##less##lite##ral', '(', ')', '|', 'case##less##lite##ral', '(', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "num_int = ToInteger ( Combine ( Optional ( sign ) + digits ) ) \n"
Original    (015): ['num_int', '=', 'ToInteger', '(', 'Combine', '(', 'Optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Tokenized   (023): ['[CLS]', 'nu', '##m', '_', 'int', '=', 'to', '##int', '##eger', '(', 'combine', '(', 'optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['nu', '##m', '_', 'int', '=', 'to', '##int', '##eger', '(', 'combine', '(', 'optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\', 'n']
Detokenized (015): ['nu##m_int', '=', 'to##int##eger', '(', 'combine', '(', 'optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "num_float = ToFloat ( Combine ( Optional ( sign ) + \n"
Original    (012): ['num_float', '=', 'ToFloat', '(', 'Combine', '(', 'Optional', '(', 'sign', ')', '+', '\\n']
Tokenized   (020): ['[CLS]', 'nu', '##m', '_', 'float', '=', 'to', '##fl', '##oat', '(', 'combine', '(', 'optional', '(', 'sign', ')', '+', '\\', 'n', '[SEP]']
Filtered   (018): ['nu', '##m', '_', 'float', '=', 'to', '##fl', '##oat', '(', 'combine', '(', 'optional', '(', 'sign', ')', '+', '\\', 'n']
Detokenized (012): ['nu##m_float', '=', 'to##fl##oat', '(', 'combine', '(', 'optional', '(', 'sign', ')', '+', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Optional ( ee + Optional ( sign ) + digits ) \n"
Original    (012): ['Optional', '(', 'ee', '+', 'Optional', '(', 'sign', ')', '+', 'digits', ')', '\\n']
Tokenized   (015): ['[CLS]', 'optional', '(', 'ee', '+', 'optional', '(', 'sign', ')', '+', 'digits', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['optional', '(', 'ee', '+', 'optional', '(', 'sign', ')', '+', 'digits', ')', '\\', 'n']
Detokenized (012): ['optional', '(', 'ee', '+', 'optional', '(', 'sign', ')', '+', 'digits', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mixed_exp = ToFloat ( Combine ( digits + ee + Optional ( sign ) + digits ) ) \n"
Original    (019): ['mixed_exp', '=', 'ToFloat', '(', 'Combine', '(', 'digits', '+', 'ee', '+', 'Optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Tokenized   (027): ['[CLS]', 'mixed', '_', 'ex', '##p', '=', 'to', '##fl', '##oat', '(', 'combine', '(', 'digits', '+', 'ee', '+', 'optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['mixed', '_', 'ex', '##p', '=', 'to', '##fl', '##oat', '(', 'combine', '(', 'digits', '+', 'ee', '+', 'optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\', 'n']
Detokenized (019): ['mixed_ex##p', '=', 'to##fl##oat', '(', 'combine', '(', 'digits', '+', 'ee', '+', 'optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "string_text ) ) ) \n"
Original    (005): ['string_text', ')', ')', ')', '\\n']
Tokenized   (010): ['[CLS]', 'string', '_', 'text', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['string', '_', 'text', ')', ')', ')', '\\', 'n']
Detokenized (005): ['string_text', ')', ')', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "J [ , ] = - 1.0 \n"
Original    (008): ['J', '[', ',', ']', '=', '-', '1.0', '\\n']
Tokenized   (013): ['[CLS]', 'j', '[', ',', ']', '=', '-', '1', '.', '0', '\\', 'n', '[SEP]']
Filtered   (011): ['j', '[', ',', ']', '=', '-', '1', '.', '0', '\\', 'n']
Detokenized (008): ['j', '[', ',', ']', '=', '-', '1.0', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "top [ ] = - 7.0 \n"
Original    (007): ['top', '[', ']', '=', '-', '7.0', '\\n']
Tokenized   (012): ['[CLS]', 'top', '[', ']', '=', '-', '7', '.', '0', '\\', 'n', '[SEP]']
Filtered   (010): ['top', '[', ']', '=', '-', '7', '.', '0', '\\', 'n']
Detokenized (007): ['top', '[', ']', '=', '-', '7.0', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "lhs , op , rhs = _parse_constraint ( expr ) \n"
Original    (011): ['lhs', ',', 'op', ',', 'rhs', '=', '_parse_constraint', '(', 'expr', ')', '\\n']
Tokenized   (021): ['[CLS]', 'l', '##hs', ',', 'op', ',', 'r', '##hs', '=', '_', 'par', '##se', '_', 'constraint', '(', 'ex', '##pr', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['l', '##hs', ',', 'op', ',', 'r', '##hs', '=', '_', 'par', '##se', '_', 'constraint', '(', 'ex', '##pr', ')', '\\', 'n']
Detokenized (011): ['l##hs', ',', 'op', ',', 'r##hs', '=', '_par##se_constraint', '(', 'ex##pr', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "first , second = ( rhs , lhs ) if op . startswith ( ) else ( lhs , rhs ) \n"
Original    (022): ['first', ',', 'second', '=', '(', 'rhs', ',', 'lhs', ')', 'if', 'op', '.', 'startswith', '(', ')', 'else', '(', 'lhs', ',', 'rhs', ')', '\\n']
Tokenized   (030): ['[CLS]', 'first', ',', 'second', '=', '(', 'r', '##hs', ',', 'l', '##hs', ')', 'if', 'op', '.', 'starts', '##with', '(', ')', 'else', '(', 'l', '##hs', ',', 'r', '##hs', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['first', ',', 'second', '=', '(', 'r', '##hs', ',', 'l', '##hs', ')', 'if', 'op', '.', 'starts', '##with', '(', ')', 'else', '(', 'l', '##hs', ',', 'r', '##hs', ')', '\\', 'n']
Detokenized (022): ['first', ',', 'second', '=', '(', 'r##hs', ',', 'l##hs', ')', 'if', 'op', '.', 'starts##with', '(', ')', 'else', '(', 'l##hs', ',', 'r##hs', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "input_graph . add_edges_from ( ( ( start , p ) for p in plist [ 1 : ] ) , \n"
Original    (021): ['input_graph', '.', 'add_edges_from', '(', '(', '(', 'start', ',', 'p', ')', 'for', 'p', 'in', 'plist', '[', '1', ':', ']', ')', ',', '\\n']
Tokenized   (031): ['[CLS]', 'input', '_', 'graph', '.', 'add', '_', 'edges', '_', 'from', '(', '(', '(', 'start', ',', 'p', ')', 'for', 'p', 'in', 'pl', '##ist', '[', '1', ':', ']', ')', ',', '\\', 'n', '[SEP]']
Filtered   (029): ['input', '_', 'graph', '.', 'add', '_', 'edges', '_', 'from', '(', '(', '(', 'start', ',', 'p', ')', 'for', 'p', 'in', 'pl', '##ist', '[', '1', ':', ']', ')', ',', '\\', 'n']
Detokenized (021): ['input_graph', '.', 'add_edges_from', '(', '(', '(', 'start', ',', 'p', ')', 'for', 'p', 'in', 'pl##ist', '[', '1', ':', ']', ')', ',', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "src_idxs = { src : None } \n"
Original    (008): ['src_idxs', '=', '{', 'src', ':', 'None', '}', '\\n']
Tokenized   (017): ['[CLS]', 'sr', '##c', '_', 'id', '##x', '##s', '=', '{', 'sr', '##c', ':', 'none', '}', '\\', 'n', '[SEP]']
Filtered   (015): ['sr', '##c', '_', 'id', '##x', '##s', '=', '{', 'sr', '##c', ':', 'none', '}', '\\', 'n']
Detokenized (008): ['sr##c_id##x##s', '=', '{', 'sr##c', ':', 'none', '}', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "units = [ params_dict [ n ] . get ( ) for n in connected_inputs ] \n"
Original    (017): ['units', '=', '[', 'params_dict', '[', 'n', ']', '.', 'get', '(', ')', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Tokenized   (026): ['[CLS]', 'units', '=', '[', 'para', '##ms', '_', 'di', '##ct', '[', 'n', ']', '.', 'get', '(', ')', 'for', 'n', 'in', 'connected', '_', 'inputs', ']', '\\', 'n', '[SEP]']
Filtered   (024): ['units', '=', '[', 'para', '##ms', '_', 'di', '##ct', '[', 'n', ']', '.', 'get', '(', ')', 'for', 'n', 'in', 'connected', '_', 'inputs', ']', '\\', 'n']
Detokenized (017): ['units', '=', '[', 'para##ms_di##ct', '[', 'n', ']', '.', 'get', '(', ')', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "vals = [ params_dict [ n ] [ ] for n in connected_inputs ] \n"
Original    (015): ['vals', '=', '[', 'params_dict', '[', 'n', ']', '[', ']', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Tokenized   (025): ['[CLS]', 'val', '##s', '=', '[', 'para', '##ms', '_', 'di', '##ct', '[', 'n', ']', '[', ']', 'for', 'n', 'in', 'connected', '_', 'inputs', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['val', '##s', '=', '[', 'para', '##ms', '_', 'di', '##ct', '[', 'n', ']', '[', ']', 'for', 'n', 'in', 'connected', '_', 'inputs', ']', '\\', 'n']
Detokenized (015): ['val##s', '=', '[', 'para##ms_di##ct', '[', 'n', ']', '[', ']', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tname , t = connected_inputs [ i ] , u \n"
Original    (011): ['tname', ',', 't', '=', 'connected_inputs', '[', 'i', ']', ',', 'u', '\\n']
Tokenized   (017): ['[CLS]', 'tna', '##me', ',', 't', '=', 'connected', '_', 'inputs', '[', 'i', ']', ',', 'u', '\\', 'n', '[SEP]']
Filtered   (015): ['tna', '##me', ',', 't', '=', 'connected', '_', 'inputs', '[', 'i', ']', ',', 'u', '\\', 'n']
Detokenized (011): ['tna##me', ',', 't', '=', 'connected_inputs', '[', 'i', ']', ',', 'u', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "correct_src = params_dict [ connected_inputs [ 0 ] ] [ ] \n"
Original    (012): ['correct_src', '=', 'params_dict', '[', 'connected_inputs', '[', '0', ']', ']', '[', ']', '\\n']
Tokenized   (024): ['[CLS]', 'correct', '_', 'sr', '##c', '=', 'para', '##ms', '_', 'di', '##ct', '[', 'connected', '_', 'inputs', '[', '0', ']', ']', '[', ']', '\\', 'n', '[SEP]']
Filtered   (022): ['correct', '_', 'sr', '##c', '=', 'para', '##ms', '_', 'di', '##ct', '[', 'connected', '_', 'inputs', '[', '0', ']', ']', '[', ']', '\\', 'n']
Detokenized (012): ['correct_sr##c', '=', 'para##ms_di##ct', '[', 'connected_inputs', '[', '0', ']', ']', '[', ']', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "sorted ( [ ( v , k ) for k , v in forms . items ( ) ] ) ) ) \n"
Original    (023): ['sorted', '(', '[', '(', 'v', ',', 'k', ')', 'for', 'k', ',', 'v', 'in', 'forms', '.', 'items', '(', ')', ']', ')', ')', ')', '\\n']
Tokenized   (026): ['[CLS]', 'sorted', '(', '[', '(', 'v', ',', 'k', ')', 'for', 'k', ',', 'v', 'in', 'forms', '.', 'items', '(', ')', ']', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['sorted', '(', '[', '(', 'v', ',', 'k', ')', 'for', 'k', ',', 'v', 'in', 'forms', '.', 'items', '(', ')', ']', ')', ')', ')', '\\', 'n']
Detokenized (023): ['sorted', '(', '[', '(', 'v', ',', 'k', ')', 'for', 'k', ',', 'v', 'in', 'forms', '.', 'items', '(', ')', ']', ')', ')', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "full_order = { s . pathname : i for i , s in \n"
Original    (014): ['full_order', '=', '{', 's', '.', 'pathname', ':', 'i', 'for', 'i', ',', 's', 'in', '\\n']
Tokenized   (020): ['[CLS]', 'full', '_', 'order', '=', '{', 's', '.', 'path', '##name', ':', 'i', 'for', 'i', ',', 's', 'in', '\\', 'n', '[SEP]']
Filtered   (018): ['full', '_', 'order', '=', '{', 's', '.', 'path', '##name', ':', 'i', 'for', 'i', ',', 's', 'in', '\\', 'n']
Detokenized (014): ['full_order', '=', '{', 's', '.', 'path##name', ':', 'i', 'for', 'i', ',', 's', 'in', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "enumerate ( self . root . subsystems ( recurse = True ) ) } \n"
Original    (015): ['enumerate', '(', 'self', '.', 'root', '.', 'subsystems', '(', 'recurse', '=', 'True', ')', ')', '}', '\\n']
Tokenized   (022): ['[CLS]', 'en', '##ume', '##rate', '(', 'self', '.', 'root', '.', 'sub', '##systems', '(', 'rec', '##urse', '=', 'true', ')', ')', '}', '\\', 'n', '[SEP]']
Filtered   (020): ['en', '##ume', '##rate', '(', 'self', '.', 'root', '.', 'sub', '##systems', '(', 'rec', '##urse', '=', 'true', ')', ')', '}', '\\', 'n']
Detokenized (015): ['en##ume##rate', '(', 'self', '.', 'root', '.', 'sub##systems', '(', 'rec##urse', '=', 'true', ')', ')', '}', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "ssys = srcs [ 0 ] . rsplit ( , 1 ) [ 0 ] \n"
Original    (016): ['ssys', '=', 'srcs', '[', '0', ']', '.', 'rsplit', '(', ',', '1', ')', '[', '0', ']', '\\n']
Tokenized   (023): ['[CLS]', 'ss', '##ys', '=', 'sr', '##cs', '[', '0', ']', '.', 'rs', '##pl', '##it', '(', ',', '1', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (021): ['ss', '##ys', '=', 'sr', '##cs', '[', '0', ']', '.', 'rs', '##pl', '##it', '(', ',', '1', ')', '[', '0', ']', '\\', 'n']
Detokenized (016): ['ss##ys', '=', 'sr##cs', '[', '0', ']', '.', 'rs##pl##it', '(', ',', '1', ')', '[', '0', ']', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "params_dict , unknowns_dict = self . root . _setup_variables ( ) \n"
Original    (012): ['params_dict', ',', 'unknowns_dict', '=', 'self', '.', 'root', '.', '_setup_variables', '(', ')', '\\n']
Tokenized   (026): ['[CLS]', 'para', '##ms', '_', 'di', '##ct', ',', 'unknown', '##s', '_', 'di', '##ct', '=', 'self', '.', 'root', '.', '_', 'setup', '_', 'variables', '(', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['para', '##ms', '_', 'di', '##ct', ',', 'unknown', '##s', '_', 'di', '##ct', '=', 'self', '.', 'root', '.', '_', 'setup', '_', 'variables', '(', ')', '\\', 'n']
Detokenized (012): ['para##ms_di##ct', ',', 'unknown##s_di##ct', '=', 'self', '.', 'root', '.', '_setup_variables', '(', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "is not Component . setup_distrib ) ) : \n"
Original    (009): ['is', 'not', 'Component', '.', 'setup_distrib', ')', ')', ':', '\\n']
Tokenized   (017): ['[CLS]', 'is', 'not', 'component', '.', 'setup', '_', 'di', '##st', '##ri', '##b', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (015): ['is', 'not', 'component', '.', 'setup', '_', 'di', '##st', '##ri', '##b', ')', ')', ':', '\\', 'n']
Detokenized (009): ['is', 'not', 'component', '.', 'setup_di##st##ri##b', ')', ')', ':', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "alloc_derivs = not self . root . fd_options [ ] \n"
Original    (011): ['alloc_derivs', '=', 'not', 'self', '.', 'root', '.', 'fd_options', '[', ']', '\\n']
Tokenized   (022): ['[CLS]', 'all', '##oc', '_', 'der', '##iv', '##s', '=', 'not', 'self', '.', 'root', '.', 'f', '##d', '_', 'options', '[', ']', '\\', 'n', '[SEP]']
Filtered   (020): ['all', '##oc', '_', 'der', '##iv', '##s', '=', 'not', 'self', '.', 'root', '.', 'f', '##d', '_', 'options', '[', ']', '\\', 'n']
Detokenized (011): ['all##oc_der##iv##s', '=', 'not', 'self', '.', 'root', '.', 'f##d_options', '[', ']', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dangling_params = sorted ( set ( [ \n"
Original    (008): ['dangling_params', '=', 'sorted', '(', 'set', '(', '[', '\\n']
Tokenized   (014): ['[CLS]', 'dangling', '_', 'para', '##ms', '=', 'sorted', '(', 'set', '(', '[', '\\', 'n', '[SEP]']
Filtered   (012): ['dangling', '_', 'para', '##ms', '=', 'sorted', '(', 'set', '(', '[', '\\', 'n']
Detokenized (008): ['dangling_para##ms', '=', 'sorted', '(', 'set', '(', '[', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "nocomps = sorted ( [ c . pathname for c in self . root . components ( recurse = True , \n"
Original    (022): ['nocomps', '=', 'sorted', '(', '[', 'c', '.', 'pathname', 'for', 'c', 'in', 'self', '.', 'root', '.', 'components', '(', 'recurse', '=', 'True', ',', '\\n']
Tokenized   (029): ['[CLS]', 'no', '##com', '##ps', '=', 'sorted', '(', '[', 'c', '.', 'path', '##name', 'for', 'c', 'in', 'self', '.', 'root', '.', 'components', '(', 'rec', '##urse', '=', 'true', ',', '\\', 'n', '[SEP]']
Filtered   (027): ['no', '##com', '##ps', '=', 'sorted', '(', '[', 'c', '.', 'path', '##name', 'for', 'c', 'in', 'self', '.', 'root', '.', 'components', '(', 'rec', '##urse', '=', 'true', ',', '\\', 'n']
Detokenized (022): ['no##com##ps', '=', 'sorted', '(', '[', 'c', '.', 'path##name', 'for', 'c', 'in', 'self', '.', 'root', '.', 'components', '(', 'rec##urse', '=', 'true', ',', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "local = True ) \n"
Original    (005): ['local', '=', 'True', ')', '\\n']
Tokenized   (008): ['[CLS]', 'local', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (006): ['local', '=', 'true', ')', '\\', 'n']
Detokenized (005): ['local', '=', 'true', ')', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "recorders . extend ( grp . ln_solver . recorders ) \n"
Original    (011): ['recorders', '.', 'extend', '(', 'grp', '.', 'ln_solver', '.', 'recorders', ')', '\\n']
Tokenized   (021): ['[CLS]', 'recorder', '##s', '.', 'extend', '(', 'gr', '##p', '.', 'l', '##n', '_', 'solve', '##r', '.', 'recorder', '##s', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['recorder', '##s', '.', 'extend', '(', 'gr', '##p', '.', 'l', '##n', '_', 'solve', '##r', '.', 'recorder', '##s', ')', '\\', 'n']
Detokenized (011): ['recorder##s', '.', 'extend', '(', 'gr##p', '.', 'l##n_solve##r', '.', 'recorder##s', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "conn_comps . update ( [ s . rsplit ( , 1 ) [ 0 ] \n"
Original    (016): ['conn_comps', '.', 'update', '(', '[', 's', '.', 'rsplit', '(', ',', '1', ')', '[', '0', ']', '\\n']
Tokenized   (025): ['[CLS]', 'con', '##n', '_', 'com', '##ps', '.', 'update', '(', '[', 's', '.', 'rs', '##pl', '##it', '(', ',', '1', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['con', '##n', '_', 'com', '##ps', '.', 'update', '(', '[', 's', '.', 'rs', '##pl', '##it', '(', ',', '1', ')', '[', '0', ']', '\\', 'n']
Detokenized (016): ['con##n_com##ps', '.', 'update', '(', '[', 's', '.', 'rs##pl##it', '(', ',', '1', ')', '[', '0', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "noconn_comps = sorted ( [ c . pathname \n"
Original    (009): ['noconn_comps', '=', 'sorted', '(', '[', 'c', '.', 'pathname', '\\n']
Tokenized   (018): ['[CLS]', 'no', '##con', '##n', '_', 'com', '##ps', '=', 'sorted', '(', '[', 'c', '.', 'path', '##name', '\\', 'n', '[SEP]']
Filtered   (016): ['no', '##con', '##n', '_', 'com', '##ps', '=', 'sorted', '(', '[', 'c', '.', 'path', '##name', '\\', 'n']
Detokenized (009): ['no##con##n_com##ps', '=', 'sorted', '(', '[', 'c', '.', 'path##name', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "strong = [ s for s in nx . strongly_connected_components ( graph ) \n"
Original    (014): ['strong', '=', '[', 's', 'for', 's', 'in', 'nx', '.', 'strongly_connected_components', '(', 'graph', ')', '\\n']
Tokenized   (022): ['[CLS]', 'strong', '=', '[', 's', 'for', 's', 'in', 'n', '##x', '.', 'strongly', '_', 'connected', '_', 'components', '(', 'graph', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['strong', '=', '[', 's', 'for', 's', 'in', 'n', '##x', '.', 'strongly', '_', 'connected', '_', 'components', '(', 'graph', ')', '\\', 'n']
Detokenized (014): ['strong', '=', '[', 's', 'for', 's', 'in', 'n##x', '.', 'strongly_connected_components', '(', 'graph', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "subs = [ s for s in grp . _subsystems ] \n"
Original    (012): ['subs', '=', '[', 's', 'for', 's', 'in', 'grp', '.', '_subsystems', ']', '\\n']
Tokenized   (019): ['[CLS]', 'sub', '##s', '=', '[', 's', 'for', 's', 'in', 'gr', '##p', '.', '_', 'sub', '##systems', ']', '\\', 'n', '[SEP]']
Filtered   (017): ['sub', '##s', '=', '[', 's', 'for', 's', 'in', 'gr', '##p', '.', '_', 'sub', '##systems', ']', '\\', 'n']
Detokenized (012): ['sub##s', '=', '[', 's', 'for', 's', 'in', 'gr##p', '.', '_sub##systems', ']', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "tups = sorted ( [ ( subs . index ( s ) , s ) for s in relstrong [ - 1 ] ] ) \n"
Original    (026): ['tups', '=', 'sorted', '(', '[', '(', 'subs', '.', 'index', '(', 's', ')', ',', 's', ')', 'for', 's', 'in', 'relstrong', '[', '-', '1', ']', ']', ')', '\\n']
Tokenized   (034): ['[CLS]', 'tu', '##ps', '=', 'sorted', '(', '[', '(', 'sub', '##s', '.', 'index', '(', 's', ')', ',', 's', ')', 'for', 's', 'in', 're', '##ls', '##tron', '##g', '[', '-', '1', ']', ']', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['tu', '##ps', '=', 'sorted', '(', '[', '(', 'sub', '##s', '.', 'index', '(', 's', ')', ',', 's', ')', 'for', 's', 'in', 're', '##ls', '##tron', '##g', '[', '-', '1', ']', ']', ')', '\\', 'n']
Detokenized (026): ['tu##ps', '=', 'sorted', '(', '[', '(', 'sub##s', '.', 'index', '(', 's', ')', ',', 's', ')', 'for', 's', 'in', 're##ls##tron##g', '[', '-', '1', ']', ']', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "relstrong [ - 1 ] = [ t [ 1 ] for t in tups ] \n"
Original    (017): ['relstrong', '[', '-', '1', ']', '=', '[', 't', '[', '1', ']', 'for', 't', 'in', 'tups', ']', '\\n']
Tokenized   (024): ['[CLS]', 're', '##ls', '##tron', '##g', '[', '-', '1', ']', '=', '[', 't', '[', '1', ']', 'for', 't', 'in', 'tu', '##ps', ']', '\\', 'n', '[SEP]']
Filtered   (022): ['re', '##ls', '##tron', '##g', '[', '-', '1', ']', '=', '[', 't', '[', '1', ']', 'for', 't', 'in', 'tu', '##ps', ']', '\\', 'n']
Detokenized (017): ['re##ls##tron##g', '[', '-', '1', ']', '=', '[', 't', '[', '1', ']', 'for', 't', 'in', 'tu##ps', ']', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "nearest_child ( grp . pathname , n ) for n in out_of_order [ name ] \n"
Original    (016): ['nearest_child', '(', 'grp', '.', 'pathname', ',', 'n', ')', 'for', 'n', 'in', 'out_of_order', '[', 'name', ']', '\\n']
Tokenized   (027): ['[CLS]', 'nearest', '_', 'child', '(', 'gr', '##p', '.', 'path', '##name', ',', 'n', ')', 'for', 'n', 'in', 'out', '_', 'of', '_', 'order', '[', 'name', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['nearest', '_', 'child', '(', 'gr', '##p', '.', 'path', '##name', ',', 'n', ')', 'for', 'n', 'in', 'out', '_', 'of', '_', 'order', '[', 'name', ']', '\\', 'n']
Detokenized (016): ['nearest_child', '(', 'gr##p', '.', 'path##name', ',', 'n', ')', 'for', 'n', 'in', 'out_of_order', '[', 'name', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "pbos = [ var for var in vec if vec . metadata ( var ) . get ( ) ] \n"
Original    (021): ['pbos', '=', '[', 'var', 'for', 'var', 'in', 'vec', 'if', 'vec', '.', 'metadata', '(', 'var', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (027): ['[CLS]', 'p', '##bos', '=', '[', 'var', 'for', 'var', 'in', 've', '##c', 'if', 've', '##c', '.', 'metadata', '(', 'var', ')', '.', 'get', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['p', '##bos', '=', '[', 'var', 'for', 'var', 'in', 've', '##c', 'if', 've', '##c', '.', 'metadata', '(', 'var', ')', '.', 'get', '(', ')', ']', '\\', 'n']
Detokenized (021): ['p##bos', '=', '[', 'var', 'for', 'var', 'in', 've##c', 'if', 've##c', '.', 'metadata', '(', 'var', ')', '.', 'get', '(', ')', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "iteritems ( self . root . _params_dict ) ) : \n"
Original    (011): ['iteritems', '(', 'self', '.', 'root', '.', '_params_dict', ')', ')', ':', '\\n']
Tokenized   (022): ['[CLS]', 'it', '##eri', '##tem', '##s', '(', 'self', '.', 'root', '.', '_', 'para', '##ms', '_', 'di', '##ct', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (020): ['it', '##eri', '##tem', '##s', '(', 'self', '.', 'root', '.', '_', 'para', '##ms', '_', 'di', '##ct', ')', ')', ':', '\\', 'n']
Detokenized (011): ['it##eri##tem##s', '(', 'self', '.', 'root', '.', '_para##ms_di##ct', ')', ')', ':', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dv_scale = None , cn_scale = None , sparsity = None ) : \n"
Original    (014): ['dv_scale', '=', 'None', ',', 'cn_scale', '=', 'None', ',', 'sparsity', '=', 'None', ')', ':', '\\n']
Tokenized   (024): ['[CLS]', 'd', '##v', '_', 'scale', '=', 'none', ',', 'cn', '_', 'scale', '=', 'none', ',', 'spa', '##rs', '##ity', '=', 'none', ')', ':', '\\', 'n', '[SEP]']
Filtered   (022): ['d', '##v', '_', 'scale', '=', 'none', ',', 'cn', '_', 'scale', '=', 'none', ',', 'spa', '##rs', '##ity', '=', 'none', ')', ':', '\\', 'n']
Detokenized (014): ['d##v_scale', '=', 'none', ',', 'cn_scale', '=', 'none', ',', 'spa##rs##ity', '=', 'none', ')', ':', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "fd_unknowns = [ var for var in unknown_list if var not in indep_list ] \n"
Original    (015): ['fd_unknowns', '=', '[', 'var', 'for', 'var', 'in', 'unknown_list', 'if', 'var', 'not', 'in', 'indep_list', ']', '\\n']
Tokenized   (027): ['[CLS]', 'f', '##d', '_', 'unknown', '##s', '=', '[', 'var', 'for', 'var', 'in', 'unknown', '_', 'list', 'if', 'var', 'not', 'in', 'ind', '##ep', '_', 'list', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['f', '##d', '_', 'unknown', '##s', '=', '[', 'var', 'for', 'var', 'in', 'unknown', '_', 'list', 'if', 'var', 'not', 'in', 'ind', '##ep', '_', 'list', ']', '\\', 'n']
Detokenized (015): ['f##d_unknown##s', '=', '[', 'var', 'for', 'var', 'in', 'unknown_list', 'if', 'var', 'not', 'in', 'ind##ep_list', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "usize += len ( idx ) \n"
Original    (007): ['usize', '+=', 'len', '(', 'idx', ')', '\\n']
Tokenized   (013): ['[CLS]', 'us', '##ize', '+', '=', 'len', '(', 'id', '##x', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['us', '##ize', '+', '=', 'len', '(', 'id', '##x', ')', '\\', 'n']
Detokenized (007): ['us##ize', '+=', 'len', '(', 'id##x', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "fwd = mode == \n"
Original    (005): ['fwd', '=', 'mode', '==', '\\n']
Tokenized   (010): ['[CLS]', 'f', '##wd', '=', 'mode', '=', '=', '\\', 'n', '[SEP]']
Filtered   (008): ['f', '##wd', '=', 'mode', '=', '=', '\\', 'n']
Detokenized (005): ['f##wd', '=', 'mode', '==', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "poi_indices , qoi_indices = self . _poi_indices , self . _qoi_indices \n"
Original    (012): ['poi_indices', ',', 'qoi_indices', '=', 'self', '.', '_poi_indices', ',', 'self', '.', '_qoi_indices', '\\n']
Tokenized   (029): ['[CLS]', 'po', '##i', '_', 'indices', ',', 'q', '##oi', '_', 'indices', '=', 'self', '.', '_', 'po', '##i', '_', 'indices', ',', 'self', '.', '_', 'q', '##oi', '_', 'indices', '\\', 'n', '[SEP]']
Filtered   (027): ['po', '##i', '_', 'indices', ',', 'q', '##oi', '_', 'indices', '=', 'self', '.', '_', 'po', '##i', '_', 'indices', ',', 'self', '.', '_', 'q', '##oi', '_', 'indices', '\\', 'n']
Detokenized (012): ['po##i_indices', ',', 'q##oi_indices', '=', 'self', '.', '_po##i_indices', ',', 'self', '.', '_q##oi_indices', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "in_scale , un_scale = cn_scale , dv_scale \n"
Original    (008): ['in_scale', ',', 'un_scale', '=', 'cn_scale', ',', 'dv_scale', '\\n']
Tokenized   (020): ['[CLS]', 'in', '_', 'scale', ',', 'un', '_', 'scale', '=', 'cn', '_', 'scale', ',', 'd', '##v', '_', 'scale', '\\', 'n', '[SEP]']
Filtered   (018): ['in', '_', 'scale', ',', 'un', '_', 'scale', '=', 'cn', '_', 'scale', ',', 'd', '##v', '_', 'scale', '\\', 'n']
Detokenized (008): ['in_scale', ',', 'un_scale', '=', 'cn_scale', ',', 'd##v_scale', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "duvec = self . root . dumat [ vkey ] \n"
Original    (011): ['duvec', '=', 'self', '.', 'root', '.', 'dumat', '[', 'vkey', ']', '\\n']
Tokenized   (018): ['[CLS]', 'du', '##ve', '##c', '=', 'self', '.', 'root', '.', 'du', '##mat', '[', 'v', '##key', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['du', '##ve', '##c', '=', 'self', '.', 'root', '.', 'du', '##mat', '[', 'v', '##key', ']', '\\', 'n']
Detokenized (011): ['du##ve##c', '=', 'self', '.', 'root', '.', 'du##mat', '[', 'v##key', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "rhs [ vkey ] [ : ] = 0.0 \n"
Original    (010): ['rhs', '[', 'vkey', ']', '[', ':', ']', '=', '0.0', '\\n']
Tokenized   (017): ['[CLS]', 'r', '##hs', '[', 'v', '##key', ']', '[', ':', ']', '=', '0', '.', '0', '\\', 'n', '[SEP]']
Filtered   (015): ['r', '##hs', '[', 'v', '##key', ']', '[', ':', ']', '=', '0', '.', '0', '\\', 'n']
Detokenized (010): ['r##hs', '[', 'v##key', ']', '[', ':', ']', '=', '0.0', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "isinstance ( self . root . ln_solver , LinearGaussSeidel ) ) : \n"
Original    (013): ['isinstance', '(', 'self', '.', 'root', '.', 'ln_solver', ',', 'LinearGaussSeidel', ')', ')', ':', '\\n']
Tokenized   (026): ['[CLS]', 'is', '##ins', '##tance', '(', 'self', '.', 'root', '.', 'l', '##n', '_', 'solve', '##r', ',', 'linear', '##gau', '##ss', '##sei', '##del', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (024): ['is', '##ins', '##tance', '(', 'self', '.', 'root', '.', 'l', '##n', '_', 'solve', '##r', ',', 'linear', '##gau', '##ss', '##sei', '##del', ')', ')', ':', '\\', 'n']
Detokenized (013): ['is##ins##tance', '(', 'self', '.', 'root', '.', 'l##n_solve##r', ',', 'linear##gau##ss##sei##del', ')', ')', ':', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "unkn_list = [ item for item in dunknowns if not dunknowns . metadata ( item ) . get ( ) ] \n"
Original    (022): ['unkn_list', '=', '[', 'item', 'for', 'item', 'in', 'dunknowns', 'if', 'not', 'dunknowns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (035): ['[CLS]', 'un', '##k', '##n', '_', 'list', '=', '[', 'item', 'for', 'item', 'in', 'dun', '##k', '##now', '##ns', 'if', 'not', 'dun', '##k', '##now', '##ns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (033): ['un', '##k', '##n', '_', 'list', '=', '[', 'item', 'for', 'item', 'in', 'dun', '##k', '##now', '##ns', 'if', 'not', 'dun', '##k', '##now', '##ns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\', 'n']
Detokenized (022): ['un##k##n_list', '=', '[', 'item', 'for', 'item', 'in', 'dun##k##now##ns', 'if', 'not', 'dun##k##now##ns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "p_size = np . size ( dinputs [ p_name ] ) \n"
Original    (012): ['p_size', '=', 'np', '.', 'size', '(', 'dinputs', '[', 'p_name', ']', ')', '\\n']
Tokenized   (021): ['[CLS]', 'p', '_', 'size', '=', 'np', '.', 'size', '(', 'din', '##put', '##s', '[', 'p', '_', 'name', ']', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['p', '_', 'size', '=', 'np', '.', 'size', '(', 'din', '##put', '##s', '[', 'p', '_', 'name', ']', ')', '\\', 'n']
Detokenized (012): ['p_size', '=', 'np', '.', 'size', '(', 'din##put##s', '[', 'p_name', ']', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "dresids . _dat [ u_name ] . val [ idx ] = 1.0 \n"
Original    (014): ['dresids', '.', '_dat', '[', 'u_name', ']', '.', 'val', '[', 'idx', ']', '=', '1.0', '\\n']
Tokenized   (025): ['[CLS]', 'dr', '##es', '##ids', '.', '_', 'dat', '[', 'u', '_', 'name', ']', '.', 'val', '[', 'id', '##x', ']', '=', '1', '.', '0', '\\', 'n', '[SEP]']
Filtered   (023): ['dr', '##es', '##ids', '.', '_', 'dat', '[', 'u', '_', 'name', ']', '.', 'val', '[', 'id', '##x', ']', '=', '1', '.', '0', '\\', 'n']
Detokenized (014): ['dr##es##ids', '.', '_dat', '[', 'u_name', ']', '.', 'val', '[', 'id##x', ']', '=', '1.0', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dunknowns , dresids , ) \n"
Original    (006): ['dunknowns', ',', 'dresids', ',', ')', '\\n']
Tokenized   (014): ['[CLS]', 'dun', '##k', '##now', '##ns', ',', 'dr', '##es', '##ids', ',', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['dun', '##k', '##now', '##ns', ',', 'dr', '##es', '##ids', ',', ')', '\\', 'n']
Detokenized (006): ['dun##k##now##ns', ',', 'dr##es##ids', ',', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "jac_rev [ ( u_name , p_name ) ] [ idx , : ] = dinputs . _dat [ p_name ] . val \n"
Original    (023): ['jac_rev', '[', '(', 'u_name', ',', 'p_name', ')', ']', '[', 'idx', ',', ':', ']', '=', 'dinputs', '.', '_dat', '[', 'p_name', ']', '.', 'val', '\\n']
Tokenized   (039): ['[CLS]', 'ja', '##c', '_', 'rev', '[', '(', 'u', '_', 'name', ',', 'p', '_', 'name', ')', ']', '[', 'id', '##x', ',', ':', ']', '=', 'din', '##put', '##s', '.', '_', 'dat', '[', 'p', '_', 'name', ']', '.', 'val', '\\', 'n', '[SEP]']
Filtered   (037): ['ja', '##c', '_', 'rev', '[', '(', 'u', '_', 'name', ',', 'p', '_', 'name', ')', ']', '[', 'id', '##x', ',', ':', ']', '=', 'din', '##put', '##s', '.', '_', 'dat', '[', 'p', '_', 'name', ']', '.', 'val', '\\', 'n']
Detokenized (023): ['ja##c_rev', '[', '(', 'u_name', ',', 'p_name', ')', ']', '[', 'id##x', ',', ':', ']', '=', 'din##put##s', '.', '_dat', '[', 'p_name', ']', '.', 'val', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "c_name = cname , jac_fd2 = jac_fd2 , fd_desc = fd_desc , \n"
Original    (013): ['c_name', '=', 'cname', ',', 'jac_fd2', '=', 'jac_fd2', ',', 'fd_desc', '=', 'fd_desc', ',', '\\n']
Tokenized   (037): ['[CLS]', 'c', '_', 'name', '=', 'cn', '##ame', ',', 'ja', '##c', '_', 'f', '##d', '##2', '=', 'ja', '##c', '_', 'f', '##d', '##2', ',', 'f', '##d', '_', 'des', '##c', '=', 'f', '##d', '_', 'des', '##c', ',', '\\', 'n', '[SEP]']
Filtered   (035): ['c', '_', 'name', '=', 'cn', '##ame', ',', 'ja', '##c', '_', 'f', '##d', '##2', '=', 'ja', '##c', '_', 'f', '##d', '##2', ',', 'f', '##d', '_', 'des', '##c', '=', 'f', '##d', '_', 'des', '##c', ',', '\\', 'n']
Detokenized (013): ['c_name', '=', 'cn##ame', ',', 'ja##c_f##d##2', '=', 'ja##c_f##d##2', ',', 'f##d_des##c', '=', 'f##d_des##c', ',', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "param_srcs = [ root . connections [ p ] for p in abs_indep_list if not root . _params_dict [ p ] . get ( ) ] \n"
Original    (027): ['param_srcs', '=', '[', 'root', '.', 'connections', '[', 'p', ']', 'for', 'p', 'in', 'abs_indep_list', 'if', 'not', 'root', '.', '_params_dict', '[', 'p', ']', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (044): ['[CLS]', 'para', '##m', '_', 'sr', '##cs', '=', '[', 'root', '.', 'connections', '[', 'p', ']', 'for', 'p', 'in', 'abs', '_', 'ind', '##ep', '_', 'list', 'if', 'not', 'root', '.', '_', 'para', '##ms', '_', 'di', '##ct', '[', 'p', ']', '.', 'get', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (042): ['para', '##m', '_', 'sr', '##cs', '=', '[', 'root', '.', 'connections', '[', 'p', ']', 'for', 'p', 'in', 'abs', '_', 'ind', '##ep', '_', 'list', 'if', 'not', 'root', '.', '_', 'para', '##ms', '_', 'di', '##ct', '[', 'p', ']', '.', 'get', '(', ')', ']', '\\', 'n']
Detokenized (027): ['para##m_sr##cs', '=', '[', 'root', '.', 'connections', '[', 'p', ']', 'for', 'p', 'in', 'abs_ind##ep_list', 'if', 'not', 'root', '.', '_para##ms_di##ct', '[', 'p', ']', '.', 'get', '(', ')', ']', '\\n']
Counter: 42
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "to_prom_name [ p ] for p , idxs in param_srcs \n"
Original    (011): ['to_prom_name', '[', 'p', ']', 'for', 'p', ',', 'idxs', 'in', 'param_srcs', '\\n']
Tokenized   (024): ['[CLS]', 'to', '_', 'prom', '_', 'name', '[', 'p', ']', 'for', 'p', ',', 'id', '##x', '##s', 'in', 'para', '##m', '_', 'sr', '##cs', '\\', 'n', '[SEP]']
Filtered   (022): ['to', '_', 'prom', '_', 'name', '[', 'p', ']', 'for', 'p', ',', 'id', '##x', '##s', 'in', 'para', '##m', '_', 'sr', '##cs', '\\', 'n']
Detokenized (011): ['to_prom_name', '[', 'p', ']', 'for', 'p', ',', 'id##x##s', 'in', 'para##m_sr##cs', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "unknown_list = [ item for item in unknown_list if not root . unknowns . metadata ( item ) . get ( ) ] \n"
Original    (024): ['unknown_list', '=', '[', 'item', 'for', 'item', 'in', 'unknown_list', 'if', 'not', 'root', '.', 'unknowns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (032): ['[CLS]', 'unknown', '_', 'list', '=', '[', 'item', 'for', 'item', 'in', 'unknown', '_', 'list', 'if', 'not', 'root', '.', 'unknown', '##s', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\', 'n', '[SEP]']
Filtered   (030): ['unknown', '_', 'list', '=', '[', 'item', 'for', 'item', 'in', 'unknown', '_', 'list', 'if', 'not', 'root', '.', 'unknown', '##s', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\', 'n']
Detokenized (024): ['unknown_list', '=', '[', 'item', 'for', 'item', 'in', 'unknown_list', 'if', 'not', 'root', '.', 'unknown##s', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "_assemble_deriv_data ( indep_list , unknown_list , data , \n"
Original    (009): ['_assemble_deriv_data', '(', 'indep_list', ',', 'unknown_list', ',', 'data', ',', '\\n']
Tokenized   (023): ['[CLS]', '_', 'assemble', '_', 'der', '##iv', '_', 'data', '(', 'ind', '##ep', '_', 'list', ',', 'unknown', '_', 'list', ',', 'data', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['_', 'assemble', '_', 'der', '##iv', '_', 'data', '(', 'ind', '##ep', '_', 'list', ',', 'unknown', '_', 'list', ',', 'data', ',', '\\', 'n']
Detokenized (009): ['_assemble_der##iv_data', '(', 'ind##ep_list', ',', 'unknown_list', ',', 'data', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_both_names ( tmeta , to_prom_name ) ) \n"
Original    (008): ['_both_names', '(', 'tmeta', ',', 'to_prom_name', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', '_', 'both', '_', 'names', '(', 't', '##met', '##a', ',', 'to', '_', 'prom', '_', 'name', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['_', 'both', '_', 'names', '(', 't', '##met', '##a', ',', 'to', '_', 'prom', '_', 'name', ')', ')', '\\', 'n']
Detokenized (008): ['_both_names', '(', 't##met##a', ',', 'to_prom_name', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "abs_unames = self . root . _sysdata . to_abs_uname \n"
Original    (010): ['abs_unames', '=', 'self', '.', 'root', '.', '_sysdata', '.', 'to_abs_uname', '\\n']
Tokenized   (024): ['[CLS]', 'abs', '_', 'una', '##mes', '=', 'self', '.', 'root', '.', '_', 'sy', '##sd', '##ata', '.', 'to', '_', 'abs', '_', 'una', '##me', '\\', 'n', '[SEP]']
Filtered   (022): ['abs', '_', 'una', '##mes', '=', 'self', '.', 'root', '.', '_', 'sy', '##sd', '##ata', '.', 'to', '_', 'abs', '_', 'una', '##me', '\\', 'n']
Detokenized (010): ['abs_una##mes', '=', 'self', '.', 'root', '.', '_sy##sd##ata', '.', 'to_abs_una##me', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "out_str = tmp1 . format ( _pad_name ( ) , _pad_name ( ) , \n"
Original    (015): ['out_str', '=', 'tmp1', '.', 'format', '(', '_pad_name', '(', ')', ',', '_pad_name', '(', ')', ',', '\\n']
Tokenized   (029): ['[CLS]', 'out', '_', 'st', '##r', '=', 't', '##mp', '##1', '.', 'format', '(', '_', 'pad', '_', 'name', '(', ')', ',', '_', 'pad', '_', 'name', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (027): ['out', '_', 'st', '##r', '=', 't', '##mp', '##1', '.', 'format', '(', '_', 'pad', '_', 'name', '(', ')', ',', '_', 'pad', '_', 'name', '(', ')', ',', '\\', 'n']
Detokenized (015): ['out_st##r', '=', 't##mp##1', '.', 'format', '(', '_pad_name', '(', ')', ',', '_pad_name', '(', ')', ',', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "magfor , magrev , magfd , abs1 , abs2 , \n"
Original    (011): ['magfor', ',', 'magrev', ',', 'magfd', ',', 'abs1', ',', 'abs2', ',', '\\n']
Tokenized   (021): ['[CLS]', 'mag', '##for', ',', 'mag', '##re', '##v', ',', 'mag', '##f', '##d', ',', 'abs', '##1', ',', 'abs', '##2', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['mag', '##for', ',', 'mag', '##re', '##v', ',', 'mag', '##f', '##d', ',', 'abs', '##1', ',', 'abs', '##2', ',', '\\', 'n']
Detokenized (011): ['mag##for', ',', 'mag##re##v', ',', 'mag##f##d', ',', 'abs##1', ',', 'abs##2', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "rel1 , rel2 ) ) \n"
Original    (006): ['rel1', ',', 'rel2', ')', ')', '\\n']
Tokenized   (013): ['[CLS]', 're', '##l', '##1', ',', 're', '##l', '##2', ')', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['re', '##l', '##1', ',', 're', '##l', '##2', ')', ')', '\\', 'n']
Detokenized (006): ['re##l##1', ',', 're##l##2', ')', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_pad_name ( , 12 , quotes = False ) \n"
Original    (010): ['_pad_name', '(', ',', '12', ',', 'quotes', '=', 'False', ')', '\\n']
Tokenized   (016): ['[CLS]', '_', 'pad', '_', 'name', '(', ',', '12', ',', 'quotes', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['_', 'pad', '_', 'name', '(', ',', '12', ',', 'quotes', '=', 'false', ')', '\\', 'n']
Detokenized (010): ['_pad_name', '(', ',', '12', ',', 'quotes', '=', 'false', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "magfd , magfd2 , abs4 , rel4 ) ) \n"
Original    (010): ['magfd', ',', 'magfd2', ',', 'abs4', ',', 'rel4', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'mag', '##f', '##d', ',', 'mag', '##f', '##d', '##2', ',', 'abs', '##4', ',', 're', '##l', '##4', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['mag', '##f', '##d', ',', 'mag', '##f', '##d', '##2', ',', 'abs', '##4', ',', 're', '##l', '##4', ')', ')', '\\', 'n']
Detokenized (010): ['mag##f##d', ',', 'mag##f##d##2', ',', 'abs##4', ',', 're##l##4', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "out_stream . write ( str ( Jsub_fd2 ) ) \n"
Original    (010): ['out_stream', '.', 'write', '(', 'str', '(', 'Jsub_fd2', ')', ')', '\\n']
Tokenized   (022): ['[CLS]', 'out', '_', 'stream', '.', 'write', '(', 'st', '##r', '(', 'j', '##su', '##b', '_', 'f', '##d', '##2', ')', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['out', '_', 'stream', '.', 'write', '(', 'st', '##r', '(', 'j', '##su', '##b', '_', 'f', '##d', '##2', ')', ')', '\\', 'n']
Detokenized (010): ['out_stream', '.', 'write', '(', 'st##r', '(', 'j##su##b_f##d##2', ')', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sqlite_dict_args . setdefault ( , ) \n"
Original    (007): ['sqlite_dict_args', '.', 'setdefault', '(', ',', ')', '\\n']
Tokenized   (020): ['[CLS]', 'sql', '##ite', '_', 'di', '##ct', '_', 'ar', '##gs', '.', 'set', '##de', '##fa', '##ult', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['sql', '##ite', '_', 'di', '##ct', '_', 'ar', '##gs', '.', 'set', '##de', '##fa', '##ult', '(', ',', ')', '\\', 'n']
Detokenized (007): ['sql##ite_di##ct_ar##gs', '.', 'set##de##fa##ult', '(', ',', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ll_1 = ll_0 + n_samples - k - 1 \n"
Original    (010): ['ll_1', '=', 'll_0', '+', 'n_samples', '-', 'k', '-', '1', '\\n']
Tokenized   (019): ['[CLS]', 'll', '_', '1', '=', 'll', '_', '0', '+', 'n', '_', 'samples', '-', 'k', '-', '1', '\\', 'n', '[SEP]']
Filtered   (017): ['ll', '_', '1', '=', 'll', '_', '0', '+', 'n', '_', 'samples', '-', 'k', '-', '1', '\\', 'n']
Detokenized (010): ['ll_1', '=', 'll_0', '+', 'n_samples', '-', 'k', '-', '1', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "D = self . D [ lvl ] \n"
Original    (009): ['D', '=', 'self', '.', 'D', '[', 'lvl', ']', '\\n']
Tokenized   (014): ['[CLS]', 'd', '=', 'self', '.', 'd', '[', 'l', '##v', '##l', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['d', '=', 'self', '.', 'd', '[', 'l', '##v', '##l', ']', '\\', 'n']
Detokenized (009): ['d', '=', 'self', '.', 'd', '[', 'l##v##l', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "initial_range = INITIAL_RANGE_DEFAULT , tol = TOLERANCE_DEFAULT ) : \n"
Original    (010): ['initial_range', '=', 'INITIAL_RANGE_DEFAULT', ',', 'tol', '=', 'TOLERANCE_DEFAULT', ')', ':', '\\n']
Tokenized   (022): ['[CLS]', 'initial', '_', 'range', '=', 'initial', '_', 'range', '_', 'default', ',', 'to', '##l', '=', 'tolerance', '_', 'default', ')', ':', '\\', 'n', '[SEP]']
Filtered   (020): ['initial', '_', 'range', '=', 'initial', '_', 'range', '_', 'default', ',', 'to', '##l', '=', 'tolerance', '_', 'default', ')', ':', '\\', 'n']
Detokenized (010): ['initial_range', '=', 'initial_range_default', ',', 'to##l', '=', 'tolerance_default', ')', ':', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "y_best = y [ nlevel - 1 ] \n"
Original    (009): ['y_best', '=', 'y', '[', 'nlevel', '-', '1', ']', '\\n']
Tokenized   (016): ['[CLS]', 'y', '_', 'best', '=', 'y', '[', 'nl', '##eve', '##l', '-', '1', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['y', '_', 'best', '=', 'y', '[', 'nl', '##eve', '##l', '-', '1', ']', '\\', 'n']
Detokenized (009): ['y_best', '=', 'y', '[', 'nl##eve##l', '-', '1', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "+ str ( theta ) ) \n"
Original    (007): ['+', 'str', '(', 'theta', ')', ')', '\\n']
Tokenized   (011): ['[CLS]', '+', 'st', '##r', '(', 'theta', ')', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['+', 'st', '##r', '(', 'theta', ')', ')', '\\', 'n']
Detokenized (007): ['+', 'st##r', '(', 'theta', ')', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Yt = solve_triangular ( C , y , lower = True ) \n"
Original    (013): ['Yt', '=', 'solve_triangular', '(', 'C', ',', 'y', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (019): ['[CLS]', 'y', '##t', '=', 'solve', '_', 'triangular', '(', 'c', ',', 'y', ',', 'lower', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['y', '##t', '=', 'solve', '_', 'triangular', '(', 'c', ',', 'y', ',', 'lower', '=', 'true', ')', '\\', 'n']
Detokenized (013): ['y##t', '=', 'solve_triangular', '(', 'c', ',', 'y', ',', 'lower', '=', 'true', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "err2 = np . dot ( err . T , err ) [ 0 , 0 ] \n"
Original    (018): ['err2', '=', 'np', '.', 'dot', '(', 'err', '.', 'T', ',', 'err', ')', '[', '0', ',', '0', ']', '\\n']
Tokenized   (025): ['[CLS]', 'er', '##r', '##2', '=', 'np', '.', 'dot', '(', 'er', '##r', '.', 't', ',', 'er', '##r', ')', '[', '0', ',', '0', ']', '\\', 'n', '[SEP]']
Filtered   (023): ['er', '##r', '##2', '=', 'np', '.', 'dot', '(', 'er', '##r', '.', 't', ',', 'er', '##r', ')', '[', '0', ',', '0', ']', '\\', 'n']
Detokenized (018): ['er##r##2', '=', 'np', '.', 'dot', '(', 'er##r', '.', 't', ',', 'er##r', ')', '[', '0', ',', '0', ']', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "sigma2 = err2 / ( n_samples - p - q ) \n"
Original    (012): ['sigma2', '=', 'err2', '/', '(', 'n_samples', '-', 'p', '-', 'q', ')', '\\n']
Tokenized   (020): ['[CLS]', 'sigma', '##2', '=', 'er', '##r', '##2', '/', '(', 'n', '_', 'samples', '-', 'p', '-', 'q', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['sigma', '##2', '=', 'er', '##r', '##2', '/', '(', 'n', '_', 'samples', '-', 'p', '-', 'q', ')', '\\', 'n']
Detokenized (012): ['sigma##2', '=', 'er##r##2', '/', '(', 'n_samples', '-', 'p', '-', 'q', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "detR = ( ( np . diag ( C ) ) ** ( 2. / n_samples ) ) . prod ( ) \n"
Original    (023): ['detR', '=', '(', '(', 'np', '.', 'diag', '(', 'C', ')', ')', '**', '(', '2.', '/', 'n_samples', ')', ')', '.', 'prod', '(', ')', '\\n']
Tokenized   (033): ['[CLS]', 'det', '##r', '=', '(', '(', 'np', '.', 'dia', '##g', '(', 'c', ')', ')', '*', '*', '(', '2', '.', '/', 'n', '_', 'samples', ')', ')', '.', 'pro', '##d', '(', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['det', '##r', '=', '(', '(', 'np', '.', 'dia', '##g', '(', 'c', ')', ')', '*', '*', '(', '2', '.', '/', 'n', '_', 'samples', ')', ')', '.', 'pro', '##d', '(', ')', '\\', 'n']
Detokenized (023): ['det##r', '=', '(', '(', 'np', '.', 'dia##g', '(', 'c', ')', ')', '**', '(', '2.', '/', 'n_samples', ')', ')', '.', 'pro##d', '(', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "rlf_value = ( n_samples - p - q ) * np . log10 ( sigma2 ) + n_samples * np . log10 ( detR ) \n"
Original    (026): ['rlf_value', '=', '(', 'n_samples', '-', 'p', '-', 'q', ')', '*', 'np', '.', 'log10', '(', 'sigma2', ')', '+', 'n_samples', '*', 'np', '.', 'log10', '(', 'detR', ')', '\\n']
Tokenized   (040): ['[CLS]', 'r', '##lf', '_', 'value', '=', '(', 'n', '_', 'samples', '-', 'p', '-', 'q', ')', '*', 'np', '.', 'log', '##10', '(', 'sigma', '##2', ')', '+', 'n', '_', 'samples', '*', 'np', '.', 'log', '##10', '(', 'det', '##r', ')', '\\', 'n', '[SEP]']
Filtered   (038): ['r', '##lf', '_', 'value', '=', '(', 'n', '_', 'samples', '-', 'p', '-', 'q', ')', '*', 'np', '.', 'log', '##10', '(', 'sigma', '##2', ')', '+', 'n', '_', 'samples', '*', 'np', '.', 'log', '##10', '(', 'det', '##r', ')', '\\', 'n']
Detokenized (026): ['r##lf_value', '=', '(', 'n_samples', '-', 'p', '-', 'q', ')', '*', 'np', '.', 'log##10', '(', 'sigma##2', ')', '+', 'n_samples', '*', 'np', '.', 'log##10', '(', 'det##r', ')', '\\n']
Counter: 38
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "log10t [ i ] - np . log10 ( thetaL [ 0 ] [ i ] ) } ) \n"
Original    (020): ['log10t', '[', 'i', ']', '-', 'np', '.', 'log10', '(', 'thetaL', '[', '0', ']', '[', 'i', ']', ')', '}', ')', '\\n']
Tokenized   (027): ['[CLS]', 'log', '##10', '##t', '[', 'i', ']', '-', 'np', '.', 'log', '##10', '(', 'theta', '##l', '[', '0', ']', '[', 'i', ']', ')', '}', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['log', '##10', '##t', '[', 'i', ']', '-', 'np', '.', 'log', '##10', '(', 'theta', '##l', '[', '0', ']', '[', 'i', ']', ')', '}', ')', '\\', 'n']
Detokenized (020): ['log##10##t', '[', 'i', ']', '-', 'np', '.', 'log##10', '(', 'theta##l', '[', '0', ']', '[', 'i', ']', ')', '}', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "np . log10 ( thetaU [ 0 ] [ i ] ) - log10t [ i ] } ) \n"
Original    (020): ['np', '.', 'log10', '(', 'thetaU', '[', '0', ']', '[', 'i', ']', ')', '-', 'log10t', '[', 'i', ']', '}', ')', '\\n']
Tokenized   (027): ['[CLS]', 'np', '.', 'log', '##10', '(', 'theta', '##u', '[', '0', ']', '[', 'i', ']', ')', '-', 'log', '##10', '##t', '[', 'i', ']', '}', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['np', '.', 'log', '##10', '(', 'theta', '##u', '[', '0', ']', '[', 'i', ']', ')', '-', 'log', '##10', '##t', '[', 'i', ']', '}', ')', '\\', 'n']
Detokenized (020): ['np', '.', 'log##10', '(', 'theta##u', '[', '0', ']', '[', 'i', ']', ')', '-', 'log##10##t', '[', 'i', ']', '}', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "sol = minimize ( rlf_transform , x0 , method = , \n"
Original    (012): ['sol', '=', 'minimize', '(', 'rlf_transform', ',', 'x0', ',', 'method', '=', ',', '\\n']
Tokenized   (019): ['[CLS]', 'sol', '=', 'minimize', '(', 'r', '##lf', '_', 'transform', ',', 'x', '##0', ',', 'method', '=', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['sol', '=', 'minimize', '(', 'r', '##lf', '_', 'transform', ',', 'x', '##0', ',', 'method', '=', ',', '\\', 'n']
Detokenized (012): ['sol', '=', 'minimize', '(', 'r##lf_transform', ',', 'x##0', ',', 'method', '=', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "optimal_theta = 10. ** log10_optimal_x \n"
Original    (006): ['optimal_theta', '=', '10.', '**', 'log10_optimal_x', '\\n']
Tokenized   (018): ['[CLS]', 'optimal', '_', 'theta', '=', '10', '.', '*', '*', 'log', '##10', '_', 'optimal', '_', 'x', '\\', 'n', '[SEP]']
Filtered   (016): ['optimal', '_', 'theta', '=', '10', '.', '*', '*', 'log', '##10', '_', 'optimal', '_', 'x', '\\', 'n']
Detokenized (006): ['optimal_theta', '=', '10.', '**', 'log##10_optimal_x', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "r_t = solve_triangular ( C , r_ . T , lower = True ) \n"
Original    (015): ['r_t', '=', 'solve_triangular', '(', 'C', ',', 'r_', '.', 'T', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (023): ['[CLS]', 'r', '_', 't', '=', 'solve', '_', 'triangular', '(', 'c', ',', 'r', '_', '.', 't', ',', 'lower', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['r', '_', 't', '=', 'solve', '_', 'triangular', '(', 'c', ',', 'r', '_', '.', 't', ',', 'lower', '=', 'true', ')', '\\', 'n']
Detokenized (015): ['r_t', '=', 'solve_triangular', '(', 'c', ',', 'r_', '.', 't', ',', 'lower', '=', 'true', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "dx = l1_cross_distances ( X , Y = self . X [ i ] ) \n"
Original    (016): ['dx', '=', 'l1_cross_distances', '(', 'X', ',', 'Y', '=', 'self', '.', 'X', '[', 'i', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'd', '##x', '=', 'l', '##1', '_', 'cross', '_', 'distances', '(', 'x', ',', 'y', '=', 'self', '.', 'x', '[', 'i', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['d', '##x', '=', 'l', '##1', '_', 'cross', '_', 'distances', '(', 'x', ',', 'y', '=', 'self', '.', 'x', '[', 'i', ']', ')', '\\', 'n']
Detokenized (016): ['d##x', '=', 'l##1_cross_distances', '(', 'x', ',', 'y', '=', 'self', '.', 'x', '[', 'i', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "r_ = self . corr ( self . theta [ i ] , dx ) . reshape ( n_eval , self . n_samples [ i ] ) \n"
Original    (028): ['r_', '=', 'self', '.', 'corr', '(', 'self', '.', 'theta', '[', 'i', ']', ',', 'dx', ')', '.', 'reshape', '(', 'n_eval', ',', 'self', '.', 'n_samples', '[', 'i', ']', ')', '\\n']
Tokenized   (041): ['[CLS]', 'r', '_', '=', 'self', '.', 'co', '##rr', '(', 'self', '.', 'theta', '[', 'i', ']', ',', 'd', '##x', ')', '.', 'res', '##ha', '##pe', '(', 'n', '_', 'eva', '##l', ',', 'self', '.', 'n', '_', 'samples', '[', 'i', ']', ')', '\\', 'n', '[SEP]']
Filtered   (039): ['r', '_', '=', 'self', '.', 'co', '##rr', '(', 'self', '.', 'theta', '[', 'i', ']', ',', 'd', '##x', ')', '.', 'res', '##ha', '##pe', '(', 'n', '_', 'eva', '##l', ',', 'self', '.', 'n', '_', 'samples', '[', 'i', ']', ')', '\\', 'n']
Detokenized (028): ['r_', '=', 'self', '.', 'co##rr', '(', 'self', '.', 'theta', '[', 'i', ']', ',', 'd##x', ')', '.', 'res##ha##pe', '(', 'n_eva##l', ',', 'self', '.', 'n_samples', '[', 'i', ']', ')', '\\n']
Counter: 39
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "yt = solve_triangular ( C , self . y [ i ] , lower = True ) \n"
Original    (018): ['yt', '=', 'solve_triangular', '(', 'C', ',', 'self', '.', 'y', '[', 'i', ']', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (024): ['[CLS]', 'y', '##t', '=', 'solve', '_', 'triangular', '(', 'c', ',', 'self', '.', 'y', '[', 'i', ']', ',', 'lower', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['y', '##t', '=', 'solve', '_', 'triangular', '(', 'c', ',', 'self', '.', 'y', '[', 'i', ']', ',', 'lower', '=', 'true', ')', '\\', 'n']
Detokenized (018): ['y##t', '=', 'solve_triangular', '(', 'c', ',', 'self', '.', 'y', '[', 'i', ']', ',', 'lower', '=', 'true', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "mu [ : , i ] = ( np . dot ( f . T , beta ) + np . dot ( r_t . T , yt - np . dot ( Ft , beta ) ) ) . ravel ( ) \n"
Original    (044): ['mu', '[', ':', ',', 'i', ']', '=', '(', 'np', '.', 'dot', '(', 'f', '.', 'T', ',', 'beta', ')', '+', 'np', '.', 'dot', '(', 'r_t', '.', 'T', ',', 'yt', '-', 'np', '.', 'dot', '(', 'Ft', ',', 'beta', ')', ')', ')', '.', 'ravel', '(', ')', '\\n']
Tokenized   (051): ['[CLS]', 'mu', '[', ':', ',', 'i', ']', '=', '(', 'np', '.', 'dot', '(', 'f', '.', 't', ',', 'beta', ')', '+', 'np', '.', 'dot', '(', 'r', '_', 't', '.', 't', ',', 'y', '##t', '-', 'np', '.', 'dot', '(', 'ft', ',', 'beta', ')', ')', ')', '.', 'rave', '##l', '(', ')', '\\', 'n', '[SEP]']
Filtered   (049): ['mu', '[', ':', ',', 'i', ']', '=', '(', 'np', '.', 'dot', '(', 'f', '.', 't', ',', 'beta', ')', '+', 'np', '.', 'dot', '(', 'r', '_', 't', '.', 't', ',', 'y', '##t', '-', 'np', '.', 'dot', '(', 'ft', ',', 'beta', ')', ')', ')', '.', 'rave', '##l', '(', ')', '\\', 'n']
Detokenized (044): ['mu', '[', ':', ',', 'i', ']', '=', '(', 'np', '.', 'dot', '(', 'f', '.', 't', ',', 'beta', ')', '+', 'np', '.', 'dot', '(', 'r_t', '.', 't', ',', 'y##t', '-', 'np', '.', 'dot', '(', 'ft', ',', 'beta', ')', ')', ')', '.', 'rave##l', '(', ')', '\\n']
Counter: 49
===================================================================
Hidden states:  (13, 44, 768)
# Extracted words:  44
Sentence         : "u_ = solve_triangular ( G . T , f - np . dot ( Ft . T , r_t ) , lower = True ) \n"
Original    (026): ['u_', '=', 'solve_triangular', '(', 'G', '.', 'T', ',', 'f', '-', 'np', '.', 'dot', '(', 'Ft', '.', 'T', ',', 'r_t', ')', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (034): ['[CLS]', 'u', '_', '=', 'solve', '_', 'triangular', '(', 'g', '.', 't', ',', 'f', '-', 'np', '.', 'dot', '(', 'ft', '.', 't', ',', 'r', '_', 't', ')', ',', 'lower', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['u', '_', '=', 'solve', '_', 'triangular', '(', 'g', '.', 't', ',', 'f', '-', 'np', '.', 'dot', '(', 'ft', '.', 't', ',', 'r', '_', 't', ')', ',', 'lower', '=', 'true', ')', '\\', 'n']
Detokenized (026): ['u_', '=', 'solve_triangular', '(', 'g', '.', 't', ',', 'f', '-', 'np', '.', 'dot', '(', 'ft', '.', 't', ',', 'r_t', ')', ',', 'lower', '=', 'true', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "sigma2_rho = ( sigma2_rho * g ) . sum ( axis = 1 ) \n"
Original    (015): ['sigma2_rho', '=', '(', 'sigma2_rho', '*', 'g', ')', '.', 'sum', '(', 'axis', '=', '1', ')', '\\n']
Tokenized   (026): ['[CLS]', 'sigma', '##2', '_', 'r', '##ho', '=', '(', 'sigma', '##2', '_', 'r', '##ho', '*', 'g', ')', '.', 'sum', '(', 'axis', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['sigma', '##2', '_', 'r', '##ho', '=', '(', 'sigma', '##2', '_', 'r', '##ho', '*', 'g', ')', '.', 'sum', '(', 'axis', '=', '1', ')', '\\', 'n']
Detokenized (015): ['sigma##2_r##ho', '=', '(', 'sigma##2_r##ho', '*', 'g', ')', '.', 'sum', '(', 'axis', '=', '1', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "MSE [ : , i ] = sigma2_rho * MSE [ : , i - 1 ] + Q_ / ( 2 * ( self . n_samples [ i ] - self . p [ i ] - self . q [ i ] ) ) * ( 1 - ( r_t ** 2 ) . sum ( axis = 0 ) ) + self . sigma2 [ i ] * ( u_ ** 2 ) . sum ( axis = 0 ) \n"
Original    (084): ['MSE', '[', ':', ',', 'i', ']', '=', 'sigma2_rho', '*', 'MSE', '[', ':', ',', 'i', '-', '1', ']', '+', 'Q_', '/', '(', '2', '*', '(', 'self', '.', 'n_samples', '[', 'i', ']', '-', 'self', '.', 'p', '[', 'i', ']', '-', 'self', '.', 'q', '[', 'i', ']', ')', ')', '*', '(', '1', '-', '(', 'r_t', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', ')', '+', 'self', '.', 'sigma2', '[', 'i', ']', '*', '(', 'u_', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', '\\n']
Tokenized   (102): ['[CLS]', 'ms', '##e', '[', ':', ',', 'i', ']', '=', 'sigma', '##2', '_', 'r', '##ho', '*', 'ms', '##e', '[', ':', ',', 'i', '-', '1', ']', '+', 'q', '_', '/', '(', '2', '*', '(', 'self', '.', 'n', '_', 'samples', '[', 'i', ']', '-', 'self', '.', 'p', '[', 'i', ']', '-', 'self', '.', 'q', '[', 'i', ']', ')', ')', '*', '(', '1', '-', '(', 'r', '_', 't', '*', '*', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', ')', '+', 'self', '.', 'sigma', '##2', '[', 'i', ']', '*', '(', 'u', '_', '*', '*', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (100): ['ms', '##e', '[', ':', ',', 'i', ']', '=', 'sigma', '##2', '_', 'r', '##ho', '*', 'ms', '##e', '[', ':', ',', 'i', '-', '1', ']', '+', 'q', '_', '/', '(', '2', '*', '(', 'self', '.', 'n', '_', 'samples', '[', 'i', ']', '-', 'self', '.', 'p', '[', 'i', ']', '-', 'self', '.', 'q', '[', 'i', ']', ')', ')', '*', '(', '1', '-', '(', 'r', '_', 't', '*', '*', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', ')', '+', 'self', '.', 'sigma', '##2', '[', 'i', ']', '*', '(', 'u', '_', '*', '*', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', '\\', 'n']
Detokenized (084): ['ms##e', '[', ':', ',', 'i', ']', '=', 'sigma##2_r##ho', '*', 'ms##e', '[', ':', ',', 'i', '-', '1', ']', '+', 'q_', '/', '(', '2', '*', '(', 'self', '.', 'n_samples', '[', 'i', ']', '-', 'self', '.', 'p', '[', 'i', ']', '-', 'self', '.', 'q', '[', 'i', ']', ')', ')', '*', '(', '1', '-', '(', 'r_t', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', ')', '+', 'self', '.', 'sigma##2', '[', 'i', ']', '*', '(', 'u_', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', '\\n']
Counter: 100
===================================================================
Hidden states:  (13, 84, 768)
# Extracted words:  84
Sentence         : "n_features = np . zeros ( nlevel , dtype = int ) \n"
Original    (013): ['n_features', '=', 'np', '.', 'zeros', '(', 'nlevel', ',', 'dtype', '=', 'int', ')', '\\n']
Tokenized   (022): ['[CLS]', 'n', '_', 'features', '=', 'np', '.', 'zero', '##s', '(', 'nl', '##eve', '##l', ',', 'dt', '##ype', '=', 'int', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['n', '_', 'features', '=', 'np', '.', 'zero', '##s', '(', 'nl', '##eve', '##l', ',', 'dt', '##ype', '=', 'int', ')', '\\', 'n']
Detokenized (013): ['n_features', '=', 'np', '.', 'zero##s', '(', 'nl##eve##l', ',', 'dt##ype', '=', 'int', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "n_samples_y [ i ] = y [ i ] . shape [ 0 ] \n"
Original    (015): ['n_samples_y', '[', 'i', ']', '=', 'y', '[', 'i', ']', '.', 'shape', '[', '0', ']', '\\n']
Tokenized   (022): ['[CLS]', 'n', '_', 'samples', '_', 'y', '[', 'i', ']', '=', 'y', '[', 'i', ']', '.', 'shape', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (020): ['n', '_', 'samples', '_', 'y', '[', 'i', ']', '=', 'y', '[', 'i', ']', '.', 'shape', '[', '0', ']', '\\', 'n']
Detokenized (015): ['n_samples_y', '[', 'i', ']', '=', 'y', '[', 'i', ']', '.', 'shape', '[', '0', ']', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "Y_pred , MSE = self . model . predict ( [ new_x ] ) \n"
Original    (015): ['Y_pred', ',', 'MSE', '=', 'self', '.', 'model', '.', 'predict', '(', '[', 'new_x', ']', ')', '\\n']
Tokenized   (024): ['[CLS]', 'y', '_', 'pre', '##d', ',', 'ms', '##e', '=', 'self', '.', 'model', '.', 'predict', '(', '[', 'new', '_', 'x', ']', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['y', '_', 'pre', '##d', ',', 'ms', '##e', '=', 'self', '.', 'model', '.', 'predict', '(', '[', 'new', '_', 'x', ']', ')', '\\', 'n']
Detokenized (015): ['y_pre##d', ',', 'ms##e', '=', 'self', '.', 'model', '.', 'predict', '(', '[', 'new_x', ']', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "X , Y = self . _fit_adapter ( X , Y ) \n"
Original    (013): ['X', ',', 'Y', '=', 'self', '.', '_fit_adapter', '(', 'X', ',', 'Y', ')', '\\n']
Tokenized   (020): ['[CLS]', 'x', ',', 'y', '=', 'self', '.', '_', 'fit', '_', 'adapt', '##er', '(', 'x', ',', 'y', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['x', ',', 'y', '=', 'self', '.', '_', 'fit', '_', 'adapt', '##er', '(', 'x', ',', 'y', ')', '\\', 'n']
Detokenized (013): ['x', ',', 'y', '=', 'self', '.', '_fit_adapt##er', '(', 'x', ',', 'y', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Y = [ np . array ( y ) for y in reversed ( Y ) ] \n"
Original    (018): ['Y', '=', '[', 'np', '.', 'array', '(', 'y', ')', 'for', 'y', 'in', 'reversed', '(', 'Y', ')', ']', '\\n']
Tokenized   (021): ['[CLS]', 'y', '=', '[', 'np', '.', 'array', '(', 'y', ')', 'for', 'y', 'in', 'reversed', '(', 'y', ')', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['y', '=', '[', 'np', '.', 'array', '(', 'y', ')', 'for', 'y', 'in', 'reversed', '(', 'y', ')', ']', '\\', 'n']
Detokenized (018): ['y', '=', '[', 'np', '.', 'array', '(', 'y', ')', 'for', 'y', 'in', 'reversed', '(', 'y', ')', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "newdata = np . array ( parsed [ : ] ) \n"
Original    (012): ['newdata', '=', 'np', '.', 'array', '(', 'parsed', '[', ':', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'new', '##da', '##ta', '=', 'np', '.', 'array', '(', 'par', '##sed', '[', ':', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['new', '##da', '##ta', '=', 'np', '.', 'array', '(', 'par', '##sed', '[', ':', ']', ')', '\\', 'n']
Detokenized (012): ['new##da##ta', '=', 'np', '.', 'array', '(', 'par##sed', '[', ':', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "icc . DB_USER ) , shell = True ) \n"
Original    (010): ['icc', '.', 'DB_USER', ')', ',', 'shell', '=', 'True', ')', '\\n']
Tokenized   (015): ['[CLS]', 'icc', '.', 'db', '_', 'user', ')', ',', 'shell', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['icc', '.', 'db', '_', 'user', ')', ',', 'shell', '=', 'true', ')', '\\', 'n']
Detokenized (010): ['icc', '.', 'db_user', ')', ',', 'shell', '=', 'true', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "instance_db_name , shell = True ) \n"
Original    (007): ['instance_db_name', ',', 'shell', '=', 'True', ')', '\\n']
Tokenized   (014): ['[CLS]', 'instance', '_', 'db', '_', 'name', ',', 'shell', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['instance', '_', 'db', '_', 'name', ',', 'shell', '=', 'true', ')', '\\', 'n']
Detokenized (007): ['instance_db_name', ',', 'shell', '=', 'true', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "customslide = CustomSlide . objects . create ( title = , text = default_projector = Projector . objects . get ( pk = 1 ) \n"
Original    (026): ['customslide', '=', 'CustomSlide', '.', 'objects', '.', 'create', '(', 'title', '=', ',', 'text', '=', 'default_projector', '=', 'Projector', '.', 'objects', '.', 'get', '(', 'pk', '=', '1', ')', '\\n']
Tokenized   (036): ['[CLS]', 'customs', '##lide', '=', 'customs', '##lide', '.', 'objects', '.', 'create', '(', 'title', '=', ',', 'text', '=', 'default', '_', 'project', '##or', '=', 'project', '##or', '.', 'objects', '.', 'get', '(', 'p', '##k', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['customs', '##lide', '=', 'customs', '##lide', '.', 'objects', '.', 'create', '(', 'title', '=', ',', 'text', '=', 'default', '_', 'project', '##or', '=', 'project', '##or', '.', 'objects', '.', 'get', '(', 'p', '##k', '=', '1', ')', '\\', 'n']
Detokenized (026): ['customs##lide', '=', 'customs##lide', '.', 'objects', '.', 'create', '(', 'title', '=', ',', 'text', '=', 'default_project##or', '=', 'project##or', '.', 'objects', '.', 'get', '(', 'p##k', '=', '1', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "default_projector = Projector . objects . get ( pk = 1 ) \n"
Original    (013): ['default_projector', '=', 'Projector', '.', 'objects', '.', 'get', '(', 'pk', '=', '1', ')', '\\n']
Tokenized   (021): ['[CLS]', 'default', '_', 'project', '##or', '=', 'project', '##or', '.', 'objects', '.', 'get', '(', 'p', '##k', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['default', '_', 'project', '##or', '=', 'project', '##or', '.', 'objects', '.', 'get', '(', 'p', '##k', '=', '1', ')', '\\', 'n']
Detokenized (013): ['default_project##or', '=', 'project##or', '.', 'objects', '.', 'get', '(', 'p##k', '=', '1', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "reverse ( , args = [ ] ) ) \n"
Original    (010): ['reverse', '(', ',', 'args', '=', '[', ']', ')', ')', '\\n']
Tokenized   (014): ['[CLS]', 'reverse', '(', ',', 'ar', '##gs', '=', '[', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['reverse', '(', ',', 'ar', '##gs', '=', '[', ']', ')', ')', '\\', 'n']
Detokenized (010): ['reverse', '(', ',', 'ar##gs', '=', '[', ']', ')', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "yield ConfigVariable ( \n"
Original    (004): ['yield', 'ConfigVariable', '(', '\\n']
Tokenized   (011): ['[CLS]', 'yield', 'con', '##fi', '##g', '##var', '##iable', '(', '\\', 'n', '[SEP]']
Filtered   (009): ['yield', 'con', '##fi', '##g', '##var', '##iable', '(', '\\', 'n']
Detokenized (004): ['yield', 'con##fi##g##var##iable', '(', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "{ : , : } , { : , : } ) \n"
Original    (013): ['{', ':', ',', ':', '}', ',', '{', ':', ',', ':', '}', ')', '\\n']
Tokenized   (016): ['[CLS]', '{', ':', ',', ':', '}', ',', '{', ':', ',', ':', '}', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['{', ':', ',', ':', '}', ',', '{', ':', ',', ':', '}', ')', '\\', 'n']
Detokenized (013): ['{', ':', ',', ':', '}', ',', '{', ':', ',', ':', '}', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "validators = ( validator_for_testing , ) ) \n"
Original    (008): ['validators', '=', '(', 'validator_for_testing', ',', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 'valid', '##ators', '=', '(', 'valid', '##ator', '_', 'for', '_', 'testing', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['valid', '##ators', '=', '(', 'valid', '##ator', '_', 'for', '_', 'testing', ',', ')', ')', '\\', 'n']
Detokenized (008): ['valid##ators', '=', '(', 'valid##ator_for_testing', ',', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "generate_username . return_value = \n"
Original    (005): ['generate_username', '.', 'return_value', '=', '\\n']
Tokenized   (013): ['[CLS]', 'generate', '_', 'user', '##name', '.', 'return', '_', 'value', '=', '\\', 'n', '[SEP]']
Filtered   (011): ['generate', '_', 'user', '##name', '.', 'return', '_', 'value', '=', '\\', 'n']
Detokenized (005): ['generate_user##name', '.', 'return_value', '=', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "serializer = UserFullSerializer ( context = { : view } ) \n"
Original    (012): ['serializer', '=', 'UserFullSerializer', '(', 'context', '=', '{', ':', 'view', '}', ')', '\\n']
Tokenized   (020): ['[CLS]', 'serial', '##izer', '=', 'user', '##ful', '##ls', '##eria', '##lizer', '(', 'context', '=', '{', ':', 'view', '}', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['serial', '##izer', '=', 'user', '##ful', '##ls', '##eria', '##lizer', '(', 'context', '=', '{', ':', 'view', '}', ')', '\\', 'n']
Detokenized (012): ['serial##izer', '=', 'user##ful##ls##eria##lizer', '(', 'context', '=', '{', ':', 'view', '}', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "#domain... #localhost... \n"
Original    (003): ['#domain...', '#localhost...', '\\n']
Tokenized   (016): ['[CLS]', '#', 'domain', '.', '.', '.', '#', 'local', '##hos', '##t', '.', '.', '.', '\\', 'n', '[SEP]']
Filtered   (014): ['#', 'domain', '.', '.', '.', '#', 'local', '##hos', '##t', '.', '.', '.', '\\', 'n']
Detokenized (003): ['#domain...', '#local##hos##t...', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "USERNAME_REGEX = re . compile ( , re . I ) \n"
Original    (012): ['USERNAME_REGEX', '=', 're', '.', 'compile', '(', ',', 're', '.', 'I', ')', '\\n']
Tokenized   (020): ['[CLS]', 'user', '##name', '_', 'reg', '##ex', '=', 're', '.', 'com', '##pile', '(', ',', 're', '.', 'i', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['user', '##name', '_', 'reg', '##ex', '=', 're', '.', 'com', '##pile', '(', ',', 're', '.', 'i', ')', '\\', 'n']
Detokenized (012): ['user##name_reg##ex', '=', 're', '.', 'com##pile', '(', ',', 're', '.', 'i', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "RouteDistinguisher . TYPE_IP_LOC , None , \n"
Original    (007): ['RouteDistinguisher', '.', 'TYPE_IP_LOC', ',', 'None', ',', '\\n']
Tokenized   (019): ['[CLS]', 'routed', '##ist', '##ing', '##uis', '##her', '.', 'type', '_', 'ip', '_', 'lo', '##c', ',', 'none', ',', '\\', 'n', '[SEP]']
Filtered   (017): ['routed', '##ist', '##ing', '##uis', '##her', '.', 'type', '_', 'ip', '_', 'lo', '##c', ',', 'none', ',', '\\', 'n']
Detokenized (007): ['routed##ist##ing##uis##her', '.', 'type_ip_lo##c', ',', 'none', ',', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "10000 + label ) \n"
Original    (005): ['10000', '+', 'label', ')', '\\n']
Tokenized   (009): ['[CLS]', '1000', '##0', '+', 'label', ')', '\\', 'n', '[SEP]']
Filtered   (007): ['1000', '##0', '+', 'label', ')', '\\', 'n']
Detokenized (005): ['1000##0', '+', 'label', ')', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "nh = Inet ( 1 , socket . inet_pton ( socket . AF_INET , \n"
Original    (015): ['nh', '=', 'Inet', '(', '1', ',', 'socket', '.', 'inet_pton', '(', 'socket', '.', 'AF_INET', ',', '\\n']
Tokenized   (026): ['[CLS]', 'nh', '=', 'in', '##et', '(', '1', ',', 'socket', '.', 'in', '##et', '_', 'pt', '##on', '(', 'socket', '.', 'af', '_', 'in', '##et', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['nh', '=', 'in', '##et', '(', '1', ',', 'socket', '.', 'in', '##et', '_', 'pt', '##on', '(', 'socket', '.', 'af', '_', 'in', '##et', ',', '\\', 'n']
Detokenized (015): ['nh', '=', 'in##et', '(', '1', ',', 'socket', '.', 'in##et_pt##on', '(', 'socket', '.', 'af_in##et', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "route . attributes . add ( ECommunities ( self . readvertiseToRTs ) ) \n"
Original    (014): ['route', '.', 'attributes', '.', 'add', '(', 'ECommunities', '(', 'self', '.', 'readvertiseToRTs', ')', ')', '\\n']
Tokenized   (024): ['[CLS]', 'route', '.', 'attributes', '.', 'add', '(', 'eco', '##mm', '##uni', '##ties', '(', 'self', '.', 'read', '##vert', '##ise', '##tort', '##s', ')', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['route', '.', 'attributes', '.', 'add', '(', 'eco', '##mm', '##uni', '##ties', '(', 'self', '.', 'read', '##vert', '##ise', '##tort', '##s', ')', ')', '\\', 'n']
Detokenized (014): ['route', '.', 'attributes', '.', 'add', '(', 'eco##mm##uni##ties', '(', 'self', '.', 'read##vert##ise##tort##s', ')', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "nlri . prefix , label ) \n"
Original    (007): ['nlri', '.', 'prefix', ',', 'label', ')', '\\n']
Tokenized   (011): ['[CLS]', 'nl', '##ri', '.', 'prefix', ',', 'label', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['nl', '##ri', '.', 'prefix', ',', 'label', ')', '\\', 'n']
Detokenized (007): ['nl##ri', '.', 'prefix', ',', 'label', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "set ( self . importRTs ) ) ) > 0 ) \n"
Original    (012): ['set', '(', 'self', '.', 'importRTs', ')', ')', ')', '>', '0', ')', '\\n']
Tokenized   (016): ['[CLS]', 'set', '(', 'self', '.', 'import', '##rts', ')', ')', ')', '>', '0', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['set', '(', 'self', '.', 'import', '##rts', ')', ')', ')', '>', '0', ')', '\\', 'n']
Detokenized (012): ['set', '(', 'self', '.', 'import##rts', ')', ')', ')', '>', '0', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "newRoute . nlri . labelStack [ 0 ] . labelValue , newRoute . nlri , encaps ) \n"
Original    (018): ['newRoute', '.', 'nlri', '.', 'labelStack', '[', '0', ']', '.', 'labelValue', ',', 'newRoute', '.', 'nlri', ',', 'encaps', ')', '\\n']
Tokenized   (033): ['[CLS]', 'new', '##rou', '##te', '.', 'nl', '##ri', '.', 'labels', '##ta', '##ck', '[', '0', ']', '.', 'label', '##val', '##ue', ',', 'new', '##rou', '##te', '.', 'nl', '##ri', ',', 'en', '##cap', '##s', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['new', '##rou', '##te', '.', 'nl', '##ri', '.', 'labels', '##ta', '##ck', '[', '0', ']', '.', 'label', '##val', '##ue', ',', 'new', '##rou', '##te', '.', 'nl', '##ri', ',', 'en', '##cap', '##s', ')', '\\', 'n']
Detokenized (018): ['new##rou##te', '.', 'nl##ri', '.', 'labels##ta##ck', '[', '0', ']', '.', 'label##val##ue', ',', 'new##rou##te', '.', 'nl##ri', ',', 'en##cap##s', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "prefix , oldRoute . attributes . get ( NextHop . ID ) . next_hop , \n"
Original    (016): ['prefix', ',', 'oldRoute', '.', 'attributes', '.', 'get', '(', 'NextHop', '.', 'ID', ')', '.', 'next_hop', ',', '\\n']
Tokenized   (024): ['[CLS]', 'prefix', ',', 'old', '##rou', '##te', '.', 'attributes', '.', 'get', '(', 'next', '##hop', '.', 'id', ')', '.', 'next', '_', 'hop', ',', '\\', 'n', '[SEP]']
Filtered   (022): ['prefix', ',', 'old', '##rou', '##te', '.', 'attributes', '.', 'get', '(', 'next', '##hop', '.', 'id', ')', '.', 'next', '_', 'hop', ',', '\\', 'n']
Detokenized (016): ['prefix', ',', 'old##rou##te', '.', 'attributes', '.', 'get', '(', 'next##hop', '.', 'id', ')', '.', 'next_hop', ',', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "oldRoute . nlri . labelStack [ 0 ] . labelValue , oldRoute . nlri ) \n"
Original    (016): ['oldRoute', '.', 'nlri', '.', 'labelStack', '[', '0', ']', '.', 'labelValue', ',', 'oldRoute', '.', 'nlri', ')', '\\n']
Tokenized   (029): ['[CLS]', 'old', '##rou', '##te', '.', 'nl', '##ri', '.', 'labels', '##ta', '##ck', '[', '0', ']', '.', 'label', '##val', '##ue', ',', 'old', '##rou', '##te', '.', 'nl', '##ri', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['old', '##rou', '##te', '.', 'nl', '##ri', '.', 'labels', '##ta', '##ck', '[', '0', ']', '.', 'label', '##val', '##ue', ',', 'old', '##rou', '##te', '.', 'nl', '##ri', ')', '\\', 'n']
Detokenized (016): ['old##rou##te', '.', 'nl##ri', '.', 'labels##ta##ck', '[', '0', ']', '.', 'label##val##ue', ',', 'old##rou##te', '.', 'nl##ri', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""readvertised" : ( LGMap . VALUE , [ repr ( prefix ) for prefix in \n"
Original    (016): ['"readvertised"', ':', '(', 'LGMap', '.', 'VALUE', ',', '[', 'repr', '(', 'prefix', ')', 'for', 'prefix', 'in', '\\n']
Tokenized   (026): ['[CLS]', '"', 'read', '##vert', '##ised', '"', ':', '(', 'l', '##gm', '##ap', '.', 'value', ',', '[', 'rep', '##r', '(', 'prefix', ')', 'for', 'prefix', 'in', '\\', 'n', '[SEP]']
Filtered   (024): ['"', 'read', '##vert', '##ised', '"', ':', '(', 'l', '##gm', '##ap', '.', 'value', ',', '[', 'rep', '##r', '(', 'prefix', ')', 'for', 'prefix', 'in', '\\', 'n']
Detokenized (016): ['"read##vert##ised"', ':', '(', 'l##gm##ap', '.', 'value', ',', '[', 'rep##r', '(', 'prefix', ')', 'for', 'prefix', 'in', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "REACTORNAME = DEFAULT_REACTORS . get ( platform . system ( ) , ) \n"
Original    (014): ['REACTORNAME', '=', 'DEFAULT_REACTORS', '.', 'get', '(', 'platform', '.', 'system', '(', ')', ',', ')', '\\n']
Tokenized   (020): ['[CLS]', 'reactor', '##name', '=', 'default', '_', 'reactors', '.', 'get', '(', 'platform', '.', 'system', '(', ')', ',', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['reactor', '##name', '=', 'default', '_', 'reactors', '.', 'get', '(', 'platform', '.', 'system', '(', ')', ',', ')', '\\', 'n']
Detokenized (014): ['reactor##name', '=', 'default_reactors', '.', 'get', '(', 'platform', '.', 'system', '(', ')', ',', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "set_reactor = lambda : reactor \n"
Original    (006): ['set_reactor', '=', 'lambda', ':', 'reactor', '\\n']
Tokenized   (011): ['[CLS]', 'set', '_', 'reactor', '=', 'lambda', ':', 'reactor', '\\', 'n', '[SEP]']
Filtered   (009): ['set', '_', 'reactor', '=', 'lambda', ':', 'reactor', '\\', 'n']
Detokenized (006): ['set_reactor', '=', 'lambda', ':', 'reactor', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "SIGNALS = dict ( ( k , v ) for v , k in signal . __dict__ . iteritems ( ) if v . startswith ( ) and not v . startswith ( ) ) \n"
Original    (036): ['SIGNALS', '=', 'dict', '(', '(', 'k', ',', 'v', ')', 'for', 'v', ',', 'k', 'in', 'signal', '.', '__dict__', '.', 'iteritems', '(', ')', 'if', 'v', '.', 'startswith', '(', ')', 'and', 'not', 'v', '.', 'startswith', '(', ')', ')', '\\n']
Tokenized   (050): ['[CLS]', 'signals', '=', 'di', '##ct', '(', '(', 'k', ',', 'v', ')', 'for', 'v', ',', 'k', 'in', 'signal', '.', '_', '_', 'di', '##ct', '_', '_', '.', 'it', '##eri', '##tem', '##s', '(', ')', 'if', 'v', '.', 'starts', '##with', '(', ')', 'and', 'not', 'v', '.', 'starts', '##with', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (048): ['signals', '=', 'di', '##ct', '(', '(', 'k', ',', 'v', ')', 'for', 'v', ',', 'k', 'in', 'signal', '.', '_', '_', 'di', '##ct', '_', '_', '.', 'it', '##eri', '##tem', '##s', '(', ')', 'if', 'v', '.', 'starts', '##with', '(', ')', 'and', 'not', 'v', '.', 'starts', '##with', '(', ')', ')', '\\', 'n']
Detokenized (036): ['signals', '=', 'di##ct', '(', '(', 'k', ',', 'v', ')', 'for', 'v', ',', 'k', 'in', 'signal', '.', '__di##ct__', '.', 'it##eri##tem##s', '(', ')', 'if', 'v', '.', 'starts##with', '(', ')', 'and', 'not', 'v', '.', 'starts##with', '(', ')', ')', '\\n']
Counter: 48
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "pargs = ( self . name , self . label , self . reactor ) \n"
Original    (016): ['pargs', '=', '(', 'self', '.', 'name', ',', 'self', '.', 'label', ',', 'self', '.', 'reactor', ')', '\\n']
Tokenized   (020): ['[CLS]', 'par', '##gs', '=', '(', 'self', '.', 'name', ',', 'self', '.', 'label', ',', 'self', '.', 'reactor', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['par', '##gs', '=', '(', 'self', '.', 'name', ',', 'self', '.', 'label', ',', 'self', '.', 'reactor', ')', '\\', 'n']
Detokenized (016): ['par##gs', '=', '(', 'self', '.', 'name', ',', 'self', '.', 'label', ',', 'self', '.', 'reactor', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "* pargs , ** pkwargs \n"
Original    (006): ['*', 'pargs', ',', '**', 'pkwargs', '\\n']
Tokenized   (014): ['[CLS]', '*', 'par', '##gs', ',', '*', '*', 'p', '##k', '##war', '##gs', '\\', 'n', '[SEP]']
Filtered   (012): ['*', 'par', '##gs', ',', '*', '*', 'p', '##k', '##war', '##gs', '\\', 'n']
Detokenized (006): ['*', 'par##gs', ',', '**', 'p##k##war##gs', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "logdir = env . pop ( , os . path . join ( os . path . sep , ) ) \n"
Original    (022): ['logdir', '=', 'env', '.', 'pop', '(', ',', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'sep', ',', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'log', '##di', '##r', '=', 'en', '##v', '.', 'pop', '(', ',', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'sep', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['log', '##di', '##r', '=', 'en', '##v', '.', 'pop', '(', ',', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'sep', ',', ')', ')', '\\', 'n']
Detokenized (022): ['log##di##r', '=', 'en##v', '.', 'pop', '(', ',', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'sep', ',', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "masksignals = bool ( env . pop ( , True ) ) \n"
Original    (013): ['masksignals', '=', 'bool', '(', 'env', '.', 'pop', '(', ',', 'True', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'masks', '##ign', '##als', '=', 'boo', '##l', '(', 'en', '##v', '.', 'pop', '(', ',', 'true', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['masks', '##ign', '##als', '=', 'boo', '##l', '(', 'en', '##v', '.', 'pop', '(', ',', 'true', ')', ')', '\\', 'n']
Detokenized (013): ['masks##ign##als', '=', 'boo##l', '(', 'en##v', '.', 'pop', '(', ',', 'true', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "usetty = bool ( env . pop ( , ) ) \n"
Original    (012): ['usetty', '=', 'bool', '(', 'env', '.', 'pop', '(', ',', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'use', '##tty', '=', 'boo', '##l', '(', 'en', '##v', '.', 'pop', '(', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['use', '##tty', '=', 'boo', '##l', '(', 'en', '##v', '.', 'pop', '(', ',', ')', ')', '\\', 'n']
Detokenized (012): ['use##tty', '=', 'boo##l', '(', 'en##v', '.', 'pop', '(', ',', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "maxfd = resource . getrlimit ( resource . RLIMIT_NOFILE ) [ 1 ] \n"
Original    (014): ['maxfd', '=', 'resource', '.', 'getrlimit', '(', 'resource', '.', 'RLIMIT_NOFILE', ')', '[', '1', ']', '\\n']
Tokenized   (028): ['[CLS]', 'max', '##f', '##d', '=', 'resource', '.', 'get', '##rl', '##imi', '##t', '(', 'resource', '.', 'r', '##lim', '##it', '_', 'no', '##fi', '##le', ')', '[', '1', ']', '\\', 'n', '[SEP]']
Filtered   (026): ['max', '##f', '##d', '=', 'resource', '.', 'get', '##rl', '##imi', '##t', '(', 'resource', '.', 'r', '##lim', '##it', '_', 'no', '##fi', '##le', ')', '[', '1', ']', '\\', 'n']
Detokenized (014): ['max##f##d', '=', 'resource', '.', 'get##rl##imi##t', '(', 'resource', '.', 'r##lim##it_no##fi##le', ')', '[', '1', ']', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "hasattr ( os , "devnull" ) and os . devnull or "/dev/null" , \n"
Original    (014): ['hasattr', '(', 'os', ',', '"devnull"', ')', 'and', 'os', '.', 'devnull', 'or', '"/dev/null"', ',', '\\n']
Tokenized   (030): ['[CLS]', 'has', '##att', '##r', '(', 'os', ',', '"', 'dev', '##nu', '##ll', '"', ')', 'and', 'os', '.', 'dev', '##nu', '##ll', 'or', '"', '/', 'dev', '/', 'null', '"', ',', '\\', 'n', '[SEP]']
Filtered   (028): ['has', '##att', '##r', '(', 'os', ',', '"', 'dev', '##nu', '##ll', '"', ')', 'and', 'os', '.', 'dev', '##nu', '##ll', 'or', '"', '/', 'dev', '/', 'null', '"', ',', '\\', 'n']
Detokenized (014): ['has##att##r', '(', 'os', ',', '"dev##nu##ll"', ')', 'and', 'os', '.', 'dev##nu##ll', 'or', '"/dev/null"', ',', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "droned . logging . logToDir ( \n"
Original    (007): ['droned', '.', 'logging', '.', 'logToDir', '(', '\\n']
Tokenized   (014): ['[CLS]', 'drone', '##d', '.', 'logging', '.', 'log', '##to', '##di', '##r', '(', '\\', 'n', '[SEP]']
Filtered   (012): ['drone', '##d', '.', 'logging', '.', 'log', '##to', '##di', '##r', '(', '\\', 'n']
Detokenized (007): ['drone##d', '.', 'logging', '.', 'log##to##di##r', '(', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "conversation . say ( contextSummary , useHTML = False ) \n"
Original    (011): ['conversation', '.', 'say', '(', 'contextSummary', ',', 'useHTML', '=', 'False', ')', '\\n']
Tokenized   (019): ['[CLS]', 'conversation', '.', 'say', '(', 'contexts', '##um', '##mar', '##y', ',', 'use', '##ht', '##ml', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['conversation', '.', 'say', '(', 'contexts', '##um', '##mar', '##y', ',', 'use', '##ht', '##ml', '=', 'false', ')', '\\', 'n']
Detokenized (011): ['conversation', '.', 'say', '(', 'contexts##um##mar##y', ',', 'use##ht##ml', '=', 'false', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "moduleProvides ( IDroneDService ) #requirement \n"
Original    (006): ['moduleProvides', '(', 'IDroneDService', ')', '#requirement', '\\n']
Tokenized   (018): ['[CLS]', 'module', '##pro', '##vid', '##es', '(', 'id', '##rone', '##ds', '##er', '##vic', '##e', ')', '#', 'requirement', '\\', 'n', '[SEP]']
Filtered   (016): ['module', '##pro', '##vid', '##es', '(', 'id', '##rone', '##ds', '##er', '##vic', '##e', ')', '#', 'requirement', '\\', 'n']
Detokenized (006): ['module##pro##vid##es', '(', 'id##rone##ds##er##vic##e', ')', '#requirement', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "hour = property ( lambda foo : 3600 ) \n"
Original    (010): ['hour', '=', 'property', '(', 'lambda', 'foo', ':', '3600', ')', '\\n']
Tokenized   (014): ['[CLS]', 'hour', '=', 'property', '(', 'lambda', 'foo', ':', '360', '##0', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['hour', '=', 'property', '(', 'lambda', 'foo', ':', '360', '##0', ')', '\\', 'n']
Detokenized (010): ['hour', '=', 'property', '(', 'lambda', 'foo', ':', '360##0', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "watchDict = property ( lambda s : SERVICECONFIG . wrapped . get ( , { } ) ) \n"
Original    (019): ['watchDict', '=', 'property', '(', 'lambda', 's', ':', 'SERVICECONFIG', '.', 'wrapped', '.', 'get', '(', ',', '{', '}', ')', ')', '\\n']
Tokenized   (026): ['[CLS]', 'watch', '##dict', '=', 'property', '(', 'lambda', 's', ':', 'service', '##con', '##fi', '##g', '.', 'wrapped', '.', 'get', '(', ',', '{', '}', ')', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['watch', '##dict', '=', 'property', '(', 'lambda', 's', ':', 'service', '##con', '##fi', '##g', '.', 'wrapped', '.', 'get', '(', ',', '{', '}', ')', ')', '\\', 'n']
Detokenized (019): ['watch##dict', '=', 'property', '(', 'lambda', 's', ':', 'service##con##fi##g', '.', 'wrapped', '.', 'get', '(', ',', '{', '}', ')', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "model = gm . throat_surface_area . cylinder ) \n"
Original    (009): ['model', '=', 'gm', '.', 'throat_surface_area', '.', 'cylinder', ')', '\\n']
Tokenized   (016): ['[CLS]', 'model', '=', 'gm', '.', 'throat', '_', 'surface', '_', 'area', '.', 'cylinder', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['model', '=', 'gm', '.', 'throat', '_', 'surface', '_', 'area', '.', 'cylinder', ')', '\\', 'n']
Detokenized (009): ['model', '=', 'gm', '.', 'throat_surface_area', '.', 'cylinder', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pores = network . find_connected_pores ( throats , flatten = False ) \n"
Original    (013): ['pores', '=', 'network', '.', 'find_connected_pores', '(', 'throats', ',', 'flatten', '=', 'False', ')', '\\n']
Tokenized   (024): ['[CLS]', 'por', '##es', '=', 'network', '.', 'find', '_', 'connected', '_', 'por', '##es', '(', 'throat', '##s', ',', 'flat', '##ten', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['por', '##es', '=', 'network', '.', 'find', '_', 'connected', '_', 'por', '##es', '(', 'throat', '##s', ',', 'flat', '##ten', '=', 'false', ')', '\\', 'n']
Detokenized (013): ['por##es', '=', 'network', '.', 'find_connected_por##es', '(', 'throat##s', ',', 'flat##ten', '=', 'false', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "C0 = network [ ] [ pores , 0 ] \n"
Original    (011): ['C0', '=', 'network', '[', ']', '[', 'pores', ',', '0', ']', '\\n']
Tokenized   (016): ['[CLS]', 'c', '##0', '=', 'network', '[', ']', '[', 'por', '##es', ',', '0', ']', '\\', 'n', '[SEP]']
Filtered   (014): ['c', '##0', '=', 'network', '[', ']', '[', 'por', '##es', ',', '0', ']', '\\', 'n']
Detokenized (011): ['c##0', '=', 'network', '[', ']', '[', 'por##es', ',', '0', ']', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "P = phase [ pore_P ] / 100000 \n"
Original    (009): ['P', '=', 'phase', '[', 'pore_P', ']', '/', '100000', '\\n']
Tokenized   (016): ['[CLS]', 'p', '=', 'phase', '[', 'por', '##e', '_', 'p', ']', '/', '1000', '##00', '\\', 'n', '[SEP]']
Filtered   (014): ['p', '=', 'phase', '[', 'por', '##e', '_', 'p', ']', '/', '1000', '##00', '\\', 'n']
Detokenized (009): ['p', '=', 'phase', '[', 'por##e_p', ']', '/', '1000##00', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "a1 = - 1 / b \n"
Original    (007): ['a1', '=', '-', '1', '/', 'b', '\\n']
Tokenized   (010): ['[CLS]', 'a1', '=', '-', '1', '/', 'b', '\\', 'n', '[SEP]']
Filtered   (008): ['a1', '=', '-', '1', '/', 'b', '\\', 'n']
Detokenized (007): ['a1', '=', '-', '1', '/', 'b', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "a2 = ( R * T + b * P ) / ( a * b ) \n"
Original    (018): ['a2', '=', '(', 'R', '*', 'T', '+', 'b', '*', 'P', ')', '/', '(', 'a', '*', 'b', ')', '\\n']
Tokenized   (021): ['[CLS]', 'a2', '=', '(', 'r', '*', 't', '+', 'b', '*', 'p', ')', '/', '(', 'a', '*', 'b', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['a2', '=', '(', 'r', '*', 't', '+', 'b', '*', 'p', ')', '/', '(', 'a', '*', 'b', ')', '\\', 'n']
Detokenized (018): ['a2', '=', '(', 'r', '*', 't', '+', 'b', '*', 'p', ')', '/', '(', 'a', '*', 'b', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "a3 = - P / ( a * b ) \n"
Original    (011): ['a3', '=', '-', 'P', '/', '(', 'a', '*', 'b', ')', '\\n']
Tokenized   (015): ['[CLS]', 'a', '##3', '=', '-', 'p', '/', '(', 'a', '*', 'b', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['a', '##3', '=', '-', 'p', '/', '(', 'a', '*', 'b', ')', '\\', 'n']
Detokenized (011): ['a##3', '=', '-', 'p', '/', '(', 'a', '*', 'b', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "coeffs = sp . vstack ( ( a0 , a1 , a2 , a3 ) ) . T \n"
Original    (019): ['coeffs', '=', 'sp', '.', 'vstack', '(', '(', 'a0', ',', 'a1', ',', 'a2', ',', 'a3', ')', ')', '.', 'T', '\\n']
Tokenized   (027): ['[CLS]', 'coe', '##ffs', '=', 'sp', '.', 'vs', '##ta', '##ck', '(', '(', 'a', '##0', ',', 'a1', ',', 'a2', ',', 'a', '##3', ')', ')', '.', 't', '\\', 'n', '[SEP]']
Filtered   (025): ['coe', '##ffs', '=', 'sp', '.', 'vs', '##ta', '##ck', '(', '(', 'a', '##0', ',', 'a1', ',', 'a2', ',', 'a', '##3', ')', ')', '.', 't', '\\', 'n']
Detokenized (019): ['coe##ffs', '=', 'sp', '.', 'vs##ta##ck', '(', '(', 'a##0', ',', 'a1', ',', 'a2', ',', 'a##3', ')', ')', '.', 't', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "density = sp . array ( [ sp . roots ( C ) for C in coeffs ] ) \n"
Original    (020): ['density', '=', 'sp', '.', 'array', '(', '[', 'sp', '.', 'roots', '(', 'C', ')', 'for', 'C', 'in', 'coeffs', ']', ')', '\\n']
Tokenized   (024): ['[CLS]', 'density', '=', 'sp', '.', 'array', '(', '[', 'sp', '.', 'roots', '(', 'c', ')', 'for', 'c', 'in', 'coe', '##ffs', ']', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['density', '=', 'sp', '.', 'array', '(', '[', 'sp', '.', 'roots', '(', 'c', ')', 'for', 'c', 'in', 'coe', '##ffs', ']', ')', '\\', 'n']
Detokenized (020): ['density', '=', 'sp', '.', 'array', '(', '[', 'sp', '.', 'roots', '(', 'c', ')', 'for', 'c', 'in', 'coe##ffs', ']', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "comp2 = OpenPNM . Phases . GenericPhase ( network = self . net ) \n"
Original    (015): ['comp2', '=', 'OpenPNM', '.', 'Phases', '.', 'GenericPhase', '(', 'network', '=', 'self', '.', 'net', ')', '\\n']
Tokenized   (025): ['[CLS]', 'com', '##p', '##2', '=', 'open', '##p', '##n', '##m', '.', 'phases', '.', 'generic', '##pha', '##se', '(', 'network', '=', 'self', '.', 'net', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['com', '##p', '##2', '=', 'open', '##p', '##n', '##m', '.', 'phases', '.', 'generic', '##pha', '##se', '(', 'network', '=', 'self', '.', 'net', ')', '\\', 'n']
Detokenized (015): ['com##p##2', '=', 'open##p##n##m', '.', 'phases', '.', 'generic##pha##se', '(', 'network', '=', 'self', '.', 'net', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "OpenPNM . Phases . GenericPhase ( network = self . net , \n"
Original    (013): ['OpenPNM', '.', 'Phases', '.', 'GenericPhase', '(', 'network', '=', 'self', '.', 'net', ',', '\\n']
Tokenized   (021): ['[CLS]', 'open', '##p', '##n', '##m', '.', 'phases', '.', 'generic', '##pha', '##se', '(', 'network', '=', 'self', '.', 'net', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['open', '##p', '##n', '##m', '.', 'phases', '.', 'generic', '##pha', '##se', '(', 'network', '=', 'self', '.', 'net', ',', '\\', 'n']
Detokenized (013): ['open##p##n##m', '.', 'phases', '.', 'generic##pha##se', '(', 'network', '=', 'self', '.', 'net', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "components = [ comp1 , comp2 ] ) \n"
Original    (009): ['components', '=', '[', 'comp1', ',', 'comp2', ']', ')', '\\n']
Tokenized   (016): ['[CLS]', 'components', '=', '[', 'com', '##p', '##1', ',', 'com', '##p', '##2', ']', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['components', '=', '[', 'com', '##p', '##1', ',', 'com', '##p', '##2', ']', ')', '\\', 'n']
Detokenized (009): ['components', '=', '[', 'com##p##1', ',', 'com##p##2', ']', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "phase . set_component ( comp2 , mode = ) \n"
Original    (010): ['phase', '.', 'set_component', '(', 'comp2', ',', 'mode', '=', ')', '\\n']
Tokenized   (017): ['[CLS]', 'phase', '.', 'set', '_', 'component', '(', 'com', '##p', '##2', ',', 'mode', '=', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['phase', '.', 'set', '_', 'component', '(', 'com', '##p', '##2', ',', 'mode', '=', ')', '\\', 'n']
Detokenized (010): ['phase', '.', 'set_component', '(', 'com##p##2', ',', 'mode', '=', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "best_seq = fd [ x ] . sequence \n"
Original    (009): ['best_seq', '=', 'fd', '[', 'x', ']', '.', 'sequence', '\\n']
Tokenized   (016): ['[CLS]', 'best', '_', 'se', '##q', '=', 'f', '##d', '[', 'x', ']', '.', 'sequence', '\\', 'n', '[SEP]']
Filtered   (014): ['best', '_', 'se', '##q', '=', 'f', '##d', '[', 'x', ']', '.', 'sequence', '\\', 'n']
Detokenized (009): ['best_se##q', '=', 'f##d', '[', 'x', ']', '.', 'sequence', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "best_id , best_seq , best_qual = rep_info [ pb_id ] \n"
Original    (011): ['best_id', ',', 'best_seq', ',', 'best_qual', '=', 'rep_info', '[', 'pb_id', ']', '\\n']
Tokenized   (027): ['[CLS]', 'best', '_', 'id', ',', 'best', '_', 'se', '##q', ',', 'best', '_', 'qu', '##al', '=', 'rep', '_', 'info', '[', 'p', '##b', '_', 'id', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['best', '_', 'id', ',', 'best', '_', 'se', '##q', ',', 'best', '_', 'qu', '##al', '=', 'rep', '_', 'info', '[', 'p', '##b', '_', 'id', ']', '\\', 'n']
Detokenized (011): ['best_id', ',', 'best_se##q', ',', 'best_qu##al', '=', 'rep_info', '[', 'p##b_id', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_id_ = "{0}|{1}|{2}" . format ( pb_id , coords [ best_id ] , best_id ) \n"
Original    (016): ['_id_', '=', '"{0}|{1}|{2}"', '.', 'format', '(', 'pb_id', ',', 'coords', '[', 'best_id', ']', ',', 'best_id', ')', '\\n']
Tokenized   (042): ['[CLS]', '_', 'id', '_', '=', '"', '{', '0', '}', '|', '{', '1', '}', '|', '{', '2', '}', '"', '.', 'format', '(', 'p', '##b', '_', 'id', ',', 'co', '##ord', '##s', '[', 'best', '_', 'id', ']', ',', 'best', '_', 'id', ')', '\\', 'n', '[SEP]']
Filtered   (040): ['_', 'id', '_', '=', '"', '{', '0', '}', '|', '{', '1', '}', '|', '{', '2', '}', '"', '.', 'format', '(', 'p', '##b', '_', 'id', ',', 'co', '##ord', '##s', '[', 'best', '_', 'id', ']', ',', 'best', '_', 'id', ')', '\\', 'n']
Detokenized (016): ['_id_', '=', '"{0}|{1}|{2}"', '.', 'format', '(', 'p##b_id', ',', 'co##ord##s', '[', 'best_id', ']', ',', 'best_id', ')', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "iter = BioReaders . GMAPSAMReader ( gmap_sam_filename , True , query_len_dict = transfrag_len_dict ) \n"
Original    (015): ['iter', '=', 'BioReaders', '.', 'GMAPSAMReader', '(', 'gmap_sam_filename', ',', 'True', ',', 'query_len_dict', '=', 'transfrag_len_dict', ')', '\\n']
Tokenized   (043): ['[CLS]', 'it', '##er', '=', 'bio', '##rea', '##ders', '.', 'gma', '##ps', '##am', '##rea', '##der', '(', 'gma', '##p', '_', 'sam', '_', 'file', '##name', ',', 'true', ',', 'query', '_', 'len', '_', 'di', '##ct', '=', 'trans', '##fra', '##g', '_', 'len', '_', 'di', '##ct', ')', '\\', 'n', '[SEP]']
Filtered   (041): ['it', '##er', '=', 'bio', '##rea', '##ders', '.', 'gma', '##ps', '##am', '##rea', '##der', '(', 'gma', '##p', '_', 'sam', '_', 'file', '##name', ',', 'true', ',', 'query', '_', 'len', '_', 'di', '##ct', '=', 'trans', '##fra', '##g', '_', 'len', '_', 'di', '##ct', ')', '\\', 'n']
Detokenized (015): ['it##er', '=', 'bio##rea##ders', '.', 'gma##ps##am##rea##der', '(', 'gma##p_sam_file##name', ',', 'true', ',', 'query_len_di##ct', '=', 'trans##fra##g_len_di##ct', ')', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "TmpRec = namedtuple ( , [ , , , , , , ] ) \n"
Original    (015): ['TmpRec', '=', 'namedtuple', '(', ',', '[', ',', ',', ',', ',', ',', ',', ']', ')', '\\n']
Tokenized   (023): ['[CLS]', 't', '##mp', '##re', '##c', '=', 'named', '##tu', '##ple', '(', ',', '[', ',', ',', ',', ',', ',', ',', ']', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['t', '##mp', '##re', '##c', '=', 'named', '##tu', '##ple', '(', ',', '[', ',', ',', ',', ',', ',', ',', ']', ')', '\\', 'n']
Detokenized (015): ['t##mp##re##c', '=', 'named##tu##ple', '(', ',', '[', ',', ',', ',', ',', ',', ',', ']', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "compressed_records_pointer_dict = defaultdict ( lambda : [ ] ) \n"
Original    (010): ['compressed_records_pointer_dict', '=', 'defaultdict', '(', 'lambda', ':', '[', ']', ')', '\\n']
Tokenized   (021): ['[CLS]', 'compressed', '_', 'records', '_', 'pointer', '_', 'di', '##ct', '=', 'default', '##dict', '(', 'lambda', ':', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['compressed', '_', 'records', '_', 'pointer', '_', 'di', '##ct', '=', 'default', '##dict', '(', 'lambda', ':', '[', ']', ')', '\\', 'n']
Detokenized (010): ['compressed_records_pointer_di##ct', '=', 'default##dict', '(', 'lambda', ':', '[', ']', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "check_ids_unique ( fa_or_fq_filename , is_fq = is_fq ) \n"
Original    (009): ['check_ids_unique', '(', 'fa_or_fq_filename', ',', 'is_fq', '=', 'is_fq', ')', '\\n']
Tokenized   (031): ['[CLS]', 'check', '_', 'id', '##s', '_', 'unique', '(', 'fa', '_', 'or', '_', 'f', '##q', '_', 'file', '##name', ',', 'is', '_', 'f', '##q', '=', 'is', '_', 'f', '##q', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['check', '_', 'id', '##s', '_', 'unique', '(', 'fa', '_', 'or', '_', 'f', '##q', '_', 'file', '##name', ',', 'is', '_', 'f', '##q', '=', 'is', '_', 'f', '##q', ')', '\\', 'n']
Detokenized (009): ['check_id##s_unique', '(', 'fa_or_f##q_file##name', ',', 'is_f##q', '=', 'is_f##q', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "fusion_candidates = find_fusion_candidates ( sam_filename , bs . transfrag_len_dict , min_locus_coverage \n"
Original    (012): ['fusion_candidates', '=', 'find_fusion_candidates', '(', 'sam_filename', ',', 'bs', '.', 'transfrag_len_dict', ',', 'min_locus_coverage', '\\n']
Tokenized   (035): ['[CLS]', 'fusion', '_', 'candidates', '=', 'find', '_', 'fusion', '_', 'candidates', '(', 'sam', '_', 'file', '##name', ',', 'bs', '.', 'trans', '##fra', '##g', '_', 'len', '_', 'di', '##ct', ',', 'min', '_', 'locus', '_', 'coverage', '\\', 'n', '[SEP]']
Filtered   (033): ['fusion', '_', 'candidates', '=', 'find', '_', 'fusion', '_', 'candidates', '(', 'sam', '_', 'file', '##name', ',', 'bs', '.', 'trans', '##fra', '##g', '_', 'len', '_', 'di', '##ct', ',', 'min', '_', 'locus', '_', 'coverage', '\\', 'n']
Detokenized (012): ['fusion_candidates', '=', 'find_fusion_candidates', '(', 'sam_file##name', ',', 'bs', '.', 'trans##fra##g_len_di##ct', ',', 'min_locus_coverage', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "pbid1 , groups1 = line . strip ( ) . split ( ) \n"
Original    (014): ['pbid1', ',', 'groups1', '=', 'line', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (020): ['[CLS]', 'p', '##bid', '##1', ',', 'groups', '##1', '=', 'line', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['p', '##bid', '##1', ',', 'groups', '##1', '=', 'line', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n']
Detokenized (014): ['p##bid##1', ',', 'groups##1', '=', 'line', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pbid2 , groups2 = f . readline ( ) . strip ( ) . split ( ) \n"
Original    (018): ['pbid2', ',', 'groups2', '=', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (025): ['[CLS]', 'p', '##bid', '##2', ',', 'groups', '##2', '=', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['p', '##bid', '##2', ',', 'groups', '##2', '=', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n']
Detokenized (018): ['p##bid##2', ',', 'groups##2', '=', 'f', '.', 'read##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "f_group . write ( "{0}\\t{1}\\n" . format ( pbid1 [ : pbid1 . rfind ( ) ] , "," . join ( group ) ) ) \n"
Original    (027): ['f_group', '.', 'write', '(', '"{0}\\\\t{1}\\\\n"', '.', 'format', '(', 'pbid1', '[', ':', 'pbid1', '.', 'rfind', '(', ')', ']', ',', '","', '.', 'join', '(', 'group', ')', ')', ')', '\\n']
Tokenized   (052): ['[CLS]', 'f', '_', 'group', '.', 'write', '(', '"', '{', '0', '}', '\\', '\\', 't', '{', '1', '}', '\\', '\\', 'n', '"', '.', 'format', '(', 'p', '##bid', '##1', '[', ':', 'p', '##bid', '##1', '.', 'rf', '##ind', '(', ')', ']', ',', '"', ',', '"', '.', 'join', '(', 'group', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (050): ['f', '_', 'group', '.', 'write', '(', '"', '{', '0', '}', '\\', '\\', 't', '{', '1', '}', '\\', '\\', 'n', '"', '.', 'format', '(', 'p', '##bid', '##1', '[', ':', 'p', '##bid', '##1', '.', 'rf', '##ind', '(', ')', ']', ',', '"', ',', '"', '.', 'join', '(', 'group', ')', ')', ')', '\\', 'n']
Detokenized (027): ['f_group', '.', 'write', '(', '"{0}\\\\t{1}\\\\n"', '.', 'format', '(', 'p##bid##1', '[', ':', 'p##bid##1', '.', 'rf##ind', '(', ')', ']', ',', '","', '.', 'join', '(', 'group', ')', ')', ')', '\\n']
Counter: 50
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "group_info [ pbid1 [ : pbid1 . rfind ( ) ] ] = list ( group ) \n"
Original    (018): ['group_info', '[', 'pbid1', '[', ':', 'pbid1', '.', 'rfind', '(', ')', ']', ']', '=', 'list', '(', 'group', ')', '\\n']
Tokenized   (028): ['[CLS]', 'group', '_', 'info', '[', 'p', '##bid', '##1', '[', ':', 'p', '##bid', '##1', '.', 'rf', '##ind', '(', ')', ']', ']', '=', 'list', '(', 'group', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['group', '_', 'info', '[', 'p', '##bid', '##1', '[', ':', 'p', '##bid', '##1', '.', 'rf', '##ind', '(', ')', ']', ']', '=', 'list', '(', 'group', ')', '\\', 'n']
Detokenized (018): ['group_info', '[', 'p##bid##1', '[', ':', 'p##bid##1', '.', 'rf##ind', '(', ')', ']', ']', '=', 'list', '(', 'group', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "d1 . update ( d [ ] ) \n"
Original    (009): ['d1', '.', 'update', '(', 'd', '[', ']', ')', '\\n']
Tokenized   (013): ['[CLS]', 'd', '##1', '.', 'update', '(', 'd', '[', ']', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['d', '##1', '.', 'update', '(', 'd', '[', ']', ')', '\\', 'n']
Detokenized (009): ['d##1', '.', 'update', '(', 'd', '[', ']', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "fusion_main ( args . input , args . sam , args . prefix , \n"
Original    (015): ['fusion_main', '(', 'args', '.', 'input', ',', 'args', '.', 'sam', ',', 'args', '.', 'prefix', ',', '\\n']
Tokenized   (023): ['[CLS]', 'fusion', '_', 'main', '(', 'ar', '##gs', '.', 'input', ',', 'ar', '##gs', '.', 'sam', ',', 'ar', '##gs', '.', 'prefix', ',', '\\', 'n', '[SEP]']
Filtered   (021): ['fusion', '_', 'main', '(', 'ar', '##gs', '.', 'input', ',', 'ar', '##gs', '.', 'sam', ',', 'ar', '##gs', '.', 'prefix', ',', '\\', 'n']
Detokenized (015): ['fusion_main', '(', 'ar##gs', '.', 'input', ',', 'ar##gs', '.', 'sam', ',', 'ar##gs', '.', 'prefix', ',', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "is_fq = args . fq , allow_extra_5_exons = args . allow_extra_5exon , \n"
Original    (013): ['is_fq', '=', 'args', '.', 'fq', ',', 'allow_extra_5_exons', '=', 'args', '.', 'allow_extra_5exon', ',', '\\n']
Tokenized   (035): ['[CLS]', 'is', '_', 'f', '##q', '=', 'ar', '##gs', '.', 'f', '##q', ',', 'allow', '_', 'extra', '_', '5', '_', 'ex', '##ons', '=', 'ar', '##gs', '.', 'allow', '_', 'extra', '_', '5', '##ex', '##on', ',', '\\', 'n', '[SEP]']
Filtered   (033): ['is', '_', 'f', '##q', '=', 'ar', '##gs', '.', 'f', '##q', ',', 'allow', '_', 'extra', '_', '5', '_', 'ex', '##ons', '=', 'ar', '##gs', '.', 'allow', '_', 'extra', '_', '5', '##ex', '##on', ',', '\\', 'n']
Detokenized (013): ['is_f##q', '=', 'ar##gs', '.', 'f##q', ',', 'allow_extra_5_ex##ons', '=', 'ar##gs', '.', 'allow_extra_5##ex##on', ',', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "skip_5_exon_alt = False , prefix_dict_pickle_filename = args . prefix_dict_pickle_filename , min_locus_coverage = args . min_locus_coverage , min_locus_coverage_bp = args . min_locus_coverage_bp min_total_coverage = args . min_total_coverage , \n"
Original    (028): ['skip_5_exon_alt', '=', 'False', ',', 'prefix_dict_pickle_filename', '=', 'args', '.', 'prefix_dict_pickle_filename', ',', 'min_locus_coverage', '=', 'args', '.', 'min_locus_coverage', ',', 'min_locus_coverage_bp', '=', 'args', '.', 'min_locus_coverage_bp', 'min_total_coverage', '=', 'args', '.', 'min_total_coverage', ',', '\\n']
Tokenized   (088): ['[CLS]', 'skip', '_', '5', '_', 'ex', '##on', '_', 'alt', '=', 'false', ',', 'prefix', '_', 'di', '##ct', '_', 'pick', '##le', '_', 'file', '##name', '=', 'ar', '##gs', '.', 'prefix', '_', 'di', '##ct', '_', 'pick', '##le', '_', 'file', '##name', ',', 'min', '_', 'locus', '_', 'coverage', '=', 'ar', '##gs', '.', 'min', '_', 'locus', '_', 'coverage', ',', 'min', '_', 'locus', '_', 'coverage', '_', 'bp', '=', 'ar', '##gs', '.', 'min', '_', 'locus', '_', 'coverage', '_', 'bp', 'min', '_', 'total', '_', 'coverage', '=', 'ar', '##gs', '.', 'min', '_', 'total', '_', 'coverage', ',', '\\', 'n', '[SEP]']
Filtered   (086): ['skip', '_', '5', '_', 'ex', '##on', '_', 'alt', '=', 'false', ',', 'prefix', '_', 'di', '##ct', '_', 'pick', '##le', '_', 'file', '##name', '=', 'ar', '##gs', '.', 'prefix', '_', 'di', '##ct', '_', 'pick', '##le', '_', 'file', '##name', ',', 'min', '_', 'locus', '_', 'coverage', '=', 'ar', '##gs', '.', 'min', '_', 'locus', '_', 'coverage', ',', 'min', '_', 'locus', '_', 'coverage', '_', 'bp', '=', 'ar', '##gs', '.', 'min', '_', 'locus', '_', 'coverage', '_', 'bp', 'min', '_', 'total', '_', 'coverage', '=', 'ar', '##gs', '.', 'min', '_', 'total', '_', 'coverage', ',', '\\', 'n']
Detokenized (028): ['skip_5_ex##on_alt', '=', 'false', ',', 'prefix_di##ct_pick##le_file##name', '=', 'ar##gs', '.', 'prefix_di##ct_pick##le_file##name', ',', 'min_locus_coverage', '=', 'ar##gs', '.', 'min_locus_coverage', ',', 'min_locus_coverage_bp', '=', 'ar##gs', '.', 'min_locus_coverage_bp', 'min_total_coverage', '=', 'ar##gs', '.', 'min_total_coverage', ',', '\\n']
Counter: 86
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "raw = self . f . readline ( ) . strip ( ) . split ( ) \n"
Original    (018): ['raw', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (022): ['[CLS]', 'raw', '=', 'self', '.', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['raw', '=', 'self', '.', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n']
Detokenized (018): ['raw', '=', 'self', '.', 'f', '.', 'read##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "iden = float ( raw [ 3 ] ) \n"
Original    (010): ['iden', '=', 'float', '(', 'raw', '[', '3', ']', ')', '\\n']
Tokenized   (014): ['[CLS]', 'id', '##en', '=', 'float', '(', 'raw', '[', '3', ']', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['id', '##en', '=', 'float', '(', 'raw', '[', '3', ']', ')', '\\', 'n']
Detokenized (010): ['id##en', '=', 'float', '(', 'raw', '[', '3', ']', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_qStart , qAln = self . f . readline ( ) . strip ( ) . split ( ) \n"
Original    (020): ['_qStart', ',', 'qAln', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (029): ['[CLS]', '_', 'q', '##star', '##t', ',', 'q', '##al', '##n', '=', 'self', '.', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['_', 'q', '##star', '##t', ',', 'q', '##al', '##n', '=', 'self', '.', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\', 'n']
Detokenized (020): ['_q##star##t', ',', 'q##al##n', '=', 'self', '.', 'f', '.', 'read##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "_sStart , sAln = self . f . readline ( ) . strip ( ) . split ( ) [ : 2 ] \n"
Original    (024): ['_sStart', ',', 'sAln', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '[', ':', '2', ']', '\\n']
Tokenized   (032): ['[CLS]', '_', 'ss', '##tar', '##t', ',', 'sal', '##n', '=', 'self', '.', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '[', ':', '2', ']', '\\', 'n', '[SEP]']
Filtered   (030): ['_', 'ss', '##tar', '##t', ',', 'sal', '##n', '=', 'self', '.', 'f', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '[', ':', '2', ']', '\\', 'n']
Detokenized (024): ['_ss##tar##t', ',', 'sal##n', '=', 'self', '.', 'f', '.', 'read##line', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '[', ':', '2', ']', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "missed_q = missed_q * 1. / r . qLength , \n"
Original    (011): ['missed_q', '=', 'missed_q', '*', '1.', '/', 'r', '.', 'qLength', ',', '\\n']
Tokenized   (022): ['[CLS]', 'missed', '_', 'q', '=', 'missed', '_', 'q', '*', '1', '.', '/', 'r', '.', 'q', '##len', '##gt', '##h', ',', '\\', 'n', '[SEP]']
Filtered   (020): ['missed', '_', 'q', '=', 'missed', '_', 'q', '*', '1', '.', '/', 'r', '.', 'q', '##len', '##gt', '##h', ',', '\\', 'n']
Detokenized (011): ['missed_q', '=', 'missed_q', '*', '1.', '/', 'r', '.', 'q##len##gt##h', ',', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "ece_penalty , ece_min_len ) : \n"
Original    (006): ['ece_penalty', ',', 'ece_min_len', ')', ':', '\\n']
Tokenized   (017): ['[CLS]', 'ec', '##e', '_', 'penalty', ',', 'ec', '##e', '_', 'min', '_', 'len', ')', ':', '\\', 'n', '[SEP]']
Filtered   (015): ['ec', '##e', '_', 'penalty', ',', 'ec', '##e', '_', 'min', '_', 'len', ')', ':', '\\', 'n']
Detokenized (006): ['ec##e_penalty', ',', 'ec##e_min_len', ')', ':', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "heading = % ( current_indent , , self . heading ) \n"
Original    (012): ['heading', '=', '%', '(', 'current_indent', ',', ',', 'self', '.', 'heading', ')', '\\n']
Tokenized   (018): ['[CLS]', 'heading', '=', '%', '(', 'current', '_', 'ind', '##ent', ',', ',', 'self', '.', 'heading', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['heading', '=', '%', '(', 'current', '_', 'ind', '##ent', ',', ',', 'self', '.', 'heading', ')', '\\', 'n']
Detokenized (012): ['heading', '=', '%', '(', 'current_ind##ent', ',', ',', 'self', '.', 'heading', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "section = self . _Section ( self , self . _current_section , heading ) \n"
Original    (015): ['section', '=', 'self', '.', '_Section', '(', 'self', ',', 'self', '.', '_current_section', ',', 'heading', ')', '\\n']
Tokenized   (022): ['[CLS]', 'section', '=', 'self', '.', '_', 'section', '(', 'self', ',', 'self', '.', '_', 'current', '_', 'section', ',', 'heading', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['section', '=', 'self', '.', '_', 'section', '(', 'self', ',', 'self', '.', '_', 'current', '_', 'section', ',', 'heading', ')', '\\', 'n']
Detokenized (015): ['section', '=', 'self', '.', '_section', '(', 'self', ',', 'self', '.', '_current_section', ',', 'heading', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "invocations = [ get_invocation ( action ) ] \n"
Original    (009): ['invocations', '=', '[', 'get_invocation', '(', 'action', ')', ']', '\\n']
Tokenized   (017): ['[CLS]', 'in', '##vocation', '##s', '=', '[', 'get', '_', 'in', '##vocation', '(', 'action', ')', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['in', '##vocation', '##s', '=', '[', 'get', '_', 'in', '##vocation', '(', 'action', ')', ']', '\\', 'n']
Detokenized (009): ['in##vocation##s', '=', '[', 'get_in##vocation', '(', 'action', ')', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "action_usage = format ( optionals + positionals , groups ) \n"
Original    (011): ['action_usage', '=', 'format', '(', 'optionals', '+', 'positionals', ',', 'groups', ')', '\\n']
Tokenized   (018): ['[CLS]', 'action', '_', 'usage', '=', 'format', '(', 'optional', '##s', '+', 'position', '##als', ',', 'groups', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['action', '_', 'usage', '=', 'format', '(', 'optional', '##s', '+', 'position', '##als', ',', 'groups', ')', '\\', 'n']
Detokenized (011): ['action_usage', '=', 'format', '(', 'optional##s', '+', 'position##als', ',', 'groups', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "text_width = self . _width - self . _current_indent \n"
Original    (010): ['text_width', '=', 'self', '.', '_width', '-', 'self', '.', '_current_indent', '\\n']
Tokenized   (020): ['[CLS]', 'text', '_', 'width', '=', 'self', '.', '_', 'width', '-', 'self', '.', '_', 'current', '_', 'ind', '##ent', '\\', 'n', '[SEP]']
Filtered   (018): ['text', '_', 'width', '=', 'self', '.', '_', 'width', '-', 'self', '.', '_', 'current', '_', 'ind', '##ent', '\\', 'n']
Detokenized (010): ['text_width', '=', 'self', '.', '_width', '-', 'self', '.', '_current_ind##ent', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "line_len += len ( part ) + 1 \n"
Original    (009): ['line_len', '+=', 'len', '(', 'part', ')', '+', '1', '\\n']
Tokenized   (015): ['[CLS]', 'line', '_', 'len', '+', '=', 'len', '(', 'part', ')', '+', '1', '\\', 'n', '[SEP]']
Filtered   (013): ['line', '_', 'len', '+', '=', 'len', '(', 'part', ')', '+', '1', '\\', 'n']
Detokenized (009): ['line_len', '+=', 'len', '(', 'part', ')', '+', '1', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "part = % ( option_string , args_string ) \n"
Original    (009): ['part', '=', '%', '(', 'option_string', ',', 'args_string', ')', '\\n']
Tokenized   (017): ['[CLS]', 'part', '=', '%', '(', 'option', '_', 'string', ',', 'ar', '##gs', '_', 'string', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['part', '=', '%', '(', 'option', '_', 'string', ',', 'ar', '##gs', '_', 'string', ')', '\\', 'n']
Detokenized (009): ['part', '=', '%', '(', 'option_string', ',', 'ar##gs_string', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "indent = * self . _current_indent \n"
Original    (007): ['indent', '=', '*', 'self', '.', '_current_indent', '\\n']
Tokenized   (015): ['[CLS]', 'ind', '##ent', '=', '*', 'self', '.', '_', 'current', '_', 'ind', '##ent', '\\', 'n', '[SEP]']
Filtered   (013): ['ind', '##ent', '=', '*', 'self', '.', '_', 'current', '_', 'ind', '##ent', '\\', 'n']
Detokenized (007): ['ind##ent', '=', '*', 'self', '.', '_current_ind##ent', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "help_width = self . _width - help_position \n"
Original    (008): ['help_width', '=', 'self', '.', '_width', '-', 'help_position', '\\n']
Tokenized   (016): ['[CLS]', 'help', '_', 'width', '=', 'self', '.', '_', 'width', '-', 'help', '_', 'position', '\\', 'n', '[SEP]']
Filtered   (014): ['help', '_', 'width', '=', 'self', '.', '_', 'width', '-', 'help', '_', 'position', '\\', 'n']
Detokenized (008): ['help_width', '=', 'self', '.', '_width', '-', 'help_position', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "action_width = help_position - self . _current_indent - 2 \n"
Original    (010): ['action_width', '=', 'help_position', '-', 'self', '.', '_current_indent', '-', '2', '\\n']
Tokenized   (021): ['[CLS]', 'action', '_', 'width', '=', 'help', '_', 'position', '-', 'self', '.', '_', 'current', '_', 'ind', '##ent', '-', '2', '\\', 'n', '[SEP]']
Filtered   (019): ['action', '_', 'width', '=', 'help', '_', 'position', '-', 'self', '.', '_', 'current', '_', 'ind', '##ent', '-', '2', '\\', 'n']
Detokenized (010): ['action_width', '=', 'help_position', '-', 'self', '.', '_current_ind##ent', '-', '2', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sup . __init__ ( option_strings = [ ] , dest = name , help = help ) \n"
Original    (018): ['sup', '.', '__init__', '(', 'option_strings', '=', '[', ']', ',', 'dest', '=', 'name', ',', 'help', '=', 'help', ')', '\\n']
Tokenized   (030): ['[CLS]', 'su', '##p', '.', '_', '_', 'in', '##it', '_', '_', '(', 'option', '_', 'strings', '=', '[', ']', ',', 'des', '##t', '=', 'name', ',', 'help', '=', 'help', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['su', '##p', '.', '_', '_', 'in', '##it', '_', '_', '(', 'option', '_', 'strings', '=', '[', ']', ',', 'des', '##t', '=', 'name', ',', 'help', '=', 'help', ')', '\\', 'n']
Detokenized (018): ['su##p', '.', '__in##it__', '(', 'option_strings', '=', '[', ']', ',', 'des##t', '=', 'name', ',', 'help', '=', 'help', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "arg_strings = values [ 1 : ] \n"
Original    (008): ['arg_strings', '=', 'values', '[', '1', ':', ']', '\\n']
Tokenized   (014): ['[CLS]', 'ar', '##g', '_', 'strings', '=', 'values', '[', '1', ':', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['ar', '##g', '_', 'strings', '=', 'values', '[', '1', ':', ']', '\\', 'n']
Detokenized (008): ['ar##g_strings', '=', 'values', '[', '1', ':', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "args_str = . join ( [ repr ( arg ) for arg in args if arg is not None ] ) \n"
Original    (022): ['args_str', '=', '.', 'join', '(', '[', 'repr', '(', 'arg', ')', 'for', 'arg', 'in', 'args', 'if', 'arg', 'is', 'not', 'None', ']', ')', '\\n']
Tokenized   (034): ['[CLS]', 'ar', '##gs', '_', 'st', '##r', '=', '.', 'join', '(', '[', 'rep', '##r', '(', 'ar', '##g', ')', 'for', 'ar', '##g', 'in', 'ar', '##gs', 'if', 'ar', '##g', 'is', 'not', 'none', ']', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['ar', '##gs', '_', 'st', '##r', '=', '.', 'join', '(', '[', 'rep', '##r', '(', 'ar', '##g', ')', 'for', 'ar', '##g', 'in', 'ar', '##gs', 'if', 'ar', '##g', 'is', 'not', 'none', ']', ')', '\\', 'n']
Detokenized (022): ['ar##gs_st##r', '=', '.', 'join', '(', '[', 'rep##r', '(', 'ar##g', ')', 'for', 'ar##g', 'in', 'ar##gs', 'if', 'ar##g', 'is', 'not', 'none', ']', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "type_func = self . _registry_get ( , action . type , action . type ) \n"
Original    (016): ['type_func', '=', 'self', '.', '_registry_get', '(', ',', 'action', '.', 'type', ',', 'action', '.', 'type', ')', '\\n']
Tokenized   (025): ['[CLS]', 'type', '_', 'fun', '##c', '=', 'self', '.', '_', 'registry', '_', 'get', '(', ',', 'action', '.', 'type', ',', 'action', '.', 'type', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['type', '_', 'fun', '##c', '=', 'self', '.', '_', 'registry', '_', 'get', '(', ',', 'action', '.', 'type', ',', 'action', '.', 'type', ')', '\\', 'n']
Detokenized (016): ['type_fun##c', '=', 'self', '.', '_registry_get', '(', ',', 'action', '.', 'type', ',', 'action', '.', 'type', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "conflict_string = . join ( [ option_string \n"
Original    (008): ['conflict_string', '=', '.', 'join', '(', '[', 'option_string', '\\n']
Tokenized   (015): ['[CLS]', 'conflict', '_', 'string', '=', '.', 'join', '(', '[', 'option', '_', 'string', '\\', 'n', '[SEP]']
Filtered   (013): ['conflict', '_', 'string', '=', '.', 'join', '(', '[', 'option', '_', 'string', '\\', 'n']
Detokenized (008): ['conflict_string', '=', '.', 'join', '(', '[', 'option_string', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "in conflicting_actions ] ) \n"
Original    (005): ['in', 'conflicting_actions', ']', ')', '\\n']
Tokenized   (010): ['[CLS]', 'in', 'conflicting', '_', 'actions', ']', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['in', 'conflicting', '_', 'actions', ']', ')', '\\', 'n']
Detokenized (005): ['in', 'conflicting_actions', ']', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "super_init ( description = description , ** kwargs ) \n"
Original    (010): ['super_init', '(', 'description', '=', 'description', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (019): ['[CLS]', 'super', '_', 'in', '##it', '(', 'description', '=', 'description', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['super', '_', 'in', '##it', '(', 'description', '=', 'description', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n']
Detokenized (010): ['super_in##it', '(', 'description', '=', 'description', ',', '**', 'kw##ar##gs', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : """"instead""" , DeprecationWarning ) \n"
Original    (005): ['"""instead"""', ',', 'DeprecationWarning', ')', '\\n']
Tokenized   (018): ['[CLS]', '"', '"', '"', 'instead', '"', '"', '"', ',', 'de', '##pre', '##cation', '##war', '##ning', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['"', '"', '"', 'instead', '"', '"', '"', ',', 'de', '##pre', '##cation', '##war', '##ning', ')', '\\', 'n']
Detokenized (005): ['"""instead"""', ',', 'de##pre##cation##war##ning', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "superinit ( description = description , \n"
Original    (007): ['superinit', '(', 'description', '=', 'description', ',', '\\n']
Tokenized   (012): ['[CLS]', 'super', '##ini', '##t', '(', 'description', '=', 'description', ',', '\\', 'n', '[SEP]']
Filtered   (010): ['super', '##ini', '##t', '(', 'description', '=', 'description', ',', '\\', 'n']
Detokenized (007): ['super##ini##t', '(', 'description', '=', 'description', ',', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "default_prefix + , default_prefix * 2 + , \n"
Original    (009): ['default_prefix', '+', ',', 'default_prefix', '*', '2', '+', ',', '\\n']
Tokenized   (016): ['[CLS]', 'default', '_', 'prefix', '+', ',', 'default', '_', 'prefix', '*', '2', '+', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['default', '_', 'prefix', '+', ',', 'default', '_', 'prefix', '*', '2', '+', ',', '\\', 'n']
Detokenized (009): ['default_prefix', '+', ',', 'default_prefix', '*', '2', '+', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "conflicts . extend ( group_actions [ i + 1 : ] ) \n"
Original    (013): ['conflicts', '.', 'extend', '(', 'group_actions', '[', 'i', '+', '1', ':', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'conflicts', '.', 'extend', '(', 'group', '_', 'actions', '[', 'i', '+', '1', ':', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['conflicts', '.', 'extend', '(', 'group', '_', 'actions', '[', 'i', '+', '1', ':', ']', ')', '\\', 'n']
Detokenized (013): ['conflicts', '.', 'extend', '(', 'group_actions', '[', 'i', '+', '1', ':', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "action , option_string , explicit_arg = option_tuple \n"
Original    (008): ['action', ',', 'option_string', ',', 'explicit_arg', '=', 'option_tuple', '\\n']
Tokenized   (019): ['[CLS]', 'action', ',', 'option', '_', 'string', ',', 'explicit', '_', 'ar', '##g', '=', 'option', '_', 'tu', '##ple', '\\', 'n', '[SEP]']
Filtered   (017): ['action', ',', 'option', '_', 'string', ',', 'explicit', '_', 'ar', '##g', '=', 'option', '_', 'tu', '##ple', '\\', 'n']
Detokenized (008): ['action', ',', 'option_string', ',', 'explicit_ar##g', '=', 'option_tu##ple', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "option_string = char + explicit_arg [ 0 ] \n"
Original    (009): ['option_string', '=', 'char', '+', 'explicit_arg', '[', '0', ']', '\\n']
Tokenized   (017): ['[CLS]', 'option', '_', 'string', '=', 'char', '+', 'explicit', '_', 'ar', '##g', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['option', '_', 'string', '=', 'char', '+', 'explicit', '_', 'ar', '##g', '[', '0', ']', '\\', 'n']
Detokenized (009): ['option_string', '=', 'char', '+', 'explicit_ar##g', '[', '0', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "new_explicit_arg = explicit_arg [ 1 : ] or None \n"
Original    (010): ['new_explicit_arg', '=', 'explicit_arg', '[', '1', ':', ']', 'or', 'None', '\\n']
Tokenized   (021): ['[CLS]', 'new', '_', 'explicit', '_', 'ar', '##g', '=', 'explicit', '_', 'ar', '##g', '[', '1', ':', ']', 'or', 'none', '\\', 'n', '[SEP]']
Filtered   (019): ['new', '_', 'explicit', '_', 'ar', '##g', '=', 'explicit', '_', 'ar', '##g', '[', '1', ':', ']', 'or', 'none', '\\', 'n']
Detokenized (010): ['new_explicit_ar##g', '=', 'explicit_ar##g', '[', '1', ':', ']', 'or', 'none', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "action_tuples . append ( ( action , args , option_string ) ) \n"
Original    (013): ['action_tuples', '.', 'append', '(', '(', 'action', ',', 'args', ',', 'option_string', ')', ')', '\\n']
Tokenized   (023): ['[CLS]', 'action', '_', 'tu', '##ples', '.', 'app', '##end', '(', '(', 'action', ',', 'ar', '##gs', ',', 'option', '_', 'string', ')', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['action', '_', 'tu', '##ples', '.', 'app', '##end', '(', '(', 'action', ',', 'ar', '##gs', ',', 'option', '_', 'string', ')', ')', '\\', 'n']
Detokenized (013): ['action_tu##ples', '.', 'app##end', '(', '(', 'action', ',', 'ar##gs', ',', 'option_string', ')', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "selected_patterns = arg_strings_pattern [ start : ] \n"
Original    (008): ['selected_patterns', '=', 'arg_strings_pattern', '[', 'start', ':', ']', '\\n']
Tokenized   (018): ['[CLS]', 'selected', '_', 'patterns', '=', 'ar', '##g', '_', 'strings', '_', 'pattern', '[', 'start', ':', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['selected', '_', 'patterns', '=', 'ar', '##g', '_', 'strings', '_', 'pattern', '[', 'start', ':', ']', '\\', 'n']
Detokenized (008): ['selected_patterns', '=', 'ar##g_strings_pattern', '[', 'start', ':', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "extras . extend ( arg_strings [ stop_index : ] ) \n"
Original    (011): ['extras', '.', 'extend', '(', 'arg_strings', '[', 'stop_index', ':', ']', ')', '\\n']
Tokenized   (019): ['[CLS]', 'extras', '.', 'extend', '(', 'ar', '##g', '_', 'strings', '[', 'stop', '_', 'index', ':', ']', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['extras', '.', 'extend', '(', 'ar', '##g', '_', 'strings', '[', 'stop', '_', 'index', ':', ']', ')', '\\', 'n']
Detokenized (011): ['extras', '.', 'extend', '(', 'ar##g_strings', '[', 'stop_index', ':', ']', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "OPTIONAL : _ ( ) , \n"
Original    (007): ['OPTIONAL', ':', '_', '(', ')', ',', '\\n']
Tokenized   (010): ['[CLS]', 'optional', ':', '_', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (008): ['optional', ':', '_', '(', ')', ',', '\\', 'n']
Detokenized (007): ['optional', ':', '_', '(', ')', ',', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "pattern = . join ( [ self . _get_nargs_pattern ( action ) \n"
Original    (013): ['pattern', '=', '.', 'join', '(', '[', 'self', '.', '_get_nargs_pattern', '(', 'action', ')', '\\n']
Tokenized   (023): ['[CLS]', 'pattern', '=', '.', 'join', '(', '[', 'self', '.', '_', 'get', '_', 'na', '##rg', '##s', '_', 'pattern', '(', 'action', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['pattern', '=', '.', 'join', '(', '[', 'self', '.', '_', 'get', '_', 'na', '##rg', '##s', '_', 'pattern', '(', 'action', ')', '\\', 'n']
Detokenized (013): ['pattern', '=', '.', 'join', '(', '[', 'self', '.', '_get_na##rg##s_pattern', '(', 'action', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "short_option_prefix = option_string [ : 2 ] \n"
Original    (008): ['short_option_prefix', '=', 'option_string', '[', ':', '2', ']', '\\n']
Tokenized   (017): ['[CLS]', 'short', '_', 'option', '_', 'prefix', '=', 'option', '_', 'string', '[', ':', '2', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['short', '_', 'option', '_', 'prefix', '=', 'option', '_', 'string', '[', ':', '2', ']', '\\', 'n']
Detokenized (008): ['short_option_prefix', '=', 'option_string', '[', ':', '2', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "tup = action , option_string , short_explicit_arg \n"
Original    (008): ['tup', '=', 'action', ',', 'option_string', ',', 'short_explicit_arg', '\\n']
Tokenized   (019): ['[CLS]', 'tu', '##p', '=', 'action', ',', 'option', '_', 'string', ',', 'short', '_', 'explicit', '_', 'ar', '##g', '\\', 'n', '[SEP]']
Filtered   (017): ['tu', '##p', '=', 'action', ',', 'option', '_', 'string', ',', 'short', '_', 'explicit', '_', 'ar', '##g', '\\', 'n']
Detokenized (008): ['tu##p', '=', 'action', ',', 'option_string', ',', 'short_explicit_ar##g', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "not action . option_strings ) : \n"
Original    (007): ['not', 'action', '.', 'option_strings', ')', ':', '\\n']
Tokenized   (012): ['[CLS]', 'not', 'action', '.', 'option', '_', 'strings', ')', ':', '\\', 'n', '[SEP]']
Filtered   (010): ['not', 'action', '.', 'option', '_', 'strings', ')', ':', '\\', 'n']
Detokenized (007): ['not', 'action', '.', 'option_strings', ')', ':', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "vulnerability = obj [ ] [ ] [ ] [ ] [ ] \n"
Original    (014): ['vulnerability', '=', 'obj', '[', ']', '[', ']', '[', ']', '[', ']', '[', ']', '\\n']
Tokenized   (018): ['[CLS]', 'vulnerability', '=', 'ob', '##j', '[', ']', '[', ']', '[', ']', '[', ']', '[', ']', '\\', 'n', '[SEP]']
Filtered   (016): ['vulnerability', '=', 'ob', '##j', '[', ']', '[', ']', '[', ']', '[', ']', '[', ']', '\\', 'n']
Detokenized (014): ['vulnerability', '=', 'ob##j', '[', ']', '[', ']', '[', ']', '[', ']', '[', ']', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "apikey = common . apikey ( sessionKey , args [ 0 ] , debug ) \n"
Original    (016): ['apikey', '=', 'common', '.', 'apikey', '(', 'sessionKey', ',', 'args', '[', '0', ']', ',', 'debug', ')', '\\n']
Tokenized   (025): ['[CLS]', 'api', '##key', '=', 'common', '.', 'api', '##key', '(', 'session', '##key', ',', 'ar', '##gs', '[', '0', ']', ',', 'de', '##bu', '##g', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['api', '##key', '=', 'common', '.', 'api', '##key', '(', 'session', '##key', ',', 'ar', '##gs', '[', '0', ']', ',', 'de', '##bu', '##g', ')', '\\', 'n']
Detokenized (016): ['api##key', '=', 'common', '.', 'api##key', '(', 'session##key', ',', 'ar##gs', '[', '0', ']', ',', 'de##bu##g', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "device = pandevice . base . PanDevice ( args [ 0 ] , api_key = apikey ) \n"
Original    (018): ['device', '=', 'pandevice', '.', 'base', '.', 'PanDevice', '(', 'args', '[', '0', ']', ',', 'api_key', '=', 'apikey', ')', '\\n']
Tokenized   (029): ['[CLS]', 'device', '=', 'pan', '##dev', '##ice', '.', 'base', '.', 'pan', '##dev', '##ice', '(', 'ar', '##gs', '[', '0', ']', ',', 'api', '_', 'key', '=', 'api', '##key', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['device', '=', 'pan', '##dev', '##ice', '.', 'base', '.', 'pan', '##dev', '##ice', '(', 'ar', '##gs', '[', '0', ']', ',', 'api', '_', 'key', '=', 'api', '##key', ')', '\\', 'n']
Detokenized (018): ['device', '=', 'pan##dev##ice', '.', 'base', '.', 'pan##dev##ice', '(', 'ar##gs', '[', '0', ']', ',', 'api_key', '=', 'api##key', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "rebalance_backoff_ms = 2 * 1000 , \n"
Original    (007): ['rebalance_backoff_ms', '=', '2', '*', '1000', ',', '\\n']
Tokenized   (016): ['[CLS]', 're', '##balance', '_', 'back', '##off', '_', 'ms', '=', '2', '*', '1000', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['re', '##balance', '_', 'back', '##off', '_', 'ms', '=', '2', '*', '1000', ',', '\\', 'n']
Detokenized (007): ['re##balance_back##off_ms', '=', '2', '*', '1000', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "uuid = uuid4 ( ) \n"
Original    (006): ['uuid', '=', 'uuid4', '(', ')', '\\n']
Tokenized   (012): ['[CLS]', 'u', '##uid', '=', 'u', '##uid', '##4', '(', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['u', '##uid', '=', 'u', '##uid', '##4', '(', ')', '\\', 'n']
Detokenized (006): ['u##uid', '=', 'u##uid##4', '(', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : """ . join ( traceback . format_tb ( tb ) ) ) \n"
Original    (013): ['""', '.', 'join', '(', 'traceback', '.', 'format_tb', '(', 'tb', ')', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', '"', '"', '.', 'join', '(', 'trace', '##back', '.', 'format', '_', 'tb', '(', 'tb', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['"', '"', '.', 'join', '(', 'trace', '##back', '.', 'format', '_', 'tb', '(', 'tb', ')', ')', ')', '\\', 'n']
Detokenized (013): ['""', '.', 'join', '(', 'trace##back', '.', 'format_tb', '(', 'tb', ')', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "kazoo_kwargs = { : timeout / 1000 } \n"
Original    (009): ['kazoo_kwargs', '=', '{', ':', 'timeout', '/', '1000', '}', '\\n']
Tokenized   (018): ['[CLS]', 'ka', '##zoo', '_', 'kw', '##ar', '##gs', '=', '{', ':', 'time', '##out', '/', '1000', '}', '\\', 'n', '[SEP]']
Filtered   (016): ['ka', '##zoo', '_', 'kw', '##ar', '##gs', '=', '{', ':', 'time', '##out', '/', '1000', '}', '\\', 'n']
Detokenized (009): ['ka##zoo_kw##ar##gs', '=', '{', ':', 'time##out', '/', '1000', '}', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "p_to_str = lambda p : . join ( [ str ( p . topic . name ) , str ( p . leader . id ) , str ( p . id ) ] ) \n"
Original    (036): ['p_to_str', '=', 'lambda', 'p', ':', '.', 'join', '(', '[', 'str', '(', 'p', '.', 'topic', '.', 'name', ')', ',', 'str', '(', 'p', '.', 'leader', '.', 'id', ')', ',', 'str', '(', 'p', '.', 'id', ')', ']', ')', '\\n']
Tokenized   (047): ['[CLS]', 'p', '_', 'to', '_', 'st', '##r', '=', 'lambda', 'p', ':', '.', 'join', '(', '[', 'st', '##r', '(', 'p', '.', 'topic', '.', 'name', ')', ',', 'st', '##r', '(', 'p', '.', 'leader', '.', 'id', ')', ',', 'st', '##r', '(', 'p', '.', 'id', ')', ']', ')', '\\', 'n', '[SEP]']
Filtered   (045): ['p', '_', 'to', '_', 'st', '##r', '=', 'lambda', 'p', ':', '.', 'join', '(', '[', 'st', '##r', '(', 'p', '.', 'topic', '.', 'name', ')', ',', 'st', '##r', '(', 'p', '.', 'leader', '.', 'id', ')', ',', 'st', '##r', '(', 'p', '.', 'id', ')', ']', ')', '\\', 'n']
Detokenized (036): ['p_to_st##r', '=', 'lambda', 'p', ':', '.', 'join', '(', '[', 'st##r', '(', 'p', '.', 'topic', '.', 'name', ')', ',', 'st##r', '(', 'p', '.', 'leader', '.', 'id', ')', ',', 'st##r', '(', 'p', '.', 'id', ')', ']', ')', '\\n']
Counter: 45
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "idx = participants . index ( consumer_id or self . _consumer_id ) \n"
Original    (013): ['idx', '=', 'participants', '.', 'index', '(', 'consumer_id', 'or', 'self', '.', '_consumer_id', ')', '\\n']
Tokenized   (022): ['[CLS]', 'id', '##x', '=', 'participants', '.', 'index', '(', 'consumer', '_', 'id', 'or', 'self', '.', '_', 'consumer', '_', 'id', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['id', '##x', '=', 'participants', '.', 'index', '(', 'consumer', '_', 'id', 'or', 'self', '.', '_', 'consumer', '_', 'id', ')', '\\', 'n']
Detokenized (013): ['id##x', '=', 'participants', '.', 'index', '(', 'consumer_id', 'or', 'self', '.', '_consumer_id', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "parts_per_consumer = len ( all_parts ) // len ( participants ) \n"
Original    (012): ['parts_per_consumer', '=', 'len', '(', 'all_parts', ')', '//', 'len', '(', 'participants', ')', '\\n']
Tokenized   (022): ['[CLS]', 'parts', '_', 'per', '_', 'consumer', '=', 'len', '(', 'all', '_', 'parts', ')', '/', '/', 'len', '(', 'participants', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['parts', '_', 'per', '_', 'consumer', '=', 'len', '(', 'all', '_', 'parts', ')', '/', '/', 'len', '(', 'participants', ')', '\\', 'n']
Detokenized (012): ['parts_per_consumer', '=', 'len', '(', 'all_parts', ')', '//', 'len', '(', 'participants', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "remainder_ppc = len ( all_parts ) % len ( participants ) \n"
Original    (012): ['remainder_ppc', '=', 'len', '(', 'all_parts', ')', '%', 'len', '(', 'participants', ')', '\\n']
Tokenized   (020): ['[CLS]', 'remainder', '_', 'pp', '##c', '=', 'len', '(', 'all', '_', 'parts', ')', '%', 'len', '(', 'participants', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['remainder', '_', 'pp', '##c', '=', 'len', '(', 'all', '_', 'parts', ')', '%', 'len', '(', 'participants', ')', '\\', 'n']
Detokenized (012): ['remainder_pp##c', '=', 'len', '(', 'all_parts', ')', '%', 'len', '(', 'participants', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "num_parts = parts_per_consumer + ( 0 if ( idx + 1 > remainder_ppc ) else 1 ) \n"
Original    (018): ['num_parts', '=', 'parts_per_consumer', '+', '(', '0', 'if', '(', 'idx', '+', '1', '>', 'remainder_ppc', ')', 'else', '1', ')', '\\n']
Tokenized   (032): ['[CLS]', 'nu', '##m', '_', 'parts', '=', 'parts', '_', 'per', '_', 'consumer', '+', '(', '0', 'if', '(', 'id', '##x', '+', '1', '>', 'remainder', '_', 'pp', '##c', ')', 'else', '1', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['nu', '##m', '_', 'parts', '=', 'parts', '_', 'per', '_', 'consumer', '+', '(', '0', 'if', '(', 'id', '##x', '+', '1', '>', 'remainder', '_', 'pp', '##c', ')', 'else', '1', ')', '\\', 'n']
Detokenized (018): ['nu##m_parts', '=', 'parts_per_consumer', '+', '(', '0', 'if', '(', 'id##x', '+', '1', '>', 'remainder_pp##c', ')', 'else', '1', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "log . debug ( , [ p_to_str ( p ) for p in new_partitions ] ) \n"
Original    (017): ['log', '.', 'debug', '(', ',', '[', 'p_to_str', '(', 'p', ')', 'for', 'p', 'in', 'new_partitions', ']', ')', '\\n']
Tokenized   (030): ['[CLS]', 'log', '.', 'de', '##bu', '##g', '(', ',', '[', 'p', '_', 'to', '_', 'st', '##r', '(', 'p', ')', 'for', 'p', 'in', 'new', '_', 'partition', '##s', ']', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['log', '.', 'de', '##bu', '##g', '(', ',', '[', 'p', '_', 'to', '_', 'st', '##r', '(', 'p', ')', 'for', 'p', 'in', 'new', '_', 'partition', '##s', ']', ')', '\\', 'n']
Detokenized (017): ['log', '.', 'de##bu##g', '(', ',', '[', 'p_to_st##r', '(', 'p', ')', 'for', 'p', 'in', 'new_partition##s', ']', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "id_ = get_string ( self . _consumer_id ) \n"
Original    (009): ['id_', '=', 'get_string', '(', 'self', '.', '_consumer_id', ')', '\\n']
Tokenized   (018): ['[CLS]', 'id', '_', '=', 'get', '_', 'string', '(', 'self', '.', '_', 'consumer', '_', 'id', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['id', '_', '=', 'get', '_', 'string', '(', 'self', '.', '_', 'consumer', '_', 'id', ')', '\\', 'n']
Detokenized (009): ['id_', '=', 'get_string', '(', 'self', '.', '_consumer_id', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "path = self . _topic_path , slug = partition_slug ) ) \n"
Original    (012): ['path', '=', 'self', '.', '_topic_path', ',', 'slug', '=', 'partition_slug', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'path', '=', 'self', '.', '_', 'topic', '_', 'path', ',', 'slug', '=', 'partition', '_', 'slug', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['path', '=', 'self', '.', '_', 'topic', '_', 'path', ',', 'slug', '=', 'partition', '_', 'slug', ')', ')', '\\', 'n']
Detokenized (012): ['path', '=', 'self', '.', '_topic_path', ',', 'slug', '=', 'partition_slug', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "HZCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (016): ['HZCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (023): ['[CLS]', 'hz', '##cha', '##rle', '##nta', '##ble', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['hz', '##cha', '##rle', '##nta', '##ble', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\', 'n']
Detokenized (016): ['hz##cha##rle##nta##ble', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "ISO2022CNCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (022): ['ISO2022CNCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (032): ['[CLS]', 'iso', '##20', '##22', '##c', '##nch', '##ar', '##lent', '##able', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['iso', '##20', '##22', '##c', '##nch', '##ar', '##lent', '##able', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\', 'n']
Detokenized (022): ['iso##20##22##c##nch##ar##lent##able', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "ISO2022JPCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (024): ['ISO2022JPCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (034): ['[CLS]', 'iso', '##20', '##22', '##j', '##pc', '##har', '##lent', '##able', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\', 'n', '[SEP]']
Filtered   (032): ['iso', '##20', '##22', '##j', '##pc', '##har', '##lent', '##able', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\', 'n']
Detokenized (024): ['iso##20##22##j##pc##har##lent##able', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "logging . basicConfig ( level = logging . INFO ) \n"
Original    (011): ['logging', '.', 'basicConfig', '(', 'level', '=', 'logging', '.', 'INFO', ')', '\\n']
Tokenized   (017): ['[CLS]', 'logging', '.', 'basic', '##con', '##fi', '##g', '(', 'level', '=', 'logging', '.', 'info', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['logging', '.', 'basic', '##con', '##fi', '##g', '(', 'level', '=', 'logging', '.', 'info', ')', '\\', 'n']
Detokenized (011): ['logging', '.', 'basic##con##fi##g', '(', 'level', '=', 'logging', '.', 'info', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tasa . __version__ , sys . version ) ) \n"
Original    (010): ['tasa', '.', '__version__', ',', 'sys', '.', 'version', ')', ')', '\\n']
Tokenized   (019): ['[CLS]', 'ta', '##sa', '.', '_', '_', 'version', '_', '_', ',', 'sy', '##s', '.', 'version', ')', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['ta', '##sa', '.', '_', '_', 'version', '_', '_', ',', 'sy', '##s', '.', 'version', ')', ')', '\\', 'n']
Detokenized (010): ['ta##sa', '.', '__version__', ',', 'sy##s', '.', 'version', ')', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "type = lambda w : w . partition ( ) [ : : 2 ] , \n"
Original    (017): ['type', '=', 'lambda', 'w', ':', 'w', '.', 'partition', '(', ')', '[', ':', ':', '2', ']', ',', '\\n']
Tokenized   (020): ['[CLS]', 'type', '=', 'lambda', 'w', ':', 'w', '.', 'partition', '(', ')', '[', ':', ':', '2', ']', ',', '\\', 'n', '[SEP]']
Filtered   (018): ['type', '=', 'lambda', 'w', ':', 'w', '.', 'partition', '(', ')', '[', ':', ':', '2', ']', ',', '\\', 'n']
Detokenized (017): ['type', '=', 'lambda', 'w', ':', 'w', '.', 'partition', '(', ')', '[', ':', ':', '2', ']', ',', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "worker_class_name = args . worker [ 1 ] or \n"
Original    (010): ['worker_class_name', '=', 'args', '.', 'worker', '[', '1', ']', 'or', '\\n']
Tokenized   (018): ['[CLS]', 'worker', '_', 'class', '_', 'name', '=', 'ar', '##gs', '.', 'worker', '[', '1', ']', 'or', '\\', 'n', '[SEP]']
Filtered   (016): ['worker', '_', 'class', '_', 'name', '=', 'ar', '##gs', '.', 'worker', '[', '1', ']', 'or', '\\', 'n']
Detokenized (010): ['worker_class_name', '=', 'ar##gs', '.', 'worker', '[', '1', ']', 'or', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "str ( job ) [ : 50 ] ) \n"
Original    (010): ['str', '(', 'job', ')', '[', ':', '50', ']', ')', '\\n']
Tokenized   (014): ['[CLS]', 'st', '##r', '(', 'job', ')', '[', ':', '50', ']', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['st', '##r', '(', 'job', ')', '[', ':', '50', ']', ')', '\\', 'n']
Detokenized (010): ['st##r', '(', 'job', ')', '[', ':', '50', ']', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "processes = [ Process ( target = run , args = ( ) ) for x in range ( count ) ] \n"
Original    (023): ['processes', '=', '[', 'Process', '(', 'target', '=', 'run', ',', 'args', '=', '(', ')', ')', 'for', 'x', 'in', 'range', '(', 'count', ')', ']', '\\n']
Tokenized   (027): ['[CLS]', 'processes', '=', '[', 'process', '(', 'target', '=', 'run', ',', 'ar', '##gs', '=', '(', ')', ')', 'for', 'x', 'in', 'range', '(', 'count', ')', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['processes', '=', '[', 'process', '(', 'target', '=', 'run', ',', 'ar', '##gs', '=', '(', ')', ')', 'for', 'x', 'in', 'range', '(', 'count', ')', ']', '\\', 'n']
Detokenized (023): ['processes', '=', '[', 'process', '(', 'target', '=', 'run', ',', 'ar##gs', '=', '(', ')', ')', 'for', 'x', 'in', 'range', '(', 'count', ')', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "color = models . CharField ( max_length = 6 , validators = [ color_regex ] , help_text = \n"
Original    (019): ['color', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '6', ',', 'validators', '=', '[', 'color_regex', ']', ',', 'help_text', '=', '\\n']
Tokenized   (031): ['[CLS]', 'color', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '6', ',', 'valid', '##ators', '=', '[', 'color', '_', 'reg', '##ex', ']', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (029): ['color', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '6', ',', 'valid', '##ators', '=', '[', 'color', '_', 'reg', '##ex', ']', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (019): ['color', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '6', ',', 'valid##ators', '=', '[', 'color_reg##ex', ']', ',', 'help_text', '=', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "first_name = models . CharField ( max_length = 64 ) \n"
Original    (011): ['first_name', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '64', ')', '\\n']
Tokenized   (019): ['[CLS]', 'first', '_', 'name', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '64', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['first', '_', 'name', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '64', ')', '\\', 'n']
Detokenized (011): ['first_name', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '64', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "role = models . CharField ( max_length = 17 , choices = ROLE_CHOICES ) \n"
Original    (015): ['role', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '17', ',', 'choices', '=', 'ROLE_CHOICES', ')', '\\n']
Tokenized   (023): ['[CLS]', 'role', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '17', ',', 'choices', '=', 'role', '_', 'choices', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['role', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '17', ',', 'choices', '=', 'role', '_', 'choices', ')', '\\', 'n']
Detokenized (015): ['role', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '17', ',', 'choices', '=', 'role_choices', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "phone_work = models . CharField ( max_length = 15 , validators = [ phone_regex ] , blank = True ) \n"
Original    (021): ['phone_work', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '15', ',', 'validators', '=', '[', 'phone_regex', ']', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (033): ['[CLS]', 'phone', '_', 'work', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '15', ',', 'valid', '##ators', '=', '[', 'phone', '_', 'reg', '##ex', ']', ',', 'blank', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['phone', '_', 'work', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '15', ',', 'valid', '##ators', '=', '[', 'phone', '_', 'reg', '##ex', ']', ',', 'blank', '=', 'true', ')', '\\', 'n']
Detokenized (021): ['phone_work', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '15', ',', 'valid##ators', '=', '[', 'phone_reg##ex', ']', ',', 'blank', '=', 'true', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "job_title = models . CharField ( max_length = 128 , blank = True ) \n"
Original    (015): ['job_title', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '128', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (023): ['[CLS]', 'job', '_', 'title', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '128', ',', 'blank', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['job', '_', 'title', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '128', ',', 'blank', '=', 'true', ')', '\\', 'n']
Detokenized (015): ['job_title', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '128', ',', 'blank', '=', 'true', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "category = models . CharField ( max_length = 21 , choices = CATEGORY_CHOICES , help_text = description = models . CharField ( max_length = 256 , blank = True , help_text = reference = models . URLField ( blank = True , help_text = ) \n"
Original    (046): ['category', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '21', ',', 'choices', '=', 'CATEGORY_CHOICES', ',', 'help_text', '=', 'description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '256', ',', 'blank', '=', 'True', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (065): ['[CLS]', 'category', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '21', ',', 'choices', '=', 'category', '_', 'choices', ',', 'help', '_', 'text', '=', 'description', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '256', ',', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'reference', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', ')', '\\', 'n', '[SEP]']
Filtered   (063): ['category', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '21', ',', 'choices', '=', 'category', '_', 'choices', ',', 'help', '_', 'text', '=', 'description', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '256', ',', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'reference', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', ')', '\\', 'n']
Detokenized (046): ['category', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '21', ',', 'choices', '=', 'category_choices', ',', 'help_text', '=', 'description', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '256', ',', 'blank', '=', 'true', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'ur##lf##ield', '(', 'blank', '=', 'true', ',', 'help_text', '=', ')', '\\n']
Counter: 63
===================================================================
Hidden states:  (13, 46, 768)
# Extracted words:  46
Sentence         : "acronym = models . CharField ( max_length = 20 , unique = True , help_text = category = models . CharField ( max_length = 9 , choices = CATEGORY_CHOICES , help_text = jurisdiction = models . CharField ( max_length = 64 , help_text = description = models . TextField ( blank = True , help_text = reference = models . URLField ( blank = True , help_text = ) \n"
Original    (070): ['acronym', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '20', ',', 'unique', '=', 'True', ',', 'help_text', '=', 'category', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '9', ',', 'choices', '=', 'CATEGORY_CHOICES', ',', 'help_text', '=', 'jurisdiction', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '64', ',', 'help_text', '=', 'description', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (097): ['[CLS]', 'acronym', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '20', ',', 'unique', '=', 'true', ',', 'help', '_', 'text', '=', 'category', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '9', ',', 'choices', '=', 'category', '_', 'choices', ',', 'help', '_', 'text', '=', 'jurisdiction', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '64', ',', 'help', '_', 'text', '=', 'description', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'reference', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', ')', '\\', 'n', '[SEP]']
Filtered   (095): ['acronym', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '20', ',', 'unique', '=', 'true', ',', 'help', '_', 'text', '=', 'category', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '9', ',', 'choices', '=', 'category', '_', 'choices', ',', 'help', '_', 'text', '=', 'jurisdiction', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '64', ',', 'help', '_', 'text', '=', 'description', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'reference', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', ')', '\\', 'n']
Detokenized (070): ['acronym', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '20', ',', 'unique', '=', 'true', ',', 'help_text', '=', 'category', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '9', ',', 'choices', '=', 'category_choices', ',', 'help_text', '=', 'jurisdiction', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '64', ',', 'help_text', '=', 'description', '=', 'models', '.', 'text##field', '(', 'blank', '=', 'true', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'ur##lf##ield', '(', 'blank', '=', 'true', ',', 'help_text', '=', ')', '\\n']
Counter: 95
===================================================================
Hidden states:  (13, 70, 768)
# Extracted words:  70
Sentence         : "description = models . CharField ( max_length = 256 , blank = True , help_text = \n"
Original    (017): ['description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '256', ',', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (025): ['[CLS]', 'description', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '256', ',', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (023): ['description', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '256', ',', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (017): ['description', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '256', ',', 'blank', '=', 'true', ',', 'help_text', '=', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "business_criticality = models . CharField ( max_length = 9 , choices = BUSINESS_CRITICALITY_CHOICES , blank platform = models . CharField ( max_length = 11 , choices = PLATFORM_CHOICES , blank = True , null = True ) \n"
Original    (038): ['business_criticality', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '9', ',', 'choices', '=', 'BUSINESS_CRITICALITY_CHOICES', ',', 'blank', 'platform', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '11', ',', 'choices', '=', 'PLATFORM_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (057): ['[CLS]', 'business', '_', 'critical', '##ity', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '9', ',', 'choices', '=', 'business', '_', 'critical', '##ity', '_', 'choices', ',', 'blank', 'platform', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '11', ',', 'choices', '=', 'platform', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (055): ['business', '_', 'critical', '##ity', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '9', ',', 'choices', '=', 'business', '_', 'critical', '##ity', '_', 'choices', ',', 'blank', 'platform', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '11', ',', 'choices', '=', 'platform', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\', 'n']
Detokenized (038): ['business_critical##ity', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '9', ',', 'choices', '=', 'business_critical##ity_choices', ',', 'blank', 'platform', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '11', ',', 'choices', '=', 'platform_choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\n']
Counter: 55
===================================================================
Hidden states:  (13, 38, 768)
# Extracted words:  38
Sentence         : "lifecycle = models . CharField ( max_length = 8 , choices = LIFECYCLE_CHOICES , blank = True , null = True ) \n"
Original    (023): ['lifecycle', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '8', ',', 'choices', '=', 'LIFECYCLE_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (033): ['[CLS]', 'life', '##cycle', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '8', ',', 'choices', '=', 'life', '##cycle', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['life', '##cycle', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '8', ',', 'choices', '=', 'life', '##cycle', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\', 'n']
Detokenized (023): ['life##cycle', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '8', ',', 'choices', '=', 'life##cycle_choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "user_records = models . PositiveIntegerField ( blank = True , null = True , help_text = revenue = models . DecimalField ( max_digits = 15 , decimal_places = 2 , blank = True , null = True , help_text = external_audience = models . BooleanField ( default = False , help_text = internet_accessible = models . BooleanField ( default = False , help_text = requestable = models . NullBooleanField ( default = True , help_text = _ ( \n"
Original    (079): ['user_records', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'revenue', '=', 'models', '.', 'DecimalField', '(', 'max_digits', '=', '15', ',', 'decimal_places', '=', '2', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'external_audience', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', 'internet_accessible', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', 'requestable', '=', 'models', '.', 'NullBooleanField', '(', 'default', '=', 'True', ',', 'help_text', '=', '_', '(', '\\n']
Tokenized   (115): ['[CLS]', 'user', '_', 'records', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'revenue', '=', 'models', '.', 'decimal', '##field', '(', 'max', '_', 'digits', '=', '15', ',', 'decimal', '_', 'places', '=', '2', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'external', '_', 'audience', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ',', 'help', '_', 'text', '=', 'internet', '_', 'accessible', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ',', 'help', '_', 'text', '=', 'request', '##able', '=', 'models', '.', 'null', '##bo', '##ole', '##an', '##field', '(', 'default', '=', 'true', ',', 'help', '_', 'text', '=', '_', '(', '\\', 'n', '[SEP]']
Filtered   (113): ['user', '_', 'records', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'revenue', '=', 'models', '.', 'decimal', '##field', '(', 'max', '_', 'digits', '=', '15', ',', 'decimal', '_', 'places', '=', '2', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'external', '_', 'audience', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ',', 'help', '_', 'text', '=', 'internet', '_', 'accessible', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ',', 'help', '_', 'text', '=', 'request', '##able', '=', 'models', '.', 'null', '##bo', '##ole', '##an', '##field', '(', 'default', '=', 'true', ',', 'help', '_', 'text', '=', '_', '(', '\\', 'n']
Detokenized (079): ['user_records', '=', 'models', '.', 'positive##int##eger##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'revenue', '=', 'models', '.', 'decimal##field', '(', 'max_digits', '=', '15', ',', 'decimal_places', '=', '2', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'external_audience', '=', 'models', '.', 'boo##lean##field', '(', 'default', '=', 'false', ',', 'help_text', '=', 'internet_accessible', '=', 'models', '.', 'boo##lean##field', '(', 'default', '=', 'false', ',', 'help_text', '=', 'request##able', '=', 'models', '.', 'null##bo##ole##an##field', '(', 'default', '=', 'true', ',', 'help_text', '=', '_', '(', '\\n']
Counter: 113
===================================================================
Hidden states:  (13, 79, 768)
# Extracted words:  79
Sentence         : "override_dcl = models . IntegerField ( choices = DATA_CLASSIFICATION_CHOICES , blank = True , null = True , help_text override_reason = models . TextField ( blank = True , help_text = \n"
Original    (032): ['override_dcl', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'DATA_CLASSIFICATION_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', 'override_reason', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (052): ['[CLS]', 'over', '##ride', '_', 'dc', '##l', '=', 'models', '.', 'integer', '##field', '(', 'choices', '=', 'data', '_', 'classification', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', 'over', '##ride', '_', 'reason', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (050): ['over', '##ride', '_', 'dc', '##l', '=', 'models', '.', 'integer', '##field', '(', 'choices', '=', 'data', '_', 'classification', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', 'over', '##ride', '_', 'reason', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (032): ['over##ride_dc##l', '=', 'models', '.', 'integer##field', '(', 'choices', '=', 'data_classification_choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', 'over##ride_reason', '=', 'models', '.', 'text##field', '(', 'blank', '=', 'true', ',', 'help_text', '=', '\\n']
Counter: 50
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "threadfix = models . ForeignKey ( ThreadFix , blank = True , null = True , help_text = threadfix_team_id = models . PositiveIntegerField ( blank = True , null = True , help_text = threadfix_application_id = models . PositiveIntegerField ( blank = True , null = True , help_text = \n"
Original    (051): ['threadfix', '=', 'models', '.', 'ForeignKey', '(', 'ThreadFix', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'threadfix_team_id', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'threadfix_application_id', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (083): ['[CLS]', 'thread', '##fi', '##x', '=', 'models', '.', 'foreign', '##key', '(', 'thread', '##fi', '##x', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'thread', '##fi', '##x', '_', 'team', '_', 'id', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'thread', '##fi', '##x', '_', 'application', '_', 'id', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (081): ['thread', '##fi', '##x', '=', 'models', '.', 'foreign', '##key', '(', 'thread', '##fi', '##x', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'thread', '##fi', '##x', '_', 'team', '_', 'id', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'thread', '##fi', '##x', '_', 'application', '_', 'id', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (051): ['thread##fi##x', '=', 'models', '.', 'foreign##key', '(', 'thread##fi##x', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'thread##fi##x_team_id', '=', 'models', '.', 'positive##int##eger##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'thread##fi##x_application_id', '=', 'models', '.', 'positive##int##eger##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', '\\n']
Counter: 81
===================================================================
Hidden states:  (13, 51, 768)
# Extracted words:  51
Sentence         : "asvs_level = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = asvs_level_percent_achieved = models . PositiveIntegerField ( blank = True , null = True , help_text = asvs_doc_url = models . URLField ( blank = True , help_text = ) \n"
Original    (050): ['asvs_level', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'ASVS_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'asvs_level_percent_achieved', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'asvs_doc_url', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (084): ['[CLS]', 'as', '##vs', '_', 'level', '=', 'models', '.', 'integer', '##field', '(', 'choices', '=', 'as', '##vs', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'as', '##vs', '_', 'level', '_', 'percent', '_', 'achieved', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'as', '##vs', '_', 'doc', '_', 'ur', '##l', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', ')', '\\', 'n', '[SEP]']
Filtered   (082): ['as', '##vs', '_', 'level', '=', 'models', '.', 'integer', '##field', '(', 'choices', '=', 'as', '##vs', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'as', '##vs', '_', 'level', '_', 'percent', '_', 'achieved', '=', 'models', '.', 'positive', '##int', '##eger', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'as', '##vs', '_', 'doc', '_', 'ur', '##l', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', ')', '\\', 'n']
Detokenized (050): ['as##vs_level', '=', 'models', '.', 'integer##field', '(', 'choices', '=', 'as##vs_choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'as##vs_level_percent_achieved', '=', 'models', '.', 'positive##int##eger##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'as##vs_doc_ur##l', '=', 'models', '.', 'ur##lf##ield', '(', 'blank', '=', 'true', ',', 'help_text', '=', ')', '\\n']
Counter: 82
===================================================================
Hidden states:  (13, 50, 768)
# Extracted words:  50
Sentence         : "asvs_level_target = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = \n"
Original    (021): ['asvs_level_target', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'ASVS_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (035): ['[CLS]', 'as', '##vs', '_', 'level', '_', 'target', '=', 'models', '.', 'integer', '##field', '(', 'choices', '=', 'as', '##vs', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (033): ['as', '##vs', '_', 'level', '_', 'target', '=', 'models', '.', 'integer', '##field', '(', 'choices', '=', 'as', '##vs', '_', 'choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (021): ['as##vs_level_target', '=', 'models', '.', 'integer##field', '(', 'choices', '=', 'as##vs_choices', ',', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "organization = models . ForeignKey ( Organization , help_text = people = models . ManyToManyField ( Person , through = , blank = True ) \n"
Original    (026): ['organization', '=', 'models', '.', 'ForeignKey', '(', 'Organization', ',', 'help_text', '=', 'people', '=', 'models', '.', 'ManyToManyField', '(', 'Person', ',', 'through', '=', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (035): ['[CLS]', 'organization', '=', 'models', '.', 'foreign', '##key', '(', 'organization', ',', 'help', '_', 'text', '=', 'people', '=', 'models', '.', 'many', '##tom', '##any', '##field', '(', 'person', ',', 'through', '=', ',', 'blank', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (033): ['organization', '=', 'models', '.', 'foreign', '##key', '(', 'organization', ',', 'help', '_', 'text', '=', 'people', '=', 'models', '.', 'many', '##tom', '##any', '##field', '(', 'person', ',', 'through', '=', ',', 'blank', '=', 'true', ')', '\\', 'n']
Detokenized (026): ['organization', '=', 'models', '.', 'foreign##key', '(', 'organization', ',', 'help_text', '=', 'people', '=', 'models', '.', 'many##tom##any##field', '(', 'person', ',', 'through', '=', ',', 'blank', '=', 'true', ')', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "delta = self . created_date - timezone . now ( ) \n"
Original    (012): ['delta', '=', 'self', '.', 'created_date', '-', 'timezone', '.', 'now', '(', ')', '\\n']
Tokenized   (018): ['[CLS]', 'delta', '=', 'self', '.', 'created', '_', 'date', '-', 'time', '##zone', '.', 'now', '(', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['delta', '=', 'self', '.', 'created', '_', 'date', '-', 'time', '##zone', '.', 'now', '(', ')', '\\', 'n']
Detokenized (012): ['delta', '=', 'self', '.', 'created_date', '-', 'time##zone', '.', 'now', '(', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "person = models . ForeignKey ( Person , help_text = ) \n"
Original    (012): ['person', '=', 'models', '.', 'ForeignKey', '(', 'Person', ',', 'help_text', '=', ')', '\\n']
Tokenized   (018): ['[CLS]', 'person', '=', 'models', '.', 'foreign', '##key', '(', 'person', ',', 'help', '_', 'text', '=', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['person', '=', 'models', '.', 'foreign', '##key', '(', 'person', ',', 'help', '_', 'text', '=', ')', '\\', 'n']
Detokenized (012): ['person', '=', 'models', '.', 'foreign##key', '(', 'person', ',', 'help_text', '=', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "environment_type = models . CharField ( max_length = 4 , choices = ENVIRONMENT_CHOICES , help_text = description = models . TextField ( blank = True , help_text = testing_approved = models . BooleanField ( default = False , help_text = \n"
Original    (041): ['environment_type', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '4', ',', 'choices', '=', 'ENVIRONMENT_CHOICES', ',', 'help_text', '=', 'description', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', 'testing_approved', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', '\\n']
Tokenized   (062): ['[CLS]', 'environment', '_', 'type', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '4', ',', 'choices', '=', 'environment', '_', 'choices', ',', 'help', '_', 'text', '=', 'description', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'testing', '_', 'approved', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (060): ['environment', '_', 'type', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '4', ',', 'choices', '=', 'environment', '_', 'choices', ',', 'help', '_', 'text', '=', 'description', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'testing', '_', 'approved', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (041): ['environment_type', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '4', ',', 'choices', '=', 'environment_choices', ',', 'help_text', '=', 'description', '=', 'models', '.', 'text##field', '(', 'blank', '=', 'true', ',', 'help_text', '=', 'testing_approved', '=', 'models', '.', 'boo##lean##field', '(', 'default', '=', 'false', ',', 'help_text', '=', '\\n']
Counter: 60
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "location = models . URLField ( help_text = notes = models . TextField ( blank = True , help_text = \n"
Original    (021): ['location', '=', 'models', '.', 'URLField', '(', 'help_text', '=', 'notes', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (031): ['[CLS]', 'location', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'help', '_', 'text', '=', 'notes', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (029): ['location', '=', 'models', '.', 'ur', '##lf', '##ield', '(', 'help', '_', 'text', '=', 'notes', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (021): ['location', '=', 'models', '.', 'ur##lf##ield', '(', 'help_text', '=', 'notes', '=', 'models', '.', 'text##field', '(', 'blank', '=', 'true', ',', 'help_text', '=', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "role_description = models . CharField ( max_length = 128 , blank = True , help_text = notes = models . TextField ( blank = True , help_text = \n"
Original    (029): ['role_description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '128', ',', 'blank', '=', 'True', ',', 'help_text', '=', 'notes', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (042): ['[CLS]', 'role', '_', 'description', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '128', ',', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'notes', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n', '[SEP]']
Filtered   (040): ['role', '_', 'description', '=', 'models', '.', 'char', '##field', '(', 'max', '_', 'length', '=', '128', ',', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', 'notes', '=', 'models', '.', 'text', '##field', '(', 'blank', '=', 'true', ',', 'help', '_', 'text', '=', '\\', 'n']
Detokenized (029): ['role_description', '=', 'models', '.', 'char##field', '(', 'max_length', '=', '128', ',', 'blank', '=', 'true', ',', 'help_text', '=', 'notes', '=', 'models', '.', 'text##field', '(', 'blank', '=', 'true', ',', 'help_text', '=', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "start_date = models . DateField ( help_text = ) \n"
Original    (010): ['start_date', '=', 'models', '.', 'DateField', '(', 'help_text', '=', ')', '\\n']
Tokenized   (018): ['[CLS]', 'start', '_', 'date', '=', 'models', '.', 'date', '##field', '(', 'help', '_', 'text', '=', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['start', '_', 'date', '=', 'models', '.', 'date', '##field', '(', 'help', '_', 'text', '=', ')', '\\', 'n']
Detokenized (010): ['start_date', '=', 'models', '.', 'date##field', '(', 'help_text', '=', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "open_date = models . DateTimeField ( blank = True , null = True , help_text = close_date = models . DateTimeField ( blank = True , null = True , help_text = duration = models . DurationField ( blank = True , null = True ) \n"
Original    (047): ['open_date', '=', 'models', '.', 'DateTimeField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'close_date', '=', 'models', '.', 'DateTimeField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'duration', '=', 'models', '.', 'DurationField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (063): ['[CLS]', 'open', '_', 'date', '=', 'models', '.', 'date', '##time', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'close', '_', 'date', '=', 'models', '.', 'date', '##time', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'duration', '=', 'models', '.', 'duration', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (061): ['open', '_', 'date', '=', 'models', '.', 'date', '##time', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'close', '_', 'date', '=', 'models', '.', 'date', '##time', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help', '_', 'text', '=', 'duration', '=', 'models', '.', 'duration', '##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\', 'n']
Detokenized (047): ['open_date', '=', 'models', '.', 'date##time##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'close_date', '=', 'models', '.', 'date##time##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ',', 'help_text', '=', 'duration', '=', 'models', '.', 'duration##field', '(', 'blank', '=', 'true', ',', 'null', '=', 'true', ')', '\\n']
Counter: 61
===================================================================
Hidden states:  (13, 47, 768)
# Extracted words:  47
Sentence         : "metrics = managers . ActivityTypeMetrics . from_queryset ( managers . ActivityTypeQuerySet ) ( ) \n"
Original    (015): ['metrics', '=', 'managers', '.', 'ActivityTypeMetrics', '.', 'from_queryset', '(', 'managers', '.', 'ActivityTypeQuerySet', ')', '(', ')', '\\n']
Tokenized   (029): ['[CLS]', 'metric', '##s', '=', 'managers', '.', 'activity', '##type', '##metric', '##s', '.', 'from', '_', 'query', '##set', '(', 'managers', '.', 'activity', '##type', '##que', '##rys', '##et', ')', '(', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['metric', '##s', '=', 'managers', '.', 'activity', '##type', '##metric', '##s', '.', 'from', '_', 'query', '##set', '(', 'managers', '.', 'activity', '##type', '##que', '##rys', '##et', ')', '(', ')', '\\', 'n']
Detokenized (015): ['metric##s', '=', 'managers', '.', 'activity##type##metric##s', '.', 'from_query##set', '(', 'managers', '.', 'activity##type##que##rys##et', ')', '(', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "token = models . UUIDField ( default = uuid . uuid4 , editable = False ) \n"
Original    (017): ['token', '=', 'models', '.', 'UUIDField', '(', 'default', '=', 'uuid', '.', 'uuid4', ',', 'editable', '=', 'False', ')', '\\n']
Tokenized   (026): ['[CLS]', 'token', '=', 'models', '.', 'u', '##uid', '##field', '(', 'default', '=', 'u', '##uid', '.', 'u', '##uid', '##4', ',', 'edit', '##able', '=', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (024): ['token', '=', 'models', '.', 'u', '##uid', '##field', '(', 'default', '=', 'u', '##uid', '.', 'u', '##uid', '##4', ',', 'edit', '##able', '=', 'false', ')', '\\', 'n']
Detokenized (017): ['token', '=', 'models', '.', 'u##uid##field', '(', 'default', '=', 'u##uid', '.', 'u##uid##4', ',', 'edit##able', '=', 'false', ')', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "activities = models . ManyToManyField ( ActivityType , limit_choices_to = { : True } ) \n"
Original    (016): ['activities', '=', 'models', '.', 'ManyToManyField', '(', 'ActivityType', ',', 'limit_choices_to', '=', '{', ':', 'True', '}', ')', '\\n']
Tokenized   (027): ['[CLS]', 'activities', '=', 'models', '.', 'many', '##tom', '##any', '##field', '(', 'activity', '##type', ',', 'limit', '_', 'choices', '_', 'to', '=', '{', ':', 'true', '}', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['activities', '=', 'models', '.', 'many', '##tom', '##any', '##field', '(', 'activity', '##type', ',', 'limit', '_', 'choices', '_', 'to', '=', '{', ':', 'true', '}', ')', '\\', 'n']
Detokenized (016): ['activities', '=', 'models', '.', 'many##tom##any##field', '(', 'activity##type', ',', 'limit_choices_to', '=', '{', ':', 'true', '}', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "opener . addheaders = [ ( , ) ] \n"
Original    (010): ['opener', '.', 'addheaders', '=', '[', '(', ',', ')', ']', '\\n']
Tokenized   (015): ['[CLS]', 'opener', '.', 'add', '##head', '##ers', '=', '[', '(', ',', ')', ']', '\\', 'n', '[SEP]']
Filtered   (013): ['opener', '.', 'add', '##head', '##ers', '=', '[', '(', ',', ')', ']', '\\', 'n']
Detokenized (010): ['opener', '.', 'add##head##ers', '=', '[', '(', ',', ')', ']', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "False = 0 \n"
Original    (004): ['False', '=', '0', '\\n']
Tokenized   (007): ['[CLS]', 'false', '=', '0', '\\', 'n', '[SEP]']
Filtered   (005): ['false', '=', '0', '\\', 'n']
Detokenized (004): ['false', '=', '0', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "option_pattern = chr ( 0 ) * 8 \n"
Original    (009): ['option_pattern', '=', 'chr', '(', '0', ')', '*', '8', '\\n']
Tokenized   (015): ['[CLS]', 'option', '_', 'pattern', '=', 'ch', '##r', '(', '0', ')', '*', '8', '\\', 'n', '[SEP]']
Filtered   (013): ['option', '_', 'pattern', '=', 'ch', '##r', '(', '0', ')', '*', '8', '\\', 'n']
Detokenized (009): ['option_pattern', '=', 'ch##r', '(', '0', ')', '*', '8', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "begin = toint ( s [ 5 : 9 ] ) \n"
Original    (012): ['begin', '=', 'toint', '(', 's', '[', '5', ':', '9', ']', ')', '\\n']
Tokenized   (016): ['[CLS]', 'begin', '=', 'to', '##int', '(', 's', '[', '5', ':', '9', ']', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['begin', '=', 'to', '##int', '(', 's', '[', '5', ':', '9', ']', ')', '\\', 'n']
Detokenized (012): ['begin', '=', 'to##int', '(', 's', '[', '5', ':', '9', ']', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "length = len ( s ) - 9 \n"
Original    (009): ['length', '=', 'len', '(', 's', ')', '-', '9', '\\n']
Tokenized   (012): ['[CLS]', 'length', '=', 'len', '(', 's', ')', '-', '9', '\\', 'n', '[SEP]']
Filtered   (010): ['length', '=', 'len', '(', 's', ')', '-', '9', '\\', 'n']
Detokenized (009): ['length', '=', 'len', '(', 's', ')', '-', '9', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "DivergeCommits = namedtuple ( "DivergeCommits" , [ "common_parent" , \n"
Original    (010): ['DivergeCommits', '=', 'namedtuple', '(', '"DivergeCommits"', ',', '[', '"common_parent"', ',', '\\n']
Tokenized   (029): ['[CLS]', 'diver', '##ge', '##com', '##mit', '##s', '=', 'named', '##tu', '##ple', '(', '"', 'diver', '##ge', '##com', '##mit', '##s', '"', ',', '[', '"', 'common', '_', 'parent', '"', ',', '\\', 'n', '[SEP]']
Filtered   (027): ['diver', '##ge', '##com', '##mit', '##s', '=', 'named', '##tu', '##ple', '(', '"', 'diver', '##ge', '##com', '##mit', '##s', '"', ',', '[', '"', 'common', '_', 'parent', '"', ',', '\\', 'n']
Detokenized (010): ['diver##ge##com##mit##s', '=', 'named##tu##ple', '(', '"diver##ge##com##mit##s"', ',', '[', '"common_parent"', ',', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : ""first_commits" , "second_commits" ] ) \n"
Original    (006): ['"first_commits"', ',', '"second_commits"', ']', ')', '\\n']
Tokenized   (017): ['[CLS]', '"', 'first', '_', 'commits', '"', ',', '"', 'second', '_', 'commits', '"', ']', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['"', 'first', '_', 'commits', '"', ',', '"', 'second', '_', 'commits', '"', ']', ')', '\\', 'n']
Detokenized (006): ['"first_commits"', ',', '"second_commits"', ']', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "behind = len ( diverge_commits . second_commits ) > 0 \n"
Original    (011): ['behind', '=', 'len', '(', 'diverge_commits', '.', 'second_commits', ')', '>', '0', '\\n']
Tokenized   (019): ['[CLS]', 'behind', '=', 'len', '(', 'diver', '##ge', '_', 'commits', '.', 'second', '_', 'commits', ')', '>', '0', '\\', 'n', '[SEP]']
Filtered   (017): ['behind', '=', 'len', '(', 'diver', '##ge', '_', 'commits', '.', 'second', '_', 'commits', ')', '>', '0', '\\', 'n']
Detokenized (011): ['behind', '=', 'len', '(', 'diver##ge_commits', '.', 'second_commits', ')', '>', '0', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "onerror = lambda function , fpath , excinfo : log . info ( \n"
Original    (014): ['onerror', '=', 'lambda', 'function', ',', 'fpath', ',', 'excinfo', ':', 'log', '.', 'info', '(', '\\n']
Tokenized   (022): ['[CLS]', 'one', '##rro', '##r', '=', 'lambda', 'function', ',', 'f', '##path', ',', 'ex', '##cin', '##fo', ':', 'log', '.', 'info', '(', '\\', 'n', '[SEP]']
Filtered   (020): ['one', '##rro', '##r', '=', 'lambda', 'function', ',', 'f', '##path', ',', 'ex', '##cin', '##fo', ':', 'log', '.', 'info', '(', '\\', 'n']
Detokenized (014): ['one##rro##r', '=', 'lambda', 'function', ',', 'f##path', ',', 'ex##cin##fo', ':', 'log', '.', 'info', '(', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "commiter = Signature ( commiter [ 0 ] , commiter [ 1 ] ) \n"
Original    (015): ['commiter', '=', 'Signature', '(', 'commiter', '[', '0', ']', ',', 'commiter', '[', '1', ']', ')', '\\n']
Tokenized   (021): ['[CLS]', 'commit', '##er', '=', 'signature', '(', 'commit', '##er', '[', '0', ']', ',', 'commit', '##er', '[', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['commit', '##er', '=', 'signature', '(', 'commit', '##er', '[', '0', ']', ',', 'commit', '##er', '[', '1', ']', ')', '\\', 'n']
Detokenized (015): ['commit##er', '=', 'signature', '(', 'commit##er', '[', '0', ']', ',', 'commit##er', '[', '1', ']', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "len ( path_components ) == 1 and \n"
Original    (008): ['len', '(', 'path_components', ')', '==', '1', 'and', '\\n']
Tokenized   (014): ['[CLS]', 'len', '(', 'path', '_', 'components', ')', '=', '=', '1', 'and', '\\', 'n', '[SEP]']
Filtered   (012): ['len', '(', 'path', '_', 'components', ')', '=', '=', '1', 'and', '\\', 'n']
Detokenized (008): ['len', '(', 'path_components', ')', '==', '1', 'and', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "entry_name == path_components [ 0 ] ) \n"
Original    (008): ['entry_name', '==', 'path_components', '[', '0', ']', ')', '\\n']
Tokenized   (016): ['[CLS]', 'entry', '_', 'name', '=', '=', 'path', '_', 'components', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['entry', '_', 'name', '=', '=', 'path', '_', 'components', '[', '0', ']', ')', '\\', 'n']
Detokenized (008): ['entry_name', '==', 'path_components', '[', '0', ']', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "lambda entry : self . _repo [ entry . id ] ) \n"
Original    (013): ['lambda', 'entry', ':', 'self', '.', '_repo', '[', 'entry', '.', 'id', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'lambda', 'entry', ':', 'self', '.', '_', 'rep', '##o', '[', 'entry', '.', 'id', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['lambda', 'entry', ':', 'self', '.', '_', 'rep', '##o', '[', 'entry', '.', 'id', ']', ')', '\\', 'n']
Detokenized (013): ['lambda', 'entry', ':', 'self', '.', '_rep##o', '[', 'entry', '.', 'id', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "GIT_FILEMODE_LINK : { \n"
Original    (004): ['GIT_FILEMODE_LINK', ':', '{', '\\n']
Tokenized   (014): ['[CLS]', 'gi', '##t', '_', 'file', '##mo', '##de', '_', 'link', ':', '{', '\\', 'n', '[SEP]']
Filtered   (012): ['gi', '##t', '_', 'file', '##mo', '##de', '_', 'link', ':', '{', '\\', 'n']
Detokenized (004): ['gi##t_file##mo##de_link', ':', '{', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "iterators = [ self . _repo . walk ( branch . target , sort ) \n"
Original    (016): ['iterators', '=', '[', 'self', '.', '_repo', '.', 'walk', '(', 'branch', '.', 'target', ',', 'sort', ')', '\\n']
Tokenized   (023): ['[CLS]', 'it', '##era', '##tors', '=', '[', 'self', '.', '_', 'rep', '##o', '.', 'walk', '(', 'branch', '.', 'target', ',', 'sort', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['it', '##era', '##tors', '=', '[', 'self', '.', '_', 'rep', '##o', '.', 'walk', '(', 'branch', '.', 'target', ',', 'sort', ')', '\\', 'n']
Detokenized (016): ['it##era##tors', '=', '[', 'self', '.', '_rep##o', '.', 'walk', '(', 'branch', '.', 'target', ',', 'sort', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "stop_iteration = [ False for branch in branches ] \n"
Original    (010): ['stop_iteration', '=', '[', 'False', 'for', 'branch', 'in', 'branches', ']', '\\n']
Tokenized   (015): ['[CLS]', 'stop', '_', 'iteration', '=', '[', 'false', 'for', 'branch', 'in', 'branches', ']', '\\', 'n', '[SEP]']
Filtered   (013): ['stop', '_', 'iteration', '=', '[', 'false', 'for', 'branch', 'in', 'branches', ']', '\\', 'n']
Detokenized (010): ['stop_iteration', '=', '[', 'false', 'for', 'branch', 'in', 'branches', ']', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "second_commit in first_commits ) : \n"
Original    (006): ['second_commit', 'in', 'first_commits', ')', ':', '\\n']
Tokenized   (013): ['[CLS]', 'second', '_', 'commit', 'in', 'first', '_', 'commits', ')', ':', '\\', 'n', '[SEP]']
Filtered   (011): ['second', '_', 'commit', 'in', 'first', '_', 'commits', ')', ':', '\\', 'n']
Detokenized (006): ['second_commit', 'in', 'first_commits', ')', ':', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "new_commit = Commit ( 2 , 2 , "21111111111" ) \n"
Original    (011): ['new_commit', '=', 'Commit', '(', '2', ',', '2', ',', '"21111111111"', ')', '\\n']
Tokenized   (022): ['[CLS]', 'new', '_', 'commit', '=', 'commit', '(', '2', ',', '2', ',', '"', '211', '##11', '##11', '##11', '##11', '"', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['new', '_', 'commit', '=', 'commit', '(', '2', ',', '2', ',', '"', '211', '##11', '##11', '##11', '##11', '"', ')', '\\', 'n']
Detokenized (011): ['new_commit', '=', 'commit', '(', '2', ',', '2', ',', '"211##11##11##11##11"', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "mocked_repo . walk . assert_called_once_with ( "head" , GIT_SORT_TIME ) \n"
Original    (011): ['mocked_repo', '.', 'walk', '.', 'assert_called_once_with', '(', '"head"', ',', 'GIT_SORT_TIME', ')', '\\n']
Tokenized   (030): ['[CLS]', 'mocked', '_', 'rep', '##o', '.', 'walk', '.', 'assert', '_', 'called', '_', 'once', '_', 'with', '(', '"', 'head', '"', ',', 'gi', '##t', '_', 'sort', '_', 'time', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['mocked', '_', 'rep', '##o', '.', 'walk', '.', 'assert', '_', 'called', '_', 'once', '_', 'with', '(', '"', 'head', '"', ',', 'gi', '##t', '_', 'sort', '_', 'time', ')', '\\', 'n']
Detokenized (011): ['mocked_rep##o', '.', 'walk', '.', 'assert_called_once_with', '(', '"head"', ',', 'gi##t_sort_time', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "to_datetime = True ) == datetime \n"
Original    (007): ['to_datetime', '=', 'True', ')', '==', 'datetime', '\\n']
Tokenized   (015): ['[CLS]', 'to', '_', 'date', '##time', '=', 'true', ')', '=', '=', 'date', '##time', '\\', 'n', '[SEP]']
Filtered   (013): ['to', '_', 'date', '##time', '=', 'true', ')', '=', '=', 'date', '##time', '\\', 'n']
Detokenized (007): ['to_date##time', '=', 'true', ')', '==', 'date##time', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "date = dt . date ( 1970 , 1 , 1 ) \n"
Original    (013): ['date', '=', 'dt', '.', 'date', '(', '1970', ',', '1', ',', '1', ')', '\\n']
Tokenized   (016): ['[CLS]', 'date', '=', 'dt', '.', 'date', '(', '1970', ',', '1', ',', '1', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['date', '=', 'dt', '.', 'date', '(', '1970', ',', '1', ',', '1', ')', '\\', 'n']
Detokenized (013): ['date', '=', 'dt', '.', 'date', '(', '1970', ',', '1', ',', '1', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "datetime = dt . datetime ( 1970 , 1 , 1 , 13 , 30 ) \n"
Original    (017): ['datetime', '=', 'dt', '.', 'datetime', '(', '1970', ',', '1', ',', '1', ',', '13', ',', '30', ')', '\\n']
Tokenized   (022): ['[CLS]', 'date', '##time', '=', 'dt', '.', 'date', '##time', '(', '1970', ',', '1', ',', '1', ',', '13', ',', '30', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['date', '##time', '=', 'dt', '.', 'date', '##time', '(', '1970', ',', '1', ',', '1', ',', '13', ',', '30', ')', '\\', 'n']
Detokenized (017): ['date##time', '=', 'dt', '.', 'date##time', '(', '1970', ',', '1', ',', '1', ',', '13', ',', '30', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "internationalizeDocstring = lambda x : x \n"
Original    (007): ['internationalizeDocstring', '=', 'lambda', 'x', ':', 'x', '\\n']
Tokenized   (014): ['[CLS]', 'international', '##ized', '##oc', '##st', '##ring', '=', 'lambda', 'x', ':', 'x', '\\', 'n', '[SEP]']
Filtered   (012): ['international', '##ized', '##oc', '##st', '##ring', '=', 'lambda', 'x', ':', 'x', '\\', 'n']
Detokenized (007): ['international##ized##oc##st##ring', '=', 'lambda', 'x', ':', 'x', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "conf . supybot . drivers . maxReconnectWait ( ) ) \n"
Original    (011): ['conf', '.', 'supybot', '.', 'drivers', '.', 'maxReconnectWait', '(', ')', ')', '\\n']
Tokenized   (023): ['[CLS]', 'con', '##f', '.', 'su', '##py', '##bot', '.', 'drivers', '.', 'max', '##re', '##con', '##ne', '##ct', '##wai', '##t', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['con', '##f', '.', 'su', '##py', '##bot', '.', 'drivers', '.', 'max', '##re', '##con', '##ne', '##ct', '##wai', '##t', '(', ')', ')', '\\', 'n']
Detokenized (011): ['con##f', '.', 'su##py##bot', '.', 'drivers', '.', 'max##re##con##ne##ct##wai##t', '(', ')', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "inst . conn . _sock . __class__ is socket . _closedsocket ) : \n"
Original    (014): ['inst', '.', 'conn', '.', '_sock', '.', '__class__', 'is', 'socket', '.', '_closedsocket', ')', ':', '\\n']
Tokenized   (028): ['[CLS]', 'ins', '##t', '.', 'con', '##n', '.', '_', 'sock', '.', '_', '_', 'class', '_', '_', 'is', 'socket', '.', '_', 'closed', '##so', '##cke', '##t', ')', ':', '\\', 'n', '[SEP]']
Filtered   (026): ['ins', '##t', '.', 'con', '##n', '.', '_', 'sock', '.', '_', '_', 'class', '_', '_', 'is', 'socket', '.', '_', 'closed', '##so', '##cke', '##t', ')', ':', '\\', 'n']
Detokenized (014): ['ins##t', '.', 'con##n', '.', '_sock', '.', '__class__', 'is', 'socket', '.', '_closed##so##cke##t', ')', ':', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "network_config = getattr ( conf . supybot . networks , self . irc . network ) \n"
Original    (017): ['network_config', '=', 'getattr', '(', 'conf', '.', 'supybot', '.', 'networks', ',', 'self', '.', 'irc', '.', 'network', ')', '\\n']
Tokenized   (030): ['[CLS]', 'network', '_', 'con', '##fi', '##g', '=', 'get', '##att', '##r', '(', 'con', '##f', '.', 'su', '##py', '##bot', '.', 'networks', ',', 'self', '.', 'ir', '##c', '.', 'network', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['network', '_', 'con', '##fi', '##g', '=', 'get', '##att', '##r', '(', 'con', '##f', '.', 'su', '##py', '##bot', '.', 'networks', ',', 'self', '.', 'ir', '##c', '.', 'network', ')', '\\', 'n']
Detokenized (017): ['network_con##fi##g', '=', 'get##att##r', '(', 'con##f', '.', 'su##py##bot', '.', 'networks', ',', 'self', '.', 'ir##c', '.', 'network', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "vhost = conf . supybot . protocols . irc . vhost ( ) , \n"
Original    (015): ['vhost', '=', 'conf', '.', 'supybot', '.', 'protocols', '.', 'irc', '.', 'vhost', '(', ')', ',', '\\n']
Tokenized   (026): ['[CLS]', 'v', '##hos', '##t', '=', 'con', '##f', '.', 'su', '##py', '##bot', '.', 'protocols', '.', 'ir', '##c', '.', 'v', '##hos', '##t', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['v', '##hos', '##t', '=', 'con', '##f', '.', 'su', '##py', '##bot', '.', 'protocols', '.', 'ir', '##c', '.', 'v', '##hos', '##t', '(', ')', ',', '\\', 'n']
Detokenized (015): ['v##hos##t', '=', 'con##f', '.', 'su##py##bot', '.', 'protocols', '.', 'ir##c', '.', 'v##hos##t', '(', ')', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "trusted_fingerprints = network_config . ssl . serverFingerprints ( ) , \n"
Original    (011): ['trusted_fingerprints', '=', 'network_config', '.', 'ssl', '.', 'serverFingerprints', '(', ')', ',', '\\n']
Tokenized   (024): ['[CLS]', 'trusted', '_', 'fingerprints', '=', 'network', '_', 'con', '##fi', '##g', '.', 'ss', '##l', '.', 'server', '##finger', '##print', '##s', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (022): ['trusted', '_', 'fingerprints', '=', 'network', '_', 'con', '##fi', '##g', '.', 'ss', '##l', '.', 'server', '##finger', '##print', '##s', '(', ')', ',', '\\', 'n']
Detokenized (011): ['trusted_fingerprints', '=', 'network_con##fi##g', '.', 'ss##l', '.', 'server##finger##print##s', '(', ')', ',', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "while tb : \n"
Original    (004): ['while', 'tb', ':', '\\n']
Tokenized   (007): ['[CLS]', 'while', 'tb', ':', '\\', 'n', '[SEP]']
Filtered   (005): ['while', 'tb', ':', '\\', 'n']
Detokenized (004): ['while', 'tb', ':', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "frame . f_lineno ) ) \n"
Original    (006): ['frame', '.', 'f_lineno', ')', ')', '\\n']
Tokenized   (012): ['[CLS]', 'frame', '.', 'f', '_', 'linen', '##o', ')', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['frame', '.', 'f', '_', 'linen', '##o', ')', ')', '\\', 'n']
Detokenized (006): ['frame', '.', 'f_linen##o', ')', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "window = timedelta ( 0 , 0 , 0 , 0 , settings . SESSION_TIMEOUT ) \n"
Original    (017): ['window', '=', 'timedelta', '(', '0', ',', '0', ',', '0', ',', '0', ',', 'settings', '.', 'SESSION_TIMEOUT', ')', '\\n']
Tokenized   (025): ['[CLS]', 'window', '=', 'timed', '##elt', '##a', '(', '0', ',', '0', ',', '0', ',', '0', ',', 'settings', '.', 'session', '_', 'time', '##out', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['window', '=', 'timed', '##elt', '##a', '(', '0', ',', '0', ',', '0', ',', '0', ',', 'settings', '.', 'session', '_', 'time', '##out', ')', '\\', 'n']
Detokenized (017): ['window', '=', 'timed##elt##a', '(', '0', ',', '0', ',', '0', ',', '0', ',', 'settings', '.', 'session_time##out', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "shared = request . POST . get ( "shared" , False ) \n"
Original    (013): ['shared', '=', 'request', '.', 'POST', '.', 'get', '(', '"shared"', ',', 'False', ')', '\\n']
Tokenized   (018): ['[CLS]', 'shared', '=', 'request', '.', 'post', '.', 'get', '(', '"', 'shared', '"', ',', 'false', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['shared', '=', 'request', '.', 'post', '.', 'get', '(', '"', 'shared', '"', ',', 'false', ')', '\\', 'n']
Detokenized (013): ['shared', '=', 'request', '.', 'post', '.', 'get', '(', '"shared"', ',', 'false', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "} , p . score_functions . all ( ) . filter ( selectable_bodies = plan . legislative_body } , report_displays [ 0 ] . scorepanel_set . all ( ) . order_by ( ) ) \n"
Original    (035): ['}', ',', 'p', '.', 'score_functions', '.', 'all', '(', ')', '.', 'filter', '(', 'selectable_bodies', '=', 'plan', '.', 'legislative_body', '}', ',', 'report_displays', '[', '0', ']', '.', 'scorepanel_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', ')', '\\n']
Tokenized   (053): ['[CLS]', '}', ',', 'p', '.', 'score', '_', 'functions', '.', 'all', '(', ')', '.', 'filter', '(', 'select', '##able', '_', 'bodies', '=', 'plan', '.', 'legislative', '_', 'body', '}', ',', 'report', '_', 'displays', '[', '0', ']', '.', 'score', '##pan', '##el', '_', 'set', '.', 'all', '(', ')', '.', 'order', '_', 'by', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (051): ['}', ',', 'p', '.', 'score', '_', 'functions', '.', 'all', '(', ')', '.', 'filter', '(', 'select', '##able', '_', 'bodies', '=', 'plan', '.', 'legislative', '_', 'body', '}', ',', 'report', '_', 'displays', '[', '0', ']', '.', 'score', '##pan', '##el', '_', 'set', '.', 'all', '(', ')', '.', 'order', '_', 'by', '(', ')', ')', '\\', 'n']
Detokenized (035): ['}', ',', 'p', '.', 'score_functions', '.', 'all', '(', ')', '.', 'filter', '(', 'select##able_bodies', '=', 'plan', '.', 'legislative_body', '}', ',', 'report_displays', '[', '0', ']', '.', 'score##pan##el_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', ')', '\\n']
Counter: 51
===================================================================
Hidden states:  (13, 35, 768)
# Extracted words:  35
Sentence         : "body_member_long_label = _ ( ) + \n"
Original    (007): ['body_member_long_label', '=', '_', '(', ')', '+', '\\n']
Tokenized   (016): ['[CLS]', 'body', '_', 'member', '_', 'long', '_', 'label', '=', '_', '(', ')', '+', '\\', 'n', '[SEP]']
Filtered   (014): ['body', '_', 'member', '_', 'long', '_', 'label', '=', '_', '(', ')', '+', '\\', 'n']
Detokenized (007): ['body_member_long_label', '=', '_', '(', ')', '+', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "body_members = _n ( , , 2 ) \n"
Original    (009): ['body_members', '=', '_n', '(', ',', ',', '2', ')', '\\n']
Tokenized   (015): ['[CLS]', 'body', '_', 'members', '=', '_', 'n', '(', ',', ',', '2', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['body', '_', 'members', '=', '_', 'n', '(', ',', ',', '2', ')', '\\', 'n']
Detokenized (009): ['body_members', '=', '_n', '(', ',', ',', '2', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "has_regions = Region . objects . all ( ) . count ( ) > 1 \n"
Original    (016): ['has_regions', '=', 'Region', '.', 'objects', '.', 'all', '(', ')', '.', 'count', '(', ')', '>', '1', '\\n']
Tokenized   (021): ['[CLS]', 'has', '_', 'regions', '=', 'region', '.', 'objects', '.', 'all', '(', ')', '.', 'count', '(', ')', '>', '1', '\\', 'n', '[SEP]']
Filtered   (019): ['has', '_', 'regions', '=', 'region', '.', 'objects', '.', 'all', '(', ')', '.', 'count', '(', ')', '>', '1', '\\', 'n']
Detokenized (016): ['has_regions', '=', 'region', '.', 'objects', '.', 'all', '(', ')', '.', 'count', '(', ')', '>', '1', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "bodies = LegislativeBody . objects . all ( ) . order_by ( , ) \n"
Original    (015): ['bodies', '=', 'LegislativeBody', '.', 'objects', '.', 'all', '(', ')', '.', 'order_by', '(', ',', ')', '\\n']
Tokenized   (021): ['[CLS]', 'bodies', '=', 'legislative', '##body', '.', 'objects', '.', 'all', '(', ')', '.', 'order', '_', 'by', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['bodies', '=', 'legislative', '##body', '.', 'objects', '.', 'all', '(', ')', '.', 'order', '_', 'by', '(', ',', ')', '\\', 'n']
Detokenized (015): ['bodies', '=', 'legislative##body', '.', 'objects', '.', 'all', '(', ')', '.', 'order_by', '(', ',', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "l_bodies = [ b for b in bodies if b in [ sd . legislative_body for sd in ScoreDisplay . objects . filter \n"
Original    (024): ['l_bodies', '=', '[', 'b', 'for', 'b', 'in', 'bodies', 'if', 'b', 'in', '[', 'sd', '.', 'legislative_body', 'for', 'sd', 'in', 'ScoreDisplay', '.', 'objects', '.', 'filter', '\\n']
Tokenized   (033): ['[CLS]', 'l', '_', 'bodies', '=', '[', 'b', 'for', 'b', 'in', 'bodies', 'if', 'b', 'in', '[', 'sd', '.', 'legislative', '_', 'body', 'for', 'sd', 'in', 'scored', '##is', '##play', '.', 'objects', '.', 'filter', '\\', 'n', '[SEP]']
Filtered   (031): ['l', '_', 'bodies', '=', '[', 'b', 'for', 'b', 'in', 'bodies', 'if', 'b', 'in', '[', 'sd', '.', 'legislative', '_', 'body', 'for', 'sd', 'in', 'scored', '##is', '##play', '.', 'objects', '.', 'filter', '\\', 'n']
Detokenized (024): ['l_bodies', '=', '[', 'b', 'for', 'b', 'in', 'bodies', 'if', 'b', 'in', '[', 'sd', '.', 'legislative_body', 'for', 'sd', 'in', 'scored##is##play', '.', 'objects', '.', 'filter', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "cfg [ ] = datetime . now ( ) \n"
Original    (010): ['cfg', '[', ']', '=', 'datetime', '.', 'now', '(', ')', '\\n']
Tokenized   (015): ['[CLS]', 'cf', '##g', '[', ']', '=', 'date', '##time', '.', 'now', '(', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['cf', '##g', '[', ']', '=', 'date', '##time', '.', 'now', '(', ')', '\\', 'n']
Detokenized (010): ['cf##g', '[', ']', '=', 'date##time', '.', 'now', '(', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ll = ModestMaps . Geo . Location ( pt1 . y , pt1 . x ) \n"
Original    (017): ['ll', '=', 'ModestMaps', '.', 'Geo', '.', 'Location', '(', 'pt1', '.', 'y', ',', 'pt1', '.', 'x', ')', '\\n']
Tokenized   (024): ['[CLS]', 'll', '=', 'modest', '##ma', '##ps', '.', 'geo', '.', 'location', '(', 'pt', '##1', '.', 'y', ',', 'pt', '##1', '.', 'x', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['ll', '=', 'modest', '##ma', '##ps', '.', 'geo', '.', 'location', '(', 'pt', '##1', '.', 'y', ',', 'pt', '##1', '.', 'x', ')', '\\', 'n']
Detokenized (017): ['ll', '=', 'modest##ma##ps', '.', 'geo', '.', 'location', '(', 'pt##1', '.', 'y', ',', 'pt##1', '.', 'x', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "provider = ModestMaps . WMS . Provider ( cfg [ ] , { \n"
Original    (014): ['provider', '=', 'ModestMaps', '.', 'WMS', '.', 'Provider', '(', 'cfg', '[', ']', ',', '{', '\\n']
Tokenized   (021): ['[CLS]', 'provider', '=', 'modest', '##ma', '##ps', '.', 'w', '##ms', '.', 'provider', '(', 'cf', '##g', '[', ']', ',', '{', '\\', 'n', '[SEP]']
Filtered   (019): ['provider', '=', 'modest', '##ma', '##ps', '.', 'w', '##ms', '.', 'provider', '(', 'cf', '##g', '[', ']', ',', '{', '\\', 'n']
Detokenized (014): ['provider', '=', 'modest##ma##ps', '.', 'w##ms', '.', 'provider', '(', 'cf##g', '[', ']', ',', '{', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "overlayImg = Image . blend ( overlayImg , ModestMaps . mapByExtent ( provider , ll , ur , dims ) . draw ( ) , \n"
Original    (026): ['overlayImg', '=', 'Image', '.', 'blend', '(', 'overlayImg', ',', 'ModestMaps', '.', 'mapByExtent', '(', 'provider', ',', 'll', ',', 'ur', ',', 'dims', ')', '.', 'draw', '(', ')', ',', '\\n']
Tokenized   (042): ['[CLS]', 'over', '##lay', '##im', '##g', '=', 'image', '.', 'blend', '(', 'over', '##lay', '##im', '##g', ',', 'modest', '##ma', '##ps', '.', 'map', '##by', '##ex', '##ten', '##t', '(', 'provider', ',', 'll', ',', 'ur', ',', 'dim', '##s', ')', '.', 'draw', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (040): ['over', '##lay', '##im', '##g', '=', 'image', '.', 'blend', '(', 'over', '##lay', '##im', '##g', ',', 'modest', '##ma', '##ps', '.', 'map', '##by', '##ex', '##ten', '##t', '(', 'provider', ',', 'll', ',', 'ur', ',', 'dim', '##s', ')', '.', 'draw', '(', ')', ',', '\\', 'n']
Detokenized (026): ['over##lay##im##g', '=', 'image', '.', 'blend', '(', 'over##lay##im##g', ',', 'modest##ma##ps', '.', 'map##by##ex##ten##t', '(', 'provider', ',', 'll', ',', 'ur', ',', 'dim##s', ')', '.', 'draw', '(', ')', ',', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "fullImg . save ( settings . WEB_TEMP + ( % sha . hexdigest ( ) ) , , quality = 100 ) \n"
Original    (023): ['fullImg', '.', 'save', '(', 'settings', '.', 'WEB_TEMP', '+', '(', '%', 'sha', '.', 'hexdigest', '(', ')', ')', ',', ',', 'quality', '=', '100', ')', '\\n']
Tokenized   (035): ['[CLS]', 'full', '##im', '##g', '.', 'save', '(', 'settings', '.', 'web', '_', 'te', '##mp', '+', '(', '%', 'sha', '.', 'he', '##x', '##di', '##ges', '##t', '(', ')', ')', ',', ',', 'quality', '=', '100', ')', '\\', 'n', '[SEP]']
Filtered   (033): ['full', '##im', '##g', '.', 'save', '(', 'settings', '.', 'web', '_', 'te', '##mp', '+', '(', '%', 'sha', '.', 'he', '##x', '##di', '##ges', '##t', '(', ')', ')', ',', ',', 'quality', '=', '100', ')', '\\', 'n']
Detokenized (023): ['full##im##g', '.', 'save', '(', 'settings', '.', 'web_te##mp', '+', '(', '%', 'sha', '.', 'he##x##di##ges##t', '(', ')', ')', ',', ',', 'quality', '=', '100', ')', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "CreatePDF ( page , result , show_error_as_pdf = True ) \n"
Original    (011): ['CreatePDF', '(', 'page', ',', 'result', ',', 'show_error_as_pdf', '=', 'True', ')', '\\n']
Tokenized   (022): ['[CLS]', 'create', '##pd', '##f', '(', 'page', ',', 'result', ',', 'show', '_', 'error', '_', 'as', '_', 'pdf', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['create', '##pd', '##f', '(', 'page', ',', 'result', ',', 'show', '_', 'error', '_', 'as', '_', 'pdf', '=', 'true', ')', '\\', 'n']
Detokenized (011): ['create##pd##f', '(', 'page', ',', 'result', ',', 'show_error_as_pdf', '=', 'true', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "body = LegislativeBody . objects . get ( id = int ( request . POST [ ] ) ) \n"
Original    (020): ['body', '=', 'LegislativeBody', '.', 'objects', '.', 'get', '(', 'id', '=', 'int', '(', 'request', '.', 'POST', '[', ']', ')', ')', '\\n']
Tokenized   (024): ['[CLS]', 'body', '=', 'legislative', '##body', '.', 'objects', '.', 'get', '(', 'id', '=', 'int', '(', 'request', '.', 'post', '[', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['body', '=', 'legislative', '##body', '.', 'objects', '.', 'get', '(', 'id', '=', 'int', '(', 'request', '.', 'post', '[', ']', ')', ')', '\\', 'n']
Detokenized (020): ['body', '=', 'legislative##body', '.', 'objects', '.', 'get', '(', 'id', '=', 'int', '(', 'request', '.', 'post', '[', ']', ')', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "PlanReport . createreport . delay ( planid , stamp , req , language = translation . get_language ( ) ) \n"
Original    (021): ['PlanReport', '.', 'createreport', '.', 'delay', '(', 'planid', ',', 'stamp', ',', 'req', ',', 'language', '=', 'translation', '.', 'get_language', '(', ')', ')', '\\n']
Tokenized   (032): ['[CLS]', 'plan', '##re', '##port', '.', 'create', '##re', '##port', '.', 'delay', '(', 'plan', '##id', ',', 'stamp', ',', 're', '##q', ',', 'language', '=', 'translation', '.', 'get', '_', 'language', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (030): ['plan', '##re', '##port', '.', 'create', '##re', '##port', '.', 'delay', '(', 'plan', '##id', ',', 'stamp', ',', 're', '##q', ',', 'language', '=', 'translation', '.', 'get', '_', 'language', '(', ')', ')', '\\', 'n']
Detokenized (021): ['plan##re##port', '.', 'create##re##port', '.', 'delay', '(', 'plan##id', ',', 'stamp', ',', 're##q', ',', 'language', '=', 'translation', '.', 'get_language', '(', ')', ')', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "stamp = request . POST . get ( , sha . hexdigest ( ) ) \n"
Original    (016): ['stamp', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'sha', '.', 'hexdigest', '(', ')', ')', '\\n']
Tokenized   (023): ['[CLS]', 'stamp', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'sha', '.', 'he', '##x', '##di', '##ges', '##t', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['stamp', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'sha', '.', 'he', '##x', '##di', '##ges', '##t', '(', ')', ')', '\\', 'n']
Detokenized (016): ['stamp', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'sha', '.', 'he##x##di##ges##t', '(', ')', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "CalculatorReport . createcalculatorreport . delay ( planid , stamp , req , language = translation . get_language ~~ else : \n"
Original    (021): ['CalculatorReport', '.', 'createcalculatorreport', '.', 'delay', '(', 'planid', ',', 'stamp', ',', 'req', ',', 'language', '=', 'translation', '.', 'get_language', '~~', 'else', ':', '\\n']
Tokenized   (038): ['[CLS]', 'cal', '##cula', '##tor', '##re', '##port', '.', 'create', '##cal', '##cula', '##tor', '##re', '##port', '.', 'delay', '(', 'plan', '##id', ',', 'stamp', ',', 're', '##q', ',', 'language', '=', 'translation', '.', 'get', '_', 'language', '~', '~', 'else', ':', '\\', 'n', '[SEP]']
Filtered   (036): ['cal', '##cula', '##tor', '##re', '##port', '.', 'create', '##cal', '##cula', '##tor', '##re', '##port', '.', 'delay', '(', 'plan', '##id', ',', 'stamp', ',', 're', '##q', ',', 'language', '=', 'translation', '.', 'get', '_', 'language', '~', '~', 'else', ':', '\\', 'n']
Detokenized (021): ['cal##cula##tor##re##port', '.', 'create##cal##cula##tor##re##port', '.', 'delay', '(', 'plan##id', ',', 'stamp', ',', 're##q', ',', 'language', '=', 'translation', '.', 'get_language', '~~', 'else', ':', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "site_id = Site . objects . get_current ( ) . id , \n"
Original    (013): ['site_id', '=', 'Site', '.', 'objects', '.', 'get_current', '(', ')', '.', 'id', ',', '\\n']
Tokenized   (020): ['[CLS]', 'site', '_', 'id', '=', 'site', '.', 'objects', '.', 'get', '_', 'current', '(', ')', '.', 'id', ',', '\\', 'n', '[SEP]']
Filtered   (018): ['site', '_', 'id', '=', 'site', '.', 'objects', '.', 'get', '_', 'current', '(', ')', '.', 'id', ',', '\\', 'n']
Detokenized (013): ['site_id', '=', 'site', '.', 'objects', '.', 'get_current', '(', ')', '.', 'id', ',', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "from_id = int ( request . POST . get ( , - 1 ) ) \n"
Original    (016): ['from_id', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', '-', '1', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'from', '_', 'id', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', '-', '1', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['from', '_', 'id', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', '-', '1', ')', ')', '\\', 'n']
Detokenized (016): ['from_id', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', '-', '1', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "to_id = int ( request . POST . get ( , None ) ) \n"
Original    (015): ['to_id', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', 'None', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'to', '_', 'id', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', 'none', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['to', '_', 'id', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', 'none', ')', ')', '\\', 'n']
Detokenized (015): ['to_id', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', 'none', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "from_districts = filter ( lambda d : True if d . district_id == from_id else False , all_districts to_district = filter ( lambda d : True if d . district_id == to_id else False , all_districts ) [ 0 ] \n"
Original    (041): ['from_districts', '=', 'filter', '(', 'lambda', 'd', ':', 'True', 'if', 'd', '.', 'district_id', '==', 'from_id', 'else', 'False', ',', 'all_districts', 'to_district', '=', 'filter', '(', 'lambda', 'd', ':', 'True', 'if', 'd', '.', 'district_id', '==', 'to_id', 'else', 'False', ',', 'all_districts', ')', '[', '0', ']', '\\n']
Tokenized   (062): ['[CLS]', 'from', '_', 'districts', '=', 'filter', '(', 'lambda', 'd', ':', 'true', 'if', 'd', '.', 'district', '_', 'id', '=', '=', 'from', '_', 'id', 'else', 'false', ',', 'all', '_', 'districts', 'to', '_', 'district', '=', 'filter', '(', 'lambda', 'd', ':', 'true', 'if', 'd', '.', 'district', '_', 'id', '=', '=', 'to', '_', 'id', 'else', 'false', ',', 'all', '_', 'districts', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (060): ['from', '_', 'districts', '=', 'filter', '(', 'lambda', 'd', ':', 'true', 'if', 'd', '.', 'district', '_', 'id', '=', '=', 'from', '_', 'id', 'else', 'false', ',', 'all', '_', 'districts', 'to', '_', 'district', '=', 'filter', '(', 'lambda', 'd', ':', 'true', 'if', 'd', '.', 'district', '_', 'id', '=', '=', 'to', '_', 'id', 'else', 'false', ',', 'all', '_', 'districts', ')', '[', '0', ']', '\\', 'n']
Detokenized (041): ['from_districts', '=', 'filter', '(', 'lambda', 'd', ':', 'true', 'if', 'd', '.', 'district_id', '==', 'from_id', 'else', 'false', ',', 'all_districts', 'to_district', '=', 'filter', '(', 'lambda', 'd', ':', 'true', 'if', 'd', '.', 'district_id', '==', 'to_id', 'else', 'false', ',', 'all_districts', ')', '[', '0', ']', '\\n']
Counter: 60
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "inverse = request . REQUEST [ ] == if in request . REQUEST else False \n"
Original    (016): ['inverse', '=', 'request', '.', 'REQUEST', '[', ']', '==', 'if', 'in', 'request', '.', 'REQUEST', 'else', 'False', '\\n']
Tokenized   (020): ['[CLS]', 'inverse', '=', 'request', '.', 'request', '[', ']', '=', '=', 'if', 'in', 'request', '.', 'request', 'else', 'false', '\\', 'n', '[SEP]']
Filtered   (018): ['inverse', '=', 'request', '.', 'request', '[', ']', '=', '=', 'if', 'in', 'request', '.', 'request', 'else', 'false', '\\', 'n']
Detokenized (016): ['inverse', '=', 'request', '.', 'request', '[', ']', '==', 'if', 'in', 'request', '.', 'request', 'else', 'false', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "my_context . update ( plan . compute_splits ( layer , version = version , inverse = inverse , extended last_item = layer is layers [ - 1 ] \n"
Original    (029): ['my_context', '.', 'update', '(', 'plan', '.', 'compute_splits', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', ',', 'extended', 'last_item', '=', 'layer', 'is', 'layers', '[', '-', '1', ']', '\\n']
Tokenized   (038): ['[CLS]', 'my', '_', 'context', '.', 'update', '(', 'plan', '.', 'compute', '_', 'splits', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', ',', 'extended', 'last', '_', 'item', '=', 'layer', 'is', 'layers', '[', '-', '1', ']', '\\', 'n', '[SEP]']
Filtered   (036): ['my', '_', 'context', '.', 'update', '(', 'plan', '.', 'compute', '_', 'splits', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', ',', 'extended', 'last', '_', 'item', '=', 'layer', 'is', 'layers', '[', '-', '1', ']', '\\', 'n']
Detokenized (029): ['my_context', '.', 'update', '(', 'plan', '.', 'compute_splits', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', ',', 'extended', 'last_item', '=', 'layer', 'is', 'layers', '[', '-', '1', ']', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "community_info = plan . get_community_type_info ( layer , version = version , inverse = inverse if community_info is not None : \n"
Original    (022): ['community_info', '=', 'plan', '.', 'get_community_type_info', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', 'if', 'community_info', 'is', 'not', 'None', ':', '\\n']
Tokenized   (035): ['[CLS]', 'community', '_', 'info', '=', 'plan', '.', 'get', '_', 'community', '_', 'type', '_', 'info', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', 'if', 'community', '_', 'info', 'is', 'not', 'none', ':', '\\', 'n', '[SEP]']
Filtered   (033): ['community', '_', 'info', '=', 'plan', '.', 'get', '_', 'community', '_', 'type', '_', 'info', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', 'if', 'community', '_', 'info', 'is', 'not', 'none', ':', '\\', 'n']
Detokenized (022): ['community_info', '=', 'plan', '.', 'get_community_type_info', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', 'if', 'community_info', 'is', 'not', 'none', ':', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "html += report . render ( calc_context ) \n"
Original    (009): ['html', '+=', 'report', '.', 'render', '(', 'calc_context', ')', '\\n']
Tokenized   (016): ['[CLS]', 'html', '+', '=', 'report', '.', 'render', '(', 'cal', '##c', '_', 'context', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['html', '+', '=', 'report', '.', 'render', '(', 'cal', '##c', '_', 'context', ')', '\\', 'n']
Detokenized (009): ['html', '+=', 'report', '.', 'render', '(', 'cal##c_context', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "geounit_ids = string . split ( request . REQUEST [ "geounits" ] , "|" ) \n"
Original    (016): ['geounit_ids', '=', 'string', '.', 'split', '(', 'request', '.', 'REQUEST', '[', '"geounits"', ']', ',', '"|"', ')', '\\n']
Tokenized   (030): ['[CLS]', 'geo', '##uni', '##t', '_', 'id', '##s', '=', 'string', '.', 'split', '(', 'request', '.', 'request', '[', '"', 'geo', '##uni', '##ts', '"', ']', ',', '"', '|', '"', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['geo', '##uni', '##t', '_', 'id', '##s', '=', 'string', '.', 'split', '(', 'request', '.', 'request', '[', '"', 'geo', '##uni', '##ts', '"', ']', ',', '"', '|', '"', ')', '\\', 'n']
Detokenized (016): ['geo##uni##t_id##s', '=', 'string', '.', 'split', '(', 'request', '.', 'request', '[', '"geo##uni##ts"', ']', ',', '"|"', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "max_version = max ( [ d . version for d in districts ] ) \n"
Original    (015): ['max_version', '=', 'max', '(', '[', 'd', '.', 'version', 'for', 'd', 'in', 'districts', ']', ')', '\\n']
Tokenized   (020): ['[CLS]', 'max', '_', 'version', '=', 'max', '(', '[', 'd', '.', 'version', 'for', 'd', 'in', 'districts', ']', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['max', '_', 'version', '=', 'max', '(', '[', 'd', '.', 'version', 'for', 'd', 'in', 'districts', ']', ')', '\\', 'n']
Detokenized (015): ['max_version', '=', 'max', '(', '[', 'd', '.', 'version', 'for', 'd', 'in', 'districts', ']', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "can_undo = max_version > plan . min_version \n"
Original    (008): ['can_undo', '=', 'max_version', '>', 'plan', '.', 'min_version', '\\n']
Tokenized   (017): ['[CLS]', 'can', '_', 'undo', '=', 'max', '_', 'version', '>', 'plan', '.', 'min', '_', 'version', '\\', 'n', '[SEP]']
Filtered   (015): ['can', '_', 'undo', '=', 'max', '_', 'version', '>', 'plan', '.', 'min', '_', 'version', '\\', 'n']
Detokenized (008): ['can_undo', '=', 'max_version', '>', 'plan', '.', 'min_version', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bbox = tuple ( map ( lambda x : float ( x ) , bbox . split ( ) ) ) \n"
Original    (022): ['bbox', '=', 'tuple', '(', 'map', '(', 'lambda', 'x', ':', 'float', '(', 'x', ')', ',', 'bbox', '.', 'split', '(', ')', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'bb', '##ox', '=', 'tu', '##ple', '(', 'map', '(', 'lambda', 'x', ':', 'float', '(', 'x', ')', ',', 'bb', '##ox', '.', 'split', '(', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['bb', '##ox', '=', 'tu', '##ple', '(', 'map', '(', 'lambda', 'x', ':', 'float', '(', 'x', ')', ',', 'bb', '##ox', '.', 'split', '(', ')', ')', ')', '\\', 'n']
Detokenized (022): ['bb##ox', '=', 'tu##ple', '(', 'map', '(', 'lambda', 'x', ':', 'float', '(', 'x', ')', ',', 'bb##ox', '.', 'split', '(', ')', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "wkt = wkt . replace ( , ) . replace ( , ) \n"
Original    (014): ['wkt', '=', 'wkt', '.', 'replace', '(', ',', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (019): ['[CLS]', 'w', '##kt', '=', 'w', '##kt', '.', 'replace', '(', ',', ')', '.', 'replace', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['w', '##kt', '=', 'w', '##kt', '.', 'replace', '(', ',', ')', '.', 'replace', '(', ',', ')', '\\', 'n']
Detokenized (014): ['w##kt', '=', 'w##kt', '.', 'replace', '(', ',', ')', '.', 'replace', '(', ',', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "districts = [ d . id for d in plan . get_districts_at_version ( version , include_geom = True ) if locked = District . objects . filter ( id__in = districts ) . collect ( ) \n"
Original    (037): ['districts', '=', '[', 'd', '.', 'id', 'for', 'd', 'in', 'plan', '.', 'get_districts_at_version', '(', 'version', ',', 'include_geom', '=', 'True', ')', 'if', 'locked', '=', 'District', '.', 'objects', '.', 'filter', '(', 'id__in', '=', 'districts', ')', '.', 'collect', '(', ')', '\\n']
Tokenized   (052): ['[CLS]', 'districts', '=', '[', 'd', '.', 'id', 'for', 'd', 'in', 'plan', '.', 'get', '_', 'districts', '_', 'at', '_', 'version', '(', 'version', ',', 'include', '_', 'geo', '##m', '=', 'true', ')', 'if', 'locked', '=', 'district', '.', 'objects', '.', 'filter', '(', 'id', '_', '_', 'in', '=', 'districts', ')', '.', 'collect', '(', ')', '\\', 'n', '[SEP]']
Filtered   (050): ['districts', '=', '[', 'd', '.', 'id', 'for', 'd', 'in', 'plan', '.', 'get', '_', 'districts', '_', 'at', '_', 'version', '(', 'version', ',', 'include', '_', 'geo', '##m', '=', 'true', ')', 'if', 'locked', '=', 'district', '.', 'objects', '.', 'filter', '(', 'id', '_', '_', 'in', '=', 'districts', ')', '.', 'collect', '(', ')', '\\', 'n']
Detokenized (037): ['districts', '=', '[', 'd', '.', 'id', 'for', 'd', 'in', 'plan', '.', 'get_districts_at_version', '(', 'version', ',', 'include_geo##m', '=', 'true', ')', 'if', 'locked', '=', 'district', '.', 'objects', '.', 'filter', '(', 'id__in', '=', 'districts', ')', '.', 'collect', '(', ')', '\\n']
Counter: 50
===================================================================
Hidden states:  (13, 37, 768)
# Extracted words:  37
Sentence         : "locked_buffered = locked . simplify ( 100 , True ) . buffer ( 100 ) if locked else None \n"
Original    (020): ['locked_buffered', '=', 'locked', '.', 'simplify', '(', '100', ',', 'True', ')', '.', 'buffer', '(', '100', ')', 'if', 'locked', 'else', 'None', '\\n']
Tokenized   (027): ['[CLS]', 'locked', '_', 'buffer', '##ed', '=', 'locked', '.', 'sim', '##plify', '(', '100', ',', 'true', ')', '.', 'buffer', '(', '100', ')', 'if', 'locked', 'else', 'none', '\\', 'n', '[SEP]']
Filtered   (025): ['locked', '_', 'buffer', '##ed', '=', 'locked', '.', 'sim', '##plify', '(', '100', ',', 'true', ')', '.', 'buffer', '(', '100', ')', 'if', 'locked', 'else', 'none', '\\', 'n']
Detokenized (020): ['locked_buffer##ed', '=', 'locked', '.', 'sim##plify', '(', '100', ',', 'true', ')', '.', 'buffer', '(', '100', ')', 'if', 'locked', 'else', 'none', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "filtered = Geolevel . objects . get ( id = geolevel ) . geounit_set . filter ( selection ) \n"
Original    (020): ['filtered', '=', 'Geolevel', '.', 'objects', '.', 'get', '(', 'id', '=', 'geolevel', ')', '.', 'geounit_set', '.', 'filter', '(', 'selection', ')', '\\n']
Tokenized   (031): ['[CLS]', 'filtered', '=', 'geo', '##lev', '##el', '.', 'objects', '.', 'get', '(', 'id', '=', 'geo', '##lev', '##el', ')', '.', 'geo', '##uni', '##t', '_', 'set', '.', 'filter', '(', 'selection', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['filtered', '=', 'geo', '##lev', '##el', '.', 'objects', '.', 'get', '(', 'id', '=', 'geo', '##lev', '##el', ')', '.', 'geo', '##uni', '##t', '_', 'set', '.', 'filter', '(', 'selection', ')', '\\', 'n']
Detokenized (020): ['filtered', '=', 'geo##lev##el', '.', 'objects', '.', 'get', '(', 'id', '=', 'geo##lev##el', ')', '.', 'geo##uni##t_set', '.', 'filter', '(', 'selection', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "pfilter = Q ( legislative_body = leg_body ) & Q ( is_valid = True ) \n"
Original    (016): ['pfilter', '=', 'Q', '(', 'legislative_body', '=', 'leg_body', ')', '&', 'Q', '(', 'is_valid', '=', 'True', ')', '\\n']
Tokenized   (027): ['[CLS]', 'p', '##fi', '##lter', '=', 'q', '(', 'legislative', '_', 'body', '=', 'leg', '_', 'body', ')', '&', 'q', '(', 'is', '_', 'valid', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['p', '##fi', '##lter', '=', 'q', '(', 'legislative', '_', 'body', '=', 'leg', '_', 'body', ')', '&', 'q', '(', 'is', '_', 'valid', '=', 'true', ')', '\\', 'n']
Detokenized (016): ['p##fi##lter', '=', 'q', '(', 'legislative_body', '=', 'leg_body', ')', '&', 'q', '(', 'is_valid', '=', 'true', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "panels = display . scorepanel_set . all ( ) . order_by ( ) \n"
Original    (014): ['panels', '=', 'display', '.', 'scorepanel_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', '\\n']
Tokenized   (023): ['[CLS]', 'panels', '=', 'display', '.', 'score', '##pan', '##el', '_', 'set', '.', 'all', '(', ')', '.', 'order', '_', 'by', '(', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['panels', '=', 'display', '.', 'score', '##pan', '##el', '_', 'set', '.', 'all', '(', ')', '.', 'order', '_', 'by', '(', ')', '\\', 'n']
Detokenized (014): ['panels', '=', 'display', '.', 'score##pan##el_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "writer . writerow ( [ , , ] + [ p . __unicode__ ( ) for p in panels ] ) \n"
Original    (022): ['writer', '.', 'writerow', '(', '[', ',', ',', ']', '+', '[', 'p', '.', '__unicode__', '(', ')', 'for', 'p', 'in', 'panels', ']', ')', '\\n']
Tokenized   (030): ['[CLS]', 'writer', '.', 'writer', '##ow', '(', '[', ',', ',', ']', '+', '[', 'p', '.', '_', '_', 'unicode', '_', '_', '(', ')', 'for', 'p', 'in', 'panels', ']', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['writer', '.', 'writer', '##ow', '(', '[', ',', ',', ']', '+', '[', 'p', '.', '_', '_', 'unicode', '_', '_', '(', ')', 'for', 'p', 'in', 'panels', ']', ')', '\\', 'n']
Detokenized (022): ['writer', '.', 'writer##ow', '(', '[', ',', ',', ']', '+', '[', 'p', '.', '__unicode__', '(', ')', 'for', 'p', 'in', 'panels', ']', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "rows = int ( request . POST . get ( , 10 ) ) \n"
Original    (015): ['rows', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', '10', ')', ')', '\\n']
Tokenized   (018): ['[CLS]', 'rows', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', '10', ')', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['rows', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', '10', ')', ')', '\\', 'n']
Detokenized (015): ['rows', '=', 'int', '(', 'request', '.', 'post', '.', 'get', '(', ',', '10', ')', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "sidx = request . POST . get ( , ) \n"
Original    (011): ['sidx', '=', 'request', '.', 'POST', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (015): ['[CLS]', 'sid', '##x', '=', 'request', '.', 'post', '.', 'get', '(', ',', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['sid', '##x', '=', 'request', '.', 'post', '.', 'get', '(', ',', ')', '\\', 'n']
Detokenized (011): ['sid##x', '=', 'request', '.', 'post', '.', 'get', '(', ',', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "owner_filter = request . POST . get ( ) ; \n"
Original    (011): ['owner_filter', '=', 'request', '.', 'POST', '.', 'get', '(', ')', ';', '\\n']
Tokenized   (016): ['[CLS]', 'owner', '_', 'filter', '=', 'request', '.', 'post', '.', 'get', '(', ')', ';', '\\', 'n', '[SEP]']
Filtered   (014): ['owner', '_', 'filter', '=', 'request', '.', 'post', '.', 'get', '(', ')', ';', '\\', 'n']
Detokenized (011): ['owner_filter', '=', 'request', '.', 'post', '.', 'get', '(', ')', ';', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "body_pk = int ( body_pk ) if body_pk else body_pk ; \n"
Original    (012): ['body_pk', '=', 'int', '(', 'body_pk', ')', 'if', 'body_pk', 'else', 'body_pk', ';', '\\n']
Tokenized   (027): ['[CLS]', 'body', '_', 'p', '##k', '=', 'int', '(', 'body', '_', 'p', '##k', ')', 'if', 'body', '_', 'p', '##k', 'else', 'body', '_', 'p', '##k', ';', '\\', 'n', '[SEP]']
Filtered   (025): ['body', '_', 'p', '##k', '=', 'int', '(', 'body', '_', 'p', '##k', ')', 'if', 'body', '_', 'p', '##k', 'else', 'body', '_', 'p', '##k', ';', '\\', 'n']
Detokenized (012): ['body_p##k', '=', 'int', '(', 'body_p##k', ')', 'if', 'body_p##k', 'else', 'body_p##k', ';', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "search = request . POST . get ( , False ) ; \n"
Original    (013): ['search', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'False', ')', ';', '\\n']
Tokenized   (016): ['[CLS]', 'search', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'false', ')', ';', '\\', 'n', '[SEP]']
Filtered   (014): ['search', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'false', ')', ';', '\\', 'n']
Detokenized (013): ['search', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'false', ')', ';', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "search_string = request . POST . get ( , ) ; \n"
Original    (012): ['search_string', '=', 'request', '.', 'POST', '.', 'get', '(', ',', ')', ';', '\\n']
Tokenized   (017): ['[CLS]', 'search', '_', 'string', '=', 'request', '.', 'post', '.', 'get', '(', ',', ')', ';', '\\', 'n', '[SEP]']
Filtered   (015): ['search', '_', 'string', '=', 'request', '.', 'post', '.', 'get', '(', ',', ')', ';', '\\', 'n']
Detokenized (012): ['search_string', '=', 'request', '.', 'post', '.', 'get', '(', ',', ')', ';', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "is_community = request . POST . get ( , False ) == ; \n"
Original    (014): ['is_community', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'False', ')', '==', ';', '\\n']
Tokenized   (020): ['[CLS]', 'is', '_', 'community', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'false', ')', '=', '=', ';', '\\', 'n', '[SEP]']
Filtered   (018): ['is', '_', 'community', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'false', ')', '=', '=', ';', '\\', 'n']
Detokenized (014): ['is_community', '=', 'request', '.', 'post', '.', 'get', '(', ',', 'false', ')', '==', ';', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "all_plans = Plan . objects . filter ( available , not_creating , search_filter , community_filter ) . order_by \n"
Original    (019): ['all_plans', '=', 'Plan', '.', 'objects', '.', 'filter', '(', 'available', ',', 'not_creating', ',', 'search_filter', ',', 'community_filter', ')', '.', 'order_by', '\\n']
Tokenized   (032): ['[CLS]', 'all', '_', 'plans', '=', 'plan', '.', 'objects', '.', 'filter', '(', 'available', ',', 'not', '_', 'creating', ',', 'search', '_', 'filter', ',', 'community', '_', 'filter', ')', '.', 'order', '_', 'by', '\\', 'n', '[SEP]']
Filtered   (030): ['all', '_', 'plans', '=', 'plan', '.', 'objects', '.', 'filter', '(', 'available', ',', 'not', '_', 'creating', ',', 'search', '_', 'filter', ',', 'community', '_', 'filter', ')', '.', 'order', '_', 'by', '\\', 'n']
Detokenized (019): ['all_plans', '=', 'plan', '.', 'objects', '.', 'filter', '(', 'available', ',', 'not_creating', ',', 'search_filter', ',', 'community_filter', ')', '.', 'order_by', '\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "all_districts = ( ) \n"
Original    (005): ['all_districts', '=', '(', ')', '\\n']
Tokenized   (010): ['[CLS]', 'all', '_', 'districts', '=', '(', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['all', '_', 'districts', '=', '(', ')', '\\', 'n']
Detokenized (005): ['all_districts', '=', '(', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "_ ( ) ) \n"
Original    (005): ['_', '(', ')', ')', '\\n']
Tokenized   (008): ['[CLS]', '_', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (006): ['_', '(', ')', ')', '\\', 'n']
Detokenized (005): ['_', '(', ')', ')', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "user_functions = ScoreFunction . objects . filter ( selectable_bodies = plan . legislative_body ) . order_by for f in user_functions : \n"
Original    (022): ['user_functions', '=', 'ScoreFunction', '.', 'objects', '.', 'filter', '(', 'selectable_bodies', '=', 'plan', '.', 'legislative_body', ')', '.', 'order_by', 'for', 'f', 'in', 'user_functions', ':', '\\n']
Tokenized   (038): ['[CLS]', 'user', '_', 'functions', '=', 'score', '##fu', '##nction', '.', 'objects', '.', 'filter', '(', 'select', '##able', '_', 'bodies', '=', 'plan', '.', 'legislative', '_', 'body', ')', '.', 'order', '_', 'by', 'for', 'f', 'in', 'user', '_', 'functions', ':', '\\', 'n', '[SEP]']
Filtered   (036): ['user', '_', 'functions', '=', 'score', '##fu', '##nction', '.', 'objects', '.', 'filter', '(', 'select', '##able', '_', 'bodies', '=', 'plan', '.', 'legislative', '_', 'body', ')', '.', 'order', '_', 'by', 'for', 'f', 'in', 'user', '_', 'functions', ':', '\\', 'n']
Detokenized (022): ['user_functions', '=', 'score##fu##nction', '.', 'objects', '.', 'filter', '(', 'select##able_bodies', '=', 'plan', '.', 'legislative_body', ')', '.', 'order_by', 'for', 'f', 'in', 'user_functions', ':', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : ""%s_sidebar_demo" % plan . legislative_body . name , \n"
Original    (009): ['"%s_sidebar_demo"', '%', 'plan', '.', 'legislative_body', '.', 'name', ',', '\\n']
Tokenized   (022): ['[CLS]', '"', '%', 's', '_', 'side', '##bar', '_', 'demo', '"', '%', 'plan', '.', 'legislative', '_', 'body', '.', 'name', ',', '\\', 'n', '[SEP]']
Filtered   (020): ['"', '%', 's', '_', 'side', '##bar', '_', 'demo', '"', '%', 'plan', '.', 'legislative', '_', 'body', '.', 'name', ',', '\\', 'n']
Detokenized (009): ['"%s_side##bar_demo"', '%', 'plan', '.', 'legislative_body', '.', 'name', ',', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "plan . legislative_body . name ) \n"
Original    (007): ['plan', '.', 'legislative_body', '.', 'name', ')', '\\n']
Tokenized   (012): ['[CLS]', 'plan', '.', 'legislative', '_', 'body', '.', 'name', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['plan', '.', 'legislative', '_', 'body', '.', 'name', ')', '\\', 'n']
Detokenized (007): ['plan', '.', 'legislative_body', '.', 'name', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "functions = map ( lambda x : int ( x ) , functions ) \n"
Original    (015): ['functions', '=', 'map', '(', 'lambda', 'x', ':', 'int', '(', 'x', ')', ',', 'functions', ')', '\\n']
Tokenized   (018): ['[CLS]', 'functions', '=', 'map', '(', 'lambda', 'x', ':', 'int', '(', 'x', ')', ',', 'functions', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['functions', '=', 'map', '(', 'lambda', 'x', ':', 'int', '(', 'x', ')', ',', 'functions', ')', '\\', 'n']
Detokenized (015): ['functions', '=', 'map', '(', 'lambda', 'x', ':', 'int', '(', 'x', ')', ',', 'functions', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "display = display . copy_from ( display = demo , title = request . POST . get ( ) , owner = result [ ] = True \n"
Original    (028): ['display', '=', 'display', '.', 'copy_from', '(', 'display', '=', 'demo', ',', 'title', '=', 'request', '.', 'POST', '.', 'get', '(', ')', ',', 'owner', '=', 'result', '[', ']', '=', 'True', '\\n']
Tokenized   (033): ['[CLS]', 'display', '=', 'display', '.', 'copy', '_', 'from', '(', 'display', '=', 'demo', ',', 'title', '=', 'request', '.', 'post', '.', 'get', '(', ')', ',', 'owner', '=', 'result', '[', ']', '=', 'true', '\\', 'n', '[SEP]']
Filtered   (031): ['display', '=', 'display', '.', 'copy', '_', 'from', '(', 'display', '=', 'demo', ',', 'title', '=', 'request', '.', 'post', '.', 'get', '(', ')', ',', 'owner', '=', 'result', '[', ']', '=', 'true', '\\', 'n']
Detokenized (028): ['display', '=', 'display', '.', 'copy_from', '(', 'display', '=', 'demo', ',', 'title', '=', 'request', '.', 'post', '.', 'get', '(', ')', ',', 'owner', '=', 'result', '[', ']', '=', 'true', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "version = min ( plan . version , int ( version ) ) \n"
Original    (014): ['version', '=', 'min', '(', 'plan', '.', 'version', ',', 'int', '(', 'version', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 'version', '=', 'min', '(', 'plan', '.', 'version', ',', 'int', '(', 'version', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['version', '=', 'min', '(', 'plan', '.', 'version', ',', 'int', '(', 'version', ')', ')', '\\', 'n']
Detokenized (014): ['version', '=', 'min', '(', 'plan', '.', 'version', ',', 'int', '(', 'version', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "Comment . objects . filter ( object_pk = district . id , content_type = ct ) . delete ( ) \n"
Original    (021): ['Comment', '.', 'objects', '.', 'filter', '(', 'object_pk', '=', 'district', '.', 'id', ',', 'content_type', '=', 'ct', ')', '.', 'delete', '(', ')', '\\n']
Tokenized   (030): ['[CLS]', 'comment', '.', 'objects', '.', 'filter', '(', 'object', '_', 'p', '##k', '=', 'district', '.', 'id', ',', 'content', '_', 'type', '=', 'ct', ')', '.', 'del', '##ete', '(', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['comment', '.', 'objects', '.', 'filter', '(', 'object', '_', 'p', '##k', '=', 'district', '.', 'id', ',', 'content', '_', 'type', '=', 'ct', ')', '.', 'del', '##ete', '(', ')', '\\', 'n']
Detokenized (021): ['comment', '.', 'objects', '.', 'filter', '(', 'object_p##k', '=', 'district', '.', 'id', ',', 'content_type', '=', 'ct', ')', '.', 'del##ete', '(', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "TaggedItem . objects . filter ( tag__in = tset , object_id = district . id ) . delete ( ) \n"
Original    (021): ['TaggedItem', '.', 'objects', '.', 'filter', '(', 'tag__in', '=', 'tset', ',', 'object_id', '=', 'district', '.', 'id', ')', '.', 'delete', '(', ')', '\\n']
Tokenized   (033): ['[CLS]', 'tagged', '##ite', '##m', '.', 'objects', '.', 'filter', '(', 'tag', '_', '_', 'in', '=', 'ts', '##et', ',', 'object', '_', 'id', '=', 'district', '.', 'id', ')', '.', 'del', '##ete', '(', ')', '\\', 'n', '[SEP]']
Filtered   (031): ['tagged', '##ite', '##m', '.', 'objects', '.', 'filter', '(', 'tag', '_', '_', 'in', '=', 'ts', '##et', ',', 'object', '_', 'id', '=', 'district', '.', 'id', ')', '.', 'del', '##ete', '(', ')', '\\', 'n']
Detokenized (021): ['tagged##ite##m', '.', 'objects', '.', 'filter', '(', 'tag__in', '=', 'ts##et', ',', 'object_id', '=', 'district', '.', 'id', ')', '.', 'del##ete', '(', ')', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "geolevel = plans [ 0 ] . legislative_body . get_geolevels ( ) [ 0 ] \n"
Original    (016): ['geolevel', '=', 'plans', '[', '0', ']', '.', 'legislative_body', '.', 'get_geolevels', '(', ')', '[', '0', ']', '\\n']
Tokenized   (027): ['[CLS]', 'geo', '##lev', '##el', '=', 'plans', '[', '0', ']', '.', 'legislative', '_', 'body', '.', 'get', '_', 'geo', '##lev', '##els', '(', ')', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (025): ['geo', '##lev', '##el', '=', 'plans', '[', '0', ']', '.', 'legislative', '_', 'body', '.', 'get', '_', 'geo', '##lev', '##els', '(', ')', '[', '0', ']', '\\', 'n']
Detokenized (016): ['geo##lev##el', '=', 'plans', '[', '0', ']', '.', 'legislative_body', '.', 'get_geo##lev##els', '(', ')', '[', '0', ']', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "plans = Plan . objects . filter ( is_shared = True ) . order_by ( ) [ 0 : 10 ] \n"
Original    (022): ['plans', '=', 'Plan', '.', 'objects', '.', 'filter', '(', 'is_shared', '=', 'True', ')', '.', 'order_by', '(', ')', '[', '0', ':', '10', ']', '\\n']
Tokenized   (029): ['[CLS]', 'plans', '=', 'plan', '.', 'objects', '.', 'filter', '(', 'is', '_', 'shared', '=', 'true', ')', '.', 'order', '_', 'by', '(', ')', '[', '0', ':', '10', ']', '\\', 'n', '[SEP]']
Filtered   (027): ['plans', '=', 'plan', '.', 'objects', '.', 'filter', '(', 'is', '_', 'shared', '=', 'true', ')', '.', 'order', '_', 'by', '(', ')', '[', '0', ':', '10', ']', '\\', 'n']
Detokenized (022): ['plans', '=', 'plan', '.', 'objects', '.', 'filter', '(', 'is_shared', '=', 'true', ')', '.', 'order_by', '(', ')', '[', '0', ':', '10', ']', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "write_page = 0 if write_page == 1 else write_page + 1 \n"
Original    (012): ['write_page', '=', '0', 'if', 'write_page', '==', '1', 'else', 'write_page', '+', '1', '\\n']
Tokenized   (022): ['[CLS]', 'write', '_', 'page', '=', '0', 'if', 'write', '_', 'page', '=', '=', '1', 'else', 'write', '_', 'page', '+', '1', '\\', 'n', '[SEP]']
Filtered   (020): ['write', '_', 'page', '=', '0', 'if', 'write', '_', 'page', '=', '=', '1', 'else', 'write', '_', 'page', '+', '1', '\\', 'n']
Detokenized (012): ['write_page', '=', '0', 'if', 'write_page', '==', '1', 'else', 'write_page', '+', '1', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "init_sum = 1 if i == 0 else 0 \n"
Original    (010): ['init_sum', '=', '1', 'if', 'i', '==', '0', 'else', '0', '\\n']
Tokenized   (017): ['[CLS]', 'in', '##it', '_', 'sum', '=', '1', 'if', 'i', '=', '=', '0', 'else', '0', '\\', 'n', '[SEP]']
Filtered   (015): ['in', '##it', '_', 'sum', '=', '1', 'if', 'i', '=', '=', '0', 'else', '0', '\\', 'n']
Detokenized (010): ['in##it_sum', '=', '1', 'if', 'i', '==', '0', 'else', '0', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "mem_d0 . read_nonblocking ( 1 , write_addr , mesh_size - 2 ) \n"
Original    (013): ['mem_d0', '.', 'read_nonblocking', '(', '1', ',', 'write_addr', ',', 'mesh_size', '-', '2', ')', '\\n']
Tokenized   (029): ['[CLS]', 'me', '##m', '_', 'd', '##0', '.', 'read', '_', 'non', '##block', '##ing', '(', '1', ',', 'write', '_', 'add', '##r', ',', 'mesh', '_', 'size', '-', '2', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['me', '##m', '_', 'd', '##0', '.', 'read', '_', 'non', '##block', '##ing', '(', '1', ',', 'write', '_', 'add', '##r', ',', 'mesh', '_', 'size', '-', '2', ')', '\\', 'n']
Detokenized (013): ['me##m_d##0', '.', 'read_non##block##ing', '(', '1', ',', 'write_add##r', ',', 'mesh_size', '-', '2', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "write_addr += mesh_size * DSIZE \n"
Original    (006): ['write_addr', '+=', 'mesh_size', '*', 'DSIZE', '\\n']
Tokenized   (016): ['[CLS]', 'write', '_', 'add', '##r', '+', '=', 'mesh', '_', 'size', '*', 'ds', '##ize', '\\', 'n', '[SEP]']
Filtered   (014): ['write', '_', 'add', '##r', '+', '=', 'mesh', '_', 'size', '*', 'ds', '##ize', '\\', 'n']
Detokenized (006): ['write_add##r', '+=', 'mesh_size', '*', 'ds##ize', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "sub_id_base = ( 10 if sub_id_m . group ( 1 ) . count ( "\'d" ) > 0 else \n"
Original    (020): ['sub_id_base', '=', '(', '10', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'d"', ')', '>', '0', 'else', '\\n']
Tokenized   (035): ['[CLS]', 'sub', '_', 'id', '_', 'base', '=', '(', '10', 'if', 'sub', '_', 'id', '_', 'm', '.', 'group', '(', '1', ')', '.', 'count', '(', '"', '\\', "'", 'd', '"', ')', '>', '0', 'else', '\\', 'n', '[SEP]']
Filtered   (033): ['sub', '_', 'id', '_', 'base', '=', '(', '10', 'if', 'sub', '_', 'id', '_', 'm', '.', 'group', '(', '1', ')', '.', 'count', '(', '"', '\\', "'", 'd', '"', ')', '>', '0', 'else', '\\', 'n']
Detokenized (020): ['sub_id_base', '=', '(', '10', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'d"', ')', '>', '0', 'else', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "16 if sub_id_m . group ( 1 ) . count ( "\'h" ) > 0 else \n"
Original    (017): ['16', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'h"', ')', '>', '0', 'else', '\\n']
Tokenized   (028): ['[CLS]', '16', 'if', 'sub', '_', 'id', '_', 'm', '.', 'group', '(', '1', ')', '.', 'count', '(', '"', '\\', "'", 'h', '"', ')', '>', '0', 'else', '\\', 'n', '[SEP]']
Filtered   (026): ['16', 'if', 'sub', '_', 'id', '_', 'm', '.', 'group', '(', '1', ')', '.', 'count', '(', '"', '\\', "'", 'h', '"', ')', '>', '0', 'else', '\\', 'n']
Detokenized (017): ['16', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'h"', ')', '>', '0', 'else', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "10 ) \n"
Original    (003): ['10', ')', '\\n']
Tokenized   (006): ['[CLS]', '10', ')', '\\', 'n', '[SEP]']
Filtered   (004): ['10', ')', '\\', 'n']
Detokenized (003): ['10', ')', '\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "optparser . add_option ( "--noreorder" , action = "store_true" , dest = "noreorder" , \n"
Original    (015): ['optparser', '.', 'add_option', '(', '"--noreorder"', ',', 'action', '=', '"store_true"', ',', 'dest', '=', '"noreorder"', ',', '\\n']
Tokenized   (037): ['[CLS]', 'opt', '##par', '##ser', '.', 'add', '_', 'option', '(', '"', '-', '-', 'nor', '##eo', '##rder', '"', ',', 'action', '=', '"', 'store', '_', 'true', '"', ',', 'des', '##t', '=', '"', 'nor', '##eo', '##rder', '"', ',', '\\', 'n', '[SEP]']
Filtered   (035): ['opt', '##par', '##ser', '.', 'add', '_', 'option', '(', '"', '-', '-', 'nor', '##eo', '##rder', '"', ',', 'action', '=', '"', 'store', '_', 'true', '"', ',', 'des', '##t', '=', '"', 'nor', '##eo', '##rder', '"', ',', '\\', 'n']
Detokenized (015): ['opt##par##ser', '.', 'add_option', '(', '"--nor##eo##rder"', ',', 'action', '=', '"store_true"', ',', 'des##t', '=', '"nor##eo##rder"', ',', '\\n']
Counter: 35
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "truenode = replaceUndefined ( tree . truenode , termname ) \n"
Original    (011): ['truenode', '=', 'replaceUndefined', '(', 'tree', '.', 'truenode', ',', 'termname', ')', '\\n']
Tokenized   (021): ['[CLS]', 'true', '##no', '##de', '=', 'replace', '##und', '##efined', '(', 'tree', '.', 'true', '##no', '##de', ',', 'term', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['true', '##no', '##de', '=', 'replace', '##und', '##efined', '(', 'tree', '.', 'true', '##no', '##de', ',', 'term', '##name', ')', '\\', 'n']
Detokenized (011): ['true##no##de', '=', 'replace##und##efined', '(', 'tree', '.', 'true##no##de', ',', 'term##name', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "codedir = os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) + \n"
Original    (033): ['codedir', '=', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'abspath', '(', '__file__', ')', ')', ')', ')', '+', '\\n']
Tokenized   (045): ['[CLS]', 'coded', '##ir', '=', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'abs', '##path', '(', '_', '_', 'file', '_', '_', ')', ')', ')', ')', '+', '\\', 'n', '[SEP]']
Filtered   (043): ['coded', '##ir', '=', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'dir', '##name', '(', 'os', '.', 'path', '.', 'abs', '##path', '(', '_', '_', 'file', '_', '_', ')', ')', ')', ')', '+', '\\', 'n']
Detokenized (033): ['coded##ir', '=', 'os', '.', 'path', '.', 'dir##name', '(', 'os', '.', 'path', '.', 'dir##name', '(', 'os', '.', 'path', '.', 'dir##name', '(', 'os', '.', 'path', '.', 'abs##path', '(', '__file__', ')', ')', ')', ')', '+', '\\n']
Counter: 43
===================================================================
Hidden states:  (13, 33, 768)
# Extracted words:  33
Sentence         : "analyzer = VerilogDataflowAnalyzer ( filelist , topmodule , \n"
Original    (009): ['analyzer', '=', 'VerilogDataflowAnalyzer', '(', 'filelist', ',', 'topmodule', ',', '\\n']
Tokenized   (025): ['[CLS]', 'analyze', '##r', '=', 've', '##ril', '##og', '##da', '##ta', '##flow', '##anal', '##y', '##zer', '(', 'file', '##list', ',', 'top', '##mo', '##du', '##le', ',', '\\', 'n', '[SEP]']
Filtered   (023): ['analyze', '##r', '=', 've', '##ril', '##og', '##da', '##ta', '##flow', '##anal', '##y', '##zer', '(', 'file', '##list', ',', 'top', '##mo', '##du', '##le', ',', '\\', 'n']
Detokenized (009): ['analyze##r', '=', 've##ril##og##da##ta##flow##anal##y##zer', '(', 'file##list', ',', 'top##mo##du##le', ',', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "constlist = optimizer . getConstlist ( ) \n"
Original    (008): ['constlist', '=', 'optimizer', '.', 'getConstlist', '(', ')', '\\n']
Tokenized   (018): ['[CLS]', 'con', '##st', '##list', '=', 'opt', '##imi', '##zer', '.', 'get', '##con', '##st', '##list', '(', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['con', '##st', '##list', '=', 'opt', '##imi', '##zer', '.', 'get', '##con', '##st', '##list', '(', ')', '\\', 'n']
Detokenized (008): ['con##st##list', '=', 'opt##imi##zer', '.', 'get##con##st##list', '(', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "interval = m . Parameter ( , 16 ) \n"
Original    (010): ['interval', '=', 'm', '.', 'Parameter', '(', ',', '16', ')', '\\n']
Tokenized   (013): ['[CLS]', 'interval', '=', 'm', '.', 'parameter', '(', ',', '16', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['interval', '=', 'm', '.', 'parameter', '(', ',', '16', ')', '\\', 'n']
Detokenized (010): ['interval', '=', 'm', '.', 'parameter', '(', ',', '16', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "led ( led + 1 ) , \n"
Original    (008): ['led', '(', 'led', '+', '1', ')', ',', '\\n']
Tokenized   (011): ['[CLS]', 'led', '(', 'led', '+', '1', ')', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['led', '(', 'led', '+', '1', ')', ',', '\\', 'n']
Detokenized (008): ['led', '(', 'led', '+', '1', ')', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "SingleStatement ( SystemTask ( , , led ) ) \n"
Original    (010): ['SingleStatement', '(', 'SystemTask', '(', ',', ',', 'led', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 'singles', '##tate', '##ment', '(', 'system', '##tas', '##k', '(', ',', ',', 'led', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['singles', '##tate', '##ment', '(', 'system', '##tas', '##k', '(', ',', ',', 'led', ')', ')', '\\', 'n']
Detokenized (010): ['singles##tate##ment', '(', 'system##tas##k', '(', ',', ',', 'led', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "y = dataflow . Variable ( , valid = , ready = , point = 4 ) \n"
Original    (018): ['y', '=', 'dataflow', '.', 'Variable', '(', ',', 'valid', '=', ',', 'ready', '=', ',', 'point', '=', '4', ')', '\\n']
Tokenized   (022): ['[CLS]', 'y', '=', 'data', '##flow', '.', 'variable', '(', ',', 'valid', '=', ',', 'ready', '=', ',', 'point', '=', '4', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['y', '=', 'data', '##flow', '.', 'variable', '(', ',', 'valid', '=', ',', 'ready', '=', ',', 'point', '=', '4', ')', '\\', 'n']
Detokenized (018): ['y', '=', 'data##flow', '.', 'variable', '(', ',', 'valid', '=', ',', 'ready', '=', ',', 'point', '=', '4', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "z . output ( , valid = , ready = ) \n"
Original    (012): ['z', '.', 'output', '(', ',', 'valid', '=', ',', 'ready', '=', ')', '\\n']
Tokenized   (015): ['[CLS]', 'z', '.', 'output', '(', ',', 'valid', '=', ',', 'ready', '=', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['z', '.', 'output', '(', ',', 'valid', '=', ',', 'ready', '=', ')', '\\', 'n']
Detokenized (012): ['z', '.', 'output', '(', ',', 'valid', '=', ',', 'ready', '=', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "xdata_orig = m . RegLike ( ports [ ] , name = , initval = 0 ) \n"
Original    (018): ['xdata_orig', '=', 'm', '.', 'RegLike', '(', 'ports', '[', ']', ',', 'name', '=', ',', 'initval', '=', '0', ')', '\\n']
Tokenized   (029): ['[CLS]', 'x', '##da', '##ta', '_', 'or', '##ig', '=', 'm', '.', 'reg', '##like', '(', 'ports', '[', ']', ',', 'name', '=', ',', 'in', '##it', '##val', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['x', '##da', '##ta', '_', 'or', '##ig', '=', 'm', '.', 'reg', '##like', '(', 'ports', '[', ']', ',', 'name', '=', ',', 'in', '##it', '##val', '=', '0', ')', '\\', 'n']
Detokenized (018): ['x##da##ta_or##ig', '=', 'm', '.', 'reg##like', '(', 'ports', '[', ']', ',', 'name', '=', ',', 'in##it##val', '=', '0', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "zdata_orig = m . WireLike ( ports [ ] , name = ) \n"
Original    (014): ['zdata_orig', '=', 'm', '.', 'WireLike', '(', 'ports', '[', ']', ',', 'name', '=', ')', '\\n']
Tokenized   (023): ['[CLS]', 'z', '##da', '##ta', '_', 'or', '##ig', '=', 'm', '.', 'wire', '##like', '(', 'ports', '[', ']', ',', 'name', '=', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['z', '##da', '##ta', '_', 'or', '##ig', '=', 'm', '.', 'wire', '##like', '(', 'ports', '[', ']', ',', 'name', '=', ')', '\\', 'n']
Detokenized (014): ['z##da##ta_or##ig', '=', 'm', '.', 'wire##like', '(', 'ports', '[', ']', ',', 'name', '=', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "params = m . connect_params ( main ) , \n"
Original    (010): ['params', '=', 'm', '.', 'connect_params', '(', 'main', ')', ',', '\\n']
Tokenized   (017): ['[CLS]', 'para', '##ms', '=', 'm', '.', 'connect', '_', 'para', '##ms', '(', 'main', ')', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['para', '##ms', '=', 'm', '.', 'connect', '_', 'para', '##ms', '(', 'main', ')', ',', '\\', 'n']
Detokenized (010): ['para##ms', '=', 'm', '.', 'connect_para##ms', '(', 'main', ')', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "reset_stmt . append ( ydata_orig ( 0 ) ) \n"
Original    (010): ['reset_stmt', '.', 'append', '(', 'ydata_orig', '(', '0', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'reset', '_', 'st', '##mt', '.', 'app', '##end', '(', 'yd', '##ata', '_', 'or', '##ig', '(', '0', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['reset', '_', 'st', '##mt', '.', 'app', '##end', '(', 'yd', '##ata', '_', 'or', '##ig', '(', '0', ')', ')', '\\', 'n']
Detokenized (010): ['reset_st##mt', '.', 'app##end', '(', 'yd##ata_or##ig', '(', '0', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "nclk ( clk ) , \n"
Original    (006): ['nclk', '(', 'clk', ')', ',', '\\n']
Tokenized   (011): ['[CLS]', 'nc', '##lk', '(', 'cl', '##k', ')', ',', '\\', 'n', '[SEP]']
Filtered   (009): ['nc', '##lk', '(', 'cl', '##k', ')', ',', '\\', 'n']
Detokenized (006): ['nc##lk', '(', 'cl##k', ')', ',', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "send ( , ydata_orig , yvalid , yready , step = 1 , waitnum = 20 ) \n"
Original    (018): ['send', '(', ',', 'ydata_orig', ',', 'yvalid', ',', 'yready', ',', 'step', '=', '1', ',', 'waitnum', '=', '20', ')', '\\n']
Tokenized   (030): ['[CLS]', 'send', '(', ',', 'yd', '##ata', '_', 'or', '##ig', ',', 'y', '##val', '##id', ',', 'y', '##rea', '##dy', ',', 'step', '=', '1', ',', 'wait', '##num', '=', '20', ')', '\\', 'n', '[SEP]']
Filtered   (028): ['send', '(', ',', 'yd', '##ata', '_', 'or', '##ig', ',', 'y', '##val', '##id', ',', 'y', '##rea', '##dy', ',', 'step', '=', '1', ',', 'wait', '##num', '=', '20', ')', '\\', 'n']
Detokenized (018): ['send', '(', ',', 'yd##ata_or##ig', ',', 'y##val##id', ',', 'y##rea##dy', ',', 'step', '=', '1', ',', 'wait##num', '=', '20', ')', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "receive ( , zdata , zvalid , zready , waitnum = 50 ) \n"
Original    (014): ['receive', '(', ',', 'zdata', ',', 'zvalid', ',', 'zready', ',', 'waitnum', '=', '50', ')', '\\n']
Tokenized   (024): ['[CLS]', 'receive', '(', ',', 'z', '##da', '##ta', ',', 'z', '##val', '##id', ',', 'z', '##rea', '##dy', ',', 'wait', '##num', '=', '50', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['receive', '(', ',', 'z', '##da', '##ta', ',', 'z', '##val', '##id', ',', 'z', '##rea', '##dy', ',', 'wait', '##num', '=', '50', ')', '\\', 'n']
Detokenized (014): ['receive', '(', ',', 'z##da##ta', ',', 'z##val##id', ',', 'z##rea##dy', ',', 'wait##num', '=', '50', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "If ( AndList ( zvalid , zready ) ) ( \n"
Original    (011): ['If', '(', 'AndList', '(', 'zvalid', ',', 'zready', ')', ')', '(', '\\n']
Tokenized   (019): ['[CLS]', 'if', '(', 'and', '##list', '(', 'z', '##val', '##id', ',', 'z', '##rea', '##dy', ')', ')', '(', '\\', 'n', '[SEP]']
Filtered   (017): ['if', '(', 'and', '##list', '(', 'z', '##val', '##id', ',', 'z', '##rea', '##dy', ')', ')', '(', '\\', 'n']
Detokenized (011): ['if', '(', 'and##list', '(', 'z##val##id', ',', 'z##rea##dy', ')', ')', '(', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Systask ( , , zdata_orig ) \n"
Original    (007): ['Systask', '(', ',', ',', 'zdata_orig', ')', '\\n']
Tokenized   (017): ['[CLS]', 'sy', '##sta', '##sk', '(', ',', ',', 'z', '##da', '##ta', '_', 'or', '##ig', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['sy', '##sta', '##sk', '(', ',', ',', 'z', '##da', '##ta', '_', 'or', '##ig', ')', '\\', 'n']
Detokenized (007): ['sy##sta##sk', '(', ',', ',', 'z##da##ta_or##ig', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "count = m . Reg ( , width = 32 , initval = 0 ) \n"
Original    (016): ['count', '=', 'm', '.', 'Reg', '(', ',', 'width', '=', '32', ',', 'initval', '=', '0', ')', '\\n']
Tokenized   (021): ['[CLS]', 'count', '=', 'm', '.', 'reg', '(', ',', 'width', '=', '32', ',', 'in', '##it', '##val', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['count', '=', 'm', '.', 'reg', '(', ',', 'width', '=', '32', ',', 'in', '##it', '##val', '=', '0', ')', '\\', 'n']
Detokenized (016): ['count', '=', 'm', '.', 'reg', '(', ',', 'width', '=', '32', ',', 'in##it##val', '=', '0', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "fsm . add ( valid ( down ) , cond = c , delay = 4 , eager_val = True , lazy_cond = True ) \n"
Original    (026): ['fsm', '.', 'add', '(', 'valid', '(', 'down', ')', ',', 'cond', '=', 'c', ',', 'delay', '=', '4', ',', 'eager_val', '=', 'True', ',', 'lazy_cond', '=', 'True', ')', '\\n']
Tokenized   (036): ['[CLS]', 'f', '##sm', '.', 'add', '(', 'valid', '(', 'down', ')', ',', 'con', '##d', '=', 'c', ',', 'delay', '=', '4', ',', 'eager', '_', 'val', '=', 'true', ',', 'lazy', '_', 'con', '##d', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['f', '##sm', '.', 'add', '(', 'valid', '(', 'down', ')', ',', 'con', '##d', '=', 'c', ',', 'delay', '=', '4', ',', 'eager', '_', 'val', '=', 'true', ',', 'lazy', '_', 'con', '##d', '=', 'true', ')', '\\', 'n']
Detokenized (026): ['f##sm', '.', 'add', '(', 'valid', '(', 'down', ')', ',', 'con##d', '=', 'c', ',', 'delay', '=', '4', ',', 'eager_val', '=', 'true', ',', 'lazy_con##d', '=', 'true', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "uut = m . Instance ( mkLed ( ) , , \n"
Original    (012): ['uut', '=', 'm', '.', 'Instance', '(', 'mkLed', '(', ')', ',', ',', '\\n']
Tokenized   (017): ['[CLS]', 'u', '##ut', '=', 'm', '.', 'instance', '(', 'mk', '##led', '(', ')', ',', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['u', '##ut', '=', 'm', '.', 'instance', '(', 'mk', '##led', '(', ')', ',', ',', '\\', 'n']
Detokenized (012): ['u##ut', '=', 'm', '.', 'instance', '(', 'mk##led', '(', ')', ',', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "rslt = m . Wire ( , retwidth , signed = True ) \n"
Original    (014): ['rslt', '=', 'm', '.', 'Wire', '(', ',', 'retwidth', ',', 'signed', '=', 'True', ')', '\\n']
Tokenized   (022): ['[CLS]', 'rs', '##lt', '=', 'm', '.', 'wire', '(', ',', 're', '##t', '##wi', '##dt', '##h', ',', 'signed', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['rs', '##lt', '=', 'm', '.', 'wire', '(', ',', 're', '##t', '##wi', '##dt', '##h', ',', 'signed', '=', 'true', ')', '\\', 'n']
Detokenized (014): ['rs##lt', '=', 'm', '.', 'wire', '(', ',', 're##t##wi##dt##h', ',', 'signed', '=', 'true', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "tmpval [ 0 ] ( rslt ) , \n"
Original    (009): ['tmpval', '[', '0', ']', '(', 'rslt', ')', ',', '\\n']
Tokenized   (015): ['[CLS]', 't', '##mp', '##val', '[', '0', ']', '(', 'rs', '##lt', ')', ',', '\\', 'n', '[SEP]']
Filtered   (013): ['t', '##mp', '##val', '[', '0', ']', '(', 'rs', '##lt', ')', ',', '\\', 'n']
Detokenized (009): ['t##mp##val', '[', '0', ']', '(', 'rs##lt', ')', ',', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "vtypes . If ( rst ) ( \n"
Original    (008): ['vtypes', '.', 'If', '(', 'rst', ')', '(', '\\n']
Tokenized   (014): ['[CLS]', 'vt', '##ype', '##s', '.', 'if', '(', 'rs', '##t', ')', '(', '\\', 'n', '[SEP]']
Filtered   (012): ['vt', '##ype', '##s', '.', 'if', '(', 'rs', '##t', ')', '(', '\\', 'n']
Detokenized (008): ['vt##ype##s', '.', 'if', '(', 'rs##t', ')', '(', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ports = [ ( , clk ) , ( , update ) , ( , a ) , ( , b ) , ( , c ) ] \n"
Original    (029): ['ports', '=', '[', '(', ',', 'clk', ')', ',', '(', ',', 'update', ')', ',', '(', ',', 'a', ')', ',', '(', ',', 'b', ')', ',', '(', ',', 'c', ')', ']', '\\n']
Tokenized   (033): ['[CLS]', 'ports', '=', '[', '(', ',', 'cl', '##k', ')', ',', '(', ',', 'update', ')', ',', '(', ',', 'a', ')', ',', '(', ',', 'b', ')', ',', '(', ',', 'c', ')', ']', '\\', 'n', '[SEP]']
Filtered   (031): ['ports', '=', '[', '(', ',', 'cl', '##k', ')', ',', '(', ',', 'update', ')', ',', '(', ',', 'a', ')', ',', '(', ',', 'b', ')', ',', '(', ',', 'c', ')', ']', '\\', 'n']
Detokenized (029): ['ports', '=', '[', '(', ',', 'cl##k', ')', ',', '(', ',', 'update', ')', ',', '(', ',', 'a', ')', ',', '(', ',', 'b', ')', ',', '(', ',', 'c', ')', ']', '\\n']
Counter: 31
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "m . Instance ( mult , , ports = ports ) \n"
Original    (012): ['m', '.', 'Instance', '(', 'mult', ',', ',', 'ports', '=', 'ports', ')', '\\n']
Tokenized   (016): ['[CLS]', 'm', '.', 'instance', '(', 'mu', '##lt', ',', ',', 'ports', '=', 'ports', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['m', '.', 'instance', '(', 'mu', '##lt', ',', ',', 'ports', '=', 'ports', ')', '\\', 'n']
Detokenized (012): ['m', '.', 'instance', '(', 'mu##lt', ',', ',', 'ports', '=', 'ports', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "stdout = subprocess . PIPE ) . stdout \n"
Original    (009): ['stdout', '=', 'subprocess', '.', 'PIPE', ')', '.', 'stdout', '\\n']
Tokenized   (019): ['[CLS]', 'st', '##dou', '##t', '=', 'sub', '##pro', '##ces', '##s', '.', 'pipe', ')', '.', 'st', '##dou', '##t', '\\', 'n', '[SEP]']
Filtered   (017): ['st', '##dou', '##t', '=', 'sub', '##pro', '##ces', '##s', '.', 'pipe', ')', '.', 'st', '##dou', '##t', '\\', 'n']
Detokenized (009): ['st##dou##t', '=', 'sub##pro##ces##s', '.', 'pipe', ')', '.', 'st##dou##t', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "line = [ l for l in sout ] [ 0 ] \n"
Original    (013): ['line', '=', '[', 'l', 'for', 'l', 'in', 'sout', ']', '[', '0', ']', '\\n']
Tokenized   (017): ['[CLS]', 'line', '=', '[', 'l', 'for', 'l', 'in', 'so', '##ut', ']', '[', '0', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['line', '=', '[', 'l', 'for', 'l', 'in', 'so', '##ut', ']', '[', '0', ']', '\\', 'n']
Detokenized (013): ['line', '=', '[', 'l', 'for', 'l', 'in', 'so##ut', ']', '[', '0', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "round ( wmean , prec ) , "+-" , round ( wstd , prec ) ) \n"
Original    (017): ['round', '(', 'wmean', ',', 'prec', ')', ',', '"+-"', ',', 'round', '(', 'wstd', ',', 'prec', ')', ')', '\\n']
Tokenized   (029): ['[CLS]', 'round', '(', 'w', '##me', '##an', ',', 'pre', '##c', ')', ',', '"', '+', '-', '"', ',', 'round', '(', 'w', '##st', '##d', ',', 'pre', '##c', ')', ')', '\\', 'n', '[SEP]']
Filtered   (027): ['round', '(', 'w', '##me', '##an', ',', 'pre', '##c', ')', ',', '"', '+', '-', '"', ',', 'round', '(', 'w', '##st', '##d', ',', 'pre', '##c', ')', ')', '\\', 'n']
Detokenized (017): ['round', '(', 'w##me##an', ',', 'pre##c', ')', ',', '"+-"', ',', 'round', '(', 'w##st##d', ',', 'pre##c', ')', ')', '\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "size = stop - start ) \n"
Original    (007): ['size', '=', 'stop', '-', 'start', ')', '\\n']
Tokenized   (010): ['[CLS]', 'size', '=', 'stop', '-', 'start', ')', '\\', 'n', '[SEP]']
Filtered   (008): ['size', '=', 'stop', '-', 'start', ')', '\\', 'n']
Detokenized (007): ['size', '=', 'stop', '-', 'start', ')', '\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "rndbase = numpy . random . randint ( self . nrows , size = niter ) \n"
Original    (017): ['rndbase', '=', 'numpy', '.', 'random', '.', 'randint', '(', 'self', '.', 'nrows', ',', 'size', '=', 'niter', ')', '\\n']
Tokenized   (027): ['[CLS]', 'rn', '##db', '##ase', '=', 'nu', '##mp', '##y', '.', 'random', '.', 'rand', '##int', '(', 'self', '.', 'nr', '##ows', ',', 'size', '=', 'ni', '##ter', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['rn', '##db', '##ase', '=', 'nu', '##mp', '##y', '.', 'random', '.', 'rand', '##int', '(', 'self', '.', 'nr', '##ows', ',', 'size', '=', 'ni', '##ter', ')', '\\', 'n']
Detokenized (017): ['rn##db##ase', '=', 'nu##mp##y', '.', 'random', '.', 'rand##int', '(', 'self', '.', 'nr##ows', ',', 'size', '=', 'ni##ter', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "rng = [ - 1000 , - 1000 ] \n"
Original    (010): ['rng', '=', '[', '-', '1000', ',', '-', '1000', ']', '\\n']
Tokenized   (014): ['[CLS]', 'rn', '##g', '=', '[', '-', '1000', ',', '-', '1000', ']', '\\', 'n', '[SEP]']
Filtered   (012): ['rn', '##g', '=', '[', '-', '1000', ',', '-', '1000', ']', '\\', 'n']
Detokenized (010): ['rn##g', '=', '[', '-', '1000', ',', '-', '1000', ']', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "benchtime , stones = prof . run ( \n"
Original    (009): ['benchtime', ',', 'stones', '=', 'prof', '.', 'run', '(', '\\n']
Tokenized   (013): ['[CLS]', 'bench', '##time', ',', 'stones', '=', 'prof', '.', 'run', '(', '\\', 'n', '[SEP]']
Filtered   (011): ['bench', '##time', ',', 'stones', '=', 'prof', '.', 'run', '(', '\\', 'n']
Detokenized (009): ['bench##time', ',', 'stones', '=', 'prof', '.', 'run', '(', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "db . rng = [ - rng / 2 , rng / 2 ] \n"
Original    (015): ['db', '.', 'rng', '=', '[', '-', 'rng', '/', '2', ',', 'rng', '/', '2', ']', '\\n']
Tokenized   (021): ['[CLS]', 'db', '.', 'rn', '##g', '=', '[', '-', 'rn', '##g', '/', '2', ',', 'rn', '##g', '/', '2', ']', '\\', 'n', '[SEP]']
Filtered   (019): ['db', '.', 'rn', '##g', '=', '[', '-', 'rn', '##g', '/', '2', ',', 'rn', '##g', '/', '2', ']', '\\', 'n']
Detokenized (015): ['db', '.', 'rn##g', '=', '[', '-', 'rn##g', '/', '2', ',', 'rn##g', '/', '2', ']', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "MB_ = 1024 * KB_ \n"
Original    (006): ['MB_', '=', '1024', '*', 'KB_', '\\n']
Tokenized   (012): ['[CLS]', 'mb', '_', '=', '102', '##4', '*', 'kb', '_', '\\', 'n', '[SEP]']
Filtered   (010): ['mb', '_', '=', '102', '##4', '*', 'kb', '_', '\\', 'n']
Detokenized (006): ['mb_', '=', '102##4', '*', 'kb_', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "markers = [ , , , , , , , , , ] \n"
Original    (014): ['markers', '=', '[', ',', ',', ',', ',', ',', ',', ',', ',', ',', ']', '\\n']
Tokenized   (017): ['[CLS]', 'markers', '=', '[', ',', ',', ',', ',', ',', ',', ',', ',', ',', ']', '\\', 'n', '[SEP]']
Filtered   (015): ['markers', '=', '[', ',', ',', ',', ',', ',', ',', ',', ',', ',', ']', '\\', 'n']
Detokenized (014): ['markers', '=', '[', ',', ',', ',', ',', ',', ',', ',', ',', ',', ']', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "memcpyw = float ( tmp . split ( ) [ 1 ] ) \n"
Original    (014): ['memcpyw', '=', 'float', '(', 'tmp', '.', 'split', '(', ')', '[', '1', ']', ')', '\\n']
Tokenized   (021): ['[CLS]', 'me', '##mc', '##py', '##w', '=', 'float', '(', 't', '##mp', '.', 'split', '(', ')', '[', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['me', '##mc', '##py', '##w', '=', 'float', '(', 't', '##mp', '.', 'split', '(', ')', '[', '1', ']', ')', '\\', 'n']
Detokenized (014): ['me##mc##py##w', '=', 'float', '(', 't##mp', '.', 'split', '(', ')', '[', '1', ']', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "values [ "memcpyr" ] . append ( memcpyr ) \n"
Original    (010): ['values', '[', '"memcpyr"', ']', '.', 'append', '(', 'memcpyr', ')', '\\n']
Tokenized   (022): ['[CLS]', 'values', '[', '"', 'me', '##mc', '##py', '##r', '"', ']', '.', 'app', '##end', '(', 'me', '##mc', '##py', '##r', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['values', '[', '"', 'me', '##mc', '##py', '##r', '"', ']', '.', 'app', '##end', '(', 'me', '##mc', '##py', '##r', ')', '\\', 'n']
Detokenized (010): ['values', '[', '"me##mc##py##r"', ']', '.', 'app##end', '(', 'me##mc##py##r', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ratio = float ( line . split ( ) [ - 1 ] ) \n"
Original    (015): ['ratio', '=', 'float', '(', 'line', '.', 'split', '(', ')', '[', '-', '1', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'ratio', '=', 'float', '(', 'line', '.', 'split', '(', ')', '[', '-', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['ratio', '=', 'float', '(', 'line', '.', 'split', '(', ')', '[', '-', '1', ']', ')', '\\', 'n']
Detokenized (015): ['ratio', '=', 'float', '(', 'line', '.', 'split', '(', ')', '[', '-', '1', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "xlim ( 0 , xmax ) \n"
Original    (007): ['xlim', '(', '0', ',', 'xmax', ')', '\\n']
Tokenized   (012): ['[CLS]', 'xl', '##im', '(', '0', ',', 'x', '##max', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['xl', '##im', '(', '0', ',', 'x', '##max', ')', '\\', 'n']
Detokenized (007): ['xl##im', '(', '0', ',', 'x##max', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ylim ( 0 , None ) \n"
Original    (007): ['ylim', '(', '0', ',', 'None', ')', '\\n']
Tokenized   (011): ['[CLS]', 'y', '##lim', '(', '0', ',', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['y', '##lim', '(', '0', ',', 'none', ')', '\\', 'n']
Detokenized (007): ['y##lim', '(', '0', ',', 'none', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "grid ( True ) \n"
Original    (005): ['grid', '(', 'True', ')', '\\n']
Tokenized   (008): ['[CLS]', 'grid', '(', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (006): ['grid', '(', 'true', ')', '\\', 'n']
Detokenized (005): ['grid', '(', 'true', ')', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "legend ( [ p [ 0 ] for p in plots \n"
Original    (012): ['legend', '(', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'plots', '\\n']
Tokenized   (015): ['[CLS]', 'legend', '(', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'plots', '\\', 'n', '[SEP]']
Filtered   (013): ['legend', '(', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'plots', '\\', 'n']
Detokenized (012): ['legend', '(', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'plots', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "savefig ( outfile , dpi = 64 ) \n"
Original    (009): ['savefig', '(', 'outfile', ',', 'dpi', '=', '64', ')', '\\n']
Tokenized   (017): ['[CLS]', 'save', '##fi', '##g', '(', 'out', '##fi', '##le', ',', 'd', '##pi', '=', '64', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['save', '##fi', '##g', '(', 'out', '##fi', '##le', ',', 'd', '##pi', '=', '64', ')', '\\', 'n']
Detokenized (009): ['save##fi##g', '(', 'out##fi##le', ',', 'd##pi', '=', '64', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "help = , ) \n"
Original    (005): ['help', '=', ',', ')', '\\n']
Tokenized   (008): ['[CLS]', 'help', '=', ',', ')', '\\', 'n', '[SEP]']
Filtered   (006): ['help', '=', ',', ')', '\\', 'n']
Detokenized (005): ['help', '=', ',', ')', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "parser . add_option ( , , action = , \n"
Original    (010): ['parser', '.', 'add_option', '(', ',', ',', 'action', '=', ',', '\\n']
Tokenized   (016): ['[CLS]', 'par', '##ser', '.', 'add', '_', 'option', '(', ',', ',', 'action', '=', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['par', '##ser', '.', 'add', '_', 'option', '(', ',', ',', 'action', '=', ',', '\\', 'n']
Detokenized (010): ['par##ser', '.', 'add_option', '(', ',', ',', 'action', '=', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "show_plot ( plots , yaxis , legends , gtitle , xmax = int ( options . xmax ) if \n"
Original    (020): ['show_plot', '(', 'plots', ',', 'yaxis', ',', 'legends', ',', 'gtitle', ',', 'xmax', '=', 'int', '(', 'options', '.', 'xmax', ')', 'if', '\\n']
Tokenized   (031): ['[CLS]', 'show', '_', 'plot', '(', 'plots', ',', 'ya', '##xi', '##s', ',', 'legends', ',', 'gt', '##it', '##le', ',', 'x', '##max', '=', 'int', '(', 'options', '.', 'x', '##max', ')', 'if', '\\', 'n', '[SEP]']
Filtered   (029): ['show', '_', 'plot', '(', 'plots', ',', 'ya', '##xi', '##s', ',', 'legends', ',', 'gt', '##it', '##le', ',', 'x', '##max', '=', 'int', '(', 'options', '.', 'x', '##max', ')', 'if', '\\', 'n']
Detokenized (020): ['show_plot', '(', 'plots', ',', 'ya##xi##s', ',', 'legends', ',', 'gt##it##le', ',', 'x##max', '=', 'int', '(', 'options', '.', 'x##max', ')', 'if', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "options . xmax else None ) \n"
Original    (007): ['options', '.', 'xmax', 'else', 'None', ')', '\\n']
Tokenized   (011): ['[CLS]', 'options', '.', 'x', '##max', 'else', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['options', '.', 'x', '##max', 'else', 'none', ')', '\\', 'n']
Detokenized (007): ['options', '.', 'x##max', 'else', 'none', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "hdfarray . attrs . object = { "a" : 32.1 , "b" : 1 , "c" : [ 1 , 2 ] } \n"
Original    (024): ['hdfarray', '.', 'attrs', '.', 'object', '=', '{', '"a"', ':', '32.1', ',', '"b"', ':', '1', ',', '"c"', ':', '[', '1', ',', '2', ']', '}', '\\n']
Tokenized   (039): ['[CLS]', 'hd', '##far', '##ray', '.', 'at', '##tr', '##s', '.', 'object', '=', '{', '"', 'a', '"', ':', '32', '.', '1', ',', '"', 'b', '"', ':', '1', ',', '"', 'c', '"', ':', '[', '1', ',', '2', ']', '}', '\\', 'n', '[SEP]']
Filtered   (037): ['hd', '##far', '##ray', '.', 'at', '##tr', '##s', '.', 'object', '=', '{', '"', 'a', '"', ':', '32', '.', '1', ',', '"', 'b', '"', ':', '1', ',', '"', 'c', '"', ':', '[', '1', ',', '2', ']', '}', '\\', 'n']
Detokenized (024): ['hd##far##ray', '.', 'at##tr##s', '.', 'object', '=', '{', '"a"', ':', '32.1', ',', '"b"', ':', '1', ',', '"c"', ':', '[', '1', ',', '2', ']', '}', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "addr = hex ( id ( self ) ) \n"
Original    (010): ['addr', '=', 'hex', '(', 'id', '(', 'self', ')', ')', '\\n']
Tokenized   (015): ['[CLS]', 'add', '##r', '=', 'he', '##x', '(', 'id', '(', 'self', ')', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['add', '##r', '=', 'he', '##x', '(', 'id', '(', 'self', ')', ')', '\\', 'n']
Detokenized (010): ['add##r', '=', 'he##x', '(', 'id', '(', 'self', ')', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "node_manager . registry . pop ( pathname , None ) \n"
Original    (011): ['node_manager', '.', 'registry', '.', 'pop', '(', 'pathname', ',', 'None', ')', '\\n']
Tokenized   (017): ['[CLS]', 'node', '_', 'manager', '.', 'registry', '.', 'pop', '(', 'path', '##name', ',', 'none', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['node', '_', 'manager', '.', 'registry', '.', 'pop', '(', 'path', '##name', ',', 'none', ')', '\\', 'n']
Detokenized (011): ['node_manager', '.', 'registry', '.', 'pop', '(', 'path##name', ',', 'none', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "oldpathname , self . _v_pathname ) \n"
Original    (007): ['oldpathname', ',', 'self', '.', '_v_pathname', ')', '\\n']
Tokenized   (016): ['[CLS]', 'old', '##path', '##name', ',', 'self', '.', '_', 'v', '_', 'path', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['old', '##path', '##name', ',', 'self', '.', '_', 'v', '_', 'path', '##name', ')', '\\', 'n']
Detokenized (007): ['old##path##name', ',', 'self', '.', '_v_path##name', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "recursive = False , _log = False , ** kwargs ) \n"
Original    (012): ['recursive', '=', 'False', ',', '_log', '=', 'False', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (021): ['[CLS]', 'rec', '##urs', '##ive', '=', 'false', ',', '_', 'log', '=', 'false', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['rec', '##urs', '##ive', '=', 'false', ',', '_', 'log', '=', 'false', ',', '*', '*', 'kw', '##ar', '##gs', ')', '\\', 'n']
Detokenized (012): ['rec##urs##ive', '=', 'false', ',', '_log', '=', 'false', ',', '**', 'kw##ar##gs', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "% node . _v_pathname ) \n"
Original    (006): ['%', 'node', '.', '_v_pathname', ')', '\\n']
Tokenized   (013): ['[CLS]', '%', 'node', '.', '_', 'v', '_', 'path', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['%', 'node', '.', '_', 'v', '_', 'path', '##name', ')', '\\', 'n']
Detokenized (006): ['%', 'node', '.', '_v_path##name', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "or pathname . startswith ( mypathname + ) ) : \n"
Original    (011): ['or', 'pathname', '.', 'startswith', '(', 'mypathname', '+', ')', ')', ':', '\\n']
Tokenized   (018): ['[CLS]', 'or', 'path', '##name', '.', 'starts', '##with', '(', 'my', '##path', '##name', '+', ')', ')', ':', '\\', 'n', '[SEP]']
Filtered   (016): ['or', 'path', '##name', '.', 'starts', '##with', '(', 'my', '##path', '##name', '+', ')', ')', ':', '\\', 'n']
Detokenized (011): ['or', 'path##name', '.', 'starts##with', '(', 'my##path##name', '+', ')', ')', ':', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "newarr = self . h5file . create_array ( , , [ 1 ] ) \n"
Original    (015): ['newarr', '=', 'self', '.', 'h5file', '.', 'create_array', '(', ',', ',', '[', '1', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'new', '##ar', '##r', '=', 'self', '.', 'h', '##5', '##fi', '##le', '.', 'create', '_', 'array', '(', ',', ',', '[', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['new', '##ar', '##r', '=', 'self', '.', 'h', '##5', '##fi', '##le', '.', 'create', '_', 'array', '(', ',', ',', '[', '1', ']', ')', '\\', 'n']
Detokenized (015): ['new##ar##r', '=', 'self', '.', 'h##5##fi##le', '.', 'create_array', '(', ',', ',', '[', '1', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "with self . assertRaises ( tables . UndoRedoError ) : \n"
Original    (011): ['with', 'self', '.', 'assertRaises', '(', 'tables', '.', 'UndoRedoError', ')', ':', '\\n']
Tokenized   (019): ['[CLS]', 'with', 'self', '.', 'assert', '##rai', '##ses', '(', 'tables', '.', 'undo', '##redo', '##er', '##ror', ')', ':', '\\', 'n', '[SEP]']
Filtered   (017): ['with', 'self', '.', 'assert', '##rai', '##ses', '(', 'tables', '.', 'undo', '##redo', '##er', '##ror', ')', ':', '\\', 'n']
Detokenized (011): ['with', 'self', '.', 'assert##rai##ses', '(', 'tables', '.', 'undo##redo##er##ror', ')', ':', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""/othergroup1/othergroup2/othergroup3" not in self . h5file ) \n"
Original    (008): ['"/othergroup1/othergroup2/othergroup3"', 'not', 'in', 'self', '.', 'h5file', ')', '\\n']
Tokenized   (027): ['[CLS]', '"', '/', 'other', '##group', '##1', '/', 'other', '##group', '##2', '/', 'other', '##group', '##3', '"', 'not', 'in', 'self', '.', 'h', '##5', '##fi', '##le', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['"', '/', 'other', '##group', '##1', '/', 'other', '##group', '##2', '/', 'other', '##group', '##3', '"', 'not', 'in', 'self', '.', 'h', '##5', '##fi', '##le', ')', '\\', 'n']
Detokenized (008): ['"/other##group##1/other##group##2/other##group##3"', 'not', 'in', 'self', '.', 'h##5##fi##le', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "var2 = BoolCol ( dflt = 0 , pos = 2 ) \n"
Original    (013): ['var2', '=', 'BoolCol', '(', 'dflt', '=', '0', ',', 'pos', '=', '2', ')', '\\n']
Tokenized   (022): ['[CLS]', 'var', '##2', '=', 'boo', '##lco', '##l', '(', 'd', '##fl', '##t', '=', '0', ',', 'po', '##s', '=', '2', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['var', '##2', '=', 'boo', '##lco', '##l', '(', 'd', '##fl', '##t', '=', '0', ',', 'po', '##s', '=', '2', ')', '\\', 'n']
Detokenized (013): ['var##2', '=', 'boo##lco##l', '(', 'd##fl##t', '=', '0', ',', 'po##s', '=', '2', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "None , nrows ) \n"
Original    (005): ['None', ',', 'nrows', ')', '\\n']
Tokenized   (009): ['[CLS]', 'none', ',', 'nr', '##ows', ')', '\\', 'n', '[SEP]']
Filtered   (007): ['none', ',', 'nr', '##ows', ')', '\\', 'n']
Detokenized (005): ['none', ',', 'nr##ows', ')', '\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "populateTable ( self . h5file . root , ) \n"
Original    (010): ['populateTable', '(', 'self', '.', 'h5file', '.', 'root', ',', ')', '\\n']
Tokenized   (018): ['[CLS]', 'pop', '##ulate', '##table', '(', 'self', '.', 'h', '##5', '##fi', '##le', '.', 'root', ',', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['pop', '##ulate', '##table', '(', 'self', '.', 'h', '##5', '##fi', '##le', '.', 'root', ',', ')', '\\', 'n']
Detokenized (010): ['pop##ulate##table', '(', 'self', '.', 'h##5##fi##le', '.', 'root', ',', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "new_node = self . h5file . copy_children ( \n"
Original    (009): ['new_node', '=', 'self', '.', 'h5file', '.', 'copy_children', '(', '\\n']
Tokenized   (019): ['[CLS]', 'new', '_', 'node', '=', 'self', '.', 'h', '##5', '##fi', '##le', '.', 'copy', '_', 'children', '(', '\\', 'n', '[SEP]']
Filtered   (017): ['new', '_', 'node', '=', 'self', '.', 'h', '##5', '##fi', '##le', '.', 'copy', '_', 'children', '(', '\\', 'n']
Detokenized (009): ['new_node', '=', 'self', '.', 'h##5##fi##le', '.', 'copy_children', '(', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ", , recursive = 1 ) \n"
Original    (007): [',', ',', 'recursive', '=', '1', ')', '\\n']
Tokenized   (012): ['[CLS]', ',', ',', 'rec', '##urs', '##ive', '=', '1', ')', '\\', 'n', '[SEP]']
Filtered   (010): [',', ',', 'rec', '##urs', '##ive', '=', '1', ')', '\\', 'n']
Detokenized (007): [',', ',', 'rec##urs##ive', '=', '1', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "setattr ( attrs , , 11 ) \n"
Original    (008): ['setattr', '(', 'attrs', ',', ',', '11', ')', '\\n']
Tokenized   (015): ['[CLS]', 'set', '##att', '##r', '(', 'at', '##tr', '##s', ',', ',', '11', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['set', '##att', '##r', '(', 'at', '##tr', '##s', ',', ',', '11', ')', '\\', 'n']
Detokenized (008): ['set##att##r', '(', 'at##tr##s', ',', ',', '11', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "delattr ( attrs , ) \n"
Original    (006): ['delattr', '(', 'attrs', ',', ')', '\\n']
Tokenized   (013): ['[CLS]', 'del', '##att', '##r', '(', 'at', '##tr', '##s', ',', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['del', '##att', '##r', '(', 'at', '##tr', '##s', ',', ')', '\\', 'n']
Detokenized (006): ['del##att##r', '(', 'at##tr##s', ',', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "arr . _v_attrs . foo = \n"
Original    (007): ['arr', '.', '_v_attrs', '.', 'foo', '=', '\\n']
Tokenized   (016): ['[CLS]', 'ar', '##r', '.', '_', 'v', '_', 'at', '##tr', '##s', '.', 'foo', '=', '\\', 'n', '[SEP]']
Filtered   (014): ['ar', '##r', '.', '_', 'v', '_', 'at', '##tr', '##s', '.', 'foo', '=', '\\', 'n']
Detokenized (007): ['ar##r', '.', '_v_at##tr##s', '.', 'foo', '=', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "assert response . header ( ) == \n"
Original    (008): ['assert', 'response', '.', 'header', '(', ')', '==', '\\n']
Tokenized   (012): ['[CLS]', 'assert', 'response', '.', 'header', '(', ')', '=', '=', '\\', 'n', '[SEP]']
Filtered   (010): ['assert', 'response', '.', 'header', '(', ')', '=', '=', '\\', 'n']
Detokenized (008): ['assert', 'response', '.', 'header', '(', ')', '==', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "CHANGES = open ( os . path . join ( here , ) , encoding = "utf-8" ) . read ( ) \n"
Original    (023): ['CHANGES', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ',', 'encoding', '=', '"utf-8"', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (031): ['[CLS]', 'changes', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ',', 'encoding', '=', '"', 'ut', '##f', '-', '8', '"', ')', '.', 'read', '(', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['changes', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ',', 'encoding', '=', '"', 'ut', '##f', '-', '8', '"', ')', '.', 'read', '(', ')', '\\', 'n']
Detokenized (023): ['changes', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ',', 'encoding', '=', '"ut##f-8"', ')', '.', 'read', '(', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "tests_require = requires + [ ] , \n"
Original    (008): ['tests_require', '=', 'requires', '+', '[', ']', ',', '\\n']
Tokenized   (013): ['[CLS]', 'tests', '_', 'require', '=', 'requires', '+', '[', ']', ',', '\\', 'n', '[SEP]']
Filtered   (011): ['tests', '_', 'require', '=', 'requires', '+', '[', ']', ',', '\\', 'n']
Detokenized (008): ['tests_require', '=', 'requires', '+', '[', ']', ',', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "user_id = Column ( Integer , primary_key = True ) \n"
Original    (011): ['user_id', '=', 'Column', '(', 'Integer', ',', 'primary_key', '=', 'True', ')', '\\n']
Tokenized   (018): ['[CLS]', 'user', '_', 'id', '=', 'column', '(', 'integer', ',', 'primary', '_', 'key', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['user', '_', 'id', '=', 'column', '(', 'integer', ',', 'primary', '_', 'key', '=', 'true', ')', '\\', 'n']
Detokenized (011): ['user_id', '=', 'column', '(', 'integer', ',', 'primary_key', '=', 'true', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "username = Column ( Unicode ( 20 ) , unique = True ) \n"
Original    (014): ['username', '=', 'Column', '(', 'Unicode', '(', '20', ')', ',', 'unique', '=', 'True', ')', '\\n']
Tokenized   (018): ['[CLS]', 'user', '##name', '=', 'column', '(', 'unicode', '(', '20', ')', ',', 'unique', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['user', '##name', '=', 'column', '(', 'unicode', '(', '20', ')', ',', 'unique', '=', 'true', ')', '\\', 'n']
Detokenized (014): ['user##name', '=', 'column', '(', 'unicode', '(', '20', ')', ',', 'unique', '=', 'true', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "hits = Column ( Integer , default = 0 ) \n"
Original    (011): ['hits', '=', 'Column', '(', 'Integer', ',', 'default', '=', '0', ')', '\\n']
Tokenized   (014): ['[CLS]', 'hits', '=', 'column', '(', 'integer', ',', 'default', '=', '0', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['hits', '=', 'column', '(', 'integer', ',', 'default', '=', '0', ')', '\\', 'n']
Detokenized (011): ['hits', '=', 'column', '(', 'integer', ',', 'default', '=', '0', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_password = Column ( , Unicode ( 60 ) ) \n"
Original    (011): ['_password', '=', 'Column', '(', ',', 'Unicode', '(', '60', ')', ')', '\\n']
Tokenized   (015): ['[CLS]', '_', 'password', '=', 'column', '(', ',', 'unicode', '(', '60', ')', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['_', 'password', '=', 'column', '(', ',', 'unicode', '(', '60', ')', ')', '\\', 'n']
Detokenized (011): ['_password', '=', 'column', '(', ',', 'unicode', '(', '60', ')', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Column ( , Integer , ForeignKey ( ) ) \n"
Original    (010): ['Column', '(', ',', 'Integer', ',', 'ForeignKey', '(', ')', ')', '\\n']
Tokenized   (014): ['[CLS]', 'column', '(', ',', 'integer', ',', 'foreign', '##key', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['column', '(', ',', 'integer', ',', 'foreign', '##key', '(', ')', ')', '\\', 'n']
Detokenized (010): ['column', '(', ',', 'integer', ',', 'foreign##key', '(', ')', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "target_id = Column ( Integer , ForeignKey ( ) ) \n"
Original    (011): ['target_id', '=', 'Column', '(', 'Integer', ',', 'ForeignKey', '(', ')', ')', '\\n']
Tokenized   (017): ['[CLS]', 'target', '_', 'id', '=', 'column', '(', 'integer', ',', 'foreign', '##key', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['target', '_', 'id', '=', 'column', '(', 'integer', ',', 'foreign', '##key', '(', ')', ')', '\\', 'n']
Detokenized (011): ['target_id', '=', 'column', '(', 'integer', ',', 'foreign##key', '(', ')', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "comments = relation ( , cascade = "delete" , \n"
Original    (010): ['comments', '=', 'relation', '(', ',', 'cascade', '=', '"delete"', ',', '\\n']
Tokenized   (016): ['[CLS]', 'comments', '=', 'relation', '(', ',', 'cascade', '=', '"', 'del', '##ete', '"', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['comments', '=', 'relation', '(', ',', 'cascade', '=', '"', 'del', '##ete', '"', ',', '\\', 'n']
Detokenized (010): ['comments', '=', 'relation', '(', ',', 'cascade', '=', '"del##ete"', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "author = relation ( User , cascade = "delete" , backref = ) \n"
Original    (014): ['author', '=', 'relation', '(', 'User', ',', 'cascade', '=', '"delete"', ',', 'backref', '=', ')', '\\n']
Tokenized   (022): ['[CLS]', 'author', '=', 'relation', '(', 'user', ',', 'cascade', '=', '"', 'del', '##ete', '"', ',', 'back', '##re', '##f', '=', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['author', '=', 'relation', '(', 'user', ',', 'cascade', '=', '"', 'del', '##ete', '"', ',', 'back', '##re', '##f', '=', ')', '\\', 'n']
Detokenized (014): ['author', '=', 'relation', '(', 'user', ',', 'cascade', '=', '"del##ete"', ',', 'back##re##f', '=', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "tags = relation ( Tag , secondary = ideas_tags , backref = ) \n"
Original    (014): ['tags', '=', 'relation', '(', 'Tag', ',', 'secondary', '=', 'ideas_tags', ',', 'backref', '=', ')', '\\n']
Tokenized   (021): ['[CLS]', 'tags', '=', 'relation', '(', 'tag', ',', 'secondary', '=', 'ideas', '_', 'tags', ',', 'back', '##re', '##f', '=', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['tags', '=', 'relation', '(', 'tag', ',', 'secondary', '=', 'ideas', '_', 'tags', ',', 'back', '##re', '##f', '=', ')', '\\', 'n']
Detokenized (014): ['tags', '=', 'relation', '(', 'tag', ',', 'secondary', '=', 'ideas_tags', ',', 'back##re##f', '=', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "voted_users = relation ( User , secondary = voted_users , lazy = , \n"
Original    (014): ['voted_users', '=', 'relation', '(', 'User', ',', 'secondary', '=', 'voted_users', ',', 'lazy', '=', ',', '\\n']
Tokenized   (021): ['[CLS]', 'voted', '_', 'users', '=', 'relation', '(', 'user', ',', 'secondary', '=', 'voted', '_', 'users', ',', 'lazy', '=', ',', '\\', 'n', '[SEP]']
Filtered   (019): ['voted', '_', 'users', '=', 'relation', '(', 'user', ',', 'secondary', '=', 'voted', '_', 'users', ',', 'lazy', '=', ',', '\\', 'n']
Detokenized (014): ['voted_users', '=', 'relation', '(', 'user', ',', 'secondary', '=', 'voted_users', ',', 'lazy', '=', ',', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "total_votes = column_property ( ( hits + misses ) . label ( ) ) \n"
Original    (015): ['total_votes', '=', 'column_property', '(', '(', 'hits', '+', 'misses', ')', '.', 'label', '(', ')', ')', '\\n']
Tokenized   (022): ['[CLS]', 'total', '_', 'votes', '=', 'column', '_', 'property', '(', '(', 'hits', '+', 'misses', ')', '.', 'label', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['total', '_', 'votes', '=', 'column', '_', 'property', '(', '(', 'hits', '+', 'misses', ')', '.', 'label', '(', ')', ')', '\\', 'n']
Detokenized (015): ['total_votes', '=', 'column_property', '(', '(', 'hits', '+', 'misses', ')', '.', 'label', '(', ')', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "query = query . filter ( cls . target == None ) . order_by ( order_by ) \n"
Original    (018): ['query', '=', 'query', '.', 'filter', '(', 'cls', '.', 'target', '==', 'None', ')', '.', 'order_by', '(', 'order_by', ')', '\\n']
Tokenized   (027): ['[CLS]', 'query', '=', 'query', '.', 'filter', '(', 'cl', '##s', '.', 'target', '=', '=', 'none', ')', '.', 'order', '_', 'by', '(', 'order', '_', 'by', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['query', '=', 'query', '.', 'filter', '(', 'cl', '##s', '.', 'target', '=', '=', 'none', ')', '.', 'order', '_', 'by', '(', 'order', '_', 'by', ')', '\\', 'n']
Detokenized (018): ['query', '=', 'query', '.', 'filter', '(', 'cl##s', '.', 'target', '==', 'none', ')', '.', 'order_by', '(', 'order_by', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "mock_get_auditlog . side_effect = lambda c : auditlog \n"
Original    (009): ['mock_get_auditlog', '.', 'side_effect', '=', 'lambda', 'c', ':', 'auditlog', '\\n']
Tokenized   (020): ['[CLS]', 'mock', '_', 'get', '_', 'audit', '##log', '.', 'side', '_', 'effect', '=', 'lambda', 'c', ':', 'audit', '##log', '\\', 'n', '[SEP]']
Filtered   (018): ['mock', '_', 'get', '_', 'audit', '##log', '.', 'side', '_', 'effect', '=', 'lambda', 'c', ':', 'audit', '##log', '\\', 'n']
Detokenized (009): ['mock_get_audit##log', '.', 'side_effect', '=', 'lambda', 'c', ':', 'audit##log', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "json . loads ( entry [ 2 ] . payload ) , \n"
Original    (013): ['json', '.', 'loads', '(', 'entry', '[', '2', ']', '.', 'payload', ')', ',', '\\n']
Tokenized   (017): ['[CLS]', 'j', '##son', '.', 'loads', '(', 'entry', '[', '2', ']', '.', 'payload', ')', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['j', '##son', '.', 'loads', '(', 'entry', '[', '2', ']', '.', 'payload', ')', ',', '\\', 'n']
Detokenized (013): ['j##son', '.', 'loads', '(', 'entry', '[', '2', ']', '.', 'payload', ')', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : ": 5 \n"
Original    (003): [':', '5', '\\n']
Tokenized   (006): ['[CLS]', ':', '5', '\\', 'n', '[SEP]']
Filtered   (004): [':', '5', '\\', 'n']
Detokenized (003): [':', '5', '\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "registry . content = DummyContentRegistry ( ) \n"
Original    (008): ['registry', '.', 'content', '=', 'DummyContentRegistry', '(', ')', '\\n']
Tokenized   (016): ['[CLS]', 'registry', '.', 'content', '=', 'dummy', '##con', '##ten', '##tre', '##gist', '##ry', '(', ')', '\\', 'n', '[SEP]']
Filtered   (014): ['registry', '.', 'content', '=', 'dummy', '##con', '##ten', '##tre', '##gist', '##ry', '(', ')', '\\', 'n']
Detokenized (008): ['registry', '.', 'content', '=', 'dummy##con##ten##tre##gist##ry', '(', ')', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ep = DummyFunction ( True ) \n"
Original    (007): ['ep', '=', 'DummyFunction', '(', 'True', ')', '\\n']
Tokenized   (012): ['[CLS]', 'ep', '=', 'dummy', '##fu', '##nction', '(', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['ep', '=', 'dummy', '##fu', '##nction', '(', 'true', ')', '\\', 'n']
Detokenized (007): ['ep', '=', 'dummy##fu##nction', '(', 'true', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "name_node . validator ( node [ ] , filename ) \n"
Original    (011): ['name_node', '.', 'validator', '(', 'node', '[', ']', ',', 'filename', ')', '\\n']
Tokenized   (018): ['[CLS]', 'name', '_', 'node', '.', 'valid', '##ator', '(', 'node', '[', ']', ',', 'file', '##name', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['name', '_', 'node', '.', 'valid', '##ator', '(', 'node', '[', ']', ',', 'file', '##name', ')', '\\', 'n']
Detokenized (011): ['name_node', '.', 'valid##ator', '(', 'node', '[', ']', ',', 'file##name', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "schema [ ] . missing = colander . null \n"
Original    (010): ['schema', '[', ']', '.', 'missing', '=', 'colander', '.', 'null', '\\n']
Tokenized   (015): ['[CLS]', 'sc', '##hema', '[', ']', '.', 'missing', '=', 'cola', '##nder', '.', 'null', '\\', 'n', '[SEP]']
Filtered   (013): ['sc', '##hema', '[', ']', '.', 'missing', '=', 'cola', '##nder', '.', 'null', '\\', 'n']
Detokenized (010): ['sc##hema', '[', ']', '.', 'missing', '=', 'cola##nder', '.', 'null', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "title = appstruct [ ] or None \n"
Original    (008): ['title', '=', 'appstruct', '[', ']', 'or', 'None', '\\n']
Tokenized   (012): ['[CLS]', 'title', '=', 'apps', '##truct', '[', ']', 'or', 'none', '\\', 'n', '[SEP]']
Filtered   (010): ['title', '=', 'apps', '##truct', '[', ']', 'or', 'none', '\\', 'n']
Detokenized (008): ['title', '=', 'apps##truct', '[', ']', 'or', 'none', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mimetype = appstruct [ ] or USE_MAGIC \n"
Original    (008): ['mimetype', '=', 'appstruct', '[', ']', 'or', 'USE_MAGIC', '\\n']
Tokenized   (016): ['[CLS]', 'mi', '##met', '##ype', '=', 'apps', '##truct', '[', ']', 'or', 'use', '_', 'magic', '\\', 'n', '[SEP]']
Filtered   (014): ['mi', '##met', '##ype', '=', 'apps', '##truct', '[', ']', 'or', 'use', '_', 'magic', '\\', 'n']
Detokenized (008): ['mi##met##ype', '=', 'apps##truct', '[', ']', 'or', 'use_magic', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "filedata = tempstore . get ( uid , { } ) \n"
Original    (012): ['filedata', '=', 'tempstore', '.', 'get', '(', 'uid', ',', '{', '}', ')', '\\n']
Tokenized   (018): ['[CLS]', 'filed', '##ata', '=', 'temps', '##tore', '.', 'get', '(', 'ui', '##d', ',', '{', '}', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['filed', '##ata', '=', 'temps', '##tore', '.', 'get', '(', 'ui', '##d', ',', '{', '}', ')', '\\', 'n']
Detokenized (012): ['filed##ata', '=', 'temps##tore', '.', 'get', '(', 'ui##d', ',', '{', '}', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "resource1 . __acl__ = [ ( None , , None ) , ( None , 1 , None ) ] \n"
Original    (021): ['resource1', '.', '__acl__', '=', '[', '(', 'None', ',', ',', 'None', ')', ',', '(', 'None', ',', '1', ',', 'None', ')', ']', '\\n']
Tokenized   (030): ['[CLS]', 'resource', '##1', '.', '_', '_', 'ac', '##l', '_', '_', '=', '[', '(', 'none', ',', ',', 'none', ')', ',', '(', 'none', ',', '1', ',', 'none', ')', ']', '\\', 'n', '[SEP]']
Filtered   (028): ['resource', '##1', '.', '_', '_', 'ac', '##l', '_', '_', '=', '[', '(', 'none', ',', ',', 'none', ')', ',', '(', 'none', ',', '1', ',', 'none', ')', ']', '\\', 'n']
Detokenized (021): ['resource##1', '.', '__ac##l__', '=', '[', '(', 'none', ',', ',', 'none', ')', ',', '(', 'none', ',', '1', ',', 'none', ')', ']', '\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "new_acl = [ ( None , , None ) , ( None , 1 , None ) ] , \n"
Original    (020): ['new_acl', '=', '[', '(', 'None', ',', ',', 'None', ')', ',', '(', 'None', ',', '1', ',', 'None', ')', ']', ',', '\\n']
Tokenized   (026): ['[CLS]', 'new', '_', 'ac', '##l', '=', '[', '(', 'none', ',', ',', 'none', ')', ',', '(', 'none', ',', '1', ',', 'none', ')', ']', ',', '\\', 'n', '[SEP]']
Filtered   (024): ['new', '_', 'ac', '##l', '=', '[', '(', 'none', ',', ',', 'none', ')', ',', '(', 'none', ',', '1', ',', 'none', ')', ']', ',', '\\', 'n']
Detokenized (020): ['new_ac##l', '=', '[', '(', 'none', ',', ',', 'none', ')', ',', '(', 'none', ',', '1', ',', 'none', ')', ']', ',', '\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "request . registry . notify ( LoggedIn ( login , user , context , request ) ) \n"
Original    (018): ['request', '.', 'registry', '.', 'notify', '(', 'LoggedIn', '(', 'login', ',', 'user', ',', 'context', ',', 'request', ')', ')', '\\n']
Tokenized   (024): ['[CLS]', 'request', '.', 'registry', '.', 'not', '##ify', '(', 'logged', '##in', '(', 'log', '##in', ',', 'user', ',', 'context', ',', 'request', ')', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['request', '.', 'registry', '.', 'not', '##ify', '(', 'logged', '##in', '(', 'log', '##in', ',', 'user', ',', 'context', ',', 'request', ')', ')', '\\', 'n']
Detokenized (018): ['request', '.', 'registry', '.', 'not##ify', '(', 'logged##in', '(', 'log##in', ',', 'user', ',', 'context', ',', 'request', ')', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "dirname , filename = os . path . split ( context . path ) \n"
Original    (015): ['dirname', ',', 'filename', '=', 'os', '.', 'path', '.', 'split', '(', 'context', '.', 'path', ')', '\\n']
Tokenized   (020): ['[CLS]', 'dir', '##name', ',', 'file', '##name', '=', 'os', '.', 'path', '.', 'split', '(', 'context', '.', 'path', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['dir', '##name', ',', 'file', '##name', '=', 'os', '.', 'path', '.', 'split', '(', 'context', '.', 'path', ')', '\\', 'n']
Detokenized (015): ['dir##name', ',', 'file##name', '=', 'os', '.', 'path', '.', 'split', '(', 'context', '.', 'path', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "response . content_type = mt or \n"
Original    (007): ['response', '.', 'content_type', '=', 'mt', 'or', '\\n']
Tokenized   (012): ['[CLS]', 'response', '.', 'content', '_', 'type', '=', 'mt', 'or', '\\', 'n', '[SEP]']
Filtered   (010): ['response', '.', 'content', '_', 'type', '=', 'mt', 'or', '\\', 'n']
Detokenized (007): ['response', '.', 'content_type', '=', 'mt', 'or', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "getattr ( SkipCase ( ) , ) ) \n"
Original    (009): ['getattr', '(', 'SkipCase', '(', ')', ',', ')', ')', '\\n']
Tokenized   (015): ['[CLS]', 'get', '##att', '##r', '(', 'skip', '##case', '(', ')', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['get', '##att', '##r', '(', 'skip', '##case', '(', ')', ',', ')', ')', '\\', 'n']
Detokenized (009): ['get##att##r', '(', 'skip##case', '(', ')', ',', ')', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "iterator . __class__ . __name__ ) ) \n"
Original    (008): ['iterator', '.', '__class__', '.', '__name__', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'it', '##era', '##tor', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['it', '##era', '##tor', '.', '_', '_', 'class', '_', '_', '.', '_', '_', 'name', '_', '_', ')', ')', '\\', 'n']
Detokenized (008): ['it##era##tor', '.', '__class__', '.', '__name__', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "parts = super ( newbytes , self ) . splitlines ( keepends ) \n"
Original    (014): ['parts', '=', 'super', '(', 'newbytes', ',', 'self', ')', '.', 'splitlines', '(', 'keepends', ')', '\\n']
Tokenized   (022): ['[CLS]', 'parts', '=', 'super', '(', 'new', '##by', '##tes', ',', 'self', ')', '.', 'split', '##lines', '(', 'keep', '##end', '##s', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['parts', '=', 'super', '(', 'new', '##by', '##tes', ',', 'self', ')', '.', 'split', '##lines', '(', 'keep', '##end', '##s', ')', '\\', 'n']
Detokenized (014): ['parts', '=', 'super', '(', 'new##by##tes', ',', 'self', ')', '.', 'split##lines', '(', 'keep##end##s', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pos = self . rfind ( sub , * args ) \n"
Original    (012): ['pos', '=', 'self', '.', 'rfind', '(', 'sub', ',', '*', 'args', ')', '\\n']
Tokenized   (018): ['[CLS]', 'po', '##s', '=', 'self', '.', 'rf', '##ind', '(', 'sub', ',', '*', 'ar', '##gs', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['po', '##s', '=', 'self', '.', 'rf', '##ind', '(', 'sub', ',', '*', 'ar', '##gs', ')', '\\', 'n']
Detokenized (012): ['po##s', '=', 'self', '.', 'rf##ind', '(', 'sub', ',', '*', 'ar##gs', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "replaced_builtins = . split ( ) \n"
Original    (007): ['replaced_builtins', '=', '.', 'split', '(', ')', '\\n']
Tokenized   (013): ['[CLS]', 'replaced', '_', 'built', '##ins', '=', '.', 'split', '(', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['replaced', '_', 'built', '##ins', '=', '.', 'split', '(', ')', '\\', 'n']
Detokenized (007): ['replaced_built##ins', '=', '.', 'split', '(', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "expression = . join ( [ "name=\'{0}\'" . format ( name ) for name in replaced_builtins ] ) \n"
Original    (019): ['expression', '=', '.', 'join', '(', '[', '"name=\\\'{0}\\\'"', '.', 'format', '(', 'name', ')', 'for', 'name', 'in', 'replaced_builtins', ']', ')', '\\n']
Tokenized   (035): ['[CLS]', 'expression', '=', '.', 'join', '(', '[', '"', 'name', '=', '\\', "'", '{', '0', '}', '\\', "'", '"', '.', 'format', '(', 'name', ')', 'for', 'name', 'in', 'replaced', '_', 'built', '##ins', ']', ')', '\\', 'n', '[SEP]']
Filtered   (033): ['expression', '=', '.', 'join', '(', '[', '"', 'name', '=', '\\', "'", '{', '0', '}', '\\', "'", '"', '.', 'format', '(', 'name', ')', 'for', 'name', 'in', 'replaced', '_', 'built', '##ins', ']', ')', '\\', 'n']
Detokenized (019): ['expression', '=', '.', 'join', '(', '[', '"name=\\\'{0}\\\'"', '.', 'format', '(', 'name', ')', 'for', 'name', 'in', 'replaced_built##ins', ']', ')', '\\n']
Counter: 33
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "touch_import_top ( , name . value , node ) \n"
Original    (010): ['touch_import_top', '(', ',', 'name', '.', 'value', ',', 'node', ')', '\\n']
Tokenized   (017): ['[CLS]', 'touch', '_', 'import', '_', 'top', '(', ',', 'name', '.', 'value', ',', 'node', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['touch', '_', 'import', '_', 'top', '(', ',', 'name', '.', 'value', ',', 'node', ')', '\\', 'n']
Detokenized (010): ['touch_import_top', '(', ',', 'name', '.', 'value', ',', 'node', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "retcode = main ( [ self . textfilename ] ) \n"
Original    (011): ['retcode', '=', 'main', '(', '[', 'self', '.', 'textfilename', ']', ')', '\\n']
Tokenized   (019): ['[CLS]', 're', '##tc', '##ode', '=', 'main', '(', '[', 'self', '.', 'text', '##fi', '##lena', '##me', ']', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['re', '##tc', '##ode', '=', 'main', '(', '[', 'self', '.', 'text', '##fi', '##lena', '##me', ']', ')', '\\', 'n']
Detokenized (011): ['re##tc##ode', '=', 'main', '(', '[', 'self', '.', 'text##fi##lena##me', ']', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "v = self . visit ( node . values [ i ] ) \n"
Original    (014): ['v', '=', 'self', '.', 'visit', '(', 'node', '.', 'values', '[', 'i', ']', ')', '\\n']
Tokenized   (017): ['[CLS]', 'v', '=', 'self', '.', 'visit', '(', 'node', '.', 'values', '[', 'i', ']', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['v', '=', 'self', '.', 'visit', '(', 'node', '.', 'values', '[', 'i', ']', ')', '\\', 'n']
Detokenized (014): ['v', '=', 'self', '.', 'visit', '(', 'node', '.', 'values', '[', 'i', ']', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "props . update ( self . _class_props [ p ] ) \n"
Original    (012): ['props', '.', 'update', '(', 'self', '.', '_class_props', '[', 'p', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'props', '.', 'update', '(', 'self', '.', '_', 'class', '_', 'props', '[', 'p', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['props', '.', 'update', '(', 'self', '.', '_', 'class', '_', 'props', '[', 'p', ']', ')', '\\', 'n']
Detokenized (012): ['props', '.', 'update', '(', 'self', '.', '_class_props', '[', 'p', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "kwargs_init = [ % ( x . split ( ) [ 0 ] , x . split ( ) [ 0 ] ) for x in kwargs ] \n"
Original    (029): ['kwargs_init', '=', '[', '%', '(', 'x', '.', 'split', '(', ')', '[', '0', ']', ',', 'x', '.', 'split', '(', ')', '[', '0', ']', ')', 'for', 'x', 'in', 'kwargs', ']', '\\n']
Tokenized   (039): ['[CLS]', 'kw', '##ar', '##gs', '_', 'in', '##it', '=', '[', '%', '(', 'x', '.', 'split', '(', ')', '[', '0', ']', ',', 'x', '.', 'split', '(', ')', '[', '0', ']', ')', 'for', 'x', 'in', 'kw', '##ar', '##gs', ']', '\\', 'n', '[SEP]']
Filtered   (037): ['kw', '##ar', '##gs', '_', 'in', '##it', '=', '[', '%', '(', 'x', '.', 'split', '(', ')', '[', '0', ']', ',', 'x', '.', 'split', '(', ')', '[', '0', ']', ')', 'for', 'x', 'in', 'kw', '##ar', '##gs', ']', '\\', 'n']
Detokenized (029): ['kw##ar##gs_in##it', '=', '[', '%', '(', 'x', '.', 'split', '(', ')', '[', '0', ']', ',', 'x', '.', 'split', '(', ')', '[', '0', ']', ')', 'for', 'x', 'in', 'kw##ar##gs', ']', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "else : nargs = node . args . args \n"
Original    (010): ['else', ':', 'nargs', '=', 'node', '.', 'args', '.', 'args', '\\n']
Tokenized   (017): ['[CLS]', 'else', ':', 'na', '##rg', '##s', '=', 'node', '.', 'ar', '##gs', '.', 'ar', '##gs', '\\', 'n', '[SEP]']
Filtered   (015): ['else', ':', 'na', '##rg', '##s', '=', 'node', '.', 'ar', '##gs', '.', 'ar', '##gs', '\\', 'n']
Detokenized (010): ['else', ':', 'na##rg##s', '=', 'node', '.', 'ar##gs', '.', 'ar##gs', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "kwargs . append ( % ( a , default_value ) ) \n"
Original    (012): ['kwargs', '.', 'append', '(', '%', '(', 'a', ',', 'default_value', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'kw', '##ar', '##gs', '.', 'app', '##end', '(', '%', '(', 'a', ',', 'default', '_', 'value', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['kw', '##ar', '##gs', '.', 'app', '##end', '(', '%', '(', 'a', ',', 'default', '_', 'value', ')', ')', '\\', 'n']
Detokenized (012): ['kw##ar##gs', '.', 'app##end', '(', '%', '(', 'a', ',', 'default_value', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "offset = len ( node . args . args ) - len ( node . args . defaults ) \n"
Original    (020): ['offset', '=', 'len', '(', 'node', '.', 'args', '.', 'args', ')', '-', 'len', '(', 'node', '.', 'args', '.', 'defaults', ')', '\\n']
Tokenized   (027): ['[CLS]', 'offset', '=', 'len', '(', 'node', '.', 'ar', '##gs', '.', 'ar', '##gs', ')', '-', 'len', '(', 'node', '.', 'ar', '##gs', '.', 'default', '##s', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['offset', '=', 'len', '(', 'node', '.', 'ar', '##gs', '.', 'ar', '##gs', ')', '-', 'len', '(', 'node', '.', 'ar', '##gs', '.', 'default', '##s', ')', '\\', 'n']
Detokenized (020): ['offset', '=', 'len', '(', 'node', '.', 'ar##gs', '.', 'ar##gs', ')', '-', 'len', '(', 'node', '.', 'ar##gs', '.', 'default##s', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "varargs = [ % n for n in range ( 16 ) ] \n"
Original    (014): ['varargs', '=', '[', '%', 'n', 'for', 'n', 'in', 'range', '(', '16', ')', ']', '\\n']
Tokenized   (019): ['[CLS]', 'var', '##ar', '##gs', '=', '[', '%', 'n', 'for', 'n', 'in', 'range', '(', '16', ')', ']', '\\', 'n', '[SEP]']
Filtered   (017): ['var', '##ar', '##gs', '=', '[', '%', 'n', 'for', 'n', 'in', 'range', '(', '16', ')', ']', '\\', 'n']
Detokenized (014): ['var##ar##gs', '=', '[', '%', 'n', 'for', 'n', 'in', 'range', '(', '16', ')', ']', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "buffer += % self . indent ( ) \n"
Original    (009): ['buffer', '+=', '%', 'self', '.', 'indent', '(', ')', '\\n']
Tokenized   (014): ['[CLS]', 'buffer', '+', '=', '%', 'self', '.', 'ind', '##ent', '(', ')', '\\', 'n', '[SEP]']
Filtered   (012): ['buffer', '+', '=', '%', 'self', '.', 'ind', '##ent', '(', ')', '\\', 'n']
Detokenized (009): ['buffer', '+=', '%', 'self', '.', 'ind##ent', '(', ')', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "arg_name = args = None \n"
Original    (006): ['arg_name', '=', 'args', '=', 'None', '\\n']
Tokenized   (013): ['[CLS]', 'ar', '##g', '_', 'name', '=', 'ar', '##gs', '=', 'none', '\\', 'n', '[SEP]']
Filtered   (011): ['ar', '##g', '_', 'name', '=', 'ar', '##gs', '=', 'none', '\\', 'n']
Detokenized (006): ['ar##g_name', '=', 'ar##gs', '=', 'none', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "comp . append ( self . visit ( node . comparators [ i ] ) ) \n"
Original    (017): ['comp', '.', 'append', '(', 'self', '.', 'visit', '(', 'node', '.', 'comparators', '[', 'i', ']', ')', ')', '\\n']
Tokenized   (024): ['[CLS]', 'com', '##p', '.', 'app', '##end', '(', 'self', '.', 'visit', '(', 'node', '.', 'com', '##para', '##tors', '[', 'i', ']', ')', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['com', '##p', '.', 'app', '##end', '(', 'self', '.', 'visit', '(', 'node', '.', 'com', '##para', '##tors', '[', 'i', ']', ')', ')', '\\', 'n']
Detokenized (017): ['com##p', '.', 'app##end', '(', 'self', '.', 'visit', '(', 'node', '.', 'com##para##tors', '[', 'i', ']', ')', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "testtime = time ( ) - starttime \n"
Original    (008): ['testtime', '=', 'time', '(', ')', '-', 'starttime', '\\n']
Tokenized   (013): ['[CLS]', 'test', '##time', '=', 'time', '(', ')', '-', 'start', '##time', '\\', 'n', '[SEP]']
Filtered   (011): ['test', '##time', '=', 'time', '(', ')', '-', 'start', '##time', '\\', 'n']
Detokenized (008): ['test##time', '=', 'time', '(', ')', '-', 'start##time', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "primes_per_sec = len ( seq ) * ( 1.0 / testtime ) \n"
Original    (013): ['primes_per_sec', '=', 'len', '(', 'seq', ')', '*', '(', '1.0', '/', 'testtime', ')', '\\n']
Tokenized   (025): ['[CLS]', 'prime', '##s', '_', 'per', '_', 'sec', '=', 'len', '(', 'se', '##q', ')', '*', '(', '1', '.', '0', '/', 'test', '##time', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['prime', '##s', '_', 'per', '_', 'sec', '=', 'len', '(', 'se', '##q', ')', '*', '(', '1', '.', '0', '/', 'test', '##time', ')', '\\', 'n']
Detokenized (013): ['prime##s_per_sec', '=', 'len', '(', 'se##q', ')', '*', '(', '1.0', '/', 'test##time', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "b = range ( 1 , 10 ) \n"
Original    (009): ['b', '=', 'range', '(', '1', ',', '10', ')', '\\n']
Tokenized   (012): ['[CLS]', 'b', '=', 'range', '(', '1', ',', '10', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['b', '=', 'range', '(', '1', ',', '10', ')', '\\', 'n']
Detokenized (009): ['b', '=', 'range', '(', '1', ',', '10', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "w1 = threading . start_webworker ( worker , ( seq , , ) ) \n"
Original    (015): ['w1', '=', 'threading', '.', 'start_webworker', '(', 'worker', ',', '(', 'seq', ',', ',', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'w', '##1', '=', 'thread', '##ing', '.', 'start', '_', 'web', '##work', '##er', '(', 'worker', ',', '(', 'se', '##q', ',', ',', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['w', '##1', '=', 'thread', '##ing', '.', 'start', '_', 'web', '##work', '##er', '(', 'worker', ',', '(', 'se', '##q', ',', ',', ')', ')', '\\', 'n']
Detokenized (015): ['w##1', '=', 'thread##ing', '.', 'start_web##work##er', '(', 'worker', ',', '(', 'se##q', ',', ',', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "TestError ( in seq ) \n"
Original    (006): ['TestError', '(', 'in', 'seq', ')', '\\n']
Tokenized   (012): ['[CLS]', 'test', '##er', '##ror', '(', 'in', 'se', '##q', ')', '\\', 'n', '[SEP]']
Filtered   (010): ['test', '##er', '##ror', '(', 'in', 'se', '##q', ')', '\\', 'n']
Detokenized (006): ['test##er##ror', '(', 'in', 'se##q', ')', '\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "del self . face_groups [ : ] \n"
Original    (008): ['del', 'self', '.', 'face_groups', '[', ':', ']', '\\n']
Tokenized   (013): ['[CLS]', 'del', 'self', '.', 'face', '_', 'groups', '[', ':', ']', '\\', 'n', '[SEP]']
Filtered   (011): ['del', 'self', '.', 'face', '_', 'groups', '[', ':', ']', '\\', 'n']
Detokenized (008): ['del', 'self', '.', 'face_groups', '[', ':', ']', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mtllib_path = os . path . join ( model_path , data [ 0 ] ) \n"
Original    (016): ['mtllib_path', '=', 'os', '.', 'path', '.', 'join', '(', 'model_path', ',', 'data', '[', '0', ']', ')', '\\n']
Tokenized   (025): ['[CLS]', 'mt', '##lli', '##b', '_', 'path', '=', 'os', '.', 'path', '.', 'join', '(', 'model', '_', 'path', ',', 'data', '[', '0', ']', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['mt', '##lli', '##b', '_', 'path', '=', 'os', '.', 'path', '.', 'join', '(', 'model', '_', 'path', ',', 'data', '[', '0', ']', ')', '\\', 'n']
Detokenized (016): ['mt##lli##b_path', '=', 'os', '.', 'path', '.', 'join', '(', 'model_path', ',', 'data', '[', '0', ']', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "vertex = ( float ( x ) , float ( y ) , float ( z ) ) \n"
Original    (019): ['vertex', '=', '(', 'float', '(', 'x', ')', ',', 'float', '(', 'y', ')', ',', 'float', '(', 'z', ')', ')', '\\n']
Tokenized   (022): ['[CLS]', 'vertex', '=', '(', 'float', '(', 'x', ')', ',', 'float', '(', 'y', ')', ',', 'float', '(', 'z', ')', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['vertex', '=', '(', 'float', '(', 'x', ')', ',', 'float', '(', 'y', ')', ',', 'float', '(', 'z', ')', ')', '\\', 'n']
Detokenized (019): ['vertex', '=', '(', 'float', '(', 'x', ')', ',', 'float', '(', 'y', ')', ',', 'float', '(', 'z', ')', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "tex_coord = ( float ( s ) , float ( t ) ) \n"
Original    (014): ['tex_coord', '=', '(', 'float', '(', 's', ')', ',', 'float', '(', 't', ')', ')', '\\n']
Tokenized   (020): ['[CLS]', 'tex', '_', 'co', '##ord', '=', '(', 'float', '(', 's', ')', ',', 'float', '(', 't', ')', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['tex', '_', 'co', '##ord', '=', '(', 'float', '(', 's', ')', ',', 'float', '(', 't', ')', ')', '\\', 'n']
Detokenized (014): ['tex_co##ord', '=', '(', 'float', '(', 's', ')', ',', 'float', '(', 't', ')', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "indices = ( int ( vi ) - 1 , int ( ti ) - 1 , int ( ni ) - 1 ) \n"
Original    (025): ['indices', '=', '(', 'int', '(', 'vi', ')', '-', '1', ',', 'int', '(', 'ti', ')', '-', '1', ',', 'int', '(', 'ni', ')', '-', '1', ')', '\\n']
Tokenized   (028): ['[CLS]', 'indices', '=', '(', 'int', '(', 'vi', ')', '-', '1', ',', 'int', '(', 'ti', ')', '-', '1', ',', 'int', '(', 'ni', ')', '-', '1', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['indices', '=', '(', 'int', '(', 'vi', ')', '-', '1', ',', 'int', '(', 'ti', ')', '-', '1', ',', 'int', '(', 'ni', ')', '-', '1', ')', '\\', 'n']
Detokenized (025): ['indices', '=', '(', 'int', '(', 'vi', ')', '-', '1', ',', 'int', '(', 'ti', ')', '-', '1', ',', 'int', '(', 'ni', ')', '-', '1', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "glBindTexture ( GL_TEXTURE_2D , material . texture_id ) \n"
Original    (009): ['glBindTexture', '(', 'GL_TEXTURE_2D', ',', 'material', '.', 'texture_id', ')', '\\n']
Tokenized   (023): ['[CLS]', 'g', '##lb', '##ind', '##text', '##ure', '(', 'g', '##l', '_', 'texture', '_', '2d', ',', 'material', '.', 'texture', '_', 'id', ')', '\\', 'n', '[SEP]']
Filtered   (021): ['g', '##lb', '##ind', '##text', '##ure', '(', 'g', '##l', '_', 'texture', '_', '2d', ',', 'material', '.', 'texture', '_', 'id', ')', '\\', 'n']
Detokenized (009): ['g##lb##ind##text##ure', '(', 'g##l_texture_2d', ',', 'material', '.', 'texture_id', ')', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "glPixelStorei ( GL_UNPACK_ALIGNMENT , 1 ) \n"
Original    (007): ['glPixelStorei', '(', 'GL_UNPACK_ALIGNMENT', ',', '1', ')', '\\n']
Tokenized   (021): ['[CLS]', 'g', '##lp', '##ix', '##els', '##tore', '##i', '(', 'g', '##l', '_', 'un', '##pack', '_', 'alignment', ',', '1', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['g', '##lp', '##ix', '##els', '##tore', '##i', '(', 'g', '##l', '_', 'un', '##pack', '_', 'alignment', ',', '1', ')', '\\', 'n']
Detokenized (007): ['g##lp##ix##els##tore##i', '(', 'g##l_un##pack_alignment', ',', '1', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "glNormal3fv ( normals [ ni ] ) \n"
Original    (008): ['glNormal3fv', '(', 'normals', '[', 'ni', ']', ')', '\\n']
Tokenized   (018): ['[CLS]', 'g', '##ln', '##or', '##mal', '##3', '##f', '##v', '(', 'normal', '##s', '[', 'ni', ']', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['g', '##ln', '##or', '##mal', '##3', '##f', '##v', '(', 'normal', '##s', '[', 'ni', ']', ')', '\\', 'n']
Detokenized (008): ['g##ln##or##mal##3##f##v', '(', 'normal##s', '[', 'ni', ']', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "picture = pygame . image . load ( picture_file ) . convert ( ) \n"
Original    (015): ['picture', '=', 'pygame', '.', 'image', '.', 'load', '(', 'picture_file', ')', '.', 'convert', '(', ')', '\\n']
Tokenized   (022): ['[CLS]', 'picture', '=', 'p', '##y', '##game', '.', 'image', '.', 'load', '(', 'picture', '_', 'file', ')', '.', 'convert', '(', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['picture', '=', 'p', '##y', '##game', '.', 'image', '.', 'load', '(', 'picture', '_', 'file', ')', '.', 'convert', '(', ')', '\\', 'n']
Detokenized (015): ['picture', '=', 'p##y##game', '.', 'image', '.', 'load', '(', 'picture_file', ')', '.', 'convert', '(', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "screen . blit ( picture , ( - picture_pos . x , picture_pos . y ) ) \n"
Original    (018): ['screen', '.', 'blit', '(', 'picture', ',', '(', '-', 'picture_pos', '.', 'x', ',', 'picture_pos', '.', 'y', ')', ')', '\\n']
Tokenized   (028): ['[CLS]', 'screen', '.', 'b', '##lit', '(', 'picture', ',', '(', '-', 'picture', '_', 'po', '##s', '.', 'x', ',', 'picture', '_', 'po', '##s', '.', 'y', ')', ')', '\\', 'n', '[SEP]']
Filtered   (026): ['screen', '.', 'b', '##lit', '(', 'picture', ',', '(', '-', 'picture', '_', 'po', '##s', '.', 'x', ',', 'picture', '_', 'po', '##s', '.', 'y', ')', ')', '\\', 'n']
Detokenized (018): ['screen', '.', 'b##lit', '(', 'picture', ',', '(', '-', 'picture_po##s', '.', 'x', ',', 'picture_po##s', '.', 'y', ')', ')', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "time_passed_seconds = time_passed / 1000.0 \n"
Original    (006): ['time_passed_seconds', '=', 'time_passed', '/', '1000.0', '\\n']
Tokenized   (017): ['[CLS]', 'time', '_', 'passed', '_', 'seconds', '=', 'time', '_', 'passed', '/', '1000', '.', '0', '\\', 'n', '[SEP]']
Filtered   (015): ['time', '_', 'passed', '_', 'seconds', '=', 'time', '_', 'passed', '/', '1000', '.', '0', '\\', 'n']
Detokenized (006): ['time_passed_seconds', '=', 'time_passed', '/', '1000.0', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "picture_pos += scroll_direction * scroll_speed * time_passed_seconds \n"
Original    (008): ['picture_pos', '+=', 'scroll_direction', '*', 'scroll_speed', '*', 'time_passed_seconds', '\\n']
Tokenized   (023): ['[CLS]', 'picture', '_', 'po', '##s', '+', '=', 'scroll', '_', 'direction', '*', 'scroll', '_', 'speed', '*', 'time', '_', 'passed', '_', 'seconds', '\\', 'n', '[SEP]']
Filtered   (021): ['picture', '_', 'po', '##s', '+', '=', 'scroll', '_', 'direction', '*', 'scroll', '_', 'speed', '*', 'time', '_', 'passed', '_', 'seconds', '\\', 'n']
Detokenized (008): ['picture_po##s', '+=', 'scroll_direction', '*', 'scroll_speed', '*', 'time_passed_seconds', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "VERSION = open ( "version.txt" ) . readline ( ) . strip ( ) \n"
Original    (015): ['VERSION', '=', 'open', '(', '"version.txt"', ')', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '\\n']
Tokenized   (024): ['[CLS]', 'version', '=', 'open', '(', '"', 'version', '.', 'tx', '##t', '"', ')', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['version', '=', 'open', '(', '"', 'version', '.', 'tx', '##t', '"', ')', '.', 'read', '##line', '(', ')', '.', 'strip', '(', ')', '\\', 'n']
Detokenized (015): ['version', '=', 'open', '(', '"version.tx##t"', ')', '.', 'read##line', '(', ')', '.', 'strip', '(', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "DOWNLOAD_URL = DOWNLOAD_BASEURL + "dubbo-client-%s-py2.7.egg" % VERSION \n"
Original    (008): ['DOWNLOAD_URL', '=', 'DOWNLOAD_BASEURL', '+', '"dubbo-client-%s-py2.7.egg"', '%', 'VERSION', '\\n']
Tokenized   (034): ['[CLS]', 'download', '_', 'ur', '##l', '=', 'download', '_', 'base', '##ur', '##l', '+', '"', 'dub', '##bo', '-', 'client', '-', '%', 's', '-', 'p', '##y', '##2', '.', '7', '.', 'egg', '"', '%', 'version', '\\', 'n', '[SEP]']
Filtered   (032): ['download', '_', 'ur', '##l', '=', 'download', '_', 'base', '##ur', '##l', '+', '"', 'dub', '##bo', '-', 'client', '-', '%', 's', '-', 'p', '##y', '##2', '.', '7', '.', 'egg', '"', '%', 'version', '\\', 'n']
Detokenized (008): ['download_ur##l', '=', 'download_base##ur##l', '+', '"dub##bo-client-%s-p##y##2.7.egg"', '%', 'version', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "long_description = open ( "README.md" ) . read ( ) , \n"
Original    (012): ['long_description', '=', 'open', '(', '"README.md"', ')', '.', 'read', '(', ')', ',', '\\n']
Tokenized   (022): ['[CLS]', 'long', '_', 'description', '=', 'open', '(', '"', 'read', '##me', '.', 'md', '"', ')', '.', 'read', '(', ')', ',', '\\', 'n', '[SEP]']
Filtered   (020): ['long', '_', 'description', '=', 'open', '(', '"', 'read', '##me', '.', 'md', '"', ')', '.', 'read', '(', ')', ',', '\\', 'n']
Detokenized (012): ['long_description', '=', 'open', '(', '"read##me.md"', ')', '.', 'read', '(', ')', ',', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "install_requires = [ "kazoo>=2.0" , "python-jsonrpc>=0.7.3" ] , \n"
Original    (009): ['install_requires', '=', '[', '"kazoo>=2.0"', ',', '"python-jsonrpc>=0.7.3"', ']', ',', '\\n']
Tokenized   (036): ['[CLS]', 'install', '_', 'requires', '=', '[', '"', 'ka', '##zoo', '>', '=', '2', '.', '0', '"', ',', '"', 'python', '-', 'j', '##son', '##rp', '##c', '>', '=', '0', '.', '7', '.', '3', '"', ']', ',', '\\', 'n', '[SEP]']
Filtered   (034): ['install', '_', 'requires', '=', '[', '"', 'ka', '##zoo', '>', '=', '2', '.', '0', '"', ',', '"', 'python', '-', 'j', '##son', '##rp', '##c', '>', '=', '0', '.', '7', '.', '3', '"', ']', ',', '\\', 'n']
Detokenized (009): ['install_requires', '=', '[', '"ka##zoo>=2.0"', ',', '"python-j##son##rp##c>=0.7.3"', ']', ',', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "field = models . BooleanField ( default = False ) , \n"
Original    (012): ['field', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ')', ',', '\\n']
Tokenized   (017): ['[CLS]', 'field', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ')', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['field', '=', 'models', '.', 'boo', '##lean', '##field', '(', 'default', '=', 'false', ')', ',', '\\', 'n']
Detokenized (012): ['field', '=', 'models', '.', 'boo##lean##field', '(', 'default', '=', 'false', ')', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "args = [ in_path , user_out_path ] , env = [ "PATH=" + os . environ . get ( "PATH" , "" ) use_sandbox = True , use_nobody = True ) \n"
Original    (032): ['args', '=', '[', 'in_path', ',', 'user_out_path', ']', ',', 'env', '=', '[', '"PATH="', '+', 'os', '.', 'environ', '.', 'get', '(', '"PATH"', ',', '""', ')', 'use_sandbox', '=', 'True', ',', 'use_nobody', '=', 'True', ')', '\\n']
Tokenized   (056): ['[CLS]', 'ar', '##gs', '=', '[', 'in', '_', 'path', ',', 'user', '_', 'out', '_', 'path', ']', ',', 'en', '##v', '=', '[', '"', 'path', '=', '"', '+', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', '"', 'path', '"', ',', '"', '"', ')', 'use', '_', 'sand', '##box', '=', 'true', ',', 'use', '_', 'nobody', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (054): ['ar', '##gs', '=', '[', 'in', '_', 'path', ',', 'user', '_', 'out', '_', 'path', ']', ',', 'en', '##v', '=', '[', '"', 'path', '=', '"', '+', 'os', '.', 'en', '##vir', '##on', '.', 'get', '(', '"', 'path', '"', ',', '"', '"', ')', 'use', '_', 'sand', '##box', '=', 'true', ',', 'use', '_', 'nobody', '=', 'true', ')', '\\', 'n']
Detokenized (032): ['ar##gs', '=', '[', 'in_path', ',', 'user_out_path', ']', ',', 'en##v', '=', '[', '"path="', '+', 'os', '.', 'en##vir##on', '.', 'get', '(', '"path"', ',', '""', ')', 'use_sand##box', '=', 'true', ',', 'use_nobody', '=', 'true', ')', '\\n']
Counter: 54
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "print_skip = 5 , * args , ** kwargs ) : \n"
Original    (012): ['print_skip', '=', '5', ',', '*', 'args', ',', '**', 'kwargs', ')', ':', '\\n']
Tokenized   (021): ['[CLS]', 'print', '_', 'skip', '=', '5', ',', '*', 'ar', '##gs', ',', '*', '*', 'kw', '##ar', '##gs', ')', ':', '\\', 'n', '[SEP]']
Filtered   (019): ['print', '_', 'skip', '=', '5', ',', '*', 'ar', '##gs', ',', '*', '*', 'kw', '##ar', '##gs', ')', ':', '\\', 'n']
Detokenized (012): ['print_skip', '=', '5', ',', '*', 'ar##gs', ',', '**', 'kw##ar##gs', ')', ':', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "error = np . max ( np . abs ( new_v - v ) ) \n"
Original    (016): ['error', '=', 'np', '.', 'max', '(', 'np', '.', 'abs', '(', 'new_v', '-', 'v', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'error', '=', 'np', '.', 'max', '(', 'np', '.', 'abs', '(', 'new', '_', 'v', '-', 'v', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['error', '=', 'np', '.', 'max', '(', 'np', '.', 'abs', '(', 'new', '_', 'v', '-', 'v', ')', ')', '\\', 'n']
Detokenized (016): ['error', '=', 'np', '.', 'max', '(', 'np', '.', 'abs', '(', 'new_v', '-', 'v', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "ac = ( a_0 - c ) / 2.0 \n"
Original    (010): ['ac', '=', '(', 'a_0', '-', 'c', ')', '/', '2.0', '\\n']
Tokenized   (017): ['[CLS]', 'ac', '=', '(', 'a', '_', '0', '-', 'c', ')', '/', '2', '.', '0', '\\', 'n', '[SEP]']
Filtered   (015): ['ac', '=', '(', 'a', '_', '0', '-', 'c', ')', '/', '2', '.', '0', '\\', 'n']
Detokenized (010): ['ac', '=', '(', 'a_0', '-', 'c', ')', '/', '2.0', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "R = - R \n"
Original    (005): ['R', '=', '-', 'R', '\\n']
Tokenized   (008): ['[CLS]', 'r', '=', '-', 'r', '\\', 'n', '[SEP]']
Filtered   (006): ['r', '=', '-', 'r', '\\', 'n']
Detokenized (005): ['r', '=', '-', 'r', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "B = np . array ( [ [ 0. ] , \n"
Original    (012): ['B', '=', 'np', '.', 'array', '(', '[', '[', '0.', ']', ',', '\\n']
Tokenized   (016): ['[CLS]', 'b', '=', 'np', '.', 'array', '(', '[', '[', '0', '.', ']', ',', '\\', 'n', '[SEP]']
Filtered   (014): ['b', '=', 'np', '.', 'array', '(', '[', '[', '0', '.', ']', ',', '\\', 'n']
Detokenized (012): ['b', '=', 'np', '.', 'array', '(', '[', '[', '0.', ']', ',', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Fr , Kr , Pr = self . Fr , self . Kr , self . Pr \n"
Original    (018): ['Fr', ',', 'Kr', ',', 'Pr', '=', 'self', '.', 'Fr', ',', 'self', '.', 'Kr', ',', 'self', '.', 'Pr', '\\n']
Tokenized   (023): ['[CLS]', 'fr', ',', 'k', '##r', ',', 'pr', '=', 'self', '.', 'fr', ',', 'self', '.', 'k', '##r', ',', 'self', '.', 'pr', '\\', 'n', '[SEP]']
Filtered   (021): ['fr', ',', 'k', '##r', ',', 'pr', '=', 'self', '.', 'fr', ',', 'self', '.', 'k', '##r', ',', 'self', '.', 'pr', '\\', 'n']
Detokenized (018): ['fr', ',', 'k##r', ',', 'pr', '=', 'self', '.', 'fr', ',', 'self', '.', 'k##r', ',', 'self', '.', 'pr', '\\n']
Counter: 21
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "Fs , Ks , Ps = rblq . robust_rule_simple ( P_init = Pr , tol = 1e-12 ) \n"
Original    (019): ['Fs', ',', 'Ks', ',', 'Ps', '=', 'rblq', '.', 'robust_rule_simple', '(', 'P_init', '=', 'Pr', ',', 'tol', '=', '1e-12', ')', '\\n']
Tokenized   (036): ['[CLS]', 'f', '##s', ',', 'ks', ',', 'ps', '=', 'rb', '##l', '##q', '.', 'robust', '_', 'rule', '_', 'simple', '(', 'p', '_', 'in', '##it', '=', 'pr', ',', 'to', '##l', '=', '1', '##e', '-', '12', ')', '\\', 'n', '[SEP]']
Filtered   (034): ['f', '##s', ',', 'ks', ',', 'ps', '=', 'rb', '##l', '##q', '.', 'robust', '_', 'rule', '_', 'simple', '(', 'p', '_', 'in', '##it', '=', 'pr', ',', 'to', '##l', '=', '1', '##e', '-', '12', ')', '\\', 'n']
Detokenized (019): ['f##s', ',', 'ks', ',', 'ps', '=', 'rb##l##q', '.', 'robust_rule_simple', '(', 'p_in##it', '=', 'pr', ',', 'to##l', '=', '1##e-12', ')', '\\n']
Counter: 34
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "Kf , Pf , df , Of , of = rblq . evaluate_F ( Fr ) \n"
Original    (017): ['Kf', ',', 'Pf', ',', 'df', ',', 'Of', ',', 'of', '=', 'rblq', '.', 'evaluate_F', '(', 'Fr', ')', '\\n']
Tokenized   (027): ['[CLS]', 'k', '##f', ',', 'p', '##f', ',', 'd', '##f', ',', 'of', ',', 'of', '=', 'rb', '##l', '##q', '.', 'evaluate', '_', 'f', '(', 'fr', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['k', '##f', ',', 'p', '##f', ',', 'd', '##f', ',', 'of', ',', 'of', '=', 'rb', '##l', '##q', '.', 'evaluate', '_', 'f', '(', 'fr', ')', '\\', 'n']
Detokenized (017): ['k##f', ',', 'p##f', ',', 'd##f', ',', 'of', ',', 'of', '=', 'rb##l##q', '.', 'evaluate_f', '(', 'fr', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "group = h5f . createGroup ( "/" , ) \n"
Original    (010): ['group', '=', 'h5f', '.', 'createGroup', '(', '"/"', ',', ')', '\\n']
Tokenized   (018): ['[CLS]', 'group', '=', 'h', '##5', '##f', '.', 'create', '##group', '(', '"', '/', '"', ',', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['group', '=', 'h', '##5', '##f', '.', 'create', '##group', '(', '"', '/', '"', ',', ')', '\\', 'n']
Detokenized (010): ['group', '=', 'h##5##f', '.', 'create##group', '(', '"/"', ',', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "global ctr \n"
Original    (003): ['global', 'ctr', '\\n']
Tokenized   (007): ['[CLS]', 'global', 'ct', '##r', '\\', 'n', '[SEP]']
Filtered   (005): ['global', 'ct', '##r', '\\', 'n']
Detokenized (003): ['global', 'ct##r', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "listOfInputPaths . append ( rootdir + "/Raw/Yahoo/US/NYSE/" ) \n"
Original    (009): ['listOfInputPaths', '.', 'append', '(', 'rootdir', '+', '"/Raw/Yahoo/US/NYSE/"', ')', '\\n']
Tokenized   (031): ['[CLS]', 'list', '##of', '##in', '##put', '##path', '##s', '.', 'app', '##end', '(', 'root', '##di', '##r', '+', '"', '/', 'raw', '/', 'yahoo', '/', 'us', '/', 'ny', '##se', '/', '"', ')', '\\', 'n', '[SEP]']
Filtered   (029): ['list', '##of', '##in', '##put', '##path', '##s', '.', 'app', '##end', '(', 'root', '##di', '##r', '+', '"', '/', 'raw', '/', 'yahoo', '/', 'us', '/', 'ny', '##se', '/', '"', ')', '\\', 'n']
Detokenized (009): ['list##of##in##put##path##s', '.', 'app##end', '(', 'root##di##r', '+', '"/raw/yahoo/us/ny##se/"', ')', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "filtered_names = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ 0 ] ) , filtered_names ) \n"
Original    (025): ['filtered_names', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'str', '(', 'fileExtensionToRemove', ')', ')', '[', '0', ']', ')', ',', 'filtered_names', ')', '\\n']
Tokenized   (038): ['[CLS]', 'filtered', '_', 'names', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'st', '##r', '(', 'file', '##ex', '##tension', '##tore', '##mo', '##ve', ')', ')', '[', '0', ']', ')', ',', 'filtered', '_', 'names', ')', '\\', 'n', '[SEP]']
Filtered   (036): ['filtered', '_', 'names', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'st', '##r', '(', 'file', '##ex', '##tension', '##tore', '##mo', '##ve', ')', ')', '[', '0', ']', ')', ',', 'filtered', '_', 'names', ')', '\\', 'n']
Detokenized (025): ['filtered_names', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'st##r', '(', 'file##ex##tension##tore##mo##ve', ')', ')', '[', '0', ']', ')', ',', 'filtered_names', ')', '\\n']
Counter: 36
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "stock_data = np . loadtxt ( path + stock + ".csv" , np . float , None , "," , None , 1 , use_cols ) \n"
Original    (027): ['stock_data', '=', 'np', '.', 'loadtxt', '(', 'path', '+', 'stock', '+', '".csv"', ',', 'np', '.', 'float', ',', 'None', ',', '","', ',', 'None', ',', '1', ',', 'use_cols', ')', '\\n']
Tokenized   (043): ['[CLS]', 'stock', '_', 'data', '=', 'np', '.', 'load', '##t', '##xt', '(', 'path', '+', 'stock', '+', '"', '.', 'cs', '##v', '"', ',', 'np', '.', 'float', ',', 'none', ',', '"', ',', '"', ',', 'none', ',', '1', ',', 'use', '_', 'col', '##s', ')', '\\', 'n', '[SEP]']
Filtered   (041): ['stock', '_', 'data', '=', 'np', '.', 'load', '##t', '##xt', '(', 'path', '+', 'stock', '+', '"', '.', 'cs', '##v', '"', ',', 'np', '.', 'float', ',', 'none', ',', '"', ',', '"', ',', 'none', ',', '1', ',', 'use', '_', 'col', '##s', ')', '\\', 'n']
Detokenized (027): ['stock_data', '=', 'np', '.', 'load##t##xt', '(', 'path', '+', 'stock', '+', '".cs##v"', ',', 'np', '.', 'float', ',', 'none', ',', '","', ',', 'none', ',', '1', ',', 'use_col##s', ')', '\\n']
Counter: 41
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "pkl . dump ( stock_data , f , - 1 ) \n"
Original    (012): ['pkl', '.', 'dump', '(', 'stock_data', ',', 'f', ',', '-', '1', ')', '\\n']
Tokenized   (019): ['[CLS]', 'p', '##k', '##l', '.', 'dump', '(', 'stock', '_', 'data', ',', 'f', ',', '-', '1', ')', '\\', 'n', '[SEP]']
Filtered   (017): ['p', '##k', '##l', '.', 'dump', '(', 'stock', '_', 'data', ',', 'f', ',', '-', '1', ')', '\\', 'n']
Detokenized (012): ['p##k##l', '.', 'dump', '(', 'stock_data', ',', 'f', ',', '-', '1', ')', '\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "startday = dt . datetime ( t [ 2 ] , t [ 0 ] , t [ 1 ] ) \n"
Original    (022): ['startday', '=', 'dt', '.', 'datetime', '(', 't', '[', '2', ']', ',', 't', '[', '0', ']', ',', 't', '[', '1', ']', ')', '\\n']
Tokenized   (027): ['[CLS]', 'start', '##day', '=', 'dt', '.', 'date', '##time', '(', 't', '[', '2', ']', ',', 't', '[', '0', ']', ',', 't', '[', '1', ']', ')', '\\', 'n', '[SEP]']
Filtered   (025): ['start', '##day', '=', 'dt', '.', 'date', '##time', '(', 't', '[', '2', ']', ',', 't', '[', '0', ']', ',', 't', '[', '1', ']', ')', '\\', 'n']
Detokenized (022): ['start##day', '=', 'dt', '.', 'date##time', '(', 't', '[', '2', ']', ',', 't', '[', '0', ']', ',', 't', '[', '1', ']', ')', '\\n']
Counter: 25
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "t = map ( int , sys . argv [ 2 ] . split ( ) ) \n"
Original    (018): ['t', '=', 'map', '(', 'int', ',', 'sys', '.', 'argv', '[', '2', ']', '.', 'split', '(', ')', ')', '\\n']
Tokenized   (024): ['[CLS]', 't', '=', 'map', '(', 'int', ',', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '2', ']', '.', 'split', '(', ')', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['t', '=', 'map', '(', 'int', ',', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '2', ']', '.', 'split', '(', ')', ')', '\\', 'n']
Detokenized (018): ['t', '=', 'map', '(', 'int', ',', 'sy##s', '.', 'ar##g##v', '[', '2', ']', '.', 'split', '(', ')', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "historic = dataobj . get_data ( timestamps , symbols , "close" ) \n"
Original    (013): ['historic', '=', 'dataobj', '.', 'get_data', '(', 'timestamps', ',', 'symbols', ',', '"close"', ')', '\\n']
Tokenized   (024): ['[CLS]', 'historic', '=', 'data', '##ob', '##j', '.', 'get', '_', 'data', '(', 'times', '##tam', '##ps', ',', 'symbols', ',', '"', 'close', '"', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['historic', '=', 'data', '##ob', '##j', '.', 'get', '_', 'data', '(', 'times', '##tam', '##ps', ',', 'symbols', ',', '"', 'close', '"', ')', '\\', 'n']
Detokenized (013): ['historic', '=', 'data##ob##j', '.', 'get_data', '(', 'times##tam##ps', ',', 'symbols', ',', '"close"', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "alloc = alloc . append ( DataMatrix ( index = [ historic . index [ date ] ] , data = [ alloc_val ] , columns = [ symbols ~~ alloc [ ] = 1 - alloc [ symbols [ 0 ] ] \n"
Original    (044): ['alloc', '=', 'alloc', '.', 'append', '(', 'DataMatrix', '(', 'index', '=', '[', 'historic', '.', 'index', '[', 'date', ']', ']', ',', 'data', '=', '[', 'alloc_val', ']', ',', 'columns', '=', '[', 'symbols', '~~', 'alloc', '[', ']', '=', '1', '-', 'alloc', '[', 'symbols', '[', '0', ']', ']', '\\n']
Tokenized   (058): ['[CLS]', 'all', '##oc', '=', 'all', '##oc', '.', 'app', '##end', '(', 'data', '##mat', '##rix', '(', 'index', '=', '[', 'historic', '.', 'index', '[', 'date', ']', ']', ',', 'data', '=', '[', 'all', '##oc', '_', 'val', ']', ',', 'columns', '=', '[', 'symbols', '~', '~', 'all', '##oc', '[', ']', '=', '1', '-', 'all', '##oc', '[', 'symbols', '[', '0', ']', ']', '\\', 'n', '[SEP]']
Filtered   (056): ['all', '##oc', '=', 'all', '##oc', '.', 'app', '##end', '(', 'data', '##mat', '##rix', '(', 'index', '=', '[', 'historic', '.', 'index', '[', 'date', ']', ']', ',', 'data', '=', '[', 'all', '##oc', '_', 'val', ']', ',', 'columns', '=', '[', 'symbols', '~', '~', 'all', '##oc', '[', ']', '=', '1', '-', 'all', '##oc', '[', 'symbols', '[', '0', ']', ']', '\\', 'n']
Detokenized (044): ['all##oc', '=', 'all##oc', '.', 'app##end', '(', 'data##mat##rix', '(', 'index', '=', '[', 'historic', '.', 'index', '[', 'date', ']', ']', ',', 'data', '=', '[', 'all##oc_val', ']', ',', 'columns', '=', '[', 'symbols', '~~', 'all##oc', '[', ']', '=', '1', '-', 'all##oc', '[', 'symbols', '[', '0', ']', ']', '\\n']
Counter: 56
===================================================================
Hidden states:  (13, 44, 768)
# Extracted words:  44
Sentence         : "output = open ( sys . argv [ 3 ] , "wb" ) \n"
Original    (014): ['output', '=', 'open', '(', 'sys', '.', 'argv', '[', '3', ']', ',', '"wb"', ')', '\\n']
Tokenized   (022): ['[CLS]', 'output', '=', 'open', '(', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '3', ']', ',', '"', 'wb', '"', ')', '\\', 'n', '[SEP]']
Filtered   (020): ['output', '=', 'open', '(', 'sy', '##s', '.', 'ar', '##g', '##v', '[', '3', ']', ',', '"', 'wb', '"', ')', '\\', 'n']
Detokenized (014): ['output', '=', 'open', '(', 'sy##s', '.', 'ar##g##v', '[', '3', ']', ',', '"wb"', ')', '\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "stocksAtThisPath = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ 0 ] ) , stocksAtThisPath \n"
Original    (024): ['stocksAtThisPath', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'str', '(', 'fileExtensionToRemove', ')', ')', '[', '0', ']', ')', ',', 'stocksAtThisPath', '\\n']
Tokenized   (039): ['[CLS]', 'stocks', '##att', '##his', '##path', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'st', '##r', '(', 'file', '##ex', '##tension', '##tore', '##mo', '##ve', ')', ')', '[', '0', ']', ')', ',', 'stocks', '##att', '##his', '##path', '\\', 'n', '[SEP]']
Filtered   (037): ['stocks', '##att', '##his', '##path', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'st', '##r', '(', 'file', '##ex', '##tension', '##tore', '##mo', '##ve', ')', ')', '[', '0', ']', ')', ',', 'stocks', '##att', '##his', '##path', '\\', 'n']
Detokenized (024): ['stocks##att##his##path', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'st##r', '(', 'file##ex##tension##tore##mo##ve', ')', ')', '[', '0', ']', ')', ',', 'stocks##att##his##path', '\\n']
Counter: 37
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "@ memoize_default ( None , evaluator_is_first_arg = True ) \n"
Original    (010): ['@', 'memoize_default', '(', 'None', ',', 'evaluator_is_first_arg', '=', 'True', ')', '\\n']
Tokenized   (025): ['[CLS]', '@', 'memo', '##ize', '_', 'default', '(', 'none', ',', 'eva', '##lu', '##ator', '_', 'is', '_', 'first', '_', 'ar', '##g', '=', 'true', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['@', 'memo', '##ize', '_', 'default', '(', 'none', ',', 'eva', '##lu', '##ator', '_', 'is', '_', 'first', '_', 'ar', '##g', '=', 'true', ')', '\\', 'n']
Detokenized (010): ['@', 'memo##ize_default', '(', 'none', ',', 'eva##lu##ator_is_first_ar##g', '=', 'true', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "param_str = _search_param_in_docstr ( func . raw_doc , str ( param . get_name ( ) ) ) \n"
Original    (018): ['param_str', '=', '_search_param_in_docstr', '(', 'func', '.', 'raw_doc', ',', 'str', '(', 'param', '.', 'get_name', '(', ')', ')', ')', '\\n']
Tokenized   (042): ['[CLS]', 'para', '##m', '_', 'st', '##r', '=', '_', 'search', '_', 'para', '##m', '_', 'in', '_', 'doc', '##st', '##r', '(', 'fun', '##c', '.', 'raw', '_', 'doc', ',', 'st', '##r', '(', 'para', '##m', '.', 'get', '_', 'name', '(', ')', ')', ')', '\\', 'n', '[SEP]']
Filtered   (040): ['para', '##m', '_', 'st', '##r', '=', '_', 'search', '_', 'para', '##m', '_', 'in', '_', 'doc', '##st', '##r', '(', 'fun', '##c', '.', 'raw', '_', 'doc', ',', 'st', '##r', '(', 'para', '##m', '.', 'get', '_', 'name', '(', ')', ')', ')', '\\', 'n']
Detokenized (018): ['para##m_st##r', '=', '_search_para##m_in_doc##st##r', '(', 'fun##c', '.', 'raw_doc', ',', 'st##r', '(', 'para##m', '.', 'get_name', '(', ')', ')', ')', '\\n']
Counter: 40
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "patterns = [ re . compile ( p % re . escape ( param_str ) ) \n"
Original    (017): ['patterns', '=', '[', 're', '.', 'compile', '(', 'p', '%', 're', '.', 'escape', '(', 'param_str', ')', ')', '\\n']
Tokenized   (025): ['[CLS]', 'patterns', '=', '[', 're', '.', 'com', '##pile', '(', 'p', '%', 're', '.', 'escape', '(', 'para', '##m', '_', 'st', '##r', ')', ')', '\\', 'n', '[SEP]']
Filtered   (023): ['patterns', '=', '[', 're', '.', 'com', '##pile', '(', 'p', '%', 're', '.', 'escape', '(', 'para', '##m', '_', 'st', '##r', ')', ')', '\\', 'n']
Detokenized (017): ['patterns', '=', '[', 're', '.', 'com##pile', '(', 'p', '%', 're', '.', 'escape', '(', 'para##m_st##r', ')', ')', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "it = ( evaluator . execute ( d ) for d in definitions ) \n"
Original    (015): ['it', '=', '(', 'evaluator', '.', 'execute', '(', 'd', ')', 'for', 'd', 'in', 'definitions', ')', '\\n']
Tokenized   (020): ['[CLS]', 'it', '=', '(', 'eva', '##lu', '##ator', '.', 'execute', '(', 'd', ')', 'for', 'd', 'in', 'definitions', ')', '\\', 'n', '[SEP]']
Filtered   (018): ['it', '=', '(', 'eva', '##lu', '##ator', '.', 'execute', '(', 'd', ')', 'for', 'd', 'in', 'definitions', ')', '\\', 'n']
Detokenized (015): ['it', '=', '(', 'eva##lu##ator', '.', 'execute', '(', 'd', ')', 'for', 'd', 'in', 'definitions', ')', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tok = parsed . module . subscopes [ 0 ] . statements [ 0 ] . _token_list [ 2 ] \n"
Original    (021): ['tok', '=', 'parsed', '.', 'module', '.', 'subscopes', '[', '0', ']', '.', 'statements', '[', '0', ']', '.', '_token_list', '[', '2', ']', '\\n']
Tokenized   (031): ['[CLS]', 'to', '##k', '=', 'par', '##sed', '.', 'module', '.', 'sub', '##scope', '##s', '[', '0', ']', '.', 'statements', '[', '0', ']', '.', '_', 'token', '_', 'list', '[', '2', ']', '\\', 'n', '[SEP]']
Filtered   (029): ['to', '##k', '=', 'par', '##sed', '.', 'module', '.', 'sub', '##scope', '##s', '[', '0', ']', '.', 'statements', '[', '0', ']', '.', '_', 'token', '_', 'list', '[', '2', ']', '\\', 'n']
Detokenized (021): ['to##k', '=', 'par##sed', '.', 'module', '.', 'sub##scope##s', '[', '0', ']', '.', 'statements', '[', '0', ']', '.', '_token_list', '[', '2', ']', '\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "__slots__ = ( "graphVariable" , \n"
Original    (006): ['__slots__', '=', '(', '"graphVariable"', ',', '\\n']
Tokenized   (017): ['[CLS]', '_', '_', 'slots', '_', '_', '=', '(', '"', 'graph', '##var', '##iable', '"', ',', '\\', 'n', '[SEP]']
Filtered   (015): ['_', '_', 'slots', '_', '_', '=', '(', '"', 'graph', '##var', '##iable', '"', ',', '\\', 'n']
Detokenized (006): ['__slots__', '=', '(', '"graph##var##iable"', ',', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "( None , \n"
Original    (004): ['(', 'None', ',', '\\n']
Tokenized   (007): ['[CLS]', '(', 'none', ',', '\\', 'n', '[SEP]']
Filtered   (005): ['(', 'none', ',', '\\', 'n']
Detokenized (004): ['(', 'none', ',', '\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "def __init__ ( self , patterns = [ ] , prolog = None ) : \n"
Original    (016): ['def', '__init__', '(', 'self', ',', 'patterns', '=', '[', ']', ',', 'prolog', '=', 'None', ')', ':', '\\n']
Tokenized   (025): ['[CLS]', 'def', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', 'patterns', '=', '[', ']', ',', 'pro', '##log', '=', 'none', ')', ':', '\\', 'n', '[SEP]']
Filtered   (023): ['def', '_', '_', 'in', '##it', '_', '_', '(', 'self', ',', 'patterns', '=', '[', ']', ',', 'pro', '##log', '=', 'none', ')', ':', '\\', 'n']
Detokenized (016): ['def', '__in##it__', '(', 'self', ',', 'patterns', '=', '[', ']', ',', 'pro##log', '=', 'none', ')', ':', '\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "return term . n3 ( ) \n"
Original    (007): ['return', 'term', '.', 'n3', '(', ')', '\\n']
Tokenized   (011): ['[CLS]', 'return', 'term', '.', 'n', '##3', '(', ')', '\\', 'n', '[SEP]']
Filtered   (009): ['return', 'term', '.', 'n', '##3', '(', ')', '\\', 'n']
Detokenized (007): ['return', 'term', '.', 'n##3', '(', ')', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ". join ( [ + . join ( [ \n"
Original    (010): ['.', 'join', '(', '[', '+', '.', 'join', '(', '[', '\\n']
Tokenized   (013): ['[CLS]', '.', 'join', '(', '[', '+', '.', 'join', '(', '[', '\\', 'n', '[SEP]']
Filtered   (011): ['.', 'join', '(', '[', '+', '.', 'join', '(', '[', '\\', 'n']
Detokenized (010): ['.', 'join', '(', '[', '+', '.', 'join', '(', '[', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "[ ( "a" , "?b" , 24 ) , ( "?r" , "?c" , 12345 ) , ( v1 , "?c" , 3333 ) , ( u1 , "?c" , 9999 ) ] ) \n"
Original    (035): ['[', '(', '"a"', ',', '"?b"', ',', '24', ')', ',', '(', '"?r"', ',', '"?c"', ',', '12345', ')', ',', '(', 'v1', ',', '"?c"', ',', '3333', ')', ',', '(', 'u1', ',', '"?c"', ',', '9999', ')', ']', ')', '\\n']
Tokenized   (060): ['[CLS]', '[', '(', '"', 'a', '"', ',', '"', '?', 'b', '"', ',', '24', ')', ',', '(', '"', '?', 'r', '"', ',', '"', '?', 'c', '"', ',', '123', '##45', ')', ',', '(', 'v', '##1', ',', '"', '?', 'c', '"', ',', '333', '##3', ')', ',', '(', 'u', '##1', ',', '"', '?', 'c', '"', ',', '999', '##9', ')', ']', ')', '\\', 'n', '[SEP]']
Filtered   (058): ['[', '(', '"', 'a', '"', ',', '"', '?', 'b', '"', ',', '24', ')', ',', '(', '"', '?', 'r', '"', ',', '"', '?', 'c', '"', ',', '123', '##45', ')', ',', '(', 'v', '##1', ',', '"', '?', 'c', '"', ',', '333', '##3', ')', ',', '(', 'u', '##1', ',', '"', '?', 'c', '"', ',', '999', '##9', ')', ']', ')', '\\', 'n']
Detokenized (035): ['[', '(', '"a"', ',', '"?b"', ',', '24', ')', ',', '(', '"?r"', ',', '"?c"', ',', '123##45', ')', ',', '(', 'v##1', ',', '"?c"', ',', '333##3', ')', ',', '(', 'u##1', ',', '"?c"', ',', '999##9', ')', ']', ')', '\\n']
Counter: 58
===================================================================
Hidden states:  (13, 35, 768)
# Extracted words:  35
Sentence         : "unittest . TextTestRunner ( verbosity = 3 ) . run ( suite ) \n"
Original    (014): ['unittest', '.', 'TextTestRunner', '(', 'verbosity', '=', '3', ')', '.', 'run', '(', 'suite', ')', '\\n']
Tokenized   (021): ['[CLS]', 'unit', '##test', '.', 'text', '##test', '##runner', '(', 'verb', '##osity', '=', '3', ')', '.', 'run', '(', 'suite', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['unit', '##test', '.', 'text', '##test', '##runner', '(', 'verb', '##osity', '=', '3', ')', '.', 'run', '(', 'suite', ')', '\\', 'n']
Detokenized (014): ['unit##test', '.', 'text##test##runner', '(', 'verb##osity', '=', '3', ')', '.', 'run', '(', 'suite', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ") . parse ( "http://www.w3.org/People/Berners-Lee/card.rdf" ) \n"
Original    (007): [')', '.', 'parse', '(', '"http://www.w3.org/People/Berners-Lee/card.rdf"', ')', '\\n']
Tokenized   (034): ['[CLS]', ')', '.', 'par', '##se', '(', '"', 'http', ':', '/', '/', 'www', '.', 'w', '##3', '.', 'org', '/', 'people', '/', 'bern', '##ers', '-', 'lee', '/', 'card', '.', 'rd', '##f', '"', ')', '\\', 'n', '[SEP]']
Filtered   (032): [')', '.', 'par', '##se', '(', '"', 'http', ':', '/', '/', 'www', '.', 'w', '##3', '.', 'org', '/', 'people', '/', 'bern', '##ers', '-', 'lee', '/', 'card', '.', 'rd', '##f', '"', ')', '\\', 'n']
Detokenized (007): [')', '.', 'par##se', '(', '"http://www.w##3.org/people/bern##ers-lee/card.rd##f"', ')', '\\n']
Counter: 32
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "graph . get_context ( URIRef ( ) \n"
Original    (008): ['graph', '.', 'get_context', '(', 'URIRef', '(', ')', '\\n']
Tokenized   (015): ['[CLS]', 'graph', '.', 'get', '_', 'context', '(', 'ur', '##ire', '##f', '(', ')', '\\', 'n', '[SEP]']
Filtered   (013): ['graph', '.', 'get', '_', 'context', '(', 'ur', '##ire', '##f', '(', ')', '\\', 'n']
Detokenized (008): ['graph', '.', 'get_context', '(', 'ur##ire##f', '(', ')', '\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bob . set ( FOAF . name , Literal ( "Bob" ) ) \n"
Original    (014): ['bob', '.', 'set', '(', 'FOAF', '.', 'name', ',', 'Literal', '(', '"Bob"', ')', ')', '\\n']
Tokenized   (021): ['[CLS]', 'bob', '.', 'set', '(', 'f', '##oa', '##f', '.', 'name', ',', 'literal', '(', '"', 'bob', '"', ')', ')', '\\', 'n', '[SEP]']
Filtered   (019): ['bob', '.', 'set', '(', 'f', '##oa', '##f', '.', 'name', ',', 'literal', '(', '"', 'bob', '"', ')', ')', '\\', 'n']
Detokenized (014): ['bob', '.', 'set', '(', 'f##oa##f', '.', 'name', ',', 'literal', '(', '"bob"', ')', ')', '\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "print g . serialize ( format = ) \n"
Original    (009): ['print', 'g', '.', 'serialize', '(', 'format', '=', ')', '\\n']
Tokenized   (013): ['[CLS]', 'print', 'g', '.', 'serial', '##ize', '(', 'format', '=', ')', '\\', 'n', '[SEP]']
Filtered   (011): ['print', 'g', '.', 'serial', '##ize', '(', 'format', '=', ')', '\\', 'n']
Detokenized (009): ['print', 'g', '.', 'serial##ize', '(', 'format', '=', ')', '\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "context = self . uriref ( ) or self . nodeid ( ) or self . sink . identifier \n"
Original    (020): ['context', '=', 'self', '.', 'uriref', '(', ')', 'or', 'self', '.', 'nodeid', '(', ')', 'or', 'self', '.', 'sink', '.', 'identifier', '\\n']
Tokenized   (028): ['[CLS]', 'context', '=', 'self', '.', 'ur', '##ire', '##f', '(', ')', 'or', 'self', '.', 'node', '##id', '(', ')', 'or', 'self', '.', 'sink', '.', 'id', '##ent', '##ifier', '\\', 'n', '[SEP]']
Filtered   (026): ['context', '=', 'self', '.', 'ur', '##ire', '##f', '(', ')', 'or', 'self', '.', 'node', '##id', '(', ')', 'or', 'self', '.', 'sink', '.', 'id', '##ent', '##ifier', '\\', 'n']
Detokenized (020): ['context', '=', 'self', '.', 'ur##ire##f', '(', ')', 'or', 'self', '.', 'node##id', '(', ')', 'or', 'self', '.', 'sink', '.', 'id##ent##ifier', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "from rdflib . query import Result , ResultSerializer , ResultParser \n"
Original    (011): ['from', 'rdflib', '.', 'query', 'import', 'Result', ',', 'ResultSerializer', ',', 'ResultParser', '\\n']
Tokenized   (020): ['[CLS]', 'from', 'rd', '##fl', '##ib', '.', 'query', 'import', 'result', ',', 'results', '##eria', '##lizer', ',', 'result', '##par', '##ser', '\\', 'n', '[SEP]']
Filtered   (018): ['from', 'rd', '##fl', '##ib', '.', 'query', 'import', 'result', ',', 'results', '##eria', '##lizer', ',', 'result', '##par', '##ser', '\\', 'n']
Detokenized (011): ['from', 'rd##fl##ib', '.', 'query', 'import', 'result', ',', 'results##eria##lizer', ',', 'result##par##ser', '\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "class CSVResultParser ( ResultParser ) : \n"
Original    (007): ['class', 'CSVResultParser', '(', 'ResultParser', ')', ':', '\\n']
Tokenized   (016): ['[CLS]', 'class', 'cs', '##vres', '##ult', '##par', '##ser', '(', 'result', '##par', '##ser', ')', ':', '\\', 'n', '[SEP]']
Filtered   (014): ['class', 'cs', '##vres', '##ult', '##par', '##ser', '(', 'result', '##par', '##ser', ')', ':', '\\', 'n']
Detokenized (007): ['class', 'cs##vres##ult##par##ser', '(', 'result##par##ser', ')', ':', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "r . bindings = [ ] \n"
Original    (007): ['r', '.', 'bindings', '=', '[', ']', '\\n']
Tokenized   (011): ['[CLS]', 'r', '.', 'binding', '##s', '=', '[', ']', '\\', 'n', '[SEP]']
Filtered   (009): ['r', '.', 'binding', '##s', '=', '[', ']', '\\', 'n']
Detokenized (007): ['r', '.', 'binding##s', '=', '[', ']', '\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "if result . type != "SELECT" : \n"
Original    (008): ['if', 'result', '.', 'type', '!=', '"SELECT"', ':', '\\n']
Tokenized   (014): ['[CLS]', 'if', 'result', '.', 'type', '!', '=', '"', 'select', '"', ':', '\\', 'n', '[SEP]']
Filtered   (012): ['if', 'result', '.', 'type', '!', '=', '"', 'select', '"', ':', '\\', 'n']
Detokenized (008): ['if', 'result', '.', 'type', '!=', '"select"', ':', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "stream = codecs . getwriter ( encoding ) ( stream ) \n"
Original    (012): ['stream', '=', 'codecs', '.', 'getwriter', '(', 'encoding', ')', '(', 'stream', ')', '\\n']
Tokenized   (017): ['[CLS]', 'stream', '=', 'code', '##cs', '.', 'get', '##writer', '(', 'encoding', ')', '(', 'stream', ')', '\\', 'n', '[SEP]']
Filtered   (015): ['stream', '=', 'code', '##cs', '.', 'get', '##writer', '(', 'encoding', ')', '(', 'stream', ')', '\\', 'n']
Detokenized (012): ['stream', '=', 'code##cs', '.', 'get##writer', '(', 'encoding', ')', '(', 'stream', ')', '\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "vs = [ self . serializeTerm ( v , encoding ) for v in self . result . vars ] \n"
Original    (021): ['vs', '=', '[', 'self', '.', 'serializeTerm', '(', 'v', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'vars', ']', '\\n']
Tokenized   (028): ['[CLS]', 'vs', '=', '[', 'self', '.', 'serial', '##ize', '##ter', '##m', '(', 'v', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'var', '##s', ']', '\\', 'n', '[SEP]']
Filtered   (026): ['vs', '=', '[', 'self', '.', 'serial', '##ize', '##ter', '##m', '(', 'v', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'var', '##s', ']', '\\', 'n']
Detokenized (021): ['vs', '=', '[', 'self', '.', 'serial##ize##ter##m', '(', 'v', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'var##s', ']', '\\n']
Counter: 26
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "for row in self . result . bindings : \n"
Original    (010): ['for', 'row', 'in', 'self', '.', 'result', '.', 'bindings', ':', '\\n']
Tokenized   (014): ['[CLS]', 'for', 'row', 'in', 'self', '.', 'result', '.', 'binding', '##s', ':', '\\', 'n', '[SEP]']
Filtered   (012): ['for', 'row', 'in', 'self', '.', 'result', '.', 'binding', '##s', ':', '\\', 'n']
Detokenized (010): ['for', 'row', 'in', 'self', '.', 'result', '.', 'binding##s', ':', '\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "row . get ( v ) , encoding ) for v in self . result . vars ] ) \n"
Original    (020): ['row', '.', 'get', '(', 'v', ')', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'vars', ']', ')', '\\n']
Tokenized   (024): ['[CLS]', 'row', '.', 'get', '(', 'v', ')', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'var', '##s', ']', ')', '\\', 'n', '[SEP]']
Filtered   (022): ['row', '.', 'get', '(', 'v', ')', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'var', '##s', ']', ')', '\\', 'n']
Detokenized (020): ['row', '.', 'get', '(', 'v', ')', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'var##s', ']', ')', '\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "try : import nose \n"
Original    (005): ['try', ':', 'import', 'nose', '\\n']
Tokenized   (008): ['[CLS]', 'try', ':', 'import', 'nose', '\\', 'n', '[SEP]']
Filtered   (006): ['try', ':', 'import', 'nose', '\\', 'n']
Detokenized (005): ['try', ':', 'import', 'nose', '\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "~~~ argv += DEFAULT_DIRS \n"
Original    (005): ['~~~', 'argv', '+=', 'DEFAULT_DIRS', '\\n']
Tokenized   (016): ['[CLS]', '~', '~', '~', 'ar', '##g', '##v', '+', '=', 'default', '_', 'dir', '##s', '\\', 'n', '[SEP]']
Filtered   (014): ['~', '~', '~', 'ar', '##g', '##v', '+', '=', 'default', '_', 'dir', '##s', '\\', 'n']
Detokenized (005): ['~~~', 'ar##g##v', '+=', 'default_dir##s', '\\n']
Counter: 14
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "nose . run_exit ( argv = finalArgs ) \n"
Original    (009): ['nose', '.', 'run_exit', '(', 'argv', '=', 'finalArgs', ')', '\\n']
Tokenized   (018): ['[CLS]', 'nose', '.', 'run', '_', 'exit', '(', 'ar', '##g', '##v', '=', 'final', '##ar', '##gs', ')', '\\', 'n', '[SEP]']
Filtered   (016): ['nose', '.', 'run', '_', 'exit', '(', 'ar', '##g', '##v', '=', 'final', '##ar', '##gs', ')', '\\', 'n']
Detokenized (009): ['nose', '.', 'run_exit', '(', 'ar##g##v', '=', 'final##ar##gs', ')', '\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Loading model: microsoft/codebert-base
Reading input corpus
Preparing output file
Extracting representations from model
Sentence         : "\n"
Original    (001): ['\\n']
Tokenized   (004): ['<s>', '\\', 'n', '</s>']
Filtered   (002): ['\\', 'n']
Detokenized (001): ['\\n']
Counter: 2
===================================================================
Hidden states:  (13, 1, 768)
# Extracted words:  1
Sentence         : "# \n"
Original    (002): ['#', '\\n']
Tokenized   (005): ['<s>', '#', 'Ġ\\', 'n', '</s>']
Filtered   (003): ['#', 'Ġ\\', 'n']
Detokenized (002): ['#', 'Ġ\\n']
Counter: 3
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "template_name = \n"
Original    (003): ['template_name', '=', '\\n']
Tokenized   (008): ['<s>', 'template', '_', 'name', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['template', '_', 'name', 'Ġ=', 'Ġ\\', 'n']
Detokenized (003): ['template_name', 'Ġ=', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "slug = "policy_profile" \n"
Original    (004): ['slug', '=', '"policy_profile"', '\\n']
Tokenized   (012): ['<s>', 'sl', 'ug', 'Ġ=', 'Ġ"', 'policy', '_', 'profile', '"', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['sl', 'ug', 'Ġ=', 'Ġ"', 'policy', '_', 'profile', '"', 'Ġ\\', 'n']
Detokenized (004): ['slug', 'Ġ=', 'Ġ"policy_profile"', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "preload = False \n"
Original    (004): ['preload', '=', 'False', '\\n']
Tokenized   (008): ['<s>', 'pre', 'load', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['pre', 'load', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (004): ['preload', 'Ġ=', 'ĠFalse', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "tabs = ( NetworkProfileTab , PolicyProfileTab ) \n"
Original    (008): ['tabs', '=', '(', 'NetworkProfileTab', ',', 'PolicyProfileTab', ')', '\\n']
Tokenized   (016): ['<s>', 'tab', 's', 'Ġ=', 'Ġ(', 'ĠNetwork', 'Profile', 'Tab', 'Ġ,', 'ĠPolicy', 'Profile', 'Tab', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['tab', 's', 'Ġ=', 'Ġ(', 'ĠNetwork', 'Profile', 'Tab', 'Ġ,', 'ĠPolicy', 'Profile', 'Tab', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['tabs', 'Ġ=', 'Ġ(', 'ĠNetworkProfileTab', 'Ġ,', 'ĠPolicyProfileTab', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "weak_store = WeakLocal ( ) \n"
Original    (006): ['weak_store', '=', 'WeakLocal', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'weak', '_', 'store', 'Ġ=', 'ĠWeak', 'Local', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['weak', '_', 'store', 'Ġ=', 'ĠWeak', 'Local', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['weak_store', 'Ġ=', 'ĠWeakLocal', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "strong_store = corolocal . local \n"
Original    (006): ['strong_store', '=', 'corolocal', '.', 'local', '\\n']
Tokenized   (013): ['<s>', 'strong', '_', 'store', 'Ġ=', 'Ġcor', 'ol', 'ocal', 'Ġ.', 'Ġlocal', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['strong', '_', 'store', 'Ġ=', 'Ġcor', 'ol', 'ocal', 'Ġ.', 'Ġlocal', 'Ġ\\', 'n']
Detokenized (006): ['strong_store', 'Ġ=', 'Ġcorolocal', 'Ġ.', 'Ġlocal', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "eventlet . monkey_patch ( ) \n"
Original    (006): ['eventlet', '.', 'monkey_patch', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'event', 'let', 'Ġ.', 'Ġmonkey', '_', 'patch', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['event', 'let', 'Ġ.', 'Ġmonkey', '_', 'patch', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['eventlet', 'Ġ.', 'Ġmonkey_patch', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "CONF . register_opts ( impl_zmq . zmq_opts ) \n"
Original    (009): ['CONF', '.', 'register_opts', '(', 'impl_zmq', '.', 'zmq_opts', ')', '\\n']
Tokenized   (025): ['<s>', 'CON', 'F', 'Ġ.', 'Ġregister', '_', 'op', 'ts', 'Ġ(', 'Ġimpl', '_', 'z', 'm', 'q', 'Ġ.', 'Ġz', 'm', 'q', '_', 'op', 'ts', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['CON', 'F', 'Ġ.', 'Ġregister', '_', 'op', 'ts', 'Ġ(', 'Ġimpl', '_', 'z', 'm', 'q', 'Ġ.', 'Ġz', 'm', 'q', '_', 'op', 'ts', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['CONF', 'Ġ.', 'Ġregister_opts', 'Ġ(', 'Ġimpl_zmq', 'Ġ.', 'Ġzmq_opts', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "vpnservices_dict = { : self . api_vpnservices . list ( ) } \n"
Original    (013): ['vpnservices_dict', '=', '{', ':', 'self', '.', 'api_vpnservices', '.', 'list', '(', ')', '}', '\\n']
Tokenized   (024): ['<s>', 'v', 'pn', 'services', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġapi', '_', 'v', 'pn', 'services', 'Ġ.', 'Ġlist', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['v', 'pn', 'services', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġapi', '_', 'v', 'pn', 'services', 'Ġ.', 'Ġlist', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (013): ['vpnservices_dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġapi_vpnservices', 'Ġ.', 'Ġlist', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "vpnservice [ ] [ ] ) \n"
Original    (007): ['vpnservice', '[', ']', '[', ']', ')', '\\n']
Tokenized   (012): ['<s>', 'v', 'pn', 'service', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['v', 'pn', 'service', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['vpnservice', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "form_data } ) . AndReturn ( ipsecsiteconnection ) \n"
Original    (009): ['form_data', '}', ')', '.', 'AndReturn', '(', 'ipsecsiteconnection', ')', '\\n']
Tokenized   (018): ['<s>', 'form', '_', 'data', 'Ġ}', 'Ġ)', 'Ġ.', 'ĠAnd', 'Return', 'Ġ(', 'Ġip', 'sec', 'site', 'connection', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['form', '_', 'data', 'Ġ}', 'Ġ)', 'Ġ.', 'ĠAnd', 'Return', 'Ġ(', 'Ġip', 'sec', 'site', 'connection', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['form_data', 'Ġ}', 'Ġ)', 'Ġ.', 'ĠAndReturn', 'Ġ(', 'Ġipsecsiteconnection', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "ipsecsiteconnections_dict ) \n"
Original    (003): ['ipsecsiteconnections_dict', ')', '\\n']
Tokenized   (012): ['<s>', 'ip', 'sec', 'site', 'connect', 'ions', '_', 'dict', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['ip', 'sec', 'site', 'connect', 'ions', '_', 'dict', 'Ġ)', 'Ġ\\', 'n']
Detokenized (003): ['ipsecsiteconnections_dict', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "ipsecsiteconnections [ ] ) : \n"
Original    (006): ['ipsecsiteconnections', '[', ']', ')', ':', '\\n']
Tokenized   (013): ['<s>', 'ip', 'sec', 'site', 'connect', 'ions', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['ip', 'sec', 'site', 'connect', 'ions', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['ipsecsiteconnections', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "neutronclient . show_ipsec_site_connection ( \n"
Original    (005): ['neutronclient', '.', 'show_ipsec_site_connection', '(', '\\n']
Tokenized   (018): ['<s>', 'ne', 'ut', 'ron', 'client', 'Ġ.', 'Ġshow', '_', 'ip', 'sec', '_', 'site', '_', 'connection', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['ne', 'ut', 'ron', 'client', 'Ġ.', 'Ġshow', '_', 'ip', 'sec', '_', 'site', '_', 'connection', 'Ġ(', 'Ġ\\', 'n']
Detokenized (005): ['neutronclient', 'Ġ.', 'Ġshow_ipsec_site_connection', 'Ġ(', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "ret_val = api . vpn . ipsecsiteconnection_get ( self . request , \n"
Original    (013): ['ret_val', '=', 'api', '.', 'vpn', '.', 'ipsecsiteconnection_get', '(', 'self', '.', 'request', ',', '\\n']
Tokenized   (024): ['<s>', 'ret', '_', 'val', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġv', 'pn', 'Ġ.', 'Ġip', 'sec', 'site', 'connection', '_', 'get', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrequest', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ret', '_', 'val', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġv', 'pn', 'Ġ.', 'Ġip', 'sec', 'site', 'connection', '_', 'get', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrequest', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['ret_val', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġvpn', 'Ġ.', 'Ġipsecsiteconnection_get', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrequest', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "response_kwargs . setdefault ( "filename" , "usage.csv" ) \n"
Original    (009): ['response_kwargs', '.', 'setdefault', '(', '"filename"', ',', '"usage.csv"', ')', '\\n']
Tokenized   (022): ['<s>', 'response', '_', 'kw', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ"', 'filename', '"', 'Ġ,', 'Ġ"', 'usage', '.', 'csv', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['response', '_', 'kw', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ"', 'filename', '"', 'Ġ,', 'Ġ"', 'usage', '.', 'csv', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['response_kwargs', 'Ġ.', 'Ġsetdefault', 'Ġ(', 'Ġ"filename"', 'Ġ,', 'Ġ"usage.csv"', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "BlendProbes = 1 \n"
Original    (004): ['BlendProbes', '=', '1', '\\n']
Tokenized   (010): ['<s>', 'Bl', 'end', 'Pro', 'bes', 'Ġ=', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Bl', 'end', 'Pro', 'bes', 'Ġ=', 'Ġ1', 'Ġ\\', 'n']
Detokenized (004): ['BlendProbes', 'Ġ=', 'Ġ1', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "lightmap_index = field ( "m_LightmapIndex" ) \n"
Original    (007): ['lightmap_index', '=', 'field', '(', '"m_LightmapIndex"', ')', '\\n']
Tokenized   (019): ['<s>', 'light', 'map', '_', 'index', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Light', 'map', 'Index', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['light', 'map', '_', 'index', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Light', 'map', 'Index', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['lightmap_index', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"m_LightmapIndex"', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "receive_shadows = field ( "m_ReceiveShadows" , bool ) \n"
Original    (009): ['receive_shadows', '=', 'field', '(', '"m_ReceiveShadows"', ',', 'bool', ')', '\\n']
Tokenized   (023): ['<s>', 're', 'ceive', '_', 'sh', 'adows', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Re', 'ceive', 'Sh', 'adows', '"', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['re', 'ceive', '_', 'sh', 'adows', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Re', 'ceive', 'Sh', 'adows', '"', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['receive_shadows', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"m_ReceiveShadows"', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "Config . parser . readfp ( sconf ) \n"
Original    (009): ['Config', '.', 'parser', '.', 'readfp', '(', 'sconf', ')', '\\n']
Tokenized   (015): ['<s>', 'Config', 'Ġ.', 'Ġparser', 'Ġ.', 'Ġread', 'fp', 'Ġ(', 'Ġsc', 'on', 'f', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Config', 'Ġ.', 'Ġparser', 'Ġ.', 'Ġread', 'fp', 'Ġ(', 'Ġsc', 'on', 'f', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['Config', 'Ġ.', 'Ġparser', 'Ġ.', 'Ġreadfp', 'Ġ(', 'Ġsconf', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "BBS_XMPP_CERT_FILE = BBS_ROOT + "xmpp.crt" \n"
Original    (006): ['BBS_XMPP_CERT_FILE', '=', 'BBS_ROOT', '+', '"xmpp.crt"', '\\n']
Tokenized   (030): ['<s>', 'B', 'BS', '_', 'X', 'MP', 'P', '_', 'C', 'ERT', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ"', 'x', 'm', 'pp', '.', 'cr', 't', '"', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['B', 'BS', '_', 'X', 'MP', 'P', '_', 'C', 'ERT', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ"', 'x', 'm', 'pp', '.', 'cr', 't', '"', 'Ġ\\', 'n']
Detokenized (006): ['BBS_XMPP_CERT_FILE', 'Ġ=', 'ĠBBS_ROOT', 'Ġ+', 'Ġ"xmpp.crt"', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "BOARDS_FILE = BBS_ROOT + \n"
Original    (005): ['BOARDS_FILE', '=', 'BBS_ROOT', '+', '\\n']
Tokenized   (015): ['<s>', 'BO', 'ARDS', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['BO', 'ARDS', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ\\', 'n']
Detokenized (005): ['BOARDS_FILE', 'Ġ=', 'ĠBBS_ROOT', 'Ġ+', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "USHM_SIZE = MAXACTIVE + 10 \n"
Original    (006): ['USHM_SIZE', '=', 'MAXACTIVE', '+', '10', '\\n']
Tokenized   (014): ['<s>', 'USH', 'M', '_', 'SIZE', 'Ġ=', 'ĠMAX', 'ACT', 'IVE', 'Ġ+', 'Ġ10', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['USH', 'M', '_', 'SIZE', 'Ġ=', 'ĠMAX', 'ACT', 'IVE', 'Ġ+', 'Ġ10', 'Ġ\\', 'n']
Detokenized (006): ['USHM_SIZE', 'Ġ=', 'ĠMAXACTIVE', 'Ġ+', 'Ġ10', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "UTMP_HASHSIZE = USHM_SIZE * 4 \n"
Original    (006): ['UTMP_HASHSIZE', '=', 'USHM_SIZE', '*', '4', '\\n']
Tokenized   (018): ['<s>', 'UT', 'MP', '_', 'H', 'AS', 'HS', 'IZE', 'Ġ=', 'ĠUS', 'HM', '_', 'SIZE', 'Ġ*', 'Ġ4', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['UT', 'MP', '_', 'H', 'AS', 'HS', 'IZE', 'Ġ=', 'ĠUS', 'HM', '_', 'SIZE', 'Ġ*', 'Ġ4', 'Ġ\\', 'n']
Detokenized (006): ['UTMP_HASHSIZE', 'Ġ=', 'ĠUSHM_SIZE', 'Ġ*', 'Ġ4', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "SESSION_TIMEOUT = datetime . timedelta ( 30 ) \n"
Original    (009): ['SESSION_TIMEOUT', '=', 'datetime', '.', 'timedelta', '(', '30', ')', '\\n']
Tokenized   (018): ['<s>', 'S', 'ESSION', '_', 'TIME', 'OUT', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['S', 'ESSION', '_', 'TIME', 'OUT', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['SESSION_TIMEOUT', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "SESSION_TIMEOUT_SECONDS = 86400 * 30 \n"
Original    (006): ['SESSION_TIMEOUT_SECONDS', '=', '86400', '*', '30', '\\n']
Tokenized   (019): ['<s>', 'S', 'ESSION', '_', 'TIME', 'OUT', '_', 'SEC', 'ON', 'DS', 'Ġ=', 'Ġ8', '64', '00', 'Ġ*', 'Ġ30', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['S', 'ESSION', '_', 'TIME', 'OUT', '_', 'SEC', 'ON', 'DS', 'Ġ=', 'Ġ8', '64', '00', 'Ġ*', 'Ġ30', 'Ġ\\', 'n']
Detokenized (006): ['SESSION_TIMEOUT_SECONDS', 'Ġ=', 'Ġ86400', 'Ġ*', 'Ġ30', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "MAX_ATTACHSIZE = 20 * 1024 * 1024 \n"
Original    (008): ['MAX_ATTACHSIZE', '=', '20', '*', '1024', '*', '1024', '\\n']
Tokenized   (016): ['<s>', 'MAX', '_', 'ATT', 'AC', 'HS', 'IZE', 'Ġ=', 'Ġ20', 'Ġ*', 'Ġ1024', 'Ġ*', 'Ġ1024', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['MAX', '_', 'ATT', 'AC', 'HS', 'IZE', 'Ġ=', 'Ġ20', 'Ġ*', 'Ġ1024', 'Ġ*', 'Ġ1024', 'Ġ\\', 'n']
Detokenized (008): ['MAX_ATTACHSIZE', 'Ġ=', 'Ġ20', 'Ġ*', 'Ġ1024', 'Ġ*', 'Ġ1024', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "MAIL_SIZE_LIMIT = - 1 \n"
Original    (005): ['MAIL_SIZE_LIMIT', '=', '-', '1', '\\n']
Tokenized   (015): ['<s>', 'MA', 'IL', '_', 'SIZE', '_', 'L', 'IM', 'IT', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['MA', 'IL', '_', 'SIZE', '_', 'L', 'IM', 'IT', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (005): ['MAIL_SIZE_LIMIT', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "newparts = [ ] \n"
Original    (005): ['newparts', '=', '[', ']', '\\n']
Tokenized   (009): ['<s>', 'new', 'parts', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['new', 'parts', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (005): ['newparts', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "firstitem = self . GetItem ( user , route + [ start ] , has_perm , need_perm ) \n"
Original    (019): ['firstitem', '=', 'self', '.', 'GetItem', '(', 'user', ',', 'route', '+', '[', 'start', ']', ',', 'has_perm', ',', 'need_perm', ')', '\\n']
Tokenized   (028): ['<s>', 'first', 'item', 'Ġ=', 'Ġself', 'Ġ.', 'ĠGet', 'Item', 'Ġ(', 'Ġuser', 'Ġ,', 'Ġroute', 'Ġ+', 'Ġ[', 'Ġstart', 'Ġ]', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġneed', '_', 'perm', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['first', 'item', 'Ġ=', 'Ġself', 'Ġ.', 'ĠGet', 'Item', 'Ġ(', 'Ġuser', 'Ġ,', 'Ġroute', 'Ġ+', 'Ġ[', 'Ġstart', 'Ġ]', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġneed', '_', 'perm', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['firstitem', 'Ġ=', 'Ġself', 'Ġ.', 'ĠGetItem', 'Ġ(', 'Ġuser', 'Ġ,', 'Ġroute', 'Ġ+', 'Ġ[', 'Ġstart', 'Ġ]', 'Ġ,', 'Ġhas_perm', 'Ġ,', 'Ġneed_perm', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "_id = start - 1 \n"
Original    (006): ['_id', '=', 'start', '-', '1', '\\n']
Tokenized   (010): ['<s>', '_', 'id', 'Ġ=', 'Ġstart', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['_', 'id', 'Ġ=', 'Ġstart', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (006): ['_id', 'Ġ=', 'Ġstart', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "linkfile = "%s/boards/xattach/%s" % ( Config . BBS_ROOT , filename ) \n"
Original    (012): ['linkfile', '=', '"%s/boards/xattach/%s"', '%', '(', 'Config', '.', 'BBS_ROOT', ',', 'filename', ')', '\\n']
Tokenized   (030): ['<s>', 'link', 'file', 'Ġ=', 'Ġ"%', 's', '/', 'boards', '/', 'x', 'attach', '/', '%', 's', '"', 'Ġ%', 'Ġ(', 'ĠConfig', 'Ġ.', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['link', 'file', 'Ġ=', 'Ġ"%', 's', '/', 'boards', '/', 'x', 'attach', '/', '%', 's', '"', 'Ġ%', 'Ġ(', 'ĠConfig', 'Ġ.', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['linkfile', 'Ġ=', 'Ġ"%s/boards/xattach/%s"', 'Ġ%', 'Ġ(', 'ĠConfig', 'Ġ.', 'ĠBBS_ROOT', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "boardname = svc . get_str ( params , , ) \n"
Original    (011): ['boardname', '=', 'svc', '.', 'get_str', '(', 'params', ',', ',', ')', '\\n']
Tokenized   (018): ['<s>', 'board', 'name', 'Ġ=', 'Ġs', 'vc', 'Ġ.', 'Ġget', '_', 'str', 'Ġ(', 'Ġparams', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['board', 'name', 'Ġ=', 'Ġs', 'vc', 'Ġ.', 'Ġget', '_', 'str', 'Ġ(', 'Ġparams', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['boardname', 'Ġ=', 'Ġsvc', 'Ġ.', 'Ġget_str', 'Ġ(', 'Ġparams', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "has_perm = user . IsDigestMgr ( ) \n"
Original    (008): ['has_perm', '=', 'user', '.', 'IsDigestMgr', '(', ')', '\\n']
Tokenized   (017): ['<s>', 'has', '_', 'perm', 'Ġ=', 'Ġuser', 'Ġ.', 'ĠIs', 'Dig', 'est', 'M', 'gr', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['has', '_', 'perm', 'Ġ=', 'Ġuser', 'Ġ.', 'ĠIs', 'Dig', 'est', 'M', 'gr', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['has_perm', 'Ġ=', 'Ġuser', 'Ġ.', 'ĠIsDigestMgr', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Digest . View ( svc , basenode , route , session , has_perm , start , count ) \n"
Original    (019): ['Digest', '.', 'View', '(', 'svc', ',', 'basenode', ',', 'route', ',', 'session', ',', 'has_perm', ',', 'start', ',', 'count', ')', '\\n']
Tokenized   (028): ['<s>', 'Dig', 'est', 'Ġ.', 'ĠView', 'Ġ(', 'Ġs', 'vc', 'Ġ,', 'Ġbas', 'en', 'ode', 'Ġ,', 'Ġroute', 'Ġ,', 'Ġsession', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġstart', 'Ġ,', 'Ġcount', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['Dig', 'est', 'Ġ.', 'ĠView', 'Ġ(', 'Ġs', 'vc', 'Ġ,', 'Ġbas', 'en', 'ode', 'Ġ,', 'Ġroute', 'Ġ,', 'Ġsession', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġstart', 'Ġ,', 'Ġcount', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['Digest', 'Ġ.', 'ĠView', 'Ġ(', 'Ġsvc', 'Ġ,', 'Ġbasenode', 'Ġ,', 'Ġroute', 'Ġ,', 'Ġsession', 'Ġ,', 'Ġhas_perm', 'Ġ,', 'Ġstart', 'Ġ,', 'Ġcount', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "svc . writedata ( json . dumps ( result ) ) \n"
Original    (012): ['svc', '.', 'writedata', '(', 'json', '.', 'dumps', '(', 'result', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'sv', 'c', 'Ġ.', 'Ġwrit', 'ed', 'ata', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['sv', 'c', 'Ġ.', 'Ġwrit', 'ed', 'ata', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['svc', 'Ġ.', 'Ġwritedata', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "postinfo = Post . Post ( item . realpath ( ) , None ) \n"
Original    (015): ['postinfo', '=', 'Post', '.', 'Post', '(', 'item', '.', 'realpath', '(', ')', ',', 'None', ')', '\\n']
Tokenized   (020): ['<s>', 'post', 'info', 'Ġ=', 'ĠPost', 'Ġ.', 'ĠPost', 'Ġ(', 'Ġitem', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['post', 'info', 'Ġ=', 'ĠPost', 'Ġ.', 'ĠPost', 'Ġ(', 'Ġitem', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['postinfo', 'Ġ=', 'ĠPost', 'Ġ.', 'ĠPost', 'Ġ(', 'Ġitem', 'Ġ.', 'Ġrealpath', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "msg_count = msgbox . GetMsgCount ( all = False ) \n"
Original    (011): ['msg_count', '=', 'msgbox', '.', 'GetMsgCount', '(', 'all', '=', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'msg', '_', 'count', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠGet', 'Msg', 'Count', 'Ġ(', 'Ġall', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['msg', '_', 'count', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠGet', 'Msg', 'Count', 'Ġ(', 'Ġall', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['msg_count', 'Ġ=', 'Ġmsgbox', 'Ġ.', 'ĠGetMsgCount', 'Ġ(', 'Ġall', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "xmpp_read = self . rosters . get_xmpp_read ( self . _user . GetUID ( ) ) \n"
Original    (017): ['xmpp_read', '=', 'self', '.', 'rosters', '.', 'get_xmpp_read', '(', 'self', '.', '_user', '.', 'GetUID', '(', ')', ')', '\\n']
Tokenized   (032): ['<s>', 'x', 'm', 'pp', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'x', 'm', 'pp', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'user', 'Ġ.', 'ĠGet', 'UID', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['x', 'm', 'pp', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'x', 'm', 'pp', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'user', 'Ġ.', 'ĠGet', 'UID', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['xmpp_read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget_xmpp_read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_user', 'Ġ.', 'ĠGetUID', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "read_count = msg_count - msg_unread \n"
Original    (006): ['read_count', '=', 'msg_count', '-', 'msg_unread', '\\n']
Tokenized   (016): ['<s>', 'read', '_', 'count', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ-', 'Ġmsg', '_', 'un', 'read', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['read', '_', 'count', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ-', 'Ġmsg', '_', 'un', 'read', 'Ġ\\', 'n']
Detokenized (006): ['read_count', 'Ġ=', 'Ġmsg_count', 'Ġ-', 'Ġmsg_unread', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "term_read = self . rosters . get_term_read ( self . get_uid ( ) ) \n"
Original    (015): ['term_read', '=', 'self', '.', 'rosters', '.', 'get_term_read', '(', 'self', '.', 'get_uid', '(', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'term', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'term', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', '_', 'uid', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['term', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'term', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', '_', 'uid', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['term_read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget_term_read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget_uid', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "new_unread [ msghead . topid ] = i \n"
Original    (009): ['new_unread', '[', 'msghead', '.', 'topid', ']', '=', 'i', '\\n']
Tokenized   (017): ['<s>', 'new', '_', 'un', 'read', 'Ġ[', 'Ġmsg', 'head', 'Ġ.', 'Ġtop', 'id', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['new', '_', 'un', 'read', 'Ġ[', 'Ġmsg', 'head', 'Ġ.', 'Ġtop', 'id', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n']
Detokenized (009): ['new_unread', 'Ġ[', 'Ġmsghead', 'Ġ.', 'Ġtopid', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "to_steal = { } \n"
Original    (005): ['to_steal', '=', '{', '}', '\\n']
Tokenized   (011): ['<s>', 'to', '_', 'st', 'eal', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['to', '_', 'st', 'eal', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n']
Detokenized (005): ['to_steal', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "to_steal_begin = msg_count \n"
Original    (004): ['to_steal_begin', '=', 'msg_count', '\\n']
Tokenized   (014): ['<s>', 'to', '_', 'st', 'eal', '_', 'begin', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['to', '_', 'st', 'eal', '_', 'begin', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ\\', 'n']
Detokenized (004): ['to_steal_begin', 'Ġ=', 'Ġmsg_count', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "pass \n"
Original    (002): ['pass', '\\n']
Tokenized   (005): ['<s>', 'pass', 'Ġ\\', 'n', '</s>']
Filtered   (003): ['pass', 'Ġ\\', 'n']
Detokenized (002): ['pass', 'Ġ\\n']
Counter: 3
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "final_unread [ pid ] = ( new_unread [ pid ] , 1 ) \n"
Original    (014): ['final_unread', '[', 'pid', ']', '=', '(', 'new_unread', '[', 'pid', ']', ',', '1', ')', '\\n']
Tokenized   (023): ['<s>', 'final', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['final', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['final_unread', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew_unread', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "msgtext = msgbox . LoadMsgText ( msghead ) \n"
Original    (009): ['msgtext', '=', 'msgbox', '.', 'LoadMsgText', '(', 'msghead', ')', '\\n']
Tokenized   (017): ['<s>', 'msg', 'text', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠLoad', 'Msg', 'Text', 'Ġ(', 'Ġmsg', 'head', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['msg', 'text', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠLoad', 'Msg', 'Text', 'Ġ(', 'Ġmsg', 'head', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['msgtext', 'Ġ=', 'Ġmsgbox', 'Ġ.', 'ĠLoadMsgText', 'Ġ(', 'Ġmsghead', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "roster = self . rosters . get ( self ) \n"
Original    (011): ['roster', '=', 'self', '.', 'rosters', '.', 'get', '(', 'self', ')', '\\n']
Tokenized   (015): ['<s>', 'ro', 'ster', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ro', 'ster', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['roster', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "PYTHON_VERSION = sys . version_info [ : 3 ] \n"
Original    (010): ['PYTHON_VERSION', '=', 'sys', '.', 'version_info', '[', ':', '3', ']', '\\n']
Tokenized   (020): ['<s>', 'P', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġversion', '_', 'info', 'Ġ[', 'Ġ:', 'Ġ3', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['P', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġversion', '_', 'info', 'Ġ[', 'Ġ:', 'Ġ3', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['PYTHON_VERSION', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġversion_info', 'Ġ[', 'Ġ:', 'Ġ3', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "PY2 = ( PYTHON_VERSION [ 0 ] == 2 ) \n"
Original    (011): ['PY2', '=', '(', 'PYTHON_VERSION', '[', '0', ']', '==', '2', ')', '\\n']
Tokenized   (021): ['<s>', 'P', 'Y', '2', 'Ġ=', 'Ġ(', 'ĠP', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['P', 'Y', '2', 'Ġ=', 'Ġ(', 'ĠP', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['PY2', 'Ġ=', 'Ġ(', 'ĠPYTHON_VERSION', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "sp_desc , \n"
Original    (003): ['sp_desc', ',', '\\n']
Tokenized   (008): ['<s>', 'sp', '_', 'desc', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['sp', '_', 'desc', 'Ġ,', 'Ġ\\', 'n']
Detokenized (003): ['sp_desc', 'Ġ,', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "con = hpov . connection ( args . host ) \n"
Original    (011): ['con', '=', 'hpov', '.', 'connection', '(', 'args', '.', 'host', ')', '\\n']
Tokenized   (015): ['<s>', 'con', 'Ġ=', 'Ġhp', 'ov', 'Ġ.', 'Ġconnection', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġhost', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['con', 'Ġ=', 'Ġhp', 'ov', 'Ġ.', 'Ġconnection', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġhost', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['con', 'Ġ=', 'Ġhpov', 'Ġ.', 'Ġconnection', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġhost', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "acceptEULA ( con ) \n"
Original    (005): ['acceptEULA', '(', 'con', ')', '\\n']
Tokenized   (011): ['<s>', 'accept', 'E', 'UL', 'A', 'Ġ(', 'Ġcon', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['accept', 'E', 'UL', 'A', 'Ġ(', 'Ġcon', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['acceptEULA', 'Ġ(', 'Ġcon', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "fw_settings = profile . make_firmware_dict ( sts , args . baseline ) \n"
Original    (013): ['fw_settings', '=', 'profile', '.', 'make_firmware_dict', '(', 'sts', ',', 'args', '.', 'baseline', ')', '\\n']
Tokenized   (024): ['<s>', 'fw', '_', 'settings', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'f', 'irm', 'ware', '_', 'dict', 'Ġ(', 'Ġsts', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġbaseline', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['fw', '_', 'settings', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'f', 'irm', 'ware', '_', 'dict', 'Ġ(', 'Ġsts', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġbaseline', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['fw_settings', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake_firmware_dict', 'Ġ(', 'Ġsts', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġbaseline', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "boot , bootmode = profile . make_boot_settings_dict ( srv , sht , args . disable_manage_boot , \n"
Original    (017): ['boot', ',', 'bootmode', '=', 'profile', '.', 'make_boot_settings_dict', '(', 'srv', ',', 'sht', ',', 'args', '.', 'disable_manage_boot', ',', '\\n']
Tokenized   (034): ['<s>', 'boot', 'Ġ,', 'Ġboot', 'mode', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'boot', '_', 'settings', '_', 'dict', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġsh', 't', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġdisable', '_', 'man', 'age', '_', 'boot', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['boot', 'Ġ,', 'Ġboot', 'mode', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'boot', '_', 'settings', '_', 'dict', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġsh', 't', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġdisable', '_', 'man', 'age', '_', 'boot', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['boot', 'Ġ,', 'Ġbootmode', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake_boot_settings_dict', 'Ġ(', 'Ġsrv', 'Ġ,', 'Ġsht', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġdisable_manage_boot', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "define_profile_template ( srv , \n"
Original    (005): ['define_profile_template', '(', 'srv', ',', '\\n']
Tokenized   (013): ['<s>', 'define', '_', 'profile', '_', 'template', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['define', '_', 'profile', '_', 'template', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['define_profile_template', 'Ġ(', 'Ġsrv', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "sht [ ] , \n"
Original    (005): ['sht', '[', ']', ',', '\\n']
Tokenized   (009): ['<s>', 'sh', 't', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['sh', 't', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['sht', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "credential = { : args . domain . upper ( ) , : args . user , : args . passwd } \n"
Original    (023): ['credential', '=', '{', ':', 'args', '.', 'domain', '.', 'upper', '(', ')', ',', ':', 'args', '.', 'user', ',', ':', 'args', '.', 'passwd', '}', '\\n']
Tokenized   (029): ['<s>', 'c', 'red', 'ential', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġdomain', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġuser', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġpass', 'wd', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['c', 'red', 'ential', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġdomain', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġuser', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġpass', 'wd', 'Ġ}', 'Ġ\\', 'n']
Detokenized (023): ['credential', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġdomain', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġuser', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġpasswd', 'Ġ}', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "get_address_pools ( con , srv , args . types ) \n"
Original    (011): ['get_address_pools', '(', 'con', ',', 'srv', ',', 'args', '.', 'types', ')', '\\n']
Tokenized   (020): ['<s>', 'get', '_', 'address', '_', 'pool', 's', 'Ġ(', 'Ġcon', 'Ġ,', 'Ġsr', 'v', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġtypes', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['get', '_', 'address', '_', 'pool', 's', 'Ġ(', 'Ġcon', 'Ġ,', 'Ġsr', 'v', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġtypes', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['get_address_pools', 'Ġ(', 'Ġcon', 'Ġ,', 'Ġsrv', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġtypes', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "enclosure_group = None , server_profile = None ) : \n"
Original    (010): ['enclosure_group', '=', 'None', ',', 'server_profile', '=', 'None', ')', ':', '\\n']
Tokenized   (018): ['<s>', 'en', 'closure', '_', 'group', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġserver', '_', 'profile', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['en', 'closure', '_', 'group', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġserver', '_', 'profile', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (010): ['enclosure_group', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġserver_profile', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "biosSettings = None , \n"
Original    (005): ['biosSettings', '=', 'None', ',', '\\n']
Tokenized   (010): ['<s>', 'b', 'ios', 'Settings', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['b', 'ios', 'Settings', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['biosSettings', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "macType = , \n"
Original    (004): ['macType', '=', ',', '\\n']
Tokenized   (008): ['<s>', 'mac', 'Type', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['mac', 'Type', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['macType', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "localStorageSettingsV3 , macType , name , \n"
Original    (007): ['localStorageSettingsV3', ',', 'macType', ',', 'name', ',', '\\n']
Tokenized   (015): ['<s>', 'local', 'Storage', 'Settings', 'V', '3', 'Ġ,', 'Ġmac', 'Type', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['local', 'Storage', 'Settings', 'V', '3', 'Ġ,', 'Ġmac', 'Type', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['localStorageSettingsV3', 'Ġ,', 'ĠmacType', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "sanStorageV3 , serialNumber , \n"
Original    (005): ['sanStorageV3', ',', 'serialNumber', ',', '\\n']
Tokenized   (012): ['<s>', 'san', 'Storage', 'V', '3', 'Ġ,', 'Ġserial', 'Number', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['san', 'Storage', 'V', '3', 'Ġ,', 'Ġserial', 'Number', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['sanStorageV3', 'Ġ,', 'ĠserialNumber', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "serverProfileTemplateUri , uuid , wwnType ) \n"
Original    (007): ['serverProfileTemplateUri', ',', 'uuid', ',', 'wwnType', ')', '\\n']
Tokenized   (017): ['<s>', 'server', 'Profile', 'Template', 'U', 'ri', 'Ġ,', 'Ġu', 'uid', 'Ġ,', 'Ġw', 'wn', 'Type', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['server', 'Profile', 'Template', 'U', 'ri', 'Ġ,', 'Ġu', 'uid', 'Ġ,', 'Ġw', 'wn', 'Type', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['serverProfileTemplateUri', 'Ġ,', 'Ġuuid', 'Ġ,', 'ĠwwnType', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "profile_template = self . _con . get ( entity [ ] ) \n"
Original    (013): ['profile_template', '=', 'self', '.', '_con', '.', 'get', '(', 'entity', '[', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'profile', '_', 'template', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'con', 'Ġ.', 'Ġget', 'Ġ(', 'Ġentity', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['profile', '_', 'template', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'con', 'Ġ.', 'Ġget', 'Ġ(', 'Ġentity', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['profile_template', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_con', 'Ġ.', 'Ġget', 'Ġ(', 'Ġentity', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "powerMode = ) : \n"
Original    (005): ['powerMode', '=', ')', ':', '\\n']
Tokenized   (009): ['<s>', 'power', 'Mode', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['power', 'Mode', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (005): ['powerMode', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "egroup = make_EnclosureGroupV200 ( associatedLIGs , name , powerMode ) \n"
Original    (011): ['egroup', '=', 'make_EnclosureGroupV200', '(', 'associatedLIGs', ',', 'name', ',', 'powerMode', ')', '\\n']
Tokenized   (025): ['<s>', 'eg', 'roup', 'Ġ=', 'Ġmake', '_', 'En', 'closure', 'Group', 'V', '200', 'Ġ(', 'Ġassociated', 'L', 'IG', 's', 'Ġ,', 'Ġname', 'Ġ,', 'Ġpower', 'Mode', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['eg', 'roup', 'Ġ=', 'Ġmake', '_', 'En', 'closure', 'Group', 'V', '200', 'Ġ(', 'Ġassociated', 'L', 'IG', 's', 'Ġ,', 'Ġname', 'Ġ,', 'Ġpower', 'Mode', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['egroup', 'Ġ=', 'Ġmake_EnclosureGroupV200', 'Ġ(', 'ĠassociatedLIGs', 'Ġ,', 'Ġname', 'Ġ,', 'ĠpowerMode', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "allocatorBody = { : count } \n"
Original    (007): ['allocatorBody', '=', '{', ':', 'count', '}', '\\n']
Tokenized   (012): ['<s>', 'alloc', 'ator', 'Body', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġcount', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['alloc', 'ator', 'Body', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġcount', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['allocatorBody', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġcount', 'Ġ}', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "prange [ ] = False \n"
Original    (006): ['prange', '[', ']', '=', 'False', '\\n']
Tokenized   (010): ['<s>', 'pr', 'ange', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['pr', 'ange', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (006): ['prange', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠFalse', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tempstr = "hp-rest-classes-bios-" + romfamily + "-" + biosversion \n"
Original    (010): ['tempstr', '=', '"hp-rest-classes-bios-"', '+', 'romfamily', '+', '"-"', '+', 'biosversion', '\\n']
Tokenized   (026): ['<s>', 'temp', 'str', 'Ġ=', 'Ġ"', 'hp', '-', 'rest', '-', 'classes', '-', 'b', 'ios', '-"', 'Ġ+', 'Ġrom', 'family', 'Ġ+', 'Ġ"', '-"', 'Ġ+', 'Ġbios', 'version', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['temp', 'str', 'Ġ=', 'Ġ"', 'hp', '-', 'rest', '-', 'classes', '-', 'b', 'ios', '-"', 'Ġ+', 'Ġrom', 'family', 'Ġ+', 'Ġ"', '-"', 'Ġ+', 'Ġbios', 'version', 'Ġ\\', 'n']
Detokenized (010): ['tempstr', 'Ġ=', 'Ġ"hp-rest-classes-bios-"', 'Ġ+', 'Ġromfamily', 'Ġ+', 'Ġ"-"', 'Ġ+', 'Ġbiosversion', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "monolith = None ) : \n"
Original    (006): ['monolith', '=', 'None', ')', ':', '\\n']
Tokenized   (010): ['<s>', 'mon', 'olith', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['mon', 'olith', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['monolith', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "pathjoinstr ) ) : \n"
Original    (005): ['pathjoinstr', ')', ')', ':', '\\n']
Tokenized   (010): ['<s>', 'path', 'join', 'str', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['path', 'join', 'str', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (005): ['pathjoinstr', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "newclass . set_root ( root ) \n"
Original    (007): ['newclass', '.', 'set_root', '(', 'root', ')', '\\n']
Tokenized   (013): ['<s>', 'new', 'class', 'Ġ.', 'Ġset', '_', 'root', 'Ġ(', 'Ġroot', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['new', 'class', 'Ġ.', 'Ġset', '_', 'root', 'Ġ(', 'Ġroot', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['newclass', 'Ġ.', 'Ġset_root', 'Ġ(', 'Ġroot', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "folderentries = data [ "links" ] \n"
Original    (007): ['folderentries', '=', 'data', '[', '"links"', ']', '\\n']
Tokenized   (014): ['<s>', 'fold', 'erent', 'ries', 'Ġ=', 'Ġdata', 'Ġ[', 'Ġ"', 'links', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['fold', 'erent', 'ries', 'Ġ=', 'Ġdata', 'Ġ[', 'Ġ"', 'links', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['folderentries', 'Ġ=', 'Ġdata', 'Ġ[', 'Ġ"links"', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "datareturn . append ( self . load_file ( fqpath , root = root , biossection = True , registries = True , datareturn = True ) ) \n"
Original    (028): ['datareturn', '.', 'append', '(', 'self', '.', 'load_file', '(', 'fqpath', ',', 'root', '=', 'root', ',', 'biossection', '=', 'True', ',', 'registries', '=', 'True', ',', 'datareturn', '=', 'True', ')', ')', '\\n']
Tokenized   (041): ['<s>', 'dat', 'aret', 'urn', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġload', '_', 'file', 'Ġ(', 'Ġf', 'q', 'path', 'Ġ,', 'Ġroot', 'Ġ=', 'Ġroot', 'Ġ,', 'Ġbios', 'section', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġregist', 'ries', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġdat', 'aret', 'urn', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['dat', 'aret', 'urn', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġload', '_', 'file', 'Ġ(', 'Ġf', 'q', 'path', 'Ġ,', 'Ġroot', 'Ġ=', 'Ġroot', 'Ġ,', 'Ġbios', 'section', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġregist', 'ries', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġdat', 'aret', 'urn', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (028): ['datareturn', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġload_file', 'Ġ(', 'Ġfqpath', 'Ġ,', 'Ġroot', 'Ġ=', 'Ġroot', 'Ġ,', 'Ġbiossection', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġregistries', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġdatareturn', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "currdict = currdict , monolith = monolith , \n"
Original    (009): ['currdict', '=', 'currdict', ',', 'monolith', '=', 'monolith', ',', '\\n']
Tokenized   (018): ['<s>', 'cur', 'rd', 'ict', 'Ġ=', 'Ġcur', 'rd', 'ict', 'Ġ,', 'Ġmon', 'olith', 'Ġ=', 'Ġmon', 'olith', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['cur', 'rd', 'ict', 'Ġ=', 'Ġcur', 'rd', 'ict', 'Ġ,', 'Ġmon', 'olith', 'Ġ=', 'Ġmon', 'olith', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['currdict', 'Ġ=', 'Ġcurrdict', 'Ġ,', 'Ġmonolith', 'Ġ=', 'Ġmonolith', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newarg = newarg , checkall = checkall ) \n"
Original    (009): ['newarg', '=', 'newarg', ',', 'checkall', '=', 'checkall', ')', '\\n']
Tokenized   (016): ['<s>', 'new', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ,', 'Ġcheck', 'all', 'Ġ=', 'Ġcheck', 'all', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['new', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ,', 'Ġcheck', 'all', 'Ġ=', 'Ġcheck', 'all', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['newarg', 'Ġ=', 'Ġnewarg', 'Ġ,', 'Ġcheckall', 'Ġ=', 'Ġcheckall', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "attrreg = self . find_bios_registry ( regname = regname ) \n"
Original    (011): ['attrreg', '=', 'self', '.', 'find_bios_registry', '(', 'regname', '=', 'regname', ')', '\\n']
Tokenized   (023): ['<s>', 'attr', 'reg', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfind', '_', 'b', 'ios', '_', 'reg', 'istry', 'Ġ(', 'Ġreg', 'name', 'Ġ=', 'Ġreg', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['attr', 'reg', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfind', '_', 'b', 'ios', '_', 'reg', 'istry', 'Ġ(', 'Ġreg', 'name', 'Ġ=', 'Ġreg', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['attrreg', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfind_bios_registry', 'Ġ(', 'Ġregname', 'Ġ=', 'Ġregname', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "schlink = schlink [ len ( schlink ) - 2 ] \n"
Original    (012): ['schlink', '=', 'schlink', '[', 'len', '(', 'schlink', ')', '-', '2', ']', '\\n']
Tokenized   (018): ['<s>', 'sch', 'link', 'Ġ=', 'Ġsch', 'link', 'Ġ[', 'Ġlen', 'Ġ(', 'Ġsch', 'link', 'Ġ)', 'Ġ-', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['sch', 'link', 'Ġ=', 'Ġsch', 'link', 'Ġ[', 'Ġlen', 'Ġ(', 'Ġsch', 'link', 'Ġ)', 'Ġ-', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['schlink', 'Ġ=', 'Ġschlink', 'Ġ[', 'Ġlen', 'Ġ(', 'Ġschlink', 'Ġ)', 'Ġ-', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "schname . lower ( ) ) : \n"
Original    (008): ['schname', '.', 'lower', '(', ')', ')', ':', '\\n']
Tokenized   (013): ['<s>', 's', 'chn', 'ame', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['s', 'chn', 'ame', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['schname', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "xref = os . path . normpath ( currloc . Uri . extref ) . lstrip ( os . path . sep ) \n"
Original    (024): ['xref', '=', 'os', '.', 'path', '.', 'normpath', '(', 'currloc', '.', 'Uri', '.', 'extref', ')', '.', 'lstrip', '(', 'os', '.', 'path', '.', 'sep', ')', '\\n']
Tokenized   (033): ['<s>', 'x', 'ref', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġnorm', 'path', 'Ġ(', 'Ġcur', 'r', 'loc', 'Ġ.', 'ĠUri', 'Ġ.', 'Ġext', 'ref', 'Ġ)', 'Ġ.', 'Ġl', 'strip', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['x', 'ref', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġnorm', 'path', 'Ġ(', 'Ġcur', 'r', 'loc', 'Ġ.', 'ĠUri', 'Ġ.', 'Ġext', 'ref', 'Ġ)', 'Ġ.', 'Ġl', 'strip', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['xref', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġnormpath', 'Ġ(', 'Ġcurrloc', 'Ġ.', 'ĠUri', 'Ġ.', 'Ġextref', 'Ġ)', 'Ġ.', 'Ġlstrip', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "fqpath = os . path . join ( root , xref ) \n"
Original    (013): ['fqpath', '=', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'xref', ')', '\\n']
Tokenized   (019): ['<s>', 'f', 'q', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġx', 'ref', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['f', 'q', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġx', 'ref', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['fqpath', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġxref', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "langcode = list ( locale . getdefaultlocale ( ) ) \n"
Original    (011): ['langcode', '=', 'list', '(', 'locale', '.', 'getdefaultlocale', '(', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'lang', 'code', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġlocale', 'Ġ.', 'Ġget', 'default', 'loc', 'ale', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['lang', 'code', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġlocale', 'Ġ.', 'Ġget', 'default', 'loc', 'ale', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['langcode', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġlocale', 'Ġ.', 'Ġgetdefaultlocale', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "locationlanguage = locationlanguage . replace ( "-" , "_" ) \n"
Original    (011): ['locationlanguage', '=', 'locationlanguage', '.', 'replace', '(', '"-"', ',', '"_"', ')', '\\n']
Tokenized   (018): ['<s>', 'location', 'language', 'Ġ=', 'Ġlocation', 'language', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '-"', 'Ġ,', 'Ġ"_', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['location', 'language', 'Ġ=', 'Ġlocation', 'language', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '-"', 'Ġ,', 'Ġ"_', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['locationlanguage', 'Ġ=', 'Ġlocationlanguage', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"-"', 'Ġ,', 'Ġ"_"', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "currtype = currtype . split ( ) [ 0 ] + \n"
Original    (012): ['currtype', '=', 'currtype', '.', 'split', '(', ')', '[', '0', ']', '+', '\\n']
Tokenized   (019): ['<s>', 'cur', 'r', 'type', 'Ġ=', 'Ġcur', 'r', 'type', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['cur', 'r', 'type', 'Ġ=', 'Ġcur', 'r', 'type', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n']
Detokenized (012): ['currtype', 'Ġ=', 'Ġcurrtype', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "insttype = instance . resp . dict [ "title" ] . split ( ) [ : 1 ] \n"
Original    (019): ['insttype', '=', 'instance', '.', 'resp', '.', 'dict', '[', '"title"', ']', '.', 'split', '(', ')', '[', ':', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'inst', 'type', 'Ġ=', 'Ġinstance', 'Ġ.', 'Ġresp', 'Ġ.', 'Ġdict', 'Ġ[', 'Ġ"', 'title', '"', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['inst', 'type', 'Ġ=', 'Ġinstance', 'Ġ.', 'Ġresp', 'Ġ.', 'Ġdict', 'Ġ[', 'Ġ"', 'title', '"', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (019): ['insttype', 'Ġ=', 'Ġinstance', 'Ġ.', 'Ġresp', 'Ġ.', 'Ġdict', 'Ġ[', 'Ġ"title"', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "nextarg = newarg [ newarg . index ( arg ) + 1 ] \n"
Original    (014): ['nextarg', '=', 'newarg', '[', 'newarg', '.', 'index', '(', 'arg', ')', '+', '1', ']', '\\n']
Tokenized   (020): ['<s>', 'next', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ[', 'Ġnew', 'arg', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['next', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ[', 'Ġnew', 'arg', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['nextarg', 'Ġ=', 'Ġnewarg', 'Ġ[', 'Ġnewarg', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "regcopy [ nextarg ] = patterninfo \n"
Original    (007): ['regcopy', '[', 'nextarg', ']', '=', 'patterninfo', '\\n']
Tokenized   (013): ['<s>', 'reg', 'copy', 'Ġ[', 'Ġnext', 'arg', 'Ġ]', 'Ġ=', 'Ġpattern', 'info', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['reg', 'copy', 'Ġ[', 'Ġnext', 'arg', 'Ġ]', 'Ġ=', 'Ġpattern', 'info', 'Ġ\\', 'n']
Detokenized (007): ['regcopy', 'Ġ[', 'Ġnextarg', 'Ġ]', 'Ġ=', 'Ġpatterninfo', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "validictory . validate ( tdict , jsonsch ) \n"
Original    (009): ['validictory', '.', 'validate', '(', 'tdict', ',', 'jsonsch', ')', '\\n']
Tokenized   (017): ['<s>', 'valid', 'ict', 'ory', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġt', 'dict', 'Ġ,', 'Ġjs', 'ons', 'ch', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['valid', 'ict', 'ory', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġt', 'dict', 'Ġ,', 'Ġjs', 'ons', 'ch', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['validictory', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġtdict', 'Ġ,', 'Ġjsonsch', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "wrapper . subsequent_indent = * 4 \n"
Original    (007): ['wrapper', '.', 'subsequent_indent', '=', '*', '4', '\\n']
Tokenized   (013): ['<s>', 'wrapper', 'Ġ.', 'Ġsubsequent', '_', 'ind', 'ent', 'Ġ=', 'Ġ*', 'Ġ4', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['wrapper', 'Ġ.', 'Ġsubsequent', '_', 'ind', 'ent', 'Ġ=', 'Ġ*', 'Ġ4', 'Ġ\\', 'n']
Detokenized (007): ['wrapper', 'Ġ.', 'Ġsubsequent_indent', 'Ġ=', 'Ġ*', 'Ġ4', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "RegistryValidationError ( \n"
Original    (003): ['RegistryValidationError', '(', '\\n']
Tokenized   (010): ['<s>', 'Reg', 'istry', 'Val', 'idation', 'Error', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Reg', 'istry', 'Val', 'idation', 'Error', 'Ġ(', 'Ġ\\', 'n']
Detokenized (003): ['RegistryValidationError', 'Ġ(', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "regentry = self \n"
Original    (004): ['regentry', '=', 'self', '\\n']
Tokenized   (008): ['<s>', 'reg', 'entry', 'Ġ=', 'Ġself', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['reg', 'entry', 'Ġ=', 'Ġself', 'Ġ\\', 'n']
Detokenized (004): ['regentry', 'Ġ=', 'Ġself', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""\'%(ValueExpression)s\'" % ( self ) , regentry = self ) ) \n"
Original    (012): ['"\\\'%(ValueExpression)s\\\'"', '%', '(', 'self', ')', ',', 'regentry', '=', 'self', ')', ')', '\\n']
Tokenized   (026): ['<s>', '"', "\\'", '%', '(', 'Value', 'Exp', 'ression', ')', 's', '\\', '\'"', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ,', 'Ġreg', 'entry', 'Ġ=', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', "\\'", '%', '(', 'Value', 'Exp', 'ression', ')', 's', '\\', '\'"', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ,', 'Ġreg', 'entry', 'Ġ=', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['"\\\'%(ValueExpression)s\\\'"', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ,', 'Ġregentry', 'Ġ=', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "intval = int ( newval ) \n"
Original    (007): ['intval', '=', 'int', '(', 'newval', ')', '\\n']
Tokenized   (012): ['<s>', 'int', 'val', 'Ġ=', 'Ġint', 'Ġ(', 'Ġnew', 'val', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['int', 'val', 'Ġ=', 'Ġint', 'Ġ(', 'Ġnew', 'val', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['intval', 'Ġ=', 'Ġint', 'Ġ(', 'Ġnewval', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "MICROS_TRANSLATIONS = ( \n"
Original    (004): ['MICROS_TRANSLATIONS', '=', '(', '\\n']
Tokenized   (014): ['<s>', 'MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġ=', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġ=', 'Ġ(', 'Ġ\\', 'n']
Detokenized (004): ['MICROS_TRANSLATIONS', 'Ġ=', 'Ġ(', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "MICROS_TRANSLATION_HASH = dict ( ( alt , v ) for k , v in MICROS_TRANSLATIONS for alt in k ) \n"
Original    (021): ['MICROS_TRANSLATION_HASH', '=', 'dict', '(', '(', 'alt', ',', 'v', ')', 'for', 'k', ',', 'v', 'in', 'MICROS_TRANSLATIONS', 'for', 'alt', 'in', 'k', ')', '\\n']
Tokenized   (041): ['<s>', 'MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATION', '_', 'H', 'ASH', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġalt', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'ĠMIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġfor', 'Ġalt', 'Ġin', 'Ġk', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATION', '_', 'H', 'ASH', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġalt', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'ĠMIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġfor', 'Ġalt', 'Ġin', 'Ġk', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['MICROS_TRANSLATION_HASH', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġalt', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'ĠMICROS_TRANSLATIONS', 'Ġfor', 'Ġalt', 'Ġin', 'Ġk', 'Ġ)', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "epoch_milliseconds = epoch_millis = milliseconds = millis = ms \n"
Original    (010): ['epoch_milliseconds', '=', 'epoch_millis', '=', 'milliseconds', '=', 'millis', '=', 'ms', '\\n']
Tokenized   (022): ['<s>', 'ep', 'och', '_', 'mill', 'isec', 'onds', 'Ġ=', 'Ġepoch', '_', 'mill', 'is', 'Ġ=', 'Ġmilliseconds', 'Ġ=', 'Ġmill', 'is', 'Ġ=', 'Ġms', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['ep', 'och', '_', 'mill', 'isec', 'onds', 'Ġ=', 'Ġepoch', '_', 'mill', 'is', 'Ġ=', 'Ġmilliseconds', 'Ġ=', 'Ġmill', 'is', 'Ġ=', 'Ġms', 'Ġ\\', 'n']
Detokenized (010): ['epoch_milliseconds', 'Ġ=', 'Ġepoch_millis', 'Ġ=', 'Ġmilliseconds', 'Ġ=', 'Ġmillis', 'Ġ=', 'Ġms', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "epoch_microseconds = epoch_micros = microseconds = micros \n"
Original    (008): ['epoch_microseconds', '=', 'epoch_micros', '=', 'microseconds', '=', 'micros', '\\n']
Tokenized   (020): ['<s>', 'ep', 'och', '_', 'micro', 'seconds', 'Ġ=', 'Ġepoch', '_', 'micro', 's', 'Ġ=', 'Ġmicro', 'seconds', 'Ġ=', 'Ġmicro', 's', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['ep', 'och', '_', 'micro', 'seconds', 'Ġ=', 'Ġepoch', '_', 'micro', 's', 'Ġ=', 'Ġmicro', 'seconds', 'Ġ=', 'Ġmicro', 's', 'Ġ\\', 'n']
Detokenized (008): ['epoch_microseconds', 'Ġ=', 'Ġepoch_micros', 'Ġ=', 'Ġmicroseconds', 'Ġ=', 'Ġmicros', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "micros = u".%06d" % dt . microsecond if dt . microsecond else \n"
Original    (013): ['micros', '=', 'u".%06d"', '%', 'dt', '.', 'microsecond', 'if', 'dt', '.', 'microsecond', 'else', '\\n']
Tokenized   (026): ['<s>', 'micro', 's', 'Ġ=', 'Ġu', '".', '%', '06', 'd', '"', 'Ġ%', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġif', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġelse', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['micro', 's', 'Ġ=', 'Ġu', '".', '%', '06', 'd', '"', 'Ġ%', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġif', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġelse', 'Ġ\\', 'n']
Detokenized (013): ['micros', 'Ġ=', 'Ġu".%06d"', 'Ġ%', 'Ġdt', 'Ġ.', 'Ġmicrosecond', 'Ġif', 'Ġdt', 'Ġ.', 'Ġmicrosecond', 'Ġelse', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "datastore_owner_uuid = request . REQUEST [ "datastore_owner__uuid" ] \n"
Original    (009): ['datastore_owner_uuid', '=', 'request', '.', 'REQUEST', '[', '"datastore_owner__uuid"', ']', '\\n']
Tokenized   (029): ['<s>', 'dat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'dat', 'ast', 'ore', '_', 'owner', '__', 'uu', 'id', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['dat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'dat', 'ast', 'ore', '_', 'owner', '__', 'uu', 'id', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['datastore_owner_uuid', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġ[', 'Ġ"datastore_owner__uuid"', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "datastore_owner , ds_owner_created = Profile . objects . get_or_create ( uuid = datastore_owner_uuid ) \n"
Original    (015): ['datastore_owner', ',', 'ds_owner_created', '=', 'Profile', '.', 'objects', '.', 'get_or_create', '(', 'uuid', '=', 'datastore_owner_uuid', ')', '\\n']
Tokenized   (039): ['<s>', 'dat', 'ast', 'ore', '_', 'owner', 'Ġ,', 'Ġd', 's', '_', 'owner', '_', 'created', 'Ġ=', 'ĠProfile', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'or', '_', 'create', 'Ġ(', 'Ġu', 'uid', 'Ġ=', 'Ġdat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['dat', 'ast', 'ore', '_', 'owner', 'Ġ,', 'Ġd', 's', '_', 'owner', '_', 'created', 'Ġ=', 'ĠProfile', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'or', '_', 'create', 'Ġ(', 'Ġu', 'uid', 'Ġ=', 'Ġdat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['datastore_owner', 'Ġ,', 'Ġds_owner_created', 'Ġ=', 'ĠProfile', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget_or_create', 'Ġ(', 'Ġuuid', 'Ġ=', 'Ġdatastore_owner_uuid', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "port = db . Column ( db . Integer , nullable = False ) \n"
Original    (015): ['port', '=', 'db', '.', 'Column', '(', 'db', '.', 'Integer', ',', 'nullable', '=', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'port', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['port', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['port', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnullable', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "eru_container_id = db . Column ( db . String ( 64 ) , index = True ) \n"
Original    (018): ['eru_container_id', '=', 'db', '.', 'Column', '(', 'db', '.', 'String', '(', '64', ')', ',', 'index', '=', 'True', ')', '\\n']
Tokenized   (026): ['<s>', 'er', 'u', '_', 'container', '_', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠString', 'Ġ(', 'Ġ64', 'Ġ)', 'Ġ,', 'Ġindex', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['er', 'u', '_', 'container', '_', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠString', 'Ġ(', 'Ġ64', 'Ġ)', 'Ġ,', 'Ġindex', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['eru_container_id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠString', 'Ġ(', 'Ġ64', 'Ġ)', 'Ġ,', 'Ġindex', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "suppress_alert = db . Column ( db . Integer , nullable = False , default = 1 ) \n"
Original    (019): ['suppress_alert', '=', 'db', '.', 'Column', '(', 'db', '.', 'Integer', ',', 'nullable', '=', 'False', ',', 'default', '=', '1', ')', '\\n']
Tokenized   (026): ['<s>', 'supp', 'ress', '_', 'alert', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['supp', 'ress', '_', 'alert', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['suppress_alert', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnullable', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "__table_args__ = ( db . Index ( , , , unique = True ) , ) \n"
Original    (017): ['__table_args__', '=', '(', 'db', '.', 'Index', '(', ',', ',', ',', 'unique', '=', 'True', ')', ',', ')', '\\n']
Tokenized   (024): ['<s>', '__', 'table', '_', 'args', '__', 'Ġ=', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠIndex', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['__', 'table', '_', 'args', '__', 'Ġ=', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠIndex', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['__table_args__', 'Ġ=', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠIndex', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "cluster_id = cluster_id ) \n"
Original    (005): ['cluster_id', '=', 'cluster_id', ')', '\\n']
Tokenized   (013): ['<s>', 'cl', 'uster', '_', 'id', 'Ġ=', 'Ġcluster', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['cl', 'uster', '_', 'id', 'Ġ=', 'Ġcluster', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['cluster_id', 'Ġ=', 'Ġcluster_id', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "Proxy . id . desc ( ) ) . offset ( offset ) . limit ( limit ) . all ( ) \n"
Original    (023): ['Proxy', '.', 'id', '.', 'desc', '(', ')', ')', '.', 'offset', '(', 'offset', ')', '.', 'limit', '(', 'limit', ')', '.', 'all', '(', ')', '\\n']
Tokenized   (026): ['<s>', 'Proxy', 'Ġ.', 'Ġid', 'Ġ.', 'Ġdesc', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġoffset', 'Ġ(', 'Ġoffset', 'Ġ)', 'Ġ.', 'Ġlimit', 'Ġ(', 'Ġlimit', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['Proxy', 'Ġ.', 'Ġid', 'Ġ.', 'Ġdesc', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġoffset', 'Ġ(', 'Ġoffset', 'Ġ)', 'Ġ.', 'Ġlimit', 'Ġ(', 'Ġlimit', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['Proxy', 'Ġ.', 'Ġid', 'Ġ.', 'Ġdesc', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġoffset', 'Ġ(', 'Ġoffset', 'Ġ)', 'Ġ.', 'Ġlimit', 'Ġ(', 'Ġlimit', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "iou_as_issuer . issue_funds ( amount_issued , ) \n"
Original    (008): ['iou_as_issuer', '.', 'issue_funds', '(', 'amount_issued', ',', ')', '\\n']
Tokenized   (022): ['<s>', 'i', 'ou', '_', 'as', '_', 'iss', 'uer', 'Ġ.', 'Ġissue', '_', 'fund', 's', 'Ġ(', 'Ġamount', '_', 'issued', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['i', 'ou', '_', 'as', '_', 'iss', 'uer', 'Ġ.', 'Ġissue', '_', 'fund', 's', 'Ġ(', 'Ġamount', '_', 'issued', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['iou_as_issuer', 'Ġ.', 'Ġissue_funds', 'Ġ(', 'Ġamount_issued', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "github_info_json = urllib2 . urlopen ( latest ) . read ( ) \n"
Original    (013): ['github_info_json', '=', 'urllib2', '.', 'urlopen', '(', 'latest', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'github', '_', 'info', '_', 'json', 'Ġ=', 'Ġur', 'll', 'ib', '2', 'Ġ.', 'Ġurl', 'open', 'Ġ(', 'Ġlatest', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['github', '_', 'info', '_', 'json', 'Ġ=', 'Ġur', 'll', 'ib', '2', 'Ġ.', 'Ġurl', 'open', 'Ġ(', 'Ġlatest', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['github_info_json', 'Ġ=', 'Ġurllib2', 'Ġ.', 'Ġurlopen', 'Ġ(', 'Ġlatest', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) , read_delay = opt . read_delay ) \n"
Original    (024): ['drawing_tool', '.', 'set_window_title', '(', 'update_notifier', ',', 'watching_player', '=', 'twitch_username', ',', 'updates_queued', '=', 'len', '(', 'new_states_queue', ')', ',', 'read_delay', '=', 'opt', '.', 'read_delay', ')', '\\n']
Tokenized   (052): ['<s>', 'draw', 'ing', '_', 'tool', 'Ġ.', 'Ġset', '_', 'window', '_', 'title', 'Ġ(', 'Ġupdate', '_', 'not', 'ifier', 'Ġ,', 'Ġwatching', '_', 'player', 'Ġ=', 'Ġtwitch', '_', 'username', 'Ġ,', 'Ġupdates', '_', 'que', 'ued', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnew', '_', 'states', '_', 'queue', 'Ġ)', 'Ġ,', 'Ġread', '_', 'delay', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġread', '_', 'delay', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (050): ['draw', 'ing', '_', 'tool', 'Ġ.', 'Ġset', '_', 'window', '_', 'title', 'Ġ(', 'Ġupdate', '_', 'not', 'ifier', 'Ġ,', 'Ġwatching', '_', 'player', 'Ġ=', 'Ġtwitch', '_', 'username', 'Ġ,', 'Ġupdates', '_', 'que', 'ued', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnew', '_', 'states', '_', 'queue', 'Ġ)', 'Ġ,', 'Ġread', '_', 'delay', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġread', '_', 'delay', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['drawing_tool', 'Ġ.', 'Ġset_window_title', 'Ġ(', 'Ġupdate_notifier', 'Ġ,', 'Ġwatching_player', 'Ġ=', 'Ġtwitch_username', 'Ġ,', 'Ġupdates_queued', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnew_states_queue', 'Ġ)', 'Ġ,', 'Ġread_delay', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġread_delay', 'Ġ)', 'Ġ\\n']
Counter: 50
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "put_url = opt . trackerserver_url + "/tracker/api/update/" + opt . trackerserver_authkey \n"
Original    (012): ['put_url', '=', 'opt', '.', 'trackerserver_url', '+', '"/tracker/api/update/"', '+', 'opt', '.', 'trackerserver_authkey', '\\n']
Tokenized   (033): ['<s>', 'put', '_', 'url', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'url', 'Ġ+', 'Ġ"/', 'tr', 'acker', '/', 'api', '/', 'update', '/"', 'Ġ+', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'auth', 'key', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['put', '_', 'url', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'url', 'Ġ+', 'Ġ"/', 'tr', 'acker', '/', 'api', '/', 'update', '/"', 'Ġ+', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'auth', 'key', 'Ġ\\', 'n']
Detokenized (012): ['put_url', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġtrackerserver_url', 'Ġ+', 'Ġ"/tracker/api/update/"', 'Ġ+', 'Ġopt', 'Ġ.', 'Ġtrackerserver_authkey', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "json_string = json . dumps ( state , cls = TrackerStateEncoder , sort_keys = True ) \n"
Original    (017): ['json_string', '=', 'json', '.', 'dumps', '(', 'state', ',', 'cls', '=', 'TrackerStateEncoder', ',', 'sort_keys', '=', 'True', ')', '\\n']
Tokenized   (028): ['<s>', 'json', '_', 'string', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġstate', 'Ġ,', 'Ġcl', 's', 'Ġ=', 'ĠTracker', 'State', 'Enc', 'oder', 'Ġ,', 'Ġsort', '_', 'keys', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['json', '_', 'string', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġstate', 'Ġ,', 'Ġcl', 's', 'Ġ=', 'ĠTracker', 'State', 'Enc', 'oder', 'Ġ,', 'Ġsort', '_', 'keys', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['json_string', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġstate', 'Ġ,', 'Ġcls', 'Ġ=', 'ĠTrackerStateEncoder', 'Ġ,', 'Ġsort_keys', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "new_states_queue . pop ( 0 ) \n"
Original    (007): ['new_states_queue', '.', 'pop', '(', '0', ')', '\\n']
Tokenized   (014): ['<s>', 'new', '_', 'states', '_', 'queue', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['new', '_', 'states', '_', 'queue', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['new_states_queue', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "framecount += 1 \n"
Original    (004): ['framecount', '+=', '1', '\\n']
Tokenized   (008): ['<s>', 'frame', 'count', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['frame', 'count', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n']
Detokenized (004): ['framecount', 'Ġ+=', 'Ġ1', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "decay = decay , \n"
Original    (005): ['decay', '=', 'decay', ',', '\\n']
Tokenized   (009): ['<s>', 'dec', 'ay', 'Ġ=', 'Ġdecay', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['dec', 'ay', 'Ġ=', 'Ġdecay', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['decay', 'Ġ=', 'Ġdecay', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "expected_kwargs = { , } \n"
Original    (006): ['expected_kwargs', '=', '{', ',', '}', '\\n']
Tokenized   (012): ['<s>', 'expected', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['expected', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n']
Detokenized (006): ['expected_kwargs', 'Ġ=', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "outputs [ ] = in_shapes [ ] \n"
Original    (008): ['outputs', '[', ']', '=', 'in_shapes', '[', ']', '\\n']
Tokenized   (015): ['<s>', 'output', 's', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['output', 's', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['outputs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġin_shapes', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "buf = BufferStructure ( self . in_shapes [ ] . feature_shape [ - 1 ] ) \n"
Original    (017): ['buf', '=', 'BufferStructure', '(', 'self', '.', 'in_shapes', '[', ']', '.', 'feature_shape', '[', '-', '1', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'buf', 'Ġ=', 'ĠBuffer', 'St', 'ructure', 'Ġ(', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġfeature', '_', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['buf', 'Ġ=', 'ĠBuffer', 'St', 'ructure', 'Ġ(', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġfeature', '_', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['buf', 'Ġ=', 'ĠBufferStructure', 'Ġ(', 'Ġself', 'Ġ.', 'Ġin_shapes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġfeature_shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "internals [ ] = self . in_shapes [ ] \n"
Original    (010): ['internals', '[', ']', '=', 'self', '.', 'in_shapes', '[', ']', '\\n']
Tokenized   (017): ['<s>', 'intern', 'als', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['intern', 'als', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['internals', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġin_shapes', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sigma_b , centered , x_hat = buffers . internals \n"
Original    (010): ['sigma_b', ',', 'centered', ',', 'x_hat', '=', 'buffers', '.', 'internals', '\\n']
Tokenized   (019): ['<s>', 's', 'igma', '_', 'b', 'Ġ,', 'Ġcentered', 'Ġ,', 'Ġx', '_', 'hat', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġintern', 'als', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['s', 'igma', '_', 'b', 'Ġ,', 'Ġcentered', 'Ġ,', 'Ġx', '_', 'hat', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġintern', 'als', 'Ġ\\', 'n']
Detokenized (010): ['sigma_b', 'Ġ,', 'Ġcentered', 'Ġ,', 'Ġx_hat', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġinternals', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "dgamma = buffers . gradients . gamma \n"
Original    (008): ['dgamma', '=', 'buffers', '.', 'gradients', '.', 'gamma', '\\n']
Tokenized   (014): ['<s>', 'd', 'gam', 'ma', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġgrad', 'ients', 'Ġ.', 'Ġgamma', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['d', 'gam', 'ma', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġgrad', 'ients', 'Ġ.', 'Ġgamma', 'Ġ\\', 'n']
Detokenized (008): ['dgamma', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġgradients', 'Ġ.', 'Ġgamma', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "outdeltas = flatten_all_but_last ( buffers . output_deltas . default ) \n"
Original    (011): ['outdeltas', '=', 'flatten_all_but_last', '(', 'buffers', '.', 'output_deltas', '.', 'default', ')', '\\n']
Tokenized   (028): ['<s>', 'out', 'd', 'elt', 'as', 'Ġ=', 'Ġflatt', 'en', '_', 'all', '_', 'but', '_', 'last', 'Ġ(', 'Ġbuffers', 'Ġ.', 'Ġoutput', '_', 'd', 'elt', 'as', 'Ġ.', 'Ġdefault', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['out', 'd', 'elt', 'as', 'Ġ=', 'Ġflatt', 'en', '_', 'all', '_', 'but', '_', 'last', 'Ġ(', 'Ġbuffers', 'Ġ.', 'Ġoutput', '_', 'd', 'elt', 'as', 'Ġ.', 'Ġdefault', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['outdeltas', 'Ġ=', 'Ġflatten_all_but_last', 'Ġ(', 'Ġbuffers', 'Ġ.', 'Ġoutput_deltas', 'Ġ.', 'Ġdefault', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_h . add_tt ( term4 , indeltas , indeltas ) \n"
Original    (011): ['_h', '.', 'add_tt', '(', 'term4', ',', 'indeltas', ',', 'indeltas', ')', '\\n']
Tokenized   (022): ['<s>', '_', 'h', 'Ġ.', 'Ġadd', '_', 'tt', 'Ġ(', 'Ġterm', '4', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'h', 'Ġ.', 'Ġadd', '_', 'tt', 'Ġ(', 'Ġterm', '4', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_h', 'Ġ.', 'Ġadd_tt', 'Ġ(', 'Ġterm4', 'Ġ,', 'Ġindeltas', 'Ġ,', 'Ġindeltas', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "targets_name = , mask_name = ) : \n"
Original    (008): ['targets_name', '=', ',', 'mask_name', '=', ')', ':', '\\n']
Tokenized   (017): ['<s>', 't', 'arg', 'ets', '_', 'name', 'Ġ=', 'Ġ,', 'Ġmask', '_', 'name', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['t', 'arg', 'ets', '_', 'name', 'Ġ=', 'Ġ,', 'Ġmask', '_', 'name', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['targets_name', 'Ġ=', 'Ġ,', 'Ġmask_name', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mask_name = , name = None ) : \n"
Original    (009): ['mask_name', '=', ',', 'name', '=', 'None', ')', ':', '\\n']
Tokenized   (014): ['<s>', 'mask', '_', 'name', 'Ġ=', 'Ġ,', 'Ġname', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['mask', '_', 'name', 'Ġ=', 'Ġ,', 'Ġname', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (009): ['mask_name', 'Ġ=', 'Ġ,', 'Ġname', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "true_labels ) . astype ( np . float ) \n"
Original    (010): ['true_labels', ')', '.', 'astype', '(', 'np', '.', 'float', ')', '\\n']
Tokenized   (017): ['<s>', 'true', '_', 'lab', 'els', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['true', '_', 'lab', 'els', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['true_labels', 'Ġ)', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "epochs = [ 0 ] * 4 + [ 1 ] * 4 + [ 2 ] * 4 \n"
Original    (020): ['epochs', '=', '[', '0', ']', '*', '4', '+', '[', '1', ']', '*', '4', '+', '[', '2', ']', '*', '4', '\\n']
Tokenized   (025): ['<s>', 'ep', 'och', 's', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['ep', 'och', 's', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ\\', 'n']
Detokenized (020): ['epochs', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "on_rtd = os . environ . get ( , None ) == \n"
Original    (013): ['on_rtd', '=', 'os', '.', 'environ', '.', 'get', '(', ',', 'None', ')', '==', '\\n']
Tokenized   (020): ['<s>', 'on', '_', 'r', 'td', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ==', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['on', '_', 'r', 'td', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ==', 'Ġ\\', 'n']
Detokenized (013): ['on_rtd', 'Ġ=', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ==', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "html_theme_path = [ sphinx_rtd_theme . get_html_theme_path ( ) ] \n"
Original    (010): ['html_theme_path', '=', '[', 'sphinx_rtd_theme', '.', 'get_html_theme_path', '(', ')', ']', '\\n']
Tokenized   (030): ['<s>', 'html', '_', 'theme', '_', 'path', 'Ġ=', 'Ġ[', 'Ġsp', 'hin', 'x', '_', 'r', 'td', '_', 'theme', 'Ġ.', 'Ġget', '_', 'html', '_', 'theme', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['html', '_', 'theme', '_', 'path', 'Ġ=', 'Ġ[', 'Ġsp', 'hin', 'x', '_', 'r', 'td', '_', 'theme', 'Ġ.', 'Ġget', '_', 'html', '_', 'theme', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['html_theme_path', 'Ġ=', 'Ġ[', 'Ġsphinx_rtd_theme', 'Ġ.', 'Ġget_html_theme_path', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "latex_elements = { \n"
Original    (004): ['latex_elements', '=', '{', '\\n']
Tokenized   (011): ['<s>', 'late', 'x', '_', 'e', 'lements', 'Ġ=', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['late', 'x', '_', 'e', 'lements', 'Ġ=', 'Ġ{', 'Ġ\\', 'n']
Detokenized (004): ['latex_elements', 'Ġ=', 'Ġ{', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "latex_documents = [ \n"
Original    (004): ['latex_documents', '=', '[', '\\n']
Tokenized   (011): ['<s>', 'late', 'x', '_', 'doc', 'uments', 'Ġ=', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['late', 'x', '_', 'doc', 'uments', 'Ġ=', 'Ġ[', 'Ġ\\', 'n']
Detokenized (004): ['latex_documents', 'Ġ=', 'Ġ[', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "ignored_fallbacks = ( ) ) : \n"
Original    (007): ['ignored_fallbacks', '=', '(', ')', ')', ':', '\\n']
Tokenized   (014): ['<s>', 'ign', 'ored', '_', 'fall', 'backs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['ign', 'ored', '_', 'fall', 'backs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (007): ['ignored_fallbacks', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""b" : 2.0 , \n"
Original    (005): ['"b"', ':', '2.0', ',', '\\n']
Tokenized   (012): ['<s>', '"', 'b', '"', 'Ġ:', 'Ġ2', '.', '0', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['"', 'b', '"', 'Ġ:', 'Ġ2', '.', '0', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"b"', 'Ġ:', 'Ġ2.0', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""c" : True , \n"
Original    (005): ['"c"', ':', 'True', ',', '\\n']
Tokenized   (010): ['<s>', '"', 'c', '"', 'Ġ:', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'c', '"', 'Ġ:', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"c"', 'Ġ:', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""d" : , \n"
Original    (004): ['"d"', ':', ',', '\\n']
Tokenized   (009): ['<s>', '"', 'd', '"', 'Ġ:', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'd', '"', 'Ġ:', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['"d"', 'Ġ:', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""e" : [ 1 , 2 , 3 ] , \n"
Original    (011): ['"e"', ':', '[', '1', ',', '2', ',', '3', ']', ',', '\\n']
Tokenized   (016): ['<s>', '"', 'e', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['"', 'e', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"e"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""f" : { : , : } , \n"
Original    (009): ['"f"', ':', '{', ':', ',', ':', '}', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'f', '"', 'Ġ:', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'f', '"', 'Ġ:', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"f"', 'Ġ:', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""answer" : 42 \n"
Original    (004): ['"answer"', ':', '42', '\\n']
Tokenized   (009): ['<s>', '"', 'answer', '"', 'Ġ:', 'Ġ42', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'answer', '"', 'Ġ:', 'Ġ42', 'Ġ\\', 'n']
Detokenized (004): ['"answer"', 'Ġ:', 'Ġ42', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "p_error = self . kp * current_error \n"
Original    (008): ['p_error', '=', 'self', '.', 'kp', '*', 'current_error', '\\n']
Tokenized   (016): ['<s>', 'p', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'p', 'Ġ*', 'Ġcurrent', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['p', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'p', 'Ġ*', 'Ġcurrent', '_', 'error', 'Ġ\\', 'n']
Detokenized (008): ['p_error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġkp', 'Ġ*', 'Ġcurrent_error', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "d_error = self . kd * ( current_error - self . previous_error ) / timestep \n"
Original    (016): ['d_error', '=', 'self', '.', 'kd', '*', '(', 'current_error', '-', 'self', '.', 'previous_error', ')', '/', 'timestep', '\\n']
Tokenized   (028): ['<s>', 'd', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'd', 'Ġ*', 'Ġ(', 'Ġcurrent', '_', 'error', 'Ġ-', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġtim', 'est', 'ep', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['d', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'd', 'Ġ*', 'Ġ(', 'Ġcurrent', '_', 'error', 'Ġ-', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġtim', 'est', 'ep', 'Ġ\\', 'n']
Detokenized (016): ['d_error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġkd', 'Ġ*', 'Ġ(', 'Ġcurrent_error', 'Ġ-', 'Ġself', 'Ġ.', 'Ġprevious_error', 'Ġ)', 'Ġ/', 'Ġtimestep', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "current_error + self . previous_error ) / 2 + self . integral_error \n"
Original    (013): ['current_error', '+', 'self', '.', 'previous_error', ')', '/', '2', '+', 'self', '.', 'integral_error', '\\n']
Tokenized   (022): ['<s>', 'current', '_', 'error', 'Ġ+', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġ2', 'Ġ+', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['current', '_', 'error', 'Ġ+', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġ2', 'Ġ+', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n']
Detokenized (013): ['current_error', 'Ġ+', 'Ġself', 'Ġ.', 'Ġprevious_error', 'Ġ)', 'Ġ/', 'Ġ2', 'Ġ+', 'Ġself', 'Ġ.', 'Ġintegral_error', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "i_error = self . ki * self . integral_error \n"
Original    (010): ['i_error', '=', 'self', '.', 'ki', '*', 'self', '.', 'integral_error', '\\n']
Tokenized   (017): ['<s>', 'i', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġki', 'Ġ*', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['i', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġki', 'Ġ*', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n']
Detokenized (010): ['i_error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġki', 'Ġ*', 'Ġself', 'Ġ.', 'Ġintegral_error', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "total_error = p_error + d_error + i_error \n"
Original    (008): ['total_error', '=', 'p_error', '+', 'd_error', '+', 'i_error', '\\n']
Tokenized   (019): ['<s>', 'total', '_', 'error', 'Ġ=', 'Ġp', '_', 'error', 'Ġ+', 'Ġd', '_', 'error', 'Ġ+', 'Ġi', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['total', '_', 'error', 'Ġ=', 'Ġp', '_', 'error', 'Ġ+', 'Ġd', '_', 'error', 'Ġ+', 'Ġi', '_', 'error', 'Ġ\\', 'n']
Detokenized (008): ['total_error', 'Ġ=', 'Ġp_error', 'Ġ+', 'Ġd_error', 'Ġ+', 'Ġi_error', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "cmd_match_names = cmd . Cmd . completenames ( self , text , * ignored ) \n"
Original    (016): ['cmd_match_names', '=', 'cmd', '.', 'Cmd', '.', 'completenames', '(', 'self', ',', 'text', ',', '*', 'ignored', ')', '\\n']
Tokenized   (026): ['<s>', 'cmd', '_', 'match', '_', 'names', 'Ġ=', 'Ġcmd', 'Ġ.', 'ĠC', 'md', 'Ġ.', 'Ġcomple', 'ten', 'ames', 'Ġ(', 'Ġself', 'Ġ,', 'Ġtext', 'Ġ,', 'Ġ*', 'Ġignored', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['cmd', '_', 'match', '_', 'names', 'Ġ=', 'Ġcmd', 'Ġ.', 'ĠC', 'md', 'Ġ.', 'Ġcomple', 'ten', 'ames', 'Ġ(', 'Ġself', 'Ġ,', 'Ġtext', 'Ġ,', 'Ġ*', 'Ġignored', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['cmd_match_names', 'Ġ=', 'Ġcmd', 'Ġ.', 'ĠCmd', 'Ġ.', 'Ġcompletenames', 'Ġ(', 'Ġself', 'Ġ,', 'Ġtext', 'Ġ,', 'Ġ*', 'Ġignored', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "obj_names = self . ctrl_client . objects . keys ( ) \n"
Original    (012): ['obj_names', '=', 'self', '.', 'ctrl_client', '.', 'objects', '.', 'keys', '(', ')', '\\n']
Tokenized   (020): ['<s>', 'obj', '_', 'names', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['obj', '_', 'names', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['obj_names', 'Ġ=', 'Ġself', 'Ġ.', 'Ġctrl_client', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "api_match_names = [ x for x in obj_names if x . startswith ( text ) ] \n"
Original    (017): ['api_match_names', '=', '[', 'x', 'for', 'x', 'in', 'obj_names', 'if', 'x', '.', 'startswith', '(', 'text', ')', ']', '\\n']
Tokenized   (028): ['<s>', 'api', '_', 'match', '_', 'names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġobj', '_', 'names', 'Ġif', 'Ġx', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['api', '_', 'match', '_', 'names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġobj', '_', 'names', 'Ġif', 'Ġx', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['api_match_names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġobj_names', 'Ġif', 'Ġx', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "reply_time = self . ctrl_client . ping ( ) \n"
Original    (010): ['reply_time', '=', 'self', '.', 'ctrl_client', '.', 'ping', '(', ')', '\\n']
Tokenized   (018): ['<s>', 'reply', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġping', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['reply', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġping', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['reply_time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġctrl_client', 'Ġ.', 'Ġping', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sub_addr = sys . argv [ 2 ] \n"
Original    (009): ['sub_addr', '=', 'sys', '.', 'argv', '[', '2', ']', '\\n']
Tokenized   (015): ['<s>', 'sub', '_', 'addr', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['sub', '_', 'addr', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['sub_addr', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "CLI ( ctrl_addr , sub_addr ) . cmdloop ( ) \n"
Original    (011): ['CLI', '(', 'ctrl_addr', ',', 'sub_addr', ')', '.', 'cmdloop', '(', ')', '\\n']
Tokenized   (021): ['<s>', 'CL', 'I', 'Ġ(', 'Ġc', 'trl', '_', 'addr', 'Ġ,', 'Ġsub', '_', 'addr', 'Ġ)', 'Ġ.', 'Ġcmd', 'loop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['CL', 'I', 'Ġ(', 'Ġc', 'trl', '_', 'addr', 'Ġ,', 'Ġsub', '_', 'addr', 'Ġ)', 'Ġ.', 'Ġcmd', 'loop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['CLI', 'Ġ(', 'Ġctrl_addr', 'Ġ,', 'Ġsub_addr', 'Ġ)', 'Ġ.', 'Ġcmdloop', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "duty = int ( cur_pwm [ "duty_ns" ] ) \n"
Original    (010): ['duty', '=', 'int', '(', 'cur_pwm', '[', '"duty_ns"', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'duty', 'Ġ=', 'Ġint', 'Ġ(', 'Ġcur', '_', 'p', 'wm', 'Ġ[', 'Ġ"', 'duty', '_', 'ns', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['duty', 'Ġ=', 'Ġint', 'Ġ(', 'Ġcur', '_', 'p', 'wm', 'Ġ[', 'Ġ"', 'duty', '_', 'ns', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['duty', 'Ġ=', 'Ġint', 'Ġ(', 'Ġcur_pwm', 'Ġ[', 'Ġ"duty_ns"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "read_pos = int ( round ( ( ( duty - 580000 ) / 2320000. ) * 180 ) ) \n"
Original    (020): ['read_pos', '=', 'int', '(', 'round', '(', '(', '(', 'duty', '-', '580000', ')', '/', '2320000.', ')', '*', '180', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'read', '_', 'pos', 'Ġ=', 'Ġint', 'Ġ(', 'Ġround', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġduty', 'Ġ-', 'Ġ58', '0000', 'Ġ)', 'Ġ/', 'Ġ23', '200', '00', '.', 'Ġ)', 'Ġ*', 'Ġ180', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['read', '_', 'pos', 'Ġ=', 'Ġint', 'Ġ(', 'Ġround', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġduty', 'Ġ-', 'Ġ58', '0000', 'Ġ)', 'Ġ/', 'Ġ23', '200', '00', '.', 'Ġ)', 'Ġ*', 'Ġ180', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['read_pos', 'Ġ=', 'Ġint', 'Ġ(', 'Ġround', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġduty', 'Ġ-', 'Ġ580000', 'Ġ)', 'Ġ/', 'Ġ2320000.', 'Ġ)', 'Ġ*', 'Ġ180', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "create_login_url , create_logout_url \n"
Original    (004): ['create_login_url', ',', 'create_logout_url', '\\n']
Tokenized   (016): ['<s>', 'create', '_', 'login', '_', 'url', 'Ġ,', 'Ġcreate', '_', 'log', 'out', '_', 'url', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['create', '_', 'login', '_', 'url', 'Ġ,', 'Ġcreate', '_', 'log', 'out', '_', 'url', 'Ġ\\', 'n']
Detokenized (004): ['create_login_url', 'Ġ,', 'Ġcreate_logout_url', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "create_logout_url ( request . url ) \n"
Original    (007): ['create_logout_url', '(', 'request', '.', 'url', ')', '\\n']
Tokenized   (015): ['<s>', 'create', '_', 'log', 'out', '_', 'url', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġurl', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['create', '_', 'log', 'out', '_', 'url', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġurl', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['create_logout_url', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġurl', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_value = _options_header_vkw ( _value , kw ) \n"
Original    (009): ['_value', '=', '_options_header_vkw', '(', '_value', ',', 'kw', ')', '\\n']
Tokenized   (021): ['<s>', '_', 'value', 'Ġ=', 'Ġ_', 'options', '_', 'header', '_', 'v', 'kw', 'Ġ(', 'Ġ_', 'value', 'Ġ,', 'Ġk', 'w', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['_', 'value', 'Ġ=', 'Ġ_', 'options', '_', 'header', '_', 'v', 'kw', 'Ġ(', 'Ġ_', 'value', 'Ġ,', 'Ġk', 'w', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['_value', 'Ġ=', 'Ġ_options_header_vkw', 'Ġ(', 'Ġ_value', 'Ġ,', 'Ġkw', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "value_type == value_subtype == ) or \n"
Original    (007): ['value_type', '==', 'value_subtype', '==', ')', 'or', '\\n']
Tokenized   (015): ['<s>', 'value', '_', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ==', 'Ġ)', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['value', '_', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ==', 'Ġ)', 'Ġor', 'Ġ\\', 'n']
Detokenized (007): ['value_type', 'Ġ==', 'Ġvalue_subtype', 'Ġ==', 'Ġ)', 'Ġor', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "value_subtype == or \n"
Original    (004): ['value_subtype', '==', 'or', '\\n']
Tokenized   (010): ['<s>', 'value', '_', 'sub', 'type', 'Ġ==', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['value', '_', 'sub', 'type', 'Ġ==', 'Ġor', 'Ġ\\', 'n']
Detokenized (004): ['value_subtype', 'Ġ==', 'Ġor', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "item_subtype == value_subtype ) ) \n"
Original    (006): ['item_subtype', '==', 'value_subtype', ')', ')', '\\n']
Tokenized   (015): ['<s>', 'item', '_', 'sub', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['item', '_', 'sub', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['item_subtype', 'Ġ==', 'Ġvalue_subtype', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "no_cache = cache_property ( , , None ) \n"
Original    (009): ['no_cache', '=', 'cache_property', '(', ',', ',', 'None', ')', '\\n']
Tokenized   (016): ['<s>', 'no', '_', 'cache', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['no', '_', 'cache', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['no_cache', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "no_store = cache_property ( , None , bool ) \n"
Original    (010): ['no_store', '=', 'cache_property', '(', ',', 'None', ',', 'bool', ')', '\\n']
Tokenized   (017): ['<s>', 'no', '_', 'store', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['no', '_', 'store', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['no_store', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "max_age = cache_property ( , - 1 , int ) \n"
Original    (011): ['max_age', '=', 'cache_property', '(', ',', '-', '1', ',', 'int', ')', '\\n']
Tokenized   (018): ['<s>', 'max', '_', 'age', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['max', '_', 'age', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['max_age', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "no_transform = cache_property ( , None , None ) \n"
Original    (010): ['no_transform', '=', 'cache_property', '(', ',', 'None', ',', 'None', ')', '\\n']
Tokenized   (017): ['<s>', 'no', '_', 'transform', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['no', '_', 'transform', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['no_transform', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "max_stale = cache_property ( , , int ) \n"
Original    (009): ['max_stale', '=', 'cache_property', '(', ',', ',', 'int', ')', '\\n']
Tokenized   (017): ['<s>', 'max', '_', 'st', 'ale', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['max', '_', 'st', 'ale', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['max_stale', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "etag , weak = unquote_etag ( etag ) \n"
Original    (009): ['etag', ',', 'weak', '=', 'unquote_etag', '(', 'etag', ')', '\\n']
Tokenized   (018): ['<s>', 'et', 'ag', 'Ġ,', 'Ġweak', 'Ġ=', 'Ġun', 'quote', '_', 'et', 'ag', 'Ġ(', 'Ġet', 'ag', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['et', 'ag', 'Ġ,', 'Ġweak', 'Ġ=', 'Ġun', 'quote', '_', 'et', 'ag', 'Ġ(', 'Ġet', 'ag', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['etag', 'Ġ,', 'Ġweak', 'Ġ=', 'Ġunquote_etag', 'Ġ(', 'Ġetag', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "uri = property ( lambda x : x . get ( ) , doc = ) \n"
Original    (017): ['uri', '=', 'property', '(', 'lambda', 'x', ':', 'x', '.', 'get', '(', ')', ',', 'doc', '=', ')', '\\n']
Tokenized   (020): ['<s>', 'uri', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['uri', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['uri', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "_require_quoting = frozenset ( [ , , , ] ) \n"
Original    (011): ['_require_quoting', '=', 'frozenset', '(', '[', ',', ',', ',', ']', ')', '\\n']
Tokenized   (020): ['<s>', '_', 'require', '_', 'qu', 'oting', 'Ġ=', 'Ġfro', 'zens', 'et', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['_', 'require', '_', 'qu', 'oting', 'Ġ=', 'Ġfro', 'zens', 'et', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_require_quoting', 'Ġ=', 'Ġfrozenset', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "auth_type = d . pop ( , None ) or \n"
Original    (011): ['auth_type', '=', 'd', '.', 'pop', '(', ',', 'None', ')', 'or', '\\n']
Tokenized   (016): ['<s>', 'auth', '_', 'type', 'Ġ=', 'Ġd', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['auth', '_', 'type', 'Ġ=', 'Ġd', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġor', 'Ġ\\', 'n']
Detokenized (011): ['auth_type', 'Ġ=', 'Ġd', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġor', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "allow_token = key not in self . _require_quoting ) ) \n"
Original    (011): ['allow_token', '=', 'key', 'not', 'in', 'self', '.', '_require_quoting', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'allow', '_', 'token', 'Ġ=', 'Ġkey', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġ_', 'require', '_', 'qu', 'oting', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['allow', '_', 'token', 'Ġ=', 'Ġkey', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġ_', 'require', '_', 'qu', 'oting', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['allow_token', 'Ġ=', 'Ġkey', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġ_require_quoting', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "realm = auth_property ( , doc = ) \n"
Original    (009): ['realm', '=', 'auth_property', '(', ',', 'doc', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'real', 'm', 'Ġ=', 'Ġauth', '_', 'property', 'Ġ(', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['real', 'm', 'Ġ=', 'Ġauth', '_', 'property', 'Ġ(', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['realm', 'Ġ=', 'Ġauth_property', 'Ġ(', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rshell , shell , clear_datastore , create_user , \n"
Original    (009): ['rshell', ',', 'shell', ',', 'clear_datastore', ',', 'create_user', ',', '\\n']
Tokenized   (019): ['<s>', 'rs', 'hell', 'Ġ,', 'Ġshell', 'Ġ,', 'Ġclear', '_', 'dat', 'ast', 'ore', 'Ġ,', 'Ġcreate', '_', 'user', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rs', 'hell', 'Ġ,', 'Ġshell', 'Ġ,', 'Ġclear', '_', 'dat', 'ast', 'ore', 'Ġ,', 'Ġcreate', '_', 'user', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['rshell', 'Ġ,', 'Ġshell', 'Ġ,', 'Ġclear_datastore', 'Ġ,', 'Ġcreate_user', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "Rule ( , endpoint = , \n"
Original    (007): ['Rule', '(', ',', 'endpoint', '=', ',', '\\n']
Tokenized   (010): ['<s>', 'Rule', 'Ġ(', 'Ġ,', 'Ġendpoint', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Rule', 'Ġ(', 'Ġ,', 'Ġendpoint', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['Rule', 'Ġ(', 'Ġ,', 'Ġendpoint', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "data_field = db . StringProperty ( required = True , \n"
Original    (011): ['data_field', '=', 'db', '.', 'StringProperty', '(', 'required', '=', 'True', ',', '\\n']
Tokenized   (017): ['<s>', 'data', '_', 'field', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠString', 'Property', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['data', '_', 'field', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠString', 'Property', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['data_field', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠStringProperty', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dst_name = path . join ( dst_path , filename ) \n"
Original    (011): ['dst_name', '=', 'path', '.', 'join', '(', 'dst_path', ',', 'filename', ')', '\\n']
Tokenized   (019): ['<s>', 'd', 'st', '_', 'name', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdst', '_', 'path', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['d', 'st', '_', 'name', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdst', '_', 'path', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['dst_name', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdst_path', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "modifiable_problem_fields = [ "description" ] \n"
Original    (006): ['modifiable_problem_fields', '=', '[', '"description"', ']', '\\n']
Tokenized   (016): ['<s>', 'mod', 'ifiable', '_', 'problem', '_', 'fields', 'Ġ=', 'Ġ[', 'Ġ"', 'description', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['mod', 'ifiable', '_', 'problem', '_', 'fields', 'Ġ=', 'Ġ[', 'Ġ"', 'description', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['modifiable_problem_fields', 'Ġ=', 'Ġ[', 'Ġ"description"', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "problem = api . problem . get_problem ( pid = pid ) \n"
Original    (013): ['problem', '=', 'api', '.', 'problem', '.', 'get_problem', '(', 'pid', '=', 'pid', ')', '\\n']
Tokenized   (018): ['<s>', 'problem', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġproblem', 'Ġ.', 'Ġget', '_', 'problem', 'Ġ(', 'Ġpid', 'Ġ=', 'Ġpid', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['problem', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġproblem', 'Ġ.', 'Ġget', '_', 'problem', 'Ġ(', 'Ġpid', 'Ġ=', 'Ġpid', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['problem', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġproblem', 'Ġ.', 'Ġget_problem', 'Ġ(', 'Ġpid', 'Ġ=', 'Ġpid', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "build = get_generator ( pid ) . generate ( random , pid , api . autogen_tools , n ) \n"
Original    (020): ['build', '=', 'get_generator', '(', 'pid', ')', '.', 'generate', '(', 'random', ',', 'pid', ',', 'api', '.', 'autogen_tools', ',', 'n', ')', '\\n']
Tokenized   (029): ['<s>', 'build', 'Ġ=', 'Ġget', '_', 'gener', 'ator', 'Ġ(', 'Ġpid', 'Ġ)', 'Ġ.', 'Ġgenerate', 'Ġ(', 'Ġrandom', 'Ġ,', 'Ġpid', 'Ġ,', 'Ġapi', 'Ġ.', 'Ġaut', 'ogen', '_', 'tools', 'Ġ,', 'Ġn', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['build', 'Ġ=', 'Ġget', '_', 'gener', 'ator', 'Ġ(', 'Ġpid', 'Ġ)', 'Ġ.', 'Ġgenerate', 'Ġ(', 'Ġrandom', 'Ġ,', 'Ġpid', 'Ġ,', 'Ġapi', 'Ġ.', 'Ġaut', 'ogen', '_', 'tools', 'Ġ,', 'Ġn', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['build', 'Ġ=', 'Ġget_generator', 'Ġ(', 'Ġpid', 'Ġ)', 'Ġ.', 'Ġgenerate', 'Ġ(', 'Ġrandom', 'Ġ,', 'Ġpid', 'Ġ,', 'Ġapi', 'Ġ.', 'Ġautogen_tools', 'Ġ,', 'Ġn', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "autogen_instance_path = get_instance_path ( pid , n = n ) \n"
Original    (011): ['autogen_instance_path', '=', 'get_instance_path', '(', 'pid', ',', 'n', '=', 'n', ')', '\\n']
Tokenized   (023): ['<s>', 'aut', 'ogen', '_', 'instance', '_', 'path', 'Ġ=', 'Ġget', '_', 'instance', '_', 'path', 'Ġ(', 'Ġpid', 'Ġ,', 'Ġn', 'Ġ=', 'Ġn', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['aut', 'ogen', '_', 'instance', '_', 'path', 'Ġ=', 'Ġget', '_', 'instance', '_', 'path', 'Ġ(', 'Ġpid', 'Ġ,', 'Ġn', 'Ġ=', 'Ġn', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['autogen_instance_path', 'Ġ=', 'Ġget_instance_path', 'Ġ(', 'Ġpid', 'Ġ,', 'Ġn', 'Ġ=', 'Ġn', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""resource_files" : { \n"
Original    (004): ['"resource_files"', ':', '{', '\\n']
Tokenized   (011): ['<s>', '"', 'resource', '_', 'files', '"', 'Ġ:', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['"', 'resource', '_', 'files', '"', 'Ġ:', 'Ġ{', 'Ġ\\', 'n']
Detokenized (004): ['"resource_files"', 'Ġ:', 'Ġ{', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "instance_path = path . join ( path . dirname ( generator_path ) , "instances" , name , str ( n ) ) \n"
Original    (023): ['instance_path', '=', 'path', '.', 'join', '(', 'path', '.', 'dirname', '(', 'generator_path', ')', ',', '"instances"', ',', 'name', ',', 'str', '(', 'n', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'instance', '_', 'path', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġgenerator', '_', 'path', 'Ġ)', 'Ġ,', 'Ġ"', 'inst', 'ances', '"', 'Ġ,', 'Ġname', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġn', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['instance', '_', 'path', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġgenerator', '_', 'path', 'Ġ)', 'Ġ,', 'Ġ"', 'inst', 'ances', '"', 'Ġ,', 'Ġname', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġn', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['instance_path', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġgenerator_path', 'Ġ)', 'Ġ,', 'Ġ"instances"', 'Ġ,', 'Ġname', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġn', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : ""correct" : correct , \n"
Original    (005): ['"correct"', ':', 'correct', ',', '\\n']
Tokenized   (010): ['<s>', '"', 'correct', '"', 'Ġ:', 'Ġcorrect', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'correct', '"', 'Ġ:', 'Ġcorrect', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"correct"', 'Ġ:', 'Ġcorrect', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""points" : problem [ "score" ] , \n"
Original    (008): ['"points"', ':', 'problem', '[', '"score"', ']', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'points', '"', 'Ġ:', 'Ġproblem', 'Ġ[', 'Ġ"', 'score', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'points', '"', 'Ġ:', 'Ġproblem', 'Ġ[', 'Ġ"', 'score', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['"points"', 'Ġ:', 'Ġproblem', 'Ġ[', 'Ġ"score"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""message" : message \n"
Original    (004): ['"message"', ':', 'message', '\\n']
Tokenized   (009): ['<s>', '"', 'message', '"', 'Ġ:', 'Ġmessage', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'message', '"', 'Ġ:', 'Ġmessage', 'Ġ\\', 'n']
Detokenized (004): ['"message"', 'Ġ:', 'Ġmessage', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "k = str ( random . randint ( 0 , 1000 ) ) \n"
Original    (014): ['k', '=', 'str', '(', 'random', '.', 'randint', '(', '0', ',', '1000', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'k', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['k', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['k', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġrandom', 'Ġ.', 'Ġrandint', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1000', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""public" : [ ( "/tmp/key" , "public_static" ) ] , \n"
Original    (011): ['"public"', ':', '[', '(', '"/tmp/key"', ',', '"public_static"', ')', ']', ',', '\\n']
Tokenized   (024): ['<s>', '"', 'public', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'public', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'public', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'public', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"public"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/tmp/key"', 'Ġ,', 'Ġ"public_static"', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""private" : [ ( "/tmp/key" , "private_static" ) ] \n"
Original    (010): ['"private"', ':', '[', '(', '"/tmp/key"', ',', '"private_static"', ')', ']', '\\n']
Tokenized   (023): ['<s>', '"', 'private', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'private', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', 'private', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'private', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['"private"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/tmp/key"', 'Ġ,', 'Ġ"private_static"', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "layout = eval ( scriptWindow . setLayout ( layout ) \n"
Original    (011): ['layout', '=', 'eval', '(', 'scriptWindow', '.', 'setLayout', '(', 'layout', ')', '\\n']
Tokenized   (016): ['<s>', 'layout', 'Ġ=', 'Ġeval', 'Ġ(', 'Ġscript', 'Window', 'Ġ.', 'Ġset', 'Layout', 'Ġ(', 'Ġlayout', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['layout', 'Ġ=', 'Ġeval', 'Ġ(', 'Ġscript', 'Window', 'Ġ.', 'Ġset', 'Layout', 'Ġ(', 'Ġlayout', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['layout', 'Ġ=', 'Ġeval', 'Ġ(', 'ĠscriptWindow', 'Ġ.', 'ĠsetLayout', 'Ġ(', 'Ġlayout', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "scriptWindow . _Widget__qtWidget . resize ( 995 , 500 ) \n"
Original    (011): ['scriptWindow', '.', '_Widget__qtWidget', '.', 'resize', '(', '995', ',', '500', ')', '\\n']
Tokenized   (020): ['<s>', 'script', 'Window', 'Ġ.', 'Ġ_', 'Widget', '__', 'qt', 'Widget', 'Ġ.', 'Ġresize', 'Ġ(', 'Ġ9', '95', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['script', 'Window', 'Ġ.', 'Ġ_', 'Widget', '__', 'qt', 'Widget', 'Ġ.', 'Ġresize', 'Ġ(', 'Ġ9', '95', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['scriptWindow', 'Ġ.', 'Ġ_Widget__qtWidget', 'Ġ.', 'Ġresize', 'Ġ(', 'Ġ995', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""inputSequence" , \n"
Original    (003): ['"inputSequence"', ',', '\\n']
Tokenized   (010): ['<s>', '"', 'input', 'Sequ', 'ence', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'input', 'Sequ', 'ence', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (003): ['"inputSequence"', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "defaultValue = "" , \n"
Original    (005): ['defaultValue', '=', '""', ',', '\\n']
Tokenized   (009): ['<s>', 'default', 'Value', 'Ġ=', 'Ġ""', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['default', 'Value', 'Ġ=', 'Ġ""', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['defaultValue', 'Ġ=', 'Ġ""', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "dc . write ( "-" + objectName , "bound" , b ) \n"
Original    (013): ['dc', '.', 'write', '(', '"-"', '+', 'objectName', ',', '"bound"', ',', 'b', ')', '\\n']
Tokenized   (020): ['<s>', 'dc', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"', '-"', 'Ġ+', 'Ġobject', 'Name', 'Ġ,', 'Ġ"', 'bound', '"', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['dc', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"', '-"', 'Ġ+', 'Ġobject', 'Name', 'Ġ,', 'Ġ"', 'bound', '"', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['dc', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"-"', 'Ġ+', 'ĠobjectName', 'Ġ,', 'Ġ"bound"', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "additionalTerminalPlugTypes = ( GafferScene . ScenePlug , ) \n"
Original    (009): ['additionalTerminalPlugTypes', '=', '(', 'GafferScene', '.', 'ScenePlug', ',', ')', '\\n']
Tokenized   (020): ['<s>', 'add', 'itional', 'Termin', 'al', 'Plug', 'Types', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Ġ.', 'ĠScene', 'Plug', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['add', 'itional', 'Termin', 'al', 'Plug', 'Types', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Ġ.', 'ĠScene', 'Plug', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['additionalTerminalPlugTypes', 'Ġ=', 'Ġ(', 'ĠGafferScene', 'Ġ.', 'ĠScenePlug', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "replace = context . get ( "textWriter:replace" , IECore . StringVectorData ( ) ) \n"
Original    (015): ['replace', '=', 'context', '.', 'get', '(', '"textWriter:replace"', ',', 'IECore', '.', 'StringVectorData', '(', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'replace', 'Ġ=', 'Ġcontext', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'text', 'Writer', ':', 'replace', '"', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['replace', 'Ġ=', 'Ġcontext', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'text', 'Writer', ':', 'replace', '"', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['replace', 'Ġ=', 'Ġcontext', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"textWriter:replace"', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠStringVectorData', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "inMetadata = r [ "out" ] [ "metadata" ] . getValue ( ) \n"
Original    (014): ['inMetadata', '=', 'r', '[', '"out"', ']', '[', '"metadata"', ']', '.', 'getValue', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'in', 'Met', 'adata', 'Ġ=', 'Ġr', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'metadata', '"', 'Ġ]', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['in', 'Met', 'adata', 'Ġ=', 'Ġr', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'metadata', '"', 'Ġ]', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['inMetadata', 'Ġ=', 'Ġr', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ[', 'Ġ"metadata"', 'Ġ]', 'Ġ.', 'ĠgetValue', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "negFileName = os . path . expandvars ( "$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr" \n"
Original    (010): ['negFileName', '=', 'os', '.', 'path', '.', 'expandvars', '(', '"$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr"', '\\n']
Tokenized   (047): ['<s>', 'neg', 'File', 'Name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'v', 'ars', 'Ġ(', 'Ġ"$', 'GA', 'FFER', '_', 'RO', 'OT', '/', 'python', '/', 'G', 'affer', 'Image', 'Test', '/', 'images', '/', 'check', 'er', 'With', 'Neg', 'ative', 'Data', 'Window', '.', '200', 'x', '150', '.', 'ex', 'r', '"', 'Ġ\\', 'n', '</s>']
Filtered   (045): ['neg', 'File', 'Name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'v', 'ars', 'Ġ(', 'Ġ"$', 'GA', 'FFER', '_', 'RO', 'OT', '/', 'python', '/', 'G', 'affer', 'Image', 'Test', '/', 'images', '/', 'check', 'er', 'With', 'Neg', 'ative', 'Data', 'Window', '.', '200', 'x', '150', '.', 'ex', 'r', '"', 'Ġ\\', 'n']
Detokenized (010): ['negFileName', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpandvars', 'Ġ(', 'Ġ"$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr"', 'Ġ\\n']
Counter: 45
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "GafferImage . Display , \n"
Original    (005): ['GafferImage', '.', 'Display', ',', '\\n']
Tokenized   (010): ['<s>', 'G', 'affer', 'Image', 'Ġ.', 'ĠDisplay', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['G', 'affer', 'Image', 'Ġ.', 'ĠDisplay', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['GafferImage', 'Ġ.', 'ĠDisplay', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""port" : [ \n"
Original    (004): ['"port"', ':', '[', '\\n']
Tokenized   (009): ['<s>', '"', 'port', '"', 'Ġ:', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'port', '"', 'Ġ:', 'Ġ[', 'Ġ\\', 'n']
Detokenized (004): ['"port"', 'Ġ:', 'Ġ[', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "updateCountPlug . setValue ( updateCountPlug . getValue ( ) + 1 ) \n"
Original    (013): ['updateCountPlug', '.', 'setValue', '(', 'updateCountPlug', '.', 'getValue', '(', ')', '+', '1', ')', '\\n']
Tokenized   (022): ['<s>', 'update', 'Count', 'Plug', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġupdate', 'Count', 'Plug', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['update', 'Count', 'Plug', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġupdate', 'Count', 'Plug', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['updateCountPlug', 'Ġ.', 'ĠsetValue', 'Ġ(', 'ĠupdateCountPlug', 'Ġ.', 'ĠgetValue', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "__import__ ( "IECore" ) . loadConfig ( "GAFFER_STARTUP_PATHS" , { } , subdirectory = "GafferImageUI" ) \n"
Original    (017): ['__import__', '(', '"IECore"', ')', '.', 'loadConfig', '(', '"GAFFER_STARTUP_PATHS"', ',', '{', '}', ',', 'subdirectory', '=', '"GafferImageUI"', ')', '\\n']
Tokenized   (044): ['<s>', '__', 'import', '__', 'Ġ(', 'Ġ"', 'I', 'EC', 'ore', '"', 'Ġ)', 'Ġ.', 'Ġload', 'Config', 'Ġ(', 'Ġ"', 'GA', 'FFER', '_', 'ST', 'ART', 'UP', '_', 'P', 'AT', 'HS', '"', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġsub', 'directory', 'Ġ=', 'Ġ"', 'G', 'affer', 'Image', 'UI', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['__', 'import', '__', 'Ġ(', 'Ġ"', 'I', 'EC', 'ore', '"', 'Ġ)', 'Ġ.', 'Ġload', 'Config', 'Ġ(', 'Ġ"', 'GA', 'FFER', '_', 'ST', 'ART', 'UP', '_', 'P', 'AT', 'HS', '"', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġsub', 'directory', 'Ġ=', 'Ġ"', 'G', 'affer', 'Image', 'UI', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['__import__', 'Ġ(', 'Ġ"IECore"', 'Ġ)', 'Ġ.', 'ĠloadConfig', 'Ġ(', 'Ġ"GAFFER_STARTUP_PATHS"', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġsubdirectory', 'Ġ=', 'Ġ"GafferImageUI"', 'Ġ)', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n"
Original    (012): ['GafferRenderMan', '.', 'RenderManShader', '.', 'shaderLoader', '(', ')', '.', 'clear', '(', ')', '\\n']
Tokenized   (022): ['<s>', 'G', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ.', 'Ġshader', 'Loader', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġclear', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['G', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ.', 'Ġshader', 'Loader', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġclear', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['GafferRenderMan', 'Ġ.', 'ĠRenderManShader', 'Ġ.', 'ĠshaderLoader', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġclear', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "coshader = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/coshader.sl" ) \n"
Original    (018): ['coshader', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/coshader.sl"', ')', '\\n']
Tokenized   (037): ['<s>', 'c', 'osh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', '.', 'sl', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['c', 'osh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', '.', 'sl', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['coshader', 'Ġ=', 'Ġself', 'Ġ.', 'ĠcompileShader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ+', 'Ġ"/shaders/coshader.sl"', 'Ġ)', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "nn [ "outString" ] = Gaffer . StringPlug ( direction = Gaffer . Plug . Direction . Out ) \n"
Original    (020): ['nn', '[', '"outString"', ']', '=', 'Gaffer', '.', 'StringPlug', '(', 'direction', '=', 'Gaffer', '.', 'Plug', '.', 'Direction', '.', 'Out', ')', '\\n']
Tokenized   (029): ['<s>', 'nn', 'Ġ[', 'Ġ"', 'out', 'String', '"', 'Ġ]', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠString', 'Plug', 'Ġ(', 'Ġdirection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['nn', 'Ġ[', 'Ġ"', 'out', 'String', '"', 'Ġ]', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠString', 'Plug', 'Ġ(', 'Ġdirection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['nn', 'Ġ[', 'Ġ"outString"', 'Ġ]', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠStringPlug', 'Ġ(', 'Ġdirection', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/version2.sl" , shaderName = "unversioned" \n"
Original    (021): ['shader2', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/version2.sl"', ',', 'shaderName', '=', '"unversioned"', '\\n']
Tokenized   (044): ['<s>', 'sh', 'ader', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'version', '2', '.', 'sl', '"', 'Ġ,', 'Ġshader', 'Name', 'Ġ=', 'Ġ"', 'un', 'version', 'ed', '"', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['sh', 'ader', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'version', '2', '.', 'sl', '"', 'Ġ,', 'Ġshader', 'Name', 'Ġ=', 'Ġ"', 'un', 'version', 'ed', '"', 'Ġ\\', 'n']
Detokenized (021): ['shader2', 'Ġ=', 'Ġself', 'Ġ.', 'ĠcompileShader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ+', 'Ġ"/shaders/version2.sl"', 'Ġ,', 'ĠshaderName', 'Ġ=', 'Ġ"unversioned"', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "assignment [ "shader" ] . setInput ( shaderNode [ "out" ] ) \n"
Original    (013): ['assignment', '[', '"shader"', ']', '.', 'setInput', '(', 'shaderNode', '[', '"out"', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'ass', 'ignment', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġshader', 'Node', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ass', 'ignment', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġshader', 'Node', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['assignment', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ.', 'ĠsetInput', 'Ġ(', 'ĠshaderNode', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "dirtiedNames = [ x [ 0 ] . fullName ( ) for x in cs ] \n"
Original    (017): ['dirtiedNames', '=', '[', 'x', '[', '0', ']', '.', 'fullName', '(', ')', 'for', 'x', 'in', 'cs', ']', '\\n']
Tokenized   (024): ['<s>', 'd', 'irt', 'ied', 'Names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġcs', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['d', 'irt', 'ied', 'Names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġcs', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['dirtiedNames', 'Ġ=', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'ĠfullName', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġcs', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : ""dynamicFloatArray" : IECore . FloatVectorData ( [ ] ) , \n"
Original    (011): ['"dynamicFloatArray"', ':', 'IECore', '.', 'FloatVectorData', '(', '[', ']', ')', ',', '\\n']
Tokenized   (023): ['<s>', '"', 'd', 'ynamic', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', 'd', 'ynamic', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"dynamicFloatArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠFloatVectorData', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""fixedFloatArray" : IECore . FloatVectorData ( [ 1 , 2 , 3 , 4 ] ) , \n"
Original    (018): ['"fixedFloatArray"', ':', 'IECore', '.', 'FloatVectorData', '(', '[', '1', ',', '2', ',', '3', ',', '4', ']', ')', ',', '\\n']
Tokenized   (029): ['<s>', '"', 'fixed', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['"', 'fixed', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (018): ['"fixedFloatArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠFloatVectorData', 'Ġ(', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : ""dynamicStringArray" : IECore . StringVectorData ( [ "dynamic" , "arrays" , "can" , "still" , "have" , "defaults" "fixedStringArray" : IECore . StringVectorData ( [ "hello" , "goodbye" ] ) , \n"
Original    (032): ['"dynamicStringArray"', ':', 'IECore', '.', 'StringVectorData', '(', '[', '"dynamic"', ',', '"arrays"', ',', '"can"', ',', '"still"', ',', '"have"', ',', '"defaults"', '"fixedStringArray"', ':', 'IECore', '.', 'StringVectorData', '(', '[', '"hello"', ',', '"goodbye"', ']', ')', ',', '\\n']
Tokenized   (072): ['<s>', '"', 'd', 'ynamic', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'd', 'ynamic', '"', 'Ġ,', 'Ġ"', 'arr', 'ays', '"', 'Ġ,', 'Ġ"', 'can', '"', 'Ġ,', 'Ġ"', 'still', '"', 'Ġ,', 'Ġ"', 'have', '"', 'Ġ,', 'Ġ"', 'default', 's', '"', 'Ġ"', 'fixed', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'hello', '"', 'Ġ,', 'Ġ"', 'good', 'bye', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (070): ['"', 'd', 'ynamic', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'd', 'ynamic', '"', 'Ġ,', 'Ġ"', 'arr', 'ays', '"', 'Ġ,', 'Ġ"', 'can', '"', 'Ġ,', 'Ġ"', 'still', '"', 'Ġ,', 'Ġ"', 'have', '"', 'Ġ,', 'Ġ"', 'default', 's', '"', 'Ġ"', 'fixed', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'hello', '"', 'Ġ,', 'Ġ"', 'good', 'bye', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (032): ['"dynamicStringArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠStringVectorData', 'Ġ(', 'Ġ[', 'Ġ"dynamic"', 'Ġ,', 'Ġ"arrays"', 'Ġ,', 'Ġ"can"', 'Ġ,', 'Ġ"still"', 'Ġ,', 'Ġ"have"', 'Ġ,', 'Ġ"defaults"', 'Ġ"fixedStringArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠStringVectorData', 'Ġ(', 'Ġ[', 'Ġ"hello"', 'Ġ,', 'Ġ"goodbye"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 70
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : ""dynamicColorArray" : IECore . Color3fVectorData ( [ IECore . Color3f ( 1 ) , IECore . Color3f ( 2 ) ] ) , \n"
Original    (024): ['"dynamicColorArray"', ':', 'IECore', '.', 'Color3fVectorData', '(', '[', 'IECore', '.', 'Color3f', '(', '1', ')', ',', 'IECore', '.', 'Color3f', '(', '2', ')', ']', ')', ',', '\\n']
Tokenized   (046): ['<s>', '"', 'd', 'ynamic', 'Color', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['"', 'd', 'ynamic', 'Color', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (024): ['"dynamicColorArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠColor3fVectorData', 'Ġ(', 'Ġ[', 'ĠIECore', 'Ġ.', 'ĠColor3f', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠColor3f', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : ""dynamicVectorArray" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Vector ) , \n"
Original    (019): ['"dynamicVectorArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', ']', ',', 'IECore', '.', 'GeometricData', '.', 'Interpretation', '.', 'Vector', ')', ',', '\\n']
Tokenized   (038): ['<s>', '"', 'd', 'ynamic', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠVector', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['"', 'd', 'ynamic', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠVector', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['"dynamicVectorArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ.', 'ĠInterpretation', 'Ġ.', 'ĠVector', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : ""fixedVectorArray" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( 1 , 6 ) ] , IECore . GeometricData "dynamicPointArray" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Point ) , \n"
Original    (046): ['"fixedVectorArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', 'IECore', '.', 'V3f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'IECore', '.', 'GeometricData', '"dynamicPointArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', ']', ',', 'IECore', '.', 'GeometricData', '.', 'Interpretation', '.', 'Point', ')', ',', '\\n']
Tokenized   (083): ['<s>', '"', 'fixed', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ"', 'd', 'ynamic', 'Point', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠPoint', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (081): ['"', 'fixed', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ"', 'd', 'ynamic', 'Point', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠPoint', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (046): ['"fixedVectorArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'ĠIECore', 'Ġ.', 'ĠV3f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ"dynamicPointArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ.', 'ĠInterpretation', 'Ġ.', 'ĠPoint', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 81
===================================================================
Hidden states:  (13, 46, 768)
# Extracted words:  46
Sentence         : ""fixedNormalArray" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( 1 , 6 ) ] , IECore . GeometricData } \n"
Original    (029): ['"fixedNormalArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', 'IECore', '.', 'V3f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'IECore', '.', 'GeometricData', '}', '\\n']
Tokenized   (050): ['<s>', '"', 'fixed', 'Normal', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (048): ['"', 'fixed', 'Normal', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ}', 'Ġ\\', 'n']
Detokenized (029): ['"fixedNormalArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'ĠIECore', 'Ġ.', 'ĠV3f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ}', 'Ġ\\n']
Counter: 48
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "arrayShader = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/coshaderArrayParameters.sl" n4 = GafferRenderMan . RenderManShader ( ) \n"
Original    (024): ['arrayShader', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/coshaderArrayParameters.sl"', 'n4', '=', 'GafferRenderMan', '.', 'RenderManShader', '(', ')', '\\n']
Tokenized   (052): ['<s>', 'array', 'Sh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', 'Array', 'Parameters', '.', 'sl', '"', 'Ġn', '4', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (050): ['array', 'Sh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', 'Array', 'Parameters', '.', 'sl', '"', 'Ġn', '4', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['arrayShader', 'Ġ=', 'Ġself', 'Ġ.', 'ĠcompileShader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ+', 'Ġ"/shaders/coshaderArrayParameters.sl"', 'Ġn4', 'Ġ=', 'ĠGafferRenderMan', 'Ġ.', 'ĠRenderManShader', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 50
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "coshaderNode [ "enabled" ] . setValue ( False ) \n"
Original    (010): ['coshaderNode', '[', '"enabled"', ']', '.', 'setValue', '(', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'c', 'osh', 'ader', 'Node', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['c', 'osh', 'ader', 'Node', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['coshaderNode', 'Ġ[', 'Ġ"enabled"', 'Ġ]', 'Ġ.', 'ĠsetValue', 'Ġ(', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "floatValue = IECore . Splineff ( \n"
Original    (007): ['floatValue', '=', 'IECore', '.', 'Splineff', '(', '\\n']
Tokenized   (015): ['<s>', 'float', 'Value', 'Ġ=', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠSpl', 'ine', 'ff', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['float', 'Value', 'Ġ=', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠSpl', 'ine', 'ff', 'Ġ(', 'Ġ\\', 'n']
Detokenized (007): ['floatValue', 'Ġ=', 'ĠIECore', 'Ġ.', 'ĠSplineff', 'Ġ(', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "S [ "parameters" ] [ "coshaderParameter" ] . setInput ( D2 [ "out" ] ) \n"
Original    (016): ['S', '[', '"parameters"', ']', '[', '"coshaderParameter"', ']', '.', 'setInput', '(', 'D2', '[', '"out"', ']', ')', '\\n']
Tokenized   (031): ['<s>', 'S', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'c', 'osh', 'ader', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'ĠD', '2', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['S', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'c', 'osh', 'ader', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'ĠD', '2', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['S', 'Ġ[', 'Ġ"parameters"', 'Ġ]', 'Ġ[', 'Ġ"coshaderParameter"', 'Ġ]', 'Ġ.', 'ĠsetInput', 'Ġ(', 'ĠD2', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "coshaderNode0 [ "parameters" ] [ "floatParameter" ] . setValue ( 0 ) \n"
Original    (013): ['coshaderNode0', '[', '"parameters"', ']', '[', '"floatParameter"', ']', '.', 'setValue', '(', '0', ')', '\\n']
Tokenized   (027): ['<s>', 'c', 'osh', 'ader', 'Node', '0', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'float', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['c', 'osh', 'ader', 'Node', '0', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'float', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['coshaderNode0', 'Ġ[', 'Ġ"parameters"', 'Ġ]', 'Ġ[', 'Ġ"floatParameter"', 'Ġ]', 'Ġ.', 'ĠsetValue', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sn1 = GafferRenderMan . RenderManShader ( "Shader1" ) \n"
Original    (009): ['sn1', '=', 'GafferRenderMan', '.', 'RenderManShader', '(', '"Shader1"', ')', '\\n']
Tokenized   (023): ['<s>', 'sn', '1', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'Sh', 'ader', '1', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['sn', '1', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'Sh', 'ader', '1', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['sn1', 'Ġ=', 'ĠGafferRenderMan', 'Ġ.', 'ĠRenderManShader', 'Ġ(', 'Ġ"Shader1"', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "script [ "assignment" ] [ "shader" ] . setInput ( script [ "shader" ] [ "out" ] ) \n"
Original    (019): ['script', '[', '"assignment"', ']', '[', '"shader"', ']', '.', 'setInput', '(', 'script', '[', '"shader"', ']', '[', '"out"', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'script', 'Ġ[', 'Ġ"', 'ass', 'ignment', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['script', 'Ġ[', 'Ġ"', 'ass', 'ignment', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['script', 'Ġ[', 'Ġ"assignment"', 'Ġ]', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ.', 'ĠsetInput', 'Ġ(', 'Ġscript', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "traverseConnection = Gaffer . ScopedConnection ( GafferSceneTest . connectTraverseSceneToPlugDirtiedSignal script [ "shader" ] . loadShader ( "matte" ) \n"
Original    (019): ['traverseConnection', '=', 'Gaffer', '.', 'ScopedConnection', '(', 'GafferSceneTest', '.', 'connectTraverseSceneToPlugDirtiedSignal', 'script', '[', '"shader"', ']', '.', 'loadShader', '(', '"matte"', ')', '\\n']
Tokenized   (048): ['<s>', 'tra', 'verse', 'Connection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠSc', 'oped', 'Connection', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Test', 'Ġ.', 'Ġconnect', 'Tra', 'verse', 'Scene', 'To', 'Plug', 'D', 'irt', 'ied', 'Sign', 'al', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġload', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'mat', 'te', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['tra', 'verse', 'Connection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠSc', 'oped', 'Connection', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Test', 'Ġ.', 'Ġconnect', 'Tra', 'verse', 'Scene', 'To', 'Plug', 'D', 'irt', 'ied', 'Sign', 'al', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġload', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'mat', 'te', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['traverseConnection', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠScopedConnection', 'Ġ(', 'ĠGafferSceneTest', 'Ġ.', 'ĠconnectTraverseSceneToPlugDirtiedSignal', 'Ġscript', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ.', 'ĠloadShader', 'Ġ(', 'Ġ"matte"', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "current = s [ "render" ] . hash ( c ) \n"
Original    (012): ['current', '=', 's', '[', '"render"', ']', '.', 'hash', '(', 'c', ')', '\\n']
Tokenized   (017): ['<s>', 'current', 'Ġ=', 'Ġs', 'Ġ[', 'Ġ"', 'render', '"', 'Ġ]', 'Ġ.', 'Ġhash', 'Ġ(', 'Ġc', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['current', 'Ġ=', 'Ġs', 'Ġ[', 'Ġ"', 'render', '"', 'Ġ]', 'Ġ.', 'Ġhash', 'Ġ(', 'Ġc', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['current', 'Ġ=', 'Ġs', 'Ġ[', 'Ġ"render"', 'Ġ]', 'Ġ.', 'Ġhash', 'Ġ(', 'Ġc', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""layout:section" , "Transform" , \n"
Original    (005): ['"layout:section"', ',', '"Transform"', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'layout', ':', 'section', '"', 'Ġ,', 'Ġ"', 'Transform', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'layout', ':', 'section', '"', 'Ġ,', 'Ġ"', 'Transform', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"layout:section"', 'Ġ,', 'Ġ"Transform"', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""toolbarLayout:index" , 2 , \n"
Original    (005): ['"toolbarLayout:index"', ',', '2', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'tool', 'bar', 'Layout', ':', 'index', '"', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'tool', 'bar', 'Layout', ':', 'index', '"', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"toolbarLayout:index"', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""toolbarLayout:divider" , True , \n"
Original    (005): ['"toolbarLayout:divider"', ',', 'True', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'tool', 'bar', 'Layout', ':', 'div', 'ider', '"', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'tool', 'bar', 'Layout', ':', 'div', 'ider', '"', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"toolbarLayout:divider"', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "currentName = self . getPlug ( ) . getValue ( ) \n"
Original    (012): ['currentName', '=', 'self', '.', 'getPlug', '(', ')', '.', 'getValue', '(', ')', '\\n']
Tokenized   (018): ['<s>', 'current', 'Name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['current', 'Name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['currentName', 'Ġ=', 'Ġself', 'Ġ.', 'ĠgetPlug', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠgetValue', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "menuButton = GafferUI . MenuButton ( menu = menu , image = "grid.png" , hasFrame = False ) \n"
Original    (019): ['menuButton', '=', 'GafferUI', '.', 'MenuButton', '(', 'menu', '=', 'menu', ',', 'image', '=', '"grid.png"', ',', 'hasFrame', '=', 'False', ')', '\\n']
Tokenized   (031): ['<s>', 'menu', 'Button', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Button', 'Ġ(', 'Ġmenu', 'Ġ=', 'Ġmenu', 'Ġ,', 'Ġimage', 'Ġ=', 'Ġ"', 'grid', '.', 'png', '"', 'Ġ,', 'Ġhas', 'Frame', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['menu', 'Button', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Button', 'Ġ(', 'Ġmenu', 'Ġ=', 'Ġmenu', 'Ġ,', 'Ġimage', 'Ġ=', 'Ġ"', 'grid', '.', 'png', '"', 'Ġ,', 'Ġhas', 'Frame', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['menuButton', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠMenuButton', 'Ġ(', 'Ġmenu', 'Ġ=', 'Ġmenu', 'Ġ,', 'Ġimage', 'Ġ=', 'Ġ"grid.png"', 'Ġ,', 'ĠhasFrame', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "p3 = Gaffer . IntPlug ( "sum" , Gaffer . Plug . Direction . Out ) \n"
Original    (017): ['p3', '=', 'Gaffer', '.', 'IntPlug', '(', '"sum"', ',', 'Gaffer', '.', 'Plug', '.', 'Direction', '.', 'Out', ')', '\\n']
Tokenized   (026): ['<s>', 'p', '3', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠInt', 'Plug', 'Ġ(', 'Ġ"', 'sum', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['p', '3', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠInt', 'Plug', 'Ġ(', 'Ġ"', 'sum', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['p3', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠIntPlug', 'Ġ(', 'Ġ"sum"', 'Ġ,', 'ĠGaffer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "childrenStrings = [ str ( c ) for c in children ] \n"
Original    (013): ['childrenStrings', '=', '[', 'str', '(', 'c', ')', 'for', 'c', 'in', 'children', ']', '\\n']
Tokenized   (018): ['<s>', 'children', 'Str', 'ings', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġc', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġchildren', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['children', 'Str', 'ings', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġc', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġchildren', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['childrenStrings', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġc', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġchildren', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "c2 = [ str ( p ) for p in path2 . children ( ) ] \n"
Original    (017): ['c2', '=', '[', 'str', '(', 'p', ')', 'for', 'p', 'in', 'path2', '.', 'children', '(', ')', ']', '\\n']
Tokenized   (022): ['<s>', 'c', '2', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpath', '2', 'Ġ.', 'Ġchildren', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['c', '2', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpath', '2', 'Ġ.', 'Ġchildren', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['c2', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpath2', 'Ġ.', 'Ġchildren', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "horizontalAlignment = GafferUI . Label . HorizontalAlignment . Right , \n"
Original    (011): ['horizontalAlignment', '=', 'GafferUI', '.', 'Label', '.', 'HorizontalAlignment', '.', 'Right', ',', '\\n']
Tokenized   (022): ['<s>', 'hor', 'izontal', 'Al', 'ignment', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠLabel', 'Ġ.', 'ĠHor', 'izontal', 'Al', 'ignment', 'Ġ.', 'ĠRight', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['hor', 'izontal', 'Al', 'ignment', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠLabel', 'Ġ.', 'ĠHor', 'izontal', 'Al', 'ignment', 'Ġ.', 'ĠRight', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['horizontalAlignment', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠLabel', 'Ġ.', 'ĠHorizontalAlignment', 'Ġ.', 'ĠRight', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "nameWidget . textWidget ( ) . _qtWidget ( ) . setFixedWidth ( GafferUI . PlugWidget . labelWidth ( ) ) \n"
Original    (021): ['nameWidget', '.', 'textWidget', '(', ')', '.', '_qtWidget', '(', ')', '.', 'setFixedWidth', '(', 'GafferUI', '.', 'PlugWidget', '.', 'labelWidth', '(', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'name', 'Widget', 'Ġ.', 'Ġtext', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'Fixed', 'Width', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPlug', 'Widget', 'Ġ.', 'Ġlabel', 'Width', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['name', 'Widget', 'Ġ.', 'Ġtext', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'Fixed', 'Width', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPlug', 'Widget', 'Ġ.', 'Ġlabel', 'Width', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['nameWidget', 'Ġ.', 'ĠtextWidget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġ_qtWidget', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠsetFixedWidth', 'Ġ(', 'ĠGafferUI', 'Ġ.', 'ĠPlugWidget', 'Ġ.', 'ĠlabelWidth', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "childPlug [ "enabled" ] , \n"
Original    (006): ['childPlug', '[', '"enabled"', ']', ',', '\\n']
Tokenized   (012): ['<s>', 'child', 'Plug', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['child', 'Plug', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['childPlug', 'Ġ[', 'Ġ"enabled"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "memberPlug = memberPlug if memberPlug is not None else plug . ancestor ( Gaffer . CompoundDataPlug . MemberPlug if memberPlug is None : \n"
Original    (024): ['memberPlug', '=', 'memberPlug', 'if', 'memberPlug', 'is', 'not', 'None', 'else', 'plug', '.', 'ancestor', '(', 'Gaffer', '.', 'CompoundDataPlug', '.', 'MemberPlug', 'if', 'memberPlug', 'is', 'None', ':', '\\n']
Tokenized   (036): ['<s>', 'member', 'Plug', 'Ġ=', 'Ġmember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'Ġnot', 'ĠNone', 'Ġelse', 'Ġplug', 'Ġ.', 'Ġancestor', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠComp', 'ound', 'Data', 'Plug', 'Ġ.', 'ĠMember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'ĠNone', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['member', 'Plug', 'Ġ=', 'Ġmember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'Ġnot', 'ĠNone', 'Ġelse', 'Ġplug', 'Ġ.', 'Ġancestor', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠComp', 'ound', 'Data', 'Plug', 'Ġ.', 'ĠMember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'ĠNone', 'Ġ:', 'Ġ\\', 'n']
Detokenized (024): ['memberPlug', 'Ġ=', 'ĠmemberPlug', 'Ġif', 'ĠmemberPlug', 'Ġis', 'Ġnot', 'ĠNone', 'Ġelse', 'Ġplug', 'Ġ.', 'Ġancestor', 'Ġ(', 'ĠGaffer', 'Ġ.', 'ĠCompoundDataPlug', 'Ġ.', 'ĠMemberPlug', 'Ġif', 'ĠmemberPlug', 'Ġis', 'ĠNone', 'Ġ:', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "menuDefinition . append ( "/Delete" , { "command" : IECore . curry ( __deletePlug , memberPlug ) , "active" \n"
Original    (020): ['menuDefinition', '.', 'append', '(', '"/Delete"', ',', '{', '"command"', ':', 'IECore', '.', 'curry', '(', '__deletePlug', ',', 'memberPlug', ')', ',', '"active"', '\\n']
Tokenized   (035): ['<s>', 'menu', 'Definition', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ"/', 'Delete', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'command', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'Ġcurry', 'Ġ(', 'Ġ__', 'delete', 'Plug', 'Ġ,', 'Ġmember', 'Plug', 'Ġ)', 'Ġ,', 'Ġ"', 'active', '"', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['menu', 'Definition', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ"/', 'Delete', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'command', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'Ġcurry', 'Ġ(', 'Ġ__', 'delete', 'Plug', 'Ġ,', 'Ġmember', 'Plug', 'Ġ)', 'Ġ,', 'Ġ"', 'active', '"', 'Ġ\\', 'n']
Detokenized (020): ['menuDefinition', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ"/Delete"', 'Ġ,', 'Ġ{', 'Ġ"command"', 'Ġ:', 'ĠIECore', 'Ġ.', 'Ġcurry', 'Ġ(', 'Ġ__deletePlug', 'Ġ,', 'ĠmemberPlug', 'Ġ)', 'Ġ,', 'Ġ"active"', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "includeSequences = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "fileSystemPathPlugValueWidget:includeSequences" \n"
Original    (016): ['includeSequences', '=', 'Gaffer', '.', 'Metadata', '.', 'plugValue', '(', 'self', '.', 'getPlug', '(', ')', ',', '"fileSystemPathPlugValueWidget:includeSequences"', '\\n']
Tokenized   (036): ['<s>', 'include', 'Sequ', 'ences', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'file', 'System', 'Path', 'Plug', 'Value', 'Widget', ':', 'include', 'Sequ', 'ences', '"', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['include', 'Sequ', 'ences', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'file', 'System', 'Path', 'Plug', 'Value', 'Widget', ':', 'include', 'Sequ', 'ences', '"', 'Ġ\\', 'n']
Detokenized (016): ['includeSequences', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠMetadata', 'Ġ.', 'ĠplugValue', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"fileSystemPathPlugValueWidget:includeSequences"', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "reuse = reuseUntil is not None \n"
Original    (007): ['reuse', '=', 'reuseUntil', 'is', 'not', 'None', '\\n']
Tokenized   (012): ['<s>', 're', 'use', 'Ġ=', 'Ġreuse', 'Until', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['re', 'use', 'Ġ=', 'Ġreuse', 'Until', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ\\', 'n']
Detokenized (007): ['reuse', 'Ġ=', 'ĠreuseUntil', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_MultiLineStringMetadataWidget ( key = "description" ) \n"
Original    (007): ['_MultiLineStringMetadataWidget', '(', 'key', '=', '"description"', ')', '\\n']
Tokenized   (018): ['<s>', '_', 'Multi', 'Line', 'String', 'Met', 'adata', 'Widget', 'Ġ(', 'Ġkey', 'Ġ=', 'Ġ"', 'description', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['_', 'Multi', 'Line', 'String', 'Met', 'adata', 'Widget', 'Ġ(', 'Ġkey', 'Ġ=', 'Ġ"', 'description', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['_MultiLineStringMetadataWidget', 'Ġ(', 'Ġkey', 'Ġ=', 'Ġ"description"', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""active" : isinstance ( node , Gaffer . Box ) or nodeEditor . nodeUI ( ) . plugValueWidget ( node [ "user" ] ) } \n"
Original    (026): ['"active"', ':', 'isinstance', '(', 'node', ',', 'Gaffer', '.', 'Box', ')', 'or', 'nodeEditor', '.', 'nodeUI', '(', ')', '.', 'plugValueWidget', '(', 'node', '[', '"user"', ']', ')', '}', '\\n']
Tokenized   (039): ['<s>', '"', 'active', '"', 'Ġ:', 'Ġis', 'instance', 'Ġ(', 'Ġnode', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠBox', 'Ġ)', 'Ġor', 'Ġnode', 'Editor', 'Ġ.', 'Ġnode', 'UI', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġplug', 'Value', 'Widget', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ"', 'user', '"', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['"', 'active', '"', 'Ġ:', 'Ġis', 'instance', 'Ġ(', 'Ġnode', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠBox', 'Ġ)', 'Ġor', 'Ġnode', 'Editor', 'Ġ.', 'Ġnode', 'UI', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġplug', 'Value', 'Widget', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ"', 'user', '"', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (026): ['"active"', 'Ġ:', 'Ġisinstance', 'Ġ(', 'Ġnode', 'Ġ,', 'ĠGaffer', 'Ġ.', 'ĠBox', 'Ġ)', 'Ġor', 'ĠnodeEditor', 'Ġ.', 'ĠnodeUI', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠplugValueWidget', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ"user"', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "dialogue = GafferUI . ColorChooserDialogue ( color = color , useDisplayTransform = False ) \n"
Original    (015): ['dialogue', '=', 'GafferUI', '.', 'ColorChooserDialogue', '(', 'color', '=', 'color', ',', 'useDisplayTransform', '=', 'False', ')', '\\n']
Tokenized   (026): ['<s>', 'dial', 'ogue', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠColor', 'Cho', 'oser', 'Dialogue', 'Ġ(', 'Ġcolor', 'Ġ=', 'Ġcolor', 'Ġ,', 'Ġuse', 'Display', 'Transform', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['dial', 'ogue', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠColor', 'Cho', 'oser', 'Dialogue', 'Ġ(', 'Ġcolor', 'Ġ=', 'Ġcolor', 'Ġ,', 'Ġuse', 'Display', 'Transform', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['dialogue', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠColorChooserDialogue', 'Ġ(', 'Ġcolor', 'Ġ=', 'Ġcolor', 'Ġ,', 'ĠuseDisplayTransform', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "editor . plugEditor ( ) . reveal ( ) \n"
Original    (010): ['editor', '.', 'plugEditor', '(', ')', '.', 'reveal', '(', ')', '\\n']
Tokenized   (014): ['<s>', 'editor', 'Ġ.', 'Ġplug', 'Editor', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreveal', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['editor', 'Ġ.', 'Ġplug', 'Editor', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreveal', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['editor', 'Ġ.', 'ĠplugEditor', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreveal', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_MetadataWidget . __init__ ( self , self . __menuButton , key , target , parenting = parenting ) \n"
Original    (019): ['_MetadataWidget', '.', '__init__', '(', 'self', ',', 'self', '.', '__menuButton', ',', 'key', ',', 'target', ',', 'parenting', '=', 'parenting', ')', '\\n']
Tokenized   (029): ['<s>', '_', 'Met', 'adata', 'Widget', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'menu', 'Button', 'Ġ,', 'Ġkey', 'Ġ,', 'Ġtarget', 'Ġ,', 'Ġparenting', 'Ġ=', 'Ġparenting', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['_', 'Met', 'adata', 'Widget', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'menu', 'Button', 'Ġ,', 'Ġkey', 'Ġ,', 'Ġtarget', 'Ġ,', 'Ġparenting', 'Ġ=', 'Ġparenting', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['_MetadataWidget', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__menuButton', 'Ġ,', 'Ġkey', 'Ġ,', 'Ġtarget', 'Ġ,', 'Ġparenting', 'Ġ=', 'Ġparenting', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : ""checkBox" : value == self . __currentValue \n"
Original    (008): ['"checkBox"', ':', 'value', '==', 'self', '.', '__currentValue', '\\n']
Tokenized   (016): ['<s>', '"', 'check', 'Box', '"', 'Ġ:', 'Ġvalue', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ__', 'current', 'Value', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['"', 'check', 'Box', '"', 'Ġ:', 'Ġvalue', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ__', 'current', 'Value', 'Ġ\\', 'n']
Detokenized (008): ['"checkBox"', 'Ġ:', 'Ġvalue', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ__currentValue', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "child . __parent = None \n"
Original    (006): ['child', '.', '__parent', '=', 'None', '\\n']
Tokenized   (010): ['<s>', 'child', 'Ġ.', 'Ġ__', 'parent', 'Ġ=', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['child', 'Ġ.', 'Ġ__', 'parent', 'Ġ=', 'ĠNone', 'Ġ\\', 'n']
Detokenized (006): ['child', 'Ġ.', 'Ġ__parent', 'Ġ=', 'ĠNone', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "columns = ( GafferUI . PathListingWidget . defaultNameColumn , ) , \n"
Original    (012): ['columns', '=', '(', 'GafferUI', '.', 'PathListingWidget', '.', 'defaultNameColumn', ',', ')', ',', '\\n']
Tokenized   (023): ['<s>', 'column', 's', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPath', 'List', 'ing', 'Widget', 'Ġ.', 'Ġdefault', 'Name', 'Column', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['column', 's', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPath', 'List', 'ing', 'Widget', 'Ġ.', 'Ġdefault', 'Name', 'Column', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['columns', 'Ġ=', 'Ġ(', 'ĠGafferUI', 'Ġ.', 'ĠPathListingWidget', 'Ġ.', 'ĠdefaultNameColumn', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "definition = Gaffer . WeakMethod ( self . __addMenuDefinition ) \n"
Original    (011): ['definition', '=', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__addMenuDefinition', ')', '\\n']
Tokenized   (019): ['<s>', 'definition', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'add', 'Menu', 'Definition', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['definition', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'add', 'Menu', 'Definition', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['definition', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠWeakMethod', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__addMenuDefinition', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "newIndex = 0 if event . line . p0 . y < 1 else len ( newParent ) \n"
Original    (019): ['newIndex', '=', '0', 'if', 'event', '.', 'line', '.', 'p0', '.', 'y', '<', '1', 'else', 'len', '(', 'newParent', ')', '\\n']
Tokenized   (025): ['<s>', 'new', 'Index', 'Ġ=', 'Ġ0', 'Ġif', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ.', 'Ġy', 'Ġ<', 'Ġ1', 'Ġelse', 'Ġlen', 'Ġ(', 'Ġnew', 'Parent', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', 'Index', 'Ġ=', 'Ġ0', 'Ġif', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ.', 'Ġy', 'Ġ<', 'Ġ1', 'Ġelse', 'Ġlen', 'Ġ(', 'Ġnew', 'Parent', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['newIndex', 'Ġ=', 'Ġ0', 'Ġif', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp0', 'Ġ.', 'Ġy', 'Ġ<', 'Ġ1', 'Ġelse', 'Ġlen', 'Ġ(', 'ĠnewParent', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "newParent . insert ( newIndex , self . __dragItem ) \n"
Original    (011): ['newParent', '.', 'insert', '(', 'newIndex', ',', 'self', '.', '__dragItem', ')', '\\n']
Tokenized   (019): ['<s>', 'new', 'Parent', 'Ġ.', 'Ġinsert', 'Ġ(', 'Ġnew', 'Index', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['new', 'Parent', 'Ġ.', 'Ġinsert', 'Ġ(', 'Ġnew', 'Index', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['newParent', 'Ġ.', 'Ġinsert', 'Ġ(', 'ĠnewIndex', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__dragItem', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "selection [ : ] = self . __dragItem . fullName ( ) . split ( "." ) \n"
Original    (018): ['selection', '[', ':', ']', '=', 'self', '.', '__dragItem', '.', 'fullName', '(', ')', '.', 'split', '(', '"."', ')', '\\n']
Tokenized   (026): ['<s>', 'selection', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ"', '."', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['selection', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ"', '."', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['selection', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__dragItem', 'Ġ.', 'ĠfullName', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ"."', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "_registerMetadata ( plug , "nodule:type" , "" ) \n"
Original    (009): ['_registerMetadata', '(', 'plug', ',', '"nodule:type"', ',', '""', ')', '\\n']
Tokenized   (021): ['<s>', '_', 'register', 'Met', 'adata', 'Ġ(', 'Ġplug', 'Ġ,', 'Ġ"', 'n', 'od', 'ule', ':', 'type', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['_', 'register', 'Met', 'adata', 'Ġ(', 'Ġplug', 'Ġ,', 'Ġ"', 'n', 'od', 'ule', ':', 'type', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['_registerMetadata', 'Ġ(', 'Ġplug', 'Ġ,', 'Ġ"nodule:type"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "parentItem \n"
Original    (002): ['parentItem', '\\n']
Tokenized   (006): ['<s>', 'parent', 'Item', 'Ġ\\', 'n', '</s>']
Filtered   (004): ['parent', 'Item', 'Ġ\\', 'n']
Detokenized (002): ['parentItem', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "existingSectionNames = set ( c . name ( ) for c in rootItem if isinstance ( c , _SectionLayoutItem ) ) \n"
Original    (022): ['existingSectionNames', '=', 'set', '(', 'c', '.', 'name', '(', ')', 'for', 'c', 'in', 'rootItem', 'if', 'isinstance', '(', 'c', ',', '_SectionLayoutItem', ')', ')', '\\n']
Tokenized   (032): ['<s>', 'existing', 'Section', 'Names', 'Ġ=', 'Ġset', 'Ġ(', 'Ġc', 'Ġ.', 'Ġname', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġroot', 'Item', 'Ġif', 'Ġis', 'instance', 'Ġ(', 'Ġc', 'Ġ,', 'Ġ_', 'Section', 'Layout', 'Item', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['existing', 'Section', 'Names', 'Ġ=', 'Ġset', 'Ġ(', 'Ġc', 'Ġ.', 'Ġname', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġroot', 'Item', 'Ġif', 'Ġis', 'instance', 'Ġ(', 'Ġc', 'Ġ,', 'Ġ_', 'Section', 'Layout', 'Item', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['existingSectionNames', 'Ġ=', 'Ġset', 'Ġ(', 'Ġc', 'Ġ.', 'Ġname', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'ĠrootItem', 'Ġif', 'Ġisinstance', 'Ġ(', 'Ġc', 'Ġ,', 'Ġ_SectionLayoutItem', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "Gaffer . Metadata . plugValue ( self . getPlug ( ) , "preset:" + selectedPaths [ 0 ] [ 0 ] ) \n"
Original    (023): ['Gaffer', '.', 'Metadata', '.', 'plugValue', '(', 'self', '.', 'getPlug', '(', ')', ',', '"preset:"', '+', 'selectedPaths', '[', '0', ']', '[', '0', ']', ')', '\\n']
Tokenized   (035): ['<s>', 'G', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'pres', 'et', ':"', 'Ġ+', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['G', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'pres', 'et', ':"', 'Ġ+', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['Gaffer', 'Ġ.', 'ĠMetadata', 'Ġ.', 'ĠplugValue', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"preset:"', 'Ġ+', 'ĠselectedPaths', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "srcPath = self . __pathListing . getPath ( ) . copy ( ) . setFromString ( event . data [ 0 ] ) \n"
Original    (024): ['srcPath', '=', 'self', '.', '__pathListing', '.', 'getPath', '(', ')', '.', 'copy', '(', ')', '.', 'setFromString', '(', 'event', '.', 'data', '[', '0', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'src', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Path', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcopy', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'From', 'String', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['src', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Path', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcopy', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'From', 'String', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['srcPath', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__pathListing', 'Ġ.', 'ĠgetPath', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcopy', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠsetFromString', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "srcIndex = d . keys ( ) . index ( srcPath [ 0 ] ) \n"
Original    (016): ['srcIndex', '=', 'd', '.', 'keys', '(', ')', '.', 'index', '(', 'srcPath', '[', '0', ']', ')', '\\n']
Tokenized   (021): ['<s>', 'src', 'Index', 'Ġ=', 'Ġd', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġsrc', 'Path', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['src', 'Index', 'Ġ=', 'Ġd', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġsrc', 'Path', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['srcIndex', 'Ġ=', 'Ġd', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġindex', 'Ġ(', 'ĠsrcPath', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "targetPath = self . __pathListing . pathAt ( event . line . p0 ) \n"
Original    (015): ['targetPath', '=', 'self', '.', '__pathListing', '.', 'pathAt', '(', 'event', '.', 'line', '.', 'p0', ')', '\\n']
Tokenized   (024): ['<s>', 'target', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġpath', 'At', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['target', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġpath', 'At', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['targetPath', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__pathListing', 'Ġ.', 'ĠpathAt', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp0', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "item = items [ srcIndex ] \n"
Original    (007): ['item', '=', 'items', '[', 'srcIndex', ']', '\\n']
Tokenized   (011): ['<s>', 'item', 'Ġ=', 'Ġitems', 'Ġ[', 'Ġsrc', 'Index', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['item', 'Ġ=', 'Ġitems', 'Ġ[', 'Ġsrc', 'Index', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['item', 'Ġ=', 'Ġitems', 'Ġ[', 'ĠsrcIndex', 'Ġ]', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "selectedPreset = self . __pathListing . getSelectedPaths ( ) [ 0 ] [ 0 ] \n"
Original    (016): ['selectedPreset', '=', 'self', '.', '__pathListing', '.', 'getSelectedPaths', '(', ')', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (028): ['<s>', 'selected', 'Pres', 'et', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Se', 'lected', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['selected', 'Pres', 'et', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Se', 'lected', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['selectedPreset', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__pathListing', 'Ġ.', 'ĠgetSelectedPaths', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "selectedIndex = [ p [ 0 ] for p in paths ] . index ( selectedPreset ) \n"
Original    (018): ['selectedIndex', '=', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'paths', ']', '.', 'index', '(', 'selectedPreset', ')', '\\n']
Tokenized   (024): ['<s>', 'selected', 'Index', 'Ġ=', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġpaths', 'Ġ]', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġselected', 'Pres', 'et', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['selected', 'Index', 'Ġ=', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġpaths', 'Ġ]', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġselected', 'Pres', 'et', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['selectedIndex', 'Ġ=', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġpaths', 'Ġ]', 'Ġ.', 'Ġindex', 'Ġ(', 'ĠselectedPreset', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "preset = selectedPaths [ 0 ] [ 0 ] \n"
Original    (010): ['preset', '=', 'selectedPaths', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (016): ['<s>', 'pres', 'et', 'Ġ=', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['pres', 'et', 'Ġ=', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['preset', 'Ġ=', 'ĠselectedPaths', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "scrolledContainer . setChild ( GafferUI . ListContainer ( spacing = 4 ) ) \n"
Original    (014): ['scrolledContainer', '.', 'setChild', '(', 'GafferUI', '.', 'ListContainer', '(', 'spacing', '=', '4', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'sc', 'rolled', 'Container', 'Ġ.', 'Ġset', 'Child', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠList', 'Container', 'Ġ(', 'Ġspacing', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['sc', 'rolled', 'Container', 'Ġ.', 'Ġset', 'Child', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠList', 'Container', 'Ġ(', 'Ġspacing', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['scrolledContainer', 'Ġ.', 'ĠsetChild', 'Ġ(', 'ĠGafferUI', 'Ġ.', 'ĠListContainer', 'Ġ(', 'Ġspacing', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __gadgetMenuDefinition ) ) \n"
Original    (016): ['menu', '=', 'GafferUI', '.', 'Menu', '(', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__gadgetMenuDefinition', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'menu', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'g', 'ad', 'get', 'Menu', 'Definition', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['menu', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'g', 'ad', 'get', 'Menu', 'Definition', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['menu', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠMenu', 'Ġ(', 'ĠGaffer', 'Ġ.', 'ĠWeakMethod', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__gadgetMenuDefinition', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""/" + g . label , \n"
Original    (007): ['"/"', '+', 'g', '.', 'label', ',', '\\n']
Tokenized   (011): ['<s>', '"', '/"', 'Ġ+', 'Ġg', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['"', '/"', 'Ġ+', 'Ġg', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"/"', 'Ġ+', 'Ġg', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""command" : functools . partial ( Gaffer . WeakMethod ( self . __registerOrDeregisterMetadata ) , key = "checkBox" : metadata == g . metadata , \n"
Original    (026): ['"command"', ':', 'functools', '.', 'partial', '(', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__registerOrDeregisterMetadata', ')', ',', 'key', '=', '"checkBox"', ':', 'metadata', '==', 'g', '.', 'metadata', ',', '\\n']
Tokenized   (046): ['<s>', '"', 'command', '"', 'Ġ:', 'Ġfun', 'ct', 'ools', 'Ġ.', 'Ġpartial', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'register', 'Or', 'D', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ)', 'Ġ,', 'Ġkey', 'Ġ=', 'Ġ"', 'check', 'Box', '"', 'Ġ:', 'Ġmetadata', 'Ġ==', 'Ġg', 'Ġ.', 'Ġmetadata', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['"', 'command', '"', 'Ġ:', 'Ġfun', 'ct', 'ools', 'Ġ.', 'Ġpartial', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'register', 'Or', 'D', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ)', 'Ġ,', 'Ġkey', 'Ġ=', 'Ġ"', 'check', 'Box', '"', 'Ġ:', 'Ġmetadata', 'Ġ==', 'Ġg', 'Ġ.', 'Ġmetadata', 'Ġ,', 'Ġ\\', 'n']
Detokenized (026): ['"command"', 'Ġ:', 'Ġfunctools', 'Ġ.', 'Ġpartial', 'Ġ(', 'ĠGaffer', 'Ġ.', 'ĠWeakMethod', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__registerOrDeregisterMetadata', 'Ġ)', 'Ġ,', 'Ġkey', 'Ġ=', 'Ġ"checkBox"', 'Ġ:', 'Ġmetadata', 'Ġ==', 'Ġg', 'Ġ.', 'Ġmetadata', 'Ġ,', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "__WidgetDefinition ( "None" , Gaffer . Plug , "" ) , \n"
Original    (012): ['__WidgetDefinition', '(', '"None"', ',', 'Gaffer', '.', 'Plug', ',', '""', ')', ',', '\\n']
Tokenized   (020): ['<s>', '__', 'Widget', 'Definition', 'Ġ(', 'Ġ"', 'None', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['__', 'Widget', 'Definition', 'Ġ(', 'Ġ"', 'None', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['__WidgetDefinition', 'Ġ(', 'Ġ"None"', 'Ġ,', 'ĠGaffer', 'Ġ.', 'ĠPlug', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "__MetadataDefinition = collections . namedtuple ( "MetadataDefinition" , ( "key" , "label" , "metadataWidgetType" __metadataDefinitions = ( \n"
Original    (018): ['__MetadataDefinition', '=', 'collections', '.', 'namedtuple', '(', '"MetadataDefinition"', ',', '(', '"key"', ',', '"label"', ',', '"metadataWidgetType"', '__metadataDefinitions', '=', '(', '\\n']
Tokenized   (041): ['<s>', '__', 'Met', 'adata', 'Definition', 'Ġ=', 'Ġcollections', 'Ġ.', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'Met', 'adata', 'Definition', '"', 'Ġ,', 'Ġ(', 'Ġ"', 'key', '"', 'Ġ,', 'Ġ"', 'label', '"', 'Ġ,', 'Ġ"', 'metadata', 'Widget', 'Type', '"', 'Ġ__', 'metadata', 'Def', 'initions', 'Ġ=', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['__', 'Met', 'adata', 'Definition', 'Ġ=', 'Ġcollections', 'Ġ.', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'Met', 'adata', 'Definition', '"', 'Ġ,', 'Ġ(', 'Ġ"', 'key', '"', 'Ġ,', 'Ġ"', 'label', '"', 'Ġ,', 'Ġ"', 'metadata', 'Widget', 'Type', '"', 'Ġ__', 'metadata', 'Def', 'initions', 'Ġ=', 'Ġ(', 'Ġ\\', 'n']
Detokenized (018): ['__MetadataDefinition', 'Ġ=', 'Ġcollections', 'Ġ.', 'Ġnamedtuple', 'Ġ(', 'Ġ"MetadataDefinition"', 'Ġ,', 'Ġ(', 'Ġ"key"', 'Ġ,', 'Ġ"label"', 'Ġ,', 'Ġ"metadataWidgetType"', 'Ġ__metadataDefinitions', 'Ġ=', 'Ġ(', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "newSectionPath [ - 1 ] = nameWidget . getText ( ) . replace ( "." , "" ) \n"
Original    (019): ['newSectionPath', '[', '-', '1', ']', '=', 'nameWidget', '.', 'getText', '(', ')', '.', 'replace', '(', '"."', ',', '""', ')', '\\n']
Tokenized   (027): ['<s>', 'new', 'Section', 'Path', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġname', 'Widget', 'Ġ.', 'Ġget', 'Text', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '."', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['new', 'Section', 'Path', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġname', 'Widget', 'Ġ.', 'Ġget', 'Text', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '."', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['newSectionPath', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'ĠnameWidget', 'Ġ.', 'ĠgetText', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"."', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "_metadata ( self . getPlugParent ( ) , name ) \n"
Original    (011): ['_metadata', '(', 'self', '.', 'getPlugParent', '(', ')', ',', 'name', ')', '\\n']
Tokenized   (017): ['<s>', '_', 'metadata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['_', 'metadata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_metadata', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlugParent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_deregisterMetadata ( self . getPlugParent ( ) , name ) \n"
Original    (011): ['_deregisterMetadata', '(', 'self', '.', 'getPlugParent', '(', ')', ',', 'name', ')', '\\n']
Tokenized   (022): ['<s>', '_', 'd', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'd', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_deregisterMetadata', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlugParent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "wr2 = weakref . ref ( w . _qtWidget ( ) ) \n"
Original    (013): ['wr2', '=', 'weakref', '.', 'ref', '(', 'w', '.', '_qtWidget', '(', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'wr', '2', 'Ġ=', 'Ġweak', 'ref', 'Ġ.', 'Ġref', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['wr', '2', 'Ġ=', 'Ġweak', 'ref', 'Ġ.', 'Ġref', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['wr2', 'Ġ=', 'Ġweakref', 'Ġ.', 'Ġref', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_qtWidget', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "WidgetTest . signalsEmitted = 0 \n"
Original    (006): ['WidgetTest', '.', 'signalsEmitted', '=', '0', '\\n']
Tokenized   (012): ['<s>', 'Widget', 'Test', 'Ġ.', 'Ġsignals', 'E', 'mitted', 'Ġ=', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Widget', 'Test', 'Ġ.', 'Ġsignals', 'E', 'mitted', 'Ġ=', 'Ġ0', 'Ġ\\', 'n']
Detokenized (006): ['WidgetTest', 'Ġ.', 'ĠsignalsEmitted', 'Ġ=', 'Ġ0', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) \n"
Original    (019): ['QtGui', '.', 'QApplication', '.', 'instance', '(', ')', '.', 'sendEvent', '(', 'w', '.', '_qtWidget', '(', ')', ',', 'event', ')', '\\n']
Tokenized   (029): ['<s>', 'Q', 't', 'Gu', 'i', 'Ġ.', 'ĠQ', 'Application', 'Ġ.', 'Ġinstance', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsend', 'Event', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġevent', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['Q', 't', 'Gu', 'i', 'Ġ.', 'ĠQ', 'Application', 'Ġ.', 'Ġinstance', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsend', 'Event', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġevent', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['QtGui', 'Ġ.', 'ĠQApplication', 'Ġ.', 'Ġinstance', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠsendEvent', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_qtWidget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġevent', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "GafferUI . BoxUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) \n"
Original    (013): ['GafferUI', '.', 'BoxUI', '.', 'appendNodeEditorToolMenuDefinitions', '(', 'nodeEditor', ',', 'node', ',', 'menuDefinition', ')', '\\n']
Tokenized   (027): ['<s>', 'G', 'affer', 'UI', 'Ġ.', 'ĠBox', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['G', 'affer', 'UI', 'Ġ.', 'ĠBox', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['GafferUI', 'Ġ.', 'ĠBoxUI', 'Ġ.', 'ĠappendNodeEditorToolMenuDefinitions', 'Ġ(', 'ĠnodeEditor', 'Ġ,', 'Ġnode', 'Ġ,', 'ĠmenuDefinition', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "GafferSceneUI . FilteredSceneProcessorUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition \n"
Original    (012): ['GafferSceneUI', '.', 'FilteredSceneProcessorUI', '.', 'appendNodeEditorToolMenuDefinitions', '(', 'nodeEditor', ',', 'node', ',', 'menuDefinition', '\\n']
Tokenized   (031): ['<s>', 'G', 'affer', 'Scene', 'UI', 'Ġ.', 'ĠFil', 'tered', 'Scene', 'Process', 'or', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['G', 'affer', 'Scene', 'UI', 'Ġ.', 'ĠFil', 'tered', 'Scene', 'Process', 'or', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ\\', 'n']
Detokenized (012): ['GafferSceneUI', 'Ġ.', 'ĠFilteredSceneProcessorUI', 'Ġ.', 'ĠappendNodeEditorToolMenuDefinitions', 'Ġ(', 'ĠnodeEditor', 'Ġ,', 'Ġnode', 'Ġ,', 'ĠmenuDefinition', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "yappi . print_stats ( sort_type = yappi . SORTTYPE_TTOT , limit = 30 , thread_stats_on = False ) \n"
Original    (019): ['yappi', '.', 'print_stats', '(', 'sort_type', '=', 'yappi', '.', 'SORTTYPE_TTOT', ',', 'limit', '=', '30', ',', 'thread_stats_on', '=', 'False', ')', '\\n']
Tokenized   (039): ['<s>', 'y', 'app', 'i', 'Ġ.', 'Ġprint', '_', 'stats', 'Ġ(', 'Ġsort', '_', 'type', 'Ġ=', 'Ġy', 'app', 'i', 'Ġ.', 'ĠS', 'ORT', 'TYPE', '_', 'TT', 'OT', 'Ġ,', 'Ġlimit', 'Ġ=', 'Ġ30', 'Ġ,', 'Ġthread', '_', 'stats', '_', 'on', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['y', 'app', 'i', 'Ġ.', 'Ġprint', '_', 'stats', 'Ġ(', 'Ġsort', '_', 'type', 'Ġ=', 'Ġy', 'app', 'i', 'Ġ.', 'ĠS', 'ORT', 'TYPE', '_', 'TT', 'OT', 'Ġ,', 'Ġlimit', 'Ġ=', 'Ġ30', 'Ġ,', 'Ġthread', '_', 'stats', '_', 'on', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['yappi', 'Ġ.', 'Ġprint_stats', 'Ġ(', 'Ġsort_type', 'Ġ=', 'Ġyappi', 'Ġ.', 'ĠSORTTYPE_TTOT', 'Ġ,', 'Ġlimit', 'Ġ=', 'Ġ30', 'Ġ,', 'Ġthread_stats_on', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "SAMPLE_EXTRACT_METRICS_PAGE = os . path . join ( datadir , "monthly_download" ) \n"
Original    (013): ['SAMPLE_EXTRACT_METRICS_PAGE', '=', 'os', '.', 'path', '.', 'join', '(', 'datadir', ',', '"monthly_download"', ')', '\\n']
Tokenized   (035): ['<s>', 'SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['SAMPLE_EXTRACT_METRICS_PAGE', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdatadir', 'Ġ,', 'Ġ"monthly_download"', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH = os . path . join ( datadir , "monthly_download_different_month" \n"
Original    (012): ['SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', '=', 'os', '.', 'path', '.', 'join', '(', 'datadir', ',', '"monthly_download_different_month"', '\\n']
Tokenized   (046): ['<s>', 'SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '_', 'different', '_', 'month', '"', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '_', 'different', '_', 'month', '"', 'Ġ\\', 'n']
Detokenized (012): ['SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdatadir', 'Ġ,', 'Ġ"monthly_download_different_month"', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "testitem_aliases = ( "pmid" , TEST_PMID ) \n"
Original    (008): ['testitem_aliases', '=', '(', '"pmid"', ',', 'TEST_PMID', ')', '\\n']
Tokenized   (021): ['<s>', 'test', 'item', '_', 'ali', 'ases', 'Ġ=', 'Ġ(', 'Ġ"', 'pm', 'id', '"', 'Ġ,', 'ĠTEST', '_', 'PM', 'ID', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['test', 'item', '_', 'ali', 'ases', 'Ġ=', 'Ġ(', 'Ġ"', 'pm', 'id', '"', 'Ġ,', 'ĠTEST', '_', 'PM', 'ID', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['testitem_aliases', 'Ġ=', 'Ġ(', 'Ġ"pmid"', 'Ġ,', 'ĠTEST_PMID', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sample_data_dump = open ( SAMPLE_EXTRACT_METRICS_PAGE , "r" ) . read ( ) \n"
Original    (013): ['sample_data_dump', '=', 'open', '(', 'SAMPLE_EXTRACT_METRICS_PAGE', ',', '"r"', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (034): ['<s>', 'sample', '_', 'data', '_', 'dump', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['sample', '_', 'data', '_', 'dump', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['sample_data_dump', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAMPLE_EXTRACT_METRICS_PAGE', 'Ġ,', 'Ġ"r"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sample_data_dump_different_month = open ( SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH , "r" ) . read \n"
Original    (011): ['sample_data_dump_different_month', '=', 'open', '(', 'SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', ',', '"r"', ')', '.', 'read', '\\n']
Tokenized   (044): ['<s>', 'sample', '_', 'data', '_', 'dump', '_', 'different', '_', 'month', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['sample', '_', 'data', '_', 'dump', '_', 'different', '_', 'month', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ\\', 'n']
Detokenized (011): ['sample_data_dump_different_month', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', 'Ġ,', 'Ġ"r"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""max_event_date" : "2012-01-31T07:34:01.126892" \n"
Original    (004): ['"max_event_date"', ':', '"2012-01-31T07:34:01.126892"', '\\n']
Tokenized   (029): ['<s>', '"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '01', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '01', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ\\', 'n']
Detokenized (004): ['"max_event_date"', 'Ġ:', 'Ġ"2012-01-31T07:34:01.126892"', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""_id" : "abc123" , \n"
Original    (005): ['"_id"', ':', '"abc123"', ',', '\\n']
Tokenized   (014): ['<s>', '"', '_', 'id', '"', 'Ġ:', 'Ġ"', 'abc', '123', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', '_', 'id', '"', 'Ġ:', 'Ġ"', 'abc', '123', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"_id"', 'Ġ:', 'Ġ"abc123"', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""raw" : "max_event_date" : "2012-10-31T07:34:01.126892" , \n"
Original    (007): ['"raw"', ':', '"max_event_date"', ':', '"2012-10-31T07:34:01.126892"', ',', '\\n']
Tokenized   (034): ['<s>', '"', 'raw', '"', 'Ġ:', 'Ġ"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '10', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['"', 'raw', '"', 'Ġ:', 'Ġ"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '10', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"raw"', 'Ġ:', 'Ġ"max_event_date"', 'Ġ:', 'Ġ"2012-10-31T07:34:01.126892"', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""23110252" \n"
Original    (002): ['"23110252"', '\\n']
Tokenized   (009): ['<s>', '"', '23', '110', '252', '"', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', '23', '110', '252', '"', 'Ġ\\', 'n']
Detokenized (002): ['"23110252"', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "cache_client = redis . from_url ( os . getenv ( "REDIS_URL" ) , REDIS_CACHE_DATABASE_NUMBER ) \n"
Original    (016): ['cache_client', '=', 'redis', '.', 'from_url', '(', 'os', '.', 'getenv', '(', '"REDIS_URL"', ')', ',', 'REDIS_CACHE_DATABASE_NUMBER', ')', '\\n']
Tokenized   (043): ['<s>', 'cache', '_', 'client', 'Ġ=', 'Ġred', 'is', 'Ġ.', 'Ġfrom', '_', 'url', 'Ġ(', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'RED', 'IS', '_', 'URL', '"', 'Ġ)', 'Ġ,', 'ĠRED', 'IS', '_', 'C', 'AC', 'HE', '_', 'D', 'AT', 'AB', 'ASE', '_', 'NUM', 'BER', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['cache', '_', 'client', 'Ġ=', 'Ġred', 'is', 'Ġ.', 'Ġfrom', '_', 'url', 'Ġ(', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'RED', 'IS', '_', 'URL', '"', 'Ġ)', 'Ġ,', 'ĠRED', 'IS', '_', 'C', 'AC', 'HE', '_', 'D', 'AT', 'AB', 'ASE', '_', 'NUM', 'BER', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['cache_client', 'Ġ=', 'Ġredis', 'Ġ.', 'Ġfrom_url', 'Ġ(', 'Ġos', 'Ġ.', 'Ġgetenv', 'Ġ(', 'Ġ"REDIS_URL"', 'Ġ)', 'Ġ,', 'ĠREDIS_CACHE_DATABASE_NUMBER', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "MAX_CACHE_SIZE_BYTES = 100 * 1000 * 1000 #100mb \n"
Original    (009): ['MAX_CACHE_SIZE_BYTES', '=', '100', '*', '1000', '*', '1000', '#100mb', '\\n']
Tokenized   (024): ['<s>', 'MAX', '_', 'C', 'AC', 'HE', '_', 'SIZE', '_', 'BY', 'T', 'ES', 'Ġ=', 'Ġ100', 'Ġ*', 'Ġ1000', 'Ġ*', 'Ġ1000', 'Ġ#', '100', 'mb', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['MAX', '_', 'C', 'AC', 'HE', '_', 'SIZE', '_', 'BY', 'T', 'ES', 'Ġ=', 'Ġ100', 'Ġ*', 'Ġ1000', 'Ġ*', 'Ġ1000', 'Ġ#', '100', 'mb', 'Ġ\\', 'n']
Detokenized (009): ['MAX_CACHE_SIZE_BYTES', 'Ġ=', 'Ġ100', 'Ġ*', 'Ġ1000', 'Ġ*', 'Ġ1000', 'Ġ#100mb', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "set_response = mc . set ( hash_key , json . dumps ( data ) ) \n"
Original    (016): ['set_response', '=', 'mc', '.', 'set', '(', 'hash_key', ',', 'json', '.', 'dumps', '(', 'data', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'set', '_', 'response', 'Ġ=', 'Ġmc', 'Ġ.', 'Ġset', 'Ġ(', 'Ġhash', '_', 'key', 'Ġ,', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġdata', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['set', '_', 'response', 'Ġ=', 'Ġmc', 'Ġ.', 'Ġset', 'Ġ(', 'Ġhash', '_', 'key', 'Ġ,', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġdata', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['set_response', 'Ġ=', 'Ġmc', 'Ġ.', 'Ġset', 'Ġ(', 'Ġhash_key', 'Ġ,', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġdata', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "metrics_url_template = "http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key=" provenance_url_template = "http://dx.doi.org/%s" \n"
Original    (007): ['metrics_url_template', '=', '"http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key="', 'provenance_url_template', '=', '"http://dx.doi.org/%s"', '\\n']
Tokenized   (063): ['<s>', 'met', 'rics', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'alm', '.', 'pl', 'os', '.', 'org', '/', 'api', '/', 'v', '3', '/', 'articles', '?', 'ids', '=', '%', 's', '&', 'source', '=', 'c', 'itations', ',', 'counter', '&', 'api', '_', 'key', '="', 'Ġproven', 'ance', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'dx', '.', 'doi', '.', 'org', '/', '%', 's', '"', 'Ġ\\', 'n', '</s>']
Filtered   (061): ['met', 'rics', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'alm', '.', 'pl', 'os', '.', 'org', '/', 'api', '/', 'v', '3', '/', 'articles', '?', 'ids', '=', '%', 's', '&', 'source', '=', 'c', 'itations', ',', 'counter', '&', 'api', '_', 'key', '="', 'Ġproven', 'ance', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'dx', '.', 'doi', '.', 'org', '/', '%', 's', '"', 'Ġ\\', 'n']
Detokenized (007): ['metrics_url_template', 'Ġ=', 'Ġ"http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key="', 'Ġprovenance_url_template', 'Ġ=', 'Ġ"http://dx.doi.org/%s"', 'Ġ\\n']
Counter: 61
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "relevant = ( ( "doi" == namespace ) and ( "10.1371/" in nid ) ) \n"
Original    (016): ['relevant', '=', '(', '(', '"doi"', '==', 'namespace', ')', 'and', '(', '"10.1371/"', 'in', 'nid', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'relevant', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ"', 'doi', '"', 'Ġ==', 'Ġnamespace', 'Ġ)', 'Ġand', 'Ġ(', 'Ġ"', '10', '.', '13', '71', '/"', 'Ġin', 'Ġn', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['relevant', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ"', 'doi', '"', 'Ġ==', 'Ġnamespace', 'Ġ)', 'Ġand', 'Ġ(', 'Ġ"', '10', '.', '13', '71', '/"', 'Ġin', 'Ġn', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['relevant', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ"doi"', 'Ġ==', 'Ġnamespace', 'Ġ)', 'Ġand', 'Ġ(', 'Ġ"10.1371/"', 'Ġin', 'Ġnid', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "this_article = json_response [ 0 ] [ "sources" ] [ 0 ] [ "metrics" ] \n"
Original    (016): ['this_article', '=', 'json_response', '[', '0', ']', '[', '"sources"', ']', '[', '0', ']', '[', '"metrics"', ']', '\\n']
Tokenized   (029): ['<s>', 'this', '_', 'article', 'Ġ=', 'Ġjson', '_', 'response', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 's', 'ources', '"', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 'met', 'rics', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['this', '_', 'article', 'Ġ=', 'Ġjson', '_', 'response', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 's', 'ources', '"', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 'met', 'rics', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['this_article', 'Ġ=', 'Ġjson_response', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"sources"', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"metrics"', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "redis_url = os . environ . get ( , "redis://127.0.0.1:6379/" ) \n"
Original    (012): ['redis_url', '=', 'os', '.', 'environ', '.', 'get', '(', ',', '"redis://127.0.0.1:6379/"', ')', '\\n']
Tokenized   (033): ['<s>', 'red', 'is', '_', 'url', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ"', 'red', 'is', '://', '127', '.', '0', '.', '0', '.', '1', ':', '6', '379', '/"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['red', 'is', '_', 'url', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ"', 'red', 'is', '://', '127', '.', '0', '.', '0', '.', '1', ':', '6', '379', '/"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['redis_url', 'Ġ=', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ"redis://127.0.0.1:6379/"', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Queue ( , routing_key = ) \n"
Original    (007): ['Queue', '(', ',', 'routing_key', '=', ')', '\\n']
Tokenized   (012): ['<s>', 'Queue', 'Ġ(', 'Ġ,', 'Ġrouting', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Queue', 'Ġ(', 'Ġ,', 'Ġrouting', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['Queue', 'Ġ(', 'Ġ,', 'Ġrouting_key', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "CELERY_ACCEPT_CONTENT = [ , ] \n"
Original    (006): ['CELERY_ACCEPT_CONTENT', '=', '[', ',', ']', '\\n']
Tokenized   (017): ['<s>', 'C', 'EL', 'ERY', '_', 'AC', 'CEPT', '_', 'CONT', 'ENT', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['C', 'EL', 'ERY', '_', 'AC', 'CEPT', '_', 'CONT', 'ENT', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['CELERY_ACCEPT_CONTENT', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "CELERY_IMPORTS = ( "core_tasks" , ) \n"
Original    (007): ['CELERY_IMPORTS', '=', '(', '"core_tasks"', ',', ')', '\\n']
Tokenized   (021): ['<s>', 'C', 'EL', 'ERY', '_', 'IM', 'P', 'ORTS', 'Ġ=', 'Ġ(', 'Ġ"', 'core', '_', 't', 'asks', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['C', 'EL', 'ERY', '_', 'IM', 'P', 'ORTS', 'Ġ=', 'Ġ(', 'Ġ"', 'core', '_', 't', 'asks', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['CELERY_IMPORTS', 'Ġ=', 'Ġ(', 'Ġ"core_tasks"', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "sampledir = os . path . join ( os . path . split ( __file__ ) [ 0 ] , "../../../extras/sample_provider_pages/" ) \n"
Original    (023): ['sampledir', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'split', '(', '__file__', ')', '[', '0', ']', ',', '"../../../extras/sample_provider_pages/"', ')', '\\n']
Tokenized   (043): ['<s>', 'sam', 'pled', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ"', '../', '../', '../', 'ext', 'ras', '/', 'sample', '_', 'prov', 'ider', '_', 'pages', '/"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['sam', 'pled', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ"', '../', '../', '../', 'ext', 'ras', '/', 'sample', '_', 'prov', 'ider', '_', 'pages', '/"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['sampledir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ"../../../extras/sample_provider_pages/"', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "TEST_XML = open ( os . path . join ( sampledir , "facebook" , "metrics" ) ) . read ( ) \n"
Original    (022): ['TEST_XML', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'sampledir', ',', '"facebook"', ',', '"metrics"', ')', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (035): ['<s>', 'T', 'EST', '_', 'X', 'ML', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġsampled', 'ir', 'Ġ,', 'Ġ"', 'facebook', '"', 'Ġ,', 'Ġ"', 'met', 'rics', '"', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['T', 'EST', '_', 'X', 'ML', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġsampled', 'ir', 'Ġ,', 'Ġ"', 'facebook', '"', 'Ġ,', 'Ġ"', 'met', 'rics', '"', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['TEST_XML', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġsampledir', 'Ġ,', 'Ġ"facebook"', 'Ġ,', 'Ġ"metrics"', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "provider_names = [ provider . __class__ . __name__ for provider in providers ] \n"
Original    (014): ['provider_names', '=', '[', 'provider', '.', '__class__', '.', '__name__', 'for', 'provider', 'in', 'providers', ']', '\\n']
Tokenized   (024): ['<s>', 'prov', 'ider', '_', 'names', 'Ġ=', 'Ġ[', 'Ġprovider', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġfor', 'Ġprovider', 'Ġin', 'Ġproviders', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['prov', 'ider', '_', 'names', 'Ġ=', 'Ġ[', 'Ġprovider', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġfor', 'Ġprovider', 'Ġin', 'Ġproviders', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['provider_names', 'Ġ=', 'Ġ[', 'Ġprovider', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġfor', 'Ġprovider', 'Ġin', 'Ġproviders', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "assert_equals ( md [ "pubmed" ] [ ] , ) \n"
Original    (011): ['assert_equals', '(', 'md', '[', '"pubmed"', ']', '[', ']', ',', ')', '\\n']
Tokenized   (020): ['<s>', 'assert', '_', 'equ', 'als', 'Ġ(', 'Ġmd', 'Ġ[', 'Ġ"', 'pub', 'med', '"', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['assert', '_', 'equ', 'als', 'Ġ(', 'Ġmd', 'Ġ[', 'Ġ"', 'pub', 'med', '"', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['assert_equals', 'Ġ(', 'Ġmd', 'Ġ[', 'Ġ"pubmed"', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tiid = db . Column ( db . Text , db . ForeignKey ( ) , primary_key = True ) \n"
Original    (021): ['tiid', '=', 'db', '.', 'Column', '(', 'db', '.', 'Text', ',', 'db', '.', 'ForeignKey', '(', ')', ',', 'primary_key', '=', 'True', ')', '\\n']
Tokenized   (028): ['<s>', 'ti', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠText', 'Ġ,', 'Ġdb', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['ti', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠText', 'Ġ,', 'Ġdb', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['tiid', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠText', 'Ġ,', 'Ġdb', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġprimary_key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "tweet_ids_with_response = [ tweet [ "id_str" ] for tweet in data ] \n"
Original    (013): ['tweet_ids_with_response', '=', '[', 'tweet', '[', '"id_str"', ']', 'for', 'tweet', 'in', 'data', ']', '\\n']
Tokenized   (027): ['<s>', 't', 'weet', '_', 'ids', '_', 'with', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ[', 'Ġ"', 'id', '_', 'str', '"', 'Ġ]', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġdata', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['t', 'weet', '_', 'ids', '_', 'with', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ[', 'Ġ"', 'id', '_', 'str', '"', 'Ġ]', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġdata', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['tweet_ids_with_response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ[', 'Ġ"id_str"', 'Ġ]', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġdata', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "tweet_ids_without_response = [ tweet for tweet in tweet_ids if tweet not in tweet_ids_with_response flag_deleted_tweets ( tweet_ids_without_response ) \n"
Original    (018): ['tweet_ids_without_response', '=', '[', 'tweet', 'for', 'tweet', 'in', 'tweet_ids', 'if', 'tweet', 'not', 'in', 'tweet_ids_with_response', 'flag_deleted_tweets', '(', 'tweet_ids_without_response', ')', '\\n']
Tokenized   (049): ['<s>', 't', 'weet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweet', '_', 'ids', 'Ġif', 'Ġtweet', 'Ġnot', 'Ġin', 'Ġtweet', '_', 'ids', '_', 'with', '_', 'response', 'Ġflag', '_', 'de', 'leted', '_', 't', 'we', 'ets', 'Ġ(', 'Ġtweet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (047): ['t', 'weet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweet', '_', 'ids', 'Ġif', 'Ġtweet', 'Ġnot', 'Ġin', 'Ġtweet', '_', 'ids', '_', 'with', '_', 'response', 'Ġflag', '_', 'de', 'leted', '_', 't', 'we', 'ets', 'Ġ(', 'Ġtweet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['tweet_ids_without_response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweet_ids', 'Ġif', 'Ġtweet', 'Ġnot', 'Ġin', 'Ġtweet_ids_with_response', 'Ġflag_deleted_tweets', 'Ġ(', 'Ġtweet_ids_without_response', 'Ġ)', 'Ġ\\n']
Counter: 47
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "access_token = os . getenv ( "TWITTER_ACCESS_TOKEN" ) \n"
Original    (009): ['access_token', '=', 'os', '.', 'getenv', '(', '"TWITTER_ACCESS_TOKEN"', ')', '\\n']
Tokenized   (025): ['<s>', 'access', '_', 'token', 'Ġ=', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'TW', 'IT', 'TER', '_', 'ACC', 'ESS', '_', 'TO', 'KEN', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['access', '_', 'token', 'Ġ=', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'TW', 'IT', 'TER', '_', 'ACC', 'ESS', '_', 'TO', 'KEN', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['access_token', 'Ġ=', 'Ġos', 'Ġ.', 'Ġgetenv', 'Ġ(', 'Ġ"TWITTER_ACCESS_TOKEN"', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "num = len ( tweets ) ) ) \n"
Original    (009): ['num', '=', 'len', '(', 'tweets', ')', ')', ')', '\\n']
Tokenized   (012): ['<s>', 'num', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['num', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['num', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "list_of_groups = [ tweets [ i : i + group_size ] for i in range ( 0 , len ( tweets ) , group_size ) ] \n"
Original    (027): ['list_of_groups', '=', '[', 'tweets', '[', 'i', ':', 'i', '+', 'group_size', ']', 'for', 'i', 'in', 'range', '(', '0', ',', 'len', '(', 'tweets', ')', ',', 'group_size', ')', ']', '\\n']
Tokenized   (038): ['<s>', 'list', '_', 'of', '_', 'groups', 'Ġ=', 'Ġ[', 'Ġtweets', 'Ġ[', 'Ġi', 'Ġ:', 'Ġi', 'Ġ+', 'Ġgroup', '_', 'size', 'Ġ]', 'Ġfor', 'Ġi', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ,', 'Ġgroup', '_', 'size', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['list', '_', 'of', '_', 'groups', 'Ġ=', 'Ġ[', 'Ġtweets', 'Ġ[', 'Ġi', 'Ġ:', 'Ġi', 'Ġ+', 'Ġgroup', '_', 'size', 'Ġ]', 'Ġfor', 'Ġi', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ,', 'Ġgroup', '_', 'size', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (027): ['list_of_groups', 'Ġ=', 'Ġ[', 'Ġtweets', 'Ġ[', 'Ġi', 'Ġ:', 'Ġi', 'Ġ+', 'Ġgroup_size', 'Ġ]', 'Ġfor', 'Ġi', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ,', 'Ġgroup_size', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "handle_all_tweets ( response . data , tweet_subset ) \n"
Original    (009): ['handle_all_tweets', '(', 'response', '.', 'data', ',', 'tweet_subset', ')', '\\n']
Tokenized   (021): ['<s>', 'handle', '_', 'all', '_', 't', 'we', 'ets', 'Ġ(', 'Ġresponse', 'Ġ.', 'Ġdata', 'Ġ,', 'Ġtweet', '_', 'sub', 'set', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['handle', '_', 'all', '_', 't', 'we', 'ets', 'Ġ(', 'Ġresponse', 'Ġ.', 'Ġdata', 'Ġ,', 'Ġtweet', '_', 'sub', 'set', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['handle_all_tweets', 'Ġ(', 'Ġresponse', 'Ġ.', 'Ġdata', 'Ġ,', 'Ġtweet_subset', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "tweets = Tweet . query . filter ( Tweet . profile_id == profile_id ) \n"
Original    (015): ['tweets', '=', 'Tweet', '.', 'query', '.', 'filter', '(', 'Tweet', '.', 'profile_id', '==', 'profile_id', ')', '\\n']
Tokenized   (024): ['<s>', 't', 'we', 'ets', 'Ġ=', 'ĠTweet', 'Ġ.', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'ĠTweet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ==', 'Ġprofile', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', 'we', 'ets', 'Ġ=', 'ĠTweet', 'Ġ.', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'ĠTweet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ==', 'Ġprofile', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['tweets', 'Ġ=', 'ĠTweet', 'Ġ.', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'ĠTweet', 'Ġ.', 'Ġprofile_id', 'Ġ==', 'Ġprofile_id', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tweet_dict = dict ( [ ( ( tweet . tweet_id , tweet . tiid ) , tweet ) for tweet in tweets ] ) \n"
Original    (025): ['tweet_dict', '=', 'dict', '(', '[', '(', '(', 'tweet', '.', 'tweet_id', ',', 'tweet', '.', 'tiid', ')', ',', 'tweet', ')', 'for', 'tweet', 'in', 'tweets', ']', ')', '\\n']
Tokenized   (034): ['<s>', 't', 'weet', '_', 'dict', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġ(', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġtweet', 'Ġ.', 'Ġti', 'id', 'Ġ)', 'Ġ,', 'Ġtweet', 'Ġ)', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['t', 'weet', '_', 'dict', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġ(', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġtweet', 'Ġ.', 'Ġti', 'id', 'Ġ)', 'Ġ,', 'Ġtweet', 'Ġ)', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['tweet_dict', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġ(', 'Ġtweet', 'Ġ.', 'Ġtweet_id', 'Ġ,', 'Ġtweet', 'Ġ.', 'Ġtiid', 'Ġ)', 'Ġ,', 'Ġtweet', 'Ġ)', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "tweet . profile_id = profile_id \n"
Original    (006): ['tweet', '.', 'profile_id', '=', 'profile_id', '\\n']
Tokenized   (014): ['<s>', 't', 'weet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ=', 'Ġprofile', '_', 'id', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['t', 'weet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ=', 'Ġprofile', '_', 'id', 'Ġ\\', 'n']
Detokenized (006): ['tweet', 'Ġ.', 'Ġprofile_id', 'Ġ=', 'Ġprofile_id', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tweet_ids = [ tweet . tweet_id for tweet in tweets_to_hydrate_from_twitter ] \n"
Original    (012): ['tweet_ids', '=', '[', 'tweet', '.', 'tweet_id', 'for', 'tweet', 'in', 'tweets_to_hydrate_from_twitter', ']', '\\n']
Tokenized   (029): ['<s>', 't', 'weet', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', '_', 'to', '_', 'hyd', 'rate', '_', 'from', '_', 'twitter', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['t', 'weet', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', '_', 'to', '_', 'hyd', 'rate', '_', 'from', '_', 'twitter', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['tweet_ids', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ.', 'Ġtweet_id', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets_to_hydrate_from_twitter', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "display_url = url_info [ "display_url" ] \n"
Original    (007): ['display_url', '=', 'url_info', '[', '"display_url"', ']', '\\n']
Tokenized   (018): ['<s>', 'display', '_', 'url', 'Ġ=', 'Ġurl', '_', 'info', 'Ġ[', 'Ġ"', 'display', '_', 'url', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['display', '_', 'url', 'Ġ=', 'Ġurl', '_', 'info', 'Ġ[', 'Ġ"', 'display', '_', 'url', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['display_url', 'Ġ=', 'Ġurl_info', 'Ġ[', 'Ġ"display_url"', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "tweet_id = self . tweet_id , \n"
Original    (007): ['tweet_id', '=', 'self', '.', 'tweet_id', ',', '\\n']
Tokenized   (015): ['<s>', 't', 'weet', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['t', 'weet', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['tweet_id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtweet_id', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "file_loc = os . path . dirname ( os . path . realpath ( __file__ ) ) \n"
Original    (018): ['file_loc', '=', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'realpath', '(', '__file__', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'file', '_', 'loc', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['file', '_', 'loc', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['file_loc', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġrealpath', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "urllib . urlretrieve ( url + fname , fname ) \n"
Original    (011): ['urllib', '.', 'urlretrieve', '(', 'url', '+', 'fname', ',', 'fname', ')', '\\n']
Tokenized   (020): ['<s>', 'ur', 'll', 'ib', 'Ġ.', 'Ġurl', 'ret', 'rieve', 'Ġ(', 'Ġurl', 'Ġ+', 'Ġf', 'name', 'Ġ,', 'Ġf', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['ur', 'll', 'ib', 'Ġ.', 'Ġurl', 'ret', 'rieve', 'Ġ(', 'Ġurl', 'Ġ+', 'Ġf', 'name', 'Ġ,', 'Ġf', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['urllib', 'Ġ.', 'Ġurlretrieve', 'Ġ(', 'Ġurl', 'Ġ+', 'Ġfname', 'Ġ,', 'Ġfname', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) \n"
Original    (019): ['loaded', '=', 'np', '.', 'fromstring', '(', 'fd', '.', 'read', '(', ')', ',', 'dtype', '=', 'np', '.', 'uint8', ')', '\\n']
Tokenized   (026): ['<s>', 'loaded', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġfrom', 'string', 'Ġ(', 'Ġf', 'd', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġuint', '8', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['loaded', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġfrom', 'string', 'Ġ(', 'Ġf', 'd', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġuint', '8', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['loaded', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġfromstring', 'Ġ(', 'Ġfd', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġuint8', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "fd = gzip . open ( os . path . join ( data_dir , ) ) \n"
Original    (017): ['fd', '=', 'gzip', '.', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'data_dir', ',', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'fd', 'Ġ=', 'Ġg', 'zip', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['fd', 'Ġ=', 'Ġg', 'zip', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['fd', 'Ġ=', 'Ġgzip', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdata_dir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "trY = loaded [ 8 : ] . reshape ( ( 60000 ) ) \n"
Original    (015): ['trY', '=', 'loaded', '[', '8', ':', ']', '.', 'reshape', '(', '(', '60000', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'tr', 'Y', 'Ġ=', 'Ġloaded', 'Ġ[', 'Ġ8', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ6', '0000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['tr', 'Y', 'Ġ=', 'Ġloaded', 'Ġ[', 'Ġ8', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ6', '0000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['trY', 'Ġ=', 'Ġloaded', 'Ġ[', 'Ġ8', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġ(', 'Ġ60000', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "trX = trX . reshape ( - 1 , 28 , 28 ) \n"
Original    (014): ['trX', '=', 'trX', '.', 'reshape', '(', '-', '1', ',', '28', ',', '28', ')', '\\n']
Tokenized   (020): ['<s>', 'tr', 'X', 'Ġ=', 'Ġtr', 'X', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ28', 'Ġ,', 'Ġ28', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['tr', 'X', 'Ġ=', 'Ġtr', 'X', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ28', 'Ġ,', 'Ġ28', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['trX', 'Ġ=', 'ĠtrX', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ28', 'Ġ,', 'Ġ28', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dirpath = os . path . join ( self . repo . path , "unused_directory" ) \n"
Original    (017): ['dirpath', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'repo', '.', 'path', ',', '"unused_directory"', ')', '\\n']
Tokenized   (026): ['<s>', 'dir', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'un', 'used', '_', 'directory', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['dir', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'un', 'used', '_', 'directory', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['dirpath', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"unused_directory"', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "subpath = os . path . join ( self . repo . path , "a" , "b" , "c" ) \n"
Original    (021): ['subpath', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'repo', '.', 'path', ',', '"a"', ',', '"b"', ',', '"c"', ')', '\\n']
Tokenized   (031): ['<s>', 'sub', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['sub', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['subpath', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"a"', 'Ġ,', 'Ġ"b"', 'Ġ,', 'Ġ"c"', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "handle = self . profile . username , \n"
Original    (009): ['handle', '=', 'self', '.', 'profile', '.', 'username', ',', '\\n']
Tokenized   (012): ['<s>', 'handle', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprofile', 'Ġ.', 'Ġusername', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['handle', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprofile', 'Ġ.', 'Ġusername', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['handle', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprofile', 'Ġ.', 'Ġusername', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "id_key = ) \n"
Original    (004): ['id_key', '=', ')', '\\n']
Tokenized   (009): ['<s>', 'id', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['id', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['id_key', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "message_thread = model . MessageThread ( okc_id = self . thread . id , \n"
Original    (015): ['message_thread', '=', 'model', '.', 'MessageThread', '(', 'okc_id', '=', 'self', '.', 'thread', '.', 'id', ',', '\\n']
Tokenized   (024): ['<s>', 'message', '_', 'thread', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Thread', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['message', '_', 'thread', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Thread', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['message_thread', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessageThread', 'Ġ(', 'Ġokc_id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "new_messages = [ message for message in self . thread . messages \n"
Original    (013): ['new_messages', '=', '[', 'message', 'for', 'message', 'in', 'self', '.', 'thread', '.', 'messages', '\\n']
Tokenized   (019): ['<s>', 'new', '_', 'mess', 'ages', 'Ġ=', 'Ġ[', 'Ġmessage', 'Ġfor', 'Ġmessage', 'Ġin', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġmessages', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['new', '_', 'mess', 'ages', 'Ġ=', 'Ġ[', 'Ġmessage', 'Ġfor', 'Ġmessage', 'Ġin', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġmessages', 'Ġ\\', 'n']
Detokenized (013): ['new_messages', 'Ġ=', 'Ġ[', 'Ġmessage', 'Ġfor', 'Ġmessage', 'Ġin', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġmessages', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "new_message_model = model . Message ( okc_id = new_message . id , \n"
Original    (013): ['new_message_model', '=', 'model', '.', 'Message', '(', 'okc_id', '=', 'new_message', '.', 'id', ',', '\\n']
Tokenized   (025): ['<s>', 'new', '_', 'message', '_', 'model', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', '_', 'message', '_', 'model', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['new_message_model', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Ġ(', 'Ġokc_id', 'Ġ=', 'Ġnew_message', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "time_sent = new_message . time_sent ) \n"
Original    (007): ['time_sent', '=', 'new_message', '.', 'time_sent', ')', '\\n']
Tokenized   (016): ['<s>', 'time', '_', 'sent', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġtime', '_', 'sent', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['time', '_', 'sent', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġtime', '_', 'sent', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['time_sent', 'Ġ=', 'Ġnew_message', 'Ġ.', 'Ġtime_sent', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "mailbox . Sync ( user ) . all ( ) \n"
Original    (011): ['mailbox', '.', 'Sync', '(', 'user', ')', '.', 'all', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'mail', 'box', 'Ġ.', 'ĠSync', 'Ġ(', 'Ġuser', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['mail', 'box', 'Ġ.', 'ĠSync', 'Ġ(', 'Ġuser', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['mailbox', 'Ġ.', 'ĠSync', 'Ġ(', 'Ġuser', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "user_model . upsert_model ( id_key = ) \n"
Original    (008): ['user_model', '.', 'upsert_model', '(', 'id_key', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'user', '_', 'model', 'Ġ.', 'Ġups', 'ert', '_', 'model', 'Ġ(', 'Ġid', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['user', '_', 'model', 'Ġ.', 'Ġups', 'ert', '_', 'model', 'Ġ(', 'Ġid', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['user_model', 'Ġ.', 'Ġupsert_model', 'Ġ(', 'Ġid_key', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "response_dict = user . photo . upload_and_confirm ( user . quickmatch ( ) . photo_infos [ 0 ] ) \n"
Original    (020): ['response_dict', '=', 'user', '.', 'photo', '.', 'upload_and_confirm', '(', 'user', '.', 'quickmatch', '(', ')', '.', 'photo_infos', '[', '0', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'response', '_', 'dict', 'Ġ=', 'Ġuser', 'Ġ.', 'Ġphoto', 'Ġ.', 'Ġupload', '_', 'and', '_', 'conf', 'irm', 'Ġ(', 'Ġuser', 'Ġ.', 'Ġquick', 'match', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġphoto', '_', 'inf', 'os', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['response', '_', 'dict', 'Ġ=', 'Ġuser', 'Ġ.', 'Ġphoto', 'Ġ.', 'Ġupload', '_', 'and', '_', 'conf', 'irm', 'Ġ(', 'Ġuser', 'Ġ.', 'Ġquick', 'match', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġphoto', '_', 'inf', 'os', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['response_dict', 'Ġ=', 'Ġuser', 'Ġ.', 'Ġphoto', 'Ġ.', 'Ġupload_and_confirm', 'Ġ(', 'Ġuser', 'Ġ.', 'Ġquickmatch', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġphoto_infos', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "vcr_live_sleep ( 2 ) \n"
Original    (005): ['vcr_live_sleep', '(', '2', ')', '\\n']
Tokenized   (013): ['<s>', 'v', 'cr', '_', 'live', '_', 'sleep', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['v', 'cr', '_', 'live', '_', 'sleep', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['vcr_live_sleep', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "b2_h = shared_zeros ( ( self . hp . batch_size , n_h ) ) \n"
Original    (015): ['b2_h', '=', 'shared_zeros', '(', '(', 'self', '.', 'hp', '.', 'batch_size', ',', 'n_h', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'b', '2', '_', 'h', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġself', 'Ġ.', 'Ġhp', 'Ġ.', 'Ġbatch', '_', 'size', 'Ġ,', 'Ġn', '_', 'h', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['b', '2', '_', 'h', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġself', 'Ġ.', 'Ġhp', 'Ġ.', 'Ġbatch', '_', 'size', 'Ġ,', 'Ġn', '_', 'h', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['b2_h', 'Ġ=', 'Ġshared_zeros', 'Ġ(', 'Ġ(', 'Ġself', 'Ġ.', 'Ġhp', 'Ġ.', 'Ġbatch_size', 'Ġ,', 'Ġn_h', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "W1 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * 1.5 ) \n"
Original    (019): ['W1', '=', 'shared_normal', '(', '(', 'n_h', ',', 'n_h', '*', 'gates', ')', ',', 'scale', '=', 'scale', '*', '1.5', ')', '\\n']
Tokenized   (031): ['<s>', 'W', '1', 'Ġ=', 'Ġshared', '_', 'normal', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ,', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ,', 'Ġscale', 'Ġ=', 'Ġscale', 'Ġ*', 'Ġ1', '.', '5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['W', '1', 'Ġ=', 'Ġshared', '_', 'normal', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ,', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ,', 'Ġscale', 'Ġ=', 'Ġscale', 'Ġ*', 'Ġ1', '.', '5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['W1', 'Ġ=', 'Ġshared_normal', 'Ġ(', 'Ġ(', 'Ġn_h', 'Ġ,', 'Ġn_h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ,', 'Ġscale', 'Ġ=', 'Ġscale', 'Ġ*', 'Ġ1.5', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "b1 = shared_zeros ( ( n_h * gates ) ) \n"
Original    (011): ['b1', '=', 'shared_zeros', '(', '(', 'n_h', '*', 'gates', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'b', '1', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['b', '1', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['b1', 'Ġ=', 'Ġshared_zeros', 'Ġ(', 'Ġ(', 'Ġn_h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "b2 = shared_zeros ( ( n_h * gates , ) ) \n"
Original    (012): ['b2', '=', 'shared_zeros', '(', '(', 'n_h', '*', 'gates', ',', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'b', '2', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['b', '2', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['b2', 'Ġ=', 'Ġshared_zeros', 'Ġ(', 'Ġ(', 'Ġn_h', 'Ġ*', 'Ġgates', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "i_on = T . nnet . sigmoid ( g_on [ : , : n_h ] ) \n"
Original    (017): ['i_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', ':', 'n_h', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'i', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['i', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['i_on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġsigmoid', 'Ġ(', 'Ġg_on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "f_on = T . nnet . sigmoid ( g_on [ : , n_h : 2 * n_h ] ) \n"
Original    (020): ['f_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'f', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['f', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['f_on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġsigmoid', 'Ġ(', 'Ġg_on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "o_on = T . nnet . sigmoid ( g_on [ : , 2 * n_h : 3 * n_h ] ) \n"
Original    (022): ['o_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', '2', '*', 'n_h', ':', '3', '*', 'n_h', ']', ')', '\\n']
Tokenized   (036): ['<s>', 'o', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ3', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['o', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ3', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['o_on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġsigmoid', 'Ġ(', 'Ġg_on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ3', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "h_t = T . tanh ( T . dot ( X , W [ : , 1 * n_h : 2 * n_h ] ) + T . dot ( h , U [ : , 1 * n_h : 2 * n_h ] ) + b [ 1 * n_h : 2 * n_h ] ) \n"
Original    (058): ['h_t', '=', 'T', '.', 'tanh', '(', 'T', '.', 'dot', '(', 'X', ',', 'W', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 'T', '.', 'dot', '(', 'h', ',', 'U', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 'b', '[', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Tokenized   (076): ['<s>', 'h', '_', 't', 'Ġ=', 'ĠT', 'Ġ.', 'Ġtan', 'h', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠX', 'Ġ,', 'ĠW', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', 'Ġ,', 'ĠU', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'Ġb', 'Ġ[', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (074): ['h', '_', 't', 'Ġ=', 'ĠT', 'Ġ.', 'Ġtan', 'h', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠX', 'Ġ,', 'ĠW', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', 'Ġ,', 'ĠU', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'Ġb', 'Ġ[', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (058): ['h_t', 'Ġ=', 'ĠT', 'Ġ.', 'Ġtanh', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠX', 'Ġ,', 'ĠW', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ+', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', 'Ġ,', 'ĠU', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ+', 'Ġb', 'Ġ[', 'Ġ1', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 74
===================================================================
Hidden states:  (13, 58, 768)
# Extracted words:  58
Sentence         : "te_cost , te_h_updates = model ( self . X , self . params , 0. ) \n"
Original    (017): ['te_cost', ',', 'te_h_updates', '=', 'model', '(', 'self', '.', 'X', ',', 'self', '.', 'params', ',', '0.', ')', '\\n']
Tokenized   (028): ['<s>', 'te', '_', 'cost', 'Ġ,', 'Ġte', '_', 'h', '_', 'up', 'dates', 'Ġ=', 'Ġmodel', 'Ġ(', 'Ġself', 'Ġ.', 'ĠX', 'Ġ,', 'Ġself', 'Ġ.', 'Ġparams', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['te', '_', 'cost', 'Ġ,', 'Ġte', '_', 'h', '_', 'up', 'dates', 'Ġ=', 'Ġmodel', 'Ġ(', 'Ġself', 'Ġ.', 'ĠX', 'Ġ,', 'Ġself', 'Ġ.', 'Ġparams', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['te_cost', 'Ġ,', 'Ġte_h_updates', 'Ġ=', 'Ġmodel', 'Ġ(', 'Ġself', 'Ġ.', 'ĠX', 'Ġ,', 'Ġself', 'Ġ.', 'Ġparams', 'Ġ,', 'Ġ0.', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "csvWriter = csv . writer ( sys . stdout , delimiter = separator , quotechar = quote , \n"
Original    (019): ['csvWriter', '=', 'csv', '.', 'writer', '(', 'sys', '.', 'stdout', ',', 'delimiter', '=', 'separator', ',', 'quotechar', '=', 'quote', ',', '\\n']
Tokenized   (028): ['<s>', 'csv', 'Writer', 'Ġ=', 'Ġc', 'sv', 'Ġ.', 'Ġwriter', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġstd', 'out', 'Ġ,', 'Ġdelim', 'iter', 'Ġ=', 'Ġsepar', 'ator', 'Ġ,', 'Ġquote', 'char', 'Ġ=', 'Ġquote', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['csv', 'Writer', 'Ġ=', 'Ġc', 'sv', 'Ġ.', 'Ġwriter', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġstd', 'out', 'Ġ,', 'Ġdelim', 'iter', 'Ġ=', 'Ġsepar', 'ator', 'Ġ,', 'Ġquote', 'char', 'Ġ=', 'Ġquote', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['csvWriter', 'Ġ=', 'Ġcsv', 'Ġ.', 'Ġwriter', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġstdout', 'Ġ,', 'Ġdelimiter', 'Ġ=', 'Ġseparator', 'Ġ,', 'Ġquotechar', 'Ġ=', 'Ġquote', 'Ġ,', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "IColumnProvider_Methods = IPersist_Methods + [ "Initialize" , "GetColumnInfo" , "GetItemData" ] \n"
Original    (012): ['IColumnProvider_Methods', '=', 'IPersist_Methods', '+', '[', '"Initialize"', ',', '"GetColumnInfo"', ',', '"GetItemData"', ']', '\\n']
Tokenized   (035): ['<s>', 'IC', 'ol', 'umn', 'Provider', '_', 'Methods', 'Ġ=', 'ĠIP', 'ers', 'ist', '_', 'Methods', 'Ġ+', 'Ġ[', 'Ġ"', 'Initial', 'ize', '"', 'Ġ,', 'Ġ"', 'Get', 'Column', 'Info', '"', 'Ġ,', 'Ġ"', 'Get', 'Item', 'Data', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['IC', 'ol', 'umn', 'Provider', '_', 'Methods', 'Ġ=', 'ĠIP', 'ers', 'ist', '_', 'Methods', 'Ġ+', 'Ġ[', 'Ġ"', 'Initial', 'ize', '"', 'Ġ,', 'Ġ"', 'Get', 'Column', 'Info', '"', 'Ġ,', 'Ġ"', 'Get', 'Item', 'Data', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['IColumnProvider_Methods', 'Ġ=', 'ĠIPersist_Methods', 'Ġ+', 'Ġ[', 'Ġ"Initialize"', 'Ġ,', 'Ġ"GetColumnInfo"', 'Ġ,', 'Ġ"GetItemData"', 'Ġ]', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "_com_interfaces_ = [ pythoncom . IID_IPersist , \n"
Original    (008): ['_com_interfaces_', '=', '[', 'pythoncom', '.', 'IID_IPersist', ',', '\\n']
Tokenized   (022): ['<s>', '_', 'com', '_', 'inter', 'faces', '_', 'Ġ=', 'Ġ[', 'Ġpython', 'com', 'Ġ.', 'ĠI', 'ID', '_', 'IP', 'ers', 'ist', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'com', '_', 'inter', 'faces', '_', 'Ġ=', 'Ġ[', 'Ġpython', 'com', 'Ġ.', 'ĠI', 'ID', '_', 'IP', 'ers', 'ist', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['_com_interfaces_', 'Ġ=', 'Ġ[', 'Ġpythoncom', 'Ġ.', 'ĠIID_IPersist', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "20 , #cChars \n"
Original    (004): ['20', ',', '#cChars', '\\n']
Tokenized   (010): ['<s>', '20', 'Ġ,', 'Ġ#', 'c', 'Ch', 'ars', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['20', 'Ġ,', 'Ġ#', 'c', 'Ch', 'ars', 'Ġ\\', 'n']
Detokenized (004): ['20', 'Ġ,', 'Ġ#cChars', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "fmt_id == self . _reg_clsid_ \n"
Original    (006): ['fmt_id', '==', 'self', '.', '_reg_clsid_', '\\n']
Tokenized   (017): ['<s>', 'f', 'mt', '_', 'id', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['f', 'mt', '_', 'id', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ\\', 'n']
Detokenized (006): ['fmt_id', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ_reg_clsid_', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : ""Folder\\\\ShellEx\\\\ColumnHandlers\\\\" + str ( ColumnProvider . _reg_clsid_ ) ) \n"
Original    (010): ['"Folder\\\\\\\\ShellEx\\\\\\\\ColumnHandlers\\\\\\\\"', '+', 'str', '(', 'ColumnProvider', '.', '_reg_clsid_', ')', ')', '\\n']
Tokenized   (029): ['<s>', '"', 'Folder', '\\\\\\\\', 'Shell', 'Ex', '\\\\\\\\', 'Column', 'Hand', 'lers', '\\\\\\\\', '"', 'Ġ+', 'Ġstr', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['"', 'Folder', '\\\\\\\\', 'Shell', 'Ex', '\\\\\\\\', 'Column', 'Hand', 'lers', '\\\\\\\\', '"', 'Ġ+', 'Ġstr', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['"Folder\\\\\\\\ShellEx\\\\\\\\ColumnHandlers\\\\\\\\"', 'Ġ+', 'Ġstr', 'Ġ(', 'ĠColumnProvider', 'Ġ.', 'Ġ_reg_clsid_', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_winreg . SetValueEx ( key , None , 0 , _winreg . REG_SZ , ColumnProvider . _reg_desc_ ) \n"
Original    (019): ['_winreg', '.', 'SetValueEx', '(', 'key', ',', 'None', ',', '0', ',', '_winreg', '.', 'REG_SZ', ',', 'ColumnProvider', '.', '_reg_desc_', ')', '\\n']
Tokenized   (036): ['<s>', '_', 'win', 'reg', 'Ġ.', 'ĠSet', 'Value', 'Ex', 'Ġ(', 'Ġkey', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ_', 'win', 'reg', 'Ġ.', 'ĠREG', '_', 'S', 'Z', 'Ġ,', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'desc', '_', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['_', 'win', 'reg', 'Ġ.', 'ĠSet', 'Value', 'Ex', 'Ġ(', 'Ġkey', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ_', 'win', 'reg', 'Ġ.', 'ĠREG', '_', 'S', 'Z', 'Ġ,', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'desc', '_', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['_winreg', 'Ġ.', 'ĠSetValueEx', 'Ġ(', 'Ġkey', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ_winreg', 'Ġ.', 'ĠREG_SZ', 'Ġ,', 'ĠColumnProvider', 'Ġ.', 'Ġ_reg_desc_', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "register . UseCommandLine ( ColumnProvider , \n"
Original    (007): ['register', '.', 'UseCommandLine', '(', 'ColumnProvider', ',', '\\n']
Tokenized   (013): ['<s>', 'register', 'Ġ.', 'ĠUse', 'Command', 'Line', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['register', 'Ġ.', 'ĠUse', 'Command', 'Line', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['register', 'Ġ.', 'ĠUseCommandLine', 'Ġ(', 'ĠColumnProvider', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "aliases = MultipleValueField ( required = False ) \n"
Original    (009): ['aliases', '=', 'MultipleValueField', '(', 'required', '=', 'False', ')', '\\n']
Tokenized   (015): ['<s>', 'ali', 'ases', 'Ġ=', 'ĠMultiple', 'Value', 'Field', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ali', 'ases', 'Ġ=', 'ĠMultiple', 'Value', 'Field', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['aliases', 'Ġ=', 'ĠMultipleValueField', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "StoredQueryParameter = namedtuple ( "StoredQueryParameter" , ( , , , , \n"
Original    (012): ['StoredQueryParameter', '=', 'namedtuple', '(', '"StoredQueryParameter"', ',', '(', ',', ',', ',', ',', '\\n']
Tokenized   (025): ['<s>', 'St', 'ored', 'Query', 'Parameter', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'St', 'ored', 'Query', 'Parameter', '"', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['St', 'ored', 'Query', 'Parameter', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'St', 'ored', 'Query', 'Parameter', '"', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['StoredQueryParameter', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ"StoredQueryParameter"', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fts = list ( self . models . keys ( ) ) \n"
Original    (013): ['fts', '=', 'list', '(', 'self', '.', 'models', '.', 'keys', '(', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'fts', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġself', 'Ġ.', 'Ġmodels', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['fts', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġself', 'Ġ.', 'Ġmodels', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['fts', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġself', 'Ġ.', 'Ġmodels', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sort_by = parms . cleaned_data [ ] \n"
Original    (008): ['sort_by', '=', 'parms', '.', 'cleaned_data', '[', ']', '\\n']
Tokenized   (016): ['<s>', 'sort', '_', 'by', 'Ġ=', 'Ġpar', 'ms', 'Ġ.', 'Ġcleaned', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['sort', '_', 'by', 'Ġ=', 'Ġpar', 'ms', 'Ġ.', 'Ġcleaned', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['sort_by', 'Ġ=', 'Ġparms', 'Ġ.', 'Ġcleaned_data', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "geometry_field = self . geometries [ type_names [ 0 ] ] \n"
Original    (012): ['geometry_field', '=', 'self', '.', 'geometries', '[', 'type_names', '[', '0', ']', ']', '\\n']
Tokenized   (022): ['<s>', 'ge', 'ometry', '_', 'field', 'Ġ=', 'Ġself', 'Ġ.', 'Ġge', 'omet', 'ries', 'Ġ[', 'Ġtype', '_', 'names', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['ge', 'ometry', '_', 'field', 'Ġ=', 'Ġself', 'Ġ.', 'Ġge', 'omet', 'ries', 'Ġ[', 'Ġtype', '_', 'names', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['geometry_field', 'Ġ=', 'Ġself', 'Ġ.', 'Ġgeometries', 'Ġ[', 'Ġtype_names', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mxy = mxy ) \n"
Original    (005): ['mxy', '=', 'mxy', ')', '\\n']
Tokenized   (010): ['<s>', 'm', 'xy', 'Ġ=', 'Ġm', 'xy', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['m', 'xy', 'Ġ=', 'Ġm', 'xy', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['mxy', 'Ġ=', 'Ġmxy', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "query_set = query_set . order_by ( * sort_by ) \n"
Original    (010): ['query_set', '=', 'query_set', '.', 'order_by', '(', '*', 'sort_by', ')', '\\n']
Tokenized   (021): ['<s>', 'query', '_', 'set', 'Ġ=', 'Ġquery', '_', 'set', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ*', 'Ġsort', '_', 'by', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['query', '_', 'set', 'Ġ=', 'Ġquery', '_', 'set', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ*', 'Ġsort', '_', 'by', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['query_set', 'Ġ=', 'Ġquery_set', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ*', 'Ġsort_by', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "output_format = root . get ( , ) \n"
Original    (009): ['output_format', '=', 'root', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (014): ['<s>', 'output', '_', 'format', 'Ġ=', 'Ġroot', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['output', '_', 'format', 'Ġ=', 'Ġroot', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['output_format', 'Ġ=', 'Ġroot', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "type_names . append ( ( namespace , name ) ) \n"
Original    (011): ['type_names', '.', 'append', '(', '(', 'namespace', ',', 'name', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'type', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġnamespace', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['type', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġnamespace', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['type_names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġnamespace', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""schema" : feature_type . schema , \n"
Original    (007): ['"schema"', ':', 'feature_type', '.', 'schema', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'sche', 'ma', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġschema', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'sche', 'ma', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġschema', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"schema"', 'Ġ:', 'Ġfeature_type', 'Ġ.', 'Ġschema', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""ns_name" : feature_type . ns_name \n"
Original    (006): ['"ns_name"', ':', 'feature_type', '.', 'ns_name', '\\n']
Tokenized   (017): ['<s>', '"', 'ns', '_', 'name', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġns', '_', 'name', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['"', 'ns', '_', 'name', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġns', '_', 'name', 'Ġ\\', 'n']
Detokenized (006): ['"ns_name"', 'Ġ:', 'Ġfeature_type', 'Ġ.', 'Ġns_name', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "db_params = settings . DATABASES [ response . db ] \n"
Original    (011): ['db_params', '=', 'settings', '.', 'DATABASES', '[', 'response', '.', 'db', ']', '\\n']
Tokenized   (020): ['<s>', 'db', '_', 'params', 'Ġ=', 'Ġsettings', 'Ġ.', 'ĠD', 'AT', 'AB', 'AS', 'ES', 'Ġ[', 'Ġresponse', 'Ġ.', 'Ġdb', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['db', '_', 'params', 'Ġ=', 'Ġsettings', 'Ġ.', 'ĠD', 'AT', 'AB', 'AS', 'ES', 'Ġ[', 'Ġresponse', 'Ġ.', 'Ġdb', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['db_params', 'Ġ=', 'Ġsettings', 'Ġ.', 'ĠDATABASES', 'Ġ[', 'Ġresponse', 'Ġ.', 'Ġdb', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "parameters = tuple ( [ adapt ( p ) for p in parameters ] ) \n"
Original    (016): ['parameters', '=', 'tuple', '(', '[', 'adapt', '(', 'p', ')', 'for', 'p', 'in', 'parameters', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'param', 'eters', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġ[', 'Ġadapt', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġparameters', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['param', 'eters', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġ[', 'Ġadapt', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġparameters', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['parameters', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġ[', 'Ġadapt', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġparameters', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "connection_string = "PG:dbname=\'{db}\'" . format ( db = db_params [ ] ) \n"
Original    (013): ['connection_string', '=', '"PG:dbname=\\\'{db}\\\'"', '.', 'format', '(', 'db', '=', 'db_params', '[', ']', ')', '\\n']
Tokenized   (030): ['<s>', 'connection', '_', 'string', 'Ġ=', 'Ġ"', 'PG', ':', 'db', 'name', '=', "\\'", '{', 'db', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġdb', 'Ġ=', 'Ġdb', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['connection', '_', 'string', 'Ġ=', 'Ġ"', 'PG', ':', 'db', 'name', '=', "\\'", '{', 'db', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġdb', 'Ġ=', 'Ġdb', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['connection_string', 'Ġ=', 'Ġ"PG:dbname=\\\'{db}\\\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġdb', 'Ġ=', 'Ġdb_params', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "etree . SubElement ( p , ) . text = parameter . abstractS \n"
Original    (014): ['etree', '.', 'SubElement', '(', 'p', ',', ')', '.', 'text', '=', 'parameter', '.', 'abstractS', '\\n']
Tokenized   (020): ['<s>', 'et', 'ree', 'Ġ.', 'ĠSub', 'Element', 'Ġ(', 'Ġp', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġabstract', 'S', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['et', 'ree', 'Ġ.', 'ĠSub', 'Element', 'Ġ(', 'Ġp', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġabstract', 'S', 'Ġ\\', 'n']
Detokenized (014): ['etree', 'Ġ.', 'ĠSubElement', 'Ġ(', 'Ġp', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'ĠabstractS', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""isPrivate" : parameter . query_expression . private == True , \n"
Original    (011): ['"isPrivate"', ':', 'parameter', '.', 'query_expression', '.', 'private', '==', 'True', ',', '\\n']
Tokenized   (019): ['<s>', '"', 'is', 'Private', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġprivate', 'Ġ==', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['"', 'is', 'Private', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġprivate', 'Ġ==', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"isPrivate"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġprivate', 'Ġ==', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""language" : parameter . query_expression . language , \n"
Original    (009): ['"language"', ':', 'parameter', '.', 'query_expression', '.', 'language', ',', '\\n']
Tokenized   (016): ['<s>', '"', 'language', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġlanguage', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['"', 'language', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġlanguage', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"language"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġlanguage', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""returnFeatureTypes" : . join ( parameter . query_expression . return_feature_types } ) . text = parameter . query_expression . text \n"
Original    (021): ['"returnFeatureTypes"', ':', '.', 'join', '(', 'parameter', '.', 'query_expression', '.', 'return_feature_types', '}', ')', '.', 'text', '=', 'parameter', '.', 'query_expression', '.', 'text', '\\n']
Tokenized   (036): ['<s>', '"', 'return', 'Feature', 'Types', '"', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġreturn', '_', 'feature', '_', 'types', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġtext', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['"', 'return', 'Feature', 'Types', '"', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġreturn', '_', 'feature', '_', 'types', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġtext', 'Ġ\\', 'n']
Detokenized (021): ['"returnFeatureTypes"', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġreturn_feature_types', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġtext', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : ""endpoint" : request . build_absolute_uri ( ) . split ( ) [ 0 ] , \n"
Original    (016): ['"endpoint"', ':', 'request', '.', 'build_absolute_uri', '(', ')', '.', 'split', '(', ')', '[', '0', ']', ',', '\\n']
Tokenized   (026): ['<s>', '"', 'end', 'point', '"', 'Ġ:', 'Ġrequest', 'Ġ.', 'Ġbuild', '_', 'absolute', '_', 'uri', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', 'end', 'point', '"', 'Ġ:', 'Ġrequest', 'Ġ.', 'Ġbuild', '_', 'absolute', '_', 'uri', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['"endpoint"', 'Ġ:', 'Ġrequest', 'Ġ.', 'Ġbuild_absolute_uri', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""output_formats" : [ ogr . GetDriver ( drv ) . GetName ( ) for drv in range ( ogr . GetDriverCount ( ) ) "addr_street" : self . addr_street , \n"
Original    (031): ['"output_formats"', ':', '[', 'ogr', '.', 'GetDriver', '(', 'drv', ')', '.', 'GetName', '(', ')', 'for', 'drv', 'in', 'range', '(', 'ogr', '.', 'GetDriverCount', '(', ')', ')', '"addr_street"', ':', 'self', '.', 'addr_street', ',', '\\n']
Tokenized   (053): ['<s>', '"', 'output', '_', 'form', 'ats', '"', 'Ġ:', 'Ġ[', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Ġ(', 'Ġdr', 'v', 'Ġ)', 'Ġ.', 'ĠGet', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġdr', 'v', 'Ġin', 'Ġrange', 'Ġ(', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Count', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ"', 'addr', '_', 'street', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġaddr', '_', 'street', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (051): ['"', 'output', '_', 'form', 'ats', '"', 'Ġ:', 'Ġ[', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Ġ(', 'Ġdr', 'v', 'Ġ)', 'Ġ.', 'ĠGet', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġdr', 'v', 'Ġin', 'Ġrange', 'Ġ(', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Count', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ"', 'addr', '_', 'street', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġaddr', '_', 'street', 'Ġ,', 'Ġ\\', 'n']
Detokenized (031): ['"output_formats"', 'Ġ:', 'Ġ[', 'Ġogr', 'Ġ.', 'ĠGetDriver', 'Ġ(', 'Ġdrv', 'Ġ)', 'Ġ.', 'ĠGetName', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġdrv', 'Ġin', 'Ġrange', 'Ġ(', 'Ġogr', 'Ġ.', 'ĠGetDriverCount', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ"addr_street"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġaddr_street', 'Ġ,', 'Ġ\\n']
Counter: 51
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : ""feature_versioning" : self . adapter . supports_feature_versioning ( ) , \n"
Original    (011): ['"feature_versioning"', ':', 'self', '.', 'adapter', '.', 'supports_feature_versioning', '(', ')', ',', '\\n']
Tokenized   (024): ['<s>', '"', 'feature', '_', 'version', 'ing', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġadapter', 'Ġ.', 'Ġsupports', '_', 'feature', '_', 'version', 'ing', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'feature', '_', 'version', 'ing', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġadapter', 'Ġ.', 'Ġsupports', '_', 'feature', '_', 'version', 'ing', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"feature_versioning"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġadapter', 'Ġ.', 'Ġsupports_feature_versioning', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""date" : datetime . now ( ) , \n"
Original    (009): ['"date"', ':', 'datetime', '.', 'now', '(', ')', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'date', '"', 'Ġ:', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'date', '"', 'Ġ:', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"date"', 'Ġ:', 'Ġdatetime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "matchItem . setText ( 3 , unicode ( self . data [ "Matches" ] ) ) \n"
Original    (017): ['matchItem', '.', 'setText', '(', '3', ',', 'unicode', '(', 'self', '.', 'data', '[', '"Matches"', ']', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'match', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġself', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ"', 'Mat', 'ches', '"', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['match', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġself', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ"', 'Mat', 'ches', '"', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['matchItem', 'Ġ.', 'ĠsetText', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunicode', 'Ġ(', 'Ġself', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ"Matches"', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "roundItem . setText ( 3 , unicode ( opponent [ 2 ] ) ) \n"
Original    (015): ['roundItem', '.', 'setText', '(', '3', ',', 'unicode', '(', 'opponent', '[', '2', ']', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'round', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġopponent', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['round', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġopponent', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['roundItem', 'Ġ.', 'ĠsetText', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunicode', 'Ġ(', 'Ġopponent', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "opponent [ 3 ] = roundItem \n"
Original    (007): ['opponent', '[', '3', ']', '=', 'roundItem', '\\n']
Tokenized   (012): ['<s>', 'opp', 'onent', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ=', 'Ġround', 'Item', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['opp', 'onent', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ=', 'Ġround', 'Item', 'Ġ\\', 'n']
Detokenized (007): ['opponent', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ=', 'ĠroundItem', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "M = np . matrix ( [ [ 2 , 3 , 4 ] , \n"
Original    (016): ['M', '=', 'np', '.', 'matrix', '(', '[', '[', '2', ',', '3', ',', '4', ']', ',', '\\n']
Tokenized   (019): ['<s>', 'M', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmatrix', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['M', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmatrix', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['M', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmatrix', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "matrix = Matrix ( M , mtype = ) \n"
Original    (010): ['matrix', '=', 'Matrix', '(', 'M', ',', 'mtype', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'mat', 'rix', 'Ġ=', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ,', 'Ġm', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['mat', 'rix', 'Ġ=', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ,', 'Ġm', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['matrix', 'Ġ=', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ,', 'Ġmtype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "math = Math ( data = [ , vec_name , , Matrix ( M * a ) ] ) \n"
Original    (020): ['math', '=', 'Math', '(', 'data', '=', '[', ',', 'vec_name', ',', ',', 'Matrix', '(', 'M', '*', 'a', ')', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'math', 'Ġ=', 'ĠMath', 'Ġ(', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġvec', '_', 'name', 'Ġ,', 'Ġ,', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ*', 'Ġa', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['math', 'Ġ=', 'ĠMath', 'Ġ(', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġvec', '_', 'name', 'Ġ,', 'Ġ,', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ*', 'Ġa', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['math', 'Ġ=', 'ĠMath', 'Ġ(', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġvec_name', 'Ġ,', 'Ġ,', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ*', 'Ġa', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "q2 = Quantity ( v , format_cb = lambda x : str ( int ( x ) ) ) \n"
Original    (020): ['q2', '=', 'Quantity', '(', 'v', ',', 'format_cb', '=', 'lambda', 'x', ':', 'str', '(', 'int', '(', 'x', ')', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'q', '2', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġformat', '_', 'cb', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['q', '2', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġformat', '_', 'cb', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['q2', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġformat_cb', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "q3 = Quantity ( v , options = { : } ) \n"
Original    (013): ['q3', '=', 'Quantity', '(', 'v', ',', 'options', '=', '{', ':', '}', ')', '\\n']
Tokenized   (017): ['<s>', 'q', '3', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġoptions', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['q', '3', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġoptions', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['q3', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġoptions', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "test_dimensionality_to_siunitx ( ) \n"
Original    (004): ['test_dimensionality_to_siunitx', '(', ')', '\\n']
Tokenized   (016): ['<s>', 'test', '_', 'dimension', 'ality', '_', 'to', '_', 'si', 'unit', 'x', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['test', '_', 'dimension', 'ality', '_', 'to', '_', 'si', 'unit', 'x', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['test_dimensionality_to_siunitx', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "ph = put_handler . put_handler ( fs , ) \n"
Original    (010): ['ph', '=', 'put_handler', '.', 'put_handler', '(', 'fs', ',', ')', '\\n']
Tokenized   (017): ['<s>', 'ph', 'Ġ=', 'Ġput', '_', 'handler', 'Ġ.', 'Ġput', '_', 'handler', 'Ġ(', 'Ġfs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['ph', 'Ġ=', 'Ġput', '_', 'handler', 'Ġ.', 'Ġput', '_', 'handler', 'Ġ(', 'Ġfs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['ph', 'Ġ=', 'Ġput_handler', 'Ġ.', 'Ġput_handler', 'Ġ(', 'Ġfs', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "hs = http_server . http_server ( ip = , port = 8080 ) \n"
Original    (014): ['hs', '=', 'http_server', '.', 'http_server', '(', 'ip', '=', ',', 'port', '=', '8080', ')', '\\n']
Tokenized   (022): ['<s>', 'hs', 'Ġ=', 'Ġhttp', '_', 'server', 'Ġ.', 'Ġhttp', '_', 'server', 'Ġ(', 'Ġip', 'Ġ=', 'Ġ,', 'Ġport', 'Ġ=', 'Ġ80', '80', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['hs', 'Ġ=', 'Ġhttp', '_', 'server', 'Ġ.', 'Ġhttp', '_', 'server', 'Ġ(', 'Ġip', 'Ġ=', 'Ġ,', 'Ġport', 'Ġ=', 'Ġ80', '80', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['hs', 'Ġ=', 'Ġhttp_server', 'Ġ.', 'Ġhttp_server', 'Ġ(', 'Ġip', 'Ġ=', 'Ġ,', 'Ġport', 'Ġ=', 'Ġ8080', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "num_trans = num_requests * num_conns \n"
Original    (006): ['num_trans', '=', 'num_requests', '*', 'num_conns', '\\n']
Tokenized   (017): ['<s>', 'num', '_', 'trans', 'Ġ=', 'Ġnum', '_', 'requ', 'ests', 'Ġ*', 'Ġnum', '_', 'con', 'ns', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['num', '_', 'trans', 'Ġ=', 'Ġnum', '_', 'requ', 'ests', 'Ġ*', 'Ġnum', '_', 'con', 'ns', 'Ġ\\', 'n']
Detokenized (006): ['num_trans', 'Ġ=', 'Ġnum_requests', 'Ġ*', 'Ġnum_conns', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "trans_per_sec = num_trans / total_time \n"
Original    (006): ['trans_per_sec', '=', 'num_trans', '/', 'total_time', '\\n']
Tokenized   (017): ['<s>', 'trans', '_', 'per', '_', 'sec', 'Ġ=', 'Ġnum', '_', 'trans', 'Ġ/', 'Ġtotal', '_', 'time', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['trans', '_', 'per', '_', 'sec', 'Ġ=', 'Ġnum', '_', 'trans', 'Ġ/', 'Ġtotal', '_', 'time', 'Ġ\\', 'n']
Detokenized (006): ['trans_per_sec', 'Ġ=', 'Ġnum_trans', 'Ġ/', 'Ġtotal_time', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "map ( str , ( num_conns , num_requests , request_size , throughput , trans_per_sec ) \n"
Original    (016): ['map', '(', 'str', ',', '(', 'num_conns', ',', 'num_requests', ',', 'request_size', ',', 'throughput', ',', 'trans_per_sec', ')', '\\n']
Tokenized   (031): ['<s>', 'map', 'Ġ(', 'Ġstr', 'Ġ,', 'Ġ(', 'Ġnum', '_', 'con', 'ns', 'Ġ,', 'Ġnum', '_', 'requ', 'ests', 'Ġ,', 'Ġrequest', '_', 'size', 'Ġ,', 'Ġthroughput', 'Ġ,', 'Ġtrans', '_', 'per', '_', 'sec', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['map', 'Ġ(', 'Ġstr', 'Ġ,', 'Ġ(', 'Ġnum', '_', 'con', 'ns', 'Ġ,', 'Ġnum', '_', 'requ', 'ests', 'Ġ,', 'Ġrequest', '_', 'size', 'Ġ,', 'Ġthroughput', 'Ġ,', 'Ġtrans', '_', 'per', '_', 'sec', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['map', 'Ġ(', 'Ġstr', 'Ġ,', 'Ġ(', 'Ġnum_conns', 'Ġ,', 'Ġnum_requests', 'Ġ,', 'Ġrequest_size', 'Ġ,', 'Ġthroughput', 'Ġ,', 'Ġtrans_per_sec', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "queue . add_task ( task , 3 ) \n"
Original    (009): ['queue', '.', 'add_task', '(', 'task', ',', '3', ')', '\\n']
Tokenized   (014): ['<s>', 'queue', 'Ġ.', 'Ġadd', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['queue', 'Ġ.', 'Ġadd', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['queue', 'Ġ.', 'Ġadd_task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "futures . append ( queue . yield_task ( task , 3 ) ) \n"
Original    (014): ['futures', '.', 'append', '(', 'queue', '.', 'yield_task', '(', 'task', ',', '3', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'f', 'ut', 'ures', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġqueue', 'Ġ.', 'Ġyield', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['f', 'ut', 'ures', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġqueue', 'Ġ.', 'Ġyield', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['futures', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġqueue', 'Ġ.', 'Ġyield_task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "task_results [ : ] = res \n"
Original    (007): ['task_results', '[', ':', ']', '=', 'res', '\\n']
Tokenized   (012): ['<s>', 'task', '_', 'results', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġres', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['task', '_', 'results', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġres', 'Ġ\\', 'n']
Detokenized (007): ['task_results', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġres', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "shuffle ( self . __queued_servers ) \n"
Original    (007): ['shuffle', '(', 'self', '.', '__queued_servers', ')', '\\n']
Tokenized   (016): ['<s>', 'sh', 'uffle', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'que', 'ued', '_', 'ser', 'vers', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['sh', 'uffle', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'que', 'ued', '_', 'ser', 'vers', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['shuffle', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__queued_servers', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "event_name = event [ ] \n"
Original    (006): ['event_name', '=', 'event', '[', ']', '\\n']
Tokenized   (011): ['<s>', 'event', '_', 'name', 'Ġ=', 'Ġevent', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['event', '_', 'name', 'Ġ=', 'Ġevent', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['event_name', 'Ġ=', 'Ġevent', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "event_data = zlib . compress ( pickle . dumps ( event ) ) \n"
Original    (014): ['event_data', '=', 'zlib', '.', 'compress', '(', 'pickle', '.', 'dumps', '(', 'event', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'event', '_', 'data', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'Ġcompress', 'Ġ(', 'Ġpick', 'le', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġevent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['event', '_', 'data', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'Ġcompress', 'Ġ(', 'Ġpick', 'le', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġevent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['event_data', 'Ġ=', 'Ġzlib', 'Ġ.', 'Ġcompress', 'Ġ(', 'Ġpickle', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġevent', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "path_only , query = self . _split_path ( path ) \n"
Original    (011): ['path_only', ',', 'query', '=', 'self', '.', '_split_path', '(', 'path', ')', '\\n']
Tokenized   (019): ['<s>', 'path', '_', 'only', 'Ġ,', 'Ġquery', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'split', '_', 'path', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['path', '_', 'only', 'Ġ,', 'Ġquery', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'split', '_', 'path', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['path_only', 'Ġ,', 'Ġquery', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_split_path', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "break ; \n"
Original    (003): ['break', ';', '\\n']
Tokenized   (006): ['<s>', 'break', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (004): ['break', 'Ġ;', 'Ġ\\', 'n']
Detokenized (003): ['break', 'Ġ;', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "u . email = user [ 2 ] \n"
Original    (009): ['u', '.', 'email', '=', 'user', '[', '2', ']', '\\n']
Tokenized   (012): ['<s>', 'u', 'Ġ.', 'Ġemail', 'Ġ=', 'Ġuser', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['u', 'Ġ.', 'Ġemail', 'Ġ=', 'Ġuser', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['u', 'Ġ.', 'Ġemail', 'Ġ=', 'Ġuser', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "trac_components = list ( [ ] ) \n"
Original    (008): ['trac_components', '=', 'list', '(', '[', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'tr', 'ac', '_', 'comp', 'onents', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['tr', 'ac', '_', 'comp', 'onents', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['trac_components', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "component . owner = self . _get_user_login ( component . owner ) \n"
Original    (013): ['component', '.', 'owner', '=', 'self', '.', '_get_user_login', '(', 'component', '.', 'owner', ')', '\\n']
Tokenized   (021): ['<s>', 'component', 'Ġ.', 'Ġowner', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'user', '_', 'login', 'Ġ(', 'Ġcomponent', 'Ġ.', 'Ġowner', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['component', 'Ġ.', 'Ġowner', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'user', '_', 'login', 'Ġ(', 'Ġcomponent', 'Ġ.', 'Ġowner', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['component', 'Ġ.', 'Ġowner', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_get_user_login', 'Ġ(', 'Ġcomponent', 'Ġ.', 'Ġowner', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "networks [ pkt . pduSource ] . append ( pkt . wirtnNetwork ) \n"
Original    (014): ['networks', '[', 'pkt', '.', 'pduSource', ']', '.', 'append', '(', 'pkt', '.', 'wirtnNetwork', ')', '\\n']
Tokenized   (025): ['<s>', 'net', 'works', 'Ġ[', 'Ġp', 'kt', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġp', 'kt', 'Ġ.', 'Ġw', 'irt', 'n', 'Network', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['net', 'works', 'Ġ[', 'Ġp', 'kt', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġp', 'kt', 'Ġ.', 'Ġw', 'irt', 'n', 'Network', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['networks', 'Ġ[', 'Ġpkt', 'Ġ.', 'ĠpduSource', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġpkt', 'Ġ.', 'ĠwirtnNetwork', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "filterSource = Address ( sys . argv [ i + 1 ] ) \n"
Original    (014): ['filterSource', '=', 'Address', '(', 'sys', '.', 'argv', '[', 'i', '+', '1', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'filter', 'Source', 'Ġ=', 'ĠAddress', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['filter', 'Source', 'Ġ=', 'ĠAddress', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['filterSource', 'Ġ=', 'ĠAddress', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "net_count . sort ( lambda x , y : cmp ( y [ 1 ] , x [ 1 ] ) ) \n"
Original    (023): ['net_count', '.', 'sort', '(', 'lambda', 'x', ',', 'y', ':', 'cmp', '(', 'y', '[', '1', ']', ',', 'x', '[', '1', ']', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'net', '_', 'count', 'Ġ.', 'Ġsort', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ,', 'Ġy', 'Ġ:', 'Ġc', 'mp', 'Ġ(', 'Ġy', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['net', '_', 'count', 'Ġ.', 'Ġsort', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ,', 'Ġy', 'Ġ:', 'Ġc', 'mp', 'Ġ(', 'Ġy', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['net_count', 'Ġ.', 'Ġsort', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ,', 'Ġy', 'Ġ:', 'Ġcmp', 'Ġ(', 'Ġy', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "strm = StringIO ( self . pickleBuffer ) \n"
Original    (009): ['strm', '=', 'StringIO', '(', 'self', '.', 'pickleBuffer', ')', '\\n']
Tokenized   (016): ['<s>', 'str', 'm', 'Ġ=', 'ĠString', 'IO', 'Ġ(', 'Ġself', 'Ġ.', 'Ġpick', 'le', 'Buffer', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['str', 'm', 'Ġ=', 'ĠString', 'IO', 'Ġ(', 'Ġself', 'Ġ.', 'Ġpick', 'le', 'Buffer', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['strm', 'Ġ=', 'ĠStringIO', 'Ġ(', 'Ġself', 'Ġ.', 'ĠpickleBuffer', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pdu . pduSource = self . peer \n"
Original    (008): ['pdu', '.', 'pduSource', '=', 'self', '.', 'peer', '\\n']
Tokenized   (014): ['<s>', 'p', 'du', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ=', 'Ġself', 'Ġ.', 'Ġpeer', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['p', 'du', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ=', 'Ġself', 'Ġ.', 'Ġpeer', 'Ġ\\', 'n']
Detokenized (008): ['pdu', 'Ġ.', 'ĠpduSource', 'Ġ=', 'Ġself', 'Ġ.', 'Ġpeer', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "connect_task . install_task ( _time ( ) + self . reconnect [ actor . peer ] ) \n"
Original    (018): ['connect_task', '.', 'install_task', '(', '_time', '(', ')', '+', 'self', '.', 'reconnect', '[', 'actor', '.', 'peer', ']', ')', '\\n']
Tokenized   (026): ['<s>', 'connect', '_', 'task', 'Ġ.', 'Ġinstall', '_', 'task', 'Ġ(', 'Ġ_', 'time', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġreconnect', 'Ġ[', 'Ġactor', 'Ġ.', 'Ġpeer', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['connect', '_', 'task', 'Ġ.', 'Ġinstall', '_', 'task', 'Ġ(', 'Ġ_', 'time', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġreconnect', 'Ġ[', 'Ġactor', 'Ġ.', 'Ġpeer', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['connect_task', 'Ġ.', 'Ġinstall_task', 'Ġ(', 'Ġ_time', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġreconnect', 'Ġ[', 'Ġactor', 'Ġ.', 'Ġpeer', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "asyncore . dispatcher . __init__ ( self , sock ) \n"
Original    (011): ['asyncore', '.', 'dispatcher', '.', '__init__', '(', 'self', ',', 'sock', ')', '\\n']
Tokenized   (018): ['<s>', 'as', 'yn', 'core', 'Ġ.', 'Ġdispatcher', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġsock', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['as', 'yn', 'core', 'Ġ.', 'Ġdispatcher', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġsock', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['asyncore', 'Ġ.', 'Ġdispatcher', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġsock', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "TCPServerDirector . _warning ( , err ) \n"
Original    (008): ['TCPServerDirector', '.', '_warning', '(', ',', 'err', ')', '\\n']
Tokenized   (015): ['<s>', 'TC', 'PS', 'erver', 'Director', 'Ġ.', 'Ġ_', 'warning', 'Ġ(', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['TC', 'PS', 'erver', 'Director', 'Ġ.', 'Ġ_', 'warning', 'Ġ(', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['TCPServerDirector', 'Ġ.', 'Ġ_warning', 'Ġ(', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "buff = packet [ 1 ] \n"
Original    (007): ['buff', '=', 'packet', '[', '1', ']', '\\n']
Tokenized   (010): ['<s>', 'buff', 'Ġ=', 'Ġpacket', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['buff', 'Ġ=', 'Ġpacket', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['buff', 'Ġ=', 'Ġpacket', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "fileIdentifier = ( obj_type , obj_inst ) , \n"
Original    (009): ['fileIdentifier', '=', '(', 'obj_type', ',', 'obj_inst', ')', ',', '\\n']
Tokenized   (018): ['<s>', 'file', 'Ident', 'ifier', 'Ġ=', 'Ġ(', 'Ġobj', '_', 'type', 'Ġ,', 'Ġobj', '_', 'inst', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['file', 'Ident', 'ifier', 'Ġ=', 'Ġ(', 'Ġobj', '_', 'type', 'Ġ,', 'Ġobj', '_', 'inst', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['fileIdentifier', 'Ġ=', 'Ġ(', 'Ġobj_type', 'Ġ,', 'Ġobj_inst', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "record_data = list ( args [ 4 : ] ) \n"
Original    (011): ['record_data', '=', 'list', '(', 'args', '[', '4', ':', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'record', '_', 'data', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ4', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['record', '_', 'data', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ4', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['record_data', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ4', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "accessMethod = AtomicWriteFileRequestAccessMethodChoice ( \n"
Original    (005): ['accessMethod', '=', 'AtomicWriteFileRequestAccessMethodChoice', '(', '\\n']
Tokenized   (015): ['<s>', 'access', 'Method', 'Ġ=', 'ĠAtomic', 'Write', 'File', 'Request', 'Access', 'Method', 'Choice', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['access', 'Method', 'Ġ=', 'ĠAtomic', 'Write', 'File', 'Request', 'Access', 'Method', 'Choice', 'Ġ(', 'Ġ\\', 'n']
Detokenized (005): ['accessMethod', 'Ġ=', 'ĠAtomicWriteFileRequestAccessMethodChoice', 'Ġ(', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "objectIdentifier = int ( args . ini . objectidentifier ) , \n"
Original    (012): ['objectIdentifier', '=', 'int', '(', 'args', '.', 'ini', '.', 'objectidentifier', ')', ',', '\\n']
Tokenized   (020): ['<s>', 'object', 'Ident', 'ifier', 'Ġ=', 'Ġint', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġobject', 'ident', 'ifier', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['object', 'Ident', 'ifier', 'Ġ=', 'Ġint', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġobject', 'ident', 'ifier', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['objectIdentifier', 'Ġ=', 'Ġint', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġini', 'Ġ.', 'Ġobjectidentifier', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "this_application = TestApplication ( this_device , args . ini . address ) \n"
Original    (013): ['this_application', '=', 'TestApplication', '(', 'this_device', ',', 'args', '.', 'ini', '.', 'address', ')', '\\n']
Tokenized   (022): ['<s>', 'this', '_', 'application', 'Ġ=', 'ĠTest', 'Application', 'Ġ(', 'Ġthis', '_', 'device', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġaddress', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['this', '_', 'application', 'Ġ=', 'ĠTest', 'Application', 'Ġ(', 'Ġthis', '_', 'device', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġaddress', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['this_application', 'Ġ=', 'ĠTestApplication', 'Ġ(', 'Ġthis_device', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġini', 'Ġ.', 'Ġaddress', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_log . debug ( "running" ) \n"
Original    (007): ['_log', '.', 'debug', '(', '"running"', ')', '\\n']
Tokenized   (013): ['<s>', '_', 'log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ"', 'running', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['_', 'log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ"', 'running', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['_log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ"running"', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Status . FAILED_TO_ADD_TO_CLIENT : % ( COLOR_FAILED_TO_ADD_TO_CLIENT , Color . ENDC ) , \n"
Original    (014): ['Status', '.', 'FAILED_TO_ADD_TO_CLIENT', ':', '%', '(', 'COLOR_FAILED_TO_ADD_TO_CLIENT', ',', 'Color', '.', 'ENDC', ')', ',', '\\n']
Tokenized   (043): ['<s>', 'Status', 'Ġ.', 'ĠFA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ:', 'Ġ%', 'Ġ(', 'ĠCOL', 'OR', '_', 'FA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ,', 'ĠColor', 'Ġ.', 'ĠEND', 'C', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['Status', 'Ġ.', 'ĠFA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ:', 'Ġ%', 'Ġ(', 'ĠCOL', 'OR', '_', 'FA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ,', 'ĠColor', 'Ġ.', 'ĠEND', 'C', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['Status', 'Ġ.', 'ĠFAILED_TO_ADD_TO_CLIENT', 'Ġ:', 'Ġ%', 'Ġ(', 'ĠCOLOR_FAILED_TO_ADD_TO_CLIENT', 'Ġ,', 'ĠColor', 'Ġ.', 'ĠENDC', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "end_size += f [ ] \n"
Original    (006): ['end_size', '+=', 'f', '[', ']', '\\n']
Tokenized   (011): ['<s>', 'end', '_', 'size', 'Ġ+=', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['end', '_', 'size', 'Ġ+=', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['end_size', 'Ġ+=', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "files_to_check += self . db . find_hash_varying_size ( f [ ] ) \n"
Original    (013): ['files_to_check', '+=', 'self', '.', 'db', '.', 'find_hash_varying_size', '(', 'f', '[', ']', ')', '\\n']
Tokenized   (028): ['<s>', 'files', '_', 'to', '_', 'check', 'Ġ+=', 'Ġself', 'Ġ.', 'Ġdb', 'Ġ.', 'Ġfind', '_', 'hash', '_', 'v', 'ary', 'ing', '_', 'size', 'Ġ(', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['files', '_', 'to', '_', 'check', 'Ġ+=', 'Ġself', 'Ġ.', 'Ġdb', 'Ġ.', 'Ġfind', '_', 'hash', '_', 'v', 'ary', 'ing', '_', 'size', 'Ġ(', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['files_to_check', 'Ġ+=', 'Ġself', 'Ġ.', 'Ġdb', 'Ġ.', 'Ġfind_hash_varying_size', 'Ġ(', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "match_start , match_end = pieces . match_file ( db_file , start_size , end_size ) \n"
Original    (015): ['match_start', ',', 'match_end', '=', 'pieces', '.', 'match_file', '(', 'db_file', ',', 'start_size', ',', 'end_size', ')', '\\n']
Tokenized   (030): ['<s>', 'match', '_', 'start', 'Ġ,', 'Ġmatch', '_', 'end', 'Ġ=', 'Ġpieces', 'Ġ.', 'Ġmatch', '_', 'file', 'Ġ(', 'Ġdb', '_', 'file', 'Ġ,', 'Ġstart', '_', 'size', 'Ġ,', 'Ġend', '_', 'size', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['match', '_', 'start', 'Ġ,', 'Ġmatch', '_', 'end', 'Ġ=', 'Ġpieces', 'Ġ.', 'Ġmatch', '_', 'file', 'Ġ(', 'Ġdb', '_', 'file', 'Ġ,', 'Ġstart', '_', 'size', 'Ġ,', 'Ġend', '_', 'size', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['match_start', 'Ġ,', 'Ġmatch_end', 'Ġ=', 'Ġpieces', 'Ġ.', 'Ġmatch_file', 'Ġ(', 'Ġdb_file', 'Ġ,', 'Ġstart_size', 'Ġ,', 'Ġend_size', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "path_files [ os . path . join ( * path ) ] . append ( { \n"
Original    (017): ['path_files', '[', 'os', '.', 'path', '.', 'join', '(', '*', 'path', ')', ']', '.', 'append', '(', '{', '\\n']
Tokenized   (022): ['<s>', 'path', '_', 'files', 'Ġ[', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ*', 'Ġpath', 'Ġ)', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['path', '_', 'files', 'Ġ[', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ*', 'Ġpath', 'Ġ)', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ\\', 'n']
Detokenized (017): ['path_files', 'Ġ[', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ*', 'Ġpath', 'Ġ)', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "files_sorted [ . join ( orig_path ) ] = i \n"
Original    (011): ['files_sorted', '[', '.', 'join', '(', 'orig_path', ')', ']', '=', 'i', '\\n']
Tokenized   (019): ['<s>', 'files', '_', 's', 'orted', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġorig', '_', 'path', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['files', '_', 's', 'orted', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġorig', '_', 'path', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n']
Detokenized (011): ['files_sorted', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġorig_path', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "found_size , missing_size = 0 , 0 \n"
Original    (008): ['found_size', ',', 'missing_size', '=', '0', ',', '0', '\\n']
Tokenized   (015): ['<s>', 'found', '_', 'size', 'Ġ,', 'Ġmissing', '_', 'size', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['found', '_', 'size', 'Ġ,', 'Ġmissing', '_', 'size', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ\\', 'n']
Detokenized (008): ['found_size', 'Ġ,', 'Ġmissing_size', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "output_fp . write ( * write_bytes ) \n"
Original    (008): ['output_fp', '.', 'write', '(', '*', 'write_bytes', ')', '\\n']
Tokenized   (015): ['<s>', 'output', '_', 'fp', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ*', 'Ġwrite', '_', 'bytes', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['output', '_', 'fp', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ*', 'Ġwrite', '_', 'bytes', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['output_fp', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ*', 'Ġwrite_bytes', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bytes_written += read_bytes \n"
Original    (004): ['bytes_written', '+=', 'read_bytes', '\\n']
Tokenized   (011): ['<s>', 'bytes', '_', 'written', 'Ġ+=', 'Ġread', '_', 'bytes', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['bytes', '_', 'written', 'Ġ+=', 'Ġread', '_', 'bytes', 'Ġ\\', 'n']
Detokenized (004): ['bytes_written', 'Ġ+=', 'Ġread_bytes', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "missing_percent = ( missing_size / ( found_size + missing_size ) ) * 100 \n"
Original    (014): ['missing_percent', '=', '(', 'missing_size', '/', '(', 'found_size', '+', 'missing_size', ')', ')', '*', '100', '\\n']
Tokenized   (025): ['<s>', 'missing', '_', 'percent', 'Ġ=', 'Ġ(', 'Ġmissing', '_', 'size', 'Ġ/', 'Ġ(', 'Ġfound', '_', 'size', 'Ġ+', 'Ġmissing', '_', 'size', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ100', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['missing', '_', 'percent', 'Ġ=', 'Ġ(', 'Ġmissing', '_', 'size', 'Ġ/', 'Ġ(', 'Ġfound', '_', 'size', 'Ġ+', 'Ġmissing', '_', 'size', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ100', 'Ġ\\', 'n']
Detokenized (014): ['missing_percent', 'Ġ=', 'Ġ(', 'Ġmissing_size', 'Ġ/', 'Ġ(', 'Ġfound_size', 'Ġ+', 'Ġmissing_size', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ100', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "found_percent = 100 - missing_percent \n"
Original    (006): ['found_percent', '=', '100', '-', 'missing_percent', '\\n']
Tokenized   (013): ['<s>', 'found', '_', 'percent', 'Ġ=', 'Ġ100', 'Ġ-', 'Ġmissing', '_', 'percent', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['found', '_', 'percent', 'Ġ=', 'Ġ100', 'Ġ-', 'Ġmissing', '_', 'percent', 'Ġ\\', 'n']
Detokenized (006): ['found_percent', 'Ġ=', 'Ġ100', 'Ġ-', 'Ġmissing_percent', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "would_not_add = missing_size and missing_percent > self . add_limit_percent or missing_size > \n"
Original    (013): ['would_not_add', '=', 'missing_size', 'and', 'missing_percent', '>', 'self', '.', 'add_limit_percent', 'or', 'missing_size', '>', '\\n']
Tokenized   (030): ['<s>', 'would', '_', 'not', '_', 'add', 'Ġ=', 'Ġmissing', '_', 'size', 'Ġand', 'Ġmissing', '_', 'percent', 'Ġ>', 'Ġself', 'Ġ.', 'Ġadd', '_', 'limit', '_', 'percent', 'Ġor', 'Ġmissing', '_', 'size', 'Ġ>', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['would', '_', 'not', '_', 'add', 'Ġ=', 'Ġmissing', '_', 'size', 'Ġand', 'Ġmissing', '_', 'percent', 'Ġ>', 'Ġself', 'Ġ.', 'Ġadd', '_', 'limit', '_', 'percent', 'Ġor', 'Ġmissing', '_', 'size', 'Ġ>', 'Ġ\\', 'n']
Detokenized (013): ['would_not_add', 'Ġ=', 'Ġmissing_size', 'Ġand', 'Ġmissing_percent', 'Ġ>', 'Ġself', 'Ġ.', 'Ġadd_limit_percent', 'Ġor', 'Ġmissing_size', 'Ġ>', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "LEGO_PALETTE = ( , , , , , , ) \n"
Original    (011): ['LEGO_PALETTE', '=', '(', ',', ',', ',', ',', ',', ',', ')', '\\n']
Tokenized   (020): ['<s>', 'LE', 'GO', '_', 'P', 'AL', 'ET', 'TE', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['LE', 'GO', '_', 'P', 'AL', 'ET', 'TE', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['LEGO_PALETTE', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Draft4Validator , RefResolver , create , extend , validator_for , validate , \n"
Original    (013): ['Draft4Validator', ',', 'RefResolver', ',', 'create', ',', 'extend', ',', 'validator_for', ',', 'validate', ',', '\\n']
Tokenized   (024): ['<s>', 'Draft', '4', 'Valid', 'ator', 'Ġ,', 'ĠRef', 'Res', 'olver', 'Ġ,', 'Ġcreate', 'Ġ,', 'Ġextend', 'Ġ,', 'Ġvalid', 'ator', '_', 'for', 'Ġ,', 'Ġvalidate', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['Draft', '4', 'Valid', 'ator', 'Ġ,', 'ĠRef', 'Res', 'olver', 'Ġ,', 'Ġcreate', 'Ġ,', 'Ġextend', 'Ġ,', 'Ġvalid', 'ator', '_', 'for', 'Ġ,', 'Ġvalidate', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['Draft4Validator', 'Ġ,', 'ĠRefResolver', 'Ġ,', 'Ġcreate', 'Ġ,', 'Ġextend', 'Ġ,', 'Ġvalidator_for', 'Ġ,', 'Ġvalidate', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "u"enum" : [ [ "a" , "b" , "c" ] , [ "d" , "e" , "f" ] ] , \n"
Original    (021): ['u"enum"', ':', '[', '[', '"a"', ',', '"b"', ',', '"c"', ']', ',', '[', '"d"', ',', '"e"', ',', '"f"', ']', ']', ',', '\\n']
Tokenized   (039): ['<s>', 'u', '"', 'enum', '"', 'Ġ:', 'Ġ[', 'Ġ[', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ"', 'd', '"', 'Ġ,', 'Ġ"', 'e', '"', 'Ġ,', 'Ġ"', 'f', '"', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['u', '"', 'enum', '"', 'Ġ:', 'Ġ[', 'Ġ[', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ"', 'd', '"', 'Ġ,', 'Ġ"', 'e', '"', 'Ġ,', 'Ġ"', 'f', '"', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (021): ['u"enum"', 'Ġ:', 'Ġ[', 'Ġ[', 'Ġ"a"', 'Ġ,', 'Ġ"b"', 'Ġ,', 'Ġ"c"', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ"d"', 'Ġ,', 'Ġ"e"', 'Ġ,', 'Ġ"f"', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "got = ( e . message for e in self . validator . iter_errors ( instance , schema ) ) \n"
Original    (021): ['got', '=', '(', 'e', '.', 'message', 'for', 'e', 'in', 'self', '.', 'validator', '.', 'iter_errors', '(', 'instance', ',', 'schema', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'got', 'Ġ=', 'Ġ(', 'Ġe', 'Ġ.', 'Ġmessage', 'Ġfor', 'Ġe', 'Ġin', 'Ġself', 'Ġ.', 'Ġvalid', 'ator', 'Ġ.', 'Ġiter', '_', 'errors', 'Ġ(', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['got', 'Ġ=', 'Ġ(', 'Ġe', 'Ġ.', 'Ġmessage', 'Ġfor', 'Ġe', 'Ġin', 'Ġself', 'Ġ.', 'Ġvalid', 'ator', 'Ġ.', 'Ġiter', '_', 'errors', 'Ġ(', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['got', 'Ġ=', 'Ġ(', 'Ġe', 'Ġ.', 'Ġmessage', 'Ġfor', 'Ġe', 'Ġin', 'Ġself', 'Ġ.', 'Ġvalidator', 'Ġ.', 'Ġiter_errors', 'Ġ(', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "checker . checks ( u"thing" ) ( check_fn ) \n"
Original    (010): ['checker', '.', 'checks', '(', 'u"thing"', ')', '(', 'check_fn', ')', '\\n']
Tokenized   (019): ['<s>', 'check', 'er', 'Ġ.', 'Ġchecks', 'Ġ(', 'Ġu', '"', 'thing', '"', 'Ġ)', 'Ġ(', 'Ġcheck', '_', 'fn', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['check', 'er', 'Ġ.', 'Ġchecks', 'Ġ(', 'Ġu', '"', 'thing', '"', 'Ġ)', 'Ġ(', 'Ġcheck', '_', 'fn', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['checker', 'Ġ.', 'Ġchecks', 'Ġ(', 'Ġu"thing"', 'Ġ)', 'Ġ(', 'Ġcheck_fn', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "deque ( [ "type" , 1 , "properties" , "foo" , "enum" ] ) , \n"
Original    (016): ['deque', '(', '[', '"type"', ',', '1', ',', '"properties"', ',', '"foo"', ',', '"enum"', ']', ')', ',', '\\n']
Tokenized   (028): ['<s>', 'de', 'que', 'Ġ(', 'Ġ[', 'Ġ"', 'type', '"', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ"', 'properties', '"', 'Ġ,', 'Ġ"', 'foo', '"', 'Ġ,', 'Ġ"', 'enum', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['de', 'que', 'Ġ(', 'Ġ[', 'Ġ"', 'type', '"', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ"', 'properties', '"', 'Ġ,', 'Ġ"', 'foo', '"', 'Ġ,', 'Ġ"', 'enum', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['deque', 'Ġ(', 'Ġ[', 'Ġ"type"', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ"properties"', 'Ġ,', 'Ġ"foo"', 'Ġ,', 'Ġ"enum"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""baz" : { "minItems" : 2 } , \n"
Original    (009): ['"baz"', ':', '{', '"minItems"', ':', '2', '}', ',', '\\n']
Tokenized   (018): ['<s>', '"', 'b', 'az', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'min', 'Items', '"', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'b', 'az', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'min', 'Items', '"', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"baz"', 'Ġ:', 'Ġ{', 'Ġ"minItems"', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""required" : [ "root" ] , \n"
Original    (007): ['"required"', ':', '[', '"root"', ']', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'required', '"', 'Ġ:', 'Ġ[', 'Ġ"', 'root', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'required', '"', 'Ġ:', 'Ġ[', 'Ġ"', 'root', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"required"', 'Ġ:', 'Ġ[', 'Ġ"root"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "e2 . absolute_schema_path , deque ( \n"
Original    (007): ['e2', '.', 'absolute_schema_path', ',', 'deque', '(', '\\n']
Tokenized   (017): ['<s>', 'e', '2', 'Ġ.', 'Ġabsolute', '_', 'sche', 'ma', '_', 'path', 'Ġ,', 'Ġde', 'que', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['e', '2', 'Ġ.', 'Ġabsolute', '_', 'sche', 'ma', '_', 'path', 'Ġ,', 'Ġde', 'que', 'Ġ(', 'Ġ\\', 'n']
Detokenized (007): ['e2', 'Ġ.', 'Ġabsolute_schema_path', 'Ġ,', 'Ġdeque', 'Ġ(', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""additionalProperties" : { "type" : "integer" , "minimum" : 5 } \n"
Original    (012): ['"additionalProperties"', ':', '{', '"type"', ':', '"integer"', ',', '"minimum"', ':', '5', '}', '\\n']
Tokenized   (026): ['<s>', '"', 'add', 'itional', 'Pro', 'perties', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'integer', '"', 'Ġ,', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', 'add', 'itional', 'Pro', 'perties', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'integer', '"', 'Ġ,', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n']
Detokenized (012): ['"additionalProperties"', 'Ġ:', 'Ġ{', 'Ġ"type"', 'Ġ:', 'Ġ"integer"', 'Ġ,', 'Ġ"minimum"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""bar" : { "type" : "string" } , \n"
Original    (009): ['"bar"', ':', '{', '"type"', ':', '"string"', '}', ',', '\\n']
Tokenized   (018): ['<s>', '"', 'bar', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'string', '"', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'bar', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'string', '"', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"bar"', 'Ġ:', 'Ġ{', 'Ġ"type"', 'Ġ:', 'Ġ"string"', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""foo" : { "minimum" : 5 } \n"
Original    (008): ['"foo"', ':', '{', '"minimum"', ':', '5', '}', '\\n']
Tokenized   (015): ['<s>', '"', 'foo', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'foo', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['"foo"', 'Ġ:', 'Ġ{', 'Ġ"minimum"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""items" : [ { } ] , \n"
Original    (008): ['"items"', ':', '[', '{', '}', ']', ',', '\\n']
Tokenized   (013): ['<s>', '"', 'items', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['"', 'items', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['"items"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "validate ( instance = instance , schema = { my_property : my_value } ) \n"
Original    (015): ['validate', '(', 'instance', '=', 'instance', ',', 'schema', '=', '{', 'my_property', ':', 'my_value', '}', ')', '\\n']
Tokenized   (023): ['<s>', 'valid', 'ate', 'Ġ(', 'Ġinstance', 'Ġ=', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ=', 'Ġ{', 'Ġmy', '_', 'property', 'Ġ:', 'Ġmy', '_', 'value', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['valid', 'ate', 'Ġ(', 'Ġinstance', 'Ġ=', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ=', 'Ġ{', 'Ġmy', '_', 'property', 'Ġ:', 'Ġmy', '_', 'value', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['validate', 'Ġ(', 'Ġinstance', 'Ġ=', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ=', 'Ġ{', 'Ġmy_property', 'Ġ:', 'Ġmy_value', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "chk_schema . assert_called_once_with ( { } ) \n"
Original    (008): ['chk_schema', '.', 'assert_called_once_with', '(', '{', '}', ')', '\\n']
Tokenized   (021): ['<s>', 'ch', 'k', '_', 'sche', 'ma', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['ch', 'k', '_', 'sche', 'ma', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['chk_schema', 'Ġ.', 'Ġassert_called_once_with', 'Ġ(', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "stored_schema = { "stored" : "schema" } \n"
Original    (008): ['stored_schema', '=', '{', '"stored"', ':', '"schema"', '}', '\\n']
Tokenized   (021): ['<s>', 'st', 'ored', '_', 'sche', 'ma', 'Ġ=', 'Ġ{', 'Ġ"', 'st', 'ored', '"', 'Ġ:', 'Ġ"', 'sche', 'ma', '"', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['st', 'ored', '_', 'sche', 'ma', 'Ġ=', 'Ġ{', 'Ġ"', 'st', 'ored', '"', 'Ġ:', 'Ġ"', 'sche', 'ma', '"', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['stored_schema', 'Ġ=', 'Ġ{', 'Ġ"stored"', 'Ġ:', 'Ġ"schema"', 'Ġ}', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""ports" : \n"
Original    (003): ['"ports"', ':', '\\n']
Tokenized   (008): ['<s>', '"', 'ports', '"', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['"', 'ports', '"', 'Ġ:', 'Ġ\\', 'n']
Detokenized (003): ['"ports"', 'Ġ:', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "l2Report . generateReport ( pod . id , True , False ) \n"
Original    (013): ['l2Report', '.', 'generateReport', '(', 'pod', '.', 'id', ',', 'True', ',', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'l', '2', 'Report', 'Ġ.', 'Ġgenerate', 'Report', 'Ġ(', 'Ġpod', 'Ġ.', 'Ġid', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['l', '2', 'Report', 'Ġ.', 'Ġgenerate', 'Report', 'Ġ(', 'Ġpod', 'Ġ.', 'Ġid', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['l2Report', 'Ġ.', 'ĠgenerateReport', 'Ġ(', 'Ġpod', 'Ġ.', 'Ġid', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_YAML_ = splitext ( __file__ ) [ 0 ] + \n"
Original    (011): ['_YAML_', '=', 'splitext', '(', '__file__', ')', '[', '0', ']', '+', '\\n']
Tokenized   (022): ['<s>', '_', 'Y', 'AM', 'L', '_', 'Ġ=', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'Y', 'AM', 'L', '_', 'Ġ=', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n']
Detokenized (011): ['_YAML_', 'Ġ=', 'Ġsplitext', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "globals ( ) . update ( loadyaml ( _YAML_ ) ) \n"
Original    (012): ['globals', '(', ')', '.', 'update', '(', 'loadyaml', '(', '_YAML_', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'gl', 'ob', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġload', 'y', 'aml', 'Ġ(', 'Ġ_', 'Y', 'AM', 'L', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['gl', 'ob', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġload', 'y', 'aml', 'Ġ(', 'Ġ_', 'Y', 'AM', 'L', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['globals', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġloadyaml', 'Ġ(', 'Ġ_YAML_', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "gather_facts = False ) \n"
Original    (005): ['gather_facts', '=', 'False', ')', '\\n']
Tokenized   (011): ['<s>', 'g', 'ather', '_', 'facts', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['g', 'ather', '_', 'facts', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['gather_facts', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "DEFAULT_API_URLS = ( , \n"
Original    (005): ['DEFAULT_API_URLS', '=', '(', ',', '\\n']
Tokenized   (014): ['<s>', 'DE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['DE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['DEFAULT_API_URLS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "BAD_STATUS_CODES = [ , , , \n"
Original    (007): ['BAD_STATUS_CODES', '=', '[', ',', ',', ',', '\\n']
Tokenized   (018): ['<s>', 'B', 'AD', '_', 'STAT', 'US', '_', 'C', 'OD', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['B', 'AD', '_', 'STAT', 'US', '_', 'C', 'OD', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['BAD_STATUS_CODES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "translate_otp = True , api_urls = DEFAULT_API_URLS , \n"
Original    (009): ['translate_otp', '=', 'True', ',', 'api_urls', '=', 'DEFAULT_API_URLS', ',', '\\n']
Tokenized   (025): ['<s>', 'trans', 'late', '_', 'ot', 'p', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġapi', '_', 'url', 's', 'Ġ=', 'ĠDE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['trans', 'late', '_', 'ot', 'p', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġapi', '_', 'url', 's', 'Ġ=', 'ĠDE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['translate_otp', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġapi_urls', 'Ġ=', 'ĠDEFAULT_API_URLS', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rand_str = b ( os . urandom ( 30 ) ) \n"
Original    (012): ['rand_str', '=', 'b', '(', 'os', '.', 'urandom', '(', '30', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'rand', '_', 'str', 'Ġ=', 'Ġb', 'Ġ(', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['rand', '_', 'str', 'Ġ=', 'Ġb', 'Ġ(', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['rand_str', 'Ġ=', 'Ġb', 'Ġ(', 'Ġos', 'Ġ.', 'Ġurandom', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "nonce = base64 . b64encode ( rand_str , b ( ) ) [ : 25 ] . decode ( ) \n"
Original    (021): ['nonce', '=', 'base64', '.', 'b64encode', '(', 'rand_str', ',', 'b', '(', ')', ')', '[', ':', '25', ']', '.', 'decode', '(', ')', '\\n']
Tokenized   (031): ['<s>', 'non', 'ce', 'Ġ=', 'Ġbase', '64', 'Ġ.', 'Ġb', '64', 'en', 'code', 'Ġ(', 'Ġrand', '_', 'str', 'Ġ,', 'Ġb', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ25', 'Ġ]', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['non', 'ce', 'Ġ=', 'Ġbase', '64', 'Ġ.', 'Ġb', '64', 'en', 'code', 'Ġ(', 'Ġrand', '_', 'str', 'Ġ,', 'Ġb', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ25', 'Ġ]', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['nonce', 'Ġ=', 'Ġbase64', 'Ġ.', 'Ġb64encode', 'Ġ(', 'Ġrand_str', 'Ġ,', 'Ġb', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ25', 'Ġ]', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "otp . otp , nonce , \n"
Original    (007): ['otp', '.', 'otp', ',', 'nonce', ',', '\\n']
Tokenized   (013): ['<s>', 'ot', 'p', 'Ġ.', 'Ġot', 'p', 'Ġ,', 'Ġnon', 'ce', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['ot', 'p', 'Ġ.', 'Ġot', 'p', 'Ġ,', 'Ġnon', 'ce', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['otp', 'Ġ.', 'Ġotp', 'Ġ,', 'Ġnonce', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "pairs_string = . join ( [ . join ( pair ) for pair in pairs_sorted ] ) \n"
Original    (018): ['pairs_string', '=', '.', 'join', '(', '[', '.', 'join', '(', 'pair', ')', 'for', 'pair', 'in', 'pairs_sorted', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'p', 'airs', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpair', 'Ġ)', 'Ġfor', 'Ġpair', 'Ġin', 'Ġpairs', '_', 's', 'orted', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['p', 'airs', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpair', 'Ġ)', 'Ġfor', 'Ġpair', 'Ġin', 'Ġpairs', '_', 's', 'orted', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['pairs_string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpair', 'Ġ)', 'Ġfor', 'Ġpair', 'Ġin', 'Ġpairs_sorted', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "digest = hmac . new ( self . key , b ( pairs_string ) , hashlib . sha1 ) . digest ( ) \n"
Original    (024): ['digest', '=', 'hmac', '.', 'new', '(', 'self', '.', 'key', ',', 'b', '(', 'pairs_string', ')', ',', 'hashlib', '.', 'sha1', ')', '.', 'digest', '(', ')', '\\n']
Tokenized   (034): ['<s>', 'dig', 'est', 'Ġ=', 'Ġh', 'mac', 'Ġ.', 'Ġnew', 'Ġ(', 'Ġself', 'Ġ.', 'Ġkey', 'Ġ,', 'Ġb', 'Ġ(', 'Ġpairs', '_', 'string', 'Ġ)', 'Ġ,', 'Ġhash', 'lib', 'Ġ.', 'Ġsh', 'a', '1', 'Ġ)', 'Ġ.', 'Ġdigest', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['dig', 'est', 'Ġ=', 'Ġh', 'mac', 'Ġ.', 'Ġnew', 'Ġ(', 'Ġself', 'Ġ.', 'Ġkey', 'Ġ,', 'Ġb', 'Ġ(', 'Ġpairs', '_', 'string', 'Ġ)', 'Ġ,', 'Ġhash', 'lib', 'Ġ.', 'Ġsh', 'a', '1', 'Ġ)', 'Ġ.', 'Ġdigest', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['digest', 'Ġ=', 'Ġhmac', 'Ġ.', 'Ġnew', 'Ġ(', 'Ġself', 'Ġ.', 'Ġkey', 'Ġ,', 'Ġb', 'Ġ(', 'Ġpairs_string', 'Ġ)', 'Ġ,', 'Ġhashlib', 'Ġ.', 'Ġsha1', 'Ġ)', 'Ġ.', 'Ġdigest', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "signature = ( [ unquote ( v ) for k , v in pairs if k == ] or [ None ] ) [ 0 ] \n"
Original    (027): ['signature', '=', '(', '[', 'unquote', '(', 'v', ')', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '==', ']', 'or', '[', 'None', ']', ')', '[', '0', ']', '\\n']
Tokenized   (032): ['<s>', 'sign', 'ature', 'Ġ=', 'Ġ(', 'Ġ[', 'Ġun', 'quote', 'Ġ(', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ==', 'Ġ]', 'Ġor', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['sign', 'ature', 'Ġ=', 'Ġ(', 'Ġ[', 'Ġun', 'quote', 'Ġ(', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ==', 'Ġ]', 'Ġor', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (027): ['signature', 'Ġ=', 'Ġ(', 'Ġ[', 'Ġunquote', 'Ġ(', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ==', 'Ġ]', 'Ġor', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "query_string = . join ( [ k + + v for k , v in pairs if k != ] ) \n"
Original    (022): ['query_string', '=', '.', 'join', '(', '[', 'k', '+', '+', 'v', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '!=', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'query', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġk', 'Ġ+', 'Ġ+', 'Ġv', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ!=', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['query', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġk', 'Ġ+', 'Ġ+', 'Ġv', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ!=', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['query_string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġk', 'Ġ+', 'Ġ+', 'Ġv', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ!=', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "pairs = ( x . split ( , 1 ) for x in query_string . split ( ) ) \n"
Original    (020): ['pairs', '=', '(', 'x', '.', 'split', '(', ',', '1', ')', 'for', 'x', 'in', 'query_string', '.', 'split', '(', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'p', 'airs', 'Ġ=', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġquery', '_', 'string', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['p', 'airs', 'Ġ=', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġquery', '_', 'string', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['pairs', 'Ġ=', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġquery_string', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "py_modules = [ ] , \n"
Original    (006): ['py_modules', '=', '[', ']', ',', '\\n']
Tokenized   (011): ['<s>', 'py', '_', 'modules', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['py', '_', 'modules', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['py_modules', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "submitter , msg = result [ 0 ] \n"
Original    (009): ['submitter', ',', 'msg', '=', 'result', '[', '0', ']', '\\n']
Tokenized   (013): ['<s>', 'sub', 'mitter', 'Ġ,', 'Ġmsg', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['sub', 'mitter', 'Ġ,', 'Ġmsg', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['submitter', 'Ġ,', 'Ġmsg', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "contact = self . line_interface . _get_contact_by_id ( me . id ) \n"
Original    (013): ['contact', '=', 'self', '.', 'line_interface', '.', '_get_contact_by_id', '(', 'me', '.', 'id', ')', '\\n']
Tokenized   (025): ['<s>', 'contact', 'Ġ=', 'Ġself', 'Ġ.', 'Ġline', '_', 'interface', 'Ġ.', 'Ġ_', 'get', '_', 'contact', '_', 'by', '_', 'id', 'Ġ(', 'Ġme', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['contact', 'Ġ=', 'Ġself', 'Ġ.', 'Ġline', '_', 'interface', 'Ġ.', 'Ġ_', 'get', '_', 'contact', '_', 'by', '_', 'id', 'Ġ(', 'Ġme', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['contact', 'Ġ=', 'Ġself', 'Ġ.', 'Ġline_interface', 'Ġ.', 'Ġ_get_contact_by_id', 'Ġ(', 'Ġme', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ok_ ( me_display_name == me . name ) \n"
Original    (009): ['ok_', '(', 'me_display_name', '==', 'me', '.', 'name', ')', '\\n']
Tokenized   (017): ['<s>', 'ok', '_', 'Ġ(', 'Ġme', '_', 'display', '_', 'name', 'Ġ==', 'Ġme', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['ok', '_', 'Ġ(', 'Ġme', '_', 'display', '_', 'name', 'Ġ==', 'Ġme', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['ok_', 'Ġ(', 'Ġme_display_name', 'Ġ==', 'Ġme', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "transport . get_extra_info . return_value = None \n"
Original    (008): ['transport', '.', 'get_extra_info', '.', 'return_value', '=', 'None', '\\n']
Tokenized   (018): ['<s>', 'trans', 'port', 'Ġ.', 'Ġget', '_', 'extra', '_', 'info', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['trans', 'port', 'Ġ.', 'Ġget', '_', 'extra', '_', 'info', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'ĠNone', 'Ġ\\', 'n']
Detokenized (008): ['transport', 'Ġ.', 'Ġget_extra_info', 'Ġ.', 'Ġreturn_value', 'Ġ=', 'ĠNone', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ShortenerSettings = namedtuple ( , [ \n"
Original    (007): ['ShortenerSettings', '=', 'namedtuple', '(', ',', '[', '\\n']
Tokenized   (014): ['<s>', 'Short', 'ener', 'Settings', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Short', 'ener', 'Settings', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ\\', 'n']
Detokenized (007): ['ShortenerSettings', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "right_to_left = [ , ] , \n"
Original    (007): ['right_to_left', '=', '[', ',', ']', ',', '\\n']
Tokenized   (014): ['<s>', 'right', '_', 'to', '_', 'left', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['right', '_', 'to', '_', 'left', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['right_to_left', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "shortener = { } , \n"
Original    (006): ['shortener', '=', '{', '}', ',', '\\n']
Tokenized   (010): ['<s>', 'short', 'ener', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['short', 'ener', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['shortener', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "workers_pool = 10 , \n"
Original    (005): ['workers_pool', '=', '10', ',', '\\n']
Tokenized   (010): ['<s>', 'workers', '_', 'pool', 'Ġ=', 'Ġ10', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['workers', '_', 'pool', 'Ġ=', 'Ġ10', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['workers_pool', 'Ġ=', 'Ġ10', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "cms_service_host = "http://localhost:5001" \n"
Original    (004): ['cms_service_host', '=', '"http://localhost:5001"', '\\n']
Tokenized   (018): ['<s>', 'cms', '_', 'service', '_', 'host', 'Ġ=', 'Ġ"', 'http', '://', 'localhost', ':', '500', '1', '"', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['cms', '_', 'service', '_', 'host', 'Ġ=', 'Ġ"', 'http', '://', 'localhost', ':', '500', '1', '"', 'Ġ\\', 'n']
Detokenized (004): ['cms_service_host', 'Ġ=', 'Ġ"http://localhost:5001"', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "subparsers = args . add_subparsers ( help = , dest = ) \n"
Original    (013): ['subparsers', '=', 'args', '.', 'add_subparsers', '(', 'help', '=', ',', 'dest', '=', ')', '\\n']
Tokenized   (024): ['<s>', 'sub', 'p', 'ars', 'ers', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġadd', '_', 'sub', 'p', 'ars', 'ers', 'Ġ(', 'Ġhelp', 'Ġ=', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['sub', 'p', 'ars', 'ers', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġadd', '_', 'sub', 'p', 'ars', 'ers', 'Ġ(', 'Ġhelp', 'Ġ=', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['subparsers', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġadd_subparsers', 'Ġ(', 'Ġhelp', 'Ġ=', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "template_parser . add_argument ( , \n"
Original    (006): ['template_parser', '.', 'add_argument', '(', ',', '\\n']
Tokenized   (013): ['<s>', 'template', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['template', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['template_parser', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "config_parser . add_argument ( , help = ) \n"
Original    (009): ['config_parser', '.', 'add_argument', '(', ',', 'help', '=', ')', '\\n']
Tokenized   (016): ['<s>', 'config', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['config', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['config_parser', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "gui_parser . add_argument ( , , type = str , help = ) \n"
Original    (014): ['gui_parser', '.', 'add_argument', '(', ',', ',', 'type', '=', 'str', ',', 'help', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'gui', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġstr', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['gui', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġstr', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['gui_parser', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġstr', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "changePwdResult = conn . extend . microsoft . modify_password ( user_dn , newpassword ) \n"
Original    (015): ['changePwdResult', '=', 'conn', '.', 'extend', '.', 'microsoft', '.', 'modify_password', '(', 'user_dn', ',', 'newpassword', ')', '\\n']
Tokenized   (027): ['<s>', 'change', 'P', 'wd', 'Result', 'Ġ=', 'Ġconn', 'Ġ.', 'Ġextend', 'Ġ.', 'Ġmicro', 'soft', 'Ġ.', 'Ġmodify', '_', 'password', 'Ġ(', 'Ġuser', '_', 'dn', 'Ġ,', 'Ġnew', 'password', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['change', 'P', 'wd', 'Result', 'Ġ=', 'Ġconn', 'Ġ.', 'Ġextend', 'Ġ.', 'Ġmicro', 'soft', 'Ġ.', 'Ġmodify', '_', 'password', 'Ġ(', 'Ġuser', '_', 'dn', 'Ġ,', 'Ġnew', 'password', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['changePwdResult', 'Ġ=', 'Ġconn', 'Ġ.', 'Ġextend', 'Ġ.', 'Ġmicrosoft', 'Ġ.', 'Ġmodify_password', 'Ġ(', 'Ġuser_dn', 'Ġ,', 'Ġnewpassword', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "cap_path = os . path . join ( caps_directory , ) \n"
Original    (012): ['cap_path', '=', 'os', '.', 'path', '.', 'join', '(', 'caps_directory', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'cap', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġcaps', '_', 'directory', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['cap', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġcaps', '_', 'directory', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['cap_path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġcaps_directory', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "cap . eventloop . stop ( ) \n"
Original    (008): ['cap', '.', 'eventloop', '.', 'stop', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'cap', 'Ġ.', 'Ġevent', 'loop', 'Ġ.', 'Ġstop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['cap', 'Ġ.', 'Ġevent', 'loop', 'Ġ.', 'Ġstop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['cap', 'Ġ.', 'Ġeventloop', 'Ġ.', 'Ġstop', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "flush = Service ( name = , \n"
Original    (008): ['flush', '=', 'Service', '(', 'name', '=', ',', '\\n']
Tokenized   (011): ['<s>', 'flush', 'Ġ=', 'ĠService', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['flush', 'Ġ=', 'ĠService', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['flush', 'Ġ=', 'ĠService', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sourceIds = [ d [ ] for d in response . json ] \n"
Original    (014): ['sourceIds', '=', '[', 'd', '[', ']', 'for', 'd', 'in', 'response', '.', 'json', ']', '\\n']
Tokenized   (019): ['<s>', 'source', 'Id', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġd', 'Ġin', 'Ġresponse', 'Ġ.', 'Ġjson', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['source', 'Id', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġd', 'Ġin', 'Ġresponse', 'Ġ.', 'Ġjson', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['sourceIds', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġd', 'Ġin', 'Ġresponse', 'Ġ.', 'Ġjson', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""folder." ) \n"
Original    (003): ['"folder."', ')', '\\n']
Tokenized   (008): ['<s>', '"', 'folder', '."', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['"', 'folder', '."', 'Ġ)', 'Ġ\\', 'n']
Detokenized (003): ['"folder."', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "minerva_metadata [ ] = { \n"
Original    (006): ['minerva_metadata', '[', ']', '=', '{', '\\n']
Tokenized   (012): ['<s>', 'min', 'erva', '_', 'metadata', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['min', 'erva', '_', 'metadata', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ\\', 'n']
Detokenized (006): ['minerva_metadata', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "Description ( ) \n"
Original    (004): ['Description', '(', ')', '\\n']
Tokenized   (007): ['<s>', 'Description', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['Description', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['Description', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "matches = re . findall ( "(\'|\\")(\\S+)(\'|\\")" , text ) \n"
Original    (011): ['matches', '=', 're', '.', 'findall', '(', '"(\\\'|\\\\")(\\\\S+)(\\\'|\\\\")"', ',', 'text', ')', '\\n']
Tokenized   (030): ['<s>', 'mat', 'ches', 'Ġ=', 'Ġre', 'Ġ.', 'Ġfind', 'all', 'Ġ(', 'Ġ"(', "\\'", '|', '\\\\', '")', '(', '\\\\', 'S', '+', ')(', "\\'", '|', '\\\\', '")', '"', 'Ġ,', 'Ġtext', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['mat', 'ches', 'Ġ=', 'Ġre', 'Ġ.', 'Ġfind', 'all', 'Ġ(', 'Ġ"(', "\\'", '|', '\\\\', '")', '(', '\\\\', 'S', '+', ')(', "\\'", '|', '\\\\', '")', '"', 'Ġ,', 'Ġtext', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['matches', 'Ġ=', 'Ġre', 'Ġ.', 'Ġfindall', 'Ġ(', 'Ġ"(\\\'|\\\\")(\\\\S+)(\\\'|\\\\")"', 'Ġ,', 'Ġtext', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "package_data = { : [ ] } , \n"
Original    (009): ['package_data', '=', '{', ':', '[', ']', '}', ',', '\\n']
Tokenized   (014): ['<s>', 'package', '_', 'data', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['package', '_', 'data', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['package_data', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "list_permissions = [ , , , ] \n"
Original    (008): ['list_permissions', '=', '[', ',', ',', ',', ']', '\\n']
Tokenized   (014): ['<s>', 'list', '_', 'per', 'missions', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['list', '_', 'per', 'missions', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['list_permissions', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "option_list = BaseCommand . option_list + ( \n"
Original    (008): ['option_list', '=', 'BaseCommand', '.', 'option_list', '+', '(', '\\n']
Tokenized   (016): ['<s>', 'option', '_', 'list', 'Ġ=', 'ĠBase', 'Command', 'Ġ.', 'Ġoption', '_', 'list', 'Ġ+', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['option', '_', 'list', 'Ġ=', 'ĠBase', 'Command', 'Ġ.', 'Ġoption', '_', 'list', 'Ġ+', 'Ġ(', 'Ġ\\', 'n']
Detokenized (008): ['option_list', 'Ġ=', 'ĠBaseCommand', 'Ġ.', 'Ġoption_list', 'Ġ+', 'Ġ(', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "make_option ( , \n"
Original    (004): ['make_option', '(', ',', '\\n']
Tokenized   (009): ['<s>', 'make', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['make', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['make_option', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "confirm_token = Column ( Unicode ( 100 ) ) \n"
Original    (010): ['confirm_token', '=', 'Column', '(', 'Unicode', '(', '100', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'conf', 'irm', '_', 'token', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['conf', 'irm', '_', 'token', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['confirm_token', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "creation_date = Column ( DateTime ( ) , nullable = False ) \n"
Original    (013): ['creation_date', '=', 'Column', '(', 'DateTime', '(', ')', ',', 'nullable', '=', 'False', ')', '\\n']
Tokenized   (020): ['<s>', 'creation', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['creation', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['creation_date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDateTime', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġnullable', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "last_login_date = Column ( DateTime ( ) ) \n"
Original    (009): ['last_login_date', '=', 'Column', '(', 'DateTime', '(', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'last', '_', 'login', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['last', '_', 'login', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['last_login_date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDateTime', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "SHARING_ROLES = [ , , ] \n"
Original    (007): ['SHARING_ROLES', '=', '[', ',', ',', ']', '\\n']
Tokenized   (016): ['<s>', 'SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['SHARING_ROLES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "USER_MANAGEMENT_ROLES = SHARING_ROLES + [ ] \n"
Original    (007): ['USER_MANAGEMENT_ROLES', '=', 'SHARING_ROLES', '+', '[', ']', '\\n']
Tokenized   (023): ['<s>', 'USER', '_', 'MAN', 'AG', 'EMENT', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['USER', '_', 'MAN', 'AG', 'EMENT', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['USER_MANAGEMENT_ROLES', 'Ġ=', 'ĠSHARING_ROLES', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_DEFAULT_SHARING_ROLES = SHARING_ROLES [ : ] \n"
Original    (007): ['_DEFAULT_SHARING_ROLES', '=', 'SHARING_ROLES', '[', ':', ']', '\\n']
Tokenized   (025): ['<s>', '_', 'DE', 'FAULT', '_', 'SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['_', 'DE', 'FAULT', '_', 'SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['_DEFAULT_SHARING_ROLES', 'Ġ=', 'ĠSHARING_ROLES', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "principal = get_principals ( ) . get ( name ) \n"
Original    (011): ['principal', '=', 'get_principals', '(', ')', '.', 'get', '(', 'name', ')', '\\n']
Tokenized   (021): ['<s>', 'pr', 'inc', 'ipal', 'Ġ=', 'Ġget', '_', 'pr', 'inc', 'ip', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['pr', 'inc', 'ipal', 'Ġ=', 'Ġget', '_', 'pr', 'inc', 'ip', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['principal', 'Ġ=', 'Ġget_principals', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "lg for lg in context . local_groups \n"
Original    (008): ['lg', 'for', 'lg', 'in', 'context', '.', 'local_groups', '\\n']
Tokenized   (015): ['<s>', 'l', 'g', 'Ġfor', 'Ġl', 'g', 'Ġin', 'Ġcontext', 'Ġ.', 'Ġlocal', '_', 'groups', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['l', 'g', 'Ġfor', 'Ġl', 'g', 'Ġin', 'Ġcontext', 'Ġ.', 'Ġlocal', '_', 'groups', 'Ġ\\', 'n']
Detokenized (008): ['lg', 'Ġfor', 'Ġlg', 'Ġin', 'Ġcontext', 'Ġ.', 'Ġlocal_groups', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "LocalGroup ( context , name , unicode ( group_name ) ) \n"
Original    (012): ['LocalGroup', '(', 'context', ',', 'name', ',', 'unicode', '(', 'group_name', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'Local', 'Group', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġname', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġgroup', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['Local', 'Group', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġname', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġgroup', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['LocalGroup', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġname', 'Ġ,', 'Ġunicode', 'Ġ(', 'Ġgroup_name', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "filters . append ( func . lower ( col ) . like ( value ) ) \n"
Original    (017): ['filters', '.', 'append', '(', 'func', '.', 'lower', '(', 'col', ')', '.', 'like', '(', 'value', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'fil', 'ters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġcol', 'Ġ)', 'Ġ.', 'Ġlike', 'Ġ(', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['fil', 'ters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġcol', 'Ġ)', 'Ġ.', 'Ġlike', 'Ġ(', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['filters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġcol', 'Ġ)', 'Ġ.', 'Ġlike', 'Ġ(', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "bcrypt . hashpw ( password . encode ( ) , hashed . encode ( ) ) ) \n"
Original    (018): ['bcrypt', '.', 'hashpw', '(', 'password', '.', 'encode', '(', ')', ',', 'hashed', '.', 'encode', '(', ')', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'bc', 'rypt', 'Ġ.', 'Ġhash', 'p', 'w', 'Ġ(', 'Ġpassword', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġhas', 'hed', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['bc', 'rypt', 'Ġ.', 'Ġhash', 'p', 'w', 'Ġ(', 'Ġpassword', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġhas', 'hed', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['bcrypt', 'Ġ.', 'Ġhashpw', 'Ġ(', 'Ġpassword', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġhashed', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "browser . open ( . format ( BASE_URL ) ) \n"
Original    (011): ['browser', '.', 'open', '(', '.', 'format', '(', 'BASE_URL', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'browser', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠBASE', '_', 'URL', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['browser', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠBASE', '_', 'URL', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['browser', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠBASE_URL', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "AUTHORS = open ( os . path . join ( here , ) ) . read ( ) \n"
Original    (019): ['AUTHORS', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'A', 'UTH', 'ORS', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['A', 'UTH', 'ORS', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['AUTHORS', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "fixed_boxes ) : \n"
Original    (004): ['fixed_boxes', ')', ':', '\\n']
Tokenized   (009): ['<s>', 'fixed', '_', 'boxes', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['fixed', '_', 'boxes', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (004): ['fixed_boxes', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "resolve_percentages ( box , ( containing_block . width , containing_block . height ) ) \n"
Original    (015): ['resolve_percentages', '(', 'box', ',', '(', 'containing_block', '.', 'width', ',', 'containing_block', '.', 'height', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'res', 'olve', '_', 'percent', 'ages', 'Ġ(', 'Ġbox', 'Ġ,', 'Ġ(', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġwidth', 'Ġ,', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġheight', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['res', 'olve', '_', 'percent', 'ages', 'Ġ(', 'Ġbox', 'Ġ,', 'Ġ(', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġwidth', 'Ġ,', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġheight', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['resolve_percentages', 'Ġ(', 'Ġbox', 'Ġ,', 'Ġ(', 'Ġcontaining_block', 'Ġ.', 'Ġwidth', 'Ġ,', 'Ġcontaining_block', 'Ġ.', 'Ġheight', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "box , _ , _ , _ , _ = block_container_layout ( \n"
Original    (013): ['box', ',', '_', ',', '_', ',', '_', ',', '_', '=', 'block_container_layout', '(', '\\n']
Tokenized   (020): ['<s>', 'box', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ=', 'Ġblock', '_', 'container', '_', 'layout', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['box', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ=', 'Ġblock', '_', 'container', '_', 'layout', 'Ġ(', 'Ġ\\', 'n']
Detokenized (013): ['box', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ=', 'Ġblock_container_layout', 'Ġ(', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "skip_stack = None , device_size = device_size , page_is_empty = False , \n"
Original    (013): ['skip_stack', '=', 'None', ',', 'device_size', '=', 'device_size', ',', 'page_is_empty', '=', 'False', ',', '\\n']
Tokenized   (026): ['<s>', 'skip', '_', 'stack', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdevice', '_', 'size', 'Ġ=', 'Ġdevice', '_', 'size', 'Ġ,', 'Ġpage', '_', 'is', '_', 'empty', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['skip', '_', 'stack', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdevice', '_', 'size', 'Ġ=', 'Ġdevice', '_', 'size', 'Ġ,', 'Ġpage', '_', 'is', '_', 'empty', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['skip_stack', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdevice_size', 'Ġ=', 'Ġdevice_size', 'Ġ,', 'Ġpage_is_empty', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "list_marker_layout ( context , box ) \n"
Original    (007): ['list_marker_layout', '(', 'context', ',', 'box', ')', '\\n']
Tokenized   (015): ['<s>', 'list', '_', 'mark', 'er', '_', 'layout', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġbox', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['list', '_', 'mark', 'er', '_', 'layout', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġbox', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['list_marker_layout', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġbox', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "hypothetical_position = box . position_y + collapsed_margin \n"
Original    (008): ['hypothetical_position', '=', 'box', '.', 'position_y', '+', 'collapsed_margin', '\\n']
Tokenized   (019): ['<s>', 'hyp', 'ot', 'hetical', '_', 'position', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġcollapsed', '_', 'margin', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['hyp', 'ot', 'hetical', '_', 'position', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġcollapsed', '_', 'margin', 'Ġ\\', 'n']
Detokenized (008): ['hypothetical_position', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġposition_y', 'Ġ+', 'Ġcollapsed_margin', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "box_width = box . margin_width ( ) if outer else box . border_width ( ) \n"
Original    (016): ['box_width', '=', 'box', '.', 'margin_width', '(', ')', 'if', 'outer', 'else', 'box', '.', 'border_width', '(', ')', '\\n']
Tokenized   (025): ['<s>', 'box', '_', 'width', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'width', 'Ġ(', 'Ġ)', 'Ġif', 'Ġouter', 'Ġelse', 'Ġbox', 'Ġ.', 'Ġborder', '_', 'width', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['box', '_', 'width', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'width', 'Ġ(', 'Ġ)', 'Ġif', 'Ġouter', 'Ġelse', 'Ġbox', 'Ġ.', 'Ġborder', '_', 'width', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['box_width', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġmargin_width', 'Ġ(', 'Ġ)', 'Ġif', 'Ġouter', 'Ġelse', 'Ġbox', 'Ġ.', 'Ġborder_width', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "max_right_bound -= box . margin_right \n"
Original    (006): ['max_right_bound', '-=', 'box', '.', 'margin_right', '\\n']
Tokenized   (015): ['<s>', 'max', '_', 'right', '_', 'bound', 'Ġ-=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'right', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['max', '_', 'right', '_', 'bound', 'Ġ-=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'right', 'Ġ\\', 'n']
Detokenized (006): ['max_right_bound', 'Ġ-=', 'Ġbox', 'Ġ.', 'Ġmargin_right', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "shape . position_y + shape . margin_height ( ) \n"
Original    (010): ['shape', '.', 'position_y', '+', 'shape', '.', 'margin_height', '(', ')', '\\n']
Tokenized   (017): ['<s>', 'shape', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġshape', 'Ġ.', 'Ġmargin', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['shape', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġshape', 'Ġ.', 'Ġmargin', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['shape', 'Ġ.', 'Ġposition_y', 'Ġ+', 'Ġshape', 'Ġ.', 'Ġmargin_height', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "urlpatterns = patterns ( , \n"
Original    (006): ['urlpatterns', '=', 'patterns', '(', ',', '\\n']
Tokenized   (011): ['<s>', 'url', 'pattern', 's', 'Ġ=', 'Ġpatterns', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['url', 'pattern', 's', 'Ġ=', 'Ġpatterns', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['urlpatterns', 'Ġ=', 'Ġpatterns', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "obj1 , obj2 = qs \n"
Original    (006): ['obj1', ',', 'obj2', '=', 'qs', '\\n']
Tokenized   (012): ['<s>', 'obj', '1', 'Ġ,', 'Ġobj', '2', 'Ġ=', 'Ġq', 's', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['obj', '1', 'Ġ,', 'Ġobj', '2', 'Ġ=', 'Ġq', 's', 'Ġ\\', 'n']
Detokenized (006): ['obj1', 'Ġ,', 'Ġobj2', 'Ġ=', 'Ġqs', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "n1 = Normal . objects . language ( ) . get ( pk = self . normal_id [ 1 ] ) \n"
Original    (022): ['n1', '=', 'Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'pk', '=', 'self', '.', 'normal_id', '[', '1', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'n', '1', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnormal', '_', 'id', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['n', '1', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnormal', '_', 'id', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['n1', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnormal_id', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "shared_field = NEW_SHARED , translated_field = NEW_TRANSLATED \n"
Original    (008): ['shared_field', '=', 'NEW_SHARED', ',', 'translated_field', '=', 'NEW_TRANSLATED', '\\n']
Tokenized   (024): ['<s>', 'shared', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'SH', 'AR', 'ED', 'Ġ,', 'Ġtranslated', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'TR', 'AN', 'SL', 'ATED', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['shared', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'SH', 'AR', 'ED', 'Ġ,', 'Ġtranslated', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'TR', 'AN', 'SL', 'ATED', 'Ġ\\', 'n']
Detokenized (008): ['shared_field', 'Ġ=', 'ĠNEW_SHARED', 'Ġ,', 'Ġtranslated_field', 'Ġ=', 'ĠNEW_TRANSLATED', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "NORMAL [ 2 ] . shared_field ] ) \n"
Original    (009): ['NORMAL', '[', '2', ']', '.', 'shared_field', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'NOR', 'MAL', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['NOR', 'MAL', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['NORMAL', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġshared_field', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "ja = Normal . objects . language ( ) . get ( pk = en . pk ) \n"
Original    (019): ['ja', '=', 'Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'pk', '=', 'en', '.', 'pk', ')', '\\n']
Tokenized   (024): ['<s>', 'ja', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġen', 'Ġ.', 'Ġp', 'k', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ja', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġen', 'Ġ.', 'Ġp', 'k', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['ja', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġen', 'Ġ.', 'Ġpk', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "AggregateModel . objects . language ( "en" ) . create ( number = 0 , translated_number = 0 ) \n"
Original    (020): ['AggregateModel', '.', 'objects', '.', 'language', '(', '"en"', ')', '.', 'create', '(', 'number', '=', '0', ',', 'translated_number', '=', '0', ')', '\\n']
Tokenized   (029): ['<s>', 'Agg', 'regate', 'Model', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ"', 'en', '"', 'Ġ)', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġnumber', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġtranslated', '_', 'number', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['Agg', 'regate', 'Model', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ"', 'en', '"', 'Ġ)', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġnumber', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġtranslated', '_', 'number', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['AggregateModel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ"en"', 'Ġ)', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġnumber', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġtranslated_number', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "shared_contains_two = Q ( shared_field__contains = ) \n"
Original    (008): ['shared_contains_two', '=', 'Q', '(', 'shared_field__contains', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'shared', '_', 'cont', 'ains', '_', 'two', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġshared', '_', 'field', '__', 'cont', 'ains', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['shared', '_', 'cont', 'ains', '_', 'two', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġshared', '_', 'field', '__', 'cont', 'ains', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['shared_contains_two', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġshared_field__contains', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "normal_one = Q ( normal_field = STANDARD [ 1 ] . normal_field ) \n"
Original    (014): ['normal_one', '=', 'Q', '(', 'normal_field', '=', 'STANDARD', '[', '1', ']', '.', 'normal_field', ')', '\\n']
Tokenized   (024): ['<s>', 'normal', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '_', 'field', 'Ġ=', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', '_', 'field', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['normal', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '_', 'field', 'Ġ=', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', '_', 'field', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['normal_one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal_field', 'Ġ=', 'ĠSTANDARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal_field', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "shared_one = Q ( normal__shared_field = NORMAL [ STANDARD [ 1 ] . normal ] . shared_field ) \n"
Original    (019): ['shared_one', '=', 'Q', '(', 'normal__shared_field', '=', 'NORMAL', '[', 'STANDARD', '[', '1', ']', '.', 'normal', ']', '.', 'shared_field', ')', '\\n']
Tokenized   (032): ['<s>', 'shared', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'shared', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['shared', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'shared', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['shared_one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal__shared_field', 'Ġ=', 'ĠNORMAL', 'Ġ[', 'ĠSTANDARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġshared_field', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "translated_one_en = Q ( normal__translated_field = NORMAL [ STANDARD [ 1 ] . normal ] . translated_field [ translated_two_en = Q ( normal__translated_field = NORMAL [ STANDARD [ 2 ] . normal ] . translated_field [ \n"
Original    (037): ['translated_one_en', '=', 'Q', '(', 'normal__translated_field', '=', 'NORMAL', '[', 'STANDARD', '[', '1', ']', '.', 'normal', ']', '.', 'translated_field', '[', 'translated_two_en', '=', 'Q', '(', 'normal__translated_field', '=', 'NORMAL', '[', 'STANDARD', '[', '2', ']', '.', 'normal', ']', '.', 'translated_field', '[', '\\n']
Tokenized   (067): ['<s>', 'trans', 'lated', '_', 'one', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (065): ['trans', 'lated', '_', 'one', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġ\\', 'n']
Detokenized (037): ['translated_one_en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal__translated_field', 'Ġ=', 'ĠNORMAL', 'Ġ[', 'ĠSTANDARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated_field', 'Ġ[', 'Ġtranslated_two_en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal__translated_field', 'Ġ=', 'ĠNORMAL', 'Ġ[', 'ĠSTANDARD', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated_field', 'Ġ[', 'Ġ\\n']
Counter: 65
===================================================================
Hidden states:  (13, 37, 768)
# Extracted words:  37
Sentence         : "qs = manager . filter ( shared_one & ~ translated_two_en ) \n"
Original    (012): ['qs', '=', 'manager', '.', 'filter', '(', 'shared_one', '&', '~', 'translated_two_en', ')', '\\n']
Tokenized   (021): ['<s>', 'qs', 'Ġ=', 'Ġmanager', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġshared', '_', 'one', 'Ġ&', 'Ġ~', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['qs', 'Ġ=', 'Ġmanager', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġshared', '_', 'one', 'Ġ&', 'Ġ~', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['qs', 'Ġ=', 'Ġmanager', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġshared_one', 'Ġ&', 'Ġ~', 'Ġtranslated_two_en', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Normal . objects . language ( ) . complex_filter , \n"
Original    (011): ['Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'complex_filter', ',', '\\n']
Tokenized   (016): ['<s>', 'Normal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcomplex', '_', 'filter', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['Normal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcomplex', '_', 'filter', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['Normal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcomplex_filter', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "analytics . track ( user_id , "Activate" , { \n"
Original    (010): ['analytics', '.', 'track', '(', 'user_id', ',', '"Activate"', ',', '{', '\\n']
Tokenized   (019): ['<s>', 'analy', 'tics', 'Ġ.', 'Ġtrack', 'Ġ(', 'Ġuser', '_', 'id', 'Ġ,', 'Ġ"', 'Activ', 'ate', '"', 'Ġ,', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['analy', 'tics', 'Ġ.', 'Ġtrack', 'Ġ(', 'Ġuser', '_', 'id', 'Ġ,', 'Ġ"', 'Activ', 'ate', '"', 'Ġ,', 'Ġ{', 'Ġ\\', 'n']
Detokenized (010): ['analytics', 'Ġ.', 'Ġtrack', 'Ġ(', 'Ġuser_id', 'Ġ,', 'Ġ"Activate"', 'Ġ,', 'Ġ{', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sublime_plugin . WindowCommand . __init__ ( self , * args , ** kwargs ) \n"
Original    (015): ['sublime_plugin', '.', 'WindowCommand', '.', '__init__', '(', 'self', ',', '*', 'args', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (026): ['<s>', 'sub', 'lime', '_', 'plugin', 'Ġ.', 'ĠWindow', 'Command', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['sub', 'lime', '_', 'plugin', 'Ġ.', 'ĠWindow', 'Command', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sublime_plugin', 'Ġ.', 'ĠWindowCommand', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : ""show_response" , { "title" : title , "text" : text } ) \n"
Original    (013): ['"show_response"', ',', '{', '"title"', ':', 'title', ',', '"text"', ':', 'text', '}', ')', '\\n']
Tokenized   (024): ['<s>', '"', 'show', '_', 'response', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'title', '"', 'Ġ:', 'Ġtitle', 'Ġ,', 'Ġ"', 'text', '"', 'Ġ:', 'Ġtext', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'show', '_', 'response', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'title', '"', 'Ġ:', 'Ġtitle', 'Ġ,', 'Ġ"', 'text', '"', 'Ġ:', 'Ġtext', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['"show_response"', 'Ġ,', 'Ġ{', 'Ġ"title"', 'Ġ:', 'Ġtitle', 'Ġ,', 'Ġ"text"', 'Ġ:', 'Ġtext', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ensure_ascii = False \n"
Original    (004): ['ensure_ascii', '=', 'False', '\\n']
Tokenized   (012): ['<s>', 'ens', 'ure', '_', 'as', 'ci', 'i', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['ens', 'ure', '_', 'as', 'ci', 'i', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (004): ['ensure_ascii', 'Ġ=', 'ĠFalse', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "syntax = "Packages/JavaScript/JSON.tmLanguage" ) \n"
Original    (005): ['syntax', '=', '"Packages/JavaScript/JSON.tmLanguage"', ')', '\\n']
Tokenized   (020): ['<s>', 'sy', 'ntax', 'Ġ=', 'Ġ"', 'Pack', 'ages', '/', 'Java', 'Script', '/', 'JSON', '.', 'tm', 'Language', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['sy', 'ntax', 'Ġ=', 'Ġ"', 'Pack', 'ages', '/', 'Java', 'Script', '/', 'JSON', '.', 'tm', 'Language', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['syntax', 'Ġ=', 'Ġ"Packages/JavaScript/JSON.tmLanguage"', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "scroll = self . settings . scroll_size \n"
Original    (008): ['scroll', '=', 'self', '.', 'settings', '.', 'scroll_size', '\\n']
Tokenized   (013): ['<s>', 'scroll', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsettings', 'Ġ.', 'Ġscroll', '_', 'size', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['scroll', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsettings', 'Ġ.', 'Ġscroll', '_', 'size', 'Ġ\\', 'n']
Detokenized (008): ['scroll', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsettings', 'Ġ.', 'Ġscroll_size', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""show_panel" , { "panel" : "output.elasticsearch" } ) \n"
Original    (009): ['"show_panel"', ',', '{', '"panel"', ':', '"output.elasticsearch"', '}', ')', '\\n']
Tokenized   (024): ['<s>', '"', 'show', '_', 'panel', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'panel', '"', 'Ġ:', 'Ġ"', 'output', '.', 'el', 'astic', 'search', '"', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'show', '_', 'panel', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'panel', '"', 'Ġ:', 'Ġ"', 'output', '.', 'el', 'astic', 'search', '"', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['"show_panel"', 'Ġ,', 'Ġ{', 'Ġ"panel"', 'Ġ:', 'Ġ"output.elasticsearch"', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "panel . set_read_only ( True ) \n"
Original    (007): ['panel', '.', 'set_read_only', '(', 'True', ')', '\\n']
Tokenized   (014): ['<s>', 'panel', 'Ġ.', 'Ġset', '_', 'read', '_', 'only', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['panel', 'Ġ.', 'Ġset', '_', 'read', '_', 'only', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['panel', 'Ġ.', 'Ġset_read_only', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "400 : RequestError , \n"
Original    (005): ['400', ':', 'RequestError', ',', '\\n']
Tokenized   (009): ['<s>', '400', 'Ġ:', 'ĠRequest', 'Error', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['400', 'Ġ:', 'ĠRequest', 'Error', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['400', 'Ġ:', 'ĠRequestError', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "TestConfigFileSource . ConcreteConfigFileSource ) \n"
Original    (005): ['TestConfigFileSource', '.', 'ConcreteConfigFileSource', ')', '\\n']
Tokenized   (015): ['<s>', 'Test', 'Config', 'File', 'Source', 'Ġ.', 'ĠCon', 'crete', 'Config', 'File', 'Source', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Test', 'Config', 'File', 'Source', 'Ġ.', 'ĠCon', 'crete', 'Config', 'File', 'Source', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['TestConfigFileSource', 'Ġ.', 'ĠConcreteConfigFileSource', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "ReferenceReachabilityTester . TwoWayScopeReferenceAttacher . attach ( self . _scope_tree ) \n"
Original    (011): ['ReferenceReachabilityTester', '.', 'TwoWayScopeReferenceAttacher', '.', 'attach', '(', 'self', '.', '_scope_tree', ')', '\\n']
Tokenized   (027): ['<s>', 'Reference', 'Re', 'ach', 'ability', 'T', 'ester', 'Ġ.', 'ĠTwo', 'Way', 'Scope', 'Reference', 'Att', 'acher', 'Ġ.', 'Ġattach', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'scope', '_', 'tree', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['Reference', 'Re', 'ach', 'ability', 'T', 'ester', 'Ġ.', 'ĠTwo', 'Way', 'Scope', 'Reference', 'Att', 'acher', 'Ġ.', 'Ġattach', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'scope', '_', 'tree', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['ReferenceReachabilityTester', 'Ġ.', 'ĠTwoWayScopeReferenceAttacher', 'Ġ.', 'Ġattach', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_scope_tree', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "declaring_id_node [ REFERECED_FLAG ] = True \n"
Original    (007): ['declaring_id_node', '[', 'REFERECED_FLAG', ']', '=', 'True', '\\n']
Tokenized   (020): ['<s>', 'decl', 'aring', '_', 'id', '_', 'node', 'Ġ[', 'ĠRE', 'FER', 'EC', 'ED', '_', 'FLAG', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['decl', 'aring', '_', 'id', '_', 'node', 'Ġ[', 'ĠRE', 'FER', 'EC', 'ED', '_', 'FLAG', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n']
Detokenized (007): ['declaring_id_node', 'Ġ[', 'ĠREFERECED_FLAG', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "node_type = NodeType ( node [ ] ) \n"
Original    (009): ['node_type', '=', 'NodeType', '(', 'node', '[', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'node', '_', 'type', 'Ġ=', 'ĠNode', 'Type', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['node', '_', 'type', 'Ġ=', 'ĠNode', 'Type', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['node_type', 'Ġ=', 'ĠNodeType', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "is_set_cmd = excmd_node [ ] [ ] . get ( ) in SetCommandFamily \n"
Original    (014): ['is_set_cmd', '=', 'excmd_node', '[', ']', '[', ']', '.', 'get', '(', ')', 'in', 'SetCommandFamily', '\\n']
Tokenized   (026): ['<s>', 'is', '_', 'set', '_', 'cmd', 'Ġ=', 'Ġexc', 'md', '_', 'node', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġin', 'ĠSet', 'Command', 'Family', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['is', '_', 'set', '_', 'cmd', 'Ġ=', 'Ġexc', 'md', '_', 'node', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġin', 'ĠSet', 'Command', 'Family', 'Ġ\\', 'n']
Detokenized (014): ['is_set_cmd', 'Ġ=', 'Ġexcmd_node', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġin', 'ĠSetCommandFamily', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "option_name = re . match ( , option_expr ) . group ( 0 ) \n"
Original    (015): ['option_name', '=', 're', '.', 'match', '(', ',', 'option_expr', ')', '.', 'group', '(', '0', ')', '\\n']
Tokenized   (022): ['<s>', 'option', '_', 'name', 'Ġ=', 'Ġre', 'Ġ.', 'Ġmatch', 'Ġ(', 'Ġ,', 'Ġoption', '_', 'expr', 'Ġ)', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['option', '_', 'name', 'Ġ=', 'Ġre', 'Ġ.', 'Ġmatch', 'Ġ(', 'Ġ,', 'Ġoption', '_', 'expr', 'Ġ)', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['option_name', 'Ġ=', 'Ġre', 'Ġ.', 'Ġmatch', 'Ġ(', 'Ġ,', 'Ġoption_expr', 'Ġ)', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "is_valid = option_name not in AbbreviationsIncludingInvertPrefix \n"
Original    (007): ['is_valid', '=', 'option_name', 'not', 'in', 'AbbreviationsIncludingInvertPrefix', '\\n']
Tokenized   (023): ['<s>', 'is', '_', 'valid', 'Ġ=', 'Ġoption', '_', 'name', 'Ġnot', 'Ġin', 'ĠAb', 'bre', 'vi', 'ations', 'In', 'cluding', 'In', 'vert', 'Pref', 'ix', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['is', '_', 'valid', 'Ġ=', 'Ġoption', '_', 'name', 'Ġnot', 'Ġin', 'ĠAb', 'bre', 'vi', 'ations', 'In', 'cluding', 'In', 'vert', 'Pref', 'ix', 'Ġ\\', 'n']
Detokenized (007): ['is_valid', 'Ġ=', 'Ġoption_name', 'Ġnot', 'Ġin', 'ĠAbbreviationsIncludingInvertPrefix', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "stderr . setFormatter ( logging . Formatter ( \n"
Original    (009): ['stderr', '.', 'setFormatter', '(', 'logging', '.', 'Formatter', '(', '\\n']
Tokenized   (017): ['<s>', 'st', 'der', 'r', 'Ġ.', 'Ġset', 'Form', 'atter', 'Ġ(', 'Ġlogging', 'Ġ.', 'ĠForm', 'atter', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['st', 'der', 'r', 'Ġ.', 'Ġset', 'Form', 'atter', 'Ġ(', 'Ġlogging', 'Ġ.', 'ĠForm', 'atter', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['stderr', 'Ġ.', 'ĠsetFormatter', 'Ġ(', 'Ġlogging', 'Ġ.', 'ĠFormatter', 'Ġ(', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "level = level if level else os . environ . get ( , ) \n"
Original    (015): ['level', '=', 'level', 'if', 'level', 'else', 'os', '.', 'environ', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'level', 'Ġ=', 'Ġlevel', 'Ġif', 'Ġlevel', 'Ġelse', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['level', 'Ġ=', 'Ġlevel', 'Ġif', 'Ġlevel', 'Ġelse', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['level', 'Ġ=', 'Ġlevel', 'Ġif', 'Ġlevel', 'Ġelse', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "g_s = g0 * g_c * g_R * g_D * g_T * g_M \n"
Original    (014): ['g_s', '=', 'g0', '*', 'g_c', '*', 'g_R', '*', 'g_D', '*', 'g_T', '*', 'g_M', '\\n']
Tokenized   (030): ['<s>', 'g', '_', 's', 'Ġ=', 'Ġg', '0', 'Ġ*', 'Ġg', '_', 'c', 'Ġ*', 'Ġg', '_', 'R', 'Ġ*', 'Ġg', '_', 'D', 'Ġ*', 'Ġg', '_', 'T', 'Ġ*', 'Ġg', '_', 'M', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['g', '_', 's', 'Ġ=', 'Ġg', '0', 'Ġ*', 'Ġg', '_', 'c', 'Ġ*', 'Ġg', '_', 'R', 'Ġ*', 'Ġg', '_', 'D', 'Ġ*', 'Ġg', '_', 'T', 'Ġ*', 'Ġg', '_', 'M', 'Ġ\\', 'n']
Detokenized (014): ['g_s', 'Ġ=', 'Ġg0', 'Ġ*', 'Ġg_c', 'Ġ*', 'Ġg_R', 'Ġ*', 'Ġg_D', 'Ġ*', 'Ġg_T', 'Ġ*', 'Ġg_M', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "g_T = ( ( TK - TL ) * ( TH - TK ) ** alpha_T ) / ( ( T0 - TL ) * ( TH - T0 ) ** alpha_T ) \n"
Original    (034): ['g_T', '=', '(', '(', 'TK', '-', 'TL', ')', '*', '(', 'TH', '-', 'TK', ')', '**', 'alpha_T', ')', '/', '(', '(', 'T0', '-', 'TL', ')', '*', '(', 'TH', '-', 'T0', ')', '**', 'alpha_T', ')', '\\n']
Tokenized   (047): ['<s>', 'g', '_', 'T', 'Ġ=', 'Ġ(', 'Ġ(', 'ĠT', 'K', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', 'K', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġ(', 'ĠT', '0', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', '0', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (045): ['g', '_', 'T', 'Ġ=', 'Ġ(', 'Ġ(', 'ĠT', 'K', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', 'K', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġ(', 'ĠT', '0', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', '0', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ\\', 'n']
Detokenized (034): ['g_T', 'Ġ=', 'Ġ(', 'Ġ(', 'ĠTK', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠTK', 'Ġ)', 'Ġ**', 'Ġalpha_T', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġ(', 'ĠT0', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT0', 'Ġ)', 'Ġ**', 'Ġalpha_T', 'Ġ)', 'Ġ\\n']
Counter: 45
===================================================================
Hidden states:  (13, 34, 768)
# Extracted words:  34
Sentence         : "r_a = AeroReist ( um , zm , z0 , d ) \n"
Original    (013): ['r_a', '=', 'AeroReist', '(', 'um', ',', 'zm', ',', 'z0', ',', 'd', ')', '\\n']
Tokenized   (022): ['<s>', 'r', '_', 'a', 'Ġ=', 'ĠAero', 'Re', 'ist', 'Ġ(', 'Ġum', 'Ġ,', 'Ġz', 'm', 'Ġ,', 'Ġz', '0', 'Ġ,', 'Ġd', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['r', '_', 'a', 'Ġ=', 'ĠAero', 'Re', 'ist', 'Ġ(', 'Ġum', 'Ġ,', 'Ġz', 'm', 'Ġ,', 'Ġz', '0', 'Ġ,', 'Ġd', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['r_a', 'Ġ=', 'ĠAeroReist', 'Ġ(', 'Ġum', 'Ġ,', 'Ġzm', 'Ġ,', 'Ġz0', 'Ġ,', 'Ġd', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "r_s = SurfResist ( g0 , S , D , Tc , SM , SM0 ) \n"
Original    (017): ['r_s', '=', 'SurfResist', '(', 'g0', ',', 'S', ',', 'D', ',', 'Tc', ',', 'SM', ',', 'SM0', ')', '\\n']
Tokenized   (027): ['<s>', 'r', '_', 's', 'Ġ=', 'ĠSurf', 'Res', 'ist', 'Ġ(', 'Ġg', '0', 'Ġ,', 'ĠS', 'Ġ,', 'ĠD', 'Ġ,', 'ĠT', 'c', 'Ġ,', 'ĠSM', 'Ġ,', 'ĠSM', '0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['r', '_', 's', 'Ġ=', 'ĠSurf', 'Res', 'ist', 'Ġ(', 'Ġg', '0', 'Ġ,', 'ĠS', 'Ġ,', 'ĠD', 'Ġ,', 'ĠT', 'c', 'Ġ,', 'ĠSM', 'Ġ,', 'ĠSM', '0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['r_s', 'Ġ=', 'ĠSurfResist', 'Ġ(', 'Ġg0', 'Ġ,', 'ĠS', 'Ġ,', 'ĠD', 'Ġ,', 'ĠTc', 'Ġ,', 'ĠSM', 'Ġ,', 'ĠSM0', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "LE = ( delta * Rn + ( rho_a * cP * D ) / r_a ) / ( delta + gamma * ( 1.0 + r_s / r_a ) ) \n"
Original    (032): ['LE', '=', '(', 'delta', '*', 'Rn', '+', '(', 'rho_a', '*', 'cP', '*', 'D', ')', '/', 'r_a', ')', '/', '(', 'delta', '+', 'gamma', '*', '(', '1.0', '+', 'r_s', '/', 'r_a', ')', ')', '\\n']
Tokenized   (048): ['<s>', 'LE', 'Ġ=', 'Ġ(', 'Ġdelta', 'Ġ*', 'ĠR', 'n', 'Ġ+', 'Ġ(', 'Ġr', 'ho', '_', 'a', 'Ġ*', 'Ġc', 'P', 'Ġ*', 'ĠD', 'Ġ)', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġdelta', 'Ġ+', 'Ġgamma', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ+', 'Ġr', '_', 's', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['LE', 'Ġ=', 'Ġ(', 'Ġdelta', 'Ġ*', 'ĠR', 'n', 'Ġ+', 'Ġ(', 'Ġr', 'ho', '_', 'a', 'Ġ*', 'Ġc', 'P', 'Ġ*', 'ĠD', 'Ġ)', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġdelta', 'Ġ+', 'Ġgamma', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ+', 'Ġr', '_', 's', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (032): ['LE', 'Ġ=', 'Ġ(', 'Ġdelta', 'Ġ*', 'ĠRn', 'Ġ+', 'Ġ(', 'Ġrho_a', 'Ġ*', 'ĠcP', 'Ġ*', 'ĠD', 'Ġ)', 'Ġ/', 'Ġr_a', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġdelta', 'Ġ+', 'Ġgamma', 'Ġ*', 'Ġ(', 'Ġ1.0', 'Ġ+', 'Ġr_s', 'Ġ/', 'Ġr_a', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "glClearColor ( * background_color ) \n"
Original    (006): ['glClearColor', '(', '*', 'background_color', ')', '\\n']
Tokenized   (013): ['<s>', 'gl', 'Clear', 'Color', 'Ġ(', 'Ġ*', 'Ġbackground', '_', 'color', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['gl', 'Clear', 'Color', 'Ġ(', 'Ġ*', 'Ġbackground', '_', 'color', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['glClearColor', 'Ġ(', 'Ġ*', 'Ġbackground_color', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "glScissor ( x , y , width , height ) \n"
Original    (011): ['glScissor', '(', 'x', ',', 'y', ',', 'width', ',', 'height', ')', '\\n']
Tokenized   (017): ['<s>', 'gl', 'Sc', 'iss', 'or', 'Ġ(', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġwidth', 'Ġ,', 'Ġheight', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['gl', 'Sc', 'iss', 'or', 'Ġ(', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġwidth', 'Ġ,', 'Ġheight', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['glScissor', 'Ġ(', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġwidth', 'Ġ,', 'Ġheight', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "glOrtho ( x , x + width , y , y + height , - 1 , 1 ) \n"
Original    (020): ['glOrtho', '(', 'x', ',', 'x', '+', 'width', ',', 'y', ',', 'y', '+', 'height', ',', '-', '1', ',', '1', ')', '\\n']
Tokenized   (026): ['<s>', 'gl', 'Or', 'th', 'o', 'Ġ(', 'Ġx', 'Ġ,', 'Ġx', 'Ġ+', 'Ġwidth', 'Ġ,', 'Ġy', 'Ġ,', 'Ġy', 'Ġ+', 'Ġheight', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['gl', 'Or', 'th', 'o', 'Ġ(', 'Ġx', 'Ġ,', 'Ġx', 'Ġ+', 'Ġwidth', 'Ġ,', 'Ġy', 'Ġ,', 'Ġy', 'Ġ+', 'Ġheight', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['glOrtho', 'Ġ(', 'Ġx', 'Ġ,', 'Ġx', 'Ġ+', 'Ġwidth', 'Ġ,', 'Ġy', 'Ġ,', 'Ġy', 'Ġ+', 'Ġheight', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "glNormal3f ( 0 , 1. , 0 ) \n"
Original    (009): ['glNormal3f', '(', '0', ',', '1.', ',', '0', ')', '\\n']
Tokenized   (016): ['<s>', 'gl', 'Normal', '3', 'f', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1', '.', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['gl', 'Normal', '3', 'f', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1', '.', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['glNormal3f', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1.', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "glVertex ( n , n , p ) \n"
Original    (009): ['glVertex', '(', 'n', ',', 'n', ',', 'p', ')', '\\n']
Tokenized   (014): ['<s>', 'gl', 'Ver', 'tex', 'Ġ(', 'Ġn', 'Ġ,', 'Ġn', 'Ġ,', 'Ġp', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['gl', 'Ver', 'tex', 'Ġ(', 'Ġn', 'Ġ,', 'Ġn', 'Ġ,', 'Ġp', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['glVertex', 'Ġ(', 'Ġn', 'Ġ,', 'Ġn', 'Ġ,', 'Ġp', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "companies = [ path for path in paths \n"
Original    (009): ['companies', '=', '[', 'path', 'for', 'path', 'in', 'paths', '\\n']
Tokenized   (013): ['<s>', 'compan', 'ies', 'Ġ=', 'Ġ[', 'Ġpath', 'Ġfor', 'Ġpath', 'Ġin', 'Ġpaths', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['compan', 'ies', 'Ġ=', 'Ġ[', 'Ġpath', 'Ġfor', 'Ġpath', 'Ġin', 'Ġpaths', 'Ġ\\', 'n']
Detokenized (009): ['companies', 'Ġ=', 'Ġ[', 'Ġpath', 'Ġfor', 'Ġpath', 'Ġin', 'Ġpaths', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "and os . path . exists ( os . path . join ( folder , path , ) ) ] \n"
Original    (021): ['and', 'os', '.', 'path', '.', 'exists', '(', 'os', '.', 'path', '.', 'join', '(', 'folder', ',', 'path', ',', ')', ')', ']', '\\n']
Tokenized   (024): ['<s>', 'and', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexists', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġfolder', 'Ġ,', 'Ġpath', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['and', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexists', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġfolder', 'Ġ,', 'Ġpath', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['and', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexists', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġfolder', 'Ġ,', 'Ġpath', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "folder = os . path . join ( root_folder , , , ) \n"
Original    (014): ['folder', '=', 'os', '.', 'path', '.', 'join', '(', 'root_folder', ',', ',', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'folder', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', '_', 'folder', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['folder', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', '_', 'folder', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['folder', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot_folder', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "scripts = [ , \n"
Original    (005): ['scripts', '=', '[', ',', '\\n']
Tokenized   (008): ['<s>', 'scripts', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['scripts', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['scripts', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "pro2 . predict ( ) from collections import OrderedDict \n"
Original    (010): ['pro2', '.', 'predict', '(', ')', 'from', 'collections', 'import', 'OrderedDict', '\\n']
Tokenized   (017): ['<s>', 'pro', '2', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġcollections', 'Ġimport', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['pro', '2', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġcollections', 'Ġimport', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ\\', 'n']
Detokenized (010): ['pro2', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġcollections', 'Ġimport', 'ĠOrderedDict', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : ""dimensions." % ( self . __class__ . __name__ , shape ) ) \n"
Original    (013): ['"dimensions."', '%', '(', 'self', '.', '__class__', '.', '__name__', ',', 'shape', ')', ')', '\\n']
Tokenized   (023): ['<s>', '"', 'dim', 'ensions', '."', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġshape', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', 'dim', 'ensions', '."', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġshape', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['"dimensions."', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġ,', 'Ġshape', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "only = set ( tag for tag , value in tags . items ( ) if value ) \n"
Original    (019): ['only', '=', 'set', '(', 'tag', 'for', 'tag', ',', 'value', 'in', 'tags', '.', 'items', '(', ')', 'if', 'value', ')', '\\n']
Tokenized   (022): ['<s>', 'only', 'Ġ=', 'Ġset', 'Ġ(', 'Ġtag', 'Ġfor', 'Ġtag', 'Ġ,', 'Ġvalue', 'Ġin', 'Ġtags', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['only', 'Ġ=', 'Ġset', 'Ġ(', 'Ġtag', 'Ġfor', 'Ġtag', 'Ġ,', 'Ġvalue', 'Ġin', 'Ġtags', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['only', 'Ġ=', 'Ġset', 'Ġ(', 'Ġtag', 'Ġfor', 'Ġtag', 'Ġ,', 'Ġvalue', 'Ġin', 'Ġtags', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġvalue', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "crop1 = [ None , , , ] \n"
Original    (009): ['crop1', '=', '[', 'None', ',', ',', ',', ']', '\\n']
Tokenized   (013): ['<s>', 'crop', '1', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['crop', '1', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['crop1', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "outs = [ o . eval ( ) for o in outs ] \n"
Original    (014): ['outs', '=', '[', 'o', '.', 'eval', '(', ')', 'for', 'o', 'in', 'outs', ']', '\\n']
Tokenized   (017): ['<s>', 'outs', 'Ġ=', 'Ġ[', 'Ġo', 'Ġ.', 'Ġeval', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġo', 'Ġin', 'Ġouts', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['outs', 'Ġ=', 'Ġ[', 'Ġo', 'Ġ.', 'Ġeval', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġo', 'Ġin', 'Ġouts', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['outs', 'Ġ=', 'Ġ[', 'Ġo', 'Ġ.', 'Ġeval', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġo', 'Ġin', 'Ġouts', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "crop_test ( crop_x , [ x0 , x1 , x2 , x0 , x1 , x2 ] , \n"
Original    (019): ['crop_test', '(', 'crop_x', ',', '[', 'x0', ',', 'x1', ',', 'x2', ',', 'x0', ',', 'x1', ',', 'x2', ']', ',', '\\n']
Tokenized   (032): ['<s>', 'crop', '_', 'test', 'Ġ(', 'Ġcrop', '_', 'x', 'Ġ,', 'Ġ[', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['crop', '_', 'test', 'Ġ(', 'Ġcrop', '_', 'x', 'Ġ,', 'Ġ[', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['crop_test', 'Ġ(', 'Ġcrop_x', 'Ġ,', 'Ġ[', 'Ġx0', 'Ġ,', 'Ġx1', 'Ġ,', 'Ġx2', 'Ġ,', 'Ġx0', 'Ġ,', 'Ġx1', 'Ġ,', 'Ġx2', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "cropping = [ ] * 2 ) \n"
Original    (008): ['cropping', '=', '[', ']', '*', '2', ')', '\\n']
Tokenized   (012): ['<s>', 'cro', 'pping', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ*', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['cro', 'pping', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ*', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['cropping', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ*', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "desired_result_0 = numpy . concatenate ( [ x0 [ : , : 2 ] , x1 [ : , : 2 ] ] , axis = 0 ) \n"
Original    (029): ['desired_result_0', '=', 'numpy', '.', 'concatenate', '(', '[', 'x0', '[', ':', ',', ':', '2', ']', ',', 'x1', '[', ':', ',', ':', '2', ']', ']', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (042): ['<s>', 'des', 'ired', '_', 'result', '_', '0', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['des', 'ired', '_', 'result', '_', '0', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (029): ['desired_result_0', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġconcatenate', 'Ġ(', 'Ġ[', 'Ġx0', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġx1', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "desired_result_1 = numpy . concatenate ( [ x0 [ : 4 , : ] , x1 [ : 4 , : ] ] , axis = 1 ) \n"
Original    (029): ['desired_result_1', '=', 'numpy', '.', 'concatenate', '(', '[', 'x0', '[', ':', '4', ',', ':', ']', ',', 'x1', '[', ':', '4', ',', ':', ']', ']', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (042): ['<s>', 'des', 'ired', '_', 'result', '_', '1', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['des', 'ired', '_', 'result', '_', '1', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (029): ['desired_result_1', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġconcatenate', 'Ġ(', 'Ġ[', 'Ġx0', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ,', 'Ġx1', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "inputs = [ theano . shared ( a ) , \n"
Original    (011): ['inputs', '=', '[', 'theano', '.', 'shared', '(', 'a', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'input', 's', 'Ġ=', 'Ġ[', 'Ġthe', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['input', 's', 'Ġ=', 'Ġ[', 'Ġthe', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['inputs', 'Ġ=', 'Ġ[', 'Ġtheano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "theano . shared ( b ) ] \n"
Original    (008): ['theano', '.', 'shared', '(', 'b', ')', ']', '\\n']
Tokenized   (012): ['<s>', 'the', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġb', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['the', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġb', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['theano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġb', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mask = os . urandom ( 4 ) if mask else None \n"
Original    (013): ['mask', '=', 'os', '.', 'urandom', '(', '4', ')', 'if', 'mask', 'else', 'None', '\\n']
Tokenized   (017): ['<s>', 'mask', 'Ġ=', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ4', 'Ġ)', 'Ġif', 'Ġmask', 'Ġelse', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['mask', 'Ġ=', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ4', 'Ġ)', 'Ġif', 'Ġmask', 'Ġelse', 'ĠNone', 'Ġ\\', 'n']
Detokenized (013): ['mask', 'Ġ=', 'Ġos', 'Ġ.', 'Ġurandom', 'Ġ(', 'Ġ4', 'Ġ)', 'Ġif', 'Ġmask', 'Ġelse', 'ĠNone', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "masking_key = mask , fin = 1 ) . build ( ) \n"
Original    (013): ['masking_key', '=', 'mask', ',', 'fin', '=', '1', ')', '.', 'build', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'mask', 'ing', '_', 'key', 'Ġ=', 'Ġmask', 'Ġ,', 'Ġfin', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mask', 'ing', '_', 'key', 'Ġ=', 'Ġmask', 'Ġ,', 'Ġfin', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['masking_key', 'Ġ=', 'Ġmask', 'Ġ,', 'Ġfin', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "fin = fin ) . build ( ) \n"
Original    (009): ['fin', '=', 'fin', ')', '.', 'build', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'fin', 'Ġ=', 'Ġfin', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['fin', 'Ġ=', 'Ġfin', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['fin', 'Ġ=', 'Ġfin', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "flags = unpack ( , msg [ idx : idx + 4 ] ) [ 0 ] \n"
Original    (018): ['flags', '=', 'unpack', '(', ',', 'msg', '[', 'idx', ':', 'idx', '+', '4', ']', ')', '[', '0', ']', '\\n']
Tokenized   (024): ['<s>', 'flags', 'Ġ=', 'Ġun', 'pack', 'Ġ(', 'Ġ,', 'Ġmsg', 'Ġ[', 'Ġid', 'x', 'Ġ:', 'Ġid', 'x', 'Ġ+', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['flags', 'Ġ=', 'Ġun', 'pack', 'Ġ(', 'Ġ,', 'Ġmsg', 'Ġ[', 'Ġid', 'x', 'Ġ:', 'Ġid', 'x', 'Ġ+', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['flags', 'Ġ=', 'Ġunpack', 'Ġ(', 'Ġ,', 'Ġmsg', 'Ġ[', 'Ġidx', 'Ġ:', 'Ġidx', 'Ġ+', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "pdc = req . get_options ( ) [ ] \n"
Original    (010): ['pdc', '=', 'req', '.', 'get_options', '(', ')', '[', ']', '\\n']
Tokenized   (016): ['<s>', 'p', 'dc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['p', 'dc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['pdc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget_options', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "bdc = req . get_options ( ) . get ( , False ) \n"
Original    (014): ['bdc', '=', 'req', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 'False', ')', '\\n']
Tokenized   (020): ['<s>', 'bd', 'c', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['bd', 'c', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['bdc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget_options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "decoded_path = urllib . unquote ( url . path ) [ 1 : ] \n"
Original    (015): ['decoded_path', '=', 'urllib', '.', 'unquote', '(', 'url', '.', 'path', ')', '[', '1', ':', ']', '\\n']
Tokenized   (024): ['<s>', 'dec', 'oded', '_', 'path', 'Ġ=', 'Ġur', 'll', 'ib', 'Ġ.', 'Ġun', 'quote', 'Ġ(', 'Ġurl', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['dec', 'oded', '_', 'path', 'Ġ=', 'Ġur', 'll', 'ib', 'Ġ.', 'Ġun', 'quote', 'Ġ(', 'Ġurl', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['decoded_path', 'Ġ=', 'Ġurllib', 'Ġ.', 'Ġunquote', 'Ġ(', 'Ġurl', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rules = . join ( req . requires ( ) ) . strip ( ) \n"
Original    (016): ['rules', '=', '.', 'join', '(', 'req', '.', 'requires', '(', ')', ')', '.', 'strip', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'rules', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġreq', 'Ġ.', 'Ġrequires', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rules', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġreq', 'Ġ.', 'Ġrequires', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['rules', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġreq', 'Ġ.', 'Ġrequires', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "domain = req . get_options ( ) . get ( , req . auth_name ( ) ) \n"
Original    (018): ['domain', '=', 'req', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 'req', '.', 'auth_name', '(', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'domain', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġreq', 'Ġ.', 'Ġauth', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['domain', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġreq', 'Ġ.', 'Ġauth', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['domain', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget_options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġreq', 'Ġ.', 'Ġauth_name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "auth_headers = req . headers_in . get ( , [ ] ) \n"
Original    (013): ['auth_headers', '=', 'req', '.', 'headers_in', '.', 'get', '(', ',', '[', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'auth', '_', 'headers', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġheaders', '_', 'in', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['auth', '_', 'headers', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġheaders', '_', 'in', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['auth_headers', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġheaders_in', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "set_remote_user ( req , ah_data [ 1 ] , domain ) \n"
Original    (012): ['set_remote_user', '(', 'req', ',', 'ah_data', '[', '1', ']', ',', 'domain', ')', '\\n']
Tokenized   (021): ['<s>', 'set', '_', 'remote', '_', 'user', 'Ġ(', 'Ġreq', 'Ġ,', 'Ġah', '_', 'data', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġdomain', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['set', '_', 'remote', '_', 'user', 'Ġ(', 'Ġreq', 'Ġ,', 'Ġah', '_', 'data', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġdomain', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['set_remote_user', 'Ġ(', 'Ġreq', 'Ġ,', 'Ġah_data', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġdomain', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "dict = json . loads ( request . data . decode ( ) ) \n"
Original    (015): ['dict', '=', 'json', '.', 'loads', '(', 'request', '.', 'data', '.', 'decode', '(', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'dict', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġdata', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['dict', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġdata', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['dict', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġdata', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rv = self . app . delete ( . format ( id ) ) \n"
Original    (015): ['rv', '=', 'self', '.', 'app', '.', 'delete', '(', '.', 'format', '(', 'id', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'r', 'v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġapp', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġid', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['r', 'v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġapp', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġid', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['rv', 'Ġ=', 'Ġself', 'Ġ.', 'Ġapp', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġid', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "configure_logging ( "index_pages_logging.config" , "index_pages.log" ) \n"
Original    (007): ['configure_logging', '(', '"index_pages_logging.config"', ',', '"index_pages.log"', ')', '\\n']
Tokenized   (029): ['<s>', 'config', 'ure', '_', 'log', 'ging', 'Ġ(', 'Ġ"', 'index', '_', 'pages', '_', 'log', 'ging', '.', 'config', '"', 'Ġ,', 'Ġ"', 'index', '_', 'pages', '.', 'log', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['config', 'ure', '_', 'log', 'ging', 'Ġ(', 'Ġ"', 'index', '_', 'pages', '_', 'log', 'ging', '.', 'config', '"', 'Ġ,', 'Ġ"', 'index', '_', 'pages', '.', 'log', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['configure_logging', 'Ġ(', 'Ġ"index_pages_logging.config"', 'Ġ,', 'Ġ"index_pages.log"', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ocr_file = join ( dir , ) \n"
Original    (008): ['ocr_file', '=', 'join', '(', 'dir', ',', ')', '\\n']
Tokenized   (013): ['<s>', 'ocr', '_', 'file', 'Ġ=', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['ocr', '_', 'file', 'Ġ=', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['ocr_file', 'Ġ=', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "expected_text = { "eng" : file ( join ( dir , ) ) . read ( ) . decode ( ) } \n"
Original    (023): ['expected_text', '=', '{', '"eng"', ':', 'file', '(', 'join', '(', 'dir', ',', ')', ')', '.', 'read', '(', ')', '.', 'decode', '(', ')', '}', '\\n']
Tokenized   (030): ['<s>', 'expected', '_', 'text', 'Ġ=', 'Ġ{', 'Ġ"', 'eng', '"', 'Ġ:', 'Ġfile', 'Ġ(', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['expected', '_', 'text', 'Ġ=', 'Ġ{', 'Ġ"', 'eng', '"', 'Ġ:', 'Ġfile', 'Ġ(', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (023): ['expected_text', 'Ġ=', 'Ġ{', 'Ġ"eng"', 'Ġ:', 'Ġfile', 'Ġ(', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "tuples . append ( ( os . path . join ( root , pair [ 0 ] ) , np . int32 ( pair [ 1 ] ) ) ) \n"
Original    (031): ['tuples', '.', 'append', '(', '(', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'pair', '[', '0', ']', ')', ',', 'np', '.', 'int32', '(', 'pair', '[', '1', ']', ')', ')', ')', '\\n']
Tokenized   (036): ['<s>', 'tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġpair', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġint', '32', 'Ġ(', 'Ġpair', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġpair', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġint', '32', 'Ġ(', 'Ġpair', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (031): ['tuples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġpair', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġint32', 'Ġ(', 'Ġpair', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "val_list = load_image_list ( args . val , args . root ) \n"
Original    (013): ['val_list', '=', 'load_image_list', '(', 'args', '.', 'val', ',', 'args', '.', 'root', ')', '\\n']
Tokenized   (022): ['<s>', 'val', '_', 'list', 'Ġ=', 'Ġload', '_', 'image', '_', 'list', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġval', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġroot', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['val', '_', 'list', 'Ġ=', 'Ġload', '_', 'image', '_', 'list', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġval', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġroot', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['val_list', 'Ġ=', 'Ġload_image_list', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġval', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġroot', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "mean_image = pickle . load ( open ( args . mean , ) ) \n"
Original    (015): ['mean_image', '=', 'pickle', '.', 'load', '(', 'open', '(', 'args', '.', 'mean', ',', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'mean', '_', 'image', 'Ġ=', 'Ġpick', 'le', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġmean', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['mean', '_', 'image', 'Ġ=', 'Ġpick', 'le', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġmean', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['mean_image', 'Ġ=', 'Ġpickle', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġmean', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "cropwidth = 256 - model . insize \n"
Original    (008): ['cropwidth', '=', '256', '-', 'model', '.', 'insize', '\\n']
Tokenized   (013): ['<s>', 'crop', 'width', 'Ġ=', 'Ġ256', 'Ġ-', 'Ġmodel', 'Ġ.', 'Ġins', 'ize', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['crop', 'width', 'Ġ=', 'Ġ256', 'Ġ-', 'Ġmodel', 'Ġ.', 'Ġins', 'ize', 'Ġ\\', 'n']
Detokenized (008): ['cropwidth', 'Ġ=', 'Ġ256', 'Ġ-', 'Ġmodel', 'Ġ.', 'Ġinsize', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "left = random . randint ( 0 , cropwidth - 1 ) \n"
Original    (013): ['left', '=', 'random', '.', 'randint', '(', '0', ',', 'cropwidth', '-', '1', ')', '\\n']
Tokenized   (018): ['<s>', 'left', 'Ġ=', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġcrop', 'width', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['left', 'Ġ=', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġcrop', 'width', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['left', 'Ġ=', 'Ġrandom', 'Ġ.', 'Ġrandint', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġcropwidth', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "image /= 255 \n"
Original    (004): ['image', '/=', '255', '\\n']
Tokenized   (008): ['<s>', 'image', 'Ġ/', '=', 'Ġ255', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['image', 'Ġ/', '=', 'Ġ255', 'Ġ\\', 'n']
Detokenized (004): ['image', 'Ġ/=', 'Ġ255', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "val_batch_pool = [ None ] * args . val_batchsize \n"
Original    (010): ['val_batch_pool', '=', '[', 'None', ']', '*', 'args', '.', 'val_batchsize', '\\n']
Tokenized   (020): ['<s>', 'val', '_', 'batch', '_', 'pool', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['val', '_', 'batch', '_', 'pool', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ\\', 'n']
Detokenized (010): ['val_batch_pool', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval_batchsize', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "perm = np . random . permutation ( len ( train_list ) ) \n"
Original    (014): ['perm', '=', 'np', '.', 'random', '.', 'permutation', '(', 'len', '(', 'train_list', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'perm', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġperm', 'utation', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġtrain', '_', 'list', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['perm', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġperm', 'utation', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġtrain', '_', 'list', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['perm', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġpermutation', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġtrain_list', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "batch_pool [ i ] = pool . apply_async ( read_image , ( path , False , True ) ) \n"
Original    (020): ['batch_pool', '[', 'i', ']', '=', 'pool', '.', 'apply_async', '(', 'read_image', ',', '(', 'path', ',', 'False', ',', 'True', ')', ')', '\\n']
Tokenized   (030): ['<s>', 'batch', '_', 'pool', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġpool', 'Ġ.', 'Ġapply', '_', 'as', 'ync', 'Ġ(', 'Ġread', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠFalse', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['batch', '_', 'pool', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġpool', 'Ġ.', 'Ġapply', '_', 'as', 'ync', 'Ġ(', 'Ġread', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠFalse', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['batch_pool', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġpool', 'Ġ.', 'Ġapply_async', 'Ġ(', 'Ġread_image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠFalse', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "read_image , ( path , True , False ) ) \n"
Original    (011): ['read_image', ',', '(', 'path', ',', 'True', ',', 'False', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'read', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['read', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['read_image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "val_count = val_loss = val_accuracy = 0 \n"
Original    (008): ['val_count', '=', 'val_loss', '=', 'val_accuracy', '=', '0', '\\n']
Tokenized   (018): ['<s>', 'val', '_', 'count', 'Ġ=', 'Ġval', '_', 'loss', 'Ġ=', 'Ġval', '_', 'acc', 'uracy', 'Ġ=', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['val', '_', 'count', 'Ġ=', 'Ġval', '_', 'loss', 'Ġ=', 'Ġval', '_', 'acc', 'uracy', 'Ġ=', 'Ġ0', 'Ġ\\', 'n']
Detokenized (008): ['val_count', 'Ġ=', 'Ġval_loss', 'Ġ=', 'Ġval_accuracy', 'Ġ=', 'Ġ0', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "duration = time . time ( ) - val_begin_at \n"
Original    (010): ['duration', '=', 'time', '.', 'time', '(', ')', '-', 'val_begin_at', '\\n']
Tokenized   (017): ['<s>', 'duration', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġval', '_', 'begin', '_', 'at', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['duration', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġval', '_', 'begin', '_', 'at', 'Ġ\\', 'n']
Detokenized (010): ['duration', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġval_begin_at', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "mean_error = 1 - val_accuracy * args . val_batchsize / 50000 \n"
Original    (012): ['mean_error', '=', '1', '-', 'val_accuracy', '*', 'args', '.', 'val_batchsize', '/', '50000', '\\n']
Tokenized   (024): ['<s>', 'mean', '_', 'error', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġval', '_', 'acc', 'uracy', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ/', 'Ġ5', '0000', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['mean', '_', 'error', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġval', '_', 'acc', 'uracy', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ/', 'Ġ5', '0000', 'Ġ\\', 'n']
Detokenized (012): ['mean_error', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġval_accuracy', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval_batchsize', 'Ġ/', 'Ġ50000', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "serializers . save_hdf5 ( args . outstate , optimizer ) \n"
Original    (011): ['serializers', '.', 'save_hdf5', '(', 'args', '.', 'outstate', ',', 'optimizer', ')', '\\n']
Tokenized   (021): ['<s>', 'serial', 'izers', 'Ġ.', 'Ġsave', '_', 'h', 'df', '5', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġout', 'state', 'Ġ,', 'Ġoptim', 'izer', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['serial', 'izers', 'Ġ.', 'Ġsave', '_', 'h', 'df', '5', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġout', 'state', 'Ġ,', 'Ġoptim', 'izer', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['serializers', 'Ġ.', 'Ġsave_hdf5', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġoutstate', 'Ġ,', 'Ġoptimizer', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "boards_name = [ slugify ( b [ ] ) for b in SETTINGS . get ( , { } ) . values ( ) ] \n"
Original    (026): ['boards_name', '=', '[', 'slugify', '(', 'b', '[', ']', ')', 'for', 'b', 'in', 'SETTINGS', '.', 'get', '(', ',', '{', '}', ')', '.', 'values', '(', ')', ']', '\\n']
Tokenized   (034): ['<s>', 'boards', '_', 'name', 'Ġ=', 'Ġ[', 'Ġslug', 'ify', 'Ġ(', 'Ġb', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġb', 'Ġin', 'ĠSET', 'T', 'INGS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['boards', '_', 'name', 'Ġ=', 'Ġ[', 'Ġslug', 'ify', 'Ġ(', 'Ġb', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġb', 'Ġin', 'ĠSET', 'T', 'INGS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (026): ['boards_name', 'Ġ=', 'Ġ[', 'Ġslugify', 'Ġ(', 'Ġb', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġb', 'Ġin', 'ĠSETTINGS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "LOGGING . info ( . format ( board_name , result ) ) \n"
Original    (013): ['LOGGING', '.', 'info', '(', '.', 'format', '(', 'board_name', ',', 'result', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'LOG', 'G', 'ING', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġboard', '_', 'name', 'Ġ,', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['LOG', 'G', 'ING', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġboard', '_', 'name', 'Ġ,', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['LOGGING', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġboard_name', 'Ġ,', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_py2 = _ver [ 0 ] == 2 \n"
Original    (009): ['is_py2', '=', '_ver', '[', '0', ']', '==', '2', '\\n']
Tokenized   (016): ['<s>', 'is', '_', 'py', '2', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['is', '_', 'py', '2', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ\\', 'n']
Detokenized (009): ['is_py2', 'Ġ=', 'Ġ_ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "is_py2_7_9_or_later = _ver [ 0 ] >= 2 and _ver [ 1 ] >= 7 and _ver [ 2 ] >= 9 \n"
Original    (023): ['is_py2_7_9_or_later', '=', '_ver', '[', '0', ']', '>=', '2', 'and', '_ver', '[', '1', ']', '>=', '7', 'and', '_ver', '[', '2', ']', '>=', '9', '\\n']
Tokenized   (040): ['<s>', 'is', '_', 'py', '2', '_', '7', '_', '9', '_', 'or', '_', 'later', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ>=', 'Ġ2', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ>=', 'Ġ7', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ>=', 'Ġ9', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['is', '_', 'py', '2', '_', '7', '_', '9', '_', 'or', '_', 'later', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ>=', 'Ġ2', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ>=', 'Ġ7', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ>=', 'Ġ9', 'Ġ\\', 'n']
Detokenized (023): ['is_py2_7_9_or_later', 'Ġ=', 'Ġ_ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ>=', 'Ġ2', 'Ġand', 'Ġ_ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ>=', 'Ġ7', 'Ġand', 'Ġ_ver', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ>=', 'Ġ9', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "is_py3_3 = is_py3 and _ver [ 1 ] == 3 \n"
Original    (011): ['is_py3_3', '=', 'is_py3', 'and', '_ver', '[', '1', ']', '==', '3', '\\n']
Tokenized   (023): ['<s>', 'is', '_', 'py', '3', '_', '3', 'Ġ=', 'Ġis', '_', 'py', '3', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ==', 'Ġ3', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['is', '_', 'py', '3', '_', '3', 'Ġ=', 'Ġis', '_', 'py', '3', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ==', 'Ġ3', 'Ġ\\', 'n']
Detokenized (011): ['is_py3_3', 'Ġ=', 'Ġis_py3', 'Ġand', 'Ġ_ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ==', 'Ġ3', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "strategy = zlib . Z_DEFAULT_STRATEGY ) : \n"
Original    (008): ['strategy', '=', 'zlib', '.', 'Z_DEFAULT_STRATEGY', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'str', 'ategy', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'ĠZ', '_', 'DE', 'FAULT', '_', 'STR', 'ATE', 'GY', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['str', 'ategy', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'ĠZ', '_', 'DE', 'FAULT', '_', 'STR', 'ATE', 'GY', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['strategy', 'Ġ=', 'Ġzlib', 'Ġ.', 'ĠZ_DEFAULT_STRATEGY', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "secure = self . secure \n"
Original    (006): ['secure', '=', 'self', '.', 'secure', '\\n']
Tokenized   (009): ['<s>', 'secure', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsecure', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['secure', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsecure', 'Ġ\\', 'n']
Detokenized (006): ['secure', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsecure', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "e . huffman_coder = HuffmanEncoder ( REQUEST_CODES , REQUEST_CODES_LENGTH ) \n"
Original    (011): ['e', '.', 'huffman_coder', '=', 'HuffmanEncoder', '(', 'REQUEST_CODES', ',', 'REQUEST_CODES_LENGTH', ')', '\\n']
Tokenized   (035): ['<s>', 'e', 'Ġ.', 'Ġh', 'uff', 'man', '_', 'c', 'oder', 'Ġ=', 'ĠHuff', 'man', 'Enc', 'oder', 'Ġ(', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', 'Ġ,', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', '_', 'L', 'ENGTH', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['e', 'Ġ.', 'Ġh', 'uff', 'man', '_', 'c', 'oder', 'Ġ=', 'ĠHuff', 'man', 'Enc', 'oder', 'Ġ(', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', 'Ġ,', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', '_', 'L', 'ENGTH', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['e', 'Ġ.', 'Ġhuffman_coder', 'Ġ=', 'ĠHuffmanEncoder', 'Ġ(', 'ĠREQUEST_CODES', 'Ġ,', 'ĠREQUEST_CODES_LENGTH', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "train_seq = corpus . read_sequence_list_conll ( input_data , max_sent_len = 15 , max_nr_sent = 1000 ) \n"
Original    (017): ['train_seq', '=', 'corpus', '.', 'read_sequence_list_conll', '(', 'input_data', ',', 'max_sent_len', '=', '15', ',', 'max_nr_sent', '=', '1000', ')', '\\n']
Tokenized   (039): ['<s>', 'train', '_', 'seq', 'Ġ=', 'Ġcorpus', 'Ġ.', 'Ġread', '_', 'sequence', '_', 'list', '_', 'con', 'll', 'Ġ(', 'Ġinput', '_', 'data', 'Ġ,', 'Ġmax', '_', 'sent', '_', 'len', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġmax', '_', 'nr', '_', 'sent', 'Ġ=', 'Ġ1000', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['train', '_', 'seq', 'Ġ=', 'Ġcorpus', 'Ġ.', 'Ġread', '_', 'sequence', '_', 'list', '_', 'con', 'll', 'Ġ(', 'Ġinput', '_', 'data', 'Ġ,', 'Ġmax', '_', 'sent', '_', 'len', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġmax', '_', 'nr', '_', 'sent', 'Ġ=', 'Ġ1000', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['train_seq', 'Ġ=', 'Ġcorpus', 'Ġ.', 'Ġread_sequence_list_conll', 'Ġ(', 'Ġinput_data', 'Ġ,', 'Ġmax_sent_len', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġmax_nr_sent', 'Ġ=', 'Ġ1000', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "pickle . dump ( ( corpus . word_dict , corpus . tag_dict ) , open ( , ) ) \n"
Original    (020): ['pickle', '.', 'dump', '(', '(', 'corpus', '.', 'word_dict', ',', 'corpus', '.', 'tag_dict', ')', ',', 'open', '(', ',', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'pick', 'le', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġ(', 'Ġcorpus', 'Ġ.', 'Ġword', '_', 'dict', 'Ġ,', 'Ġcorpus', 'Ġ.', 'Ġtag', '_', 'dict', 'Ġ)', 'Ġ,', 'Ġopen', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['pick', 'le', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġ(', 'Ġcorpus', 'Ġ.', 'Ġword', '_', 'dict', 'Ġ,', 'Ġcorpus', 'Ġ.', 'Ġtag', '_', 'dict', 'Ġ)', 'Ġ,', 'Ġopen', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['pickle', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġ(', 'Ġcorpus', 'Ġ.', 'Ġword_dict', 'Ġ,', 'Ġcorpus', 'Ġ.', 'Ġtag_dict', 'Ġ)', 'Ġ,', 'Ġopen', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "total = np . zeros ( self . features . n_feats ) \n"
Original    (013): ['total', '=', 'np', '.', 'zeros', '(', 'self', '.', 'features', '.', 'n_feats', ')', '\\n']
Tokenized   (020): ['<s>', 'total', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġn', '_', 'fe', 'ats', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['total', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġn', '_', 'fe', 'ats', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['total', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġzeros', 'Ġ(', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġn_feats', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "scores = self . features . compute_scores ( feats , self . weights ) \n"
Original    (015): ['scores', '=', 'self', '.', 'features', '.', 'compute_scores', '(', 'feats', ',', 'self', '.', 'weights', ')', '\\n']
Tokenized   (022): ['<s>', 'sc', 'ores', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġcompute', '_', 'sc', 'ores', 'Ġ(', 'Ġfeats', 'Ġ,', 'Ġself', 'Ġ.', 'Ġweights', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['sc', 'ores', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġcompute', '_', 'sc', 'ores', 'Ġ(', 'Ġfeats', 'Ġ,', 'Ġself', 'Ġ.', 'Ġweights', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['scores', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġcompute_scores', 'Ġ(', 'Ġfeats', 'Ġ,', 'Ġself', 'Ġ.', 'Ġweights', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "t0 = 1.0 / ( sigma * eta0 ) \n"
Original    (010): ['t0', '=', '1.0', '/', '(', 'sigma', '*', 'eta0', ')', '\\n']
Tokenized   (019): ['<s>', 't', '0', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ(', 'Ġs', 'igma', 'Ġ*', 'Ġet', 'a', '0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['t', '0', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ(', 'Ġs', 'igma', 'Ġ*', 'Ġet', 'a', '0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['t0', 'Ġ=', 'Ġ1.0', 'Ġ/', 'Ġ(', 'Ġsigma', 'Ġ*', 'Ġeta0', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "marginals , logZ = self . decoder . parse_marginals_nonproj ( scores ) \n"
Original    (013): ['marginals', ',', 'logZ', '=', 'self', '.', 'decoder', '.', 'parse_marginals_nonproj', '(', 'scores', ')', '\\n']
Tokenized   (026): ['<s>', 'marg', 'inals', 'Ġ,', 'Ġlog', 'Z', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdec', 'oder', 'Ġ.', 'Ġparse', '_', 'marg', 'inals', '_', 'non', 'pro', 'j', 'Ġ(', 'Ġscores', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['marg', 'inals', 'Ġ,', 'Ġlog', 'Z', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdec', 'oder', 'Ġ.', 'Ġparse', '_', 'marg', 'inals', '_', 'non', 'pro', 'j', 'Ġ(', 'Ġscores', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['marginals', 'Ġ,', 'ĠlogZ', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdecoder', 'Ġ.', 'Ġparse_marginals_nonproj', 'Ġ(', 'Ġscores', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "score_corr += scores [ h , m ] \n"
Original    (009): ['score_corr', '+=', 'scores', '[', 'h', ',', 'm', ']', '\\n']
Tokenized   (015): ['<s>', 'score', '_', 'cor', 'r', 'Ġ+=', 'Ġscores', 'Ġ[', 'Ġh', 'Ġ,', 'Ġm', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['score', '_', 'cor', 'r', 'Ġ+=', 'Ġscores', 'Ġ[', 'Ġh', 'Ġ,', 'Ġm', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['score_corr', 'Ġ+=', 'Ġscores', 'Ġ[', 'Ġh', 'Ġ,', 'Ġm', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "features = self . add_final_features ( sequence , sequence . y [ - 1 ] , features ) \n"
Original    (019): ['features', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'sequence', '.', 'y', '[', '-', '1', ']', ',', 'features', ')', '\\n']
Tokenized   (026): ['<s>', 'features', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġsequence', 'Ġ.', 'Ġy', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġfeatures', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['features', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġsequence', 'Ġ.', 'Ġy', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġfeatures', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['features', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd_final_features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġsequence', 'Ġ.', 'Ġy', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġfeatures', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "node_idx = self . add_emission_features ( sequence , pos , y , node_idx ) \n"
Original    (015): ['node_idx', '=', 'self', '.', 'add_emission_features', '(', 'sequence', ',', 'pos', ',', 'y', ',', 'node_idx', ')', '\\n']
Tokenized   (029): ['<s>', 'node', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'em', 'ission', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġpos', 'Ġ,', 'Ġy', 'Ġ,', 'Ġnode', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['node', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'em', 'ission', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġpos', 'Ġ,', 'Ġy', 'Ġ,', 'Ġnode', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['node_idx', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd_emission_features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġpos', 'Ġ,', 'Ġy', 'Ġ,', 'Ġnode_idx', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "edge_idx = self . add_final_features ( sequence , y_prev , edge_idx ) \n"
Original    (013): ['edge_idx', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'y_prev', ',', 'edge_idx', ')', '\\n']
Tokenized   (028): ['<s>', 'edge', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġy', '_', 'prev', 'Ġ,', 'Ġedge', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['edge', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġy', '_', 'prev', 'Ġ,', 'Ġedge', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['edge_idx', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd_final_features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġy_prev', 'Ġ,', 'Ġedge_idx', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "y_name = self . dataset . y_dict . get_label_name ( y ) \n"
Original    (013): ['y_name', '=', 'self', '.', 'dataset', '.', 'y_dict', '.', 'get_label_name', '(', 'y', ')', '\\n']
Tokenized   (024): ['<s>', 'y', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdataset', 'Ġ.', 'Ġy', '_', 'dict', 'Ġ.', 'Ġget', '_', 'label', '_', 'name', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['y', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdataset', 'Ġ.', 'Ġy', '_', 'dict', 'Ġ.', 'Ġget', '_', 'label', '_', 'name', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['y_name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdataset', 'Ġ.', 'Ġy_dict', 'Ġ.', 'Ġget_label_name', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "feat_name = "prev_tag:%s::%s" % ( y_prev_name , y_name ) \n"
Original    (010): ['feat_name', '=', '"prev_tag:%s::%s"', '%', '(', 'y_prev_name', ',', 'y_name', ')', '\\n']
Tokenized   (031): ['<s>', 'feat', '_', 'name', 'Ġ=', 'Ġ"', 'prev', '_', 'tag', ':', '%', 's', '::', '%', 's', '"', 'Ġ%', 'Ġ(', 'Ġy', '_', 'prev', '_', 'name', 'Ġ,', 'Ġy', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['feat', '_', 'name', 'Ġ=', 'Ġ"', 'prev', '_', 'tag', ':', '%', 's', '::', '%', 's', '"', 'Ġ%', 'Ġ(', 'Ġy', '_', 'prev', '_', 'name', 'Ġ,', 'Ġy', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['feat_name', 'Ġ=', 'Ġ"prev_tag:%s::%s"', 'Ġ%', 'Ġ(', 'Ġy_prev_name', 'Ġ,', 'Ġy_name', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "point_geom . AddPoint ( point [ 0 ] , point [ 1 ] ) \n"
Original    (015): ['point_geom', '.', 'AddPoint', '(', 'point', '[', '0', ']', ',', 'point', '[', '1', ']', ')', '\\n']
Tokenized   (022): ['<s>', 'point', '_', 'ge', 'om', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġpoint', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġpoint', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['point', '_', 'ge', 'om', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġpoint', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġpoint', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['point_geom', 'Ġ.', 'ĠAddPoint', 'Ġ(', 'Ġpoint', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġpoint', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "longitudes = [ 100 , 110 , 120 , 130 , 140 ] \n"
Original    (014): ['longitudes', '=', '[', '100', ',', '110', ',', '120', ',', '130', ',', '140', ']', '\\n']
Tokenized   (018): ['<s>', 'long', 'itudes', 'Ġ=', 'Ġ[', 'Ġ100', 'Ġ,', 'Ġ110', 'Ġ,', 'Ġ120', 'Ġ,', 'Ġ130', 'Ġ,', 'Ġ140', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['long', 'itudes', 'Ġ=', 'Ġ[', 'Ġ100', 'Ġ,', 'Ġ110', 'Ġ,', 'Ġ120', 'Ġ,', 'Ġ130', 'Ġ,', 'Ġ140', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['longitudes', 'Ġ=', 'Ġ[', 'Ġ100', 'Ġ,', 'Ġ110', 'Ġ,', 'Ġ120', 'Ġ,', 'Ġ130', 'Ġ,', 'Ġ140', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "point_1 . AddPoint ( longitudes [ 0 ] , latitudes [ 0 ] , elevation ) \n"
Original    (017): ['point_1', '.', 'AddPoint', '(', 'longitudes', '[', '0', ']', ',', 'latitudes', '[', '0', ']', ',', 'elevation', ')', '\\n']
Tokenized   (025): ['<s>', 'point', '_', '1', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġlong', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġlat', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġelevation', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['point', '_', '1', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġlong', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġlat', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġelevation', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['point_1', 'Ġ.', 'ĠAddPoint', 'Ġ(', 'Ġlongitudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġlatitudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġelevation', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "di = np . array ( [ x for x in range ( projected_X . shape [ 1 ] ) ] ) \n"
Original    (023): ['di', '=', 'np', '.', 'array', '(', '[', 'x', 'for', 'x', 'in', 'range', '(', 'projected_X', '.', 'shape', '[', '1', ']', ')', ']', ')', '\\n']
Tokenized   (028): ['<s>', 'di', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġprojected', '_', 'X', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['di', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġprojected', '_', 'X', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['di', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġprojected_X', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "projected_X = np . c_ [ ids , projected_X ] \n"
Original    (011): ['projected_X', '=', 'np', '.', 'c_', '[', 'ids', ',', 'projected_X', ']', '\\n']
Tokenized   (021): ['<s>', 'project', 'ed', '_', 'X', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġc', '_', 'Ġ[', 'Ġ', 'ids', 'Ġ,', 'Ġprojected', '_', 'X', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['project', 'ed', '_', 'X', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġc', '_', 'Ġ[', 'Ġ', 'ids', 'Ġ,', 'Ġprojected', '_', 'X', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['projected_X', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġc_', 'Ġ[', 'Ġids', 'Ġ,', 'Ġprojected_X', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "clusterer . fit ( inverse_x [ : , 1 : ] ) \n"
Original    (013): ['clusterer', '.', 'fit', '(', 'inverse_x', '[', ':', ',', '1', ':', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'cl', 'ust', 'erer', 'Ġ.', 'Ġfit', 'Ġ(', 'Ġinverse', '_', 'x', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['cl', 'ust', 'erer', 'Ġ.', 'Ġfit', 'Ġ(', 'Ġinverse', '_', 'x', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['clusterer', 'Ġ.', 'Ġfit', 'Ġ(', 'Ġinverse_x', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "complex [ "meta" ] = self . projection \n"
Original    (009): ['complex', '[', '"meta"', ']', '=', 'self', '.', 'projection', '\\n']
Tokenized   (014): ['<s>', 'complex', 'Ġ[', 'Ġ"', 'meta', '"', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprojection', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['complex', 'Ġ[', 'Ġ"', 'meta', '"', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprojection', 'Ġ\\', 'n']
Detokenized (009): ['complex', 'Ġ[', 'Ġ"meta"', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprojection', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "json_s [ "nodes" ] . append ( { "name" : str ( k ) , "tooltip" : tooltip_s , "group" : 2 * int ( np . log ( len ( complex ~~ k2e [ k ] = e \n"
Original    (040): ['json_s', '[', '"nodes"', ']', '.', 'append', '(', '{', '"name"', ':', 'str', '(', 'k', ')', ',', '"tooltip"', ':', 'tooltip_s', ',', '"group"', ':', '2', '*', 'int', '(', 'np', '.', 'log', '(', 'len', '(', 'complex', '~~', 'k2e', '[', 'k', ']', '=', 'e', '\\n']
Tokenized   (060): ['<s>', 'json', '_', 's', 'Ġ[', 'Ġ"', 'n', 'odes', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ"', 'name', '"', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġk', 'Ġ)', 'Ġ,', 'Ġ"', 'tool', 'tip', '"', 'Ġ:', 'Ġtooltip', '_', 's', 'Ġ,', 'Ġ"', 'group', '"', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġint', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġlog', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġcomplex', 'Ġ', '~~', 'Ġk', '2', 'e', 'Ġ[', 'Ġk', 'Ġ]', 'Ġ=', 'Ġe', 'Ġ\\', 'n', '</s>']
Filtered   (058): ['json', '_', 's', 'Ġ[', 'Ġ"', 'n', 'odes', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ"', 'name', '"', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġk', 'Ġ)', 'Ġ,', 'Ġ"', 'tool', 'tip', '"', 'Ġ:', 'Ġtooltip', '_', 's', 'Ġ,', 'Ġ"', 'group', '"', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġint', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġlog', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġcomplex', 'Ġ', '~~', 'Ġk', '2', 'e', 'Ġ[', 'Ġk', 'Ġ]', 'Ġ=', 'Ġe', 'Ġ\\', 'n']
Detokenized (040): ['json_s', 'Ġ[', 'Ġ"nodes"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ"name"', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġk', 'Ġ)', 'Ġ,', 'Ġ"tooltip"', 'Ġ:', 'Ġtooltip_s', 'Ġ,', 'Ġ"group"', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġint', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġlog', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġcomplex', 'Ġ~~', 'Ġk2e', 'Ġ[', 'Ġk', 'Ġ]', 'Ġ=', 'Ġe', 'Ġ\\n']
Counter: 58
===================================================================
Hidden states:  (13, 40, 768)
# Extracted words:  40
Sentence         : "width_js = "%s" % width_html \n"
Original    (006): ['width_js', '=', '"%s"', '%', 'width_html', '\\n']
Tokenized   (015): ['<s>', 'width', '_', 'js', 'Ġ=', 'Ġ"%', 's', '"', 'Ġ%', 'Ġwidth', '_', 'html', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['width', '_', 'js', 'Ġ=', 'Ġ"%', 's', '"', 'Ġ%', 'Ġwidth', '_', 'html', 'Ġ\\', 'n']
Detokenized (006): ['width_js', 'Ġ=', 'Ġ"%s"', 'Ġ%', 'Ġwidth_html', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "new_settings [ interface ] [ ] [ % protocol ] = server \n"
Original    (013): ['new_settings', '[', 'interface', ']', '[', ']', '[', '%', 'protocol', ']', '=', 'server', '\\n']
Tokenized   (018): ['<s>', 'new', '_', 'settings', 'Ġ[', 'Ġinterface', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ%', 'Ġprotocol', 'Ġ]', 'Ġ=', 'Ġserver', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['new', '_', 'settings', 'Ġ[', 'Ġinterface', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ%', 'Ġprotocol', 'Ġ]', 'Ġ=', 'Ġserver', 'Ġ\\', 'n']
Detokenized (013): ['new_settings', 'Ġ[', 'Ġinterface', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ%', 'Ġprotocol', 'Ġ]', 'Ġ=', 'Ġserver', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "setups = ( less_setup , sass_setup , stylus_setup , sass_erb_setup ) \n"
Original    (012): ['setups', '=', '(', 'less_setup', ',', 'sass_setup', ',', 'stylus_setup', ',', 'sass_erb_setup', ')', '\\n']
Tokenized   (029): ['<s>', 'set', 'ups', 'Ġ=', 'Ġ(', 'Ġless', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'setup', 'Ġ,', 'Ġstyl', 'us', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'erb', '_', 'setup', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['set', 'ups', 'Ġ=', 'Ġ(', 'Ġless', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'setup', 'Ġ,', 'Ġstyl', 'us', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'erb', '_', 'setup', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['setups', 'Ġ=', 'Ġ(', 'Ġless_setup', 'Ġ,', 'Ġsass_setup', 'Ġ,', 'Ġstylus_setup', 'Ġ,', 'Ġsass_erb_setup', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fn = self . view . file_name ( ) . encode ( "utf_8" ) \n"
Original    (015): ['fn', '=', 'self', '.', 'view', '.', 'file_name', '(', ')', '.', 'encode', '(', '"utf_8"', ')', '\\n']
Tokenized   (024): ['<s>', 'fn', 'Ġ=', 'Ġself', 'Ġ.', 'Ġview', 'Ġ.', 'Ġfile', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ"', 'utf', '_', '8', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['fn', 'Ġ=', 'Ġself', 'Ġ.', 'Ġview', 'Ġ.', 'Ġfile', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ"', 'utf', '_', '8', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['fn', 'Ġ=', 'Ġself', 'Ġ.', 'Ġview', 'Ġ.', 'Ġfile_name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ"utf_8"', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "compiled_regex = re . compile ( chosen_setup . regex , re . MULTILINE ) \n"
Original    (015): ['compiled_regex', '=', 're', '.', 'compile', '(', 'chosen_setup', '.', 'regex', ',', 're', '.', 'MULTILINE', ')', '\\n']
Tokenized   (027): ['<s>', 'comp', 'iled', '_', 're', 'gex', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġchosen', '_', 'setup', 'Ġ.', 'Ġregex', 'Ġ,', 'Ġre', 'Ġ.', 'ĠM', 'ULT', 'IL', 'INE', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['comp', 'iled', '_', 're', 'gex', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġchosen', '_', 'setup', 'Ġ.', 'Ġregex', 'Ġ,', 'Ġre', 'Ġ.', 'ĠM', 'ULT', 'IL', 'INE', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['compiled_regex', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġchosen_setup', 'Ġ.', 'Ġregex', 'Ġ,', 'Ġre', 'Ġ.', 'ĠMULTILINE', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "file_dir = os . path . dirname ( fn ) . decode ( "utf-8" ) \n"
Original    (016): ['file_dir', '=', 'os', '.', 'path', '.', 'dirname', '(', 'fn', ')', '.', 'decode', '(', '"utf-8"', ')', '\\n']
Tokenized   (026): ['<s>', 'file', '_', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġfn', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['file', '_', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġfn', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['file_dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġfn', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"utf-8"', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "partial_filename = fn_split [ 0 ] + "/_" + fn_split [ 1 ] \n"
Original    (014): ['partial_filename', '=', 'fn_split', '[', '0', ']', '+', '"/_"', '+', 'fn_split', '[', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'partial', '_', 'filename', 'Ġ=', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ"/', '_', '"', 'Ġ+', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['partial', '_', 'filename', 'Ġ=', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ"/', '_', '"', 'Ġ+', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['partial_filename', 'Ġ=', 'Ġfn_split', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ"/_"', 'Ġ+', 'Ġfn_split', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "imported_vars = imported_vars + m \n"
Original    (006): ['imported_vars', '=', 'imported_vars', '+', 'm', '\\n']
Tokenized   (016): ['<s>', 'im', 'ported', '_', 'v', 'ars', 'Ġ=', 'Ġimported', '_', 'v', 'ars', 'Ġ+', 'Ġm', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['im', 'ported', '_', 'v', 'ars', 'Ġ=', 'Ġimported', '_', 'v', 'ars', 'Ġ+', 'Ġm', 'Ġ\\', 'n']
Detokenized (006): ['imported_vars', 'Ġ=', 'Ġimported_vars', 'Ġ+', 'Ġm', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : ""params" : [ { \n"
Original    (005): ['"params"', ':', '[', '{', '\\n']
Tokenized   (010): ['<s>', '"', 'params', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'params', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ\\', 'n']
Detokenized (005): ['"params"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "LAT_MAX = + 90.0 \n"
Original    (005): ['LAT_MAX', '=', '+', '90.0', '\\n']
Tokenized   (013): ['<s>', 'L', 'AT', '_', 'MAX', 'Ġ=', 'Ġ+', 'Ġ90', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['L', 'AT', '_', 'MAX', 'Ġ=', 'Ġ+', 'Ġ90', '.', '0', 'Ġ\\', 'n']
Detokenized (005): ['LAT_MAX', 'Ġ=', 'Ġ+', 'Ġ90.0', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""purple" , "teal" , "lightgray" ] \n"
Original    (007): ['"purple"', ',', '"teal"', ',', '"lightgray"', ']', '\\n']
Tokenized   (019): ['<s>', '"', 'pur', 'ple', '"', 'Ġ,', 'Ġ"', 'te', 'al', '"', 'Ġ,', 'Ġ"', 'light', 'gray', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['"', 'pur', 'ple', '"', 'Ġ,', 'Ġ"', 'te', 'al', '"', 'Ġ,', 'Ġ"', 'light', 'gray', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['"purple"', 'Ġ,', 'Ġ"teal"', 'Ġ,', 'Ġ"lightgray"', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "numrange = None , default = None , max_width = 72 ) : \n"
Original    (014): ['numrange', '=', 'None', ',', 'default', '=', 'None', ',', 'max_width', '=', '72', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'num', 'range', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdefault', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġmax', '_', 'width', 'Ġ=', 'Ġ72', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['num', 'range', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdefault', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġmax', '_', 'width', 'Ġ=', 'Ġ72', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (014): ['numrange', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdefault', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġmax_width', 'Ġ=', 'Ġ72', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "found_letter . lower ( ) == default . lower ( ) ) ) : \n"
Original    (015): ['found_letter', '.', 'lower', '(', ')', '==', 'default', '.', 'lower', '(', ')', ')', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'found', '_', 'letter', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġdefault', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['found', '_', 'letter', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġdefault', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (015): ['found_letter', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġdefault', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "option [ : index ] + show_letter + option [ index + 1 : ] \n"
Original    (016): ['option', '[', ':', 'index', ']', '+', 'show_letter', '+', 'option', '[', 'index', '+', '1', ':', ']', '\\n']
Tokenized   (021): ['<s>', 'option', 'Ġ[', 'Ġ:', 'Ġindex', 'Ġ]', 'Ġ+', 'Ġshow', '_', 'letter', 'Ġ+', 'Ġoption', 'Ġ[', 'Ġindex', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['option', 'Ġ[', 'Ġ:', 'Ġindex', 'Ġ]', 'Ġ+', 'Ġshow', '_', 'letter', 'Ġ+', 'Ġoption', 'Ġ[', 'Ġindex', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['option', 'Ġ[', 'Ġ:', 'Ġindex', 'Ġ]', 'Ġ+', 'Ġshow_letter', 'Ġ+', 'Ġoption', 'Ġ[', 'Ġindex', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "display_letters . append ( found_letter . upper ( ) ) \n"
Original    (011): ['display_letters', '.', 'append', '(', 'found_letter', '.', 'upper', '(', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'display', '_', 'letters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfound', '_', 'letter', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['display', '_', 'letters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfound', '_', 'letter', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['display_letters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfound_letter', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "default_name = self . colorize ( , default_name ) \n"
Original    (010): ['default_name', '=', 'self', '.', 'colorize', '(', ',', 'default_name', ')', '\\n']
Tokenized   (018): ['<s>', 'default', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġ,', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['default', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġ,', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['default_name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcolorize', 'Ġ(', 'Ġ,', 'Ġdefault_name', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "prompt_parts . append ( tmpl % default_name ) \n"
Original    (009): ['prompt_parts', '.', 'append', '(', 'tmpl', '%', 'default_name', ')', '\\n']
Tokenized   (019): ['<s>', 'prom', 'pt', '_', 'parts', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġt', 'm', 'pl', 'Ġ%', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['prom', 'pt', '_', 'parts', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġt', 'm', 'pl', 'Ġ%', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['prompt_parts', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġtmpl', 'Ġ%', 'Ġdefault_name', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "matcher = SequenceMatcher ( lambda x : False , a , b ) \n"
Original    (014): ['matcher', '=', 'SequenceMatcher', '(', 'lambda', 'x', ':', 'False', ',', 'a', ',', 'b', ')', '\\n']
Tokenized   (020): ['<s>', 'mat', 'cher', 'Ġ=', 'ĠSequence', 'Mat', 'cher', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'ĠFalse', 'Ġ,', 'Ġa', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['mat', 'cher', 'Ġ=', 'ĠSequence', 'Mat', 'cher', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'ĠFalse', 'Ġ,', 'Ġa', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['matcher', 'Ġ=', 'ĠSequenceMatcher', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'ĠFalse', 'Ġ,', 'Ġa', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "b_out . append ( self . colorize ( color , b [ b_start : b_end ] ) ) \n"
Original    (019): ['b_out', '.', 'append', '(', 'self', '.', 'colorize', '(', 'color', ',', 'b', '[', 'b_start', ':', 'b_end', ']', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'b', '_', 'out', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġcolor', 'Ġ,', 'Ġb', 'Ġ[', 'Ġb', '_', 'start', 'Ġ:', 'Ġb', '_', 'end', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['b', '_', 'out', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġcolor', 'Ġ,', 'Ġb', 'Ġ[', 'Ġb', '_', 'start', 'Ġ:', 'Ġb', '_', 'end', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['b_out', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcolorize', 'Ġ(', 'Ġcolor', 'Ġ,', 'Ġb', 'Ġ[', 'Ġb_start', 'Ġ:', 'Ġb_end', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "variable = % varname \n"
Original    (005): ['variable', '=', '%', 'varname', '\\n']
Tokenized   (009): ['<s>', 'variable', 'Ġ=', 'Ġ%', 'Ġvar', 'name', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['variable', 'Ġ=', 'Ġ%', 'Ġvar', 'name', 'Ġ\\', 'n']
Detokenized (005): ['variable', 'Ġ=', 'Ġ%', 'Ġvarname', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "62 : , \n"
Original    (004): ['62', ':', ',', '\\n']
Tokenized   (007): ['<s>', '62', 'Ġ:', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['62', 'Ġ:', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['62', 'Ġ:', 'Ġ,', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "_push . update ( { \n"
Original    (006): ['_push', '.', 'update', '(', '{', '\\n']
Tokenized   (010): ['<s>', '_', 'push', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['_', 'push', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ{', 'Ġ\\', 'n']
Detokenized (006): ['_push', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ{', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_readonly = Entity . _readonly | { , } \n"
Original    (010): ['_readonly', '=', 'Entity', '.', '_readonly', '|', '{', ',', '}', '\\n']
Tokenized   (017): ['<s>', '_', 'read', 'only', 'Ġ=', 'ĠEntity', 'Ġ.', 'Ġ_', 'read', 'only', 'Ġ|', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['_', 'read', 'only', 'Ġ=', 'ĠEntity', 'Ġ.', 'Ġ_', 'read', 'only', 'Ġ|', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n']
Detokenized (010): ['_readonly', 'Ġ=', 'ĠEntity', 'Ġ.', 'Ġ_readonly', 'Ġ|', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "remove_ids = [ 6 , 7 ] \n"
Original    (008): ['remove_ids', '=', '[', '6', ',', '7', ']', '\\n']
Tokenized   (013): ['<s>', 'remove', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ6', 'Ġ,', 'Ġ7', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['remove', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ6', 'Ġ,', 'Ġ7', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['remove_ids', 'Ġ=', 'Ġ[', 'Ġ6', 'Ġ,', 'Ġ7', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "remove_advertiser_ids = [ 8 , 9 , 10 ] \n"
Original    (010): ['remove_advertiser_ids', '=', '[', '8', ',', '9', ',', '10', ']', '\\n']
Tokenized   (019): ['<s>', 'remove', '_', 'ad', 'vertis', 'er', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ,', 'Ġ9', 'Ġ,', 'Ġ10', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['remove', '_', 'ad', 'vertis', 'er', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ,', 'Ġ9', 'Ġ,', 'Ġ10', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['remove_advertiser_ids', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ,', 'Ġ9', 'Ġ,', 'Ġ10', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "num_users , num_items = dataset . shape \n"
Original    (008): ['num_users', ',', 'num_items', '=', 'dataset', '.', 'shape', '\\n']
Tokenized   (015): ['<s>', 'num', '_', 'users', 'Ġ,', 'Ġnum', '_', 'items', 'Ġ=', 'Ġdataset', 'Ġ.', 'Ġshape', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['num', '_', 'users', 'Ġ,', 'Ġnum', '_', 'items', 'Ġ=', 'Ġdataset', 'Ġ.', 'Ġshape', 'Ġ\\', 'n']
Detokenized (008): ['num_users', 'Ġ,', 'Ġnum_items', 'Ġ=', 'Ġdataset', 'Ġ.', 'Ġshape', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "async_job = view . map_async ( process , tasks , retries = 2 ) \n"
Original    (015): ['async_job', '=', 'view', '.', 'map_async', '(', 'process', ',', 'tasks', ',', 'retries', '=', '2', ')', '\\n']
Tokenized   (025): ['<s>', 'as', 'ync', '_', 'job', 'Ġ=', 'Ġview', 'Ġ.', 'Ġmap', '_', 'as', 'ync', 'Ġ(', 'Ġprocess', 'Ġ,', 'Ġtasks', 'Ġ,', 'Ġret', 'ries', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['as', 'ync', '_', 'job', 'Ġ=', 'Ġview', 'Ġ.', 'Ġmap', '_', 'as', 'ync', 'Ġ(', 'Ġprocess', 'Ġ,', 'Ġtasks', 'Ġ,', 'Ġret', 'ries', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['async_job', 'Ġ=', 'Ġview', 'Ġ.', 'Ġmap_async', 'Ġ(', 'Ġprocess', 'Ġ,', 'Ġtasks', 'Ġ,', 'Ġretries', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "remaining = len ( tasks ) - len ( done ) \n"
Original    (012): ['remaining', '=', 'len', '(', 'tasks', ')', '-', 'len', '(', 'done', ')', '\\n']
Tokenized   (016): ['<s>', 'rem', 'aining', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtasks', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġdone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['rem', 'aining', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtasks', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġdone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['remaining', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtasks', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġdone', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "num_items , type ( model ) . __name__ , simsfile ) \n"
Original    (012): ['num_items', ',', 'type', '(', 'model', ')', '.', '__name__', ',', 'simsfile', ')', '\\n']
Tokenized   (021): ['<s>', 'num', '_', 'items', 'Ġ,', 'Ġtype', 'Ġ(', 'Ġmodel', 'Ġ)', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġsim', 's', 'file', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['num', '_', 'items', 'Ġ,', 'Ġtype', 'Ġ(', 'Ġmodel', 'Ġ)', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġsim', 's', 'file', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['num_items', 'Ġ,', 'Ġtype', 'Ġ(', 'Ġmodel', 'Ġ)', 'Ġ.', 'Ġ__name__', 'Ġ,', 'Ġsimsfile', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "before = text [ : len ( text ) - len ( like ) ] \n"
Original    (016): ['before', '=', 'text', '[', ':', 'len', '(', 'text', ')', '-', 'len', '(', 'like', ')', ']', '\\n']
Tokenized   (019): ['<s>', 'before', 'Ġ=', 'Ġtext', 'Ġ[', 'Ġ:', 'Ġlen', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġlike', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['before', 'Ġ=', 'Ġtext', 'Ġ[', 'Ġ:', 'Ġlen', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġlike', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['before', 'Ġ=', 'Ġtext', 'Ġ[', 'Ġ:', 'Ġlen', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġlike', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "Version = namedtuple ( , ) \n"
Original    (007): ['Version', '=', 'namedtuple', '(', ',', ')', '\\n']
Tokenized   (012): ['<s>', 'Version', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Version', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['Version', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_defaults = collections . OrderedDict ( [ \n"
Original    (008): ['_defaults', '=', 'collections', '.', 'OrderedDict', '(', '[', '\\n']
Tokenized   (016): ['<s>', '_', 'default', 's', 'Ġ=', 'Ġcollections', 'Ġ.', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ(', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['_', 'default', 's', 'Ġ=', 'Ġcollections', 'Ġ.', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ(', 'Ġ[', 'Ġ\\', 'n']
Detokenized (008): ['_defaults', 'Ġ=', 'Ġcollections', 'Ġ.', 'ĠOrderedDict', 'Ġ(', 'Ġ[', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "rootDirectory = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ ) ) , , ) \n"
Original    (027): ['rootDirectory', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'realpath', '(', '__file__', ')', ')', ',', ',', ')', '\\n']
Tokenized   (035): ['<s>', 'root', 'Directory', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['root', 'Directory', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['rootDirectory', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġrealpath', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "httpd . handle_request ( ) from . import TestEnable # \n"
Original    (011): ['httpd', '.', 'handle_request', '(', ')', 'from', '.', 'import', 'TestEnable', '#', '\\n']
Tokenized   (018): ['<s>', 'http', 'd', 'Ġ.', 'Ġhandle', '_', 'request', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġ.', 'Ġimport', 'ĠTest', 'Enable', 'Ġ#', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['http', 'd', 'Ġ.', 'Ġhandle', '_', 'request', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġ.', 'Ġimport', 'ĠTest', 'Enable', 'Ġ#', 'Ġ\\', 'n']
Detokenized (011): ['httpd', 'Ġ.', 'Ġhandle_request', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġ.', 'Ġimport', 'ĠTestEnable', 'Ġ#', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "field_names = tuple ( field_names ) , \n"
Original    (008): ['field_names', '=', 'tuple', '(', 'field_names', ')', ',', '\\n']
Tokenized   (015): ['<s>', 'field', '_', 'names', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['field', '_', 'names', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['field_names', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġfield_names', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "arg_list = repr ( tuple ( field_names ) ) . replace ( "\'" , "" ) [ 1 : - 1 ] , \n"
Original    (024): ['arg_list', '=', 'repr', '(', 'tuple', '(', 'field_names', ')', ')', '.', 'replace', '(', '"\\\'"', ',', '""', ')', '[', '1', ':', '-', '1', ']', ',', '\\n']
Tokenized   (032): ['<s>', 'arg', '_', 'list', 'Ġ=', 'Ġrepr', 'Ġ(', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"\\', '\'"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['arg', '_', 'list', 'Ġ=', 'Ġrepr', 'Ġ(', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"\\', '\'"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (024): ['arg_list', 'Ġ=', 'Ġrepr', 'Ġ(', 'Ġtuple', 'Ġ(', 'Ġfield_names', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"\\\'"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "repr_fmt = . join ( _repr_template . format ( name = name ) \n"
Original    (014): ['repr_fmt', '=', '.', 'join', '(', '_repr_template', '.', 'format', '(', 'name', '=', 'name', ')', '\\n']
Tokenized   (025): ['<s>', 're', 'pr', '_', 'f', 'mt', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 're', 'pr', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['re', 'pr', '_', 'f', 'mt', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 're', 'pr', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['repr_fmt', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_repr_template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "field_defs = . join ( _field_template . format ( index = index , name = name ) \n"
Original    (018): ['field_defs', '=', '.', 'join', '(', '_field_template', '.', 'format', '(', 'index', '=', 'index', ',', 'name', '=', 'name', ')', '\\n']
Tokenized   (027): ['<s>', 'field', '_', 'def', 's', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 'field', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġindex', 'Ġ,', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['field', '_', 'def', 's', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 'field', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġindex', 'Ġ,', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['field_defs', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_field_template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġindex', 'Ġ,', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "OrderedDict = OrderedDict , _property = property , _tuple = tuple ) \n"
Original    (013): ['OrderedDict', '=', 'OrderedDict', ',', '_property', '=', 'property', ',', '_tuple', '=', 'tuple', ')', '\\n']
Tokenized   (025): ['<s>', 'Ord', 'ered', 'D', 'ict', 'Ġ=', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ,', 'Ġ_', 'property', 'Ġ=', 'Ġproperty', 'Ġ,', 'Ġ_', 't', 'uple', 'Ġ=', 'Ġtuple', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['Ord', 'ered', 'D', 'ict', 'Ġ=', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ,', 'Ġ_', 'property', 'Ġ=', 'Ġproperty', 'Ġ,', 'Ġ_', 't', 'uple', 'Ġ=', 'Ġtuple', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['OrderedDict', 'Ġ=', 'ĠOrderedDict', 'Ġ,', 'Ġ_property', 'Ġ=', 'Ġproperty', 'Ġ,', 'Ġ_tuple', 'Ġ=', 'Ġtuple', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "xx = Xdf [ ] . values \n"
Original    (008): ['xx', '=', 'Xdf', '[', ']', '.', 'values', '\\n']
Tokenized   (012): ['<s>', 'xx', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġvalues', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['xx', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġvalues', 'Ġ\\', 'n']
Detokenized (008): ['xx', 'Ġ=', 'ĠXdf', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġvalues', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "X_CD13 , Y_CD13 = util . get_data ( cd13 , y_names = [ , ] ) \n"
Original    (017): ['X_CD13', ',', 'Y_CD13', '=', 'util', '.', 'get_data', '(', 'cd13', ',', 'y_names', '=', '[', ',', ']', ')', '\\n']
Tokenized   (031): ['<s>', 'X', '_', 'CD', '13', 'Ġ,', 'ĠY', '_', 'CD', '13', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '13', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['X', '_', 'CD', '13', 'Ġ,', 'ĠY', '_', 'CD', '13', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '13', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['X_CD13', 'Ġ,', 'ĠY_CD13', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġcd13', 'Ġ,', 'Ġy_names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "cd33 = human_data . xs ( , level = , drop_level = False ) \n"
Original    (015): ['cd33', '=', 'human_data', '.', 'xs', '(', ',', 'level', '=', ',', 'drop_level', '=', 'False', ')', '\\n']
Tokenized   (024): ['<s>', 'cd', '33', 'Ġ=', 'Ġhuman', '_', 'data', 'Ġ.', 'Ġx', 's', 'Ġ(', 'Ġ,', 'Ġlevel', 'Ġ=', 'Ġ,', 'Ġdrop', '_', 'level', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['cd', '33', 'Ġ=', 'Ġhuman', '_', 'data', 'Ġ.', 'Ġx', 's', 'Ġ(', 'Ġ,', 'Ġlevel', 'Ġ=', 'Ġ,', 'Ġdrop', '_', 'level', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['cd33', 'Ġ=', 'Ġhuman_data', 'Ġ.', 'Ġxs', 'Ġ(', 'Ġ,', 'Ġlevel', 'Ġ=', 'Ġ,', 'Ġdrop_level', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "X_CD33 , Y_CD33 = util . get_data ( cd33 , y_names = [ , , ] ) \n"
Original    (018): ['X_CD33', ',', 'Y_CD33', '=', 'util', '.', 'get_data', '(', 'cd33', ',', 'y_names', '=', '[', ',', ',', ']', ')', '\\n']
Tokenized   (032): ['<s>', 'X', '_', 'CD', '33', 'Ġ,', 'ĠY', '_', 'CD', '33', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '33', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['X', '_', 'CD', '33', 'Ġ,', 'ĠY', '_', 'CD', '33', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '33', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['X_CD33', 'Ġ,', 'ĠY_CD33', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġcd33', 'Ġ,', 'Ġy_names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "X_CD15 , Y_CD15 = util . get_data ( cd15 , y_names = [ ] ) \n"
Original    (016): ['X_CD15', ',', 'Y_CD15', '=', 'util', '.', 'get_data', '(', 'cd15', ',', 'y_names', '=', '[', ']', ')', '\\n']
Tokenized   (030): ['<s>', 'X', '_', 'CD', '15', 'Ġ,', 'ĠY', '_', 'CD', '15', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '15', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['X', '_', 'CD', '15', 'Ġ,', 'ĠY', '_', 'CD', '15', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '15', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['X_CD15', 'Ġ,', 'ĠY_CD15', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġcd15', 'Ġ,', 'Ġy_names', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "mouse_Y = pandas . concat ( [ mouse_Y , Y ] , axis = 0 ) \n"
Original    (017): ['mouse_Y', '=', 'pandas', '.', 'concat', '(', '[', 'mouse_Y', ',', 'Y', ']', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (026): ['<s>', 'mouse', '_', 'Y', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ[', 'Ġmouse', '_', 'Y', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['mouse', '_', 'Y', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ[', 'Ġmouse', '_', 'Y', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['mouse_Y', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġconcat', 'Ġ(', 'Ġ[', 'Ġmouse_Y', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "mouse_data = pandas . read_excel ( data_file , sheetname = 1 , index_col = [ 0 , 1 ] ) \n"
Original    (021): ['mouse_data', '=', 'pandas', '.', 'read_excel', '(', 'data_file', ',', 'sheetname', '=', '1', ',', 'index_col', '=', '[', '0', ',', '1', ']', ')', '\\n']
Tokenized   (035): ['<s>', 'mouse', '_', 'data', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġread', '_', 'ex', 'cel', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġsheet', 'name', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġindex', '_', 'col', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['mouse', '_', 'data', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġread', '_', 'ex', 'cel', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġsheet', 'name', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġindex', '_', 'col', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['mouse_data', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġread_excel', 'Ġ(', 'Ġdata_file', 'Ġ,', 'Ġsheetname', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġindex_col', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "data_efficient [ ] = 1. \n"
Original    (006): ['data_efficient', '[', ']', '=', '1.', '\\n']
Tokenized   (012): ['<s>', 'data', '_', 'efficient', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', '.', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['data', '_', 'efficient', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', '.', 'Ġ\\', 'n']
Detokenized (006): ['data_efficient', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1.', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "exp_data [ ] = exp_data . groupby ( ) [ ] . transform ( exp_data [ ] = exp_data . groupby ( ) [ ] . transform ( \n"
Original    (029): ['exp_data', '[', ']', '=', 'exp_data', '.', 'groupby', '(', ')', '[', ']', '.', 'transform', '(', 'exp_data', '[', ']', '=', 'exp_data', '.', 'groupby', '(', ')', '[', ']', '.', 'transform', '(', '\\n']
Tokenized   (042): ['<s>', 'exp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġexp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['exp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġexp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġ\\', 'n']
Detokenized (029): ['exp_data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp_data', 'Ġ.', 'Ġgroupby', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġexp_data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp_data', 'Ġ.', 'Ġgroupby', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "aggregated [ ] = aggregated [ [ , ] ] . mean ( axis = 1 ) \n"
Original    (018): ['aggregated', '[', ']', '=', 'aggregated', '[', '[', ',', ']', ']', '.', 'mean', '(', 'axis', '=', '1', ')', '\\n']
Tokenized   (024): ['<s>', 'agg', 'reg', 'ated', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġaggreg', 'ated', 'Ġ[', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ]', 'Ġ.', 'Ġmean', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['agg', 'reg', 'ated', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġaggreg', 'ated', 'Ġ[', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ]', 'Ġ.', 'Ġmean', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['aggregated', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġaggregated', 'Ġ[', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ]', 'Ġ.', 'Ġmean', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "known_pairs = { : [ , , , ] , \n"
Original    (011): ['known_pairs', '=', '{', ':', '[', ',', ',', ',', ']', ',', '\\n']
Tokenized   (017): ['<s>', 'known', '_', 'p', 'airs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['known', '_', 'p', 'airs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['known_pairs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "drugs_to_genes [ ] . extend ( [ , , , , , \n"
Original    (013): ['drugs_to_genes', '[', ']', '.', 'extend', '(', '[', ',', ',', ',', ',', ',', '\\n']
Tokenized   (022): ['<s>', 'drug', 's', '_', 'to', '_', 'gen', 'es', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['drug', 's', '_', 'to', '_', 'gen', 'es', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['drugs_to_genes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Xtmp [ ] = drug \n"
Original    (006): ['Xtmp', '[', ']', '=', 'drug', '\\n']
Tokenized   (010): ['<s>', 'X', 'tmp', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdrug', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['X', 'tmp', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdrug', 'Ġ\\', 'n']
Detokenized (006): ['Xtmp', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdrug', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "y_rank = pandas . concat ( ( y_rank , y_ranktmp ) , axis = 0 ) \n"
Original    (017): ['y_rank', '=', 'pandas', '.', 'concat', '(', '(', 'y_rank', ',', 'y_ranktmp', ')', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (029): ['<s>', 'y', '_', 'rank', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġy', '_', 'rank', 'Ġ,', 'Ġy', '_', 'rank', 'tmp', 'Ġ)', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['y', '_', 'rank', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġy', '_', 'rank', 'Ġ,', 'Ġy', '_', 'rank', 'tmp', 'Ġ)', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['y_rank', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġconcat', 'Ġ(', 'Ġ(', 'Ġy_rank', 'Ġ,', 'Ġy_ranktmp', 'Ġ)', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "experiments [ ] = [ , , , ] \n"
Original    (010): ['experiments', '[', ']', '=', '[', ',', ',', ',', ']', '\\n']
Tokenized   (014): ['<s>', 'exper', 'iments', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['exper', 'iments', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['experiments', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "data_tmp [ "variance" ] = np . var ( data_tmp . values , axis = 1 ) \n"
Original    (018): ['data_tmp', '[', '"variance"', ']', '=', 'np', '.', 'var', '(', 'data_tmp', '.', 'values', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (028): ['<s>', 'data', '_', 'tmp', 'Ġ[', 'Ġ"', 'vari', 'ance', '"', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġvar', 'Ġ(', 'Ġdata', '_', 'tmp', 'Ġ.', 'Ġvalues', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['data', '_', 'tmp', 'Ġ[', 'Ġ"', 'vari', 'ance', '"', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġvar', 'Ġ(', 'Ġdata', '_', 'tmp', 'Ġ.', 'Ġvalues', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['data_tmp', 'Ġ[', 'Ġ"variance"', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġvar', 'Ġ(', 'Ġdata_tmp', 'Ġ.', 'Ġvalues', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "gene_position_xu , target_genes_xu , Xdf_xu , Y_xu = read_xu_et_al ( data_file3 , learn_options ) \n"
Original    (015): ['gene_position_xu', ',', 'target_genes_xu', ',', 'Xdf_xu', ',', 'Y_xu', '=', 'read_xu_et_al', '(', 'data_file3', ',', 'learn_options', ')', '\\n']
Tokenized   (049): ['<s>', 'g', 'ene', '_', 'position', '_', 'x', 'u', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '_', 'x', 'u', 'Ġ,', 'ĠX', 'df', '_', 'x', 'u', 'Ġ,', 'ĠY', '_', 'x', 'u', 'Ġ=', 'Ġread', '_', 'x', 'u', '_', 'et', '_', 'al', 'Ġ(', 'Ġdata', '_', 'file', '3', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (047): ['g', 'ene', '_', 'position', '_', 'x', 'u', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '_', 'x', 'u', 'Ġ,', 'ĠX', 'df', '_', 'x', 'u', 'Ġ,', 'ĠY', '_', 'x', 'u', 'Ġ=', 'Ġread', '_', 'x', 'u', '_', 'et', '_', 'al', 'Ġ(', 'Ġdata', '_', 'file', '3', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['gene_position_xu', 'Ġ,', 'Ġtarget_genes_xu', 'Ġ,', 'ĠXdf_xu', 'Ġ,', 'ĠY_xu', 'Ġ=', 'Ġread_xu_et_al', 'Ġ(', 'Ġdata_file3', 'Ġ,', 'Ġlearn_options', 'Ġ)', 'Ġ\\n']
Counter: 47
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "annotations , gene_position1 , target_genes1 , Xdf1 , Y1 = read_V1_data ( data_file , learn_options ) \n"
Original    (017): ['annotations', ',', 'gene_position1', ',', 'target_genes1', ',', 'Xdf1', ',', 'Y1', '=', 'read_V1_data', '(', 'data_file', ',', 'learn_options', ')', '\\n']
Tokenized   (040): ['<s>', 'annot', 'ations', 'Ġ,', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '1', 'Ġ,', 'ĠX', 'df', '1', 'Ġ,', 'ĠY', '1', 'Ġ=', 'Ġread', '_', 'V', '1', '_', 'data', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['annot', 'ations', 'Ġ,', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '1', 'Ġ,', 'ĠX', 'df', '1', 'Ġ,', 'ĠY', '1', 'Ġ=', 'Ġread', '_', 'V', '1', '_', 'data', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['annotations', 'Ġ,', 'Ġgene_position1', 'Ġ,', 'Ġtarget_genes1', 'Ġ,', 'ĠXdf1', 'Ġ,', 'ĠY1', 'Ġ=', 'Ġread_V1_data', 'Ġ(', 'Ġdata_file', 'Ġ,', 'Ġlearn_options', 'Ġ)', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "Y_cols_to_keep = np . unique ( [ , , , \n"
Original    (011): ['Y_cols_to_keep', '=', 'np', '.', 'unique', '(', '[', ',', ',', ',', '\\n']
Tokenized   (021): ['<s>', 'Y', '_', 'col', 's', '_', 'to', '_', 'keep', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Y', '_', 'col', 's', '_', 'to', '_', 'keep', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['Y_cols_to_keep', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "gene_position = pandas . concat ( ( gene_position1 , gene_position2 ) ) \n"
Original    (013): ['gene_position', '=', 'pandas', '.', 'concat', '(', '(', 'gene_position1', ',', 'gene_position2', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'g', 'ene', '_', 'position', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġgene', '_', 'position', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['g', 'ene', '_', 'position', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġgene', '_', 'position', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['gene_position', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġconcat', 'Ġ(', 'Ġ(', 'Ġgene_position1', 'Ġ,', 'Ġgene_position2', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "onedupind = np . where ( Y . index . duplicated ( ) ) [ 0 ] [ 0 ] \n"
Original    (021): ['onedupind', '=', 'np', '.', 'where', '(', 'Y', '.', 'index', '.', 'duplicated', '(', ')', ')', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (027): ['<s>', 'oned', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġdupl', 'icated', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['oned', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġdupl', 'icated', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['onedupind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġduplicated', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "alldupind = np . where ( Y . index . get_level_values ( 0 ) . values == Y . index [ onedupind ] [ 0 ] ) [ 0 ] \n"
Original    (031): ['alldupind', '=', 'np', '.', 'where', '(', 'Y', '.', 'index', '.', 'get_level_values', '(', '0', ')', '.', 'values', '==', 'Y', '.', 'index', '[', 'onedupind', ']', '[', '0', ']', ')', '[', '0', ']', '\\n']
Tokenized   (044): ['<s>', 'al', 'ld', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġget', '_', 'level', '_', 'values', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ==', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['al', 'ld', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġget', '_', 'level', '_', 'values', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ==', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (031): ['alldupind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġget_level_values', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ==', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "newindex [ onedupind ] = ( newindex [ onedupind ] [ 0 ] , newindex [ onedupind ] [ 1 ] , "nodrug2" ) \n"
Original    (025): ['newindex', '[', 'onedupind', ']', '=', '(', 'newindex', '[', 'onedupind', ']', '[', '0', ']', ',', 'newindex', '[', 'onedupind', ']', '[', '1', ']', ',', '"nodrug2"', ')', '\\n']
Tokenized   (045): ['<s>', 'new', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ"', 'n', 'od', 'rug', '2', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (043): ['new', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ"', 'n', 'od', 'rug', '2', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['newindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnewindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġnewindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ"nodrug2"', 'Ġ)', 'Ġ\\n']
Counter: 43
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "Xdf . index = pandas . MultiIndex . from_tuples ( newindex , names = Y . index . names ) \n"
Original    (021): ['Xdf', '.', 'index', '=', 'pandas', '.', 'MultiIndex', '.', 'from_tuples', '(', 'newindex', ',', 'names', '=', 'Y', '.', 'index', '.', 'names', ')', '\\n']
Tokenized   (031): ['<s>', 'X', 'df', 'Ġ.', 'Ġindex', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'ĠMulti', 'Index', 'Ġ.', 'Ġfrom', '_', 'tu', 'ples', 'Ġ(', 'Ġnew', 'index', 'Ġ,', 'Ġnames', 'Ġ=', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġnames', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['X', 'df', 'Ġ.', 'Ġindex', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'ĠMulti', 'Index', 'Ġ.', 'Ġfrom', '_', 'tu', 'ples', 'Ġ(', 'Ġnew', 'index', 'Ġ,', 'Ġnames', 'Ġ=', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġnames', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['Xdf', 'Ġ.', 'Ġindex', 'Ġ=', 'Ġpandas', 'Ġ.', 'ĠMultiIndex', 'Ġ.', 'Ġfrom_tuples', 'Ġ(', 'Ġnewindex', 'Ġ,', 'Ġnames', 'Ġ=', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġnames', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "mouse_genes = Xdf [ Xdf [ ] == ] [ ] . unique ( ) \n"
Original    (016): ['mouse_genes', '=', 'Xdf', '[', 'Xdf', '[', ']', '==', ']', '[', ']', '.', 'unique', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'mouse', '_', 'gen', 'es', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['mouse', '_', 'gen', 'es', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['mouse_genes', 'Ġ=', 'ĠXdf', 'Ġ[', 'ĠXdf', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "all_genes = get_V3_genes ( None , None ) return np . setdiff1d ( all_genes , mouse_genes ) \n"
Original    (018): ['all_genes', '=', 'get_V3_genes', '(', 'None', ',', 'None', ')', 'return', 'np', '.', 'setdiff1d', '(', 'all_genes', ',', 'mouse_genes', ')', '\\n']
Tokenized   (039): ['<s>', 'all', '_', 'gen', 'es', 'Ġ=', 'Ġget', '_', 'V', '3', '_', 'gen', 'es', 'Ġ(', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġreturn', 'Ġnp', 'Ġ.', 'Ġset', 'diff', '1', 'd', 'Ġ(', 'Ġall', '_', 'gen', 'es', 'Ġ,', 'Ġmouse', '_', 'gen', 'es', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['all', '_', 'gen', 'es', 'Ġ=', 'Ġget', '_', 'V', '3', '_', 'gen', 'es', 'Ġ(', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġreturn', 'Ġnp', 'Ġ.', 'Ġset', 'diff', '1', 'd', 'Ġ(', 'Ġall', '_', 'gen', 'es', 'Ġ,', 'Ġmouse', '_', 'gen', 'es', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['all_genes', 'Ġ=', 'Ġget_V3_genes', 'Ġ(', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġreturn', 'Ġnp', 'Ġ.', 'Ġsetdiff1d', 'Ġ(', 'Ġall_genes', 'Ġ,', 'Ġmouse_genes', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "option_value = self . cfg . migrate [ self . option_name ] \n"
Original    (013): ['option_value', '=', 'self', '.', 'cfg', '.', 'migrate', '[', 'self', '.', 'option_name', ']', '\\n']
Tokenized   (021): ['<s>', 'option', '_', 'value', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcf', 'g', 'Ġ.', 'Ġmigrate', 'Ġ[', 'Ġself', 'Ġ.', 'Ġoption', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['option', '_', 'value', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcf', 'g', 'Ġ.', 'Ġmigrate', 'Ġ[', 'Ġself', 'Ġ.', 'Ġoption', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['option_value', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcfg', 'Ġ.', 'Ġmigrate', 'Ġ[', 'Ġself', 'Ġ.', 'Ġoption_name', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "search_opts_tenant = kwargs . get ( , { } ) \n"
Original    (011): ['search_opts_tenant', '=', 'kwargs', '.', 'get', '(', ',', '{', '}', ')', '\\n']
Tokenized   (022): ['<s>', 'search', '_', 'op', 'ts', '_', 'ten', 'ant', 'Ġ=', 'Ġk', 'w', 'args', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['search', '_', 'op', 'ts', '_', 'ten', 'ant', 'Ġ=', 'Ġk', 'w', 'args', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['search_opts_tenant', 'Ġ=', 'Ġkwargs', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tenants_without_quotas = self . get_tenants_without_quotas ( tenants_src , \n"
Original    (009): ['tenants_without_quotas', '=', 'self', '.', 'get_tenants_without_quotas', '(', 'tenants_src', ',', '\\n']
Tokenized   (030): ['<s>', 'ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ(', 'Ġtenants', '_', 'src', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ(', 'Ġtenants', '_', 'src', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['tenants_without_quotas', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget_tenants_without_quotas', 'Ġ(', 'Ġtenants_src', 'Ġ,', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "quot = network_src . show_quota ( tenants_without_quotas [ 0 ] ) \n"
Original    (012): ['quot', '=', 'network_src', '.', 'show_quota', '(', 'tenants_without_quotas', '[', '0', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'qu', 'ot', 'Ġ=', 'Ġnetwork', '_', 'src', 'Ġ.', 'Ġshow', '_', 'qu', 'ota', 'Ġ(', 'Ġtenants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['qu', 'ot', 'Ġ=', 'Ġnetwork', '_', 'src', 'Ġ.', 'Ġshow', '_', 'qu', 'ota', 'Ġ(', 'Ġtenants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['quot', 'Ġ=', 'Ġnetwork_src', 'Ġ.', 'Ġshow_quota', 'Ġ(', 'Ġtenants_without_quotas', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "quot_default_dst [ item_quot ] ) \n"
Original    (006): ['quot_default_dst', '[', 'item_quot', ']', ')', '\\n']
Tokenized   (018): ['<s>', 'qu', 'ot', '_', 'default', '_', 'd', 'st', 'Ġ[', 'Ġitem', '_', 'qu', 'ot', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['qu', 'ot', '_', 'default', '_', 'd', 'st', 'Ġ[', 'Ġitem', '_', 'qu', 'ot', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['quot_default_dst', 'Ġ[', 'Ġitem_quot', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tenants = [ identity_src . keystone_client . tenants . find ( id = tnt_id ) for \n"
Original    (017): ['tenants', '=', '[', 'identity_src', '.', 'keystone_client', '.', 'tenants', '.', 'find', '(', 'id', '=', 'tnt_id', ')', 'for', '\\n']
Tokenized   (029): ['<s>', 'ten', 'ants', 'Ġ=', 'Ġ[', 'Ġidentity', '_', 'src', 'Ġ.', 'Ġkey', 'stone', '_', 'client', 'Ġ.', 'Ġtenants', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġid', 'Ġ=', 'Ġt', 'nt', '_', 'id', 'Ġ)', 'Ġfor', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['ten', 'ants', 'Ġ=', 'Ġ[', 'Ġidentity', '_', 'src', 'Ġ.', 'Ġkey', 'stone', '_', 'client', 'Ġ.', 'Ġtenants', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġid', 'Ġ=', 'Ġt', 'nt', '_', 'id', 'Ġ)', 'Ġfor', 'Ġ\\', 'n']
Detokenized (017): ['tenants', 'Ġ=', 'Ġ[', 'Ġidentity_src', 'Ġ.', 'Ġkeystone_client', 'Ġ.', 'Ġtenants', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġid', 'Ġ=', 'Ġtnt_id', 'Ġ)', 'Ġfor', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "tnt_id in filter_tenants_ids_list ] \n"
Original    (005): ['tnt_id', 'in', 'filter_tenants_ids_list', ']', '\\n']
Tokenized   (018): ['<s>', 't', 'nt', '_', 'id', 'Ġin', 'Ġfilter', '_', 'ten', 'ants', '_', 'ids', '_', 'list', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['t', 'nt', '_', 'id', 'Ġin', 'Ġfilter', '_', 'ten', 'ants', '_', 'ids', '_', 'list', 'Ġ]', 'Ġ\\', 'n']
Detokenized (005): ['tnt_id', 'Ġin', 'Ġfilter_tenants_ids_list', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "instance [ ] [ ] , instance [ ] [ ] ) \n"
Original    (013): ['instance', '[', ']', '[', ']', ',', 'instance', '[', ']', '[', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'instance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġinstance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['instance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġinstance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['instance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġinstance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "vol [ ] , storage_resource . get_status , , \n"
Original    (010): ['vol', '[', ']', ',', 'storage_resource', '.', 'get_status', ',', ',', '\\n']
Tokenized   (017): ['<s>', 'vol', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġstorage', '_', 'resource', 'Ġ.', 'Ġget', '_', 'status', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['vol', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġstorage', '_', 'resource', 'Ġ.', 'Ġget', '_', 'status', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['vol', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġstorage_resource', 'Ġ.', 'Ġget_status', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "inst_name = libvirt_instance_name ) ) \n"
Original    (006): ['inst_name', '=', 'libvirt_instance_name', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'inst', '_', 'name', 'Ġ=', 'Ġlib', 'virt', '_', 'instance', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['inst', '_', 'name', 'Ġ=', 'Ġlib', 'virt', '_', 'instance', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['inst_name', 'Ġ=', 'Ġlibvirt_instance_name', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "dst = instance_image_path ( instance_id ) ) \n"
Original    (008): ['dst', '=', 'instance_image_path', '(', 'instance_id', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'd', 'st', 'Ġ=', 'Ġinstance', '_', 'image', '_', 'path', 'Ġ(', 'Ġinstance', '_', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['d', 'st', 'Ġ=', 'Ġinstance', '_', 'image', '_', 'path', 'Ġ(', 'Ġinstance', '_', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['dst', 'Ġ=', 'Ġinstance_image_path', 'Ġ(', 'Ġinstance_id', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "interface . find ( ) ) \n"
Original    (007): ['interface', '.', 'find', '(', ')', ')', '\\n']
Tokenized   (010): ['<s>', 'interface', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['interface', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['interface', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "mac = self . mac , src = self . source_iface , dst = self . target_iface ) \n"
Original    (019): ['mac', '=', 'self', '.', 'mac', ',', 'src', '=', 'self', '.', 'source_iface', ',', 'dst', '=', 'self', '.', 'target_iface', ')', '\\n']
Tokenized   (028): ['<s>', 'mac', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmac', 'Ġ,', 'Ġsrc', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsource', '_', 'if', 'ace', 'Ġ,', 'Ġdst', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtarget', '_', 'if', 'ace', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['mac', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmac', 'Ġ,', 'Ġsrc', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsource', '_', 'if', 'ace', 'Ġ,', 'Ġdst', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtarget', '_', 'if', 'ace', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['mac', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmac', 'Ġ,', 'Ġsrc', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsource_iface', 'Ġ,', 'Ġdst', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtarget_iface', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "element . attrib = { attr : value } \n"
Original    (010): ['element', '.', 'attrib', '=', '{', 'attr', ':', 'value', '}', '\\n']
Tokenized   (015): ['<s>', 'element', 'Ġ.', 'Ġatt', 'rib', 'Ġ=', 'Ġ{', 'Ġatt', 'r', 'Ġ:', 'Ġvalue', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['element', 'Ġ.', 'Ġatt', 'rib', 'Ġ=', 'Ġ{', 'Ġatt', 'r', 'Ġ:', 'Ġvalue', 'Ġ}', 'Ġ\\', 'n']
Detokenized (010): ['element', 'Ġ.', 'Ġattrib', 'Ġ=', 'Ġ{', 'Ġattr', 'Ġ:', 'Ġvalue', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "rr . run ( copy . format ( src_file = source_object . path , \n"
Original    (015): ['rr', '.', 'run', '(', 'copy', '.', 'format', '(', 'src_file', '=', 'source_object', '.', 'path', ',', '\\n']
Tokenized   (022): ['<s>', 'rr', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġcopy', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġsrc', '_', 'file', 'Ġ=', 'Ġsource', '_', 'object', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['rr', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġcopy', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġsrc', '_', 'file', 'Ġ=', 'Ġsource', '_', 'object', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['rr', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġcopy', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġsrc_file', 'Ġ=', 'Ġsource_object', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "max_bytes = sizeof_format . parse_size ( kwargs . pop ( , 0 ) ) \n"
Original    (015): ['max_bytes', '=', 'sizeof_format', '.', 'parse_size', '(', 'kwargs', '.', 'pop', '(', ',', '0', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'max', '_', 'bytes', 'Ġ=', 'Ġsizeof', '_', 'format', 'Ġ.', 'Ġparse', '_', 'size', 'Ġ(', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['max', '_', 'bytes', 'Ġ=', 'Ġsizeof', '_', 'format', 'Ġ.', 'Ġparse', '_', 'size', 'Ġ(', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['max_bytes', 'Ġ=', 'Ġsizeof_format', 'Ġ.', 'Ġparse_size', 'Ġ(', 'Ġkwargs', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "scenario = os . path . splitext ( scenario_filename ) [ 0 ] \n"
Original    (014): ['scenario', '=', 'os', '.', 'path', '.', 'splitext', '(', 'scenario_filename', ')', '[', '0', ']', '\\n']
Tokenized   (022): ['<s>', 'sc', 'enario', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġscenario', '_', 'filename', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['sc', 'enario', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġscenario', '_', 'filename', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['scenario', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplitext', 'Ġ(', 'Ġscenario_filename', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "file_name = config . rollback_params [ ] [ ] \n"
Original    (010): ['file_name', '=', 'config', '.', 'rollback_params', '[', ']', '[', ']', '\\n']
Tokenized   (018): ['<s>', 'file', '_', 'name', 'Ġ=', 'Ġconfig', 'Ġ.', 'Ġroll', 'back', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['file', '_', 'name', 'Ġ=', 'Ġconfig', 'Ġ.', 'Ġroll', 'back', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['file_name', 'Ġ=', 'Ġconfig', 'Ġ.', 'Ġrollback_params', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "pre_file_path = os . path . join ( self . cloudferry_dir , file_name ) \n"
Original    (015): ['pre_file_path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'cloudferry_dir', ',', 'file_name', ')', '\\n']
Tokenized   (028): ['<s>', 'pre', '_', 'file', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcloud', 'fer', 'ry', '_', 'dir', 'Ġ,', 'Ġfile', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['pre', '_', 'file', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcloud', 'fer', 'ry', '_', 'dir', 'Ġ,', 'Ġfile', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['pre_file_path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcloudferry_dir', 'Ġ,', 'Ġfile_name', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "o2 = C ( 2 ) \n"
Original    (007): ['o2', '=', 'C', '(', '2', ')', '\\n']
Tokenized   (011): ['<s>', 'o', '2', 'Ġ=', 'ĠC', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['o', '2', 'Ġ=', 'ĠC', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['o2', 'Ġ=', 'ĠC', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "org_tag = request . user . get_profile ( ) . org_tag \n"
Original    (012): ['org_tag', '=', 'request', '.', 'user', '.', 'get_profile', '(', ')', '.', 'org_tag', '\\n']
Tokenized   (021): ['<s>', 'org', '_', 'tag', 'Ġ=', 'Ġrequest', 'Ġ.', 'Ġuser', 'Ġ.', 'Ġget', '_', 'profile', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorg', '_', 'tag', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['org', '_', 'tag', 'Ġ=', 'Ġrequest', 'Ġ.', 'Ġuser', 'Ġ.', 'Ġget', '_', 'profile', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorg', '_', 'tag', 'Ġ\\', 'n']
Detokenized (012): ['org_tag', 'Ġ=', 'Ġrequest', 'Ġ.', 'Ġuser', 'Ġ.', 'Ġget_profile', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorg_tag', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "featureset = Recording . objects . filter ( lat__lt = ne_lat , lat__gt = sw_lat , lon__lt = ne_lon , lon__gt = sw_lon \n"
Original    (024): ['featureset', '=', 'Recording', '.', 'objects', '.', 'filter', '(', 'lat__lt', '=', 'ne_lat', ',', 'lat__gt', '=', 'sw_lat', ',', 'lon__lt', '=', 'ne_lon', ',', 'lon__gt', '=', 'sw_lon', '\\n']
Tokenized   (046): ['<s>', 'features', 'et', 'Ġ=', 'ĠRecording', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġlat', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lat', 'Ġ,', 'Ġlat', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lat', 'Ġ,', 'Ġl', 'on', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lon', 'Ġ,', 'Ġl', 'on', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lon', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['features', 'et', 'Ġ=', 'ĠRecording', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġlat', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lat', 'Ġ,', 'Ġlat', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lat', 'Ġ,', 'Ġl', 'on', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lon', 'Ġ,', 'Ġl', 'on', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lon', 'Ġ\\', 'n']
Detokenized (024): ['featureset', 'Ġ=', 'ĠRecording', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġlat__lt', 'Ġ=', 'Ġne_lat', 'Ġ,', 'Ġlat__gt', 'Ġ=', 'Ġsw_lat', 'Ġ,', 'Ġlon__lt', 'Ġ=', 'Ġne_lon', 'Ġ,', 'Ġlon__gt', 'Ġ=', 'Ġsw_lon', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "httpresponse_kwargs = { : kwargs . pop ( , None ) } \n"
Original    (013): ['httpresponse_kwargs', '=', '{', ':', 'kwargs', '.', 'pop', '(', ',', 'None', ')', '}', '\\n']
Tokenized   (022): ['<s>', 'http', 'response', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['http', 'response', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (013): ['httpresponse_kwargs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġkwargs', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_testing = in sys . argv \n"
Original    (007): ['is_testing', '=', 'in', 'sys', '.', 'argv', '\\n']
Tokenized   (013): ['<s>', 'is', '_', 'testing', 'Ġ=', 'Ġin', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['is', '_', 'testing', 'Ġ=', 'Ġin', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ\\', 'n']
Detokenized (007): ['is_testing', 'Ġ=', 'Ġin', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "up_time = end_time - self . start_time \n"
Original    (008): ['up_time', '=', 'end_time', '-', 'self', '.', 'start_time', '\\n']
Tokenized   (017): ['<s>', 'up', '_', 'time', 'Ġ=', 'Ġend', '_', 'time', 'Ġ-', 'Ġself', 'Ġ.', 'Ġstart', '_', 'time', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['up', '_', 'time', 'Ġ=', 'Ġend', '_', 'time', 'Ġ-', 'Ġself', 'Ġ.', 'Ġstart', '_', 'time', 'Ġ\\', 'n']
Detokenized (008): ['up_time', 'Ġ=', 'Ġend_time', 'Ġ-', 'Ġself', 'Ġ.', 'Ġstart_time', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "remaining_time = self . count_down_total - datetime . timedelta ( seconds = ( int ( up_time ) ) ) \n"
Original    (020): ['remaining_time', '=', 'self', '.', 'count_down_total', '-', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '(', 'int', '(', 'up_time', ')', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'rem', 'aining', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcount', '_', 'down', '_', 'total', 'Ġ-', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġup', '_', 'time', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['rem', 'aining', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcount', '_', 'down', '_', 'total', 'Ġ-', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġup', '_', 'time', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['remaining_time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcount_down_total', 'Ġ-', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġup_time', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "abort_time = time . time ( ) + timeout \n"
Original    (010): ['abort_time', '=', 'time', '.', 'time', '(', ')', '+', 'timeout', '\\n']
Tokenized   (016): ['<s>', 'ab', 'ort', '_', 'time', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġtimeout', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['ab', 'ort', '_', 'time', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġtimeout', 'Ġ\\', 'n']
Detokenized (010): ['abort_time', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġtimeout', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "elif not stanza . getID ( ) : \n"
Original    (009): ['elif', 'not', 'stanza', '.', 'getID', '(', ')', ':', '\\n']
Tokenized   (015): ['<s>', 'el', 'if', 'Ġnot', 'Ġst', 'anza', 'Ġ.', 'Ġget', 'ID', 'Ġ(', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['el', 'if', 'Ġnot', 'Ġst', 'anza', 'Ġ.', 'Ġget', 'ID', 'Ġ(', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (009): ['elif', 'Ġnot', 'Ġstanza', 'Ġ.', 'ĠgetID', 'Ġ(', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_ID = ` ID ` \n"
Original    (006): ['_ID', '=', '`', 'ID', '`', '\\n']
Tokenized   (010): ['<s>', '_', 'ID', 'Ġ=', 'Ġ`', 'ĠID', 'Ġ`', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['_', 'ID', 'Ġ=', 'Ġ`', 'ĠID', 'Ġ`', 'Ġ\\', 'n']
Detokenized (006): ['_ID', 'Ġ=', 'Ġ`', 'ĠID', 'Ġ`', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "__description__ = , \n"
Original    (004): ['__description__', '=', ',', '\\n']
Tokenized   (009): ['<s>', '__', 'description', '__', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['__', 'description', '__', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['__description__', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "REQUIRES = [ i . strip ( ) for i in open ( "requirements.txt" ) . readlines ( ) ] \n"
Original    (021): ['REQUIRES', '=', '[', 'i', '.', 'strip', '(', ')', 'for', 'i', 'in', 'open', '(', '"requirements.txt"', ')', '.', 'readlines', '(', ')', ']', '\\n']
Tokenized   (033): ['<s>', 'RE', 'QU', 'IR', 'ES', 'Ġ=', 'Ġ[', 'Ġi', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġi', 'Ġin', 'Ġopen', 'Ġ(', 'Ġ"', 'requ', 'irements', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'lines', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['RE', 'QU', 'IR', 'ES', 'Ġ=', 'Ġ[', 'Ġi', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġi', 'Ġin', 'Ġopen', 'Ġ(', 'Ġ"', 'requ', 'irements', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'lines', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['REQUIRES', 'Ġ=', 'Ġ[', 'Ġi', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġi', 'Ġin', 'Ġopen', 'Ġ(', 'Ġ"requirements.txt"', 'Ġ)', 'Ġ.', 'Ġreadlines', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "BaseField . __init__ ( self , ** kwargs ) \n"
Original    (010): ['BaseField', '.', '__init__', '(', 'self', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (018): ['<s>', 'Base', 'Field', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['Base', 'Field', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['BaseField', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "is_list = not hasattr ( items , ) \n"
Original    (009): ['is_list', '=', 'not', 'hasattr', '(', 'items', ',', ')', '\\n']
Tokenized   (015): ['<s>', 'is', '_', 'list', 'Ġ=', 'Ġnot', 'Ġhas', 'attr', 'Ġ(', 'Ġitems', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['is', '_', 'list', 'Ġ=', 'Ġnot', 'Ġhas', 'attr', 'Ġ(', 'Ġitems', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['is_list', 'Ġ=', 'Ġnot', 'Ġhasattr', 'Ġ(', 'Ġitems', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "object_map [ ( collection , doc . id ) ] = doc \n"
Original    (013): ['object_map', '[', '(', 'collection', ',', 'doc', '.', 'id', ')', ']', '=', 'doc', '\\n']
Tokenized   (018): ['<s>', 'object', '_', 'map', 'Ġ[', 'Ġ(', 'Ġcollection', 'Ġ,', 'Ġdoc', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġdoc', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['object', '_', 'map', 'Ġ[', 'Ġ(', 'Ġcollection', 'Ġ,', 'Ġdoc', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġdoc', 'Ġ\\', 'n']
Detokenized (013): ['object_map', 'Ġ[', 'Ġ(', 'Ġcollection', 'Ġ,', 'Ġdoc', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġdoc', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_cls = doc . _data . pop ( , None ) \n"
Original    (012): ['_cls', '=', 'doc', '.', '_data', '.', 'pop', '(', ',', 'None', ')', '\\n']
Tokenized   (018): ['<s>', '_', 'cl', 's', 'Ġ=', 'Ġdoc', 'Ġ.', 'Ġ_', 'data', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['_', 'cl', 's', 'Ġ=', 'Ġdoc', 'Ġ.', 'Ġ_', 'data', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['_cls', 'Ġ=', 'Ġdoc', 'Ġ.', 'Ġ_data', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "81.4471435546875 , \n"
Original    (003): ['81.4471435546875', ',', '\\n']
Tokenized   (013): ['<s>', '81', '.', '447', '14', '35', '54', '68', '75', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['81', '.', '447', '14', '35', '54', '68', '75', 'Ġ,', 'Ġ\\', 'n']
Detokenized (003): ['81.4471435546875', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "23.61432859499169 \n"
Original    (002): ['23.61432859499169', '\\n']
Tokenized   (012): ['<s>', '23', '.', '6', '143', '28', '59', '499', '169', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['23', '.', '6', '143', '28', '59', '499', '169', 'Ġ\\', 'n']
Detokenized (002): ['23.61432859499169', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "invalid_coords = [ [ [ [ 1 , 2 ] , [ 3 , 4 ] ] ] ] \n"
Original    (020): ['invalid_coords', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ']', ']', ']', '\\n']
Tokenized   (027): ['<s>', 'in', 'valid', '_', 'co', 'ords', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['in', 'valid', '_', 'co', 'ords', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (020): ['invalid_coords', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "Location ( loc = [ [ [ [ 1 , 2 ] , [ 3 , 4 ] , [ 5 , 6 ] , [ 1 , 2 ] ] ] ] ) . validate ( ) \n"
Original    (039): ['Location', '(', 'loc', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ',', '[', '5', ',', '6', ']', ',', '[', '1', ',', '2', ']', ']', ']', ']', ')', '.', 'validate', '(', ')', '\\n']
Tokenized   (042): ['<s>', 'Location', 'Ġ(', 'Ġloc', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ5', 'Ġ,', 'Ġ6', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['Location', 'Ġ(', 'Ġloc', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ5', 'Ġ,', 'Ġ6', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (039): ['Location', 'Ġ(', 'Ġloc', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ5', 'Ġ,', 'Ġ6', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 39, 768)
# Extracted words:  39
Sentence         : "Parent ( name = ) . save ( ) \n"
Original    (010): ['Parent', '(', 'name', '=', ')', '.', 'save', '(', ')', '\\n']
Tokenized   (013): ['<s>', 'Parent', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['Parent', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['Parent', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "echo_payload = Struct ( "echo_payload" , \n"
Original    (007): ['echo_payload', '=', 'Struct', '(', '"echo_payload"', ',', '\\n']
Tokenized   (018): ['<s>', 'echo', '_', 'pay', 'load', 'Ġ=', 'ĠStruct', 'Ġ(', 'Ġ"', 'echo', '_', 'pay', 'load', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['echo', '_', 'pay', 'load', 'Ġ=', 'ĠStruct', 'Ġ(', 'Ġ"', 'echo', '_', 'pay', 'load', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['echo_payload', 'Ġ=', 'ĠStruct', 'Ġ(', 'Ġ"echo_payload"', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Padding ( 2 ) , \n"
Original    (006): ['Padding', '(', '2', ')', ',', '\\n']
Tokenized   (010): ['<s>', 'P', 'adding', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['P', 'adding', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['Padding', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "IpAddress ( "host" ) , \n"
Original    (006): ['IpAddress', '(', '"host"', ')', ',', '\\n']
Tokenized   (013): ['<s>', 'I', 'p', 'Address', 'Ġ(', 'Ġ"', 'host', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['I', 'p', 'Address', 'Ġ(', 'Ġ"', 'host', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['IpAddress', 'Ġ(', 'Ġ"host"', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "Bytes ( "echo" , 8 ) , \n"
Original    (008): ['Bytes', '(', '"echo"', ',', '8', ')', ',', '\\n']
Tokenized   (013): ['<s>', 'Bytes', 'Ġ(', 'Ġ"', 'echo', '"', 'Ġ,', 'Ġ8', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['Bytes', 'Ġ(', 'Ġ"', 'echo', '"', 'Ġ,', 'Ġ8', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['Bytes', 'Ġ(', 'Ġ"echo"', 'Ġ,', 'Ġ8', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "dest_unreachable_code = Enum ( Byte ( "code" ) , \n"
Original    (010): ['dest_unreachable_code', '=', 'Enum', '(', 'Byte', '(', '"code"', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'dest', '_', 'un', 'reach', 'able', '_', 'code', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'code', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['dest', '_', 'un', 'reach', 'able', '_', 'code', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'code', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['dest_unreachable_code', 'Ġ=', 'ĠEnum', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"code"', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "Enum ( Byte ( "type" ) , \n"
Original    (008): ['Enum', '(', 'Byte', '(', '"type"', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'En', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'type', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['En', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'type', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['Enum', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"type"', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Switch ( "payload" , lambda ctx : ctx . type , \n"
Original    (012): ['Switch', '(', '"payload"', ',', 'lambda', 'ctx', ':', 'ctx', '.', 'type', ',', '\\n']
Tokenized   (020): ['<s>', 'Switch', 'Ġ(', 'Ġ"', 'pay', 'load', '"', 'Ġ,', 'Ġlambda', 'Ġc', 'tx', 'Ġ:', 'Ġc', 'tx', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['Switch', 'Ġ(', 'Ġ"', 'pay', 'load', '"', 'Ġ,', 'Ġlambda', 'Ġc', 'tx', 'Ġ:', 'Ġc', 'tx', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['Switch', 'Ġ(', 'Ġ"payload"', 'Ġ,', 'Ġlambda', 'Ġctx', 'Ġ:', 'Ġctx', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""63646566676869" ) . decode ( "hex" ) \n"
Original    (008): ['"63646566676869"', ')', '.', 'decode', '(', '"hex"', ')', '\\n']
Tokenized   (021): ['<s>', '"', '63', '64', '65', '66', '67', '68', '69', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['"', '63', '64', '65', '66', '67', '68', '69', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['"63646566676869"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"hex"', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "cap2 = ( "0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162" \n"
Original    (005): ['cap2', '=', '(', '"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', '\\n']
Tokenized   (044): ['<s>', 'cap', '2', 'Ġ=', 'Ġ(', 'Ġ"', '0000', '385', 'c', '0', '2001', 'b', '006', '16', '26', '364', '65', '66', '67', '68', '696', 'a', '6', 'b', '6', 'c', '6', 'd', '6', 'e', '6', 'f', '707', '17', '27', '374', '75', '767', '76', '162', '"', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['cap', '2', 'Ġ=', 'Ġ(', 'Ġ"', '0000', '385', 'c', '0', '2001', 'b', '006', '16', '26', '364', '65', '66', '67', '68', '696', 'a', '6', 'b', '6', 'c', '6', 'd', '6', 'e', '6', 'f', '707', '17', '27', '374', '75', '767', '76', '162', '"', 'Ġ\\', 'n']
Detokenized (005): ['cap2', 'Ġ=', 'Ġ(', 'Ġ"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "cap3 = ( "0301000000001122aabbccdd0102030405060708" ) . decode ( "hex" ) \n"
Original    (011): ['cap3', '=', '(', '"0301000000001122aabbccdd0102030405060708"', ')', '.', 'decode', '(', '"hex"', ')', '\\n']
Tokenized   (034): ['<s>', 'cap', '3', 'Ġ=', 'Ġ(', 'Ġ"', '03', '01', '00000000', '112', '2', 'a', 'abb', 'cc', 'dd', '010', '20', '30', '40', '50', '60', '708', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['cap', '3', 'Ġ=', 'Ġ(', 'Ġ"', '03', '01', '00000000', '112', '2', 'a', 'abb', 'cc', 'dd', '010', '20', '30', '40', '50', '60', '708', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['cap3', 'Ġ=', 'Ġ(', 'Ġ"0301000000001122aabbccdd0102030405060708"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"hex"', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "intps [ ] = dest_target . vlan \n"
Original    (008): ['intps', '[', ']', '=', 'dest_target', '.', 'vlan', '\\n']
Tokenized   (015): ['<s>', 'int', 'ps', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdest', '_', 'target', 'Ġ.', 'Ġv', 'lan', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['int', 'ps', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdest', '_', 'target', 'Ġ.', 'Ġv', 'lan', 'Ġ\\', 'n']
Detokenized (008): ['intps', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdest_target', 'Ġ.', 'Ġvlan', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "router , interface = ri . split ( ) \n"
Original    (010): ['router', ',', 'interface', '=', 'ri', '.', 'split', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'rou', 'ter', 'Ġ,', 'Ġinterface', 'Ġ=', 'Ġr', 'i', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['rou', 'ter', 'Ġ,', 'Ġinterface', 'Ġ=', 'Ġr', 'i', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['router', 'Ġ,', 'Ġinterface', 'Ġ=', 'Ġri', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "cm = NCSVPNConnectionManager ( ncs_services_url , user , password , port_map , name ) \n"
Original    (015): ['cm', '=', 'NCSVPNConnectionManager', '(', 'ncs_services_url', ',', 'user', ',', 'password', ',', 'port_map', ',', 'name', ')', '\\n']
Tokenized   (029): ['<s>', 'cm', 'Ġ=', 'ĠN', 'CS', 'VPN', 'Connection', 'Manager', 'Ġ(', 'Ġn', 'cs', '_', 'services', '_', 'url', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġpassword', 'Ġ,', 'Ġport', '_', 'map', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['cm', 'Ġ=', 'ĠN', 'CS', 'VPN', 'Connection', 'Manager', 'Ġ(', 'Ġn', 'cs', '_', 'services', '_', 'url', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġpassword', 'Ġ,', 'Ġport', '_', 'map', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['cm', 'Ġ=', 'ĠNCSVPNConnectionManager', 'Ġ(', 'Ġncs_services_url', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġpassword', 'Ġ,', 'Ġport_map', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "soap_resource . registerDecoder ( actions . QUERY_RECURSIVE , self . queryRecursive ) \n"
Original    (013): ['soap_resource', '.', 'registerDecoder', '(', 'actions', '.', 'QUERY_RECURSIVE', ',', 'self', '.', 'queryRecursive', ')', '\\n']
Tokenized   (029): ['<s>', 'so', 'ap', '_', 'resource', 'Ġ.', 'Ġregister', 'Dec', 'oder', 'Ġ(', 'Ġactions', 'Ġ.', 'ĠQU', 'ERY', '_', 'REC', 'UR', 'S', 'IVE', 'Ġ,', 'Ġself', 'Ġ.', 'Ġquery', 'Rec', 'ursive', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['so', 'ap', '_', 'resource', 'Ġ.', 'Ġregister', 'Dec', 'oder', 'Ġ(', 'Ġactions', 'Ġ.', 'ĠQU', 'ERY', '_', 'REC', 'UR', 'S', 'IVE', 'Ġ,', 'Ġself', 'Ġ.', 'Ġquery', 'Rec', 'ursive', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['soap_resource', 'Ġ.', 'ĠregisterDecoder', 'Ġ(', 'Ġactions', 'Ġ.', 'ĠQUERY_RECURSIVE', 'Ġ,', 'Ġself', 'Ġ.', 'ĠqueryRecursive', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "soap_fault = soapresource . SOAPFault ( err . getErrorMessage ( ) , ex_element ) \n"
Original    (015): ['soap_fault', '=', 'soapresource', '.', 'SOAPFault', '(', 'err', '.', 'getErrorMessage', '(', ')', ',', 'ex_element', ')', '\\n']
Tokenized   (030): ['<s>', 'so', 'ap', '_', 'f', 'ault', 'Ġ=', 'Ġsoap', 'resource', 'Ġ.', 'ĠSO', 'AP', 'F', 'ault', 'Ġ(', 'Ġerr', 'Ġ.', 'Ġget', 'Error', 'Message', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġex', '_', 'element', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['so', 'ap', '_', 'f', 'ault', 'Ġ=', 'Ġsoap', 'resource', 'Ġ.', 'ĠSO', 'AP', 'F', 'ault', 'Ġ(', 'Ġerr', 'Ġ.', 'Ġget', 'Error', 'Message', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġex', '_', 'element', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['soap_fault', 'Ġ=', 'Ġsoapresource', 'Ġ.', 'ĠSOAPFault', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠgetErrorMessage', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġex_element', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "symmetric = p2ps . symmetricPath or False sd = nsa . Point2PointService ( src_stp , dst_stp , p2ps . capacity , p2ps . directionality , symmetric , \n"
Original    (028): ['symmetric', '=', 'p2ps', '.', 'symmetricPath', 'or', 'False', 'sd', '=', 'nsa', '.', 'Point2PointService', '(', 'src_stp', ',', 'dst_stp', ',', 'p2ps', '.', 'capacity', ',', 'p2ps', '.', 'directionality', ',', 'symmetric', ',', '\\n']
Tokenized   (053): ['<s>', 'sy', 'mm', 'etric', 'Ġ=', 'Ġp', '2', 'ps', 'Ġ.', 'Ġsymm', 'etric', 'Path', 'Ġor', 'ĠFalse', 'Ġsd', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠPoint', '2', 'Point', 'Service', 'Ġ(', 'Ġsrc', '_', 'st', 'p', 'Ġ,', 'Ġdst', '_', 'st', 'p', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġcapacity', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġdirection', 'ality', 'Ġ,', 'Ġsymm', 'etric', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (051): ['sy', 'mm', 'etric', 'Ġ=', 'Ġp', '2', 'ps', 'Ġ.', 'Ġsymm', 'etric', 'Path', 'Ġor', 'ĠFalse', 'Ġsd', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠPoint', '2', 'Point', 'Service', 'Ġ(', 'Ġsrc', '_', 'st', 'p', 'Ġ,', 'Ġdst', '_', 'st', 'p', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġcapacity', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġdirection', 'ality', 'Ġ,', 'Ġsymm', 'etric', 'Ġ,', 'Ġ\\', 'n']
Detokenized (028): ['symmetric', 'Ġ=', 'Ġp2ps', 'Ġ.', 'ĠsymmetricPath', 'Ġor', 'ĠFalse', 'Ġsd', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠPoint2PointService', 'Ġ(', 'Ġsrc_stp', 'Ġ,', 'Ġdst_stp', 'Ġ,', 'Ġp2ps', 'Ġ.', 'Ġcapacity', 'Ġ,', 'Ġp2ps', 'Ġ.', 'Ġdirectionality', 'Ġ,', 'Ġsymmetric', 'Ġ,', 'Ġ\\n']
Counter: 51
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "crt = nsa . Criteria ( criteria . version , schedule , sd ) \n"
Original    (015): ['crt', '=', 'nsa', '.', 'Criteria', '(', 'criteria', '.', 'version', ',', 'schedule', ',', 'sd', ')', '\\n']
Tokenized   (021): ['<s>', 'cr', 't', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠCrit', 'eria', 'Ġ(', 'Ġcriteria', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġschedule', 'Ġ,', 'Ġsd', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['cr', 't', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠCrit', 'eria', 'Ġ(', 'Ġcriteria', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġschedule', 'Ġ,', 'Ġsd', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['crt', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠCriteria', 'Ġ(', 'Ġcriteria', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġschedule', 'Ġ,', 'Ġsd', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tc = json . load ( open ( tcf ) ) \n"
Original    (012): ['tc', '=', 'json', '.', 'load', '(', 'open', '(', 'tcf', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'tc', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġt', 'cf', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['tc', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġt', 'cf', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['tc', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġtcf', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "source_stp = nsa . STP ( , , labels = [ nsa . Label ( nml . ETHERNET_VLAN , dest_stp = nsa . STP ( , , labels = [ nsa . Label ( nml . ETHERNET_VLAN , start_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = 2 ) \n"
Original    (057): ['source_stp', '=', 'nsa', '.', 'STP', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'Label', '(', 'nml', '.', 'ETHERNET_VLAN', ',', 'dest_stp', '=', 'nsa', '.', 'STP', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'Label', '(', 'nml', '.', 'ETHERNET_VLAN', ',', 'start_time', '=', 'datetime', '.', 'datetime', '.', 'utcnow', '(', ')', '+', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '2', ')', '\\n']
Tokenized   (092): ['<s>', 'source', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġdest', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġstart', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (090): ['source', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġdest', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġstart', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (057): ['source_stp', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠSTP', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġnsa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġnml', 'Ġ.', 'ĠETHERNET_VLAN', 'Ġ,', 'Ġdest_stp', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠSTP', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġnsa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġnml', 'Ġ.', 'ĠETHERNET_VLAN', 'Ġ,', 'Ġstart_time', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġdatetime', 'Ġ.', 'Ġutcnow', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 90
===================================================================
Hidden states:  (13, 57, 768)
# Extracted words:  57
Sentence         : "end_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = 30 ) \n"
Original    (019): ['end_time', '=', 'datetime', '.', 'datetime', '.', 'utcnow', '(', ')', '+', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '30', ')', '\\n']
Tokenized   (030): ['<s>', 'end', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ30', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['end', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ30', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['end_time', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġdatetime', 'Ġ.', 'Ġutcnow', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ30', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "connection_id , active , version_consistent , version , timestamp = yield d_down \n"
Original    (013): ['connection_id', ',', 'active', ',', 'version_consistent', ',', 'version', ',', 'timestamp', '=', 'yield', 'd_down', '\\n']
Tokenized   (023): ['<s>', 'connection', '_', 'id', 'Ġ,', 'Ġactive', 'Ġ,', 'Ġversion', '_', 'cons', 'istent', 'Ġ,', 'Ġversion', 'Ġ,', 'Ġtimestamp', 'Ġ=', 'Ġyield', 'Ġd', '_', 'down', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['connection', '_', 'id', 'Ġ,', 'Ġactive', 'Ġ,', 'Ġversion', '_', 'cons', 'istent', 'Ġ,', 'Ġversion', 'Ġ,', 'Ġtimestamp', 'Ġ=', 'Ġyield', 'Ġd', '_', 'down', 'Ġ\\', 'n']
Detokenized (013): ['connection_id', 'Ġ,', 'Ġactive', 'Ġ,', 'Ġversion_consistent', 'Ġ,', 'Ġversion', 'Ġ,', 'Ġtimestamp', 'Ġ=', 'Ġyield', 'Ġd_down', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "scheduler = digits . scheduler . Scheduler ( config_value ( ) , True ) \n"
Original    (015): ['scheduler', '=', 'digits', '.', 'scheduler', '.', 'Scheduler', '(', 'config_value', '(', ')', ',', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'sc', 'hed', 'uler', 'Ġ=', 'Ġdigits', 'Ġ.', 'Ġsched', 'uler', 'Ġ.', 'ĠSched', 'uler', 'Ġ(', 'Ġconfig', '_', 'value', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['sc', 'hed', 'uler', 'Ġ=', 'Ġdigits', 'Ġ.', 'Ġsched', 'uler', 'Ġ.', 'ĠSched', 'uler', 'Ġ(', 'Ġconfig', '_', 'value', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['scheduler', 'Ġ=', 'Ġdigits', 'Ġ.', 'Ġscheduler', 'Ġ.', 'ĠScheduler', 'Ġ(', 'Ġconfig_value', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "row_index = int ( params [ ] [ 0 ] ) \n"
Original    (012): ['row_index', '=', 'int', '(', 'params', '[', ']', '[', '0', ']', ')', '\\n']
Tokenized   (017): ['<s>', 'row', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['row', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['row_index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "char_index = int ( params [ ] [ 0 ] ) - 1 \n"
Original    (014): ['char_index', '=', 'int', '(', 'params', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Tokenized   (019): ['<s>', 'char', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['char', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (014): ['char_index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "comparator = comparators . index ( params [ ] [ 0 ] ) - 1 \n"
Original    (016): ['comparator', '=', 'comparators', '.', 'index', '(', 'params', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Tokenized   (022): ['<s>', 'com', 'par', 'ator', 'Ġ=', 'Ġcompar', 'ators', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['com', 'par', 'ator', 'Ġ=', 'Ġcompar', 'ators', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (016): ['comparator', 'Ġ=', 'Ġcomparators', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "truth = ( cmp ( ord ( current_character ) , test_char ) == comparator ) \n"
Original    (016): ['truth', '=', '(', 'cmp', '(', 'ord', '(', 'current_character', ')', ',', 'test_char', ')', '==', 'comparator', ')', '\\n']
Tokenized   (025): ['<s>', 'truth', 'Ġ=', 'Ġ(', 'Ġc', 'mp', 'Ġ(', 'Ġord', 'Ġ(', 'Ġcurrent', '_', 'character', 'Ġ)', 'Ġ,', 'Ġtest', '_', 'char', 'Ġ)', 'Ġ==', 'Ġcompar', 'ator', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['truth', 'Ġ=', 'Ġ(', 'Ġc', 'mp', 'Ġ(', 'Ġord', 'Ġ(', 'Ġcurrent', '_', 'character', 'Ġ)', 'Ġ,', 'Ġtest', '_', 'char', 'Ġ)', 'Ġ==', 'Ġcompar', 'ator', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['truth', 'Ġ=', 'Ġ(', 'Ġcmp', 'Ġ(', 'Ġord', 'Ġ(', 'Ġcurrent_character', 'Ġ)', 'Ġ,', 'Ġtest_char', 'Ġ)', 'Ġ==', 'Ġcomparator', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "start_response ( , [ ( , ) ] ) \n"
Original    (010): ['start_response', '(', ',', '[', '(', ',', ')', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'start', '_', 'response', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['start', '_', 'response', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['start_response', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "CHARSET = [ chr ( x ) for x in xrange ( 32 , 127 ) ] \n"
Original    (018): ['CHARSET', '=', '[', 'chr', '(', 'x', ')', 'for', 'x', 'in', 'xrange', '(', '32', ',', '127', ')', ']', '\\n']
Tokenized   (025): ['<s>', 'CH', 'ARS', 'ET', 'Ġ=', 'Ġ[', 'Ġch', 'r', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġx', 'range', 'Ġ(', 'Ġ32', 'Ġ,', 'Ġ127', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['CH', 'ARS', 'ET', 'Ġ=', 'Ġ[', 'Ġch', 'r', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġx', 'range', 'Ġ(', 'Ġ32', 'Ġ,', 'Ġ127', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['CHARSET', 'Ġ=', 'Ġ[', 'Ġchr', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġxrange', 'Ġ(', 'Ġ32', 'Ġ,', 'Ġ127', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "obj_struct [ ] = [ int ( bbox . find ( ) . text ) , \n"
Original    (017): ['obj_struct', '[', ']', '=', '[', 'int', '(', 'bbox', '.', 'find', '(', ')', '.', 'text', ')', ',', '\\n']
Tokenized   (023): ['<s>', 'obj', '_', 'struct', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġint', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['obj', '_', 'struct', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġint', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['obj_struct', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġint', 'Ġ(', 'Ġbbox', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "int ( bbox . find ( ) . text ) ] \n"
Original    (012): ['int', '(', 'bbox', '.', 'find', '(', ')', '.', 'text', ')', ']', '\\n']
Tokenized   (016): ['<s>', 'int', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['int', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['int', 'Ġ(', 'Ġbbox', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mpre = np . concatenate ( ( [ 0. ] , prec , [ 0. ] ) ) \n"
Original    (019): ['mpre', '=', 'np', '.', 'concatenate', '(', '(', '[', '0.', ']', ',', 'prec', ',', '[', '0.', ']', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'mp', 're', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġprec', 'Ġ,', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['mp', 're', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġprec', 'Ġ,', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['mpre', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġconcatenate', 'Ġ(', 'Ġ(', 'Ġ[', 'Ġ0.', 'Ġ]', 'Ġ,', 'Ġprec', 'Ġ,', 'Ġ[', 'Ġ0.', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "difficult = np . array ( [ x [ ] for x in R ] ) . astype ( np . bool ) \n"
Original    (024): ['difficult', '=', 'np', '.', 'array', '(', '[', 'x', '[', ']', 'for', 'x', 'in', 'R', ']', ')', '.', 'astype', '(', 'np', '.', 'bool', ')', '\\n']
Tokenized   (029): ['<s>', 'diff', 'icult', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'ĠR', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġbool', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['diff', 'icult', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'ĠR', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġbool', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['difficult', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'ĠR', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġbool', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "det = [ False ] * len ( R ) \n"
Original    (011): ['det', '=', '[', 'False', ']', '*', 'len', '(', 'R', ')', '\\n']
Tokenized   (014): ['<s>', 'det', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġ]', 'Ġ*', 'Ġlen', 'Ġ(', 'ĠR', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['det', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġ]', 'Ġ*', 'Ġlen', 'Ġ(', 'ĠR', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['det', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġ]', 'Ġ*', 'Ġlen', 'Ġ(', 'ĠR', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "npos = npos + sum ( ~ difficult ) \n"
Original    (010): ['npos', '=', 'npos', '+', 'sum', '(', '~', 'difficult', ')', '\\n']
Tokenized   (015): ['<s>', 'n', 'pos', 'Ġ=', 'Ġn', 'pos', 'Ġ+', 'Ġsum', 'Ġ(', 'Ġ~', 'Ġdifficult', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['n', 'pos', 'Ġ=', 'Ġn', 'pos', 'Ġ+', 'Ġsum', 'Ġ(', 'Ġ~', 'Ġdifficult', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['npos', 'Ġ=', 'Ġnpos', 'Ġ+', 'Ġsum', 'Ġ(', 'Ġ~', 'Ġdifficult', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "class_recs [ imagename ] = { : bbox , \n"
Original    (010): ['class_recs', '[', 'imagename', ']', '=', '{', ':', 'bbox', ',', '\\n']
Tokenized   (018): ['<s>', 'class', '_', 're', 'cs', 'Ġ[', 'Ġimag', 'ename', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġb', 'box', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['class', '_', 're', 'cs', 'Ġ[', 'Ġimag', 'ename', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġb', 'box', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['class_recs', 'Ġ[', 'Ġimagename', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġbbox', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "confidence = np . array ( [ float ( x [ 1 ] ) for x in splitlines ] ) \n"
Original    (021): ['confidence', '=', 'np', '.', 'array', '(', '[', 'float', '(', 'x', '[', '1', ']', ')', 'for', 'x', 'in', 'splitlines', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'confidence', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġsplit', 'lines', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['confidence', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġsplit', 'lines', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['confidence', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġsplitlines', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "sorted_ind = np . argsort ( - confidence ) \n"
Original    (010): ['sorted_ind', '=', 'np', '.', 'argsort', '(', '-', 'confidence', ')', '\\n']
Tokenized   (017): ['<s>', 's', 'orted', '_', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġargs', 'ort', 'Ġ(', 'Ġ-', 'Ġconfidence', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['s', 'orted', '_', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġargs', 'ort', 'Ġ(', 'Ġ-', 'Ġconfidence', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['sorted_ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġargsort', 'Ġ(', 'Ġ-', 'Ġconfidence', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "BB = BB [ sorted_ind , : ] \n"
Original    (009): ['BB', '=', 'BB', '[', 'sorted_ind', ',', ':', ']', '\\n']
Tokenized   (014): ['<s>', 'BB', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġsorted', '_', 'ind', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['BB', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġsorted', '_', 'ind', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['BB', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġsorted_ind', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "image_ids = [ image_ids [ x ] for x in sorted_ind ] \n"
Original    (013): ['image_ids', '=', '[', 'image_ids', '[', 'x', ']', 'for', 'x', 'in', 'sorted_ind', ']', '\\n']
Tokenized   (022): ['<s>', 'image', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġimage', '_', 'ids', 'Ġ[', 'Ġx', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'Ġsorted', '_', 'ind', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['image', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġimage', '_', 'ids', 'Ġ[', 'Ġx', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'Ġsorted', '_', 'ind', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['image_ids', 'Ġ=', 'Ġ[', 'Ġimage_ids', 'Ġ[', 'Ġx', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'Ġsorted_ind', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "bb = BB [ d , : ] . astype ( float ) \n"
Original    (014): ['bb', '=', 'BB', '[', 'd', ',', ':', ']', '.', 'astype', '(', 'float', ')', '\\n']
Tokenized   (018): ['<s>', 'bb', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġd', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['bb', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġd', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['bb', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġd', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "BBGT = R [ ] . astype ( float ) \n"
Original    (011): ['BBGT', '=', 'R', '[', ']', '.', 'astype', '(', 'float', ')', '\\n']
Tokenized   (016): ['<s>', 'BB', 'GT', 'Ġ=', 'ĠR', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['BB', 'GT', 'Ġ=', 'ĠR', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['BBGT', 'Ġ=', 'ĠR', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "iymin = np . maximum ( BBGT [ : , 1 ] , bb [ 1 ] ) \n"
Original    (019): ['iymin', '=', 'np', '.', 'maximum', '(', 'BBGT', '[', ':', ',', '1', ']', ',', 'bb', '[', '1', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'iy', 'min', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'ĠBB', 'GT', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['iy', 'min', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'ĠBB', 'GT', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['iymin', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'ĠBBGT', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġbb', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "iw = np . maximum ( ixmax - ixmin + 1. , 0. ) \n"
Original    (015): ['iw', '=', 'np', '.', 'maximum', '(', 'ixmax', '-', 'ixmin', '+', '1.', ',', '0.', ')', '\\n']
Tokenized   (024): ['<s>', 'iw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'Ġ', 'ix', 'max', 'Ġ-', 'Ġ', 'ix', 'min', 'Ġ+', 'Ġ1', '.', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['iw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'Ġ', 'ix', 'max', 'Ġ-', 'Ġ', 'ix', 'min', 'Ġ+', 'Ġ1', '.', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['iw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'Ġixmax', 'Ġ-', 'Ġixmin', 'Ġ+', 'Ġ1.', 'Ġ,', 'Ġ0.', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "uni = ( ( bb [ 2 ] - bb [ 0 ] + 1. ) * ( bb [ 3 ] - bb [ 1 ] + 1. ) + \n"
Original    (032): ['uni', '=', '(', '(', 'bb', '[', '2', ']', '-', 'bb', '[', '0', ']', '+', '1.', ')', '*', '(', 'bb', '[', '3', ']', '-', 'bb', '[', '1', ']', '+', '1.', ')', '+', '\\n']
Tokenized   (041): ['<s>', 'uni', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['uni', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (032): ['uni', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġbb', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ-', 'Ġbb', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ1.', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġbb', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ-', 'Ġbb', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ+', 'Ġ1.', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "rec = tp / float ( npos ) \n"
Original    (009): ['rec', '=', 'tp', '/', 'float', '(', 'npos', ')', '\\n']
Tokenized   (014): ['<s>', 'rec', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġn', 'pos', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['rec', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġn', 'pos', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['rec', 'Ġ=', 'Ġtp', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġnpos', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "prec = tp / ( tp + fp + 1e-10 ) \n"
Original    (012): ['prec', '=', 'tp', '/', '(', 'tp', '+', 'fp', '+', '1e-10', ')', '\\n']
Tokenized   (022): ['<s>', 'pre', 'c', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġ(', 'Ġt', 'p', 'Ġ+', 'Ġf', 'p', 'Ġ+', 'Ġ1', 'e', '-', '10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['pre', 'c', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġ(', 'Ġt', 'p', 'Ġ+', 'Ġf', 'p', 'Ġ+', 'Ġ1', 'e', '-', '10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['prec', 'Ġ=', 'Ġtp', 'Ġ/', 'Ġ(', 'Ġtp', 'Ġ+', 'Ġfp', 'Ġ+', 'Ġ1e-10', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "scale = strip_mantissa ( maxval ) / float ( 1 << ( bits - sign - 1 ) ) \n"
Original    (020): ['scale', '=', 'strip_mantissa', '(', 'maxval', ')', '/', 'float', '(', '1', '<<', '(', 'bits', '-', 'sign', '-', '1', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'scale', 'Ġ=', 'Ġstrip', '_', 'm', 'ant', 'issa', 'Ġ(', 'Ġmax', 'val', 'Ġ)', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġ1', 'Ġ<<', 'Ġ(', 'Ġbits', 'Ġ-', 'Ġsign', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['scale', 'Ġ=', 'Ġstrip', '_', 'm', 'ant', 'issa', 'Ġ(', 'Ġmax', 'val', 'Ġ)', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġ1', 'Ġ<<', 'Ġ(', 'Ġbits', 'Ġ-', 'Ġsign', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['scale', 'Ġ=', 'Ġstrip_mantissa', 'Ġ(', 'Ġmaxval', 'Ġ)', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġ1', 'Ġ<<', 'Ġ(', 'Ġbits', 'Ġ-', 'Ġsign', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "ary = np . around ( ary * ( 1.0 / scale ) ) . astype ( np . int64 ) \n"
Original    (022): ['ary', '=', 'np', '.', 'around', '(', 'ary', '*', '(', '1.0', '/', 'scale', ')', ')', '.', 'astype', '(', 'np', '.', 'int64', ')', '\\n']
Tokenized   (030): ['<s>', 'ary', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġaround', 'Ġ(', 'Ġa', 'ry', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġscale', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġint', '64', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['ary', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġaround', 'Ġ(', 'Ġa', 'ry', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġscale', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġint', '64', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['ary', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġaround', 'Ġ(', 'Ġary', 'Ġ*', 'Ġ(', 'Ġ1.0', 'Ġ/', 'Ġscale', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġint64', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "f2 -= dif \n"
Original    (004): ['f2', '-=', 'dif', '\\n']
Tokenized   (009): ['<s>', 'f', '2', 'Ġ-=', 'Ġd', 'if', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['f', '2', 'Ġ-=', 'Ġd', 'if', 'Ġ\\', 'n']
Detokenized (004): ['f2', 'Ġ-=', 'Ġdif', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "slicedF = F [ : , sliceR , sliceS , : ] . reshape ( ( - 1 , K ) ) \n"
Original    (023): ['slicedF', '=', 'F', '[', ':', ',', 'sliceR', ',', 'sliceS', ',', ':', ']', '.', 'reshape', '(', '(', '-', '1', ',', 'K', ')', ')', '\\n']
Tokenized   (032): ['<s>', 's', 'lic', 'ed', 'F', 'Ġ=', 'ĠF', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġslice', 'R', 'Ġ,', 'Ġslice', 'S', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['s', 'lic', 'ed', 'F', 'Ġ=', 'ĠF', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġslice', 'R', 'Ġ,', 'Ġslice', 'S', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['slicedF', 'Ġ=', 'ĠF', 'Ġ[', 'Ġ:', 'Ġ,', 'ĠsliceR', 'Ġ,', 'ĠsliceS', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "K , P , Q , N = E . shape \n"
Original    (012): ['K', ',', 'P', ',', 'Q', ',', 'N', '=', 'E', '.', 'shape', '\\n']
Tokenized   (015): ['<s>', 'K', 'Ġ,', 'ĠP', 'Ġ,', 'ĠQ', 'Ġ,', 'ĠN', 'Ġ=', 'ĠE', 'Ġ.', 'Ġshape', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['K', 'Ġ,', 'ĠP', 'Ġ,', 'ĠQ', 'Ġ,', 'ĠN', 'Ġ=', 'ĠE', 'Ġ.', 'Ġshape', 'Ġ\\', 'n']
Detokenized (012): ['K', 'Ġ,', 'ĠP', 'Ġ,', 'ĠQ', 'Ġ,', 'ĠN', 'Ġ=', 'ĠE', 'Ġ.', 'Ġshape', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "qSlice = [ fconv_slice ( q , S , X , padding [ 0 ] , strides [ 0 ] ) for q in range ( Q ) ] \n"
Original    (030): ['qSlice', '=', '[', 'fconv_slice', '(', 'q', ',', 'S', ',', 'X', ',', 'padding', '[', '0', ']', ',', 'strides', '[', '0', ']', ')', 'for', 'q', 'in', 'range', '(', 'Q', ')', ']', '\\n']
Tokenized   (038): ['<s>', 'q', 'Sl', 'ice', 'Ġ=', 'Ġ[', 'Ġf', 'conv', '_', 'slice', 'Ġ(', 'Ġq', 'Ġ,', 'ĠS', 'Ġ,', 'ĠX', 'Ġ,', 'Ġpadding', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġq', 'Ġin', 'Ġrange', 'Ġ(', 'ĠQ', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['q', 'Sl', 'ice', 'Ġ=', 'Ġ[', 'Ġf', 'conv', '_', 'slice', 'Ġ(', 'Ġq', 'Ġ,', 'ĠS', 'Ġ,', 'ĠX', 'Ġ,', 'Ġpadding', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġq', 'Ġin', 'Ġrange', 'Ġ(', 'ĠQ', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (030): ['qSlice', 'Ġ=', 'Ġ[', 'Ġfconv_slice', 'Ġ(', 'Ġq', 'Ġ,', 'ĠS', 'Ġ,', 'ĠX', 'Ġ,', 'Ġpadding', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġq', 'Ġin', 'Ġrange', 'Ġ(', 'ĠQ', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 30, 768)
# Extracted words:  30
Sentence         : "slicedE = E [ : , p , q , : ] \n"
Original    (013): ['slicedE', '=', 'E', '[', ':', ',', 'p', ',', 'q', ',', ':', ']', '\\n']
Tokenized   (019): ['<s>', 's', 'lic', 'ed', 'E', 'Ġ=', 'ĠE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġp', 'Ġ,', 'Ġq', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['s', 'lic', 'ed', 'E', 'Ġ=', 'ĠE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġp', 'Ġ,', 'Ġq', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['slicedE', 'Ġ=', 'ĠE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġp', 'Ġ,', 'Ġq', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "rcp3 = 1.0 / 3.0 \n"
Original    (006): ['rcp3', '=', '1.0', '/', '3.0', '\\n']
Tokenized   (015): ['<s>', 'rc', 'p', '3', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ3', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['rc', 'p', '3', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ3', '.', '0', 'Ġ\\', 'n']
Detokenized (006): ['rcp3', 'Ġ=', 'Ġ1.0', 'Ġ/', 'Ġ3.0', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "t3 = I [ 1 , : ] + I [ 3 , : ] * 4.0 \n"
Original    (018): ['t3', '=', 'I', '[', '1', ',', ':', ']', '+', 'I', '[', '3', ',', ':', ']', '*', '4.0', '\\n']
Tokenized   (024): ['<s>', 't', '3', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ+', 'ĠI', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ*', 'Ġ4', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', '3', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ+', 'ĠI', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ*', 'Ġ4', '.', '0', 'Ġ\\', 'n']
Detokenized (018): ['t3', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ+', 'ĠI', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ*', 'Ġ4.0', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "T1 = np . empty ( ( 3 , 3 ) ) \n"
Original    (013): ['T1', '=', 'np', '.', 'empty', '(', '(', '3', ',', '3', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'T', '1', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['T', '1', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['T1', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Fw = np . empty ( ( D , D , C , K ) ) \n"
Original    (017): ['Fw', '=', 'np', '.', 'empty', '(', '(', 'D', ',', 'D', ',', 'C', ',', 'K', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'F', 'w', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'ĠD', 'Ġ,', 'ĠD', 'Ġ,', 'ĠC', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['F', 'w', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'ĠD', 'Ġ,', 'ĠD', 'Ġ,', 'ĠC', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['Fw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'ĠD', 'Ġ,', 'ĠD', 'Ġ,', 'ĠC', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sliceI = I [ : , start_y : stop_y , start_x : stop_x , : ] \n"
Original    (017): ['sliceI', '=', 'I', '[', ':', ',', 'start_y', ':', 'stop_y', ',', 'start_x', ':', 'stop_x', ',', ':', ']', '\\n']
Tokenized   (029): ['<s>', 'slice', 'I', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġstart', '_', 'y', 'Ġ:', 'Ġstop', '_', 'y', 'Ġ,', 'Ġstart', '_', 'x', 'Ġ:', 'Ġstop', '_', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['slice', 'I', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġstart', '_', 'y', 'Ġ:', 'Ġstop', '_', 'y', 'Ġ,', 'Ġstart', '_', 'x', 'Ġ:', 'Ġstop', '_', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['sliceI', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġstart_y', 'Ġ:', 'Ġstop_y', 'Ġ,', 'Ġstart_x', 'Ġ:', 'Ġstop_x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "O [ k , p0 : p1 , q0 : q1 , n ] = Out [ 0 : plen , 0 : qlen ] \n"
Original    (026): ['O', '[', 'k', ',', 'p0', ':', 'p1', ',', 'q0', ':', 'q1', ',', 'n', ']', '=', 'Out', '[', '0', ':', 'plen', ',', '0', ':', 'qlen', ']', '\\n']
Tokenized   (035): ['<s>', 'O', 'Ġ[', 'Ġk', 'Ġ,', 'Ġp', '0', 'Ġ:', 'Ġp', '1', 'Ġ,', 'Ġq', '0', 'Ġ:', 'Ġq', '1', 'Ġ,', 'Ġn', 'Ġ]', 'Ġ=', 'ĠOut', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġpl', 'en', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġq', 'len', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['O', 'Ġ[', 'Ġk', 'Ġ,', 'Ġp', '0', 'Ġ:', 'Ġp', '1', 'Ġ,', 'Ġq', '0', 'Ġ:', 'Ġq', '1', 'Ġ,', 'Ġn', 'Ġ]', 'Ġ=', 'ĠOut', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġpl', 'en', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġq', 'len', 'Ġ]', 'Ġ\\', 'n']
Detokenized (026): ['O', 'Ġ[', 'Ġk', 'Ġ,', 'Ġp0', 'Ġ:', 'Ġp1', 'Ġ,', 'Ġq0', 'Ġ:', 'Ġq1', 'Ġ,', 'Ġn', 'Ġ]', 'Ġ=', 'ĠOut', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġplen', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġqlen', 'Ġ]', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "start_p , stop_p , pad_p = image_slice ( y , P , B , B ) \n"
Original    (017): ['start_p', ',', 'stop_p', ',', 'pad_p', '=', 'image_slice', '(', 'y', ',', 'P', ',', 'B', ',', 'B', ')', '\\n']
Tokenized   (028): ['<s>', 'start', '_', 'p', 'Ġ,', 'Ġstop', '_', 'p', 'Ġ,', 'Ġpad', '_', 'p', 'Ġ=', 'Ġimage', '_', 'slice', 'Ġ(', 'Ġy', 'Ġ,', 'ĠP', 'Ġ,', 'ĠB', 'Ġ,', 'ĠB', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['start', '_', 'p', 'Ġ,', 'Ġstop', '_', 'p', 'Ġ,', 'Ġpad', '_', 'p', 'Ġ=', 'Ġimage', '_', 'slice', 'Ġ(', 'Ġy', 'Ġ,', 'ĠP', 'Ġ,', 'ĠB', 'Ġ,', 'ĠB', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['start_p', 'Ġ,', 'Ġstop_p', 'Ġ,', 'Ġpad_p', 'Ġ=', 'Ġimage_slice', 'Ġ(', 'Ġy', 'Ġ,', 'ĠP', 'Ġ,', 'ĠB', 'Ġ,', 'ĠB', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "trans = ( 2 , 2 ) \n"
Original    (008): ['trans', '=', '(', '2', ',', '2', ')', '\\n']
Tokenized   (011): ['<s>', 'trans', 'Ġ=', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['trans', 'Ġ=', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['trans', 'Ġ=', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "E = np . random . uniform ( - 1.0 , 1.0 , dimO ) \n"
Original    (016): ['E', '=', 'np', '.', 'random', '.', 'uniform', '(', '-', '1.0', ',', '1.0', ',', 'dimO', ')', '\\n']
Tokenized   (024): ['<s>', 'E', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġuniform', 'Ġ(', 'Ġ-', 'Ġ1', '.', '0', 'Ġ,', 'Ġ1', '.', '0', 'Ġ,', 'Ġdim', 'O', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['E', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġuniform', 'Ġ(', 'Ġ-', 'Ġ1', '.', '0', 'Ġ,', 'Ġ1', '.', '0', 'Ġ,', 'Ġdim', 'O', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['E', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġuniform', 'Ġ(', 'Ġ-', 'Ġ1.0', 'Ġ,', 'Ġ1.0', 'Ġ,', 'ĠdimO', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "xprop_direct ( E , F , Bd , padding , strides , backward = True ) \n"
Original    (017): ['xprop_direct', '(', 'E', ',', 'F', ',', 'Bd', ',', 'padding', ',', 'strides', ',', 'backward', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'x', 'prop', '_', 'direct', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['x', 'prop', '_', 'direct', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['xprop_direct', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠBd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "xprop_winograd ( E , F , Bw , padding , minimal = minimal , trans = trans , backward = True ) \n"
Original    (023): ['xprop_winograd', '(', 'E', ',', 'F', ',', 'Bw', ',', 'padding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ',', 'backward', '=', 'True', ')', '\\n']
Tokenized   (032): ['<s>', 'x', 'prop', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['x', 'prop', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['xprop_winograd', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠBw', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "updat_direct ( I , E , Ud , padding , strides ) \n"
Original    (013): ['updat_direct', '(', 'I', ',', 'E', ',', 'Ud', ',', 'padding', ',', 'strides', ')', '\\n']
Tokenized   (019): ['<s>', 'up', 'dat', '_', 'direct', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['up', 'dat', '_', 'direct', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['updat_direct', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "updat_winograd ( I , E , Uw , padding , minimal = minimal , trans = trans ) \n"
Original    (019): ['updat_winograd', '(', 'I', ',', 'E', ',', 'Uw', ',', 'padding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ')', '\\n']
Tokenized   (028): ['<s>', 'up', 'dat', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠU', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['up', 'dat', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠU', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['updat_winograd', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUw', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "BranchNode , SkipNode , LRN , ColorNoise ) \n"
Original    (009): ['BranchNode', ',', 'SkipNode', ',', 'LRN', ',', 'ColorNoise', ')', '\\n']
Tokenized   (018): ['<s>', 'B', 'ranch', 'Node', 'Ġ,', 'ĠSkip', 'Node', 'Ġ,', 'ĠLR', 'N', 'Ġ,', 'ĠColor', 'No', 'ise', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['B', 'ranch', 'Node', 'Ġ,', 'ĠSkip', 'Node', 'Ġ,', 'ĠLR', 'N', 'Ġ,', 'ĠColor', 'No', 'ise', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['BranchNode', 'Ġ,', 'ĠSkipNode', 'Ġ,', 'ĠLRN', 'Ġ,', 'ĠColorNoise', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "img_set_options = dict ( repo_dir = args . data_dir , \n"
Original    (011): ['img_set_options', '=', 'dict', '(', 'repo_dir', '=', 'args', '.', 'data_dir', ',', '\\n']
Tokenized   (022): ['<s>', 'img', '_', 'set', '_', 'options', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġrepo', '_', 'dir', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['img', '_', 'set', '_', 'options', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġrepo', '_', 'dir', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['img_set_options', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġrepo_dir', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġdata_dir', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "subset_pct = 0.09990891117239205 ) \n"
Original    (005): ['subset_pct', '=', '0.09990891117239205', ')', '\\n']
Tokenized   (020): ['<s>', 'sub', 'set', '_', 'p', 'ct', 'Ġ=', 'Ġ0', '.', '0', '999', '08', '911', '17', '239', '205', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['sub', 'set', '_', 'p', 'ct', 'Ġ=', 'Ġ0', '.', '0', '999', '08', '911', '17', '239', '205', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['subset_pct', 'Ġ=', 'Ġ0.09990891117239205', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "do_transforms = False , ** img_set_options ) \n"
Original    (008): ['do_transforms', '=', 'False', ',', '**', 'img_set_options', ')', '\\n']
Tokenized   (018): ['<s>', 'do', '_', 'trans', 'forms', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġimg', '_', 'set', '_', 'options', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['do', '_', 'trans', 'forms', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġimg', '_', 'set', '_', 'options', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['do_transforms', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġimg_set_options', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "test = ImageLoader ( set_name = , scale_range = ( 256 , 384 ) , shuffle = False , \n"
Original    (020): ['test', '=', 'ImageLoader', '(', 'set_name', '=', ',', 'scale_range', '=', '(', '256', ',', '384', ')', ',', 'shuffle', '=', 'False', ',', '\\n']
Tokenized   (028): ['<s>', 'test', 'Ġ=', 'ĠImage', 'Loader', 'Ġ(', 'Ġset', '_', 'name', 'Ġ=', 'Ġ,', 'Ġscale', '_', 'range', 'Ġ=', 'Ġ(', 'Ġ256', 'Ġ,', 'Ġ384', 'Ġ)', 'Ġ,', 'Ġshuffle', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['test', 'Ġ=', 'ĠImage', 'Loader', 'Ġ(', 'Ġset', '_', 'name', 'Ġ=', 'Ġ,', 'Ġscale', '_', 'range', 'Ġ=', 'Ġ(', 'Ġ256', 'Ġ,', 'Ġ384', 'Ġ)', 'Ġ,', 'Ġshuffle', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['test', 'Ġ=', 'ĠImageLoader', 'Ġ(', 'Ġset_name', 'Ġ=', 'Ġ,', 'Ġscale_range', 'Ġ=', 'Ġ(', 'Ġ256', 'Ġ,', 'Ġ384', 'Ġ)', 'Ġ,', 'Ġshuffle', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "Pooling ( 3 , strides = 2 ) , \n"
Original    (010): ['Pooling', '(', '3', ',', 'strides', '=', '2', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'Pool', 'ing', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġstrides', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Pool', 'ing', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġstrides', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['Pooling', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġstrides', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "activation = Rectlin ( ) , padding = 1 ) , \n"
Original    (012): ['activation', '=', 'Rectlin', '(', ')', ',', 'padding', '=', '1', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'activation', 'Ġ=', 'ĠRect', 'lin', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġpadding', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['activation', 'Ġ=', 'ĠRect', 'lin', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġpadding', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['activation', 'Ġ=', 'ĠRectlin', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġpadding', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Conv ( ( 3 , 3 , 256 ) , init = Gaussian ( scale = 0.03 ) , bias = Constant ( 1 ) , \n"
Original    (027): ['Conv', '(', '(', '3', ',', '3', ',', '256', ')', ',', 'init', '=', 'Gaussian', '(', 'scale', '=', '0.03', ')', ',', 'bias', '=', 'Constant', '(', '1', ')', ',', '\\n']
Tokenized   (034): ['<s>', 'Con', 'v', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ256', 'Ġ)', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '03', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['Con', 'v', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ256', 'Ġ)', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '03', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (027): ['Conv', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ256', 'Ġ)', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGaussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0.03', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "Dropout ( keep = 1.0 ) , \n"
Original    (008): ['Dropout', '(', 'keep', '=', '1.0', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'Drop', 'out', 'Ġ(', 'Ġkeep', 'Ġ=', 'Ġ1', '.', '0', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Drop', 'out', 'Ġ(', 'Ġkeep', 'Ġ=', 'Ġ1', '.', '0', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['Dropout', 'Ġ(', 'Ġkeep', 'Ġ=', 'Ġ1.0', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Affine ( nout = 1000 , init = Gaussian ( scale = 0.01 ) , bias = Constant ( - 7 ) , activation = Softmax ( ) ) ] \n"
Original    (031): ['Affine', '(', 'nout', '=', '1000', ',', 'init', '=', 'Gaussian', '(', 'scale', '=', '0.01', ')', ',', 'bias', '=', 'Constant', '(', '-', '7', ')', ',', 'activation', '=', 'Softmax', '(', ')', ')', ']', '\\n']
Tokenized   (040): ['<s>', 'Aff', 'ine', 'Ġ(', 'Ġn', 'out', 'Ġ=', 'Ġ1000', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '01', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ-', 'Ġ7', 'Ġ)', 'Ġ,', 'Ġactivation', 'Ġ=', 'ĠSoft', 'max', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['Aff', 'ine', 'Ġ(', 'Ġn', 'out', 'Ġ=', 'Ġ1000', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '01', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ-', 'Ġ7', 'Ġ)', 'Ġ,', 'Ġactivation', 'Ġ=', 'ĠSoft', 'max', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (031): ['Affine', 'Ġ(', 'Ġnout', 'Ġ=', 'Ġ1000', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGaussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0.01', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ-', 'Ġ7', 'Ġ)', 'Ġ,', 'Ġactivation', 'Ġ=', 'ĠSoftmax', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "weight_sched = Schedule ( [ 22 , 44 , 65 ] , ( 1 / 250. ) ** ( 1 / 3. ) ) \n"
Original    (025): ['weight_sched', '=', 'Schedule', '(', '[', '22', ',', '44', ',', '65', ']', ',', '(', '1', '/', '250.', ')', '**', '(', '1', '/', '3.', ')', ')', '\\n']
Tokenized   (033): ['<s>', 'weight', '_', 'sc', 'hed', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ22', 'Ġ,', 'Ġ44', 'Ġ,', 'Ġ65', 'Ġ]', 'Ġ,', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ250', '.', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ3', '.', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['weight', '_', 'sc', 'hed', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ22', 'Ġ,', 'Ġ44', 'Ġ,', 'Ġ65', 'Ġ]', 'Ġ,', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ250', '.', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ3', '.', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['weight_sched', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ22', 'Ġ,', 'Ġ44', 'Ġ,', 'Ġ65', 'Ġ]', 'Ġ,', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ250.', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ3.', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "opt_gdm = GradientDescentMomentum ( 0.01 / 10 , 0.9 , wdecay = 0.0005 , schedule = weight_sched , \n"
Original    (019): ['opt_gdm', '=', 'GradientDescentMomentum', '(', '0.01', '/', '10', ',', '0.9', ',', 'wdecay', '=', '0.0005', ',', 'schedule', '=', 'weight_sched', ',', '\\n']
Tokenized   (043): ['<s>', 'opt', '_', 'gd', 'm', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '01', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġw', 'dec', 'ay', 'Ġ=', 'Ġ0', '.', '000', '5', 'Ġ,', 'Ġschedule', 'Ġ=', 'Ġweight', '_', 'sc', 'hed', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['opt', '_', 'gd', 'm', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '01', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġw', 'dec', 'ay', 'Ġ=', 'Ġ0', '.', '000', '5', 'Ġ,', 'Ġschedule', 'Ġ=', 'Ġweight', '_', 'sc', 'hed', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['opt_gdm', 'Ġ=', 'ĠGradientDescentMomentum', 'Ġ(', 'Ġ0.01', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0.9', 'Ġ,', 'Ġwdecay', 'Ġ=', 'Ġ0.0005', 'Ġ,', 'Ġschedule', 'Ġ=', 'Ġweight_sched', 'Ġ,', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "opt_biases = GradientDescentMomentum ( 0.02 / 10 , 0.9 , schedule = Schedule ( [ 44 ] , 0.1 ) , \n"
Original    (022): ['opt_biases', '=', 'GradientDescentMomentum', '(', '0.02', '/', '10', ',', '0.9', ',', 'schedule', '=', 'Schedule', '(', '[', '44', ']', ',', '0.1', ')', ',', '\\n']
Tokenized   (040): ['<s>', 'opt', '_', 'bi', 'ases', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '02', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġschedule', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ44', 'Ġ]', 'Ġ,', 'Ġ0', '.', '1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['opt', '_', 'bi', 'ases', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '02', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġschedule', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ44', 'Ġ]', 'Ġ,', 'Ġ0', '.', '1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (022): ['opt_biases', 'Ġ=', 'ĠGradientDescentMomentum', 'Ġ(', 'Ġ0.02', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0.9', 'Ġ,', 'Ġschedule', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ44', 'Ġ]', 'Ġ,', 'Ġ0.1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "valmetric = TopKMisclassification ( k = 5 ) \n"
Original    (009): ['valmetric', '=', 'TopKMisclassification', '(', 'k', '=', '5', ')', '\\n']
Tokenized   (018): ['<s>', 'val', 'met', 'ric', 'Ġ=', 'ĠTop', 'K', 'Mis', 'class', 'ification', 'Ġ(', 'Ġk', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['val', 'met', 'ric', 'Ġ=', 'ĠTop', 'K', 'Mis', 'class', 'ification', 'Ġ(', 'Ġk', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['valmetric', 'Ġ=', 'ĠTopKMisclassification', 'Ġ(', 'Ġk', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "nifm_rng = [ 8 ] \n"
Original    (006): ['nifm_rng', '=', '[', '8', ']', '\\n']
Tokenized   (014): ['<s>', 'n', 'if', 'm', '_', 'r', 'ng', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['n', 'if', 'm', '_', 'r', 'ng', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['nifm_rng', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "fargs_ . append ( itt . product ( fs_rng , nifm_rng , pad_rng , stride_rng , in_sz_rng , bsz_rng ) ) \n"
Original    (022): ['fargs_', '.', 'append', '(', 'itt', '.', 'product', '(', 'fs_rng', ',', 'nifm_rng', ',', 'pad_rng', ',', 'stride_rng', ',', 'in_sz_rng', ',', 'bsz_rng', ')', ')', '\\n']
Tokenized   (053): ['<s>', 'f', 'args', '_', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġit', 't', 'Ġ.', 'Ġproduct', 'Ġ(', 'Ġfs', '_', 'r', 'ng', 'Ġ,', 'Ġn', 'if', 'm', '_', 'r', 'ng', 'Ġ,', 'Ġpad', '_', 'r', 'ng', 'Ġ,', 'Ġstride', '_', 'r', 'ng', 'Ġ,', 'Ġin', '_', 's', 'z', '_', 'r', 'ng', 'Ġ,', 'Ġb', 's', 'z', '_', 'r', 'ng', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (051): ['f', 'args', '_', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġit', 't', 'Ġ.', 'Ġproduct', 'Ġ(', 'Ġfs', '_', 'r', 'ng', 'Ġ,', 'Ġn', 'if', 'm', '_', 'r', 'ng', 'Ġ,', 'Ġpad', '_', 'r', 'ng', 'Ġ,', 'Ġstride', '_', 'r', 'ng', 'Ġ,', 'Ġin', '_', 's', 'z', '_', 'r', 'ng', 'Ġ,', 'Ġb', 's', 'z', '_', 'r', 'ng', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['fargs_', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġitt', 'Ġ.', 'Ġproduct', 'Ġ(', 'Ġfs_rng', 'Ġ,', 'Ġnifm_rng', 'Ġ,', 'Ġpad_rng', 'Ġ,', 'Ġstride_rng', 'Ġ,', 'Ġin_sz_rng', 'Ġ,', 'Ġbsz_rng', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 51
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "bsz = inp . shape [ - 1 ] \n"
Original    (010): ['bsz', '=', 'inp', '.', 'shape', '[', '-', '1', ']', '\\n']
Tokenized   (015): ['<s>', 'bs', 'z', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['bs', 'z', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['bsz', 'Ġ=', 'Ġinp', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "check_inds = check_inds [ 0 : ncheck ] \n"
Original    (009): ['check_inds', '=', 'check_inds', '[', '0', ':', 'ncheck', ']', '\\n']
Tokenized   (019): ['<s>', 'check', '_', 'ind', 's', 'Ġ=', 'Ġcheck', '_', 'ind', 's', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġn', 'check', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['check', '_', 'ind', 's', 'Ġ=', 'Ġcheck', '_', 'ind', 's', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġn', 'check', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['check_inds', 'Ġ=', 'Ġcheck_inds', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġncheck', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "inpa = inp . get ( ) . reshape ( inp_lshape ) \n"
Original    (013): ['inpa', '=', 'inp', '.', 'get', '(', ')', '.', 'reshape', '(', 'inp_lshape', ')', '\\n']
Tokenized   (023): ['<s>', 'in', 'pa', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['in', 'pa', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['inpa', 'Ġ=', 'Ġinp', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġinp_lshape', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "outshape = ( inp_lshape [ 0 ] , \n"
Original    (009): ['outshape', '=', '(', 'inp_lshape', '[', '0', ']', ',', '\\n']
Tokenized   (017): ['<s>', 'out', 'shape', 'Ġ=', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['out', 'shape', 'Ġ=', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['outshape', 'Ġ=', 'Ġ(', 'Ġinp_lshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "be . output_dim ( inp_lshape [ 2 ] , fshape [ 1 ] , padding , strides [ 1 ] , pooling = True ) , \n"
Original    (027): ['be', '.', 'output_dim', '(', 'inp_lshape', '[', '2', ']', ',', 'fshape', '[', '1', ']', ',', 'padding', ',', 'strides', '[', '1', ']', ',', 'pooling', '=', 'True', ')', ',', '\\n']
Tokenized   (038): ['<s>', 'be', 'Ġ.', 'Ġoutput', '_', 'dim', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġf', 'shape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpool', 'ing', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['be', 'Ġ.', 'Ġoutput', '_', 'dim', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġf', 'shape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpool', 'ing', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (027): ['be', 'Ġ.', 'Ġoutput_dim', 'Ġ(', 'Ġinp_lshape', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġfshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpooling', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "inp_lshape [ - 1 ] ) \n"
Original    (007): ['inp_lshape', '[', '-', '1', ']', ')', '\\n']
Tokenized   (014): ['<s>', 'in', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['in', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['inp_lshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "inp_pad [ : , padding : - padding , padding : - padding , : ] = inpa [ : , 0 : , 0 : , : ] \n"
Original    (030): ['inp_pad', '[', ':', ',', 'padding', ':', '-', 'padding', ',', 'padding', ':', '-', 'padding', ',', ':', ']', '=', 'inpa', '[', ':', ',', '0', ':', ',', '0', ':', ',', ':', ']', '\\n']
Tokenized   (037): ['<s>', 'in', 'p', '_', 'pad', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġin', 'pa', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['in', 'p', '_', 'pad', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġin', 'pa', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (030): ['inp_pad', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġinpa', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 30, 768)
# Extracted words:  30
Sentence         : "out_exp [ indC , indh , indw , cnt ] = np . max ( inp_check ) \n"
Original    (018): ['out_exp', '[', 'indC', ',', 'indh', ',', 'indw', ',', 'cnt', ']', '=', 'np', '.', 'max', '(', 'inp_check', ')', '\\n']
Tokenized   (030): ['<s>', 'out', '_', 'exp', 'Ġ[', 'Ġind', 'C', 'Ġ,', 'Ġind', 'h', 'Ġ,', 'Ġind', 'w', 'Ġ,', 'Ġc', 'nt', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġin', 'p', '_', 'check', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['out', '_', 'exp', 'Ġ[', 'Ġind', 'C', 'Ġ,', 'Ġind', 'h', 'Ġ,', 'Ġind', 'w', 'Ġ,', 'Ġc', 'nt', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġin', 'p', '_', 'check', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['out_exp', 'Ġ[', 'ĠindC', 'Ġ,', 'Ġindh', 'Ġ,', 'Ġindw', 'Ġ,', 'Ġcnt', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġinp_check', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "NervanaObject . be . bsz = batch_size \n"
Original    (008): ['NervanaObject', '.', 'be', '.', 'bsz', '=', 'batch_size', '\\n']
Tokenized   (018): ['<s>', 'N', 'erv', 'ana', 'Object', 'Ġ.', 'Ġbe', 'Ġ.', 'Ġb', 's', 'z', 'Ġ=', 'Ġbatch', '_', 'size', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['N', 'erv', 'ana', 'Object', 'Ġ.', 'Ġbe', 'Ġ.', 'Ġb', 's', 'z', 'Ġ=', 'Ġbatch', '_', 'size', 'Ġ\\', 'n']
Detokenized (008): ['NervanaObject', 'Ġ.', 'Ġbe', 'Ġ.', 'Ġbsz', 'Ġ=', 'Ġbatch_size', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "inshape = ( nifm , in_sz , in_sz ) \n"
Original    (010): ['inshape', '=', '(', 'nifm', ',', 'in_sz', ',', 'in_sz', ')', '\\n']
Tokenized   (023): ['<s>', 'ins', 'h', 'ape', 'Ġ=', 'Ġ(', 'Ġn', 'if', 'm', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['ins', 'h', 'ape', 'Ġ=', 'Ġ(', 'Ġn', 'if', 'm', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['inshape', 'Ġ=', 'Ġ(', 'Ġnifm', 'Ġ,', 'Ġin_sz', 'Ġ,', 'Ġin_sz', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "src = "img/file-icon.jpg" , ** kw ) ] \n"
Original    (009): ['src', '=', '"img/file-icon.jpg"', ',', '**', 'kw', ')', ']', '\\n']
Tokenized   (021): ['<s>', 'src', 'Ġ=', 'Ġ"', 'img', '/', 'file', '-', 'icon', '.', 'jpg', '"', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['src', 'Ġ=', 'Ġ"', 'img', '/', 'file', '-', 'icon', '.', 'jpg', '"', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['src', 'Ġ=', 'Ġ"img/file-icon.jpg"', 'Ġ,', 'Ġ**', 'Ġkw', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "render = lambda r : r . div ( comp . render ( r , model = None ) , r . script ( component_to_update = + self . comp_id , \n"
Original    (032): ['render', '=', 'lambda', 'r', ':', 'r', '.', 'div', '(', 'comp', '.', 'render', '(', 'r', ',', 'model', '=', 'None', ')', ',', 'r', '.', 'script', '(', 'component_to_update', '=', '+', 'self', '.', 'comp_id', ',', '\\n']
Tokenized   (041): ['<s>', 'render', 'Ġ=', 'Ġlambda', 'Ġr', 'Ġ:', 'Ġr', 'Ġ.', 'Ġdiv', 'Ġ(', 'Ġcomp', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġr', 'Ġ,', 'Ġmodel', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġr', 'Ġ.', 'Ġscript', 'Ġ(', 'Ġcomponent', '_', 'to', '_', 'update', 'Ġ=', 'Ġ+', 'Ġself', 'Ġ.', 'Ġcomp', '_', 'id', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['render', 'Ġ=', 'Ġlambda', 'Ġr', 'Ġ:', 'Ġr', 'Ġ.', 'Ġdiv', 'Ġ(', 'Ġcomp', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġr', 'Ġ,', 'Ġmodel', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġr', 'Ġ.', 'Ġscript', 'Ġ(', 'Ġcomponent', '_', 'to', '_', 'update', 'Ġ=', 'Ġ+', 'Ġself', 'Ġ.', 'Ġcomp', '_', 'id', 'Ġ,', 'Ġ\\', 'n']
Detokenized (032): ['render', 'Ġ=', 'Ġlambda', 'Ġr', 'Ġ:', 'Ġr', 'Ġ.', 'Ġdiv', 'Ġ(', 'Ġcomp', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġr', 'Ġ,', 'Ġmodel', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġr', 'Ġ.', 'Ġscript', 'Ġ(', 'Ġcomponent_to_update', 'Ġ=', 'Ġ+', 'Ġself', 'Ġ.', 'Ġcomp_id', 'Ġ,', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "ajax . py2js ( self . crop_height ( ) ) \n"
Original    (011): ['ajax', '.', 'py2js', '(', 'self', '.', 'crop_height', '(', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'aj', 'ax', 'Ġ.', 'Ġpy', '2', 'js', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcrop', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['aj', 'ax', 'Ġ.', 'Ġpy', '2', 'js', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcrop', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['ajax', 'Ġ.', 'Ġpy2js', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcrop_height', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "local_handler = getattr ( self , , None ) \n"
Original    (010): ['local_handler', '=', 'getattr', '(', 'self', ',', ',', 'None', ')', '\\n']
Tokenized   (016): ['<s>', 'local', '_', 'handler', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['local', '_', 'handler', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['local_handler', 'Ġ=', 'Ġgetattr', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "genie2 . client . wrapper . RetryPolicy ( \n"
Original    (009): ['genie2', '.', 'client', '.', 'wrapper', '.', 'RetryPolicy', '(', '\\n']
Tokenized   (016): ['<s>', 'gen', 'ie', '2', 'Ġ.', 'Ġclient', 'Ġ.', 'Ġwrapper', 'Ġ.', 'ĠRet', 'ry', 'Policy', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['gen', 'ie', '2', 'Ġ.', 'Ġclient', 'Ġ.', 'Ġwrapper', 'Ġ.', 'ĠRet', 'ry', 'Policy', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['genie2', 'Ġ.', 'Ġclient', 'Ġ.', 'Ġwrapper', 'Ġ.', 'ĠRetryPolicy', 'Ġ(', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "tries = 8 , none_on_404 = True , no_retry_http_codes = range ( 400 , 500 ) ) \n"
Original    (018): ['tries', '=', '8', ',', 'none_on_404', '=', 'True', ',', 'no_retry_http_codes', '=', 'range', '(', '400', ',', '500', ')', ')', '\\n']
Tokenized   (033): ['<s>', 't', 'ries', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġnone', '_', 'on', '_', '404', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġno', '_', 'ret', 'ry', '_', 'http', '_', 'codes', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ400', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['t', 'ries', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġnone', '_', 'on', '_', '404', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġno', '_', 'ret', 'ry', '_', 'http', '_', 'codes', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ400', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['tries', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġnone_on_404', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġno_retry_http_codes', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ400', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "tagging . add_argument ( , , dest = , action = conf_action ( context . ami ) , help = \n"
Original    (021): ['tagging', '.', 'add_argument', '(', ',', ',', 'dest', '=', ',', 'action', '=', 'conf_action', '(', 'context', '.', 'ami', ')', ',', 'help', '=', '\\n']
Tokenized   (030): ['<s>', 'tag', 'ging', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġconf', '_', 'action', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġam', 'i', 'Ġ)', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['tag', 'ging', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġconf', '_', 'action', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġam', 'i', 'Ġ)', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ\\', 'n']
Detokenized (021): ['tagging', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġconf_action', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġami', 'Ġ)', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "BASE_URL = . format ( FQDN ) \n"
Original    (008): ['BASE_URL', '=', '.', 'format', '(', 'FQDN', ')', '\\n']
Tokenized   (016): ['<s>', 'B', 'ASE', '_', 'URL', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠF', 'Q', 'DN', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['B', 'ASE', '_', 'URL', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠF', 'Q', 'DN', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['BASE_URL', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠFQDN', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test" , config ElasticSearchServiceItem ( region = "us-west-2" , account = "TEST_ACCOUNT" , name = "es_test_2" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_3" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_4" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_5" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_6" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_7" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_8" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_9" , config ] \n"
Original    (137): ['ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-west-2"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_2"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_3"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_4"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_5"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_6"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_7"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_8"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_9"', ',', 'config', ']', '\\n']
Tokenized   (328): ['<s>', 'El', 'astic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'west', '-', '2', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '2', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '3', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '4', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '5', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '6', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '7', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '8', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '9', '"', 'Ġ,', 'Ġconfig', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (326): ['El', 'astic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'west', '-', '2', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '2', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '3', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '4', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '5', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '6', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '7', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '8', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '9', '"', 'Ġ,', 'Ġconfig', 'Ġ]', 'Ġ\\', 'n']
Detokenized (137): ['ElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-west-2"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_2"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_3"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_4"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_5"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_6"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_7"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_8"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_9"', 'Ġ,', 'Ġconfig', 'Ġ]', 'Ġ\\n']
Counter: 326
===================================================================
Hidden states:  (13, 137, 768)
# Extracted words:  137
Sentence         : "test_account . role_name = "TEST_ACCOUNT" \n"
Original    (006): ['test_account', '.', 'role_name', '=', '"TEST_ACCOUNT"', '\\n']
Tokenized   (019): ['<s>', 'test', '_', 'account', 'Ġ.', 'Ġrole', '_', 'name', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['test', '_', 'account', 'Ġ.', 'Ġrole', '_', 'name', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ\\', 'n']
Detokenized (006): ['test_account', 'Ġ.', 'Ġrole_name', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "all_clusters . extend ( response [ ] [ if response [ ] [ ] [ ] ~~~ marker = response [ ] [ ] [ ~~ else : \n"
Original    (029): ['all_clusters', '.', 'extend', '(', 'response', '[', ']', '[', 'if', 'response', '[', ']', '[', ']', '[', ']', '~~~', 'marker', '=', 'response', '[', ']', '[', ']', '[', '~~', 'else', ':', '\\n']
Tokenized   (038): ['<s>', 'all', '_', 'cl', 'usters', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġif', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ', '~~', '~', 'Ġmarker', 'Ġ=', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['all', '_', 'cl', 'usters', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġif', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ', '~~', '~', 'Ġmarker', 'Ġ=', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n']
Detokenized (029): ['all_clusters', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġif', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ~~~', 'Ġmarker', 'Ġ=', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ~~', 'Ġelse', 'Ġ:', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "_container_child_objects = ( , ) \n"
Original    (006): ['_container_child_objects', '=', '(', ',', ')', '\\n']
Tokenized   (014): ['<s>', '_', 'container', '_', 'child', '_', 'objects', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['_', 'container', '_', 'child', '_', 'objects', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['_container_child_objects', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_recommended_attrs = ( ( ( , np . ndarray , 1 , np . dtype ( ) ) , \n"
Original    (020): ['_recommended_attrs', '=', '(', '(', '(', ',', 'np', '.', 'ndarray', ',', '1', ',', 'np', '.', 'dtype', '(', ')', ')', ',', '\\n']
Tokenized   (031): ['<s>', '_', 'recomm', 'ended', '_', 'att', 'rs', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġn', 'd', 'array', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġd', 'type', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['_', 'recomm', 'ended', '_', 'att', 'rs', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġn', 'd', 'array', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġd', 'type', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['_recommended_attrs', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġndarray', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġdtype', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "errstr = . format ( errno , pszMsgBuffer . value ) \n"
Original    (012): ['errstr', '=', '.', 'format', '(', 'errno', ',', 'pszMsgBuffer', '.', 'value', ')', '\\n']
Tokenized   (020): ['<s>', 'err', 'str', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġerr', 'no', 'Ġ,', 'Ġps', 'z', 'Msg', 'Buffer', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['err', 'str', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġerr', 'no', 'Ġ,', 'Ġps', 'z', 'Msg', 'Buffer', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['errstr', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġerrno', 'Ġ,', 'ĠpszMsgBuffer', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "supported_objects = [ Segment , AnalogSignal , EventArray , SpikeTrain ] \n"
Original    (012): ['supported_objects', '=', '[', 'Segment', ',', 'AnalogSignal', ',', 'EventArray', ',', 'SpikeTrain', ']', '\\n']
Tokenized   (022): ['<s>', 'supported', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ,', 'ĠAnalog', 'Sign', 'al', 'Ġ,', 'ĠEvent', 'Array', 'Ġ,', 'ĠSpike', 'Train', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['supported', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ,', 'ĠAnalog', 'Sign', 'al', 'Ġ,', 'ĠEvent', 'Array', 'Ġ,', 'ĠSpike', 'Train', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['supported_objects', 'Ġ=', 'Ġ[', 'ĠSegment', 'Ġ,', 'ĠAnalogSignal', 'Ġ,', 'ĠEventArray', 'Ġ,', 'ĠSpikeTrain', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "readable_objects = [ Segment ] \n"
Original    (006): ['readable_objects', '=', '[', 'Segment', ']', '\\n']
Tokenized   (012): ['<s>', 'readable', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['readable', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['readable_objects', 'Ġ=', 'Ġ[', 'ĠSegment', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "read_params = { Segment : [ ] } \n"
Original    (009): ['read_params', '=', '{', 'Segment', ':', '[', ']', '}', '\\n']
Tokenized   (015): ['<s>', 'read', '_', 'params', 'Ġ=', 'Ġ{', 'ĠSe', 'gment', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['read', '_', 'params', 'Ġ=', 'Ġ{', 'ĠSe', 'gment', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ\\', 'n']
Detokenized (009): ['read_params', 'Ġ=', 'Ġ{', 'ĠSegment', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "labels . append ( str ( pData . value ) ) \n"
Original    (012): ['labels', '.', 'append', '(', 'str', '(', 'pData', '.', 'value', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'lab', 'els', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġp', 'Data', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['lab', 'els', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġp', 'Data', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['labels', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠpData', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ea . labels = np . array ( labels , dtype = ) \n"
Original    (014): ['ea', '.', 'labels', '=', 'np', '.', 'array', '(', 'labels', ',', 'dtype', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'ea', 'Ġ.', 'Ġlabels', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġlabels', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['ea', 'Ġ.', 'Ġlabels', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġlabels', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['ea', 'Ġ.', 'Ġlabels', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġlabels', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dwStopIndex , ctypes . byref ( pdwContCount ) , pData [ total_read : ] . ctypes total_read += pdwContCount . value \n"
Original    (022): ['dwStopIndex', ',', 'ctypes', '.', 'byref', '(', 'pdwContCount', ')', ',', 'pData', '[', 'total_read', ':', ']', '.', 'ctypes', 'total_read', '+=', 'pdwContCount', '.', 'value', '\\n']
Tokenized   (044): ['<s>', 'd', 'w', 'Stop', 'Index', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ)', 'Ġ,', 'Ġp', 'Data', 'Ġ[', 'Ġtotal', '_', 'read', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġc', 'types', 'Ġtotal', '_', 'read', 'Ġ+=', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ.', 'Ġvalue', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['d', 'w', 'Stop', 'Index', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ)', 'Ġ,', 'Ġp', 'Data', 'Ġ[', 'Ġtotal', '_', 'read', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġc', 'types', 'Ġtotal', '_', 'read', 'Ġ+=', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ.', 'Ġvalue', 'Ġ\\', 'n']
Detokenized (022): ['dwStopIndex', 'Ġ,', 'Ġctypes', 'Ġ.', 'Ġbyref', 'Ġ(', 'ĠpdwContCount', 'Ġ)', 'Ġ,', 'ĠpData', 'Ġ[', 'Ġtotal_read', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġctypes', 'Ġtotal_read', 'Ġ+=', 'ĠpdwContCount', 'Ġ.', 'Ġvalue', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "anaSig . annotate ( probe_info = str ( pAnalogInfo . szProbeInfo ) ) \n"
Original    (014): ['anaSig', '.', 'annotate', '(', 'probe_info', '=', 'str', '(', 'pAnalogInfo', '.', 'szProbeInfo', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'ana', 'S', 'ig', 'Ġ.', 'Ġannot', 'ate', 'Ġ(', 'Ġprobe', '_', 'info', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'An', 'alog', 'Info', 'Ġ.', 'Ġs', 'z', 'Pro', 'be', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['ana', 'S', 'ig', 'Ġ.', 'Ġannot', 'ate', 'Ġ(', 'Ġprobe', '_', 'info', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'An', 'alog', 'Info', 'Ġ.', 'Ġs', 'z', 'Pro', 'be', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['anaSig', 'Ġ.', 'Ġannotate', 'Ġ(', 'Ġprobe_info', 'Ġ=', 'Ġstr', 'Ġ(', 'ĠpAnalogInfo', 'Ġ.', 'ĠszProbeInfo', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pData = np . zeros ( ( dwDataBufferSize ) , dtype = ) \n"
Original    (014): ['pData', '=', 'np', '.', 'zeros', '(', '(', 'dwDataBufferSize', ')', ',', 'dtype', '=', ')', '\\n']
Tokenized   (023): ['<s>', 'p', 'Data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġ(', 'Ġdw', 'Data', 'Buffer', 'Size', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['p', 'Data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġ(', 'Ġdw', 'Data', 'Buffer', 'Size', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['pData', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġzeros', 'Ġ(', 'Ġ(', 'ĠdwDataBufferSize', 'Ġ)', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "waveforms = pq . Quantity ( waveforms , units = str ( pdwSegmentInfo left_sweep = nsample / 2. / float ( pdwSegmentInfo . dSampleRate ) * pq sampling_rate = float ( pdwSegmentInfo . dSampleRate ) * pq . Hz , \n"
Original    (041): ['waveforms', '=', 'pq', '.', 'Quantity', '(', 'waveforms', ',', 'units', '=', 'str', '(', 'pdwSegmentInfo', 'left_sweep', '=', 'nsample', '/', '2.', '/', 'float', '(', 'pdwSegmentInfo', '.', 'dSampleRate', ')', '*', 'pq', 'sampling_rate', '=', 'float', '(', 'pdwSegmentInfo', '.', 'dSampleRate', ')', '*', 'pq', '.', 'Hz', ',', '\\n']
Tokenized   (075): ['<s>', 'wave', 'forms', 'Ġ=', 'Ġp', 'q', 'Ġ.', 'ĠQuantity', 'Ġ(', 'Ġwave', 'forms', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġleft', '_', 'swe', 'ep', 'Ġ=', 'Ġns', 'ample', 'Ġ/', 'Ġ2', '.', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġsampling', '_', 'rate', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (073): ['wave', 'forms', 'Ġ=', 'Ġp', 'q', 'Ġ.', 'ĠQuantity', 'Ġ(', 'Ġwave', 'forms', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġleft', '_', 'swe', 'ep', 'Ġ=', 'Ġns', 'ample', 'Ġ/', 'Ġ2', '.', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġsampling', '_', 'rate', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n']
Detokenized (041): ['waveforms', 'Ġ=', 'Ġpq', 'Ġ.', 'ĠQuantity', 'Ġ(', 'Ġwaveforms', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġstr', 'Ġ(', 'ĠpdwSegmentInfo', 'Ġleft_sweep', 'Ġ=', 'Ġnsample', 'Ġ/', 'Ġ2.', 'Ġ/', 'Ġfloat', 'Ġ(', 'ĠpdwSegmentInfo', 'Ġ.', 'ĠdSampleRate', 'Ġ)', 'Ġ*', 'Ġpq', 'Ġsampling_rate', 'Ġ=', 'Ġfloat', 'Ġ(', 'ĠpdwSegmentInfo', 'Ġ.', 'ĠdSampleRate', 'Ġ)', 'Ġ*', 'Ġpq', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\n']
Counter: 73
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "ctypes . byref ( pNeuralInfo ) , ctypes . sizeof ( pNeuralInfo ) ) \n"
Original    (015): ['ctypes', '.', 'byref', '(', 'pNeuralInfo', ')', ',', 'ctypes', '.', 'sizeof', '(', 'pNeuralInfo', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'ct', 'ypes', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġsizeof', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['ct', 'ypes', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġsizeof', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['ctypes', 'Ġ.', 'Ġbyref', 'Ġ(', 'ĠpNeuralInfo', 'Ġ)', 'Ġ,', 'Ġctypes', 'Ġ.', 'Ġsizeof', 'Ġ(', 'ĠpNeuralInfo', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "neuroshare . ns_GetNeuralData ( hFile , dwEntityID , dwStartIndex , \n"
Original    (011): ['neuroshare', '.', 'ns_GetNeuralData', '(', 'hFile', ',', 'dwEntityID', ',', 'dwStartIndex', ',', '\\n']
Tokenized   (026): ['<s>', 'ne', 'uro', 'share', 'Ġ.', 'Ġns', '_', 'Get', 'Ne', 'ural', 'Data', 'Ġ(', 'Ġh', 'File', 'Ġ,', 'Ġdw', 'Entity', 'ID', 'Ġ,', 'Ġdw', 'Start', 'Index', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['ne', 'uro', 'share', 'Ġ.', 'Ġns', '_', 'Get', 'Ne', 'ural', 'Data', 'Ġ(', 'Ġh', 'File', 'Ġ,', 'Ġdw', 'Entity', 'ID', 'Ġ,', 'Ġdw', 'Start', 'Index', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['neuroshare', 'Ġ.', 'Ġns_GetNeuralData', 'Ġ(', 'ĠhFile', 'Ġ,', 'ĠdwEntityID', 'Ġ,', 'ĠdwStartIndex', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dwIndexCount , pData . ctypes . data_as ( ctypes . POINTER ( ctypes . c_double ) ) ) \n"
Original    (019): ['dwIndexCount', ',', 'pData', '.', 'ctypes', '.', 'data_as', '(', 'ctypes', '.', 'POINTER', '(', 'ctypes', '.', 'c_double', ')', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'd', 'w', 'Index', 'Count', 'Ġ,', 'Ġp', 'Data', 'Ġ.', 'Ġc', 'types', 'Ġ.', 'Ġdata', '_', 'as', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'ĠPO', 'INTER', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'Ġc', '_', 'double', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['d', 'w', 'Index', 'Count', 'Ġ,', 'Ġp', 'Data', 'Ġ.', 'Ġc', 'types', 'Ġ.', 'Ġdata', '_', 'as', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'ĠPO', 'INTER', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'Ġc', '_', 'double', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['dwIndexCount', 'Ġ,', 'ĠpData', 'Ġ.', 'Ġctypes', 'Ġ.', 'Ġdata_as', 'Ġ(', 'Ġctypes', 'Ġ.', 'ĠPOINTER', 'Ġ(', 'Ġctypes', 'Ġ.', 'Ġc_double', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "times = pData * pq . s \n"
Original    (008): ['times', '=', 'pData', '*', 'pq', '.', 's', '\\n']
Tokenized   (013): ['<s>', 'times', 'Ġ=', 'Ġp', 'Data', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'Ġs', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['times', 'Ġ=', 'Ġp', 'Data', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'Ġs', 'Ġ\\', 'n']
Detokenized (008): ['times', 'Ġ=', 'ĠpData', 'Ġ*', 'Ġpq', 'Ġ.', 'Ġs', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "clone_object , TEST_ANNOTATIONS ) \n"
Original    (005): ['clone_object', ',', 'TEST_ANNOTATIONS', ')', '\\n']
Tokenized   (014): ['<s>', 'clone', '_', 'object', 'Ġ,', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['clone', '_', 'object', 'Ġ,', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['clone_object', 'Ġ,', 'ĠTEST_ANNOTATIONS', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "range ( len ( TEST_ANNOTATIONS ) ) ] ) \n"
Original    (010): ['range', '(', 'len', '(', 'TEST_ANNOTATIONS', ')', ')', ']', ')', '\\n']
Tokenized   (017): ['<s>', 'range', 'Ġ(', 'Ġlen', 'Ġ(', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['range', 'Ġ(', 'Ġlen', 'Ġ(', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['range', 'Ġ(', 'Ġlen', 'Ġ(', 'ĠTEST_ANNOTATIONS', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "file_datetime = get_fake_value ( , datetime , seed = 0 ) \n"
Original    (012): ['file_datetime', '=', 'get_fake_value', '(', ',', 'datetime', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (023): ['<s>', 'file', '_', 'dat', 'etime', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['file', '_', 'dat', 'etime', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['file_datetime', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġdatetime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "file_origin = get_fake_value ( , str ) \n"
Original    (008): ['file_origin', '=', 'get_fake_value', '(', ',', 'str', ')', '\\n']
Tokenized   (017): ['<s>', 'file', '_', 'origin', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['file', '_', 'origin', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['file_origin', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "attrs1 = { : file_datetime , \n"
Original    (007): ['attrs1', '=', '{', ':', 'file_datetime', ',', '\\n']
Tokenized   (015): ['<s>', 'att', 'rs', '1', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġfile', '_', 'dat', 'etime', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['att', 'rs', '1', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġfile', '_', 'dat', 'etime', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['attrs1', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġfile_datetime', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "res21 = get_fake_values ( Segment , annotate = True , seed = 0 ) \n"
Original    (015): ['res21', '=', 'get_fake_values', '(', 'Segment', ',', 'annotate', '=', 'True', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (025): ['<s>', 'res', '21', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'ĠSe', 'gment', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['res', '21', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'ĠSe', 'gment', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['res21', 'Ġ=', 'Ġget_fake_values', 'Ġ(', 'ĠSegment', 'Ġ,', 'Ġannotate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "res22 = get_fake_values ( , annotate = True , seed = 0 ) \n"
Original    (014): ['res22', '=', 'get_fake_values', '(', ',', 'annotate', '=', 'True', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (023): ['<s>', 'res', '22', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['res', '22', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['res22', 'Ġ=', 'Ġget_fake_values', 'Ġ(', 'Ġ,', 'Ġannotate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "targ0 = get_fake_value ( , datetime , seed = seed + 0 ) \n"
Original    (014): ['targ0', '=', 'get_fake_value', '(', ',', 'datetime', ',', 'seed', '=', 'seed', '+', '0', ')', '\\n']
Tokenized   (024): ['<s>', 't', 'arg', '0', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', 'arg', '0', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['targ0', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġdatetime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "targ4 = get_fake_value ( , str , \n"
Original    (008): ['targ4', '=', 'get_fake_value', '(', ',', 'str', ',', '\\n']
Tokenized   (017): ['<s>', 't', 'arg', '4', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['t', 'arg', '4', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['targ4', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "seed = seed + 4 , obj = Segment ) \n"
Original    (011): ['seed', '=', 'seed', '+', '4', ',', 'obj', '=', 'Segment', ')', '\\n']
Tokenized   (015): ['<s>', 'seed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ4', 'Ġ,', 'Ġobj', 'Ġ=', 'ĠSe', 'gment', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['seed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ4', 'Ġ,', 'Ġobj', 'Ġ=', 'ĠSe', 'gment', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['seed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ4', 'Ġ,', 'Ġobj', 'Ġ=', 'ĠSegment', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "childobjs = ( , , \n"
Original    (006): ['childobjs', '=', '(', ',', ',', '\\n']
Tokenized   (011): ['<s>', 'child', 'ob', 'js', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['child', 'ob', 'js', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['childobjs', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "children = ( self . sigs1a + self . sigarrs1a + \n"
Original    (012): ['children', '=', '(', 'self', '.', 'sigs1a', '+', 'self', '.', 'sigarrs1a', '+', '\\n']
Tokenized   (022): ['<s>', 'children', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġs', 'igs', '1', 'a', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['children', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġs', 'igs', '1', 'a', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ+', 'Ġ\\', 'n']
Detokenized (012): ['children', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsigs1a', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsigarrs1a', 'Ġ+', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""analogsignals" : self . nchildren ** 2 , \n"
Original    (009): ['"analogsignals"', ':', 'self', '.', 'nchildren', '**', '2', ',', '\\n']
Tokenized   (018): ['<s>', '"', 'an', 'alog', 'sign', 'als', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ**', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'an', 'alog', 'sign', 'als', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ**', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"analogsignals"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ**', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""epocharrays" : self . nchildren , "eventarrays" : self . nchildren , \n"
Original    (013): ['"epocharrays"', ':', 'self', '.', 'nchildren', ',', '"eventarrays"', ':', 'self', '.', 'nchildren', ',', '\\n']
Tokenized   (027): ['<s>', '"', 'ep', 'och', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ"', 'event', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['"', 'ep', 'och', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ"', 'event', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['"epocharrays"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ,', 'Ġ"eventarrays"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ,', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : ""analogsignalarrays" : self . nchildren } \n"
Original    (007): ['"analogsignalarrays"', ':', 'self', '.', 'nchildren', '}', '\\n']
Tokenized   (018): ['<s>', '"', 'an', 'alog', 'sign', 'al', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'an', 'alog', 'sign', 'al', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['"analogsignalarrays"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ}', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "targdict = { : 5 } ) \n"
Original    (008): ['targdict', '=', '{', ':', '5', '}', ')', '\\n']
Tokenized   (013): ['<s>', 't', 'arg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['t', 'arg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['targdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "res6 = filterdata ( data , name = self . epcs2 [ 0 ] . name , j = 5 ) \n"
Original    (022): ['res6', '=', 'filterdata', '(', 'data', ',', 'name', '=', 'self', '.', 'epcs2', '[', '0', ']', '.', 'name', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (029): ['<s>', 'res', '6', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['res', '6', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['res6', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "res7 = filterdata ( data , { : self . epcs2 [ 1 ] . name , : 5 } ) \n"
Original    (022): ['res7', '=', 'filterdata', '(', 'data', ',', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Tokenized   (029): ['<s>', 'res', '7', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['res', '7', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['res7', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "res8 = filterdata ( data , targdict = { : self . epcs2 [ 1 ] . name , : 5 } ) \n"
Original    (024): ['res8', '=', 'filterdata', '(', 'data', ',', 'targdict', '=', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Tokenized   (032): ['<s>', 'res', '8', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['res', '8', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['res8', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtargdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "res9 = filterdata ( data , { : self . epcs2 [ 1 ] . name } , j = 5 ) \n"
Original    (023): ['res9', '=', 'filterdata', '(', 'data', ',', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (030): ['<s>', 'res', '9', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['res', '9', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['res9', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "res10 = filterdata ( data , targdict = { : self . epcs2 [ 1 ] . name } , j = 5 ) \n"
Original    (025): ['res10', '=', 'filterdata', '(', 'data', ',', 'targdict', '=', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (033): ['<s>', 'res', '10', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['res', '10', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['res10', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtargdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "res11 = filterdata ( data , name = self . epcs2 [ 1 ] . name , targdict = { : 5 } ) \n"
Original    (025): ['res11', '=', 'filterdata', '(', 'data', ',', 'name', '=', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', 'targdict', '=', '{', ':', '5', '}', ')', '\\n']
Tokenized   (033): ['<s>', 'res', '11', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['res', '11', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['res11', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġtargdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "targ = [ self . epcs1a [ 1 ] ] \n"
Original    (011): ['targ', '=', '[', 'self', '.', 'epcs1a', '[', '1', ']', ']', '\\n']
Tokenized   (018): ['<s>', 't', 'arg', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġep', 'cs', '1', 'a', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['t', 'arg', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġep', 'cs', '1', 'a', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['targ', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġepcs1a', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "res3 = filterdata ( data , [ { : 1 } , { : 2 } ] ) \n"
Original    (019): ['res3', '=', 'filterdata', '(', 'data', ',', '[', '{', ':', '1', '}', ',', '{', ':', '2', '}', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'res', '3', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['res', '3', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['res3', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "res4 = filterdata ( data , { : 1 } , i = 2 ) \n"
Original    (016): ['res4', '=', 'filterdata', '(', 'data', ',', '{', ':', '1', '}', ',', 'i', '=', '2', ')', '\\n']
Tokenized   (021): ['<s>', 'res', '4', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['res', '4', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['res4', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "res5 = filterdata ( data , [ { : 1 } ] , i = 2 ) \n"
Original    (018): ['res5', '=', 'filterdata', '(', 'data', ',', '[', '{', ':', '1', '}', ']', ',', 'i', '=', '2', ')', '\\n']
Tokenized   (023): ['<s>', 'res', '5', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['res', '5', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['res5', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "ann = pretty ( ann ) . replace ( , ) \n"
Original    (012): ['ann', '=', 'pretty', '(', 'ann', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (015): ['<s>', 'ann', 'Ġ=', 'Ġpretty', 'Ġ(', 'Ġann', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ann', 'Ġ=', 'Ġpretty', 'Ġ(', 'Ġann', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['ann', 'Ġ=', 'Ġpretty', 'Ġ(', 'Ġann', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "unit_with_sig = np . array ( [ 0 , 2 , 5 ] ) \n"
Original    (015): ['unit_with_sig', '=', 'np', '.', 'array', '(', '[', '0', ',', '2', ',', '5', ']', ')', '\\n']
Tokenized   (023): ['<s>', 'unit', '_', 'with', '_', 's', 'ig', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ5', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['unit', '_', 'with', '_', 's', 'ig', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ5', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['unit_with_sig', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ5', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rcgs = [ RecordingChannelGroup ( name = , \n"
Original    (009): ['rcgs', '=', '[', 'RecordingChannelGroup', '(', 'name', '=', ',', '\\n']
Tokenized   (015): ['<s>', 'rc', 'gs', 'Ġ=', 'Ġ[', 'ĠRecording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['rc', 'gs', 'Ġ=', 'Ġ[', 'ĠRecording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['rcgs', 'Ġ=', 'Ġ[', 'ĠRecordingChannelGroup', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "RecordingChannelGroup ( name = , \n"
Original    (006): ['RecordingChannelGroup', '(', 'name', '=', ',', '\\n']
Tokenized   (012): ['<s>', 'Rec', 'ording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Rec', 'ording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['RecordingChannelGroup', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "t_start = 0. , t_stop = 10 ) \n"
Original    (009): ['t_start', '=', '0.', ',', 't_stop', '=', '10', ')', '\\n']
Tokenized   (017): ['<s>', 't', '_', 'start', 'Ġ=', 'Ġ0', '.', 'Ġ,', 'Ġt', '_', 'stop', 'Ġ=', 'Ġ10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['t', '_', 'start', 'Ġ=', 'Ġ0', '.', 'Ġ,', 'Ġt', '_', 'stop', 'Ġ=', 'Ġ10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['t_start', 'Ġ=', 'Ġ0.', 'Ġ,', 'Ġt_stop', 'Ġ=', 'Ġ10', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "st . unit = all_unit [ j ] \n"
Original    (009): ['st', '.', 'unit', '=', 'all_unit', '[', 'j', ']', '\\n']
Tokenized   (014): ['<s>', 'st', 'Ġ.', 'Ġunit', 'Ġ=', 'Ġall', '_', 'unit', 'Ġ[', 'Ġj', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['st', 'Ġ.', 'Ġunit', 'Ġ=', 'Ġall', '_', 'unit', 'Ġ[', 'Ġj', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['st', 'Ġ.', 'Ġunit', 'Ġ=', 'Ġall_unit', 'Ġ[', 'Ġj', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "sampling_rate = 1000. * pq . Hz , \n"
Original    (009): ['sampling_rate', '=', '1000.', '*', 'pq', '.', 'Hz', ',', '\\n']
Tokenized   (017): ['<s>', 'sam', 'pling', '_', 'rate', 'Ġ=', 'Ġ1000', '.', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['sam', 'pling', '_', 'rate', 'Ġ=', 'Ġ1000', '.', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['sampling_rate', 'Ġ=', 'Ġ1000.', 'Ġ*', 'Ġpq', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newseg = seg . construct_subsegment_by_unit ( all_unit [ : 4 ] ) \n"
Original    (013): ['newseg', '=', 'seg', '.', 'construct_subsegment_by_unit', '(', 'all_unit', '[', ':', '4', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'new', 'se', 'g', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġconstruct', '_', 'sub', 'se', 'gment', '_', 'by', '_', 'unit', 'Ġ(', 'Ġall', '_', 'unit', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['new', 'se', 'g', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġconstruct', '_', 'sub', 'se', 'gment', '_', 'by', '_', 'unit', 'Ġ(', 'Ġall', '_', 'unit', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['newseg', 'Ġ=', 'Ġseg', 'Ġ.', 'Ġconstruct_subsegment_by_unit', 'Ġ(', 'Ġall_unit', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ind2 = self . unit2 . channel_indexes [ 0 ] \n"
Original    (011): ['ind2', '=', 'self', '.', 'unit2', '.', 'channel_indexes', '[', '0', ']', '\\n']
Tokenized   (019): ['<s>', 'ind', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġunit', '2', 'Ġ.', 'Ġchannel', '_', 'index', 'es', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['ind', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġunit', '2', 'Ġ.', 'Ġchannel', '_', 'index', 'es', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['ind2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġunit2', 'Ġ.', 'Ġchannel_indexes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "result22 = self . seg1 . take_analogsignal_by_channelindex ( [ ind2 ] ) \n"
Original    (013): ['result22', '=', 'self', '.', 'seg1', '.', 'take_analogsignal_by_channelindex', '(', '[', 'ind2', ']', ')', '\\n']
Tokenized   (030): ['<s>', 'result', '22', 'Ġ=', 'Ġself', 'Ġ.', 'Ġse', 'g', '1', 'Ġ.', 'Ġtake', '_', 'an', 'alog', 'sign', 'al', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['result', '22', 'Ġ=', 'Ġself', 'Ġ.', 'Ġse', 'g', '1', 'Ġ.', 'Ġtake', '_', 'an', 'alog', 'sign', 'al', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['result22', 'Ġ=', 'Ġself', 'Ġ.', 'Ġseg1', 'Ġ.', 'Ġtake_analogsignal_by_channelindex', 'Ġ(', 'Ġ[', 'Ġind2', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "targ1 = [ self . sigarrs1a [ 0 ] [ : , np . array ( [ True ] ) ] , \n"
Original    (023): ['targ1', '=', '[', 'self', '.', 'sigarrs1a', '[', '0', ']', '[', ':', ',', 'np', '.', 'array', '(', '[', 'True', ']', ')', ']', ',', '\\n']
Tokenized   (032): ['<s>', 't', 'arg', '1', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'ĠTrue', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['t', 'arg', '1', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'ĠTrue', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (023): ['targ1', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġsigarrs1a', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'ĠTrue', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "result21 = seg . take_slice_of_analogsignalarray_by_channelindex ( [ ind1 ] ) \n"
Original    (011): ['result21', '=', 'seg', '.', 'take_slice_of_analogsignalarray_by_channelindex', '(', '[', 'ind1', ']', ')', '\\n']
Tokenized   (032): ['<s>', 'result', '21', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġtake', '_', 'slice', '_', 'of', '_', 'an', 'alog', 'sign', 'al', 'array', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['result', '21', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġtake', '_', 'slice', '_', 'of', '_', 'an', 'alog', 'sign', 'al', 'array', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['result21', 'Ġ=', 'Ġseg', 'Ġ.', 'Ġtake_slice_of_analogsignalarray_by_channelindex', 'Ġ(', 'Ġ[', 'Ġind1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "json_content = json_content . decode ( "utf-8" ) . replace ( , ) \n"
Original    (014): ['json_content', '=', 'json_content', '.', 'decode', '(', '"utf-8"', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (025): ['<s>', 'json', '_', 'content', 'Ġ=', 'Ġjson', '_', 'content', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['json', '_', 'content', 'Ġ=', 'Ġjson', '_', 'content', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['json_content', 'Ġ=', 'Ġjson_content', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"utf-8"', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "Image1 = StatisticMap ( name = , collection = self . Collection1 , file = , Image1 . file = SimpleUploadedFile ( , file ( os . path . join ( self . test_path , Image1 . save ( ) \n"
Original    (041): ['Image1', '=', 'StatisticMap', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'Collection1', ',', 'file', '=', ',', 'Image1', '.', 'file', '=', 'SimpleUploadedFile', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'Image1', '.', 'save', '(', ')', '\\n']
Tokenized   (055): ['<s>', 'Image', '1', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '1', 'Ġ,', 'Ġfile', 'Ġ=', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (053): ['Image', '1', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '1', 'Ġ,', 'Ġfile', 'Ġ=', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (041): ['Image1', 'Ġ=', 'ĠStatisticMap', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection1', 'Ġ,', 'Ġfile', 'Ġ=', 'Ġ,', 'ĠImage1', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimpleUploadedFile', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest_path', 'Ġ,', 'ĠImage1', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 53
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "fname = os . path . basename ( os . path . join ( self . test_path , ) ) file_dict = { : SimpleUploadedFile ( fname , zip_file . read ( ) ) } \n"
Original    (036): ['fname', '=', 'os', '.', 'path', '.', 'basename', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', ')', ')', 'file_dict', '=', '{', ':', 'SimpleUploadedFile', '(', 'fname', ',', 'zip_file', '.', 'read', '(', ')', ')', '}', '\\n']
Tokenized   (051): ['<s>', 'f', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġbas', 'ename', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġfile', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġf', 'name', 'Ġ,', 'Ġzip', '_', 'file', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (049): ['f', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġbas', 'ename', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġfile', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġf', 'name', 'Ġ,', 'Ġzip', '_', 'file', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (036): ['fname', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġbasename', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest_path', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġfile_dict', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠSimpleUploadedFile', 'Ġ(', 'Ġfname', 'Ġ,', 'Ġzip_file', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 49
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "Image2ss = StatisticMap ( name = , collection = self . Collection3 , file = Image2ss . file = SimpleUploadedFile ( , file ( os . path . join ( self . test_path , Image2ss . save ( ) \n"
Original    (040): ['Image2ss', '=', 'StatisticMap', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'Collection3', ',', 'file', '=', 'Image2ss', '.', 'file', '=', 'SimpleUploadedFile', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'Image2ss', '.', 'save', '(', ')', '\\n']
Tokenized   (057): ['<s>', 'Image', '2', 'ss', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '3', 'Ġ,', 'Ġfile', 'Ġ=', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (055): ['Image', '2', 'ss', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '3', 'Ġ,', 'Ġfile', 'Ġ=', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (040): ['Image2ss', 'Ġ=', 'ĠStatisticMap', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection3', 'Ġ,', 'Ġfile', 'Ġ=', 'ĠImage2ss', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimpleUploadedFile', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest_path', 'Ġ,', 'ĠImage2ss', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 55
===================================================================
Hidden states:  (13, 40, 768)
# Extracted words:  40
Sentence         : "acc_new = rho * acc + ( 1 - rho ) * g ** 2 \n"
Original    (016): ['acc_new', '=', 'rho', '*', 'acc', '+', '(', '1', '-', 'rho', ')', '*', 'g', '**', '2', '\\n']
Tokenized   (023): ['<s>', 'acc', '_', 'new', 'Ġ=', 'Ġr', 'ho', 'Ġ*', 'Ġacc', 'Ġ+', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġr', 'ho', 'Ġ)', 'Ġ*', 'Ġg', 'Ġ**', 'Ġ2', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['acc', '_', 'new', 'Ġ=', 'Ġr', 'ho', 'Ġ*', 'Ġacc', 'Ġ+', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġr', 'ho', 'Ġ)', 'Ġ*', 'Ġg', 'Ġ**', 'Ġ2', 'Ġ\\', 'n']
Detokenized (016): ['acc_new', 'Ġ=', 'Ġrho', 'Ġ*', 'Ġacc', 'Ġ+', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġrho', 'Ġ)', 'Ġ*', 'Ġg', 'Ġ**', 'Ġ2', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "gradient_scaling = T . sqrt ( acc_new + epsilon ) \n"
Original    (011): ['gradient_scaling', '=', 'T', '.', 'sqrt', '(', 'acc_new', '+', 'epsilon', ')', '\\n']
Tokenized   (022): ['<s>', 'gradient', '_', 'sc', 'aling', 'Ġ=', 'ĠT', 'Ġ.', 'Ġsq', 'rt', 'Ġ(', 'Ġacc', '_', 'new', 'Ġ+', 'Ġe', 'ps', 'ilon', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['gradient', '_', 'sc', 'aling', 'Ġ=', 'ĠT', 'Ġ.', 'Ġsq', 'rt', 'Ġ(', 'Ġacc', '_', 'new', 'Ġ+', 'Ġe', 'ps', 'ilon', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['gradient_scaling', 'Ġ=', 'ĠT', 'Ġ.', 'Ġsqrt', 'Ġ(', 'Ġacc_new', 'Ġ+', 'Ġepsilon', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "py_x = softmax ( T . dot ( h2 , w_o ) ) \n"
Original    (014): ['py_x', '=', 'softmax', '(', 'T', '.', 'dot', '(', 'h2', ',', 'w_o', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'py', '_', 'x', 'Ġ=', 'Ġsoft', 'max', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['py', '_', 'x', 'Ġ=', 'Ġsoft', 'max', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['py_x', 'Ġ=', 'Ġsoftmax', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh2', 'Ġ,', 'Ġw_o', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "w_h = init_weights ( ( 784 , 625 ) ) \n"
Original    (011): ['w_h', '=', 'init_weights', '(', '(', '784', ',', '625', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'w', '_', 'h', 'Ġ=', 'Ġinit', '_', 'weights', 'Ġ(', 'Ġ(', 'Ġ7', '84', 'Ġ,', 'Ġ625', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['w', '_', 'h', 'Ġ=', 'Ġinit', '_', 'weights', 'Ġ(', 'Ġ(', 'Ġ7', '84', 'Ġ,', 'Ġ625', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['w_h', 'Ġ=', 'Ġinit_weights', 'Ġ(', 'Ġ(', 'Ġ784', 'Ġ,', 'Ġ625', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "noise_h , noise_h2 , noise_py_x = model ( X , w_h , w_h2 , w_o , 0.2 , 0.5 ) \n"
Original    (021): ['noise_h', ',', 'noise_h2', ',', 'noise_py_x', '=', 'model', '(', 'X', ',', 'w_h', ',', 'w_h2', ',', 'w_o', ',', '0.2', ',', '0.5', ')', '\\n']
Tokenized   (045): ['<s>', 'no', 'ise', '_', 'h', 'Ġ,', 'Ġnoise', '_', 'h', '2', 'Ġ,', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ=', 'Ġmodel', 'Ġ(', 'ĠX', 'Ġ,', 'Ġw', '_', 'h', 'Ġ,', 'Ġw', '_', 'h', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (043): ['no', 'ise', '_', 'h', 'Ġ,', 'Ġnoise', '_', 'h', '2', 'Ġ,', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ=', 'Ġmodel', 'Ġ(', 'ĠX', 'Ġ,', 'Ġw', '_', 'h', 'Ġ,', 'Ġw', '_', 'h', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['noise_h', 'Ġ,', 'Ġnoise_h2', 'Ġ,', 'Ġnoise_py_x', 'Ġ=', 'Ġmodel', 'Ġ(', 'ĠX', 'Ġ,', 'Ġw_h', 'Ġ,', 'Ġw_h2', 'Ġ,', 'Ġw_o', 'Ġ,', 'Ġ0.2', 'Ġ,', 'Ġ0.5', 'Ġ)', 'Ġ\\n']
Counter: 43
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "y_x = T . argmax ( py_x , axis = 1 ) \n"
Original    (013): ['y_x', '=', 'T', '.', 'argmax', '(', 'py_x', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (021): ['<s>', 'y', '_', 'x', 'Ġ=', 'ĠT', 'Ġ.', 'Ġarg', 'max', 'Ġ(', 'Ġpy', '_', 'x', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['y', '_', 'x', 'Ġ=', 'ĠT', 'Ġ.', 'Ġarg', 'max', 'Ġ(', 'Ġpy', '_', 'x', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['y_x', 'Ġ=', 'ĠT', 'Ġ.', 'Ġargmax', 'Ġ(', 'Ġpy_x', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "cost = T . mean ( T . nnet . categorical_crossentropy ( noise_py_x , Y ) ) \n"
Original    (018): ['cost', '=', 'T', '.', 'mean', '(', 'T', '.', 'nnet', '.', 'categorical_crossentropy', '(', 'noise_py_x', ',', 'Y', ')', ')', '\\n']
Tokenized   (031): ['<s>', 'cost', 'Ġ=', 'ĠT', 'Ġ.', 'Ġmean', 'Ġ(', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġcateg', 'orical', '_', 'cross', 'ent', 'ropy', 'Ġ(', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['cost', 'Ġ=', 'ĠT', 'Ġ.', 'Ġmean', 'Ġ(', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġcateg', 'orical', '_', 'cross', 'ent', 'ropy', 'Ġ(', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['cost', 'Ġ=', 'ĠT', 'Ġ.', 'Ġmean', 'Ġ(', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġcategorical_crossentropy', 'Ġ(', 'Ġnoise_py_x', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "updates = RMSprop ( cost , params , lr = 0.001 ) \n"
Original    (013): ['updates', '=', 'RMSprop', '(', 'cost', ',', 'params', ',', 'lr', '=', '0.001', ')', '\\n']
Tokenized   (022): ['<s>', 'up', 'dates', 'Ġ=', 'ĠR', 'MS', 'prop', 'Ġ(', 'Ġcost', 'Ġ,', 'Ġparams', 'Ġ,', 'Ġl', 'r', 'Ġ=', 'Ġ0', '.', '001', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['up', 'dates', 'Ġ=', 'ĠR', 'MS', 'prop', 'Ġ(', 'Ġcost', 'Ġ,', 'Ġparams', 'Ġ,', 'Ġl', 'r', 'Ġ=', 'Ġ0', '.', '001', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['updates', 'Ġ=', 'ĠRMSprop', 'Ġ(', 'Ġcost', 'Ġ,', 'Ġparams', 'Ġ,', 'Ġlr', 'Ġ=', 'Ġ0.001', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "train = theano . function ( inputs = [ X , Y ] , outputs = cost , updates = updates , allow_input_downcast = True ) \n"
Original    (027): ['train', '=', 'theano', '.', 'function', '(', 'inputs', '=', '[', 'X', ',', 'Y', ']', ',', 'outputs', '=', 'cost', ',', 'updates', '=', 'updates', ',', 'allow_input_downcast', '=', 'True', ')', '\\n']
Tokenized   (036): ['<s>', 'train', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġcost', 'Ġ,', 'Ġupdates', 'Ġ=', 'Ġupdates', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['train', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġcost', 'Ġ,', 'Ġupdates', 'Ġ=', 'Ġupdates', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['train', 'Ġ=', 'Ġtheano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġcost', 'Ġ,', 'Ġupdates', 'Ġ=', 'Ġupdates', 'Ġ,', 'Ġallow_input_downcast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "predict = theano . function ( inputs = [ X ] , outputs = y_x , allow_input_downcast = True ) \n"
Original    (021): ['predict', '=', 'theano', '.', 'function', '(', 'inputs', '=', '[', 'X', ']', ',', 'outputs', '=', 'y_x', ',', 'allow_input_downcast', '=', 'True', ')', '\\n']
Tokenized   (033): ['<s>', 'p', 'redict', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġy', '_', 'x', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['p', 'redict', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġy', '_', 'x', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['predict', 'Ġ=', 'Ġtheano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġy_x', 'Ġ,', 'Ġallow_input_downcast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "settings . DATABASE_CONFIG_DICT [ ] ) \n"
Original    (007): ['settings', '.', 'DATABASE_CONFIG_DICT', '[', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'settings', 'Ġ.', 'ĠD', 'AT', 'AB', 'ASE', '_', 'CON', 'FIG', '_', 'D', 'ICT', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['settings', 'Ġ.', 'ĠD', 'AT', 'AB', 'ASE', '_', 'CON', 'FIG', '_', 'D', 'ICT', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['settings', 'Ġ.', 'ĠDATABASE_CONFIG_DICT', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "TEMPLATES [ 0 ] [ ] [ ] = DEBUG \n"
Original    (011): ['TEMPLATES', '[', '0', ']', '[', ']', '[', ']', '=', 'DEBUG', '\\n']
Tokenized   (017): ['<s>', 'T', 'EM', 'PL', 'ATES', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠDEBUG', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['T', 'EM', 'PL', 'ATES', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠDEBUG', 'Ġ\\', 'n']
Detokenized (011): ['TEMPLATES', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠDEBUG', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "SECRET_KEY = env ( "DJANGO_SECRET_KEY" , default = ) \n"
Original    (010): ['SECRET_KEY', '=', 'env', '(', '"DJANGO_SECRET_KEY"', ',', 'default', '=', ')', '\\n']
Tokenized   (025): ['<s>', 'SEC', 'RET', '_', 'KEY', 'Ġ=', 'Ġenv', 'Ġ(', 'Ġ"', 'DJ', 'AN', 'GO', '_', 'SEC', 'RET', '_', 'KEY', '"', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['SEC', 'RET', '_', 'KEY', 'Ġ=', 'Ġenv', 'Ġ(', 'Ġ"', 'DJ', 'AN', 'GO', '_', 'SEC', 'RET', '_', 'KEY', '"', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['SECRET_KEY', 'Ġ=', 'Ġenv', 'Ġ(', 'Ġ"DJANGO_SECRET_KEY"', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "MIDDLEWARE_CLASSES += ( , ) \n"
Original    (006): ['MIDDLEWARE_CLASSES', '+=', '(', ',', ')', '\\n']
Tokenized   (016): ['<s>', 'M', 'ID', 'D', 'LE', 'WARE', '_', 'CLASS', 'ES', 'Ġ+=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['M', 'ID', 'D', 'LE', 'WARE', '_', 'CLASS', 'ES', 'Ġ+=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['MIDDLEWARE_CLASSES', 'Ġ+=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "INTERNAL_IPS = ( , , ) \n"
Original    (007): ['INTERNAL_IPS', '=', '(', ',', ',', ')', '\\n']
Tokenized   (014): ['<s>', 'IN', 'TERN', 'AL', '_', 'IPS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['IN', 'TERN', 'AL', '_', 'IPS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['INTERNAL_IPS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "redirect_url = request . POST . get ( ) or \n"
Original    (011): ['redirect_url', '=', 'request', '.', 'POST', '.', 'get', '(', ')', 'or', '\\n']
Tokenized   (017): ['<s>', 'red', 'irect', '_', 'url', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['red', 'irect', '_', 'url', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġor', 'Ġ\\', 'n']
Detokenized (011): ['redirect_url', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġor', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "icon = self . get_plugin_icon ( ) , \n"
Original    (009): ['icon', '=', 'self', '.', 'get_plugin_icon', '(', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'icon', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'plugin', '_', 'icon', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['icon', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'plugin', '_', 'icon', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['icon', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget_plugin_icon', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "memoryprofiler_act . setEnabled ( is_memoryprofiler_installed ( ) ) \n"
Original    (009): ['memoryprofiler_act', '.', 'setEnabled', '(', 'is_memoryprofiler_installed', '(', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'memory', 'prof', 'iler', '_', 'act', 'Ġ.', 'Ġset', 'Enabled', 'Ġ(', 'Ġis', '_', 'memory', 'prof', 'iler', '_', 'installed', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['memory', 'prof', 'iler', '_', 'act', 'Ġ.', 'Ġset', 'Enabled', 'Ġ(', 'Ġis', '_', 'memory', 'prof', 'iler', '_', 'installed', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['memoryprofiler_act', 'Ġ.', 'ĠsetEnabled', 'Ġ(', 'Ġis_memoryprofiler_installed', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "wdir , args = None , None \n"
Original    (008): ['wdir', ',', 'args', '=', 'None', ',', 'None', '\\n']
Tokenized   (012): ['<s>', 'w', 'dir', 'Ġ,', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['w', 'dir', 'Ġ,', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ\\', 'n']
Detokenized (008): ['wdir', 'Ġ,', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "use_colors = self . get_option ( , True ) ) \n"
Original    (011): ['use_colors', '=', 'self', '.', 'get_option', '(', ',', 'True', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'use', '_', 'col', 'ors', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'option', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['use', '_', 'col', 'ors', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'option', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['use_colors', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget_option', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "message_type = None , enum_type = None , containing_type = None , \n"
Original    (013): ['message_type', '=', 'None', ',', 'enum_type', '=', 'None', ',', 'containing_type', '=', 'None', ',', '\\n']
Tokenized   (022): ['<s>', 'message', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġenum', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcontaining', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['message', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġenum', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcontaining', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['message_type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġenum_type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcontaining_type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_extension = False , extension_scope = None , \n"
Original    (009): ['is_extension', '=', 'False', ',', 'extension_scope', '=', 'None', ',', '\\n']
Tokenized   (017): ['<s>', 'is', '_', 'ext', 'ension', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġextension', '_', 'scope', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['is', '_', 'ext', 'ension', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġextension', '_', 'scope', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['is_extension', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġextension_scope', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_BATCHNOTIFICATIONREQUEST . fields_by_name [ ] . message_type = _PUSHNOTIFICATION \n"
Original    (010): ['_BATCHNOTIFICATIONREQUEST', '.', 'fields_by_name', '[', ']', '.', 'message_type', '=', '_PUSHNOTIFICATION', '\\n']
Tokenized   (031): ['<s>', '_', 'B', 'ATCH', 'NOT', 'IFIC', 'ATION', 'RE', 'QUEST', 'Ġ.', 'Ġfields', '_', 'by', '_', 'name', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmessage', '_', 'type', 'Ġ=', 'Ġ_', 'P', 'USH', 'NOT', 'IFIC', 'ATION', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['_', 'B', 'ATCH', 'NOT', 'IFIC', 'ATION', 'RE', 'QUEST', 'Ġ.', 'Ġfields', '_', 'by', '_', 'name', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmessage', '_', 'type', 'Ġ=', 'Ġ_', 'P', 'USH', 'NOT', 'IFIC', 'ATION', 'Ġ\\', 'n']
Detokenized (010): ['_BATCHNOTIFICATIONREQUEST', 'Ġ.', 'Ġfields_by_name', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmessage_type', 'Ġ=', 'Ġ_PUSHNOTIFICATION', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "expected_zip_content = [ "manifest.json" , "sd_bl.bin" , "sd_bl.dat" ] \n"
Original    (010): ['expected_zip_content', '=', '[', '"manifest.json"', ',', '"sd_bl.bin"', ',', '"sd_bl.dat"', ']', '\\n']
Tokenized   (034): ['<s>', 'expected', '_', 'zip', '_', 'content', 'Ġ=', 'Ġ[', 'Ġ"', 'man', 'ifest', '.', 'json', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'bin', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'dat', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['expected', '_', 'zip', '_', 'content', 'Ġ=', 'Ġ[', 'Ġ"', 'man', 'ifest', '.', 'json', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'bin', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'dat', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['expected_zip_content', 'Ġ=', 'Ġ[', 'Ġ"manifest.json"', 'Ġ,', 'Ġ"sd_bl.bin"', 'Ġ,', 'Ġ"sd_bl.dat"', 'Ġ]', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sd_req = [ 0x1000 , 0xffff ] , \n"
Original    (009): ['sd_req', '=', '[', '0x1000', ',', '0xffff', ']', ',', '\\n']
Tokenized   (018): ['<s>', 'sd', '_', 'req', 'Ġ=', 'Ġ[', 'Ġ0', 'x', '1000', 'Ġ,', 'Ġ0', 'x', 'ffff', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['sd', '_', 'req', 'Ġ=', 'Ġ[', 'Ġ0', 'x', '1000', 'Ġ,', 'Ġ0', 'x', 'ffff', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['sd_req', 'Ġ=', 'Ġ[', 'Ġ0x1000', 'Ġ,', 'Ġ0xffff', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pkg_name = os . path . join ( self . work_directory , "mypackage.zip" ) \n"
Original    (015): ['pkg_name', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', '"mypackage.zip"', ')', '\\n']
Tokenized   (027): ['<s>', 'pkg', '_', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġ"', 'my', 'package', '.', 'zip', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['pkg', '_', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġ"', 'my', 'package', '.', 'zip', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['pkg_name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork_directory', 'Ġ,', 'Ġ"mypackage.zip"', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "manifest = self . p . unpack_package ( os . path . join ( self . work_directory , pkg_name ) , unpacked_dir ) \n"
Original    (024): ['manifest', '=', 'self', '.', 'p', '.', 'unpack_package', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', 'pkg_name', ')', ',', 'unpacked_dir', ')', '\\n']
Tokenized   (039): ['<s>', 'man', 'ifest', 'Ġ=', 'Ġself', 'Ġ.', 'Ġp', 'Ġ.', 'Ġun', 'pack', '_', 'package', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġp', 'kg', '_', 'name', 'Ġ)', 'Ġ,', 'Ġunp', 'acked', '_', 'dir', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['man', 'ifest', 'Ġ=', 'Ġself', 'Ġ.', 'Ġp', 'Ġ.', 'Ġun', 'pack', '_', 'package', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġp', 'kg', '_', 'name', 'Ġ)', 'Ġ,', 'Ġunp', 'acked', '_', 'dir', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['manifest', 'Ġ=', 'Ġself', 'Ġ.', 'Ġp', 'Ġ.', 'Ġunpack_package', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork_directory', 'Ġ,', 'Ġpkg_name', 'Ġ)', 'Ġ,', 'Ġunpacked_dir', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "style = wx . richtext . RE_MULTILINE , value = ) \n"
Original    (012): ['style', '=', 'wx', '.', 'richtext', '.', 'RE_MULTILINE', ',', 'value', '=', ')', '\\n']
Tokenized   (022): ['<s>', 'style', 'Ġ=', 'Ġw', 'x', 'Ġ.', 'Ġrich', 'text', 'Ġ.', 'ĠRE', '_', 'M', 'ULT', 'IL', 'INE', 'Ġ,', 'Ġvalue', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['style', 'Ġ=', 'Ġw', 'x', 'Ġ.', 'Ġrich', 'text', 'Ġ.', 'ĠRE', '_', 'M', 'ULT', 'IL', 'INE', 'Ġ,', 'Ġvalue', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['style', 'Ġ=', 'Ġwx', 'Ġ.', 'Ġrichtext', 'Ġ.', 'ĠRE_MULTILINE', 'Ġ,', 'Ġvalue', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fgSizer1 . Add ( self . lblChangelt , 0 , wx . ALL , 5 ) \n"
Original    (017): ['fgSizer1', '.', 'Add', '(', 'self', '.', 'lblChangelt', ',', '0', ',', 'wx', '.', 'ALL', ',', '5', ')', '\\n']
Tokenized   (028): ['<s>', 'fg', 'S', 'izer', '1', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġl', 'bl', 'Ch', 'ang', 'elt', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['fg', 'S', 'izer', '1', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġl', 'bl', 'Ch', 'ang', 'elt', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['fgSizer1', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'ĠlblChangelt', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġwx', 'Ġ.', 'ĠALL', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sbThreshold . Add ( fgSizer1 , 0 , wx . EXPAND , 5 ) \n"
Original    (015): ['sbThreshold', '.', 'Add', '(', 'fgSizer1', ',', '0', ',', 'wx', '.', 'EXPAND', ',', '5', ')', '\\n']
Tokenized   (026): ['<s>', 'sb', 'Th', 'reshold', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġf', 'g', 'S', 'izer', '1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['sb', 'Th', 'reshold', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġf', 'g', 'S', 'izer', '1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sbThreshold', 'Ġ.', 'ĠAdd', 'Ġ(', 'ĠfgSizer1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġwx', 'Ġ.', 'ĠEXPAND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "bsValueThresh . Add ( sbThreshold , 1 , 0 , 5 ) \n"
Original    (013): ['bsValueThresh', '.', 'Add', '(', 'sbThreshold', ',', '1', ',', '0', ',', '5', ')', '\\n']
Tokenized   (022): ['<s>', 'bs', 'Value', 'Th', 'resh', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġs', 'b', 'Th', 'reshold', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['bs', 'Value', 'Th', 'resh', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġs', 'b', 'Th', 'reshold', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['bsValueThresh', 'Ġ.', 'ĠAdd', 'Ġ(', 'ĠsbThreshold', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "cbGapTimeChoices = [ u"second" , u"minute" , u"hour" , u"day" ] \n"
Original    (012): ['cbGapTimeChoices', '=', '[', 'u"second"', ',', 'u"minute"', ',', 'u"hour"', ',', 'u"day"', ']', '\\n']
Tokenized   (032): ['<s>', 'cb', 'G', 'ap', 'Time', 'Cho', 'ices', 'Ġ=', 'Ġ[', 'Ġu', '"', 'second', '"', 'Ġ,', 'Ġu', '"', 'minute', '"', 'Ġ,', 'Ġu', '"', 'hour', '"', 'Ġ,', 'Ġu', '"', 'day', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['cb', 'G', 'ap', 'Time', 'Cho', 'ices', 'Ġ=', 'Ġ[', 'Ġu', '"', 'second', '"', 'Ġ,', 'Ġu', '"', 'minute', '"', 'Ġ,', 'Ġu', '"', 'hour', '"', 'Ġ,', 'Ġu', '"', 'day', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['cbGapTimeChoices', 'Ġ=', 'Ġ[', 'Ġu"second"', 'Ġ,', 'Ġu"minute"', 'Ġ,', 'Ġu"hour"', 'Ġ,', 'Ġu"day"', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fmt24hr = True , spinButton = self . sbBefore , oob_color = ) \n"
Original    (014): ['fmt24hr', '=', 'True', ',', 'spinButton', '=', 'self', '.', 'sbBefore', ',', 'oob_color', '=', ')', '\\n']
Tokenized   (026): ['<s>', 'f', 'mt', '24', 'hr', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġspin', 'Button', 'Ġ=', 'Ġself', 'Ġ.', 'Ġs', 'b', 'Before', 'Ġ,', 'Ġo', 'ob', '_', 'color', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['f', 'mt', '24', 'hr', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġspin', 'Button', 'Ġ=', 'Ġself', 'Ġ.', 'Ġs', 'b', 'Before', 'Ġ,', 'Ġo', 'ob', '_', 'color', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['fmt24hr', 'Ġ=', 'ĠTrue', 'Ġ,', 'ĠspinButton', 'Ġ=', 'Ġself', 'Ġ.', 'ĠsbBefore', 'Ġ,', 'Ġoob_color', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "bsButtons . Add ( self . btnOK , 1 , wx . ALL | wx . EXPAND , 5 ) \n"
Original    (021): ['bsButtons', '.', 'Add', '(', 'self', '.', 'btnOK', ',', '1', ',', 'wx', '.', 'ALL', '|', 'wx', '.', 'EXPAND', ',', '5', ')', '\\n']
Tokenized   (031): ['<s>', 'bs', 'But', 'tons', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġb', 'tn', 'OK', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ|', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['bs', 'But', 'tons', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġb', 'tn', 'OK', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ|', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['bsButtons', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'ĠbtnOK', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġwx', 'Ġ.', 'ĠALL', 'Ġ|', 'Ġwx', 'Ġ.', 'ĠEXPAND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "mat ( op2 . INC , ( elem_node [ op2 . i [ 0 ] ] , \n"
Original    (018): ['mat', '(', 'op2', '.', 'INC', ',', '(', 'elem_node', '[', 'op2', '.', 'i', '[', '0', ']', ']', ',', '\\n']
Tokenized   (026): ['<s>', 'mat', 'Ġ(', 'Ġop', '2', 'Ġ.', 'ĠINC', 'Ġ,', 'Ġ(', 'Ġele', 'm', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['mat', 'Ġ(', 'Ġop', '2', 'Ġ.', 'ĠINC', 'Ġ,', 'Ġ(', 'Ġele', 'm', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (018): ['mat', 'Ġ(', 'Ġop2', 'Ġ.', 'ĠINC', 'Ġ,', 'Ġ(', 'Ġelem_node', 'Ġ[', 'Ġop2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "elem_node [ op2 . i [ 1 ] ] ) ) , \n"
Original    (013): ['elem_node', '[', 'op2', '.', 'i', '[', '1', ']', ']', ')', ')', ',', '\\n']
Tokenized   (020): ['<s>', 'e', 'lem', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['e', 'lem', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['elem_node', 'Ġ[', 'Ġop2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "partition_size = NUM_ELE / 2 , \n"
Original    (007): ['partition_size', '=', 'NUM_ELE', '/', '2', ',', '\\n']
Tokenized   (016): ['<s>', 'part', 'ition', '_', 'size', 'Ġ=', 'ĠNUM', '_', 'E', 'LE', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['part', 'ition', '_', 'size', 'Ġ=', 'ĠNUM', '_', 'E', 'LE', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['partition_size', 'Ġ=', 'ĠNUM_ELE', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "statusBarAx . barh ( [ 0 ] , [ 100.0 * expNumber / len ( data . getPaths ( ) ) ] , \n"
Original    (024): ['statusBarAx', '.', 'barh', '(', '[', '0', ']', ',', '[', '100.0', '*', 'expNumber', '/', 'len', '(', 'data', '.', 'getPaths', '(', ')', ')', ']', ',', '\\n']
Tokenized   (035): ['<s>', 'status', 'Bar', 'Ax', 'Ġ.', 'Ġbar', 'h', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ100', '.', '0', 'Ġ*', 'Ġexp', 'Number', 'Ġ/', 'Ġlen', 'Ġ(', 'Ġdata', 'Ġ.', 'Ġget', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['status', 'Bar', 'Ax', 'Ġ.', 'Ġbar', 'h', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ100', '.', '0', 'Ġ*', 'Ġexp', 'Number', 'Ġ/', 'Ġlen', 'Ġ(', 'Ġdata', 'Ġ.', 'Ġget', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (024): ['statusBarAx', 'Ġ.', 'Ġbarh', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ100.0', 'Ġ*', 'ĠexpNumber', 'Ġ/', 'Ġlen', 'Ġ(', 'Ġdata', 'Ġ.', 'ĠgetPaths', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "fluxes , errors , photFlags = photometry . multirad ( image , x , y , \n"
Original    (017): ['fluxes', ',', 'errors', ',', 'photFlags', '=', 'photometry', '.', 'multirad', '(', 'image', ',', 'x', ',', 'y', ',', '\\n']
Tokenized   (026): ['<s>', 'f', 'lux', 'es', 'Ġ,', 'Ġerrors', 'Ġ,', 'Ġphot', 'Flags', 'Ġ=', 'Ġphot', 'ometry', 'Ġ.', 'Ġmult', 'ir', 'ad', 'Ġ(', 'Ġimage', 'Ġ,', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['f', 'lux', 'es', 'Ġ,', 'Ġerrors', 'Ġ,', 'Ġphot', 'Flags', 'Ġ=', 'Ġphot', 'ometry', 'Ġ.', 'Ġmult', 'ir', 'ad', 'Ġ(', 'Ġimage', 'Ġ,', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['fluxes', 'Ġ,', 'Ġerrors', 'Ġ,', 'ĠphotFlags', 'Ġ=', 'Ġphotometry', 'Ġ.', 'Ġmultirad', 'Ġ(', 'Ġimage', 'Ġ,', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "meanComparisonStars , meanComparisonStarErrors = data . calcMeanComparison_multirad ( ccdGain = data . ccdGain ) \n"
Original    (015): ['meanComparisonStars', ',', 'meanComparisonStarErrors', '=', 'data', '.', 'calcMeanComparison_multirad', '(', 'ccdGain', '=', 'data', '.', 'ccdGain', ')', '\\n']
Tokenized   (040): ['<s>', 'mean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġmean', 'Compar', 'ison', 'Star', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcalc', 'Me', 'an', 'Compar', 'ison', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġc', 'cd', 'G', 'ain', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġc', 'cd', 'G', 'ain', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['mean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġmean', 'Compar', 'ison', 'Star', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcalc', 'Me', 'an', 'Compar', 'ison', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġc', 'cd', 'G', 'ain', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġc', 'cd', 'G', 'ain', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['meanComparisonStars', 'Ġ,', 'ĠmeanComparisonStarErrors', 'Ġ=', 'Ġdata', 'Ġ.', 'ĠcalcMeanComparison_multirad', 'Ġ(', 'ĠccdGain', 'Ġ=', 'Ġdata', 'Ġ.', 'ĠccdGain', 'Ġ)', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "lightCurves , lightCurveErrors = data . computeLightCurve_multirad ( meanComparisonStars , \n"
Original    (011): ['lightCurves', ',', 'lightCurveErrors', '=', 'data', '.', 'computeLightCurve_multirad', '(', 'meanComparisonStars', ',', '\\n']
Tokenized   (030): ['<s>', 'light', 'Cur', 'ves', 'Ġ,', 'Ġlight', 'Cur', 've', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcompute', 'Light', 'Cur', 've', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġmean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['light', 'Cur', 'ves', 'Ġ,', 'Ġlight', 'Cur', 've', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcompute', 'Light', 'Cur', 've', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġmean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['lightCurves', 'Ġ,', 'ĠlightCurveErrors', 'Ġ=', 'Ġdata', 'Ġ.', 'ĠcomputeLightCurve_multirad', 'Ġ(', 'ĠmeanComparisonStars', 'Ġ,', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "json_data = self . _send_request ( , url , params = params ) \n"
Original    (014): ['json_data', '=', 'self', '.', '_send_request', '(', ',', 'url', ',', 'params', '=', 'params', ')', '\\n']
Tokenized   (022): ['<s>', 'json', '_', 'data', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'send', '_', 'request', 'Ġ(', 'Ġ,', 'Ġurl', 'Ġ,', 'Ġparams', 'Ġ=', 'Ġparams', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['json', '_', 'data', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'send', '_', 'request', 'Ġ(', 'Ġ,', 'Ġurl', 'Ġ,', 'Ġparams', 'Ġ=', 'Ġparams', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['json_data', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_send_request', 'Ġ(', 'Ġ,', 'Ġurl', 'Ġ,', 'Ġparams', 'Ġ=', 'Ġparams', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "mkdir ( env . hosts_data . log_path ( ) ) \n"
Original    (011): ['mkdir', '(', 'env', '.', 'hosts_data', '.', 'log_path', '(', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'mk', 'dir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġlog', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mk', 'dir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġlog', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['mkdir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġlog_path', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "StringIO ( env . hosts_data . celery_supervisor_config ( ) ) , \n"
Original    (012): ['StringIO', '(', 'env', '.', 'hosts_data', '.', 'celery_supervisor_config', '(', ')', ')', ',', '\\n']
Tokenized   (024): ['<s>', 'String', 'IO', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['String', 'IO', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['StringIO', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġcelery_supervisor_config', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "env . hosts_data . celery_supervisor_config_path ( ) , \n"
Original    (009): ['env', '.', 'hosts_data', '.', 'celery_supervisor_config_path', '(', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'env', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['env', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['env', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġcelery_supervisor_config_path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rmdir ( env . hosts_data . celery_supervisor_config_path ( ) , sudo_access = True ) \n"
Original    (015): ['rmdir', '(', 'env', '.', 'hosts_data', '.', 'celery_supervisor_config_path', '(', ')', ',', 'sudo_access', '=', 'True', ')', '\\n']
Tokenized   (032): ['<s>', 'r', 'md', 'ir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġsudo', '_', 'access', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['r', 'md', 'ir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġsudo', '_', 'access', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['rmdir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġcelery_supervisor_config_path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġsudo_access', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "sudo ( . format ( env . hosts_data . application_name ( ) ) ) \n"
Original    (015): ['sudo', '(', '.', 'format', '(', 'env', '.', 'hosts_data', '.', 'application_name', '(', ')', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'sudo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġapplication', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['sudo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġapplication', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sudo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġapplication_name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "collection_response = SharedCollectionResponse ( json . loads ( self . send ( ) . content ) ) \n"
Original    (018): ['collection_response', '=', 'SharedCollectionResponse', '(', 'json', '.', 'loads', '(', 'self', '.', 'send', '(', ')', '.', 'content', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'collection', '_', 'response', 'Ġ=', 'ĠShared', 'Collection', 'Response', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsend', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcontent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['collection', '_', 'response', 'Ġ=', 'ĠShared', 'Collection', 'Response', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsend', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcontent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['collection_response', 'Ġ=', 'ĠSharedCollectionResponse', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsend', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcontent', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "libraries = [ "sodium" ] , \n"
Original    (007): ['libraries', '=', '[', '"sodium"', ']', ',', '\\n']
Tokenized   (014): ['<s>', 'l', 'ibraries', 'Ġ=', 'Ġ[', 'Ġ"', 's', 'odium', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['l', 'ibraries', 'Ġ=', 'Ġ[', 'Ġ"', 's', 'odium', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['libraries', 'Ġ=', 'Ġ[', 'Ġ"sodium"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "number = 2 , type = 12 , cpp_type = 9 , label = 2 , \n"
Original    (017): ['number', '=', '2', ',', 'type', '=', '12', ',', 'cpp_type', '=', '9', ',', 'label', '=', '2', ',', '\\n']
Tokenized   (023): ['<s>', 'number', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġ12', 'Ġ,', 'Ġc', 'pp', '_', 'type', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġlabel', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['number', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġ12', 'Ġ,', 'Ġc', 'pp', '_', 'type', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġlabel', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['number', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġ12', 'Ġ,', 'Ġcpp_type', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġlabel', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "has_default_value = False , default_value = _b ( "" ) , \n"
Original    (012): ['has_default_value', '=', 'False', ',', 'default_value', '=', '_b', '(', '""', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'has', '_', 'default', '_', 'value', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ=', 'Ġ_', 'b', 'Ġ(', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['has', '_', 'default', '_', 'value', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ=', 'Ġ_', 'b', 'Ġ(', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['has_default_value', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault_value', 'Ġ=', 'Ġ_b', 'Ġ(', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "PeerSeeds = _reflection . GeneratedProtocolMessageType ( , ( _message . Message , ) , dict ( \n"
Original    (017): ['PeerSeeds', '=', '_reflection', '.', 'GeneratedProtocolMessageType', '(', ',', '(', '_message', '.', 'Message', ',', ')', ',', 'dict', '(', '\\n']
Tokenized   (031): ['<s>', 'Pe', 'er', 'S', 'eeds', 'Ġ=', 'Ġ_', 'ref', 'lection', 'Ġ.', 'ĠGener', 'ated', 'Prot', 'ocol', 'Message', 'Type', 'Ġ(', 'Ġ,', 'Ġ(', 'Ġ_', 'message', 'Ġ.', 'ĠMessage', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġdict', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['Pe', 'er', 'S', 'eeds', 'Ġ=', 'Ġ_', 'ref', 'lection', 'Ġ.', 'ĠGener', 'ated', 'Prot', 'ocol', 'Message', 'Type', 'Ġ(', 'Ġ,', 'Ġ(', 'Ġ_', 'message', 'Ġ.', 'ĠMessage', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġdict', 'Ġ(', 'Ġ\\', 'n']
Detokenized (017): ['PeerSeeds', 'Ġ=', 'Ġ_reflection', 'Ġ.', 'ĠGeneratedProtocolMessageType', 'Ġ(', 'Ġ,', 'Ġ(', 'Ġ_message', 'Ġ.', 'ĠMessage', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġdict', 'Ġ(', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "__module__ = \n"
Original    (003): ['__module__', '=', '\\n']
Tokenized   (008): ['<s>', '__', 'module', '__', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['__', 'module', '__', 'Ġ=', 'Ġ\\', 'n']
Detokenized (003): ['__module__', 'Ġ=', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "tstream = BytearrayStream ( istream . read ( self . length ) ) \n"
Original    (014): ['tstream', '=', 'BytearrayStream', '(', 'istream', '.', 'read', '(', 'self', '.', 'length', ')', ')', '\\n']
Tokenized   (024): ['<s>', 't', 'stream', 'Ġ=', 'ĠBy', 't', 'ear', 'ray', 'Stream', 'Ġ(', 'Ġis', 't', 'ream', 'Ġ.', 'Ġread', 'Ġ(', 'Ġself', 'Ġ.', 'Ġlength', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', 'stream', 'Ġ=', 'ĠBy', 't', 'ear', 'ray', 'Stream', 'Ġ(', 'Ġis', 't', 'ream', 'Ġ.', 'Ġread', 'Ġ(', 'Ġself', 'Ġ.', 'Ġlength', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['tstream', 'Ġ=', 'ĠBytearrayStream', 'Ġ(', 'Ġistream', 'Ġ.', 'Ġread', 'Ġ(', 'Ġself', 'Ġ.', 'Ġlength', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "opts , args = parser . parse_args ( sys . argv [ 1 : ] ) \n"
Original    (017): ['opts', ',', 'args', '=', 'parser', '.', 'parse_args', '(', 'sys', '.', 'argv', '[', '1', ':', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'op', 'ts', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġparser', 'Ġ.', 'Ġparse', '_', 'args', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['op', 'ts', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġparser', 'Ġ.', 'Ġparse', '_', 'args', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['opts', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġparser', 'Ġ.', 'Ġparse_args', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : ""{0}" . format ( uid ) ) \n"
Original    (008): ['"{0}"', '.', 'format', '(', 'uid', ')', ')', '\\n']
Tokenized   (015): ['<s>', '"', '{', '0', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġu', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', '{', '0', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġu', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['"{0}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġuid', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""located." . format ( path ) \n"
Original    (007): ['"located."', '.', 'format', '(', 'path', ')', '\\n']
Tokenized   (013): ['<s>', '"', 'l', 'ocated', '."', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['"', 'l', 'ocated', '."', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['"located."', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "discover_versions . DiscoverVersionsResponsePayload , ** kwargs ) \n"
Original    (008): ['discover_versions', '.', 'DiscoverVersionsResponsePayload', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (020): ['<s>', 'd', 'iscover', '_', 'versions', 'Ġ.', 'ĠDiscover', 'Versions', 'Response', 'Pay', 'load', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['d', 'iscover', '_', 'versions', 'Ġ.', 'ĠDiscover', 'Versions', 'Response', 'Pay', 'load', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['discover_versions', 'Ġ.', 'ĠDiscoverVersionsResponsePayload', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sqltypes . Base . metadata . create_all ( self . engine ) \n"
Original    (013): ['sqltypes', '.', 'Base', '.', 'metadata', '.', 'create_all', '(', 'self', '.', 'engine', ')', '\\n']
Tokenized   (019): ['<s>', 'sql', 'types', 'Ġ.', 'ĠBase', 'Ġ.', 'Ġmetadata', 'Ġ.', 'Ġcreate', '_', 'all', 'Ġ(', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['sql', 'types', 'Ġ.', 'ĠBase', 'Ġ.', 'Ġmetadata', 'Ġ.', 'Ġcreate', '_', 'all', 'Ġ(', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['sqltypes', 'Ġ.', 'ĠBase', 'Ġ.', 'Ġmetadata', 'Ġ.', 'Ġcreate_all', 'Ġ(', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "enums . OpaqueDataType . NONE , \n"
Original    (007): ['enums', '.', 'OpaqueDataType', '.', 'NONE', ',', '\\n']
Tokenized   (015): ['<s>', 'en', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['en', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['enums', 'Ġ.', 'ĠOpaqueDataType', 'Ġ.', 'ĠNONE', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "binascii . hexlify ( self . bytes_a ) , enums . OpaqueDataType . NONE ) \n"
Original    (016): ['binascii', '.', 'hexlify', '(', 'self', '.', 'bytes_a', ')', ',', 'enums', '.', 'OpaqueDataType', '.', 'NONE', ')', '\\n']
Tokenized   (031): ['<s>', 'bin', 'as', 'ci', 'i', 'Ġ.', 'Ġhex', 'l', 'ify', 'Ġ(', 'Ġself', 'Ġ.', 'Ġbytes', '_', 'a', 'Ġ)', 'Ġ,', 'Ġen', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['bin', 'as', 'ci', 'i', 'Ġ.', 'Ġhex', 'l', 'ify', 'Ġ(', 'Ġself', 'Ġ.', 'Ġbytes', '_', 'a', 'Ġ)', 'Ġ,', 'Ġen', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['binascii', 'Ġ.', 'Ġhexlify', 'Ġ(', 'Ġself', 'Ġ.', 'Ġbytes_a', 'Ġ)', 'Ġ,', 'Ġenums', 'Ġ.', 'ĠOpaqueDataType', 'Ġ.', 'ĠNONE', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "Session = sessionmaker ( bind = self . engine ) \n"
Original    (011): ['Session', '=', 'sessionmaker', '(', 'bind', '=', 'self', '.', 'engine', ')', '\\n']
Tokenized   (015): ['<s>', 'Session', 'Ġ=', 'Ġsession', 'maker', 'Ġ(', 'Ġbind', 'Ġ=', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Session', 'Ġ=', 'Ġsession', 'maker', 'Ġ(', 'Ġbind', 'Ġ=', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['Session', 'Ġ=', 'Ġsessionmaker', 'Ġ(', 'Ġbind', 'Ġ=', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "get_obj = session . query ( OpaqueObject ) . filter ( \n"
Original    (012): ['get_obj', '=', 'session', '.', 'query', '(', 'OpaqueObject', ')', '.', 'filter', '(', '\\n']
Tokenized   (019): ['<s>', 'get', '_', 'obj', 'Ġ=', 'Ġsession', 'Ġ.', 'Ġquery', 'Ġ(', 'ĠOp', 'aque', 'Object', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['get', '_', 'obj', 'Ġ=', 'Ġsession', 'Ġ.', 'Ġquery', 'Ġ(', 'ĠOp', 'aque', 'Object', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġ\\', 'n']
Detokenized (012): ['get_obj', 'Ġ=', 'Ġsession', 'Ġ.', 'Ġquery', 'Ġ(', 'ĠOpaqueObject', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ManagedObject . unique_identifier == obj . unique_identifier \n"
Original    (008): ['ManagedObject', '.', 'unique_identifier', '==', 'obj', '.', 'unique_identifier', '\\n']
Tokenized   (019): ['<s>', 'Man', 'aged', 'Object', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ==', 'Ġobj', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['Man', 'aged', 'Object', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ==', 'Ġobj', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ\\', 'n']
Detokenized (008): ['ManagedObject', 'Ġ.', 'Ġunique_identifier', 'Ġ==', 'Ġobj', 'Ġ.', 'Ġunique_identifier', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "0 ) ) \n"
Original    (004): ['0', ')', ')', '\\n']
Tokenized   (007): ['<s>', '0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['0', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "expected_mo_names . append ( sqltypes . ManagedObjectName ( expected_names [ 1 ] , \n"
Original    (014): ['expected_mo_names', '.', 'append', '(', 'sqltypes', '.', 'ManagedObjectName', '(', 'expected_names', '[', '1', ']', ',', '\\n']
Tokenized   (027): ['<s>', 'expected', '_', 'mo', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġsql', 'types', 'Ġ.', 'ĠMan', 'aged', 'Object', 'Name', 'Ġ(', 'Ġexpected', '_', 'names', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['expected', '_', 'mo', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġsql', 'types', 'Ġ.', 'ĠMan', 'aged', 'Object', 'Name', 'Ġ(', 'Ġexpected', '_', 'names', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['expected_mo_names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġsqltypes', 'Ġ.', 'ĠManagedObjectName', 'Ġ(', 'Ġexpected_names', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "expected_names = [ first_name , added_name ] \n"
Original    (008): ['expected_names', '=', '[', 'first_name', ',', 'added_name', ']', '\\n']
Tokenized   (017): ['<s>', 'expected', '_', 'names', 'Ġ=', 'Ġ[', 'Ġfirst', '_', 'name', 'Ġ,', 'Ġadded', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['expected', '_', 'names', 'Ġ=', 'Ġ[', 'Ġfirst', '_', 'name', 'Ġ,', 'Ġadded', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['expected_names', 'Ġ=', 'Ġ[', 'Ġfirst_name', 'Ġ,', 'Ġadded_name', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "] } , \n"
Original    (004): [']', '}', ',', '\\n']
Tokenized   (007): ['<s>', ']', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (005): [']', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): [']', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "types . MethodType ( _lib_dir_option , None , MSVCCompiler ) ) \n"
Original    (012): ['types', '.', 'MethodType', '(', '_lib_dir_option', ',', 'None', ',', 'MSVCCompiler', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'types', 'Ġ.', 'ĠMethod', 'Type', 'Ġ(', 'Ġ_', 'lib', '_', 'dir', '_', 'option', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠMS', 'V', 'CC', 'omp', 'iler', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['types', 'Ġ.', 'ĠMethod', 'Type', 'Ġ(', 'Ġ_', 'lib', '_', 'dir', '_', 'option', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠMS', 'V', 'CC', 'omp', 'iler', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['types', 'Ġ.', 'ĠMethodType', 'Ġ(', 'Ġ_lib_dir_option', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠMSVCCompiler', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "setup ( ** kwds ) \n"
Original    (006): ['setup', '(', '**', 'kwds', ')', '\\n']
Tokenized   (011): ['<s>', 'setup', 'Ġ(', 'Ġ**', 'Ġk', 'w', 'ds', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['setup', 'Ġ(', 'Ġ**', 'Ġk', 'w', 'ds', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['setup', 'Ġ(', 'Ġ**', 'Ġkwds', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "intersphinx_mapping = { : None } \n"
Original    (007): ['intersphinx_mapping', '=', '{', ':', 'None', '}', '\\n']
Tokenized   (015): ['<s>', 'inters', 'ph', 'inx', '_', 'm', 'apping', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['inters', 'ph', 'inx', '_', 'm', 'apping', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['intersphinx_mapping', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "new_w = int ( width * wrat ) \n"
Original    (009): ['new_w', '=', 'int', '(', 'width', '*', 'wrat', ')', '\\n']
Tokenized   (015): ['<s>', 'new', '_', 'w', 'Ġ=', 'Ġint', 'Ġ(', 'Ġwidth', 'Ġ*', 'Ġwr', 'at', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['new', '_', 'w', 'Ġ=', 'Ġint', 'Ġ(', 'Ġwidth', 'Ġ*', 'Ġwr', 'at', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['new_w', 'Ġ=', 'Ġint', 'Ġ(', 'Ġwidth', 'Ġ*', 'Ġwrat', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "im . getbbox ( ) , Image . BICUBIC ) \n"
Original    (011): ['im', '.', 'getbbox', '(', ')', ',', 'Image', '.', 'BICUBIC', ')', '\\n']
Tokenized   (019): ['<s>', 'im', 'Ġ.', 'Ġget', 'b', 'box', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠImage', 'Ġ.', 'ĠB', 'IC', 'UB', 'IC', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['im', 'Ġ.', 'Ġget', 'b', 'box', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠImage', 'Ġ.', 'ĠB', 'IC', 'UB', 'IC', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['im', 'Ġ.', 'Ġgetbbox', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠImage', 'Ġ.', 'ĠBICUBIC', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "resize_image ( os . path . abspath ( os . path . join ( , dest + ) ) ) \n"
Original    (021): ['resize_image', '(', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'join', '(', ',', 'dest', '+', ')', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'res', 'ize', '_', 'image', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ,', 'Ġdest', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['res', 'ize', '_', 'image', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ,', 'Ġdest', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['resize_image', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ,', 'Ġdest', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "f_x = Float ( 0.0 , iotype = "out" ) \n"
Original    (011): ['f_x', '=', 'Float', '(', '0.0', ',', 'iotype', '=', '"out"', ')', '\\n']
Tokenized   (021): ['<s>', 'f', '_', 'x', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ"', 'out', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['f', '_', 'x', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ"', 'out', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['f_x', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0.0', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ"out"', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "doe_c = [ 0.1 , 0.2 , 0.3 , 0.5 , 0.7 , 0.8 , 0.9 ] + doe_e \n"
Original    (020): ['doe_c', '=', '[', '0.1', ',', '0.2', ',', '0.3', ',', '0.5', ',', '0.7', ',', '0.8', ',', '0.9', ']', '+', 'doe_e', '\\n']
Tokenized   (043): ['<s>', 'd', 'oe', '_', 'c', 'Ġ=', 'Ġ[', 'Ġ0', '.', '1', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '3', 'Ġ,', 'Ġ0', '.', '5', 'Ġ,', 'Ġ0', '.', '7', 'Ġ,', 'Ġ0', '.', '8', 'Ġ,', 'Ġ0', '.', '9', 'Ġ]', 'Ġ+', 'Ġdo', 'e', '_', 'e', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['d', 'oe', '_', 'c', 'Ġ=', 'Ġ[', 'Ġ0', '.', '1', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '3', 'Ġ,', 'Ġ0', '.', '5', 'Ġ,', 'Ġ0', '.', '7', 'Ġ,', 'Ġ0', '.', '8', 'Ġ,', 'Ġ0', '.', '9', 'Ġ]', 'Ġ+', 'Ġdo', 'e', '_', 'e', 'Ġ\\', 'n']
Detokenized (020): ['doe_c', 'Ġ=', 'Ġ[', 'Ġ0.1', 'Ġ,', 'Ġ0.2', 'Ġ,', 'Ġ0.3', 'Ġ,', 'Ġ0.5', 'Ġ,', 'Ġ0.7', 'Ġ,', 'Ġ0.8', 'Ġ,', 'Ġ0.9', 'Ġ]', 'Ġ+', 'Ġdoe_e', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "responses = ( , ) , nfi = self . nfi ) ) \n"
Original    (014): ['responses', '=', '(', ',', ')', ',', 'nfi', '=', 'self', '.', 'nfi', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'respons', 'es', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġn', 'fi', 'Ġ=', 'Ġself', 'Ġ.', 'Ġn', 'fi', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['respons', 'es', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġn', 'fi', 'Ġ=', 'Ġself', 'Ġ.', 'Ġn', 'fi', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['responses', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġnfi', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnfi', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "sigma_cok = np . array ( [ d . sigma for d in sim_cok . mm_checker . case_outputs . meta_model . f_x ] ) \n"
Original    (025): ['sigma_cok', '=', 'np', '.', 'array', '(', '[', 'd', '.', 'sigma', 'for', 'd', 'in', 'sim_cok', '.', 'mm_checker', '.', 'case_outputs', '.', 'meta_model', '.', 'f_x', ']', ')', '\\n']
Tokenized   (046): ['<s>', 's', 'igma', '_', 'c', 'ok', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġs', 'igma', 'Ġfor', 'Ġd', 'Ġin', 'Ġsim', '_', 'c', 'ok', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmeta', '_', 'model', 'Ġ.', 'Ġf', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['s', 'igma', '_', 'c', 'ok', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġs', 'igma', 'Ġfor', 'Ġd', 'Ġin', 'Ġsim', '_', 'c', 'ok', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmeta', '_', 'model', 'Ġ.', 'Ġf', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['sigma_cok', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġsigma', 'Ġfor', 'Ġd', 'Ġin', 'Ġsim_cok', 'Ġ.', 'Ġmm_checker', 'Ġ.', 'Ġcase_outputs', 'Ġ.', 'Ġmeta_model', 'Ġ.', 'Ġf_x', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "actual = sim_k . mm_checker . case_outputs . model . f_x \n"
Original    (012): ['actual', '=', 'sim_k', '.', 'mm_checker', '.', 'case_outputs', '.', 'model', '.', 'f_x', '\\n']
Tokenized   (025): ['<s>', 'actual', 'Ġ=', 'Ġsim', '_', 'k', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġf', '_', 'x', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['actual', 'Ġ=', 'Ġsim', '_', 'k', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġf', '_', 'x', 'Ġ\\', 'n']
Detokenized (012): ['actual', 'Ġ=', 'Ġsim_k', 'Ġ.', 'Ġmm_checker', 'Ġ.', 'Ġcase_outputs', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġf_x', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "predicted_cok - 2 * sigma_cok , facecolor = , alpha = 0.2 ) \n"
Original    (014): ['predicted_cok', '-', '2', '*', 'sigma_cok', ',', 'facecolor', '=', ',', 'alpha', '=', '0.2', ')', '\\n']
Tokenized   (028): ['<s>', 'pred', 'icted', '_', 'c', 'ok', 'Ġ-', 'Ġ2', 'Ġ*', 'Ġs', 'igma', '_', 'c', 'ok', 'Ġ,', 'Ġface', 'color', 'Ġ=', 'Ġ,', 'Ġalpha', 'Ġ=', 'Ġ0', '.', '2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['pred', 'icted', '_', 'c', 'ok', 'Ġ-', 'Ġ2', 'Ġ*', 'Ġs', 'igma', '_', 'c', 'ok', 'Ġ,', 'Ġface', 'color', 'Ġ=', 'Ġ,', 'Ġalpha', 'Ġ=', 'Ġ0', '.', '2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['predicted_cok', 'Ġ-', 'Ġ2', 'Ġ*', 'Ġsigma_cok', 'Ġ,', 'Ġfacecolor', 'Ġ=', 'Ġ,', 'Ġalpha', 'Ġ=', 'Ġ0.2', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "newsetupfile = os . path . join ( os . path . dirname ( setupfile ) , \n"
Original    (018): ['newsetupfile', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dirname', '(', 'setupfile', ')', ',', '\\n']
Tokenized   (025): ['<s>', 'new', 'setup', 'file', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġsetup', 'file', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', 'setup', 'file', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġsetup', 'file', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (018): ['newsetupfile', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġsetupfile', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "srcdir = os . path . abspath ( os . path . expanduser ( srcdir ) ) . replace ( , ) \n"
Original    (023): ['srcdir', '=', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'expanduser', '(', 'srcdir', ')', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (030): ['<s>', 'src', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġsrc', 'dir', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['src', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġsrc', 'dir', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['srcdir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpanduser', 'Ġ(', 'Ġsrcdir', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "cmd . extend ( [ , destdir ] ) \n"
Original    (010): ['cmd', '.', 'extend', '(', '[', ',', 'destdir', ']', ')', '\\n']
Tokenized   (014): ['<s>', 'cmd', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġdest', 'dir', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['cmd', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġdest', 'dir', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['cmd', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġdestdir', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "list ( newfiles ) ) \n"
Original    (006): ['list', '(', 'newfiles', ')', ')', '\\n']
Tokenized   (010): ['<s>', 'list', 'Ġ(', 'Ġnew', 'files', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['list', 'Ġ(', 'Ġnew', 'files', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['list', 'Ġ(', 'Ġnewfiles', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "destdir = os . path . abspath ( os . path . expanduser ( options . destdir ) ) \n"
Original    (020): ['destdir', '=', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'expanduser', '(', 'options', '.', 'destdir', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'dest', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġdest', 'dir', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['dest', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġdest', 'dir', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['destdir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpanduser', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġdestdir', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "all_names . extend ( [ prefix + name \n"
Original    (009): ['all_names', '.', 'extend', '(', '[', 'prefix', '+', 'name', '\\n']
Tokenized   (014): ['<s>', 'all', '_', 'names', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġname', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['all', '_', 'names', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġname', 'Ġ\\', 'n']
Detokenized (009): ['all_names', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġname', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "lnames = [ prefix + rec for rec in driver [ ] ] \n"
Original    (014): ['lnames', '=', '[', 'prefix', '+', 'rec', 'for', 'rec', 'in', 'driver', '[', ']', ']', '\\n']
Tokenized   (018): ['<s>', 'l', 'names', 'Ġ=', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġrec', 'Ġfor', 'Ġrec', 'Ġin', 'Ġdriver', 'Ġ[', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['l', 'names', 'Ġ=', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġrec', 'Ġfor', 'Ġrec', 'Ġin', 'Ġdriver', 'Ġ[', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['lnames', 'Ġ=', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġrec', 'Ġfor', 'Ġrec', 'Ġin', 'Ġdriver', 'Ġ[', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "driver_grp = self . _inp [ ] [ driver_name ] \n"
Original    (011): ['driver_grp', '=', 'self', '.', '_inp', '[', ']', '[', 'driver_name', ']', '\\n']
Tokenized   (021): ['<s>', 'driver', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['driver', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['driver_grp', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_inp', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver_name', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "iteration_grp = self . _inp [ ] [ driver_name ] [ iteration_case_name ] \n"
Original    (014): ['iteration_grp', '=', 'self', '.', '_inp', '[', ']', '[', 'driver_name', ']', '[', 'iteration_case_name', ']', '\\n']
Tokenized   (029): ['<s>', 'iter', 'ation', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ[', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['iter', 'ation', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ[', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['iteration_grp', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_inp', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver_name', 'Ġ]', 'Ġ[', 'Ġiteration_case_name', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "info = self . read_iteration_case_from_hdf5 ( self . _inp , driver_name , iteration_case_name ) yield info \n"
Original    (017): ['info', '=', 'self', '.', 'read_iteration_case_from_hdf5', '(', 'self', '.', '_inp', ',', 'driver_name', ',', 'iteration_case_name', ')', 'yield', 'info', '\\n']
Tokenized   (039): ['<s>', 'info', 'Ġ=', 'Ġself', 'Ġ.', 'Ġread', '_', 'iter', 'ation', '_', 'case', '_', 'from', '_', 'h', 'df', '5', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ,', 'Ġdriver', '_', 'name', 'Ġ,', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ)', 'Ġyield', 'Ġinfo', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['info', 'Ġ=', 'Ġself', 'Ġ.', 'Ġread', '_', 'iter', 'ation', '_', 'case', '_', 'from', '_', 'h', 'df', '5', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ,', 'Ġdriver', '_', 'name', 'Ġ,', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ)', 'Ġyield', 'Ġinfo', 'Ġ\\', 'n']
Detokenized (017): ['info', 'Ġ=', 'Ġself', 'Ġ.', 'Ġread_iteration_case_from_hdf5', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_inp', 'Ġ,', 'Ġdriver_name', 'Ġ,', 'Ġiteration_case_name', 'Ġ)', 'Ġyield', 'Ġinfo', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sleep_time = Float ( 0.0 , iotype = , desc = ) \n"
Original    (013): ['sleep_time', '=', 'Float', '(', '0.0', ',', 'iotype', '=', ',', 'desc', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'sleep', '_', 'time', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġdesc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['sleep', '_', 'time', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġdesc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['sleep_time', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0.0', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġdesc', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "accuracy = Float ( 1.0e-6 , iotype = , \n"
Original    (010): ['accuracy', '=', 'Float', '(', '1.0e-6', ',', 'iotype', '=', ',', '\\n']
Tokenized   (020): ['<s>', 'acc', 'uracy', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ1', '.', '0', 'e', '-', '6', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['acc', 'uracy', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ1', '.', '0', 'e', '-', '6', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['accuracy', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ1.0e-6', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "iprint = Enum ( 0 , [ 0 , 1 , 2 , 3 ] , iotype = , \n"
Original    (020): ['iprint', '=', 'Enum', '(', '0', ',', '[', '0', ',', '1', ',', '2', ',', '3', ']', ',', 'iotype', '=', ',', '\\n']
Tokenized   (026): ['<s>', 'ip', 'rint', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['ip', 'rint', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['iprint', 'Ġ=', 'ĠEnum', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "output_filename = Str ( , iotype = , \n"
Original    (009): ['output_filename', '=', 'Str', '(', ',', 'iotype', '=', ',', '\\n']
Tokenized   (015): ['<s>', 'output', '_', 'filename', 'Ġ=', 'ĠStr', 'Ġ(', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['output', '_', 'filename', 'Ġ=', 'ĠStr', 'Ġ(', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['output_filename', 'Ġ=', 'ĠStr', 'Ġ(', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "la = max ( m , 1 ) \n"
Original    (009): ['la', '=', 'max', '(', 'm', ',', '1', ')', '\\n']
Tokenized   (012): ['<s>', 'la', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġm', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['la', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġm', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['la', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġm', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "gg = zeros ( [ la ] , ) \n"
Original    (010): ['gg', '=', 'zeros', '(', '[', 'la', ']', ',', ')', '\\n']
Tokenized   (014): ['<s>', 'gg', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['gg', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['gg', 'Ġ=', 'Ġzeros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "dg = zeros ( [ la , n + 1 ] , ) \n"
Original    (014): ['dg', '=', 'zeros', '(', '[', 'la', ',', 'n', '+', '1', ']', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'd', 'g', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ,', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['d', 'g', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ,', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['dg', 'Ġ=', 'Ġzeros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ,', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "mineq = m - meq + 2 * ( n + 1 ) \n"
Original    (014): ['mineq', '=', 'm', '-', 'meq', '+', '2', '*', '(', 'n', '+', '1', ')', '\\n']
Tokenized   (019): ['<s>', 'mine', 'q', 'Ġ=', 'Ġm', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mine', 'q', 'Ġ=', 'Ġm', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['mineq', 'Ġ=', 'Ġm', 'Ġ-', 'Ġmeq', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "lsq = ( n + 1 ) * ( ( n + 1 ) + 1 ) + meq * ( ( n + 1 ) + 1 ) + mineq * ( ( n + 1 ) + 1 ) \n"
Original    (042): ['lsq', '=', '(', 'n', '+', '1', ')', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'meq', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'mineq', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '\\n']
Tokenized   (048): ['<s>', 'ls', 'q', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġme', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['ls', 'q', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġme', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (042): ['lsq', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmeq', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmineq', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 42, 768)
# Extracted words:  42
Sentence         : "lsi = ( ( n + 1 ) - meq + 1 ) * ( mineq + 2 ) + 2 * mineq \n"
Original    (024): ['lsi', '=', '(', '(', 'n', '+', '1', ')', '-', 'meq', '+', '1', ')', '*', '(', 'mineq', '+', '2', ')', '+', '2', '*', 'mineq', '\\n']
Tokenized   (031): ['<s>', 'ls', 'i', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġmine', 'q', 'Ġ+', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmine', 'q', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['ls', 'i', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġmine', 'q', 'Ġ+', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmine', 'q', 'Ġ\\', 'n']
Detokenized (024): ['lsi', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġmeq', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġmineq', 'Ġ+', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmineq', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "lsei = ( ( n + 1 ) + mineq ) * ( ( n + 1 ) - meq ) + 2 * meq + ( n + 1 ) \n"
Original    (032): ['lsei', '=', '(', '(', 'n', '+', '1', ')', '+', 'mineq', ')', '*', '(', '(', 'n', '+', '1', ')', '-', 'meq', ')', '+', '2', '*', 'meq', '+', '(', 'n', '+', '1', ')', '\\n']
Tokenized   (039): ['<s>', 'l', 'sei', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġme', 'q', 'Ġ+', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['l', 'sei', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġme', 'q', 'Ġ+', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (032): ['lsei', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmineq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġmeq', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmeq', 'Ġ+', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "slsqpb = ( n + 1 ) * ( n / 2 ) + 2 * m + 3 * n + 3 * ( n + 1 ) + 1 \n"
Original    (032): ['slsqpb', '=', '(', 'n', '+', '1', ')', '*', '(', 'n', '/', '2', ')', '+', '2', '*', 'm', '+', '3', '*', 'n', '+', '3', '*', '(', 'n', '+', '1', ')', '+', '1', '\\n']
Tokenized   (037): ['<s>', 'sl', 'sq', 'pb', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ/', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġm', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġn', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['sl', 'sq', 'pb', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ/', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġm', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġn', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (032): ['slsqpb', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ/', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġm', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġn', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "lw = lsq + lsi + lsei + slsqpb + n + m \n"
Original    (014): ['lw', '=', 'lsq', '+', 'lsi', '+', 'lsei', '+', 'slsqpb', '+', 'n', '+', 'm', '\\n']
Tokenized   (023): ['<s>', 'l', 'w', 'Ġ=', 'Ġl', 'sq', 'Ġ+', 'Ġl', 'si', 'Ġ+', 'Ġl', 'sei', 'Ġ+', 'Ġsl', 'sq', 'pb', 'Ġ+', 'Ġn', 'Ġ+', 'Ġm', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['l', 'w', 'Ġ=', 'Ġl', 'sq', 'Ġ+', 'Ġl', 'si', 'Ġ+', 'Ġl', 'sei', 'Ġ+', 'Ġsl', 'sq', 'pb', 'Ġ+', 'Ġn', 'Ġ+', 'Ġm', 'Ġ\\', 'n']
Detokenized (014): ['lw', 'Ġ=', 'Ġlsq', 'Ġ+', 'Ġlsi', 'Ġ+', 'Ġlsei', 'Ġ+', 'Ġslsqpb', 'Ġ+', 'Ġn', 'Ġ+', 'Ġm', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "ljw = max ( mineq , ( n + 1 ) - meq ) \n"
Original    (015): ['ljw', '=', 'max', '(', 'mineq', ',', '(', 'n', '+', '1', ')', '-', 'meq', ')', '\\n']
Tokenized   (022): ['<s>', 'l', 'j', 'w', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġmine', 'q', 'Ġ,', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['l', 'j', 'w', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġmine', 'q', 'Ġ,', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['ljw', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġmineq', 'Ġ,', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġmeq', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "_iodict = { : , : } \n"
Original    (008): ['_iodict', '=', '{', ':', ',', ':', '}', '\\n']
Tokenized   (013): ['<s>', '_', 'iod', 'ict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['_', 'iod', 'ict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['_iodict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "state [ ] = { } \n"
Original    (007): ['state', '[', ']', '=', '{', '}', '\\n']
Tokenized   (010): ['<s>', 'state', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['state', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['state', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "key = ( addr_type , addr , proxy . _authkey ) \n"
Original    (012): ['key', '=', '(', 'addr_type', ',', 'addr', ',', 'proxy', '.', '_authkey', ')', '\\n']
Tokenized   (019): ['<s>', 'key', 'Ġ=', 'Ġ(', 'Ġaddr', '_', 'type', 'Ġ,', 'Ġaddr', 'Ġ,', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['key', 'Ġ=', 'Ġ(', 'Ġaddr', '_', 'type', 'Ġ,', 'Ġaddr', 'Ġ,', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['key', 'Ġ=', 'Ġ(', 'Ġaddr_type', 'Ġ,', 'Ġaddr', 'Ġ,', 'Ġproxy', 'Ġ.', 'Ġ_authkey', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "address = ( ip_addr , 0 ) \n"
Original    (008): ['address', '=', '(', 'ip_addr', ',', '0', ')', '\\n']
Tokenized   (013): ['<s>', 'address', 'Ġ=', 'Ġ(', 'Ġip', '_', 'addr', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['address', 'Ġ=', 'Ġ(', 'Ġip', '_', 'addr', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['address', 'Ġ=', 'Ġ(', 'Ġip_addr', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "access = addr if addr_type == else addr_type \n"
Original    (009): ['access', '=', 'addr', 'if', 'addr_type', '==', 'else', 'addr_type', '\\n']
Tokenized   (016): ['<s>', 'access', 'Ġ=', 'Ġaddr', 'Ġif', 'Ġaddr', '_', 'type', 'Ġ==', 'Ġelse', 'Ġaddr', '_', 'type', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['access', 'Ġ=', 'Ġaddr', 'Ġif', 'Ġaddr', '_', 'type', 'Ġ==', 'Ġelse', 'Ġaddr', '_', 'type', 'Ġ\\', 'n']
Detokenized (009): ['access', 'Ġ=', 'Ġaddr', 'Ġif', 'Ġaddr_type', 'Ġ==', 'Ġelse', 'Ġaddr_type', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "manager = ObjectManager ( self , address , authkey = proxy . _authkey , \n"
Original    (015): ['manager', '=', 'ObjectManager', '(', 'self', ',', 'address', ',', 'authkey', '=', 'proxy', '.', '_authkey', ',', '\\n']
Tokenized   (022): ['<s>', 'manager', 'Ġ=', 'ĠObject', 'Manager', 'Ġ(', 'Ġself', 'Ġ,', 'Ġaddress', 'Ġ,', 'Ġauth', 'key', 'Ġ=', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['manager', 'Ġ=', 'ĠObject', 'Manager', 'Ġ(', 'Ġself', 'Ġ,', 'Ġaddress', 'Ġ,', 'Ġauth', 'key', 'Ġ=', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['manager', 'Ġ=', 'ĠObjectManager', 'Ġ(', 'Ġself', 'Ġ,', 'Ġaddress', 'Ġ,', 'Ġauthkey', 'Ġ=', 'Ġproxy', 'Ġ.', 'Ġ_authkey', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "match_dict = self . _alltraits ( ** metadata ) \n"
Original    (010): ['match_dict', '=', 'self', '.', '_alltraits', '(', '**', 'metadata', ')', '\\n']
Tokenized   (018): ['<s>', 'match', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'all', 'tra', 'its', 'Ġ(', 'Ġ**', 'Ġmetadata', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['match', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'all', 'tra', 'its', 'Ġ(', 'Ġ**', 'Ġmetadata', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['match_dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_alltraits', 'Ġ(', 'Ġ**', 'Ġmetadata', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "childname , _ , restofpath = traitpath . partition ( ) \n"
Original    (012): ['childname', ',', '_', ',', 'restofpath', '=', 'traitpath', '.', 'partition', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'child', 'name', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġrest', 'of', 'path', 'Ġ=', 'Ġtrait', 'path', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['child', 'name', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġrest', 'of', 'path', 'Ġ=', 'Ġtrait', 'path', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['childname', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġrestofpath', 'Ġ=', 'Ġtraitpath', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mdict . setdefault ( , t . __class__ . __name__ ) \n"
Original    (012): ['mdict', '.', 'setdefault', '(', ',', 't', '.', '__class__', '.', '__name__', ')', '\\n']
Tokenized   (021): ['<s>', 'md', 'ict', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġt', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['md', 'ict', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġt', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['mdict', 'Ġ.', 'Ġsetdefault', 'Ġ(', 'Ġ,', 'Ġt', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "expr = compile ( assign , assign , mode = ) \n"
Original    (012): ['expr', '=', 'compile', '(', 'assign', ',', 'assign', ',', 'mode', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'expr', 'Ġ=', 'Ġcompile', 'Ġ(', 'Ġassign', 'Ġ,', 'Ġassign', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['expr', 'Ġ=', 'Ġcompile', 'Ġ(', 'Ġassign', 'Ġ,', 'Ġassign', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['expr', 'Ġ=', 'Ġcompile', 'Ġ(', 'Ġassign', 'Ġ,', 'Ġassign', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "tstamp = % ( now . year , now . month , now . day , now . hour , now . minute ) \n"
Original    (025): ['tstamp', '=', '%', '(', 'now', '.', 'year', ',', 'now', '.', 'month', ',', 'now', '.', 'day', ',', 'now', '.', 'hour', ',', 'now', '.', 'minute', ')', '\\n']
Tokenized   (030): ['<s>', 't', 'st', 'amp', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġnow', 'Ġ.', 'Ġyear', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġmonth', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġday', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġhour', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġminute', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['t', 'st', 'amp', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġnow', 'Ġ.', 'Ġyear', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġmonth', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġday', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġhour', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġminute', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['tstamp', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġnow', 'Ġ.', 'Ġyear', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġmonth', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġday', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġhour', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġminute', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "entry_pts = [ ( self , name , _get_entry_group ( self ) ) ] \n"
Original    (015): ['entry_pts', '=', '[', '(', 'self', ',', 'name', ',', '_get_entry_group', '(', 'self', ')', ')', ']', '\\n']
Tokenized   (026): ['<s>', 'entry', '_', 'pt', 's', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġself', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ_', 'get', '_', 'entry', '_', 'group', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['entry', '_', 'pt', 's', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġself', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ_', 'get', '_', 'entry', '_', 'group', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['entry_pts', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġself', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ_get_entry_group', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "root_start = root_start + 1 if root_start >= 0 else 0 \n"
Original    (012): ['root_start', '=', 'root_start', '+', '1', 'if', 'root_start', '>=', '0', 'else', '0', '\\n']
Tokenized   (021): ['<s>', 'root', '_', 'start', 'Ġ=', 'Ġroot', '_', 'start', 'Ġ+', 'Ġ1', 'Ġif', 'Ġroot', '_', 'start', 'Ġ>=', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['root', '_', 'start', 'Ġ=', 'Ġroot', '_', 'start', 'Ġ+', 'Ġ1', 'Ġif', 'Ġroot', '_', 'start', 'Ġ>=', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n']
Detokenized (012): ['root_start', 'Ġ=', 'Ġroot_start', 'Ġ+', 'Ġ1', 'Ġif', 'Ġroot_start', 'Ġ>=', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "root_pathname += \n"
Original    (003): ['root_pathname', '+=', '\\n']
Tokenized   (009): ['<s>', 'root', '_', 'path', 'name', 'Ġ+=', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['root', '_', 'path', 'name', 'Ġ+=', 'Ġ\\', 'n']
Detokenized (003): ['root_pathname', 'Ġ+=', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "Container . _bases ( type ( obj ) , names ) \n"
Original    (012): ['Container', '.', '_bases', '(', 'type', '(', 'obj', ')', ',', 'names', ')', '\\n']
Tokenized   (017): ['<s>', 'Container', 'Ġ.', 'Ġ_', 'b', 'ases', 'Ġ(', 'Ġtype', 'Ġ(', 'Ġobj', 'Ġ)', 'Ġ,', 'Ġnames', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['Container', 'Ġ.', 'Ġ_', 'b', 'ases', 'Ġ(', 'Ġtype', 'Ġ(', 'Ġobj', 'Ġ)', 'Ġ,', 'Ġnames', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['Container', 'Ġ.', 'Ġ_bases', 'Ġ(', 'Ġtype', 'Ġ(', 'Ġobj', 'Ġ)', 'Ġ,', 'Ġnames', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "names . append ( % ( cls . __module__ , cls . __name__ ) ) \n"
Original    (016): ['names', '.', 'append', '(', '%', '(', 'cls', '.', '__module__', ',', 'cls', '.', '__name__', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'module', '__', 'Ġ,', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'module', '__', 'Ġ,', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġcls', 'Ġ.', 'Ġ__module__', 'Ġ,', 'Ġcls', 'Ġ.', 'Ġ__name__', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "_get_entry_group . group_map = [ \n"
Original    (006): ['_get_entry_group', '.', 'group_map', '=', '[', '\\n']
Tokenized   (016): ['<s>', '_', 'get', '_', 'entry', '_', 'group', 'Ġ.', 'Ġgroup', '_', 'map', 'Ġ=', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['_', 'get', '_', 'entry', '_', 'group', 'Ġ.', 'Ġgroup', '_', 'map', 'Ġ=', 'Ġ[', 'Ġ\\', 'n']
Detokenized (006): ['_get_entry_group', 'Ġ.', 'Ġgroup_map', 'Ġ=', 'Ġ[', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "pprint . pprint ( dict ( [ ( n , str ( v ) ) \n"
Original    (016): ['pprint', '.', 'pprint', '(', 'dict', '(', '[', '(', 'n', ',', 'str', '(', 'v', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'pp', 'rint', 'Ġ.', 'Ġp', 'print', 'Ġ(', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġn', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['pp', 'rint', 'Ġ.', 'Ġp', 'print', 'Ġ(', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġn', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['pprint', 'Ġ.', 'Ġpprint', 'Ġ(', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġn', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "** metadata ) ] ) , \n"
Original    (007): ['**', 'metadata', ')', ']', ')', ',', '\\n']
Tokenized   (010): ['<s>', '**', 'Ġmetadata', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['**', 'Ġmetadata', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['**', 'Ġmetadata', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "io_attr [ ] = \n"
Original    (005): ['io_attr', '[', ']', '=', '\\n']
Tokenized   (010): ['<s>', 'io', '_', 'attr', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['io', '_', 'attr', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ\\', 'n']
Detokenized (005): ['io_attr', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "_redirect_streams ( ofile . fileno ( ) ) \n"
Original    (009): ['_redirect_streams', '(', 'ofile', '.', 'fileno', '(', ')', ')', '\\n']
Tokenized   (019): ['<s>', '_', 'red', 'irect', '_', 'stream', 's', 'Ġ(', 'Ġof', 'ile', 'Ġ.', 'Ġfil', 'eno', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['_', 'red', 'irect', '_', 'stream', 's', 'Ġ(', 'Ġof', 'ile', 'Ġ.', 'Ġfil', 'eno', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['_redirect_streams', 'Ġ(', 'Ġofile', 'Ġ.', 'Ġfileno', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "leftover = arr_size % num_divisions \n"
Original    (006): ['leftover', '=', 'arr_size', '%', 'num_divisions', '\\n']
Tokenized   (015): ['<s>', 'left', 'over', 'Ġ=', 'Ġarr', '_', 'size', 'Ġ%', 'Ġnum', '_', 'div', 'isions', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['left', 'over', 'Ġ=', 'Ġarr', '_', 'size', 'Ġ%', 'Ġnum', '_', 'div', 'isions', 'Ġ\\', 'n']
Detokenized (006): ['leftover', 'Ġ=', 'Ġarr_size', 'Ġ%', 'Ġnum_divisions', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "sizes [ : leftover ] += 1 \n"
Original    (008): ['sizes', '[', ':', 'leftover', ']', '+=', '1', '\\n']
Tokenized   (012): ['<s>', 's', 'izes', 'Ġ[', 'Ġ:', 'Ġleftover', 'Ġ]', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['s', 'izes', 'Ġ[', 'Ġ:', 'Ġleftover', 'Ġ]', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n']
Detokenized (008): ['sizes', 'Ġ[', 'Ġ:', 'Ġleftover', 'Ġ]', 'Ġ+=', 'Ġ1', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "offsets [ 1 : ] = numpy . cumsum ( sizes ) [ : - 1 ] \n"
Original    (018): ['offsets', '[', '1', ':', ']', '=', 'numpy', '.', 'cumsum', '(', 'sizes', ')', '[', ':', '-', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'offs', 'ets', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġc', 'ums', 'um', 'Ġ(', 'Ġsizes', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['offs', 'ets', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġc', 'ums', 'um', 'Ġ(', 'Ġsizes', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['offsets', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġcumsum', 'Ġ(', 'Ġsizes', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "z1 = Float ( 0. , iotype = ) \n"
Original    (010): ['z1', '=', 'Float', '(', '0.', ',', 'iotype', '=', ')', '\\n']
Tokenized   (016): ['<s>', 'z', '1', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['z', '1', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['z1', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0.', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "z_store = Array ( [ 0. , 0. ] , iotype = ) \n"
Original    (014): ['z_store', '=', 'Array', '(', '[', '0.', ',', '0.', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (022): ['<s>', 'z', '_', 'store', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ,', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['z', '_', 'store', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ,', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['z_store', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0.', 'Ġ,', 'Ġ0.', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "ssa_F = Array ( [ 0.0 ] , iotype = ) \n"
Original    (012): ['ssa_F', '=', 'Array', '(', '[', '0.0', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'ss', 'a', '_', 'F', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['ss', 'a', '_', 'F', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['ssa_F', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0.0', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ssa_dG = Array ( [ [ 0.0 , 0.0 ] , [ 0.0 , 0.0 ] ] , iotype = ) \n"
Original    (022): ['ssa_dG', '=', 'Array', '(', '[', '[', '0.0', ',', '0.0', ']', ',', '[', '0.0', ',', '0.0', ']', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (038): ['<s>', 'ss', 'a', '_', 'd', 'G', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['ss', 'a', '_', 'd', 'G', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['ssa_dG', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0.0', 'Ġ,', 'Ġ0.0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ0.0', 'Ġ,', 'Ġ0.0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "arr_out = Array ( [ 1. , 2. , 3. ] , iotype = , units = ) \n"
Original    (019): ['arr_out', '=', 'Array', '(', '[', '1.', ',', '2.', ',', '3.', ']', ',', 'iotype', '=', ',', 'units', '=', ')', '\\n']
Tokenized   (028): ['<s>', 'arr', '_', 'out', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ1', '.', 'Ġ,', 'Ġ2', '.', 'Ġ,', 'Ġ3', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['arr', '_', 'out', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ1', '.', 'Ġ,', 'Ġ2', '.', 'Ġ,', 'Ġ3', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['arr_out', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ1.', 'Ġ,', 'Ġ2.', 'Ġ,', 'Ġ3.', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "arg [ ] = np . array ( [ 3.1 ] ) \n"
Original    (013): ['arg', '[', ']', '=', 'np', '.', 'array', '(', '[', '3.1', ']', ')', '\\n']
Tokenized   (018): ['<s>', 'arg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ3', '.', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['arg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ3', '.', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['arg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ3.1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "jacs [ ] = np . array ( [ [ 100.0 , 101 , 102 , 103 ] , \n"
Original    (020): ['jacs', '[', ']', '=', 'np', '.', 'array', '(', '[', '[', '100.0', ',', '101', ',', '102', ',', '103', ']', ',', '\\n']
Tokenized   (026): ['<s>', 'j', 'acs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ100', '.', '0', 'Ġ,', 'Ġ101', 'Ġ,', 'Ġ102', 'Ġ,', 'Ġ103', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['j', 'acs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ100', '.', '0', 'Ġ,', 'Ġ101', 'Ġ,', 'Ġ102', 'Ġ,', 'Ġ103', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['jacs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ100.0', 'Ġ,', 'Ġ101', 'Ġ,', 'Ġ102', 'Ġ,', 'Ġ103', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "assert_rel_error ( self , J [ 3 ] [ 0 ] , 3.0 , 1e-5 ) \n"
Original    (017): ['assert_rel_error', '(', 'self', ',', 'J', '[', '3', ']', '[', '0', ']', ',', '3.0', ',', '1e-5', ')', '\\n']
Tokenized   (029): ['<s>', 'assert', '_', 'rel', '_', 'error', 'Ġ(', 'Ġself', 'Ġ,', 'ĠJ', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ3', '.', '0', 'Ġ,', 'Ġ1', 'e', '-', '5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['assert', '_', 'rel', '_', 'error', 'Ġ(', 'Ġself', 'Ġ,', 'ĠJ', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ3', '.', '0', 'Ġ,', 'Ġ1', 'e', '-', '5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['assert_rel_error', 'Ġ(', 'Ġself', 'Ġ,', 'ĠJ', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ3.0', 'Ġ,', 'Ġ1e-5', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "newval = _getformat ( val ) % val \n"
Original    (009): ['newval', '=', '_getformat', '(', 'val', ')', '%', 'val', '\\n']
Tokenized   (015): ['<s>', 'new', 'val', 'Ġ=', 'Ġ_', 'get', 'format', 'Ġ(', 'Ġval', 'Ġ)', 'Ġ%', 'Ġval', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['new', 'val', 'Ġ=', 'Ġ_', 'get', 'format', 'Ġ(', 'Ġval', 'Ġ)', 'Ġ%', 'Ġval', 'Ġ\\', 'n']
Detokenized (009): ['newval', 'Ġ=', 'Ġ_getformat', 'Ġ(', 'Ġval', 'Ġ)', 'Ġ%', 'Ġval', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newline = re . sub ( self . reg , sub . replace_array , line ) \n"
Original    (017): ['newline', '=', 're', '.', 'sub', '(', 'self', '.', 'reg', ',', 'sub', '.', 'replace_array', ',', 'line', ')', '\\n']
Tokenized   (023): ['<s>', 'new', 'line', 'Ġ=', 'Ġre', 'Ġ.', 'Ġsub', 'Ġ(', 'Ġself', 'Ġ.', 'Ġreg', 'Ġ,', 'Ġsub', 'Ġ.', 'Ġreplace', '_', 'array', 'Ġ,', 'Ġline', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['new', 'line', 'Ġ=', 'Ġre', 'Ġ.', 'Ġsub', 'Ġ(', 'Ġself', 'Ġ.', 'Ġreg', 'Ġ,', 'Ġsub', 'Ġ.', 'Ġreplace', '_', 'array', 'Ġ,', 'Ġline', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['newline', 'Ġ=', 'Ġre', 'Ġ.', 'Ġsub', 'Ġ(', 'Ġself', 'Ġ.', 'Ġreg', 'Ġ,', 'Ġsub', 'Ġ.', 'Ġreplace_array', 'Ġ,', 'Ġline', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "fields = self . _parse_line ( ) . parseString ( line . replace ( key , "KeyField" ) ) \n"
Original    (020): ['fields', '=', 'self', '.', '_parse_line', '(', ')', '.', 'parseString', '(', 'line', '.', 'replace', '(', 'key', ',', '"KeyField"', ')', ')', '\\n']
Tokenized   (030): ['<s>', 'fields', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'parse', '_', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġparse', 'String', 'Ġ(', 'Ġline', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġkey', 'Ġ,', 'Ġ"', 'Key', 'Field', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['fields', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'parse', '_', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġparse', 'String', 'Ġ(', 'Ġline', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġkey', 'Ġ,', 'Ġ"', 'Key', 'Field', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['fields', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_parse_line', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠparseString', 'Ġ(', 'Ġline', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġkey', 'Ġ,', 'Ġ"KeyField"', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "j2 = self . current_row + rowend + 1 \n"
Original    (010): ['j2', '=', 'self', '.', 'current_row', '+', 'rowend', '+', '1', '\\n']
Tokenized   (017): ['<s>', 'j', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcurrent', '_', 'row', 'Ġ+', 'Ġrow', 'end', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['j', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcurrent', '_', 'row', 'Ġ+', 'Ġrow', 'end', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (010): ['j2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcurrent_row', 'Ġ+', 'Ġrowend', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ee = CaselessLiteral ( ) | CaselessLiteral ( ) \n"
Original    (010): ['ee', '=', 'CaselessLiteral', '(', ')', '|', 'CaselessLiteral', '(', ')', '\\n']
Tokenized   (021): ['<s>', 'ee', 'Ġ=', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ|', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['ee', 'Ġ=', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ|', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['ee', 'Ġ=', 'ĠCaselessLiteral', 'Ġ(', 'Ġ)', 'Ġ|', 'ĠCaselessLiteral', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "num_int = ToInteger ( Combine ( Optional ( sign ) + digits ) ) \n"
Original    (015): ['num_int', '=', 'ToInteger', '(', 'Combine', '(', 'Optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'num', '_', 'int', 'Ġ=', 'ĠTo', 'Integer', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['num', '_', 'int', 'Ġ=', 'ĠTo', 'Integer', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['num_int', 'Ġ=', 'ĠToInteger', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "num_float = ToFloat ( Combine ( Optional ( sign ) + \n"
Original    (012): ['num_float', '=', 'ToFloat', '(', 'Combine', '(', 'Optional', '(', 'sign', ')', '+', '\\n']
Tokenized   (018): ['<s>', 'num', '_', 'float', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['num', '_', 'float', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (012): ['num_float', 'Ġ=', 'ĠToFloat', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Optional ( ee + Optional ( sign ) + digits ) \n"
Original    (012): ['Optional', '(', 'ee', '+', 'Optional', '(', 'sign', ')', '+', 'digits', ')', '\\n']
Tokenized   (016): ['<s>', 'Optional', 'Ġ(', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['Optional', 'Ġ(', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['Optional', 'Ġ(', 'Ġee', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mixed_exp = ToFloat ( Combine ( digits + ee + Optional ( sign ) + digits ) ) \n"
Original    (019): ['mixed_exp', '=', 'ToFloat', '(', 'Combine', '(', 'digits', '+', 'ee', '+', 'Optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'm', 'ixed', '_', 'exp', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'Ġdigits', 'Ġ+', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['m', 'ixed', '_', 'exp', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'Ġdigits', 'Ġ+', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['mixed_exp', 'Ġ=', 'ĠToFloat', 'Ġ(', 'ĠCombine', 'Ġ(', 'Ġdigits', 'Ġ+', 'Ġee', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "string_text ) ) ) \n"
Original    (005): ['string_text', ')', ')', ')', '\\n']
Tokenized   (010): ['<s>', 'string', '_', 'text', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['string', '_', 'text', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['string_text', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "J [ , ] = - 1.0 \n"
Original    (008): ['J', '[', ',', ']', '=', '-', '1.0', '\\n']
Tokenized   (013): ['<s>', 'J', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ1', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['J', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ1', '.', '0', 'Ġ\\', 'n']
Detokenized (008): ['J', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ1.0', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "top [ ] = - 7.0 \n"
Original    (007): ['top', '[', ']', '=', '-', '7.0', '\\n']
Tokenized   (012): ['<s>', 'top', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ7', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['top', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ7', '.', '0', 'Ġ\\', 'n']
Detokenized (007): ['top', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ7.0', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "lhs , op , rhs = _parse_constraint ( expr ) \n"
Original    (011): ['lhs', ',', 'op', ',', 'rhs', '=', '_parse_constraint', '(', 'expr', ')', '\\n']
Tokenized   (021): ['<s>', 'l', 'hs', 'Ġ,', 'Ġop', 'Ġ,', 'Ġrh', 's', 'Ġ=', 'Ġ_', 'parse', '_', 'con', 'str', 'aint', 'Ġ(', 'Ġexpr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['l', 'hs', 'Ġ,', 'Ġop', 'Ġ,', 'Ġrh', 's', 'Ġ=', 'Ġ_', 'parse', '_', 'con', 'str', 'aint', 'Ġ(', 'Ġexpr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['lhs', 'Ġ,', 'Ġop', 'Ġ,', 'Ġrhs', 'Ġ=', 'Ġ_parse_constraint', 'Ġ(', 'Ġexpr', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "first , second = ( rhs , lhs ) if op . startswith ( ) else ( lhs , rhs ) \n"
Original    (022): ['first', ',', 'second', '=', '(', 'rhs', ',', 'lhs', ')', 'if', 'op', '.', 'startswith', '(', ')', 'else', '(', 'lhs', ',', 'rhs', ')', '\\n']
Tokenized   (031): ['<s>', 'first', 'Ġ,', 'Ġsecond', 'Ġ=', 'Ġ(', 'Ġrh', 's', 'Ġ,', 'Ġl', 'hs', 'Ġ)', 'Ġif', 'Ġop', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġelse', 'Ġ(', 'Ġl', 'hs', 'Ġ,', 'Ġrh', 's', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['first', 'Ġ,', 'Ġsecond', 'Ġ=', 'Ġ(', 'Ġrh', 's', 'Ġ,', 'Ġl', 'hs', 'Ġ)', 'Ġif', 'Ġop', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġelse', 'Ġ(', 'Ġl', 'hs', 'Ġ,', 'Ġrh', 's', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['first', 'Ġ,', 'Ġsecond', 'Ġ=', 'Ġ(', 'Ġrhs', 'Ġ,', 'Ġlhs', 'Ġ)', 'Ġif', 'Ġop', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġ)', 'Ġelse', 'Ġ(', 'Ġlhs', 'Ġ,', 'Ġrhs', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "input_graph . add_edges_from ( ( ( start , p ) for p in plist [ 1 : ] ) , \n"
Original    (021): ['input_graph', '.', 'add_edges_from', '(', '(', '(', 'start', ',', 'p', ')', 'for', 'p', 'in', 'plist', '[', '1', ':', ']', ')', ',', '\\n']
Tokenized   (032): ['<s>', 'input', '_', 'graph', 'Ġ.', 'Ġadd', '_', 'ed', 'ges', '_', 'from', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġstart', 'Ġ,', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpl', 'ist', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['input', '_', 'graph', 'Ġ.', 'Ġadd', '_', 'ed', 'ges', '_', 'from', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġstart', 'Ġ,', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpl', 'ist', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (021): ['input_graph', 'Ġ.', 'Ġadd_edges_from', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġstart', 'Ġ,', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġplist', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "src_idxs = { src : None } \n"
Original    (008): ['src_idxs', '=', '{', 'src', ':', 'None', '}', '\\n']
Tokenized   (014): ['<s>', 'src', '_', 'id', 'xs', 'Ġ=', 'Ġ{', 'Ġsrc', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['src', '_', 'id', 'xs', 'Ġ=', 'Ġ{', 'Ġsrc', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['src_idxs', 'Ġ=', 'Ġ{', 'Ġsrc', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "units = [ params_dict [ n ] . get ( ) for n in connected_inputs ] \n"
Original    (017): ['units', '=', '[', 'params_dict', '[', 'n', ']', '.', 'get', '(', ')', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Tokenized   (025): ['<s>', 'units', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['units', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['units', 'Ġ=', 'Ġ[', 'Ġparams_dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected_inputs', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "vals = [ params_dict [ n ] [ ] for n in connected_inputs ] \n"
Original    (015): ['vals', '=', '[', 'params_dict', '[', 'n', ']', '[', ']', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Tokenized   (023): ['<s>', 'vals', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['vals', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['vals', 'Ġ=', 'Ġ[', 'Ġparams_dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected_inputs', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tname , t = connected_inputs [ i ] , u \n"
Original    (011): ['tname', ',', 't', '=', 'connected_inputs', '[', 'i', ']', ',', 'u', '\\n']
Tokenized   (018): ['<s>', 't', 'name', 'Ġ,', 'Ġt', 'Ġ=', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġu', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['t', 'name', 'Ġ,', 'Ġt', 'Ġ=', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġu', 'Ġ\\', 'n']
Detokenized (011): ['tname', 'Ġ,', 'Ġt', 'Ġ=', 'Ġconnected_inputs', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġu', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "correct_src = params_dict [ connected_inputs [ 0 ] ] [ ] \n"
Original    (012): ['correct_src', '=', 'params_dict', '[', 'connected_inputs', '[', '0', ']', ']', '[', ']', '\\n']
Tokenized   (022): ['<s>', 'correct', '_', 'src', 'Ġ=', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['correct', '_', 'src', 'Ġ=', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['correct_src', 'Ġ=', 'Ġparams_dict', 'Ġ[', 'Ġconnected_inputs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "sorted ( [ ( v , k ) for k , v in forms . items ( ) ] ) ) ) \n"
Original    (023): ['sorted', '(', '[', '(', 'v', ',', 'k', ')', 'for', 'k', ',', 'v', 'in', 'forms', '.', 'items', '(', ')', ']', ')', ')', ')', '\\n']
Tokenized   (027): ['<s>', 's', 'orted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġv', 'Ġ,', 'Ġk', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġforms', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['s', 'orted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġv', 'Ġ,', 'Ġk', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġforms', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['sorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġv', 'Ġ,', 'Ġk', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġforms', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "full_order = { s . pathname : i for i , s in \n"
Original    (014): ['full_order', '=', '{', 's', '.', 'pathname', ':', 'i', 'for', 'i', ',', 's', 'in', '\\n']
Tokenized   (020): ['<s>', 'full', '_', 'order', 'Ġ=', 'Ġ{', 'Ġs', 'Ġ.', 'Ġpath', 'name', 'Ġ:', 'Ġi', 'Ġfor', 'Ġi', 'Ġ,', 'Ġs', 'Ġin', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['full', '_', 'order', 'Ġ=', 'Ġ{', 'Ġs', 'Ġ.', 'Ġpath', 'name', 'Ġ:', 'Ġi', 'Ġfor', 'Ġi', 'Ġ,', 'Ġs', 'Ġin', 'Ġ\\', 'n']
Detokenized (014): ['full_order', 'Ġ=', 'Ġ{', 'Ġs', 'Ġ.', 'Ġpathname', 'Ġ:', 'Ġi', 'Ġfor', 'Ġi', 'Ġ,', 'Ġs', 'Ġin', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "enumerate ( self . root . subsystems ( recurse = True ) ) } \n"
Original    (015): ['enumerate', '(', 'self', '.', 'root', '.', 'subsystems', '(', 'recurse', '=', 'True', ')', ')', '}', '\\n']
Tokenized   (022): ['<s>', 'en', 'umer', 'ate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġsubsystem', 's', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['en', 'umer', 'ate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġsubsystem', 's', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (015): ['enumerate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġsubsystems', 'Ġ(', 'Ġrecurse', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "ssys = srcs [ 0 ] . rsplit ( , 1 ) [ 0 ] \n"
Original    (016): ['ssys', '=', 'srcs', '[', '0', ']', '.', 'rsplit', '(', ',', '1', ')', '[', '0', ']', '\\n']
Tokenized   (022): ['<s>', 'ss', 'ys', 'Ġ=', 'Ġsrc', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['ss', 'ys', 'Ġ=', 'Ġsrc', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['ssys', 'Ġ=', 'Ġsrcs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġrsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "params_dict , unknowns_dict = self . root . _setup_variables ( ) \n"
Original    (012): ['params_dict', ',', 'unknowns_dict', '=', 'self', '.', 'root', '.', '_setup_variables', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'params', '_', 'dict', 'Ġ,', 'Ġunknown', 's', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'setup', '_', 'vari', 'ables', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['params', '_', 'dict', 'Ġ,', 'Ġunknown', 's', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'setup', '_', 'vari', 'ables', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['params_dict', 'Ġ,', 'Ġunknowns_dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_setup_variables', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "is not Component . setup_distrib ) ) : \n"
Original    (009): ['is', 'not', 'Component', '.', 'setup_distrib', ')', ')', ':', '\\n']
Tokenized   (015): ['<s>', 'is', 'Ġnot', 'ĠComponent', 'Ġ.', 'Ġsetup', '_', 'dist', 'rib', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['is', 'Ġnot', 'ĠComponent', 'Ġ.', 'Ġsetup', '_', 'dist', 'rib', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (009): ['is', 'Ġnot', 'ĠComponent', 'Ġ.', 'Ġsetup_distrib', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "alloc_derivs = not self . root . fd_options [ ] \n"
Original    (011): ['alloc_derivs', '=', 'not', 'self', '.', 'root', '.', 'fd_options', '[', ']', '\\n']
Tokenized   (021): ['<s>', 'alloc', '_', 'der', 'iv', 's', 'Ġ=', 'Ġnot', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġf', 'd', '_', 'options', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['alloc', '_', 'der', 'iv', 's', 'Ġ=', 'Ġnot', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġf', 'd', '_', 'options', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['alloc_derivs', 'Ġ=', 'Ġnot', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġfd_options', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dangling_params = sorted ( set ( [ \n"
Original    (008): ['dangling_params', '=', 'sorted', '(', 'set', '(', '[', '\\n']
Tokenized   (014): ['<s>', 'd', 'angling', '_', 'params', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġset', 'Ġ(', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['d', 'angling', '_', 'params', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġset', 'Ġ(', 'Ġ[', 'Ġ\\', 'n']
Detokenized (008): ['dangling_params', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġset', 'Ġ(', 'Ġ[', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "nocomps = sorted ( [ c . pathname for c in self . root . components ( recurse = True , \n"
Original    (022): ['nocomps', '=', 'sorted', '(', '[', 'c', '.', 'pathname', 'for', 'c', 'in', 'self', '.', 'root', '.', 'components', '(', 'recurse', '=', 'True', ',', '\\n']
Tokenized   (029): ['<s>', 'n', 'ocom', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġfor', 'Ġc', 'Ġin', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġcomponents', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['n', 'ocom', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġfor', 'Ġc', 'Ġin', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġcomponents', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (022): ['nocomps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpathname', 'Ġfor', 'Ġc', 'Ġin', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġcomponents', 'Ġ(', 'Ġrecurse', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "local = True ) \n"
Original    (005): ['local', '=', 'True', ')', '\\n']
Tokenized   (008): ['<s>', 'local', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['local', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['local', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "recorders . extend ( grp . ln_solver . recorders ) \n"
Original    (011): ['recorders', '.', 'extend', '(', 'grp', '.', 'ln_solver', '.', 'recorders', ')', '\\n']
Tokenized   (021): ['<s>', 'rec', 'orders', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ.', 'Ġrecord', 'ers', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['rec', 'orders', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ.', 'Ġrecord', 'ers', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['recorders', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgrp', 'Ġ.', 'Ġln_solver', 'Ġ.', 'Ġrecorders', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "conn_comps . update ( [ s . rsplit ( , 1 ) [ 0 ] \n"
Original    (016): ['conn_comps', '.', 'update', '(', '[', 's', '.', 'rsplit', '(', ',', '1', ')', '[', '0', ']', '\\n']
Tokenized   (023): ['<s>', 'conn', '_', 'com', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ[', 'Ġs', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['conn', '_', 'com', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ[', 'Ġs', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['conn_comps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ[', 'Ġs', 'Ġ.', 'Ġrsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "noconn_comps = sorted ( [ c . pathname \n"
Original    (009): ['noconn_comps', '=', 'sorted', '(', '[', 'c', '.', 'pathname', '\\n']
Tokenized   (018): ['<s>', 'n', 'ocon', 'n', '_', 'com', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['n', 'ocon', 'n', '_', 'com', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġ\\', 'n']
Detokenized (009): ['noconn_comps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpathname', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "strong = [ s for s in nx . strongly_connected_components ( graph ) \n"
Original    (014): ['strong', '=', '[', 's', 'for', 's', 'in', 'nx', '.', 'strongly_connected_components', '(', 'graph', ')', '\\n']
Tokenized   (023): ['<s>', 'strong', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġn', 'x', 'Ġ.', 'Ġstrongly', '_', 'connected', '_', 'comp', 'onents', 'Ġ(', 'Ġgraph', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['strong', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġn', 'x', 'Ġ.', 'Ġstrongly', '_', 'connected', '_', 'comp', 'onents', 'Ġ(', 'Ġgraph', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['strong', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġnx', 'Ġ.', 'Ġstrongly_connected_components', 'Ġ(', 'Ġgraph', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "subs = [ s for s in grp . _subsystems ] \n"
Original    (012): ['subs', '=', '[', 's', 'for', 's', 'in', 'grp', '.', '_subsystems', ']', '\\n']
Tokenized   (020): ['<s>', 'sub', 's', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġgr', 'p', 'Ġ.', 'Ġ_', 'sub', 'system', 's', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['sub', 's', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġgr', 'p', 'Ġ.', 'Ġ_', 'sub', 'system', 's', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['subs', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġgrp', 'Ġ.', 'Ġ_subsystems', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "tups = sorted ( [ ( subs . index ( s ) , s ) for s in relstrong [ - 1 ] ] ) \n"
Original    (026): ['tups', '=', 'sorted', '(', '[', '(', 'subs', '.', 'index', '(', 's', ')', ',', 's', ')', 'for', 's', 'in', 'relstrong', '[', '-', '1', ']', ']', ')', '\\n']
Tokenized   (031): ['<s>', 't', 'ups', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġsubs', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġs', 'Ġ)', 'Ġfor', 'Ġs', 'Ġin', 'Ġrel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['t', 'ups', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġsubs', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġs', 'Ġ)', 'Ġfor', 'Ġs', 'Ġin', 'Ġrel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['tups', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġsubs', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġs', 'Ġ)', 'Ġfor', 'Ġs', 'Ġin', 'Ġrelstrong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "relstrong [ - 1 ] = [ t [ 1 ] for t in tups ] \n"
Original    (017): ['relstrong', '[', '-', '1', ']', '=', '[', 't', '[', '1', ']', 'for', 't', 'in', 'tups', ']', '\\n']
Tokenized   (022): ['<s>', 'rel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġfor', 'Ġt', 'Ġin', 'Ġt', 'ups', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['rel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġfor', 'Ġt', 'Ġin', 'Ġt', 'ups', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['relstrong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġfor', 'Ġt', 'Ġin', 'Ġtups', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "nearest_child ( grp . pathname , n ) for n in out_of_order [ name ] \n"
Original    (016): ['nearest_child', '(', 'grp', '.', 'pathname', ',', 'n', ')', 'for', 'n', 'in', 'out_of_order', '[', 'name', ']', '\\n']
Tokenized   (028): ['<s>', 'ne', 'arest', '_', 'child', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġpath', 'name', 'Ġ,', 'Ġn', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġout', '_', 'of', '_', 'order', 'Ġ[', 'Ġname', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['ne', 'arest', '_', 'child', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġpath', 'name', 'Ġ,', 'Ġn', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġout', '_', 'of', '_', 'order', 'Ġ[', 'Ġname', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['nearest_child', 'Ġ(', 'Ġgrp', 'Ġ.', 'Ġpathname', 'Ġ,', 'Ġn', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġout_of_order', 'Ġ[', 'Ġname', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "pbos = [ var for var in vec if vec . metadata ( var ) . get ( ) ] \n"
Original    (021): ['pbos', '=', '[', 'var', 'for', 'var', 'in', 'vec', 'if', 'vec', '.', 'metadata', '(', 'var', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (025): ['<s>', 'p', 'bos', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġvec', 'Ġif', 'Ġvec', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġvar', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['p', 'bos', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġvec', 'Ġif', 'Ġvec', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġvar', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['pbos', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġvec', 'Ġif', 'Ġvec', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġvar', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "iteritems ( self . root . _params_dict ) ) : \n"
Original    (011): ['iteritems', '(', 'self', '.', 'root', '.', '_params_dict', ')', ')', ':', '\\n']
Tokenized   (018): ['<s>', 'iter', 'items', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['iter', 'items', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (011): ['iteritems', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_params_dict', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dv_scale = None , cn_scale = None , sparsity = None ) : \n"
Original    (014): ['dv_scale', '=', 'None', ',', 'cn_scale', '=', 'None', ',', 'sparsity', '=', 'None', ')', ':', '\\n']
Tokenized   (024): ['<s>', 'd', 'v', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġc', 'n', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġsp', 'arsity', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['d', 'v', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġc', 'n', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġsp', 'arsity', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (014): ['dv_scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcn_scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġsparsity', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "fd_unknowns = [ var for var in unknown_list if var not in indep_list ] \n"
Original    (015): ['fd_unknowns', '=', '[', 'var', 'for', 'var', 'in', 'unknown_list', 'if', 'var', 'not', 'in', 'indep_list', ']', '\\n']
Tokenized   (026): ['<s>', 'fd', '_', 'unknown', 's', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġvar', 'Ġnot', 'Ġin', 'Ġind', 'ep', '_', 'list', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['fd', '_', 'unknown', 's', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġvar', 'Ġnot', 'Ġin', 'Ġind', 'ep', '_', 'list', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['fd_unknowns', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġunknown_list', 'Ġif', 'Ġvar', 'Ġnot', 'Ġin', 'Ġindep_list', 'Ġ]', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "usize += len ( idx ) \n"
Original    (007): ['usize', '+=', 'len', '(', 'idx', ')', '\\n']
Tokenized   (012): ['<s>', 'us', 'ize', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġid', 'x', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['us', 'ize', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġid', 'x', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['usize', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġidx', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "fwd = mode == \n"
Original    (005): ['fwd', '=', 'mode', '==', '\\n']
Tokenized   (009): ['<s>', 'f', 'wd', 'Ġ=', 'Ġmode', 'Ġ==', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['f', 'wd', 'Ġ=', 'Ġmode', 'Ġ==', 'Ġ\\', 'n']
Detokenized (005): ['fwd', 'Ġ=', 'Ġmode', 'Ġ==', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "poi_indices , qoi_indices = self . _poi_indices , self . _qoi_indices \n"
Original    (012): ['poi_indices', ',', 'qoi_indices', '=', 'self', '.', '_poi_indices', ',', 'self', '.', '_qoi_indices', '\\n']
Tokenized   (033): ['<s>', 'po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġq', 'oi', '_', 'ind', 'ices', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'q', 'oi', '_', 'ind', 'ices', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġq', 'oi', '_', 'ind', 'ices', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'q', 'oi', '_', 'ind', 'ices', 'Ġ\\', 'n']
Detokenized (012): ['poi_indices', 'Ġ,', 'Ġqoi_indices', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_poi_indices', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_qoi_indices', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "in_scale , un_scale = cn_scale , dv_scale \n"
Original    (008): ['in_scale', ',', 'un_scale', '=', 'cn_scale', ',', 'dv_scale', '\\n']
Tokenized   (021): ['<s>', 'in', '_', 'scale', 'Ġ,', 'Ġun', '_', 'scale', 'Ġ=', 'Ġc', 'n', '_', 'scale', 'Ġ,', 'Ġd', 'v', '_', 'scale', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['in', '_', 'scale', 'Ġ,', 'Ġun', '_', 'scale', 'Ġ=', 'Ġc', 'n', '_', 'scale', 'Ġ,', 'Ġd', 'v', '_', 'scale', 'Ġ\\', 'n']
Detokenized (008): ['in_scale', 'Ġ,', 'Ġun_scale', 'Ġ=', 'Ġcn_scale', 'Ġ,', 'Ġdv_scale', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "duvec = self . root . dumat [ vkey ] \n"
Original    (011): ['duvec', '=', 'self', '.', 'root', '.', 'dumat', '[', 'vkey', ']', '\\n']
Tokenized   (017): ['<s>', 'du', 'vec', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġd', 'umat', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['du', 'vec', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġd', 'umat', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['duvec', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġdumat', 'Ġ[', 'Ġvkey', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "rhs [ vkey ] [ : ] = 0.0 \n"
Original    (010): ['rhs', '[', 'vkey', ']', '[', ':', ']', '=', '0.0', '\\n']
Tokenized   (017): ['<s>', 'r', 'hs', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġ0', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['r', 'hs', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġ0', '.', '0', 'Ġ\\', 'n']
Detokenized (010): ['rhs', 'Ġ[', 'Ġvkey', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġ0.0', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "isinstance ( self . root . ln_solver , LinearGaussSeidel ) ) : \n"
Original    (013): ['isinstance', '(', 'self', '.', 'root', '.', 'ln_solver', ',', 'LinearGaussSeidel', ')', ')', ':', '\\n']
Tokenized   (025): ['<s>', 'is', 'instance', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ,', 'ĠLinear', 'Ga', 'uss', 'Se', 'idel', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['is', 'instance', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ,', 'ĠLinear', 'Ga', 'uss', 'Se', 'idel', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (013): ['isinstance', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġln_solver', 'Ġ,', 'ĠLinearGaussSeidel', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "unkn_list = [ item for item in dunknowns if not dunknowns . metadata ( item ) . get ( ) ] \n"
Original    (022): ['unkn_list', '=', '[', 'item', 'for', 'item', 'in', 'dunknowns', 'if', 'not', 'dunknowns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (032): ['<s>', 'unk', 'n', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġd', 'unknown', 's', 'Ġif', 'Ġnot', 'Ġd', 'unknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['unk', 'n', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġd', 'unknown', 's', 'Ġif', 'Ġnot', 'Ġd', 'unknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (022): ['unkn_list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġdunknowns', 'Ġif', 'Ġnot', 'Ġdunknowns', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "p_size = np . size ( dinputs [ p_name ] ) \n"
Original    (012): ['p_size', '=', 'np', '.', 'size', '(', 'dinputs', '[', 'p_name', ']', ')', '\\n']
Tokenized   (021): ['<s>', 'p', '_', 'size', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġsize', 'Ġ(', 'Ġd', 'input', 's', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['p', '_', 'size', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġsize', 'Ġ(', 'Ġd', 'input', 's', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['p_size', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġsize', 'Ġ(', 'Ġdinputs', 'Ġ[', 'Ġp_name', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "dresids . _dat [ u_name ] . val [ idx ] = 1.0 \n"
Original    (014): ['dresids', '.', '_dat', '[', 'u_name', ']', '.', 'val', '[', 'idx', ']', '=', '1.0', '\\n']
Tokenized   (025): ['<s>', 'd', 'res', 'ids', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġu', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ[', 'Ġid', 'x', 'Ġ]', 'Ġ=', 'Ġ1', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['d', 'res', 'ids', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġu', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ[', 'Ġid', 'x', 'Ġ]', 'Ġ=', 'Ġ1', '.', '0', 'Ġ\\', 'n']
Detokenized (014): ['dresids', 'Ġ.', 'Ġ_dat', 'Ġ[', 'Ġu_name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ[', 'Ġidx', 'Ġ]', 'Ġ=', 'Ġ1.0', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dunknowns , dresids , ) \n"
Original    (006): ['dunknowns', ',', 'dresids', ',', ')', '\\n']
Tokenized   (013): ['<s>', 'd', 'unknown', 's', 'Ġ,', 'Ġd', 'res', 'ids', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['d', 'unknown', 's', 'Ġ,', 'Ġd', 'res', 'ids', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['dunknowns', 'Ġ,', 'Ġdresids', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "jac_rev [ ( u_name , p_name ) ] [ idx , : ] = dinputs . _dat [ p_name ] . val \n"
Original    (023): ['jac_rev', '[', '(', 'u_name', ',', 'p_name', ')', ']', '[', 'idx', ',', ':', ']', '=', 'dinputs', '.', '_dat', '[', 'p_name', ']', '.', 'val', '\\n']
Tokenized   (038): ['<s>', 'jac', '_', 'rev', 'Ġ[', 'Ġ(', 'Ġu', '_', 'name', 'Ġ,', 'Ġp', '_', 'name', 'Ġ)', 'Ġ]', 'Ġ[', 'Ġid', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġd', 'input', 's', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['jac', '_', 'rev', 'Ġ[', 'Ġ(', 'Ġu', '_', 'name', 'Ġ,', 'Ġp', '_', 'name', 'Ġ)', 'Ġ]', 'Ġ[', 'Ġid', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġd', 'input', 's', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ\\', 'n']
Detokenized (023): ['jac_rev', 'Ġ[', 'Ġ(', 'Ġu_name', 'Ġ,', 'Ġp_name', 'Ġ)', 'Ġ]', 'Ġ[', 'Ġidx', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġdinputs', 'Ġ.', 'Ġ_dat', 'Ġ[', 'Ġp_name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "c_name = cname , jac_fd2 = jac_fd2 , fd_desc = fd_desc , \n"
Original    (013): ['c_name', '=', 'cname', ',', 'jac_fd2', '=', 'jac_fd2', ',', 'fd_desc', '=', 'fd_desc', ',', '\\n']
Tokenized   (033): ['<s>', 'c', '_', 'name', 'Ġ=', 'Ġc', 'name', 'Ġ,', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ=', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ,', 'Ġf', 'd', '_', 'desc', 'Ġ=', 'Ġf', 'd', '_', 'desc', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['c', '_', 'name', 'Ġ=', 'Ġc', 'name', 'Ġ,', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ=', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ,', 'Ġf', 'd', '_', 'desc', 'Ġ=', 'Ġf', 'd', '_', 'desc', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['c_name', 'Ġ=', 'Ġcname', 'Ġ,', 'Ġjac_fd2', 'Ġ=', 'Ġjac_fd2', 'Ġ,', 'Ġfd_desc', 'Ġ=', 'Ġfd_desc', 'Ġ,', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "param_srcs = [ root . connections [ p ] for p in abs_indep_list if not root . _params_dict [ p ] . get ( ) ] \n"
Original    (027): ['param_srcs', '=', '[', 'root', '.', 'connections', '[', 'p', ']', 'for', 'p', 'in', 'abs_indep_list', 'if', 'not', 'root', '.', '_params_dict', '[', 'p', ']', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (041): ['<s>', 'param', '_', 'src', 's', 'Ġ=', 'Ġ[', 'Ġroot', 'Ġ.', 'Ġconnections', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġabs', '_', 'ind', 'ep', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['param', '_', 'src', 's', 'Ġ=', 'Ġ[', 'Ġroot', 'Ġ.', 'Ġconnections', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġabs', '_', 'ind', 'ep', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (027): ['param_srcs', 'Ġ=', 'Ġ[', 'Ġroot', 'Ġ.', 'Ġconnections', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġabs_indep_list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġ_params_dict', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "to_prom_name [ p ] for p , idxs in param_srcs \n"
Original    (011): ['to_prom_name', '[', 'p', ']', 'for', 'p', ',', 'idxs', 'in', 'param_srcs', '\\n']
Tokenized   (022): ['<s>', 'to', '_', 'prom', '_', 'name', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġ,', 'Ġid', 'xs', 'Ġin', 'Ġparam', '_', 'src', 's', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['to', '_', 'prom', '_', 'name', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġ,', 'Ġid', 'xs', 'Ġin', 'Ġparam', '_', 'src', 's', 'Ġ\\', 'n']
Detokenized (011): ['to_prom_name', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġ,', 'Ġidxs', 'Ġin', 'Ġparam_srcs', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "unknown_list = [ item for item in unknown_list if not root . unknowns . metadata ( item ) . get ( ) ] \n"
Original    (024): ['unknown_list', '=', '[', 'item', 'for', 'item', 'in', 'unknown_list', 'if', 'not', 'root', '.', 'unknowns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (032): ['<s>', 'unknown', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġunknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['unknown', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġunknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (024): ['unknown_list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġunknown_list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġunknowns', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "_assemble_deriv_data ( indep_list , unknown_list , data , \n"
Original    (009): ['_assemble_deriv_data', '(', 'indep_list', ',', 'unknown_list', ',', 'data', ',', '\\n']
Tokenized   (024): ['<s>', '_', 'as', 'semble', '_', 'der', 'iv', '_', 'data', 'Ġ(', 'Ġind', 'ep', '_', 'list', 'Ġ,', 'Ġunknown', '_', 'list', 'Ġ,', 'Ġdata', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['_', 'as', 'semble', '_', 'der', 'iv', '_', 'data', 'Ġ(', 'Ġind', 'ep', '_', 'list', 'Ġ,', 'Ġunknown', '_', 'list', 'Ġ,', 'Ġdata', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['_assemble_deriv_data', 'Ġ(', 'Ġindep_list', 'Ġ,', 'Ġunknown_list', 'Ġ,', 'Ġdata', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_both_names ( tmeta , to_prom_name ) ) \n"
Original    (008): ['_both_names', '(', 'tmeta', ',', 'to_prom_name', ')', ')', '\\n']
Tokenized   (019): ['<s>', '_', 'both', '_', 'names', 'Ġ(', 'Ġt', 'meta', 'Ġ,', 'Ġto', '_', 'prom', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['_', 'both', '_', 'names', 'Ġ(', 'Ġt', 'meta', 'Ġ,', 'Ġto', '_', 'prom', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['_both_names', 'Ġ(', 'Ġtmeta', 'Ġ,', 'Ġto_prom_name', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "abs_unames = self . root . _sysdata . to_abs_uname \n"
Original    (010): ['abs_unames', '=', 'self', '.', 'root', '.', '_sysdata', '.', 'to_abs_uname', '\\n']
Tokenized   (023): ['<s>', 'abs', '_', 'un', 'ames', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'sys', 'data', 'Ġ.', 'Ġto', '_', 'abs', '_', 'un', 'ame', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['abs', '_', 'un', 'ames', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'sys', 'data', 'Ġ.', 'Ġto', '_', 'abs', '_', 'un', 'ame', 'Ġ\\', 'n']
Detokenized (010): ['abs_unames', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_sysdata', 'Ġ.', 'Ġto_abs_uname', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "out_str = tmp1 . format ( _pad_name ( ) , _pad_name ( ) , \n"
Original    (015): ['out_str', '=', 'tmp1', '.', 'format', '(', '_pad_name', '(', ')', ',', '_pad_name', '(', ')', ',', '\\n']
Tokenized   (027): ['<s>', 'out', '_', 'str', 'Ġ=', 'Ġtmp', '1', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['out', '_', 'str', 'Ġ=', 'Ġtmp', '1', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['out_str', 'Ġ=', 'Ġtmp1', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġ_pad_name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ_pad_name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "magfor , magrev , magfd , abs1 , abs2 , \n"
Original    (011): ['magfor', ',', 'magrev', ',', 'magfd', ',', 'abs1', ',', 'abs2', ',', '\\n']
Tokenized   (019): ['<s>', 'mag', 'for', 'Ġ,', 'Ġmag', 'rev', 'Ġ,', 'Ġmag', 'fd', 'Ġ,', 'Ġabs', '1', 'Ġ,', 'Ġabs', '2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mag', 'for', 'Ġ,', 'Ġmag', 'rev', 'Ġ,', 'Ġmag', 'fd', 'Ġ,', 'Ġabs', '1', 'Ġ,', 'Ġabs', '2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['magfor', 'Ġ,', 'Ġmagrev', 'Ġ,', 'Ġmagfd', 'Ġ,', 'Ġabs1', 'Ġ,', 'Ġabs2', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "rel1 , rel2 ) ) \n"
Original    (006): ['rel1', ',', 'rel2', ')', ')', '\\n']
Tokenized   (011): ['<s>', 'rel', '1', 'Ġ,', 'Ġrel', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['rel', '1', 'Ġ,', 'Ġrel', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['rel1', 'Ġ,', 'Ġrel2', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_pad_name ( , 12 , quotes = False ) \n"
Original    (010): ['_pad_name', '(', ',', '12', ',', 'quotes', '=', 'False', ')', '\\n']
Tokenized   (016): ['<s>', '_', 'pad', '_', 'name', 'Ġ(', 'Ġ,', 'Ġ12', 'Ġ,', 'Ġquotes', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['_', 'pad', '_', 'name', 'Ġ(', 'Ġ,', 'Ġ12', 'Ġ,', 'Ġquotes', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['_pad_name', 'Ġ(', 'Ġ,', 'Ġ12', 'Ġ,', 'Ġquotes', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "magfd , magfd2 , abs4 , rel4 ) ) \n"
Original    (010): ['magfd', ',', 'magfd2', ',', 'abs4', ',', 'rel4', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'mag', 'fd', 'Ġ,', 'Ġmag', 'fd', '2', 'Ġ,', 'Ġabs', '4', 'Ġ,', 'Ġrel', '4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['mag', 'fd', 'Ġ,', 'Ġmag', 'fd', '2', 'Ġ,', 'Ġabs', '4', 'Ġ,', 'Ġrel', '4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['magfd', 'Ġ,', 'Ġmagfd2', 'Ġ,', 'Ġabs4', 'Ġ,', 'Ġrel4', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "out_stream . write ( str ( Jsub_fd2 ) ) \n"
Original    (010): ['out_stream', '.', 'write', '(', 'str', '(', 'Jsub_fd2', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'out', '_', 'stream', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠJ', 'sub', '_', 'fd', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['out', '_', 'stream', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠJ', 'sub', '_', 'fd', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['out_stream', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠJsub_fd2', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sqlite_dict_args . setdefault ( , ) \n"
Original    (007): ['sqlite_dict_args', '.', 'setdefault', '(', ',', ')', '\\n']
Tokenized   (016): ['<s>', 'sql', 'ite', '_', 'dict', '_', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['sql', 'ite', '_', 'dict', '_', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['sqlite_dict_args', 'Ġ.', 'Ġsetdefault', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ll_1 = ll_0 + n_samples - k - 1 \n"
Original    (010): ['ll_1', '=', 'll_0', '+', 'n_samples', '-', 'k', '-', '1', '\\n']
Tokenized   (020): ['<s>', 'll', '_', '1', 'Ġ=', 'Ġll', '_', '0', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġk', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['ll', '_', '1', 'Ġ=', 'Ġll', '_', '0', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġk', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (010): ['ll_1', 'Ġ=', 'Ġll_0', 'Ġ+', 'Ġn_samples', 'Ġ-', 'Ġk', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "D = self . D [ lvl ] \n"
Original    (009): ['D', '=', 'self', '.', 'D', '[', 'lvl', ']', '\\n']
Tokenized   (012): ['<s>', 'D', 'Ġ=', 'Ġself', 'Ġ.', 'ĠD', 'Ġ[', 'Ġlvl', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['D', 'Ġ=', 'Ġself', 'Ġ.', 'ĠD', 'Ġ[', 'Ġlvl', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['D', 'Ġ=', 'Ġself', 'Ġ.', 'ĠD', 'Ġ[', 'Ġlvl', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "initial_range = INITIAL_RANGE_DEFAULT , tol = TOLERANCE_DEFAULT ) : \n"
Original    (010): ['initial_range', '=', 'INITIAL_RANGE_DEFAULT', ',', 'tol', '=', 'TOLERANCE_DEFAULT', ')', ':', '\\n']
Tokenized   (030): ['<s>', 'initial', '_', 'range', 'Ġ=', 'ĠIN', 'IT', 'IAL', '_', 'R', 'ANGE', '_', 'DE', 'FAULT', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'ĠT', 'OL', 'ER', 'ANCE', '_', 'DE', 'FAULT', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['initial', '_', 'range', 'Ġ=', 'ĠIN', 'IT', 'IAL', '_', 'R', 'ANGE', '_', 'DE', 'FAULT', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'ĠT', 'OL', 'ER', 'ANCE', '_', 'DE', 'FAULT', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (010): ['initial_range', 'Ġ=', 'ĠINITIAL_RANGE_DEFAULT', 'Ġ,', 'Ġtol', 'Ġ=', 'ĠTOLERANCE_DEFAULT', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "y_best = y [ nlevel - 1 ] \n"
Original    (009): ['y_best', '=', 'y', '[', 'nlevel', '-', '1', ']', '\\n']
Tokenized   (015): ['<s>', 'y', '_', 'best', 'Ġ=', 'Ġy', 'Ġ[', 'Ġn', 'level', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['y', '_', 'best', 'Ġ=', 'Ġy', 'Ġ[', 'Ġn', 'level', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['y_best', 'Ġ=', 'Ġy', 'Ġ[', 'Ġnlevel', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "+ str ( theta ) ) \n"
Original    (007): ['+', 'str', '(', 'theta', ')', ')', '\\n']
Tokenized   (011): ['<s>', '+', 'Ġstr', 'Ġ(', 'Ġthe', 'ta', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['+', 'Ġstr', 'Ġ(', 'Ġthe', 'ta', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['+', 'Ġstr', 'Ġ(', 'Ġtheta', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Yt = solve_triangular ( C , y , lower = True ) \n"
Original    (013): ['Yt', '=', 'solve_triangular', '(', 'C', ',', 'y', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (020): ['<s>', 'Y', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġy', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['Y', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġy', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['Yt', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġy', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "err2 = np . dot ( err . T , err ) [ 0 , 0 ] \n"
Original    (018): ['err2', '=', 'np', '.', 'dot', '(', 'err', '.', 'T', ',', 'err', ')', '[', '0', ',', '0', ']', '\\n']
Tokenized   (022): ['<s>', 'err', '2', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠT', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['err', '2', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠT', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['err2', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠT', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "sigma2 = err2 / ( n_samples - p - q ) \n"
Original    (012): ['sigma2', '=', 'err2', '/', '(', 'n_samples', '-', 'p', '-', 'q', ')', '\\n']
Tokenized   (021): ['<s>', 's', 'igma', '2', 'Ġ=', 'Ġerr', '2', 'Ġ/', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['s', 'igma', '2', 'Ġ=', 'Ġerr', '2', 'Ġ/', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['sigma2', 'Ġ=', 'Ġerr2', 'Ġ/', 'Ġ(', 'Ġn_samples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "detR = ( ( np . diag ( C ) ) ** ( 2. / n_samples ) ) . prod ( ) \n"
Original    (023): ['detR', '=', '(', '(', 'np', '.', 'diag', '(', 'C', ')', ')', '**', '(', '2.', '/', 'n_samples', ')', ')', '.', 'prod', '(', ')', '\\n']
Tokenized   (032): ['<s>', 'det', 'R', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdi', 'ag', 'Ġ(', 'ĠC', 'Ġ)', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ2', '.', 'Ġ/', 'Ġn', '_', 's', 'amples', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġprod', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['det', 'R', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdi', 'ag', 'Ġ(', 'ĠC', 'Ġ)', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ2', '.', 'Ġ/', 'Ġn', '_', 's', 'amples', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġprod', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['detR', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdiag', 'Ġ(', 'ĠC', 'Ġ)', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ2.', 'Ġ/', 'Ġn_samples', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġprod', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "rlf_value = ( n_samples - p - q ) * np . log10 ( sigma2 ) + n_samples * np . log10 ( detR ) \n"
Original    (026): ['rlf_value', '=', '(', 'n_samples', '-', 'p', '-', 'q', ')', '*', 'np', '.', 'log10', '(', 'sigma2', ')', '+', 'n_samples', '*', 'np', '.', 'log10', '(', 'detR', ')', '\\n']
Tokenized   (043): ['<s>', 'r', 'lf', '_', 'value', 'Ġ=', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġs', 'igma', '2', 'Ġ)', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġdet', 'R', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['r', 'lf', '_', 'value', 'Ġ=', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġs', 'igma', '2', 'Ġ)', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġdet', 'R', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['rlf_value', 'Ġ=', 'Ġ(', 'Ġn_samples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog10', 'Ġ(', 'Ġsigma2', 'Ġ)', 'Ġ+', 'Ġn_samples', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog10', 'Ġ(', 'ĠdetR', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "log10t [ i ] - np . log10 ( thetaL [ 0 ] [ i ] ) } ) \n"
Original    (020): ['log10t', '[', 'i', ']', '-', 'np', '.', 'log10', '(', 'thetaL', '[', '0', ']', '[', 'i', ']', ')', '}', ')', '\\n']
Tokenized   (028): ['<s>', 'log', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'L', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['log', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'L', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['log10t', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġlog10', 'Ġ(', 'ĠthetaL', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "np . log10 ( thetaU [ 0 ] [ i ] ) - log10t [ i ] } ) \n"
Original    (020): ['np', '.', 'log10', '(', 'thetaU', '[', '0', ']', '[', 'i', ']', ')', '-', 'log10t', '[', 'i', ']', '}', ')', '\\n']
Tokenized   (028): ['<s>', 'np', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'U', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġlog', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['np', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'U', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġlog', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['np', 'Ġ.', 'Ġlog10', 'Ġ(', 'ĠthetaU', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġlog10t', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "sol = minimize ( rlf_transform , x0 , method = , \n"
Original    (012): ['sol', '=', 'minimize', '(', 'rlf_transform', ',', 'x0', ',', 'method', '=', ',', '\\n']
Tokenized   (019): ['<s>', 'sol', 'Ġ=', 'Ġminimize', 'Ġ(', 'Ġr', 'lf', '_', 'transform', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġmethod', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['sol', 'Ġ=', 'Ġminimize', 'Ġ(', 'Ġr', 'lf', '_', 'transform', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġmethod', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['sol', 'Ġ=', 'Ġminimize', 'Ġ(', 'Ġrlf_transform', 'Ġ,', 'Ġx0', 'Ġ,', 'Ġmethod', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "optimal_theta = 10. ** log10_optimal_x \n"
Original    (006): ['optimal_theta', '=', '10.', '**', 'log10_optimal_x', '\\n']
Tokenized   (020): ['<s>', 'opt', 'imal', '_', 'the', 'ta', 'Ġ=', 'Ġ10', '.', 'Ġ**', 'Ġlog', '10', '_', 'opt', 'imal', '_', 'x', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['opt', 'imal', '_', 'the', 'ta', 'Ġ=', 'Ġ10', '.', 'Ġ**', 'Ġlog', '10', '_', 'opt', 'imal', '_', 'x', 'Ġ\\', 'n']
Detokenized (006): ['optimal_theta', 'Ġ=', 'Ġ10.', 'Ġ**', 'Ġlog10_optimal_x', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "r_t = solve_triangular ( C , r_ . T , lower = True ) \n"
Original    (015): ['r_t', '=', 'solve_triangular', '(', 'C', ',', 'r_', '.', 'T', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'r', '_', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġr', '_', 'Ġ.', 'ĠT', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['r', '_', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġr', '_', 'Ġ.', 'ĠT', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['r_t', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġr_', 'Ġ.', 'ĠT', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "dx = l1_cross_distances ( X , Y = self . X [ i ] ) \n"
Original    (016): ['dx', '=', 'l1_cross_distances', '(', 'X', ',', 'Y', '=', 'self', '.', 'X', '[', 'i', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'dx', 'Ġ=', 'Ġl', '1', '_', 'cross', '_', 'dist', 'ances', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'ĠX', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['dx', 'Ġ=', 'Ġl', '1', '_', 'cross', '_', 'dist', 'ances', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'ĠX', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['dx', 'Ġ=', 'Ġl1_cross_distances', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'ĠX', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "r_ = self . corr ( self . theta [ i ] , dx ) . reshape ( n_eval , self . n_samples [ i ] ) \n"
Original    (028): ['r_', '=', 'self', '.', 'corr', '(', 'self', '.', 'theta', '[', 'i', ']', ',', 'dx', ')', '.', 'reshape', '(', 'n_eval', ',', 'self', '.', 'n_samples', '[', 'i', ']', ')', '\\n']
Tokenized   (040): ['<s>', 'r', '_', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcor', 'r', 'Ġ(', 'Ġself', 'Ġ.', 'Ġthe', 'ta', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġdx', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġn', '_', 'eval', 'Ġ,', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['r', '_', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcor', 'r', 'Ġ(', 'Ġself', 'Ġ.', 'Ġthe', 'ta', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġdx', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġn', '_', 'eval', 'Ġ,', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (028): ['r_', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcorr', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtheta', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġdx', 'Ġ)', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġn_eval', 'Ġ,', 'Ġself', 'Ġ.', 'Ġn_samples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "yt = solve_triangular ( C , self . y [ i ] , lower = True ) \n"
Original    (018): ['yt', '=', 'solve_triangular', '(', 'C', ',', 'self', '.', 'y', '[', 'i', ']', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'yt', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġself', 'Ġ.', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['yt', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġself', 'Ġ.', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['yt', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġself', 'Ġ.', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "mu [ : , i ] = ( np . dot ( f . T , beta ) + np . dot ( r_t . T , yt - np . dot ( Ft , beta ) ) ) . ravel ( ) \n"
Original    (044): ['mu', '[', ':', ',', 'i', ']', '=', '(', 'np', '.', 'dot', '(', 'f', '.', 'T', ',', 'beta', ')', '+', 'np', '.', 'dot', '(', 'r_t', '.', 'T', ',', 'yt', '-', 'np', '.', 'dot', '(', 'Ft', ',', 'beta', ')', ')', ')', '.', 'ravel', '(', ')', '\\n']
Tokenized   (051): ['<s>', 'mu', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġf', 'Ġ.', 'ĠT', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ+', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġr', '_', 't', 'Ġ.', 'ĠT', 'Ġ,', 'Ġy', 't', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġra', 'vel', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (049): ['mu', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġf', 'Ġ.', 'ĠT', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ+', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġr', '_', 't', 'Ġ.', 'ĠT', 'Ġ,', 'Ġy', 't', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġra', 'vel', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (044): ['mu', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġf', 'Ġ.', 'ĠT', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ+', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġr_t', 'Ġ.', 'ĠT', 'Ġ,', 'Ġyt', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġravel', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 49
===================================================================
Hidden states:  (13, 44, 768)
# Extracted words:  44
Sentence         : "u_ = solve_triangular ( G . T , f - np . dot ( Ft . T , r_t ) , lower = True ) \n"
Original    (026): ['u_', '=', 'solve_triangular', '(', 'G', '.', 'T', ',', 'f', '-', 'np', '.', 'dot', '(', 'Ft', '.', 'T', ',', 'r_t', ')', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (035): ['<s>', 'u', '_', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠG', 'Ġ.', 'ĠT', 'Ġ,', 'Ġf', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ.', 'ĠT', 'Ġ,', 'Ġr', '_', 't', 'Ġ)', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['u', '_', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠG', 'Ġ.', 'ĠT', 'Ġ,', 'Ġf', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ.', 'ĠT', 'Ġ,', 'Ġr', '_', 't', 'Ġ)', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['u_', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠG', 'Ġ.', 'ĠT', 'Ġ,', 'Ġf', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ.', 'ĠT', 'Ġ,', 'Ġr_t', 'Ġ)', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "sigma2_rho = ( sigma2_rho * g ) . sum ( axis = 1 ) \n"
Original    (015): ['sigma2_rho', '=', '(', 'sigma2_rho', '*', 'g', ')', '.', 'sum', '(', 'axis', '=', '1', ')', '\\n']
Tokenized   (028): ['<s>', 's', 'igma', '2', '_', 'r', 'ho', 'Ġ=', 'Ġ(', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'Ġg', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['s', 'igma', '2', '_', 'r', 'ho', 'Ġ=', 'Ġ(', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'Ġg', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sigma2_rho', 'Ġ=', 'Ġ(', 'Ġsigma2_rho', 'Ġ*', 'Ġg', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "MSE [ : , i ] = sigma2_rho * MSE [ : , i - 1 ] + Q_ / ( 2 * ( self . n_samples [ i ] - self . p [ i ] - self . q [ i ] ) ) * ( 1 - ( r_t ** 2 ) . sum ( axis = 0 ) ) + self . sigma2 [ i ] * ( u_ ** 2 ) . sum ( axis = 0 ) \n"
Original    (084): ['MSE', '[', ':', ',', 'i', ']', '=', 'sigma2_rho', '*', 'MSE', '[', ':', ',', 'i', '-', '1', ']', '+', 'Q_', '/', '(', '2', '*', '(', 'self', '.', 'n_samples', '[', 'i', ']', '-', 'self', '.', 'p', '[', 'i', ']', '-', 'self', '.', 'q', '[', 'i', ']', ')', ')', '*', '(', '1', '-', '(', 'r_t', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', ')', '+', 'self', '.', 'sigma2', '[', 'i', ']', '*', '(', 'u_', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', '\\n']
Tokenized   (103): ['<s>', 'M', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'ĠM', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ+', 'ĠQ', '_', 'Ġ/', 'Ġ(', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġp', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġq', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġ(', 'Ġr', '_', 't', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġs', 'igma', '2', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ*', 'Ġ(', 'Ġu', '_', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (101): ['M', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'ĠM', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ+', 'ĠQ', '_', 'Ġ/', 'Ġ(', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġp', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġq', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġ(', 'Ġr', '_', 't', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġs', 'igma', '2', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ*', 'Ġ(', 'Ġu', '_', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (084): ['MSE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġsigma2_rho', 'Ġ*', 'ĠMSE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ+', 'ĠQ_', 'Ġ/', 'Ġ(', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn_samples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġp', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġq', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġ(', 'Ġr_t', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsigma2', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ*', 'Ġ(', 'Ġu_', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 101
===================================================================
Hidden states:  (13, 84, 768)
# Extracted words:  84
Sentence         : "n_features = np . zeros ( nlevel , dtype = int ) \n"
Original    (013): ['n_features', '=', 'np', '.', 'zeros', '(', 'nlevel', ',', 'dtype', '=', 'int', ')', '\\n']
Tokenized   (021): ['<s>', 'n', '_', 'features', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġn', 'level', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġint', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['n', '_', 'features', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġn', 'level', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġint', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['n_features', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġzeros', 'Ġ(', 'Ġnlevel', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġint', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "n_samples_y [ i ] = y [ i ] . shape [ 0 ] \n"
Original    (015): ['n_samples_y', '[', 'i', ']', '=', 'y', '[', 'i', ']', '.', 'shape', '[', '0', ']', '\\n']
Tokenized   (023): ['<s>', 'n', '_', 's', 'amples', '_', 'y', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['n', '_', 's', 'amples', '_', 'y', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['n_samples_y', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "Y_pred , MSE = self . model . predict ( [ new_x ] ) \n"
Original    (015): ['Y_pred', ',', 'MSE', '=', 'self', '.', 'model', '.', 'predict', '(', '[', 'new_x', ']', ')', '\\n']
Tokenized   (023): ['<s>', 'Y', '_', 'pred', 'Ġ,', 'ĠM', 'SE', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ[', 'Ġnew', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['Y', '_', 'pred', 'Ġ,', 'ĠM', 'SE', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ[', 'Ġnew', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['Y_pred', 'Ġ,', 'ĠMSE', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ[', 'Ġnew_x', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "X , Y = self . _fit_adapter ( X , Y ) \n"
Original    (013): ['X', ',', 'Y', '=', 'self', '.', '_fit_adapter', '(', 'X', ',', 'Y', ')', '\\n']
Tokenized   (020): ['<s>', 'X', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'fit', '_', 'ad', 'apter', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['X', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'fit', '_', 'ad', 'apter', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['X', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_fit_adapter', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Y = [ np . array ( y ) for y in reversed ( Y ) ] \n"
Original    (018): ['Y', '=', '[', 'np', '.', 'array', '(', 'y', ')', 'for', 'y', 'in', 'reversed', '(', 'Y', ')', ']', '\\n']
Tokenized   (021): ['<s>', 'Y', 'Ġ=', 'Ġ[', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġy', 'Ġ)', 'Ġfor', 'Ġy', 'Ġin', 'Ġreversed', 'Ġ(', 'ĠY', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Y', 'Ġ=', 'Ġ[', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġy', 'Ġ)', 'Ġfor', 'Ġy', 'Ġin', 'Ġreversed', 'Ġ(', 'ĠY', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['Y', 'Ġ=', 'Ġ[', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġy', 'Ġ)', 'Ġfor', 'Ġy', 'Ġin', 'Ġreversed', 'Ġ(', 'ĠY', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "newdata = np . array ( parsed [ : ] ) \n"
Original    (012): ['newdata', '=', 'np', '.', 'array', '(', 'parsed', '[', ':', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'new', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġparsed', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['new', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġparsed', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['newdata', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġparsed', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "icc . DB_USER ) , shell = True ) \n"
Original    (010): ['icc', '.', 'DB_USER', ')', ',', 'shell', '=', 'True', ')', '\\n']
Tokenized   (015): ['<s>', 'icc', 'Ġ.', 'ĠDB', '_', 'USER', 'Ġ)', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['icc', 'Ġ.', 'ĠDB', '_', 'USER', 'Ġ)', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['icc', 'Ġ.', 'ĠDB_USER', 'Ġ)', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "instance_db_name , shell = True ) \n"
Original    (007): ['instance_db_name', ',', 'shell', '=', 'True', ')', '\\n']
Tokenized   (014): ['<s>', 'instance', '_', 'db', '_', 'name', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['instance', '_', 'db', '_', 'name', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['instance_db_name', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "customslide = CustomSlide . objects . create ( title = , text = default_projector = Projector . objects . get ( pk = 1 ) \n"
Original    (026): ['customslide', '=', 'CustomSlide', '.', 'objects', '.', 'create', '(', 'title', '=', ',', 'text', '=', 'default_projector', '=', 'Projector', '.', 'objects', '.', 'get', '(', 'pk', '=', '1', ')', '\\n']
Tokenized   (038): ['<s>', 'custom', 'sl', 'ide', 'Ġ=', 'ĠCustom', 'Sl', 'ide', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġtitle', 'Ġ=', 'Ġ,', 'Ġtext', 'Ġ=', 'Ġdefault', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['custom', 'sl', 'ide', 'Ġ=', 'ĠCustom', 'Sl', 'ide', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġtitle', 'Ġ=', 'Ġ,', 'Ġtext', 'Ġ=', 'Ġdefault', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['customslide', 'Ġ=', 'ĠCustomSlide', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġtitle', 'Ġ=', 'Ġ,', 'Ġtext', 'Ġ=', 'Ġdefault_projector', 'Ġ=', 'ĠProjector', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "default_projector = Projector . objects . get ( pk = 1 ) \n"
Original    (013): ['default_projector', '=', 'Projector', '.', 'objects', '.', 'get', '(', 'pk', '=', '1', ')', '\\n']
Tokenized   (021): ['<s>', 'default', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['default', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['default_projector', 'Ġ=', 'ĠProjector', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "reverse ( , args = [ ] ) ) \n"
Original    (010): ['reverse', '(', ',', 'args', '=', '[', ']', ')', ')', '\\n']
Tokenized   (013): ['<s>', 'reverse', 'Ġ(', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['reverse', 'Ġ(', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['reverse', 'Ġ(', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "yield ConfigVariable ( \n"
Original    (004): ['yield', 'ConfigVariable', '(', '\\n']
Tokenized   (009): ['<s>', 'y', 'ield', 'ĠConfig', 'Variable', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['y', 'ield', 'ĠConfig', 'Variable', 'Ġ(', 'Ġ\\', 'n']
Detokenized (004): ['yield', 'ĠConfigVariable', 'Ġ(', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "{ : , : } , { : , : } ) \n"
Original    (013): ['{', ':', ',', ':', '}', ',', '{', ':', ',', ':', '}', ')', '\\n']
Tokenized   (016): ['<s>', '{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "validators = ( validator_for_testing , ) ) \n"
Original    (008): ['validators', '=', '(', 'validator_for_testing', ',', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'valid', 'ators', 'Ġ=', 'Ġ(', 'Ġvalid', 'ator', '_', 'for', '_', 'testing', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['valid', 'ators', 'Ġ=', 'Ġ(', 'Ġvalid', 'ator', '_', 'for', '_', 'testing', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['validators', 'Ġ=', 'Ġ(', 'Ġvalidator_for_testing', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "generate_username . return_value = \n"
Original    (005): ['generate_username', '.', 'return_value', '=', '\\n']
Tokenized   (013): ['<s>', 'gener', 'ate', '_', 'username', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['gener', 'ate', '_', 'username', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'Ġ\\', 'n']
Detokenized (005): ['generate_username', 'Ġ.', 'Ġreturn_value', 'Ġ=', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "serializer = UserFullSerializer ( context = { : view } ) \n"
Original    (012): ['serializer', '=', 'UserFullSerializer', '(', 'context', '=', '{', ':', 'view', '}', ')', '\\n']
Tokenized   (019): ['<s>', 'serial', 'izer', 'Ġ=', 'ĠUser', 'Full', 'Serial', 'izer', 'Ġ(', 'Ġcontext', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġview', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['serial', 'izer', 'Ġ=', 'ĠUser', 'Full', 'Serial', 'izer', 'Ġ(', 'Ġcontext', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġview', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['serializer', 'Ġ=', 'ĠUserFullSerializer', 'Ġ(', 'Ġcontext', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġview', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "#domain... #localhost... \n"
Original    (003): ['#domain...', '#localhost...', '\\n']
Tokenized   (010): ['<s>', '#', 'domain', '...', 'Ġ#', 'localhost', '...', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['#', 'domain', '...', 'Ġ#', 'localhost', '...', 'Ġ\\', 'n']
Detokenized (003): ['#domain...', 'Ġ#localhost...', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "USERNAME_REGEX = re . compile ( , re . I ) \n"
Original    (012): ['USERNAME_REGEX', '=', 're', '.', 'compile', '(', ',', 're', '.', 'I', ')', '\\n']
Tokenized   (019): ['<s>', 'USER', 'NAME', '_', 'REG', 'EX', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġ,', 'Ġre', 'Ġ.', 'ĠI', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['USER', 'NAME', '_', 'REG', 'EX', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġ,', 'Ġre', 'Ġ.', 'ĠI', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['USERNAME_REGEX', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġ,', 'Ġre', 'Ġ.', 'ĠI', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "RouteDistinguisher . TYPE_IP_LOC , None , \n"
Original    (007): ['RouteDistinguisher', '.', 'TYPE_IP_LOC', ',', 'None', ',', '\\n']
Tokenized   (017): ['<s>', 'Route', 'Dist', 'ingu', 'isher', 'Ġ.', 'ĠTYPE', '_', 'IP', '_', 'LOC', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['Route', 'Dist', 'ingu', 'isher', 'Ġ.', 'ĠTYPE', '_', 'IP', '_', 'LOC', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['RouteDistinguisher', 'Ġ.', 'ĠTYPE_IP_LOC', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "10000 + label ) \n"
Original    (005): ['10000', '+', 'label', ')', '\\n']
Tokenized   (008): ['<s>', '10000', 'Ġ+', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['10000', 'Ġ+', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['10000', 'Ġ+', 'Ġlabel', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "nh = Inet ( 1 , socket . inet_pton ( socket . AF_INET , \n"
Original    (015): ['nh', '=', 'Inet', '(', '1', ',', 'socket', '.', 'inet_pton', '(', 'socket', '.', 'AF_INET', ',', '\\n']
Tokenized   (026): ['<s>', 'n', 'h', 'Ġ=', 'ĠIn', 'et', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġsocket', 'Ġ.', 'Ġin', 'et', '_', 'pton', 'Ġ(', 'Ġsocket', 'Ġ.', 'ĠAF', '_', 'IN', 'ET', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['n', 'h', 'Ġ=', 'ĠIn', 'et', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġsocket', 'Ġ.', 'Ġin', 'et', '_', 'pton', 'Ġ(', 'Ġsocket', 'Ġ.', 'ĠAF', '_', 'IN', 'ET', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['nh', 'Ġ=', 'ĠInet', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġsocket', 'Ġ.', 'Ġinet_pton', 'Ġ(', 'Ġsocket', 'Ġ.', 'ĠAF_INET', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "route . attributes . add ( ECommunities ( self . readvertiseToRTs ) ) \n"
Original    (014): ['route', '.', 'attributes', '.', 'add', '(', 'ECommunities', '(', 'self', '.', 'readvertiseToRTs', ')', ')', '\\n']
Tokenized   (024): ['<s>', 'route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġadd', 'Ġ(', 'ĠE', 'Commun', 'ities', 'Ġ(', 'Ġself', 'Ġ.', 'Ġread', 'vert', 'ise', 'To', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġadd', 'Ġ(', 'ĠE', 'Commun', 'ities', 'Ġ(', 'Ġself', 'Ġ.', 'Ġread', 'vert', 'ise', 'To', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġadd', 'Ġ(', 'ĠECommunities', 'Ġ(', 'Ġself', 'Ġ.', 'ĠreadvertiseToRTs', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "nlri . prefix , label ) \n"
Original    (007): ['nlri', '.', 'prefix', ',', 'label', ')', '\\n']
Tokenized   (011): ['<s>', 'nl', 'ri', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['nl', 'ri', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['nlri', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġlabel', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "set ( self . importRTs ) ) ) > 0 ) \n"
Original    (012): ['set', '(', 'self', '.', 'importRTs', ')', ')', ')', '>', '0', ')', '\\n']
Tokenized   (017): ['<s>', 'set', 'Ġ(', 'Ġself', 'Ġ.', 'Ġimport', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['set', 'Ġ(', 'Ġself', 'Ġ.', 'Ġimport', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['set', 'Ġ(', 'Ġself', 'Ġ.', 'ĠimportRTs', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "newRoute . nlri . labelStack [ 0 ] . labelValue , newRoute . nlri , encaps ) \n"
Original    (018): ['newRoute', '.', 'nlri', '.', 'labelStack', '[', '0', ']', '.', 'labelValue', ',', 'newRoute', '.', 'nlri', ',', 'encaps', ')', '\\n']
Tokenized   (029): ['<s>', 'new', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġnew', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ,', 'Ġencaps', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['new', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġnew', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ,', 'Ġencaps', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['newRoute', 'Ġ.', 'Ġnlri', 'Ġ.', 'ĠlabelStack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'ĠlabelValue', 'Ġ,', 'ĠnewRoute', 'Ġ.', 'Ġnlri', 'Ġ,', 'Ġencaps', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "prefix , oldRoute . attributes . get ( NextHop . ID ) . next_hop , \n"
Original    (016): ['prefix', ',', 'oldRoute', '.', 'attributes', '.', 'get', '(', 'NextHop', '.', 'ID', ')', '.', 'next_hop', ',', '\\n']
Tokenized   (023): ['<s>', 'prefix', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġget', 'Ġ(', 'ĠNext', 'Hop', 'Ġ.', 'ĠID', 'Ġ)', 'Ġ.', 'Ġnext', '_', 'hop', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['prefix', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġget', 'Ġ(', 'ĠNext', 'Hop', 'Ġ.', 'ĠID', 'Ġ)', 'Ġ.', 'Ġnext', '_', 'hop', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['prefix', 'Ġ,', 'ĠoldRoute', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġget', 'Ġ(', 'ĠNextHop', 'Ġ.', 'ĠID', 'Ġ)', 'Ġ.', 'Ġnext_hop', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "oldRoute . nlri . labelStack [ 0 ] . labelValue , oldRoute . nlri ) \n"
Original    (016): ['oldRoute', '.', 'nlri', '.', 'labelStack', '[', '0', ']', '.', 'labelValue', ',', 'oldRoute', '.', 'nlri', ')', '\\n']
Tokenized   (027): ['<s>', 'old', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['old', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['oldRoute', 'Ġ.', 'Ġnlri', 'Ġ.', 'ĠlabelStack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'ĠlabelValue', 'Ġ,', 'ĠoldRoute', 'Ġ.', 'Ġnlri', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""readvertised" : ( LGMap . VALUE , [ repr ( prefix ) for prefix in \n"
Original    (016): ['"readvertised"', ':', '(', 'LGMap', '.', 'VALUE', ',', '[', 'repr', '(', 'prefix', ')', 'for', 'prefix', 'in', '\\n']
Tokenized   (025): ['<s>', '"', 'read', 'vert', 'ised', '"', 'Ġ:', 'Ġ(', 'ĠLG', 'Map', 'Ġ.', 'ĠVAL', 'UE', 'Ġ,', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġprefix', 'Ġ)', 'Ġfor', 'Ġprefix', 'Ġin', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['"', 'read', 'vert', 'ised', '"', 'Ġ:', 'Ġ(', 'ĠLG', 'Map', 'Ġ.', 'ĠVAL', 'UE', 'Ġ,', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġprefix', 'Ġ)', 'Ġfor', 'Ġprefix', 'Ġin', 'Ġ\\', 'n']
Detokenized (016): ['"readvertised"', 'Ġ:', 'Ġ(', 'ĠLGMap', 'Ġ.', 'ĠVALUE', 'Ġ,', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġprefix', 'Ġ)', 'Ġfor', 'Ġprefix', 'Ġin', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "REACTORNAME = DEFAULT_REACTORS . get ( platform . system ( ) , ) \n"
Original    (014): ['REACTORNAME', '=', 'DEFAULT_REACTORS', '.', 'get', '(', 'platform', '.', 'system', '(', ')', ',', ')', '\\n']
Tokenized   (025): ['<s>', 'RE', 'ACT', 'OR', 'NAME', 'Ġ=', 'ĠDE', 'FAULT', '_', 'RE', 'ACT', 'ORS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġplatform', 'Ġ.', 'Ġsystem', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['RE', 'ACT', 'OR', 'NAME', 'Ġ=', 'ĠDE', 'FAULT', '_', 'RE', 'ACT', 'ORS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġplatform', 'Ġ.', 'Ġsystem', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['REACTORNAME', 'Ġ=', 'ĠDEFAULT_REACTORS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġplatform', 'Ġ.', 'Ġsystem', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "set_reactor = lambda : reactor \n"
Original    (006): ['set_reactor', '=', 'lambda', ':', 'reactor', '\\n']
Tokenized   (012): ['<s>', 'set', '_', 're', 'actor', 'Ġ=', 'Ġlambda', 'Ġ:', 'Ġreactor', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['set', '_', 're', 'actor', 'Ġ=', 'Ġlambda', 'Ġ:', 'Ġreactor', 'Ġ\\', 'n']
Detokenized (006): ['set_reactor', 'Ġ=', 'Ġlambda', 'Ġ:', 'Ġreactor', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "SIGNALS = dict ( ( k , v ) for v , k in signal . __dict__ . iteritems ( ) if v . startswith ( ) and not v . startswith ( ) ) \n"
Original    (036): ['SIGNALS', '=', 'dict', '(', '(', 'k', ',', 'v', ')', 'for', 'v', ',', 'k', 'in', 'signal', '.', '__dict__', '.', 'iteritems', '(', ')', 'if', 'v', '.', 'startswith', '(', ')', 'and', 'not', 'v', '.', 'startswith', '(', ')', ')', '\\n']
Tokenized   (047): ['<s>', 'SIGN', 'ALS', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġk', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġv', 'Ġ,', 'Ġk', 'Ġin', 'Ġsignal', 'Ġ.', 'Ġ__', 'dict', '__', 'Ġ.', 'Ġiter', 'items', 'Ġ(', 'Ġ)', 'Ġif', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġand', 'Ġnot', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (045): ['SIGN', 'ALS', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġk', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġv', 'Ġ,', 'Ġk', 'Ġin', 'Ġsignal', 'Ġ.', 'Ġ__', 'dict', '__', 'Ġ.', 'Ġiter', 'items', 'Ġ(', 'Ġ)', 'Ġif', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġand', 'Ġnot', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (036): ['SIGNALS', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġk', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġv', 'Ġ,', 'Ġk', 'Ġin', 'Ġsignal', 'Ġ.', 'Ġ__dict__', 'Ġ.', 'Ġiteritems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġv', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġ)', 'Ġand', 'Ġnot', 'Ġv', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 45
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "pargs = ( self . name , self . label , self . reactor ) \n"
Original    (016): ['pargs', '=', '(', 'self', '.', 'name', ',', 'self', '.', 'label', ',', 'self', '.', 'reactor', ')', '\\n']
Tokenized   (020): ['<s>', 'p', 'args', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġself', 'Ġ.', 'Ġreactor', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['p', 'args', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġself', 'Ġ.', 'Ġreactor', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['pargs', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġself', 'Ġ.', 'Ġreactor', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "* pargs , ** pkwargs \n"
Original    (006): ['*', 'pargs', ',', '**', 'pkwargs', '\\n']
Tokenized   (012): ['<s>', '*', 'Ġp', 'args', 'Ġ,', 'Ġ**', 'Ġp', 'kw', 'args', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['*', 'Ġp', 'args', 'Ġ,', 'Ġ**', 'Ġp', 'kw', 'args', 'Ġ\\', 'n']
Detokenized (006): ['*', 'Ġpargs', 'Ġ,', 'Ġ**', 'Ġpkwargs', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "logdir = env . pop ( , os . path . join ( os . path . sep , ) ) \n"
Original    (022): ['logdir', '=', 'env', '.', 'pop', '(', ',', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'sep', ',', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'log', 'dir', 'Ġ=', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['log', 'dir', 'Ġ=', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['logdir', 'Ġ=', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "masksignals = bool ( env . pop ( , True ) ) \n"
Original    (013): ['masksignals', '=', 'bool', '(', 'env', '.', 'pop', '(', ',', 'True', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'mas', 'ks', 'ign', 'als', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mas', 'ks', 'ign', 'als', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['masksignals', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "usetty = bool ( env . pop ( , ) ) \n"
Original    (012): ['usetty', '=', 'bool', '(', 'env', '.', 'pop', '(', ',', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'us', 'et', 'ty', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['us', 'et', 'ty', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['usetty', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "maxfd = resource . getrlimit ( resource . RLIMIT_NOFILE ) [ 1 ] \n"
Original    (014): ['maxfd', '=', 'resource', '.', 'getrlimit', '(', 'resource', '.', 'RLIMIT_NOFILE', ')', '[', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'max', 'fd', 'Ġ=', 'Ġresource', 'Ġ.', 'Ġget', 'r', 'limit', 'Ġ(', 'Ġresource', 'Ġ.', 'ĠRL', 'IM', 'IT', '_', 'NO', 'FILE', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['max', 'fd', 'Ġ=', 'Ġresource', 'Ġ.', 'Ġget', 'r', 'limit', 'Ġ(', 'Ġresource', 'Ġ.', 'ĠRL', 'IM', 'IT', '_', 'NO', 'FILE', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['maxfd', 'Ġ=', 'Ġresource', 'Ġ.', 'Ġgetrlimit', 'Ġ(', 'Ġresource', 'Ġ.', 'ĠRLIMIT_NOFILE', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "hasattr ( os , "devnull" ) and os . devnull or "/dev/null" , \n"
Original    (014): ['hasattr', '(', 'os', ',', '"devnull"', ')', 'and', 'os', '.', 'devnull', 'or', '"/dev/null"', ',', '\\n']
Tokenized   (026): ['<s>', 'has', 'attr', 'Ġ(', 'Ġos', 'Ġ,', 'Ġ"', 'dev', 'null', '"', 'Ġ)', 'Ġand', 'Ġos', 'Ġ.', 'Ġdev', 'null', 'Ġor', 'Ġ"/', 'dev', '/', 'null', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['has', 'attr', 'Ġ(', 'Ġos', 'Ġ,', 'Ġ"', 'dev', 'null', '"', 'Ġ)', 'Ġand', 'Ġos', 'Ġ.', 'Ġdev', 'null', 'Ġor', 'Ġ"/', 'dev', '/', 'null', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['hasattr', 'Ġ(', 'Ġos', 'Ġ,', 'Ġ"devnull"', 'Ġ)', 'Ġand', 'Ġos', 'Ġ.', 'Ġdevnull', 'Ġor', 'Ġ"/dev/null"', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "droned . logging . logToDir ( \n"
Original    (007): ['droned', '.', 'logging', '.', 'logToDir', '(', '\\n']
Tokenized   (014): ['<s>', 'd', 'ron', 'ed', 'Ġ.', 'Ġlogging', 'Ġ.', 'Ġlog', 'To', 'Dir', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['d', 'ron', 'ed', 'Ġ.', 'Ġlogging', 'Ġ.', 'Ġlog', 'To', 'Dir', 'Ġ(', 'Ġ\\', 'n']
Detokenized (007): ['droned', 'Ġ.', 'Ġlogging', 'Ġ.', 'ĠlogToDir', 'Ġ(', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "conversation . say ( contextSummary , useHTML = False ) \n"
Original    (011): ['conversation', '.', 'say', '(', 'contextSummary', ',', 'useHTML', '=', 'False', ')', '\\n']
Tokenized   (018): ['<s>', 'con', 'vers', 'ation', 'Ġ.', 'Ġsay', 'Ġ(', 'Ġcontext', 'Summary', 'Ġ,', 'Ġuse', 'HTML', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['con', 'vers', 'ation', 'Ġ.', 'Ġsay', 'Ġ(', 'Ġcontext', 'Summary', 'Ġ,', 'Ġuse', 'HTML', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['conversation', 'Ġ.', 'Ġsay', 'Ġ(', 'ĠcontextSummary', 'Ġ,', 'ĠuseHTML', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "moduleProvides ( IDroneDService ) #requirement \n"
Original    (006): ['moduleProvides', '(', 'IDroneDService', ')', '#requirement', '\\n']
Tokenized   (017): ['<s>', 'module', 'Prov', 'ides', 'Ġ(', 'ĠID', 'rone', 'DS', 'erv', 'ice', 'Ġ)', 'Ġ#', 'requ', 'irement', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['module', 'Prov', 'ides', 'Ġ(', 'ĠID', 'rone', 'DS', 'erv', 'ice', 'Ġ)', 'Ġ#', 'requ', 'irement', 'Ġ\\', 'n']
Detokenized (006): ['moduleProvides', 'Ġ(', 'ĠIDroneDService', 'Ġ)', 'Ġ#requirement', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "hour = property ( lambda foo : 3600 ) \n"
Original    (010): ['hour', '=', 'property', '(', 'lambda', 'foo', ':', '3600', ')', '\\n']
Tokenized   (014): ['<s>', 'hour', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġfoo', 'Ġ:', 'Ġ36', '00', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['hour', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġfoo', 'Ġ:', 'Ġ36', '00', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['hour', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġfoo', 'Ġ:', 'Ġ3600', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "watchDict = property ( lambda s : SERVICECONFIG . wrapped . get ( , { } ) ) \n"
Original    (019): ['watchDict', '=', 'property', '(', 'lambda', 's', ':', 'SERVICECONFIG', '.', 'wrapped', '.', 'get', '(', ',', '{', '}', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'watch', 'D', 'ict', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġs', 'Ġ:', 'ĠSERV', 'IC', 'EC', 'ON', 'FIG', 'Ġ.', 'Ġwrapped', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['watch', 'D', 'ict', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġs', 'Ġ:', 'ĠSERV', 'IC', 'EC', 'ON', 'FIG', 'Ġ.', 'Ġwrapped', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['watchDict', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġs', 'Ġ:', 'ĠSERVICECONFIG', 'Ġ.', 'Ġwrapped', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "model = gm . throat_surface_area . cylinder ) \n"
Original    (009): ['model', '=', 'gm', '.', 'throat_surface_area', '.', 'cylinder', ')', '\\n']
Tokenized   (017): ['<s>', 'model', 'Ġ=', 'Ġg', 'm', 'Ġ.', 'Ġthroat', '_', 'surface', '_', 'area', 'Ġ.', 'Ġcylinder', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['model', 'Ġ=', 'Ġg', 'm', 'Ġ.', 'Ġthroat', '_', 'surface', '_', 'area', 'Ġ.', 'Ġcylinder', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['model', 'Ġ=', 'Ġgm', 'Ġ.', 'Ġthroat_surface_area', 'Ġ.', 'Ġcylinder', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pores = network . find_connected_pores ( throats , flatten = False ) \n"
Original    (013): ['pores', '=', 'network', '.', 'find_connected_pores', '(', 'throats', ',', 'flatten', '=', 'False', ')', '\\n']
Tokenized   (023): ['<s>', 'p', 'ores', 'Ġ=', 'Ġnetwork', 'Ġ.', 'Ġfind', '_', 'connected', '_', 'p', 'ores', 'Ġ(', 'Ġthroats', 'Ġ,', 'Ġflatt', 'en', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['p', 'ores', 'Ġ=', 'Ġnetwork', 'Ġ.', 'Ġfind', '_', 'connected', '_', 'p', 'ores', 'Ġ(', 'Ġthroats', 'Ġ,', 'Ġflatt', 'en', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['pores', 'Ġ=', 'Ġnetwork', 'Ġ.', 'Ġfind_connected_pores', 'Ġ(', 'Ġthroats', 'Ġ,', 'Ġflatten', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "C0 = network [ ] [ pores , 0 ] \n"
Original    (011): ['C0', '=', 'network', '[', ']', '[', 'pores', ',', '0', ']', '\\n']
Tokenized   (015): ['<s>', 'C', '0', 'Ġ=', 'Ġnetwork', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġpores', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['C', '0', 'Ġ=', 'Ġnetwork', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġpores', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['C0', 'Ġ=', 'Ġnetwork', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġpores', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "P = phase [ pore_P ] / 100000 \n"
Original    (009): ['P', '=', 'phase', '[', 'pore_P', ']', '/', '100000', '\\n']
Tokenized   (016): ['<s>', 'P', 'Ġ=', 'Ġphase', 'Ġ[', 'Ġp', 'ore', '_', 'P', 'Ġ]', 'Ġ/', 'Ġ100', '000', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['P', 'Ġ=', 'Ġphase', 'Ġ[', 'Ġp', 'ore', '_', 'P', 'Ġ]', 'Ġ/', 'Ġ100', '000', 'Ġ\\', 'n']
Detokenized (009): ['P', 'Ġ=', 'Ġphase', 'Ġ[', 'Ġpore_P', 'Ġ]', 'Ġ/', 'Ġ100000', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "a1 = - 1 / b \n"
Original    (007): ['a1', '=', '-', '1', '/', 'b', '\\n']
Tokenized   (011): ['<s>', 'a', '1', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ/', 'Ġb', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['a', '1', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ/', 'Ġb', 'Ġ\\', 'n']
Detokenized (007): ['a1', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ/', 'Ġb', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "a2 = ( R * T + b * P ) / ( a * b ) \n"
Original    (018): ['a2', '=', '(', 'R', '*', 'T', '+', 'b', '*', 'P', ')', '/', '(', 'a', '*', 'b', ')', '\\n']
Tokenized   (022): ['<s>', 'a', '2', 'Ġ=', 'Ġ(', 'ĠR', 'Ġ*', 'ĠT', 'Ġ+', 'Ġb', 'Ġ*', 'ĠP', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['a', '2', 'Ġ=', 'Ġ(', 'ĠR', 'Ġ*', 'ĠT', 'Ġ+', 'Ġb', 'Ġ*', 'ĠP', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['a2', 'Ġ=', 'Ġ(', 'ĠR', 'Ġ*', 'ĠT', 'Ġ+', 'Ġb', 'Ġ*', 'ĠP', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "a3 = - P / ( a * b ) \n"
Original    (011): ['a3', '=', '-', 'P', '/', '(', 'a', '*', 'b', ')', '\\n']
Tokenized   (015): ['<s>', 'a', '3', 'Ġ=', 'Ġ-', 'ĠP', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['a', '3', 'Ġ=', 'Ġ-', 'ĠP', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['a3', 'Ġ=', 'Ġ-', 'ĠP', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "coeffs = sp . vstack ( ( a0 , a1 , a2 , a3 ) ) . T \n"
Original    (019): ['coeffs', '=', 'sp', '.', 'vstack', '(', '(', 'a0', ',', 'a1', ',', 'a2', ',', 'a3', ')', ')', '.', 'T', '\\n']
Tokenized   (029): ['<s>', 'co', 'eff', 's', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġv', 'stack', 'Ġ(', 'Ġ(', 'Ġa', '0', 'Ġ,', 'Ġa', '1', 'Ġ,', 'Ġa', '2', 'Ġ,', 'Ġa', '3', 'Ġ)', 'Ġ)', 'Ġ.', 'ĠT', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['co', 'eff', 's', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġv', 'stack', 'Ġ(', 'Ġ(', 'Ġa', '0', 'Ġ,', 'Ġa', '1', 'Ġ,', 'Ġa', '2', 'Ġ,', 'Ġa', '3', 'Ġ)', 'Ġ)', 'Ġ.', 'ĠT', 'Ġ\\', 'n']
Detokenized (019): ['coeffs', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġvstack', 'Ġ(', 'Ġ(', 'Ġa0', 'Ġ,', 'Ġa1', 'Ġ,', 'Ġa2', 'Ġ,', 'Ġa3', 'Ġ)', 'Ġ)', 'Ġ.', 'ĠT', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "density = sp . array ( [ sp . roots ( C ) for C in coeffs ] ) \n"
Original    (020): ['density', '=', 'sp', '.', 'array', '(', '[', 'sp', '.', 'roots', '(', 'C', ')', 'for', 'C', 'in', 'coeffs', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'density', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġsp', 'Ġ.', 'Ġroots', 'Ġ(', 'ĠC', 'Ġ)', 'Ġfor', 'ĠC', 'Ġin', 'Ġco', 'eff', 's', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['density', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġsp', 'Ġ.', 'Ġroots', 'Ġ(', 'ĠC', 'Ġ)', 'Ġfor', 'ĠC', 'Ġin', 'Ġco', 'eff', 's', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['density', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġsp', 'Ġ.', 'Ġroots', 'Ġ(', 'ĠC', 'Ġ)', 'Ġfor', 'ĠC', 'Ġin', 'Ġcoeffs', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "comp2 = OpenPNM . Phases . GenericPhase ( network = self . net ) \n"
Original    (015): ['comp2', '=', 'OpenPNM', '.', 'Phases', '.', 'GenericPhase', '(', 'network', '=', 'self', '.', 'net', ')', '\\n']
Tokenized   (023): ['<s>', 'comp', '2', 'Ġ=', 'ĠOpen', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['comp', '2', 'Ġ=', 'ĠOpen', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['comp2', 'Ġ=', 'ĠOpenPNM', 'Ġ.', 'ĠPhases', 'Ġ.', 'ĠGenericPhase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "OpenPNM . Phases . GenericPhase ( network = self . net , \n"
Original    (013): ['OpenPNM', '.', 'Phases', '.', 'GenericPhase', '(', 'network', '=', 'self', '.', 'net', ',', '\\n']
Tokenized   (020): ['<s>', 'Open', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['Open', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['OpenPNM', 'Ġ.', 'ĠPhases', 'Ġ.', 'ĠGenericPhase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "components = [ comp1 , comp2 ] ) \n"
Original    (009): ['components', '=', '[', 'comp1', ',', 'comp2', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'comp', 'onents', 'Ġ=', 'Ġ[', 'Ġcomp', '1', 'Ġ,', 'Ġcomp', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['comp', 'onents', 'Ġ=', 'Ġ[', 'Ġcomp', '1', 'Ġ,', 'Ġcomp', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['components', 'Ġ=', 'Ġ[', 'Ġcomp1', 'Ġ,', 'Ġcomp2', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "phase . set_component ( comp2 , mode = ) \n"
Original    (010): ['phase', '.', 'set_component', '(', 'comp2', ',', 'mode', '=', ')', '\\n']
Tokenized   (016): ['<s>', 'phase', 'Ġ.', 'Ġset', '_', 'component', 'Ġ(', 'Ġcomp', '2', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['phase', 'Ġ.', 'Ġset', '_', 'component', 'Ġ(', 'Ġcomp', '2', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['phase', 'Ġ.', 'Ġset_component', 'Ġ(', 'Ġcomp2', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "best_seq = fd [ x ] . sequence \n"
Original    (009): ['best_seq', '=', 'fd', '[', 'x', ']', '.', 'sequence', '\\n']
Tokenized   (015): ['<s>', 'best', '_', 'seq', 'Ġ=', 'Ġf', 'd', 'Ġ[', 'Ġx', 'Ġ]', 'Ġ.', 'Ġsequence', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['best', '_', 'seq', 'Ġ=', 'Ġf', 'd', 'Ġ[', 'Ġx', 'Ġ]', 'Ġ.', 'Ġsequence', 'Ġ\\', 'n']
Detokenized (009): ['best_seq', 'Ġ=', 'Ġfd', 'Ġ[', 'Ġx', 'Ġ]', 'Ġ.', 'Ġsequence', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "best_id , best_seq , best_qual = rep_info [ pb_id ] \n"
Original    (011): ['best_id', ',', 'best_seq', ',', 'best_qual', '=', 'rep_info', '[', 'pb_id', ']', '\\n']
Tokenized   (025): ['<s>', 'best', '_', 'id', 'Ġ,', 'Ġbest', '_', 'seq', 'Ġ,', 'Ġbest', '_', 'qual', 'Ġ=', 'Ġrep', '_', 'info', 'Ġ[', 'Ġp', 'b', '_', 'id', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['best', '_', 'id', 'Ġ,', 'Ġbest', '_', 'seq', 'Ġ,', 'Ġbest', '_', 'qual', 'Ġ=', 'Ġrep', '_', 'info', 'Ġ[', 'Ġp', 'b', '_', 'id', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['best_id', 'Ġ,', 'Ġbest_seq', 'Ġ,', 'Ġbest_qual', 'Ġ=', 'Ġrep_info', 'Ġ[', 'Ġpb_id', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_id_ = "{0}|{1}|{2}" . format ( pb_id , coords [ best_id ] , best_id ) \n"
Original    (016): ['_id_', '=', '"{0}|{1}|{2}"', '.', 'format', '(', 'pb_id', ',', 'coords', '[', 'best_id', ']', ',', 'best_id', ')', '\\n']
Tokenized   (039): ['<s>', '_', 'id', '_', 'Ġ=', 'Ġ"{', '0', '}', '|', '{', '1', '}', '|', '{', '2', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'b', '_', 'id', 'Ġ,', 'Ġco', 'ords', 'Ġ[', 'Ġbest', '_', 'id', 'Ġ]', 'Ġ,', 'Ġbest', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['_', 'id', '_', 'Ġ=', 'Ġ"{', '0', '}', '|', '{', '1', '}', '|', '{', '2', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'b', '_', 'id', 'Ġ,', 'Ġco', 'ords', 'Ġ[', 'Ġbest', '_', 'id', 'Ġ]', 'Ġ,', 'Ġbest', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['_id_', 'Ġ=', 'Ġ"{0}|{1}|{2}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpb_id', 'Ġ,', 'Ġcoords', 'Ġ[', 'Ġbest_id', 'Ġ]', 'Ġ,', 'Ġbest_id', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "iter = BioReaders . GMAPSAMReader ( gmap_sam_filename , True , query_len_dict = transfrag_len_dict ) \n"
Original    (015): ['iter', '=', 'BioReaders', '.', 'GMAPSAMReader', '(', 'gmap_sam_filename', ',', 'True', ',', 'query_len_dict', '=', 'transfrag_len_dict', ')', '\\n']
Tokenized   (038): ['<s>', 'iter', 'Ġ=', 'ĠBio', 'Read', 'ers', 'Ġ.', 'ĠGM', 'APS', 'AM', 'Reader', 'Ġ(', 'Ġg', 'map', '_', 'sam', '_', 'filename', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġquery', '_', 'len', '_', 'dict', 'Ġ=', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['iter', 'Ġ=', 'ĠBio', 'Read', 'ers', 'Ġ.', 'ĠGM', 'APS', 'AM', 'Reader', 'Ġ(', 'Ġg', 'map', '_', 'sam', '_', 'filename', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġquery', '_', 'len', '_', 'dict', 'Ġ=', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['iter', 'Ġ=', 'ĠBioReaders', 'Ġ.', 'ĠGMAPSAMReader', 'Ġ(', 'Ġgmap_sam_filename', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġquery_len_dict', 'Ġ=', 'Ġtransfrag_len_dict', 'Ġ)', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "TmpRec = namedtuple ( , [ , , , , , , ] ) \n"
Original    (015): ['TmpRec', '=', 'namedtuple', '(', ',', '[', ',', ',', ',', ',', ',', ',', ']', ')', '\\n']
Tokenized   (022): ['<s>', 'T', 'mp', 'Rec', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['T', 'mp', 'Rec', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['TmpRec', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "compressed_records_pointer_dict = defaultdict ( lambda : [ ] ) \n"
Original    (010): ['compressed_records_pointer_dict', '=', 'defaultdict', '(', 'lambda', ':', '[', ']', ')', '\\n']
Tokenized   (022): ['<s>', 'comp', 'ressed', '_', 'rec', 'ords', '_', 'pointer', '_', 'dict', 'Ġ=', 'Ġdefault', 'dict', 'Ġ(', 'Ġlambda', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['comp', 'ressed', '_', 'rec', 'ords', '_', 'pointer', '_', 'dict', 'Ġ=', 'Ġdefault', 'dict', 'Ġ(', 'Ġlambda', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['compressed_records_pointer_dict', 'Ġ=', 'Ġdefaultdict', 'Ġ(', 'Ġlambda', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "check_ids_unique ( fa_or_fq_filename , is_fq = is_fq ) \n"
Original    (009): ['check_ids_unique', '(', 'fa_or_fq_filename', ',', 'is_fq', '=', 'is_fq', ')', '\\n']
Tokenized   (029): ['<s>', 'check', '_', 'ids', '_', 'unique', 'Ġ(', 'Ġfa', '_', 'or', '_', 'f', 'q', '_', 'filename', 'Ġ,', 'Ġis', '_', 'f', 'q', 'Ġ=', 'Ġis', '_', 'f', 'q', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['check', '_', 'ids', '_', 'unique', 'Ġ(', 'Ġfa', '_', 'or', '_', 'f', 'q', '_', 'filename', 'Ġ,', 'Ġis', '_', 'f', 'q', 'Ġ=', 'Ġis', '_', 'f', 'q', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['check_ids_unique', 'Ġ(', 'Ġfa_or_fq_filename', 'Ġ,', 'Ġis_fq', 'Ġ=', 'Ġis_fq', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "fusion_candidates = find_fusion_candidates ( sam_filename , bs . transfrag_len_dict , min_locus_coverage \n"
Original    (012): ['fusion_candidates', '=', 'find_fusion_candidates', '(', 'sam_filename', ',', 'bs', '.', 'transfrag_len_dict', ',', 'min_locus_coverage', '\\n']
Tokenized   (040): ['<s>', 'f', 'usion', '_', 'cand', 'idates', 'Ġ=', 'Ġfind', '_', 'f', 'usion', '_', 'cand', 'idates', 'Ġ(', 'Ġsam', '_', 'filename', 'Ġ,', 'Ġb', 's', 'Ġ.', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['f', 'usion', '_', 'cand', 'idates', 'Ġ=', 'Ġfind', '_', 'f', 'usion', '_', 'cand', 'idates', 'Ġ(', 'Ġsam', '_', 'filename', 'Ġ,', 'Ġb', 's', 'Ġ.', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ\\', 'n']
Detokenized (012): ['fusion_candidates', 'Ġ=', 'Ġfind_fusion_candidates', 'Ġ(', 'Ġsam_filename', 'Ġ,', 'Ġbs', 'Ġ.', 'Ġtransfrag_len_dict', 'Ġ,', 'Ġmin_locus_coverage', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "pbid1 , groups1 = line . strip ( ) . split ( ) \n"
Original    (014): ['pbid1', ',', 'groups1', '=', 'line', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (020): ['<s>', 'p', 'bid', '1', 'Ġ,', 'Ġgroups', '1', 'Ġ=', 'Ġline', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['p', 'bid', '1', 'Ġ,', 'Ġgroups', '1', 'Ġ=', 'Ġline', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['pbid1', 'Ġ,', 'Ġgroups1', 'Ġ=', 'Ġline', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pbid2 , groups2 = f . readline ( ) . strip ( ) . split ( ) \n"
Original    (018): ['pbid2', ',', 'groups2', '=', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (025): ['<s>', 'p', 'bid', '2', 'Ġ,', 'Ġgroups', '2', 'Ġ=', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['p', 'bid', '2', 'Ġ,', 'Ġgroups', '2', 'Ġ=', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['pbid2', 'Ġ,', 'Ġgroups2', 'Ġ=', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "f_group . write ( "{0}\\t{1}\\n" . format ( pbid1 [ : pbid1 . rfind ( ) ] , "," . join ( group ) ) ) \n"
Original    (027): ['f_group', '.', 'write', '(', '"{0}\\\\t{1}\\\\n"', '.', 'format', '(', 'pbid1', '[', ':', 'pbid1', '.', 'rfind', '(', ')', ']', ',', '","', '.', 'join', '(', 'group', ')', ')', ')', '\\n']
Tokenized   (048): ['<s>', 'f', '_', 'group', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"{', '0', '}', '\\\\', 't', '{', '1', '}', '\\\\', 'n', '"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ"', ',"', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['f', '_', 'group', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"{', '0', '}', '\\\\', 't', '{', '1', '}', '\\\\', 'n', '"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ"', ',"', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['f_group', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"{0}\\\\t{1}\\\\n"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpbid1', 'Ġ[', 'Ġ:', 'Ġpbid1', 'Ġ.', 'Ġrfind', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ","', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "group_info [ pbid1 [ : pbid1 . rfind ( ) ] ] = list ( group ) \n"
Original    (018): ['group_info', '[', 'pbid1', '[', ':', 'pbid1', '.', 'rfind', '(', ')', ']', ']', '=', 'list', '(', 'group', ')', '\\n']
Tokenized   (028): ['<s>', 'group', '_', 'info', 'Ġ[', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ]', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['group', '_', 'info', 'Ġ[', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ]', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['group_info', 'Ġ[', 'Ġpbid1', 'Ġ[', 'Ġ:', 'Ġpbid1', 'Ġ.', 'Ġrfind', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ]', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "d1 . update ( d [ ] ) \n"
Original    (009): ['d1', '.', 'update', '(', 'd', '[', ']', ')', '\\n']
Tokenized   (013): ['<s>', 'd', '1', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġd', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['d', '1', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġd', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['d1', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġd', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "fusion_main ( args . input , args . sam , args . prefix , \n"
Original    (015): ['fusion_main', '(', 'args', '.', 'input', ',', 'args', '.', 'sam', ',', 'args', '.', 'prefix', ',', '\\n']
Tokenized   (021): ['<s>', 'f', 'usion', '_', 'main', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġinput', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġsam', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['f', 'usion', '_', 'main', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġinput', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġsam', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['fusion_main', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġinput', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġsam', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "is_fq = args . fq , allow_extra_5_exons = args . allow_extra_5exon , \n"
Original    (013): ['is_fq', '=', 'args', '.', 'fq', ',', 'allow_extra_5_exons', '=', 'args', '.', 'allow_extra_5exon', ',', '\\n']
Tokenized   (033): ['<s>', 'is', '_', 'f', 'q', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġf', 'q', 'Ġ,', 'Ġallow', '_', 'extra', '_', '5', '_', 'ex', 'ons', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġallow', '_', 'extra', '_', '5', 'ex', 'on', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['is', '_', 'f', 'q', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġf', 'q', 'Ġ,', 'Ġallow', '_', 'extra', '_', '5', '_', 'ex', 'ons', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġallow', '_', 'extra', '_', '5', 'ex', 'on', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['is_fq', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġfq', 'Ġ,', 'Ġallow_extra_5_exons', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġallow_extra_5exon', 'Ġ,', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "skip_5_exon_alt = False , prefix_dict_pickle_filename = args . prefix_dict_pickle_filename , min_locus_coverage = args . min_locus_coverage , min_locus_coverage_bp = args . min_locus_coverage_bp min_total_coverage = args . min_total_coverage , \n"
Original    (028): ['skip_5_exon_alt', '=', 'False', ',', 'prefix_dict_pickle_filename', '=', 'args', '.', 'prefix_dict_pickle_filename', ',', 'min_locus_coverage', '=', 'args', '.', 'min_locus_coverage', ',', 'min_locus_coverage_bp', '=', 'args', '.', 'min_locus_coverage_bp', 'min_total_coverage', '=', 'args', '.', 'min_total_coverage', ',', '\\n']
Tokenized   (090): ['<s>', 'skip', '_', '5', '_', 'ex', 'on', '_', 'alt', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (088): ['skip', '_', '5', '_', 'ex', 'on', '_', 'alt', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ,', 'Ġ\\', 'n']
Detokenized (028): ['skip_5_exon_alt', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġprefix_dict_pickle_filename', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġprefix_dict_pickle_filename', 'Ġ,', 'Ġmin_locus_coverage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin_locus_coverage', 'Ġ,', 'Ġmin_locus_coverage_bp', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin_locus_coverage_bp', 'Ġmin_total_coverage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin_total_coverage', 'Ġ,', 'Ġ\\n']
Counter: 88
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "raw = self . f . readline ( ) . strip ( ) . split ( ) \n"
Original    (018): ['raw', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (022): ['<s>', 'raw', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['raw', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['raw', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "iden = float ( raw [ 3 ] ) \n"
Original    (010): ['iden', '=', 'float', '(', 'raw', '[', '3', ']', ')', '\\n']
Tokenized   (013): ['<s>', 'iden', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġraw', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['iden', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġraw', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['iden', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġraw', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_qStart , qAln = self . f . readline ( ) . strip ( ) . split ( ) \n"
Original    (020): ['_qStart', ',', 'qAln', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (028): ['<s>', '_', 'q', 'Start', 'Ġ,', 'Ġq', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['_', 'q', 'Start', 'Ġ,', 'Ġq', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['_qStart', 'Ġ,', 'ĠqAln', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "_sStart , sAln = self . f . readline ( ) . strip ( ) . split ( ) [ : 2 ] \n"
Original    (024): ['_sStart', ',', 'sAln', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '[', ':', '2', ']', '\\n']
Tokenized   (032): ['<s>', '_', 's', 'Start', 'Ġ,', 'Ġs', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['_', 's', 'Start', 'Ġ,', 'Ġs', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (024): ['_sStart', 'Ġ,', 'ĠsAln', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "missed_q = missed_q * 1. / r . qLength , \n"
Original    (011): ['missed_q', '=', 'missed_q', '*', '1.', '/', 'r', '.', 'qLength', ',', '\\n']
Tokenized   (021): ['<s>', 'miss', 'ed', '_', 'q', 'Ġ=', 'Ġmissed', '_', 'q', 'Ġ*', 'Ġ1', '.', 'Ġ/', 'Ġr', 'Ġ.', 'Ġq', 'Length', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['miss', 'ed', '_', 'q', 'Ġ=', 'Ġmissed', '_', 'q', 'Ġ*', 'Ġ1', '.', 'Ġ/', 'Ġr', 'Ġ.', 'Ġq', 'Length', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['missed_q', 'Ġ=', 'Ġmissed_q', 'Ġ*', 'Ġ1.', 'Ġ/', 'Ġr', 'Ġ.', 'ĠqLength', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "ece_penalty , ece_min_len ) : \n"
Original    (006): ['ece_penalty', ',', 'ece_min_len', ')', ':', '\\n']
Tokenized   (018): ['<s>', 'e', 'ce', '_', 'pen', 'alty', 'Ġ,', 'Ġe', 'ce', '_', 'min', '_', 'len', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['e', 'ce', '_', 'pen', 'alty', 'Ġ,', 'Ġe', 'ce', '_', 'min', '_', 'len', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['ece_penalty', 'Ġ,', 'Ġece_min_len', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "heading = % ( current_indent , , self . heading ) \n"
Original    (012): ['heading', '=', '%', '(', 'current_indent', ',', ',', 'self', '.', 'heading', ')', '\\n']
Tokenized   (018): ['<s>', 'heading', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġcurrent', '_', 'ind', 'ent', 'Ġ,', 'Ġ,', 'Ġself', 'Ġ.', 'Ġheading', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['heading', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġcurrent', '_', 'ind', 'ent', 'Ġ,', 'Ġ,', 'Ġself', 'Ġ.', 'Ġheading', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['heading', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġcurrent_indent', 'Ġ,', 'Ġ,', 'Ġself', 'Ġ.', 'Ġheading', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "section = self . _Section ( self , self . _current_section , heading ) \n"
Original    (015): ['section', '=', 'self', '.', '_Section', '(', 'self', ',', 'self', '.', '_current_section', ',', 'heading', ')', '\\n']
Tokenized   (022): ['<s>', 'section', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'Section', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'section', 'Ġ,', 'Ġheading', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['section', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'Section', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'section', 'Ġ,', 'Ġheading', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['section', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_Section', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_current_section', 'Ġ,', 'Ġheading', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "invocations = [ get_invocation ( action ) ] \n"
Original    (009): ['invocations', '=', '[', 'get_invocation', '(', 'action', ')', ']', '\\n']
Tokenized   (016): ['<s>', 'inv', 'ocations', 'Ġ=', 'Ġ[', 'Ġget', '_', 'inv', 'ocation', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['inv', 'ocations', 'Ġ=', 'Ġ[', 'Ġget', '_', 'inv', 'ocation', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['invocations', 'Ġ=', 'Ġ[', 'Ġget_invocation', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "action_usage = format ( optionals + positionals , groups ) \n"
Original    (011): ['action_usage', '=', 'format', '(', 'optionals', '+', 'positionals', ',', 'groups', ')', '\\n']
Tokenized   (018): ['<s>', 'action', '_', 'usage', 'Ġ=', 'Ġformat', 'Ġ(', 'Ġoption', 'als', 'Ġ+', 'Ġposition', 'als', 'Ġ,', 'Ġgroups', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['action', '_', 'usage', 'Ġ=', 'Ġformat', 'Ġ(', 'Ġoption', 'als', 'Ġ+', 'Ġposition', 'als', 'Ġ,', 'Ġgroups', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['action_usage', 'Ġ=', 'Ġformat', 'Ġ(', 'Ġoptionals', 'Ġ+', 'Ġpositionals', 'Ġ,', 'Ġgroups', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "text_width = self . _width - self . _current_indent \n"
Original    (010): ['text_width', '=', 'self', '.', '_width', '-', 'self', '.', '_current_indent', '\\n']
Tokenized   (020): ['<s>', 'text', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['text', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n']
Detokenized (010): ['text_width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_width', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_current_indent', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "line_len += len ( part ) + 1 \n"
Original    (009): ['line_len', '+=', 'len', '(', 'part', ')', '+', '1', '\\n']
Tokenized   (014): ['<s>', 'line', '_', 'len', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġpart', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['line', '_', 'len', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġpart', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (009): ['line_len', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġpart', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "part = % ( option_string , args_string ) \n"
Original    (009): ['part', '=', '%', '(', 'option_string', ',', 'args_string', ')', '\\n']
Tokenized   (016): ['<s>', 'part', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġoption', '_', 'string', 'Ġ,', 'Ġargs', '_', 'string', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['part', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġoption', '_', 'string', 'Ġ,', 'Ġargs', '_', 'string', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['part', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġoption_string', 'Ġ,', 'Ġargs_string', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "indent = * self . _current_indent \n"
Original    (007): ['indent', '=', '*', 'self', '.', '_current_indent', '\\n']
Tokenized   (015): ['<s>', 'ind', 'ent', 'Ġ=', 'Ġ*', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ind', 'ent', 'Ġ=', 'Ġ*', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n']
Detokenized (007): ['indent', 'Ġ=', 'Ġ*', 'Ġself', 'Ġ.', 'Ġ_current_indent', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "help_width = self . _width - help_position \n"
Original    (008): ['help_width', '=', 'self', '.', '_width', '-', 'help_position', '\\n']
Tokenized   (016): ['<s>', 'help', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġhelp', '_', 'position', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['help', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġhelp', '_', 'position', 'Ġ\\', 'n']
Detokenized (008): ['help_width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_width', 'Ġ-', 'Ġhelp_position', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "action_width = help_position - self . _current_indent - 2 \n"
Original    (010): ['action_width', '=', 'help_position', '-', 'self', '.', '_current_indent', '-', '2', '\\n']
Tokenized   (021): ['<s>', 'action', '_', 'width', 'Ġ=', 'Ġhelp', '_', 'position', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ-', 'Ġ2', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['action', '_', 'width', 'Ġ=', 'Ġhelp', '_', 'position', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ-', 'Ġ2', 'Ġ\\', 'n']
Detokenized (010): ['action_width', 'Ġ=', 'Ġhelp_position', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_current_indent', 'Ġ-', 'Ġ2', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sup . __init__ ( option_strings = [ ] , dest = name , help = help ) \n"
Original    (018): ['sup', '.', '__init__', '(', 'option_strings', '=', '[', ']', ',', 'dest', '=', 'name', ',', 'help', '=', 'help', ')', '\\n']
Tokenized   (025): ['<s>', 'sup', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġoption', '_', 'strings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġname', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġhelp', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['sup', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġoption', '_', 'strings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġname', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġhelp', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['sup', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġoption_strings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġname', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġhelp', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "arg_strings = values [ 1 : ] \n"
Original    (008): ['arg_strings', '=', 'values', '[', '1', ':', ']', '\\n']
Tokenized   (013): ['<s>', 'arg', '_', 'strings', 'Ġ=', 'Ġvalues', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['arg', '_', 'strings', 'Ġ=', 'Ġvalues', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['arg_strings', 'Ġ=', 'Ġvalues', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "args_str = . join ( [ repr ( arg ) for arg in args if arg is not None ] ) \n"
Original    (022): ['args_str', '=', '.', 'join', '(', '[', 'repr', '(', 'arg', ')', 'for', 'arg', 'in', 'args', 'if', 'arg', 'is', 'not', 'None', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'args', '_', 'str', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġfor', 'Ġarg', 'Ġin', 'Ġargs', 'Ġif', 'Ġarg', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['args', '_', 'str', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġfor', 'Ġarg', 'Ġin', 'Ġargs', 'Ġif', 'Ġarg', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['args_str', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġfor', 'Ġarg', 'Ġin', 'Ġargs', 'Ġif', 'Ġarg', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "type_func = self . _registry_get ( , action . type , action . type ) \n"
Original    (016): ['type_func', '=', 'self', '.', '_registry_get', '(', ',', 'action', '.', 'type', ',', 'action', '.', 'type', ')', '\\n']
Tokenized   (025): ['<s>', 'type', '_', 'func', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'reg', 'istry', '_', 'get', 'Ġ(', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['type', '_', 'func', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'reg', 'istry', '_', 'get', 'Ġ(', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['type_func', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_registry_get', 'Ġ(', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "conflict_string = . join ( [ option_string \n"
Original    (008): ['conflict_string', '=', '.', 'join', '(', '[', 'option_string', '\\n']
Tokenized   (016): ['<s>', 'conf', 'lict', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġoption', '_', 'string', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['conf', 'lict', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġoption', '_', 'string', 'Ġ\\', 'n']
Detokenized (008): ['conflict_string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġoption_string', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "in conflicting_actions ] ) \n"
Original    (005): ['in', 'conflicting_actions', ']', ')', '\\n']
Tokenized   (010): ['<s>', 'in', 'Ġconflicting', '_', 'actions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['in', 'Ġconflicting', '_', 'actions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['in', 'Ġconflicting_actions', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "super_init ( description = description , ** kwargs ) \n"
Original    (010): ['super_init', '(', 'description', '=', 'description', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (017): ['<s>', 'super', '_', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['super', '_', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['super_init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : """"instead""" , DeprecationWarning ) \n"
Original    (005): ['"""instead"""', ',', 'DeprecationWarning', ')', '\\n']
Tokenized   (013): ['<s>', '"""', 'instead', '"""', 'Ġ,', 'ĠDep', 'rec', 'ation', 'Warning', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['"""', 'instead', '"""', 'Ġ,', 'ĠDep', 'rec', 'ation', 'Warning', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['"""instead"""', 'Ġ,', 'ĠDeprecationWarning', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "superinit ( description = description , \n"
Original    (007): ['superinit', '(', 'description', '=', 'description', ',', '\\n']
Tokenized   (011): ['<s>', 'super', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['super', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['superinit', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "default_prefix + , default_prefix * 2 + , \n"
Original    (009): ['default_prefix', '+', ',', 'default_prefix', '*', '2', '+', ',', '\\n']
Tokenized   (016): ['<s>', 'default', '_', 'prefix', 'Ġ+', 'Ġ,', 'Ġdefault', '_', 'prefix', 'Ġ*', 'Ġ2', 'Ġ+', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['default', '_', 'prefix', 'Ġ+', 'Ġ,', 'Ġdefault', '_', 'prefix', 'Ġ*', 'Ġ2', 'Ġ+', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['default_prefix', 'Ġ+', 'Ġ,', 'Ġdefault_prefix', 'Ġ*', 'Ġ2', 'Ġ+', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "conflicts . extend ( group_actions [ i + 1 : ] ) \n"
Original    (013): ['conflicts', '.', 'extend', '(', 'group_actions', '[', 'i', '+', '1', ':', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'conf', 'licts', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgroup', '_', 'actions', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['conf', 'licts', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgroup', '_', 'actions', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['conflicts', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgroup_actions', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "action , option_string , explicit_arg = option_tuple \n"
Original    (008): ['action', ',', 'option_string', ',', 'explicit_arg', '=', 'option_tuple', '\\n']
Tokenized   (018): ['<s>', 'action', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġexplicit', '_', 'arg', 'Ġ=', 'Ġoption', '_', 't', 'uple', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['action', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġexplicit', '_', 'arg', 'Ġ=', 'Ġoption', '_', 't', 'uple', 'Ġ\\', 'n']
Detokenized (008): ['action', 'Ġ,', 'Ġoption_string', 'Ġ,', 'Ġexplicit_arg', 'Ġ=', 'Ġoption_tuple', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "option_string = char + explicit_arg [ 0 ] \n"
Original    (009): ['option_string', '=', 'char', '+', 'explicit_arg', '[', '0', ']', '\\n']
Tokenized   (016): ['<s>', 'option', '_', 'string', 'Ġ=', 'Ġchar', 'Ġ+', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['option', '_', 'string', 'Ġ=', 'Ġchar', 'Ġ+', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['option_string', 'Ġ=', 'Ġchar', 'Ġ+', 'Ġexplicit_arg', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "new_explicit_arg = explicit_arg [ 1 : ] or None \n"
Original    (010): ['new_explicit_arg', '=', 'explicit_arg', '[', '1', ':', ']', 'or', 'None', '\\n']
Tokenized   (020): ['<s>', 'new', '_', 'expl', 'icit', '_', 'arg', 'Ġ=', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['new', '_', 'expl', 'icit', '_', 'arg', 'Ġ=', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n']
Detokenized (010): ['new_explicit_arg', 'Ġ=', 'Ġexplicit_arg', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "action_tuples . append ( ( action , args , option_string ) ) \n"
Original    (013): ['action_tuples', '.', 'append', '(', '(', 'action', ',', 'args', ',', 'option_string', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'action', '_', 'tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġaction', 'Ġ,', 'Ġargs', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['action', '_', 'tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġaction', 'Ġ,', 'Ġargs', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['action_tuples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġaction', 'Ġ,', 'Ġargs', 'Ġ,', 'Ġoption_string', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "selected_patterns = arg_strings_pattern [ start : ] \n"
Original    (008): ['selected_patterns', '=', 'arg_strings_pattern', '[', 'start', ':', ']', '\\n']
Tokenized   (018): ['<s>', 'selected', '_', 'pattern', 's', 'Ġ=', 'Ġarg', '_', 'strings', '_', 'pattern', 'Ġ[', 'Ġstart', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['selected', '_', 'pattern', 's', 'Ġ=', 'Ġarg', '_', 'strings', '_', 'pattern', 'Ġ[', 'Ġstart', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['selected_patterns', 'Ġ=', 'Ġarg_strings_pattern', 'Ġ[', 'Ġstart', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "extras . extend ( arg_strings [ stop_index : ] ) \n"
Original    (011): ['extras', '.', 'extend', '(', 'arg_strings', '[', 'stop_index', ':', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'ext', 'ras', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġarg', '_', 'strings', 'Ġ[', 'Ġstop', '_', 'index', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['ext', 'ras', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġarg', '_', 'strings', 'Ġ[', 'Ġstop', '_', 'index', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['extras', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġarg_strings', 'Ġ[', 'Ġstop_index', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "OPTIONAL : _ ( ) , \n"
Original    (007): ['OPTIONAL', ':', '_', '(', ')', ',', '\\n']
Tokenized   (012): ['<s>', 'OP', 'TION', 'AL', 'Ġ:', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['OP', 'TION', 'AL', 'Ġ:', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['OPTIONAL', 'Ġ:', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "pattern = . join ( [ self . _get_nargs_pattern ( action ) \n"
Original    (013): ['pattern', '=', '.', 'join', '(', '[', 'self', '.', '_get_nargs_pattern', '(', 'action', ')', '\\n']
Tokenized   (022): ['<s>', 'pattern', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'n', 'args', '_', 'pattern', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['pattern', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'n', 'args', '_', 'pattern', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['pattern', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_get_nargs_pattern', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "short_option_prefix = option_string [ : 2 ] \n"
Original    (008): ['short_option_prefix', '=', 'option_string', '[', ':', '2', ']', '\\n']
Tokenized   (017): ['<s>', 'short', '_', 'option', '_', 'prefix', 'Ġ=', 'Ġoption', '_', 'string', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['short', '_', 'option', '_', 'prefix', 'Ġ=', 'Ġoption', '_', 'string', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['short_option_prefix', 'Ġ=', 'Ġoption_string', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "tup = action , option_string , short_explicit_arg \n"
Original    (008): ['tup', '=', 'action', ',', 'option_string', ',', 'short_explicit_arg', '\\n']
Tokenized   (019): ['<s>', 't', 'up', 'Ġ=', 'Ġaction', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġshort', '_', 'expl', 'icit', '_', 'arg', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['t', 'up', 'Ġ=', 'Ġaction', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġshort', '_', 'expl', 'icit', '_', 'arg', 'Ġ\\', 'n']
Detokenized (008): ['tup', 'Ġ=', 'Ġaction', 'Ġ,', 'Ġoption_string', 'Ġ,', 'Ġshort_explicit_arg', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "not action . option_strings ) : \n"
Original    (007): ['not', 'action', '.', 'option_strings', ')', ':', '\\n']
Tokenized   (012): ['<s>', 'not', 'Ġaction', 'Ġ.', 'Ġoption', '_', 'strings', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['not', 'Ġaction', 'Ġ.', 'Ġoption', '_', 'strings', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (007): ['not', 'Ġaction', 'Ġ.', 'Ġoption_strings', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "vulnerability = obj [ ] [ ] [ ] [ ] [ ] \n"
Original    (014): ['vulnerability', '=', 'obj', '[', ']', '[', ']', '[', ']', '[', ']', '[', ']', '\\n']
Tokenized   (018): ['<s>', 'v', 'ulnerability', 'Ġ=', 'Ġobj', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['v', 'ulnerability', 'Ġ=', 'Ġobj', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['vulnerability', 'Ġ=', 'Ġobj', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "apikey = common . apikey ( sessionKey , args [ 0 ] , debug ) \n"
Original    (016): ['apikey', '=', 'common', '.', 'apikey', '(', 'sessionKey', ',', 'args', '[', '0', ']', ',', 'debug', ')', '\\n']
Tokenized   (024): ['<s>', 'ap', 'ike', 'y', 'Ġ=', 'Ġcommon', 'Ġ.', 'Ġap', 'ike', 'y', 'Ġ(', 'Ġsession', 'Key', 'Ġ,', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġdebug', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ap', 'ike', 'y', 'Ġ=', 'Ġcommon', 'Ġ.', 'Ġap', 'ike', 'y', 'Ġ(', 'Ġsession', 'Key', 'Ġ,', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġdebug', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['apikey', 'Ġ=', 'Ġcommon', 'Ġ.', 'Ġapikey', 'Ġ(', 'ĠsessionKey', 'Ġ,', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġdebug', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "device = pandevice . base . PanDevice ( args [ 0 ] , api_key = apikey ) \n"
Original    (018): ['device', '=', 'pandevice', '.', 'base', '.', 'PanDevice', '(', 'args', '[', '0', ']', ',', 'api_key', '=', 'apikey', ')', '\\n']
Tokenized   (028): ['<s>', 'device', 'Ġ=', 'Ġpand', 'ev', 'ice', 'Ġ.', 'Ġbase', 'Ġ.', 'ĠPan', 'Device', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġapi', '_', 'key', 'Ġ=', 'Ġap', 'ike', 'y', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['device', 'Ġ=', 'Ġpand', 'ev', 'ice', 'Ġ.', 'Ġbase', 'Ġ.', 'ĠPan', 'Device', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġapi', '_', 'key', 'Ġ=', 'Ġap', 'ike', 'y', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['device', 'Ġ=', 'Ġpandevice', 'Ġ.', 'Ġbase', 'Ġ.', 'ĠPanDevice', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġapi_key', 'Ġ=', 'Ġapikey', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "rebalance_backoff_ms = 2 * 1000 , \n"
Original    (007): ['rebalance_backoff_ms', '=', '2', '*', '1000', ',', '\\n']
Tokenized   (016): ['<s>', 're', 'balance', '_', 'back', 'off', '_', 'ms', 'Ġ=', 'Ġ2', 'Ġ*', 'Ġ1000', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['re', 'balance', '_', 'back', 'off', '_', 'ms', 'Ġ=', 'Ġ2', 'Ġ*', 'Ġ1000', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['rebalance_backoff_ms', 'Ġ=', 'Ġ2', 'Ġ*', 'Ġ1000', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "uuid = uuid4 ( ) \n"
Original    (006): ['uuid', '=', 'uuid4', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'uu', 'id', 'Ġ=', 'Ġu', 'uid', '4', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['uu', 'id', 'Ġ=', 'Ġu', 'uid', '4', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['uuid', 'Ġ=', 'Ġuuid4', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : """ . join ( traceback . format_tb ( tb ) ) ) \n"
Original    (013): ['""', '.', 'join', '(', 'traceback', '.', 'format_tb', '(', 'tb', ')', ')', ')', '\\n']
Tokenized   (021): ['<s>', '""', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġtrace', 'back', 'Ġ.', 'Ġformat', '_', 't', 'b', 'Ġ(', 'Ġt', 'b', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['""', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġtrace', 'back', 'Ġ.', 'Ġformat', '_', 't', 'b', 'Ġ(', 'Ġt', 'b', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['""', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġtraceback', 'Ġ.', 'Ġformat_tb', 'Ġ(', 'Ġtb', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "kazoo_kwargs = { : timeout / 1000 } \n"
Original    (009): ['kazoo_kwargs', '=', '{', ':', 'timeout', '/', '1000', '}', '\\n']
Tokenized   (017): ['<s>', 'k', 'az', 'oo', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġtimeout', 'Ġ/', 'Ġ1000', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['k', 'az', 'oo', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġtimeout', 'Ġ/', 'Ġ1000', 'Ġ}', 'Ġ\\', 'n']
Detokenized (009): ['kazoo_kwargs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġtimeout', 'Ġ/', 'Ġ1000', 'Ġ}', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "p_to_str = lambda p : . join ( [ str ( p . topic . name ) , str ( p . leader . id ) , str ( p . id ) ] ) \n"
Original    (036): ['p_to_str', '=', 'lambda', 'p', ':', '.', 'join', '(', '[', 'str', '(', 'p', '.', 'topic', '.', 'name', ')', ',', 'str', '(', 'p', '.', 'leader', '.', 'id', ')', ',', 'str', '(', 'p', '.', 'id', ')', ']', ')', '\\n']
Tokenized   (043): ['<s>', 'p', '_', 'to', '_', 'str', 'Ġ=', 'Ġlambda', 'Ġp', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġtopic', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġleader', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['p', '_', 'to', '_', 'str', 'Ġ=', 'Ġlambda', 'Ġp', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġtopic', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġleader', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (036): ['p_to_str', 'Ġ=', 'Ġlambda', 'Ġp', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġtopic', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġleader', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "idx = participants . index ( consumer_id or self . _consumer_id ) \n"
Original    (013): ['idx', '=', 'participants', '.', 'index', '(', 'consumer_id', 'or', 'self', '.', '_consumer_id', ')', '\\n']
Tokenized   (022): ['<s>', 'id', 'x', 'Ġ=', 'Ġparticipants', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġconsumer', '_', 'id', 'Ġor', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['id', 'x', 'Ġ=', 'Ġparticipants', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġconsumer', '_', 'id', 'Ġor', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['idx', 'Ġ=', 'Ġparticipants', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġconsumer_id', 'Ġor', 'Ġself', 'Ġ.', 'Ġ_consumer_id', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "parts_per_consumer = len ( all_parts ) // len ( participants ) \n"
Original    (012): ['parts_per_consumer', '=', 'len', '(', 'all_parts', ')', '//', 'len', '(', 'participants', ')', '\\n']
Tokenized   (021): ['<s>', 'parts', '_', 'per', '_', 'consumer', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ//', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['parts', '_', 'per', '_', 'consumer', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ//', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['parts_per_consumer', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall_parts', 'Ġ)', 'Ġ//', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "remainder_ppc = len ( all_parts ) % len ( participants ) \n"
Original    (012): ['remainder_ppc', '=', 'len', '(', 'all_parts', ')', '%', 'len', '(', 'participants', ')', '\\n']
Tokenized   (022): ['<s>', 'rem', 'ain', 'der', '_', 'pp', 'c', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ%', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['rem', 'ain', 'der', '_', 'pp', 'c', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ%', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['remainder_ppc', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall_parts', 'Ġ)', 'Ġ%', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "num_parts = parts_per_consumer + ( 0 if ( idx + 1 > remainder_ppc ) else 1 ) \n"
Original    (018): ['num_parts', '=', 'parts_per_consumer', '+', '(', '0', 'if', '(', 'idx', '+', '1', '>', 'remainder_ppc', ')', 'else', '1', ')', '\\n']
Tokenized   (031): ['<s>', 'num', '_', 'parts', 'Ġ=', 'Ġparts', '_', 'per', '_', 'consumer', 'Ġ+', 'Ġ(', 'Ġ0', 'Ġif', 'Ġ(', 'Ġid', 'x', 'Ġ+', 'Ġ1', 'Ġ>', 'Ġremainder', '_', 'pp', 'c', 'Ġ)', 'Ġelse', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['num', '_', 'parts', 'Ġ=', 'Ġparts', '_', 'per', '_', 'consumer', 'Ġ+', 'Ġ(', 'Ġ0', 'Ġif', 'Ġ(', 'Ġid', 'x', 'Ġ+', 'Ġ1', 'Ġ>', 'Ġremainder', '_', 'pp', 'c', 'Ġ)', 'Ġelse', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['num_parts', 'Ġ=', 'Ġparts_per_consumer', 'Ġ+', 'Ġ(', 'Ġ0', 'Ġif', 'Ġ(', 'Ġidx', 'Ġ+', 'Ġ1', 'Ġ>', 'Ġremainder_ppc', 'Ġ)', 'Ġelse', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "log . debug ( , [ p_to_str ( p ) for p in new_partitions ] ) \n"
Original    (017): ['log', '.', 'debug', '(', ',', '[', 'p_to_str', '(', 'p', ')', 'for', 'p', 'in', 'new_partitions', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġp', '_', 'to', '_', 'str', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġnew', '_', 'part', 'itions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġp', '_', 'to', '_', 'str', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġnew', '_', 'part', 'itions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġp_to_str', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġnew_partitions', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "id_ = get_string ( self . _consumer_id ) \n"
Original    (009): ['id_', '=', 'get_string', '(', 'self', '.', '_consumer_id', ')', '\\n']
Tokenized   (018): ['<s>', 'id', '_', 'Ġ=', 'Ġget', '_', 'string', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['id', '_', 'Ġ=', 'Ġget', '_', 'string', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['id_', 'Ġ=', 'Ġget_string', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_consumer_id', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "path = self . _topic_path , slug = partition_slug ) ) \n"
Original    (012): ['path', '=', 'self', '.', '_topic_path', ',', 'slug', '=', 'partition_slug', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'topic', '_', 'path', 'Ġ,', 'Ġslug', 'Ġ=', 'Ġpartition', '_', 'sl', 'ug', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'topic', '_', 'path', 'Ġ,', 'Ġslug', 'Ġ=', 'Ġpartition', '_', 'sl', 'ug', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_topic_path', 'Ġ,', 'Ġslug', 'Ġ=', 'Ġpartition_slug', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "HZCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (016): ['HZCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (023): ['<s>', 'H', 'Z', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['H', 'Z', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['HZCharLenTable', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "ISO2022CNCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (022): ['ISO2022CNCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (031): ['<s>', 'ISO', '20', '22', 'CN', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['ISO', '20', '22', 'CN', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['ISO2022CNCharLenTable', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "ISO2022JPCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (024): ['ISO2022JPCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (033): ['<s>', 'ISO', '20', '22', 'JP', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['ISO', '20', '22', 'JP', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['ISO2022JPCharLenTable', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "logging . basicConfig ( level = logging . INFO ) \n"
Original    (011): ['logging', '.', 'basicConfig', '(', 'level', '=', 'logging', '.', 'INFO', ')', '\\n']
Tokenized   (016): ['<s>', 'log', 'ging', 'Ġ.', 'Ġbasic', 'Config', 'Ġ(', 'Ġlevel', 'Ġ=', 'Ġlogging', 'Ġ.', 'ĠINFO', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['log', 'ging', 'Ġ.', 'Ġbasic', 'Config', 'Ġ(', 'Ġlevel', 'Ġ=', 'Ġlogging', 'Ġ.', 'ĠINFO', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['logging', 'Ġ.', 'ĠbasicConfig', 'Ġ(', 'Ġlevel', 'Ġ=', 'Ġlogging', 'Ġ.', 'ĠINFO', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tasa . __version__ , sys . version ) ) \n"
Original    (010): ['tasa', '.', '__version__', ',', 'sys', '.', 'version', ')', ')', '\\n']
Tokenized   (016): ['<s>', 't', 'asa', 'Ġ.', 'Ġ__', 'version', '__', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['t', 'asa', 'Ġ.', 'Ġ__', 'version', '__', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['tasa', 'Ġ.', 'Ġ__version__', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "type = lambda w : w . partition ( ) [ : : 2 ] , \n"
Original    (017): ['type', '=', 'lambda', 'w', ':', 'w', '.', 'partition', '(', ')', '[', ':', ':', '2', ']', ',', '\\n']
Tokenized   (020): ['<s>', 'type', 'Ġ=', 'Ġlambda', 'Ġw', 'Ġ:', 'Ġw', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['type', 'Ġ=', 'Ġlambda', 'Ġw', 'Ġ:', 'Ġw', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['type', 'Ġ=', 'Ġlambda', 'Ġw', 'Ġ:', 'Ġw', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "worker_class_name = args . worker [ 1 ] or \n"
Original    (010): ['worker_class_name', '=', 'args', '.', 'worker', '[', '1', ']', 'or', '\\n']
Tokenized   (017): ['<s>', 'worker', '_', 'class', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġworker', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['worker', '_', 'class', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġworker', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġor', 'Ġ\\', 'n']
Detokenized (010): ['worker_class_name', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġworker', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġor', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "str ( job ) [ : 50 ] ) \n"
Original    (010): ['str', '(', 'job', ')', '[', ':', '50', ']', ')', '\\n']
Tokenized   (013): ['<s>', 'str', 'Ġ(', 'Ġjob', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ50', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['str', 'Ġ(', 'Ġjob', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ50', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['str', 'Ġ(', 'Ġjob', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ50', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "processes = [ Process ( target = run , args = ( ) ) for x in range ( count ) ] \n"
Original    (023): ['processes', '=', '[', 'Process', '(', 'target', '=', 'run', ',', 'args', '=', '(', ')', ')', 'for', 'x', 'in', 'range', '(', 'count', ')', ']', '\\n']
Tokenized   (027): ['<s>', 'process', 'es', 'Ġ=', 'Ġ[', 'ĠProcess', 'Ġ(', 'Ġtarget', 'Ġ=', 'Ġrun', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġcount', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['process', 'es', 'Ġ=', 'Ġ[', 'ĠProcess', 'Ġ(', 'Ġtarget', 'Ġ=', 'Ġrun', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġcount', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (023): ['processes', 'Ġ=', 'Ġ[', 'ĠProcess', 'Ġ(', 'Ġtarget', 'Ġ=', 'Ġrun', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġcount', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "color = models . CharField ( max_length = 6 , validators = [ color_regex ] , help_text = \n"
Original    (019): ['color', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '6', ',', 'validators', '=', '[', 'color_regex', ']', ',', 'help_text', '=', '\\n']
Tokenized   (031): ['<s>', 'color', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ6', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġcolor', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['color', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ6', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġcolor', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (019): ['color', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ6', 'Ġ,', 'Ġvalidators', 'Ġ=', 'Ġ[', 'Ġcolor_regex', 'Ġ]', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "first_name = models . CharField ( max_length = 64 ) \n"
Original    (011): ['first_name', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '64', ')', '\\n']
Tokenized   (019): ['<s>', 'first', '_', 'name', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['first', '_', 'name', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['first_name', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "role = models . CharField ( max_length = 17 , choices = ROLE_CHOICES ) \n"
Original    (015): ['role', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '17', ',', 'choices', '=', 'ROLE_CHOICES', ')', '\\n']
Tokenized   (025): ['<s>', 'role', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ17', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠRO', 'LE', '_', 'CHO', 'ICES', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['role', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ17', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠRO', 'LE', '_', 'CHO', 'ICES', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['role', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ17', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠROLE_CHOICES', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "phone_work = models . CharField ( max_length = 15 , validators = [ phone_regex ] , blank = True ) \n"
Original    (021): ['phone_work', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '15', ',', 'validators', '=', '[', 'phone_regex', ']', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (033): ['<s>', 'phone', '_', 'work', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġphone', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['phone', '_', 'work', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġphone', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['phone_work', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġvalidators', 'Ġ=', 'Ġ[', 'Ġphone_regex', 'Ġ]', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "job_title = models . CharField ( max_length = 128 , blank = True ) \n"
Original    (015): ['job_title', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '128', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (023): ['<s>', 'job', '_', 'title', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['job', '_', 'title', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['job_title', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "category = models . CharField ( max_length = 21 , choices = CATEGORY_CHOICES , help_text = description = models . CharField ( max_length = 256 , blank = True , help_text = reference = models . URLField ( blank = True , help_text = ) \n"
Original    (046): ['category', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '21', ',', 'choices', '=', 'CATEGORY_CHOICES', ',', 'help_text', '=', 'description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '256', ',', 'blank', '=', 'True', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (068): ['<s>', 'category', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ21', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (066): ['category', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ21', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (046): ['category', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ21', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠCATEGORY_CHOICES', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 66
===================================================================
Hidden states:  (13, 46, 768)
# Extracted words:  46
Sentence         : "acronym = models . CharField ( max_length = 20 , unique = True , help_text = category = models . CharField ( max_length = 9 , choices = CATEGORY_CHOICES , help_text = jurisdiction = models . CharField ( max_length = 64 , help_text = description = models . TextField ( blank = True , help_text = reference = models . URLField ( blank = True , help_text = ) \n"
Original    (070): ['acronym', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '20', ',', 'unique', '=', 'True', ',', 'help_text', '=', 'category', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '9', ',', 'choices', '=', 'CATEGORY_CHOICES', ',', 'help_text', '=', 'jurisdiction', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '64', ',', 'help_text', '=', 'description', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (102): ['<s>', 'ac', 'ron', 'ym', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ20', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġcategory', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġjurisdiction', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (100): ['ac', 'ron', 'ym', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ20', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġcategory', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġjurisdiction', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (070): ['acronym', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ20', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġcategory', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠCATEGORY_CHOICES', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġjurisdiction', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ64', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 100
===================================================================
Hidden states:  (13, 70, 768)
# Extracted words:  70
Sentence         : "description = models . CharField ( max_length = 256 , blank = True , help_text = \n"
Original    (017): ['description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '256', ',', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (025): ['<s>', 'description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (017): ['description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "business_criticality = models . CharField ( max_length = 9 , choices = BUSINESS_CRITICALITY_CHOICES , blank platform = models . CharField ( max_length = 11 , choices = PLATFORM_CHOICES , blank = True , null = True ) \n"
Original    (038): ['business_criticality', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '9', ',', 'choices', '=', 'BUSINESS_CRITICALITY_CHOICES', ',', 'blank', 'platform', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '11', ',', 'choices', '=', 'PLATFORM_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (064): ['<s>', 'business', '_', 'critical', 'ity', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠBUS', 'INESS', '_', 'CR', 'IT', 'ICAL', 'ITY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġplatform', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ11', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠPL', 'AT', 'FORM', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (062): ['business', '_', 'critical', 'ity', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠBUS', 'INESS', '_', 'CR', 'IT', 'ICAL', 'ITY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġplatform', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ11', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠPL', 'AT', 'FORM', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (038): ['business_criticality', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠBUSINESS_CRITICALITY_CHOICES', 'Ġ,', 'Ġblank', 'Ġplatform', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ11', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠPLATFORM_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 62
===================================================================
Hidden states:  (13, 38, 768)
# Extracted words:  38
Sentence         : "lifecycle = models . CharField ( max_length = 8 , choices = LIFECYCLE_CHOICES , blank = True , null = True ) \n"
Original    (023): ['lifecycle', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '8', ',', 'choices', '=', 'LIFECYCLE_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (037): ['<s>', 'lif', 'ecycle', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠL', 'IF', 'EC', 'Y', 'CLE', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['lif', 'ecycle', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠL', 'IF', 'EC', 'Y', 'CLE', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['lifecycle', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠLIFECYCLE_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "user_records = models . PositiveIntegerField ( blank = True , null = True , help_text = revenue = models . DecimalField ( max_digits = 15 , decimal_places = 2 , blank = True , null = True , help_text = external_audience = models . BooleanField ( default = False , help_text = internet_accessible = models . BooleanField ( default = False , help_text = requestable = models . NullBooleanField ( default = True , help_text = _ ( \n"
Original    (079): ['user_records', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'revenue', '=', 'models', '.', 'DecimalField', '(', 'max_digits', '=', '15', ',', 'decimal_places', '=', '2', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'external_audience', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', 'internet_accessible', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', 'requestable', '=', 'models', '.', 'NullBooleanField', '(', 'default', '=', 'True', ',', 'help_text', '=', '_', '(', '\\n']
Tokenized   (115): ['<s>', 'user', '_', 'rec', 'ords', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrevenue', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDec', 'imal', 'Field', 'Ġ(', 'Ġmax', '_', 'dig', 'its', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġdecimal', '_', 'places', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġexternal', '_', 'aud', 'ience', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġinternet', '_', 'accessible', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrequest', 'able', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠNull', 'Boo', 'lean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (113): ['user', '_', 'rec', 'ords', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrevenue', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDec', 'imal', 'Field', 'Ġ(', 'Ġmax', '_', 'dig', 'its', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġdecimal', '_', 'places', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġexternal', '_', 'aud', 'ience', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġinternet', '_', 'accessible', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrequest', 'able', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠNull', 'Boo', 'lean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ\\', 'n']
Detokenized (079): ['user_records', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġrevenue', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDecimalField', 'Ġ(', 'Ġmax_digits', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġdecimal_places', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġexternal_audience', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġinternet_accessible', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġrequestable', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠNullBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ\\n']
Counter: 113
===================================================================
Hidden states:  (13, 79, 768)
# Extracted words:  79
Sentence         : "override_dcl = models . IntegerField ( choices = DATA_CLASSIFICATION_CHOICES , blank = True , null = True , help_text override_reason = models . TextField ( blank = True , help_text = \n"
Original    (032): ['override_dcl', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'DATA_CLASSIFICATION_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', 'override_reason', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (054): ['<s>', 'over', 'ride', '_', 'd', 'cl', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠDATA', '_', 'CLASS', 'IFIC', 'ATION', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġoverride', '_', 'reason', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (052): ['over', 'ride', '_', 'd', 'cl', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠDATA', '_', 'CLASS', 'IFIC', 'ATION', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġoverride', '_', 'reason', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (032): ['override_dcl', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠIntegerField', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠDATA_CLASSIFICATION_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġoverride_reason', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 52
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "threadfix = models . ForeignKey ( ThreadFix , blank = True , null = True , help_text = threadfix_team_id = models . PositiveIntegerField ( blank = True , null = True , help_text = threadfix_application_id = models . PositiveIntegerField ( blank = True , null = True , help_text = \n"
Original    (051): ['threadfix', '=', 'models', '.', 'ForeignKey', '(', 'ThreadFix', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'threadfix_team_id', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'threadfix_application_id', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (077): ['<s>', 'thread', 'fix', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠThread', 'Fix', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'team', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'application', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (075): ['thread', 'fix', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠThread', 'Fix', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'team', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'application', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (051): ['threadfix', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'ĠThreadFix', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġthreadfix_team_id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġthreadfix_application_id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 75
===================================================================
Hidden states:  (13, 51, 768)
# Extracted words:  51
Sentence         : "asvs_level = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = asvs_level_percent_achieved = models . PositiveIntegerField ( blank = True , null = True , help_text = asvs_doc_url = models . URLField ( blank = True , help_text = ) \n"
Original    (050): ['asvs_level', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'ASVS_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'asvs_level_percent_achieved', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'asvs_doc_url', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (083): ['<s>', 'as', 'vs', '_', 'level', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'level', '_', 'percent', '_', 'ach', 'ieved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'doc', '_', 'url', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (081): ['as', 'vs', '_', 'level', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'level', '_', 'percent', '_', 'ach', 'ieved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'doc', '_', 'url', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (050): ['asvs_level', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠIntegerField', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠASVS_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġasvs_level_percent_achieved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġasvs_doc_url', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 81
===================================================================
Hidden states:  (13, 50, 768)
# Extracted words:  50
Sentence         : "asvs_level_target = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = \n"
Original    (021): ['asvs_level_target', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'ASVS_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (036): ['<s>', 'as', 'vs', '_', 'level', '_', 'target', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['as', 'vs', '_', 'level', '_', 'target', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (021): ['asvs_level_target', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠIntegerField', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠASVS_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "organization = models . ForeignKey ( Organization , help_text = people = models . ManyToManyField ( Person , through = , blank = True ) \n"
Original    (026): ['organization', '=', 'models', '.', 'ForeignKey', '(', 'Organization', ',', 'help_text', '=', 'people', '=', 'models', '.', 'ManyToManyField', '(', 'Person', ',', 'through', '=', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (036): ['<s>', 'organ', 'ization', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠOrganization', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġpeople', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġthrough', 'Ġ=', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['organ', 'ization', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠOrganization', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġpeople', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġthrough', 'Ġ=', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['organization', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'ĠOrganization', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġpeople', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠManyToManyField', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġthrough', 'Ġ=', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "delta = self . created_date - timezone . now ( ) \n"
Original    (012): ['delta', '=', 'self', '.', 'created_date', '-', 'timezone', '.', 'now', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'd', 'elta', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcreated', '_', 'date', 'Ġ-', 'Ġtime', 'zone', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['d', 'elta', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcreated', '_', 'date', 'Ġ-', 'Ġtime', 'zone', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['delta', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcreated_date', 'Ġ-', 'Ġtimezone', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "person = models . ForeignKey ( Person , help_text = ) \n"
Original    (012): ['person', '=', 'models', '.', 'ForeignKey', '(', 'Person', ',', 'help_text', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'person', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['person', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['person', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "environment_type = models . CharField ( max_length = 4 , choices = ENVIRONMENT_CHOICES , help_text = description = models . TextField ( blank = True , help_text = testing_approved = models . BooleanField ( default = False , help_text = \n"
Original    (041): ['environment_type', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '4', ',', 'choices', '=', 'ENVIRONMENT_CHOICES', ',', 'help_text', '=', 'description', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', 'testing_approved', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', '\\n']
Tokenized   (066): ['<s>', 'environment', '_', 'type', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠEN', 'V', 'IR', 'ON', 'MENT', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġtesting', '_', 'approved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (064): ['environment', '_', 'type', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠEN', 'V', 'IR', 'ON', 'MENT', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġtesting', '_', 'approved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (041): ['environment_type', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠENVIRONMENT_CHOICES', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġtesting_approved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 64
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "location = models . URLField ( help_text = notes = models . TextField ( blank = True , help_text = \n"
Original    (021): ['location', '=', 'models', '.', 'URLField', '(', 'help_text', '=', 'notes', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (030): ['<s>', 'location', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['location', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (021): ['location', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġhelp_text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "role_description = models . CharField ( max_length = 128 , blank = True , help_text = notes = models . TextField ( blank = True , help_text = \n"
Original    (029): ['role_description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '128', ',', 'blank', '=', 'True', ',', 'help_text', '=', 'notes', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (042): ['<s>', 'role', '_', 'description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['role', '_', 'description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (029): ['role_description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "start_date = models . DateField ( help_text = ) \n"
Original    (010): ['start_date', '=', 'models', '.', 'DateField', '(', 'help_text', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'start', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['start', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['start_date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDateField', 'Ġ(', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "open_date = models . DateTimeField ( blank = True , null = True , help_text = close_date = models . DateTimeField ( blank = True , null = True , help_text = duration = models . DurationField ( blank = True , null = True ) \n"
Original    (047): ['open_date', '=', 'models', '.', 'DateTimeField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'close_date', '=', 'models', '.', 'DateTimeField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'duration', '=', 'models', '.', 'DurationField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (063): ['<s>', 'open', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġclose', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġduration', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDuration', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (061): ['open', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġclose', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġduration', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDuration', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (047): ['open_date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDateTimeField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġclose_date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDateTimeField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġduration', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDurationField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 61
===================================================================
Hidden states:  (13, 47, 768)
# Extracted words:  47
Sentence         : "metrics = managers . ActivityTypeMetrics . from_queryset ( managers . ActivityTypeQuerySet ) ( ) \n"
Original    (015): ['metrics', '=', 'managers', '.', 'ActivityTypeMetrics', '.', 'from_queryset', '(', 'managers', '.', 'ActivityTypeQuerySet', ')', '(', ')', '\\n']
Tokenized   (029): ['<s>', 'met', 'rics', 'Ġ=', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Met', 'rics', 'Ġ.', 'Ġfrom', '_', 'quer', 'ys', 'et', 'Ġ(', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Query', 'Set', 'Ġ)', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['met', 'rics', 'Ġ=', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Met', 'rics', 'Ġ.', 'Ġfrom', '_', 'quer', 'ys', 'et', 'Ġ(', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Query', 'Set', 'Ġ)', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['metrics', 'Ġ=', 'Ġmanagers', 'Ġ.', 'ĠActivityTypeMetrics', 'Ġ.', 'Ġfrom_queryset', 'Ġ(', 'Ġmanagers', 'Ġ.', 'ĠActivityTypeQuerySet', 'Ġ)', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "token = models . UUIDField ( default = uuid . uuid4 , editable = False ) \n"
Original    (017): ['token', '=', 'models', '.', 'UUIDField', '(', 'default', '=', 'uuid', '.', 'uuid4', ',', 'editable', '=', 'False', ')', '\\n']
Tokenized   (026): ['<s>', 'token', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠU', 'UID', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'Ġu', 'uid', 'Ġ.', 'Ġu', 'uid', '4', 'Ġ,', 'Ġedit', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['token', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠU', 'UID', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'Ġu', 'uid', 'Ġ.', 'Ġu', 'uid', '4', 'Ġ,', 'Ġedit', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['token', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠUUIDField', 'Ġ(', 'Ġdefault', 'Ġ=', 'Ġuuid', 'Ġ.', 'Ġuuid4', 'Ġ,', 'Ġeditable', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "activities = models . ManyToManyField ( ActivityType , limit_choices_to = { : True } ) \n"
Original    (016): ['activities', '=', 'models', '.', 'ManyToManyField', '(', 'ActivityType', ',', 'limit_choices_to', '=', '{', ':', 'True', '}', ')', '\\n']
Tokenized   (029): ['<s>', 'activ', 'ities', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠActivity', 'Type', 'Ġ,', 'Ġlimit', '_', 'cho', 'ices', '_', 'to', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠTrue', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['activ', 'ities', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠActivity', 'Type', 'Ġ,', 'Ġlimit', '_', 'cho', 'ices', '_', 'to', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠTrue', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['activities', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠManyToManyField', 'Ġ(', 'ĠActivityType', 'Ġ,', 'Ġlimit_choices_to', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠTrue', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "opener . addheaders = [ ( , ) ] \n"
Original    (010): ['opener', '.', 'addheaders', '=', '[', '(', ',', ')', ']', '\\n']
Tokenized   (015): ['<s>', 'op', 'ener', 'Ġ.', 'Ġadd', 'headers', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['op', 'ener', 'Ġ.', 'Ġadd', 'headers', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['opener', 'Ġ.', 'Ġaddheaders', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "False = 0 \n"
Original    (004): ['False', '=', '0', '\\n']
Tokenized   (007): ['<s>', 'False', 'Ġ=', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['False', 'Ġ=', 'Ġ0', 'Ġ\\', 'n']
Detokenized (004): ['False', 'Ġ=', 'Ġ0', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "option_pattern = chr ( 0 ) * 8 \n"
Original    (009): ['option_pattern', '=', 'chr', '(', '0', ')', '*', '8', '\\n']
Tokenized   (015): ['<s>', 'option', '_', 'pattern', 'Ġ=', 'Ġch', 'r', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ*', 'Ġ8', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['option', '_', 'pattern', 'Ġ=', 'Ġch', 'r', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ*', 'Ġ8', 'Ġ\\', 'n']
Detokenized (009): ['option_pattern', 'Ġ=', 'Ġchr', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ*', 'Ġ8', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "begin = toint ( s [ 5 : 9 ] ) \n"
Original    (012): ['begin', '=', 'toint', '(', 's', '[', '5', ':', '9', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'begin', 'Ġ=', 'Ġto', 'int', 'Ġ(', 'Ġs', 'Ġ[', 'Ġ5', 'Ġ:', 'Ġ9', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['begin', 'Ġ=', 'Ġto', 'int', 'Ġ(', 'Ġs', 'Ġ[', 'Ġ5', 'Ġ:', 'Ġ9', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['begin', 'Ġ=', 'Ġtoint', 'Ġ(', 'Ġs', 'Ġ[', 'Ġ5', 'Ġ:', 'Ġ9', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "length = len ( s ) - 9 \n"
Original    (009): ['length', '=', 'len', '(', 's', ')', '-', '9', '\\n']
Tokenized   (012): ['<s>', 'length', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ-', 'Ġ9', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['length', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ-', 'Ġ9', 'Ġ\\', 'n']
Detokenized (009): ['length', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ-', 'Ġ9', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "DivergeCommits = namedtuple ( "DivergeCommits" , [ "common_parent" , \n"
Original    (010): ['DivergeCommits', '=', 'namedtuple', '(', '"DivergeCommits"', ',', '[', '"common_parent"', ',', '\\n']
Tokenized   (029): ['<s>', 'D', 'iver', 'ge', 'Comm', 'its', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'D', 'iver', 'ge', 'Comm', 'its', '"', 'Ġ,', 'Ġ[', 'Ġ"', 'common', '_', 'parent', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['D', 'iver', 'ge', 'Comm', 'its', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'D', 'iver', 'ge', 'Comm', 'its', '"', 'Ġ,', 'Ġ[', 'Ġ"', 'common', '_', 'parent', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['DivergeCommits', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ"DivergeCommits"', 'Ġ,', 'Ġ[', 'Ġ"common_parent"', 'Ġ,', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : ""first_commits" , "second_commits" ] ) \n"
Original    (006): ['"first_commits"', ',', '"second_commits"', ']', ')', '\\n']
Tokenized   (019): ['<s>', '"', 'first', '_', 'comm', 'its', '"', 'Ġ,', 'Ġ"', 'second', '_', 'comm', 'its', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['"', 'first', '_', 'comm', 'its', '"', 'Ġ,', 'Ġ"', 'second', '_', 'comm', 'its', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['"first_commits"', 'Ġ,', 'Ġ"second_commits"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "behind = len ( diverge_commits . second_commits ) > 0 \n"
Original    (011): ['behind', '=', 'len', '(', 'diverge_commits', '.', 'second_commits', ')', '>', '0', '\\n']
Tokenized   (021): ['<s>', 'behind', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġdiver', 'ge', '_', 'comm', 'its', 'Ġ.', 'Ġsecond', '_', 'comm', 'its', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['behind', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġdiver', 'ge', '_', 'comm', 'its', 'Ġ.', 'Ġsecond', '_', 'comm', 'its', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ\\', 'n']
Detokenized (011): ['behind', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġdiverge_commits', 'Ġ.', 'Ġsecond_commits', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "onerror = lambda function , fpath , excinfo : log . info ( \n"
Original    (014): ['onerror', '=', 'lambda', 'function', ',', 'fpath', ',', 'excinfo', ':', 'log', '.', 'info', '(', '\\n']
Tokenized   (020): ['<s>', 'oner', 'ror', 'Ġ=', 'Ġlambda', 'Ġfunction', 'Ġ,', 'Ġf', 'path', 'Ġ,', 'Ġexc', 'info', 'Ġ:', 'Ġlog', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['oner', 'ror', 'Ġ=', 'Ġlambda', 'Ġfunction', 'Ġ,', 'Ġf', 'path', 'Ġ,', 'Ġexc', 'info', 'Ġ:', 'Ġlog', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ\\', 'n']
Detokenized (014): ['onerror', 'Ġ=', 'Ġlambda', 'Ġfunction', 'Ġ,', 'Ġfpath', 'Ġ,', 'Ġexcinfo', 'Ġ:', 'Ġlog', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "commiter = Signature ( commiter [ 0 ] , commiter [ 1 ] ) \n"
Original    (015): ['commiter', '=', 'Signature', '(', 'commiter', '[', '0', ']', ',', 'commiter', '[', '1', ']', ')', '\\n']
Tokenized   (021): ['<s>', 'comm', 'iter', 'Ġ=', 'ĠSignature', 'Ġ(', 'Ġcomm', 'iter', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġcomm', 'iter', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['comm', 'iter', 'Ġ=', 'ĠSignature', 'Ġ(', 'Ġcomm', 'iter', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġcomm', 'iter', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['commiter', 'Ġ=', 'ĠSignature', 'Ġ(', 'Ġcommiter', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġcommiter', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "len ( path_components ) == 1 and \n"
Original    (008): ['len', '(', 'path_components', ')', '==', '1', 'and', '\\n']
Tokenized   (014): ['<s>', 'len', 'Ġ(', 'Ġpath', '_', 'comp', 'onents', 'Ġ)', 'Ġ==', 'Ġ1', 'Ġand', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['len', 'Ġ(', 'Ġpath', '_', 'comp', 'onents', 'Ġ)', 'Ġ==', 'Ġ1', 'Ġand', 'Ġ\\', 'n']
Detokenized (008): ['len', 'Ġ(', 'Ġpath_components', 'Ġ)', 'Ġ==', 'Ġ1', 'Ġand', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "entry_name == path_components [ 0 ] ) \n"
Original    (008): ['entry_name', '==', 'path_components', '[', '0', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'entry', '_', 'name', 'Ġ==', 'Ġpath', '_', 'comp', 'onents', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['entry', '_', 'name', 'Ġ==', 'Ġpath', '_', 'comp', 'onents', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['entry_name', 'Ġ==', 'Ġpath_components', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "lambda entry : self . _repo [ entry . id ] ) \n"
Original    (013): ['lambda', 'entry', ':', 'self', '.', '_repo', '[', 'entry', '.', 'id', ']', ')', '\\n']
Tokenized   (018): ['<s>', 'lambda', 'Ġentry', 'Ġ:', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ[', 'Ġentry', 'Ġ.', 'Ġid', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['lambda', 'Ġentry', 'Ġ:', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ[', 'Ġentry', 'Ġ.', 'Ġid', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['lambda', 'Ġentry', 'Ġ:', 'Ġself', 'Ġ.', 'Ġ_repo', 'Ġ[', 'Ġentry', 'Ġ.', 'Ġid', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "GIT_FILEMODE_LINK : { \n"
Original    (004): ['GIT_FILEMODE_LINK', ':', '{', '\\n']
Tokenized   (014): ['<s>', 'G', 'IT', '_', 'FILE', 'MODE', '_', 'L', 'INK', 'Ġ:', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['G', 'IT', '_', 'FILE', 'MODE', '_', 'L', 'INK', 'Ġ:', 'Ġ{', 'Ġ\\', 'n']
Detokenized (004): ['GIT_FILEMODE_LINK', 'Ġ:', 'Ġ{', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "iterators = [ self . _repo . walk ( branch . target , sort ) \n"
Original    (016): ['iterators', '=', '[', 'self', '.', '_repo', '.', 'walk', '(', 'branch', '.', 'target', ',', 'sort', ')', '\\n']
Tokenized   (022): ['<s>', 'iter', 'ators', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ(', 'Ġbranch', 'Ġ.', 'Ġtarget', 'Ġ,', 'Ġsort', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['iter', 'ators', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ(', 'Ġbranch', 'Ġ.', 'Ġtarget', 'Ġ,', 'Ġsort', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['iterators', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_repo', 'Ġ.', 'Ġwalk', 'Ġ(', 'Ġbranch', 'Ġ.', 'Ġtarget', 'Ġ,', 'Ġsort', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "stop_iteration = [ False for branch in branches ] \n"
Original    (010): ['stop_iteration', '=', '[', 'False', 'for', 'branch', 'in', 'branches', ']', '\\n']
Tokenized   (016): ['<s>', 'stop', '_', 'iter', 'ation', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġfor', 'Ġbranch', 'Ġin', 'Ġbranches', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['stop', '_', 'iter', 'ation', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġfor', 'Ġbranch', 'Ġin', 'Ġbranches', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['stop_iteration', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġfor', 'Ġbranch', 'Ġin', 'Ġbranches', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "second_commit in first_commits ) : \n"
Original    (006): ['second_commit', 'in', 'first_commits', ')', ':', '\\n']
Tokenized   (014): ['<s>', 'second', '_', 'commit', 'Ġin', 'Ġfirst', '_', 'comm', 'its', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['second', '_', 'commit', 'Ġin', 'Ġfirst', '_', 'comm', 'its', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['second_commit', 'Ġin', 'Ġfirst_commits', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "new_commit = Commit ( 2 , 2 , "21111111111" ) \n"
Original    (011): ['new_commit', '=', 'Commit', '(', '2', ',', '2', ',', '"21111111111"', ')', '\\n']
Tokenized   (020): ['<s>', 'new', '_', 'commit', 'Ġ=', 'ĠCommit', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ"', '211', '1111', '1111', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['new', '_', 'commit', 'Ġ=', 'ĠCommit', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ"', '211', '1111', '1111', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['new_commit', 'Ġ=', 'ĠCommit', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ"21111111111"', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "mocked_repo . walk . assert_called_once_with ( "head" , GIT_SORT_TIME ) \n"
Original    (011): ['mocked_repo', '.', 'walk', '.', 'assert_called_once_with', '(', '"head"', ',', 'GIT_SORT_TIME', ')', '\\n']
Tokenized   (032): ['<s>', 'm', 'ocked', '_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ"', 'head', '"', 'Ġ,', 'ĠG', 'IT', '_', 'S', 'ORT', '_', 'TIME', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['m', 'ocked', '_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ"', 'head', '"', 'Ġ,', 'ĠG', 'IT', '_', 'S', 'ORT', '_', 'TIME', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['mocked_repo', 'Ġ.', 'Ġwalk', 'Ġ.', 'Ġassert_called_once_with', 'Ġ(', 'Ġ"head"', 'Ġ,', 'ĠGIT_SORT_TIME', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "to_datetime = True ) == datetime \n"
Original    (007): ['to_datetime', '=', 'True', ')', '==', 'datetime', '\\n']
Tokenized   (014): ['<s>', 'to', '_', 'dat', 'etime', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ==', 'Ġdat', 'etime', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['to', '_', 'dat', 'etime', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ==', 'Ġdat', 'etime', 'Ġ\\', 'n']
Detokenized (007): ['to_datetime', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ==', 'Ġdatetime', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "date = dt . date ( 1970 , 1 , 1 ) \n"
Original    (013): ['date', '=', 'dt', '.', 'date', '(', '1970', ',', '1', ',', '1', ')', '\\n']
Tokenized   (017): ['<s>', 'date', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdate', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['date', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdate', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['date', 'Ġ=', 'Ġdt', 'Ġ.', 'Ġdate', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "datetime = dt . datetime ( 1970 , 1 , 1 , 13 , 30 ) \n"
Original    (017): ['datetime', '=', 'dt', '.', 'datetime', '(', '1970', ',', '1', ',', '1', ',', '13', ',', '30', ')', '\\n']
Tokenized   (023): ['<s>', 'dat', 'etime', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ13', 'Ġ,', 'Ġ30', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['dat', 'etime', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ13', 'Ġ,', 'Ġ30', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['datetime', 'Ġ=', 'Ġdt', 'Ġ.', 'Ġdatetime', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ13', 'Ġ,', 'Ġ30', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "internationalizeDocstring = lambda x : x \n"
Original    (007): ['internationalizeDocstring', '=', 'lambda', 'x', ':', 'x', '\\n']
Tokenized   (013): ['<s>', 'international', 'ize', 'Doc', 'string', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['international', 'ize', 'Doc', 'string', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ\\', 'n']
Detokenized (007): ['internationalizeDocstring', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "conf . supybot . drivers . maxReconnectWait ( ) ) \n"
Original    (011): ['conf', '.', 'supybot', '.', 'drivers', '.', 'maxReconnectWait', '(', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'conf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġdrivers', 'Ġ.', 'Ġmax', 'Rec', 'on', 'nect', 'Wait', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['conf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġdrivers', 'Ġ.', 'Ġmax', 'Rec', 'on', 'nect', 'Wait', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['conf', 'Ġ.', 'Ġsupybot', 'Ġ.', 'Ġdrivers', 'Ġ.', 'ĠmaxReconnectWait', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "inst . conn . _sock . __class__ is socket . _closedsocket ) : \n"
Original    (014): ['inst', '.', 'conn', '.', '_sock', '.', '__class__', 'is', 'socket', '.', '_closedsocket', ')', ':', '\\n']
Tokenized   (023): ['<s>', 'inst', 'Ġ.', 'Ġconn', 'Ġ.', 'Ġ_', 's', 'ock', 'Ġ.', 'Ġ__', 'class', '__', 'Ġis', 'Ġsocket', 'Ġ.', 'Ġ_', 'closed', 'socket', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['inst', 'Ġ.', 'Ġconn', 'Ġ.', 'Ġ_', 's', 'ock', 'Ġ.', 'Ġ__', 'class', '__', 'Ġis', 'Ġsocket', 'Ġ.', 'Ġ_', 'closed', 'socket', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (014): ['inst', 'Ġ.', 'Ġconn', 'Ġ.', 'Ġ_sock', 'Ġ.', 'Ġ__class__', 'Ġis', 'Ġsocket', 'Ġ.', 'Ġ_closedsocket', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "network_config = getattr ( conf . supybot . networks , self . irc . network ) \n"
Original    (017): ['network_config', '=', 'getattr', '(', 'conf', '.', 'supybot', '.', 'networks', ',', 'self', '.', 'irc', '.', 'network', ')', '\\n']
Tokenized   (026): ['<s>', 'network', '_', 'config', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġnetworks', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġnetwork', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['network', '_', 'config', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġnetworks', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġnetwork', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['network_config', 'Ġ=', 'Ġgetattr', 'Ġ(', 'Ġconf', 'Ġ.', 'Ġsupybot', 'Ġ.', 'Ġnetworks', 'Ġ,', 'Ġself', 'Ġ.', 'Ġirc', 'Ġ.', 'Ġnetwork', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "vhost = conf . supybot . protocols . irc . vhost ( ) , \n"
Original    (015): ['vhost', '=', 'conf', '.', 'supybot', '.', 'protocols', '.', 'irc', '.', 'vhost', '(', ')', ',', '\\n']
Tokenized   (023): ['<s>', 'v', 'host', 'Ġ=', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġprotocols', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġv', 'host', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['v', 'host', 'Ġ=', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġprotocols', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġv', 'host', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['vhost', 'Ġ=', 'Ġconf', 'Ġ.', 'Ġsupybot', 'Ġ.', 'Ġprotocols', 'Ġ.', 'Ġirc', 'Ġ.', 'Ġvhost', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "trusted_fingerprints = network_config . ssl . serverFingerprints ( ) , \n"
Original    (011): ['trusted_fingerprints', '=', 'network_config', '.', 'ssl', '.', 'serverFingerprints', '(', ')', ',', '\\n']
Tokenized   (024): ['<s>', 'tr', 'usted', '_', 'finger', 'prints', 'Ġ=', 'Ġnetwork', '_', 'config', 'Ġ.', 'Ġs', 'sl', 'Ġ.', 'Ġserver', 'F', 'inger', 'prints', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['tr', 'usted', '_', 'finger', 'prints', 'Ġ=', 'Ġnetwork', '_', 'config', 'Ġ.', 'Ġs', 'sl', 'Ġ.', 'Ġserver', 'F', 'inger', 'prints', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['trusted_fingerprints', 'Ġ=', 'Ġnetwork_config', 'Ġ.', 'Ġssl', 'Ġ.', 'ĠserverFingerprints', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "while tb : \n"
Original    (004): ['while', 'tb', ':', '\\n']
Tokenized   (008): ['<s>', 'while', 'Ġt', 'b', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['while', 'Ġt', 'b', 'Ġ:', 'Ġ\\', 'n']
Detokenized (004): ['while', 'Ġtb', 'Ġ:', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "frame . f_lineno ) ) \n"
Original    (006): ['frame', '.', 'f_lineno', ')', ')', '\\n']
Tokenized   (012): ['<s>', 'frame', 'Ġ.', 'Ġf', '_', 'lin', 'eno', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['frame', 'Ġ.', 'Ġf', '_', 'lin', 'eno', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['frame', 'Ġ.', 'Ġf_lineno', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "window = timedelta ( 0 , 0 , 0 , 0 , settings . SESSION_TIMEOUT ) \n"
Original    (017): ['window', '=', 'timedelta', '(', '0', ',', '0', ',', '0', ',', '0', ',', 'settings', '.', 'SESSION_TIMEOUT', ')', '\\n']
Tokenized   (025): ['<s>', 'window', 'Ġ=', 'Ġtimed', 'elta', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġsettings', 'Ġ.', 'ĠS', 'ESSION', '_', 'TIME', 'OUT', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['window', 'Ġ=', 'Ġtimed', 'elta', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġsettings', 'Ġ.', 'ĠS', 'ESSION', '_', 'TIME', 'OUT', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['window', 'Ġ=', 'Ġtimedelta', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġsettings', 'Ġ.', 'ĠSESSION_TIMEOUT', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "shared = request . POST . get ( "shared" , False ) \n"
Original    (013): ['shared', '=', 'request', '.', 'POST', '.', 'get', '(', '"shared"', ',', 'False', ')', '\\n']
Tokenized   (018): ['<s>', 'shared', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'shared', '"', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['shared', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'shared', '"', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['shared', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"shared"', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "} , p . score_functions . all ( ) . filter ( selectable_bodies = plan . legislative_body } , report_displays [ 0 ] . scorepanel_set . all ( ) . order_by ( ) ) \n"
Original    (035): ['}', ',', 'p', '.', 'score_functions', '.', 'all', '(', ')', '.', 'filter', '(', 'selectable_bodies', '=', 'plan', '.', 'legislative_body', '}', ',', 'report_displays', '[', '0', ']', '.', 'scorepanel_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', ')', '\\n']
Tokenized   (055): ['<s>', '}', 'Ġ,', 'Ġp', 'Ġ.', 'Ġscore', '_', 'fun', 'ctions', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ}', 'Ġ,', 'Ġreport', '_', 'dis', 'plays', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (053): ['}', 'Ġ,', 'Ġp', 'Ġ.', 'Ġscore', '_', 'fun', 'ctions', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ}', 'Ġ,', 'Ġreport', '_', 'dis', 'plays', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (035): ['}', 'Ġ,', 'Ġp', 'Ġ.', 'Ġscore_functions', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselectable_bodies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative_body', 'Ġ}', 'Ġ,', 'Ġreport_displays', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġscorepanel_set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 53
===================================================================
Hidden states:  (13, 35, 768)
# Extracted words:  35
Sentence         : "body_member_long_label = _ ( ) + \n"
Original    (007): ['body_member_long_label', '=', '_', '(', ')', '+', '\\n']
Tokenized   (016): ['<s>', 'body', '_', 'member', '_', 'long', '_', 'label', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['body', '_', 'member', '_', 'long', '_', 'label', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (007): ['body_member_long_label', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "body_members = _n ( , , 2 ) \n"
Original    (009): ['body_members', '=', '_n', '(', ',', ',', '2', ')', '\\n']
Tokenized   (015): ['<s>', 'body', '_', 'members', 'Ġ=', 'Ġ_', 'n', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['body', '_', 'members', 'Ġ=', 'Ġ_', 'n', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['body_members', 'Ġ=', 'Ġ_n', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "has_regions = Region . objects . all ( ) . count ( ) > 1 \n"
Original    (016): ['has_regions', '=', 'Region', '.', 'objects', '.', 'all', '(', ')', '.', 'count', '(', ')', '>', '1', '\\n']
Tokenized   (022): ['<s>', 'has', '_', 'reg', 'ions', 'Ġ=', 'ĠRegion', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ)', 'Ġ>', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['has', '_', 'reg', 'ions', 'Ġ=', 'ĠRegion', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ)', 'Ġ>', 'Ġ1', 'Ġ\\', 'n']
Detokenized (016): ['has_regions', 'Ġ=', 'ĠRegion', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ)', 'Ġ>', 'Ġ1', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "bodies = LegislativeBody . objects . all ( ) . order_by ( , ) \n"
Original    (015): ['bodies', '=', 'LegislativeBody', '.', 'objects', '.', 'all', '(', ')', '.', 'order_by', '(', ',', ')', '\\n']
Tokenized   (022): ['<s>', 'b', 'odies', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['b', 'odies', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['bodies', 'Ġ=', 'ĠLegislativeBody', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "l_bodies = [ b for b in bodies if b in [ sd . legislative_body for sd in ScoreDisplay . objects . filter \n"
Original    (024): ['l_bodies', '=', '[', 'b', 'for', 'b', 'in', 'bodies', 'if', 'b', 'in', '[', 'sd', '.', 'legislative_body', 'for', 'sd', 'in', 'ScoreDisplay', '.', 'objects', '.', 'filter', '\\n']
Tokenized   (033): ['<s>', 'l', '_', 'b', 'odies', 'Ġ=', 'Ġ[', 'Ġb', 'Ġfor', 'Ġb', 'Ġin', 'Ġbodies', 'Ġif', 'Ġb', 'Ġin', 'Ġ[', 'Ġsd', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġfor', 'Ġsd', 'Ġin', 'ĠScore', 'Display', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['l', '_', 'b', 'odies', 'Ġ=', 'Ġ[', 'Ġb', 'Ġfor', 'Ġb', 'Ġin', 'Ġbodies', 'Ġif', 'Ġb', 'Ġin', 'Ġ[', 'Ġsd', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġfor', 'Ġsd', 'Ġin', 'ĠScore', 'Display', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ\\', 'n']
Detokenized (024): ['l_bodies', 'Ġ=', 'Ġ[', 'Ġb', 'Ġfor', 'Ġb', 'Ġin', 'Ġbodies', 'Ġif', 'Ġb', 'Ġin', 'Ġ[', 'Ġsd', 'Ġ.', 'Ġlegislative_body', 'Ġfor', 'Ġsd', 'Ġin', 'ĠScoreDisplay', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "cfg [ ] = datetime . now ( ) \n"
Original    (010): ['cfg', '[', ']', '=', 'datetime', '.', 'now', '(', ')', '\\n']
Tokenized   (014): ['<s>', 'cfg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['cfg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['cfg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ll = ModestMaps . Geo . Location ( pt1 . y , pt1 . x ) \n"
Original    (017): ['ll', '=', 'ModestMaps', '.', 'Geo', '.', 'Location', '(', 'pt1', '.', 'y', ',', 'pt1', '.', 'x', ')', '\\n']
Tokenized   (023): ['<s>', 'll', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠGeo', 'Ġ.', 'ĠLocation', 'Ġ(', 'Ġpt', '1', 'Ġ.', 'Ġy', 'Ġ,', 'Ġpt', '1', 'Ġ.', 'Ġx', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['ll', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠGeo', 'Ġ.', 'ĠLocation', 'Ġ(', 'Ġpt', '1', 'Ġ.', 'Ġy', 'Ġ,', 'Ġpt', '1', 'Ġ.', 'Ġx', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['ll', 'Ġ=', 'ĠModestMaps', 'Ġ.', 'ĠGeo', 'Ġ.', 'ĠLocation', 'Ġ(', 'Ġpt1', 'Ġ.', 'Ġy', 'Ġ,', 'Ġpt1', 'Ġ.', 'Ġx', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "provider = ModestMaps . WMS . Provider ( cfg [ ] , { \n"
Original    (014): ['provider', '=', 'ModestMaps', '.', 'WMS', '.', 'Provider', '(', 'cfg', '[', ']', ',', '{', '\\n']
Tokenized   (021): ['<s>', 'prov', 'ider', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠW', 'MS', 'Ġ.', 'ĠProvider', 'Ġ(', 'Ġcf', 'g', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['prov', 'ider', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠW', 'MS', 'Ġ.', 'ĠProvider', 'Ġ(', 'Ġcf', 'g', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ{', 'Ġ\\', 'n']
Detokenized (014): ['provider', 'Ġ=', 'ĠModestMaps', 'Ġ.', 'ĠWMS', 'Ġ.', 'ĠProvider', 'Ġ(', 'Ġcfg', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ{', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "overlayImg = Image . blend ( overlayImg , ModestMaps . mapByExtent ( provider , ll , ur , dims ) . draw ( ) , \n"
Original    (026): ['overlayImg', '=', 'Image', '.', 'blend', '(', 'overlayImg', ',', 'ModestMaps', '.', 'mapByExtent', '(', 'provider', ',', 'll', ',', 'ur', ',', 'dims', ')', '.', 'draw', '(', ')', ',', '\\n']
Tokenized   (039): ['<s>', 'over', 'lay', 'Im', 'g', 'Ġ=', 'ĠImage', 'Ġ.', 'Ġblend', 'Ġ(', 'Ġoverlay', 'Im', 'g', 'Ġ,', 'ĠModest', 'Maps', 'Ġ.', 'Ġmap', 'By', 'Ext', 'ent', 'Ġ(', 'Ġprovider', 'Ġ,', 'Ġll', 'Ġ,', 'Ġur', 'Ġ,', 'Ġdim', 's', 'Ġ)', 'Ġ.', 'Ġdraw', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['over', 'lay', 'Im', 'g', 'Ġ=', 'ĠImage', 'Ġ.', 'Ġblend', 'Ġ(', 'Ġoverlay', 'Im', 'g', 'Ġ,', 'ĠModest', 'Maps', 'Ġ.', 'Ġmap', 'By', 'Ext', 'ent', 'Ġ(', 'Ġprovider', 'Ġ,', 'Ġll', 'Ġ,', 'Ġur', 'Ġ,', 'Ġdim', 's', 'Ġ)', 'Ġ.', 'Ġdraw', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (026): ['overlayImg', 'Ġ=', 'ĠImage', 'Ġ.', 'Ġblend', 'Ġ(', 'ĠoverlayImg', 'Ġ,', 'ĠModestMaps', 'Ġ.', 'ĠmapByExtent', 'Ġ(', 'Ġprovider', 'Ġ,', 'Ġll', 'Ġ,', 'Ġur', 'Ġ,', 'Ġdims', 'Ġ)', 'Ġ.', 'Ġdraw', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "fullImg . save ( settings . WEB_TEMP + ( % sha . hexdigest ( ) ) , , quality = 100 ) \n"
Original    (023): ['fullImg', '.', 'save', '(', 'settings', '.', 'WEB_TEMP', '+', '(', '%', 'sha', '.', 'hexdigest', '(', ')', ')', ',', ',', 'quality', '=', '100', ')', '\\n']
Tokenized   (035): ['<s>', 'full', 'Im', 'g', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġsettings', 'Ġ.', 'ĠWE', 'B', '_', 'T', 'EMP', 'Ġ+', 'Ġ(', 'Ġ%', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġquality', 'Ġ=', 'Ġ100', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['full', 'Im', 'g', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġsettings', 'Ġ.', 'ĠWE', 'B', '_', 'T', 'EMP', 'Ġ+', 'Ġ(', 'Ġ%', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġquality', 'Ġ=', 'Ġ100', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['fullImg', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġsettings', 'Ġ.', 'ĠWEB_TEMP', 'Ġ+', 'Ġ(', 'Ġ%', 'Ġsha', 'Ġ.', 'Ġhexdigest', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġquality', 'Ġ=', 'Ġ100', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "CreatePDF ( page , result , show_error_as_pdf = True ) \n"
Original    (011): ['CreatePDF', '(', 'page', ',', 'result', ',', 'show_error_as_pdf', '=', 'True', ')', '\\n']
Tokenized   (021): ['<s>', 'Create', 'PDF', 'Ġ(', 'Ġpage', 'Ġ,', 'Ġresult', 'Ġ,', 'Ġshow', '_', 'error', '_', 'as', '_', 'pdf', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Create', 'PDF', 'Ġ(', 'Ġpage', 'Ġ,', 'Ġresult', 'Ġ,', 'Ġshow', '_', 'error', '_', 'as', '_', 'pdf', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['CreatePDF', 'Ġ(', 'Ġpage', 'Ġ,', 'Ġresult', 'Ġ,', 'Ġshow_error_as_pdf', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "body = LegislativeBody . objects . get ( id = int ( request . POST [ ] ) ) \n"
Original    (020): ['body', '=', 'LegislativeBody', '.', 'objects', '.', 'get', '(', 'id', '=', 'int', '(', 'request', '.', 'POST', '[', ']', ')', ')', '\\n']
Tokenized   (024): ['<s>', 'body', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['body', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['body', 'Ġ=', 'ĠLegislativeBody', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "PlanReport . createreport . delay ( planid , stamp , req , language = translation . get_language ( ) ) \n"
Original    (021): ['PlanReport', '.', 'createreport', '.', 'delay', '(', 'planid', ',', 'stamp', ',', 'req', ',', 'language', '=', 'translation', '.', 'get_language', '(', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'Plan', 'Report', 'Ġ.', 'Ġcreate', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['Plan', 'Report', 'Ġ.', 'Ġcreate', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['PlanReport', 'Ġ.', 'Ġcreatereport', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplanid', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget_language', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "stamp = request . POST . get ( , sha . hexdigest ( ) ) \n"
Original    (016): ['stamp', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'sha', '.', 'hexdigest', '(', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'st', 'amp', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['st', 'amp', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['stamp', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġsha', 'Ġ.', 'Ġhexdigest', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "CalculatorReport . createcalculatorreport . delay ( planid , stamp , req , language = translation . get_language ~~ else : \n"
Original    (021): ['CalculatorReport', '.', 'createcalculatorreport', '.', 'delay', '(', 'planid', ',', 'stamp', ',', 'req', ',', 'language', '=', 'translation', '.', 'get_language', '~~', 'else', ':', '\\n']
Tokenized   (035): ['<s>', 'Cal', 'cul', 'ator', 'Report', 'Ġ.', 'Ġcreate', 'cal', 'cul', 'ator', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['Cal', 'cul', 'ator', 'Report', 'Ġ.', 'Ġcreate', 'cal', 'cul', 'ator', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n']
Detokenized (021): ['CalculatorReport', 'Ġ.', 'Ġcreatecalculatorreport', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplanid', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget_language', 'Ġ~~', 'Ġelse', 'Ġ:', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "site_id = Site . objects . get_current ( ) . id , \n"
Original    (013): ['site_id', '=', 'Site', '.', 'objects', '.', 'get_current', '(', ')', '.', 'id', ',', '\\n']
Tokenized   (020): ['<s>', 'site', '_', 'id', 'Ġ=', 'ĠSite', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'current', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['site', '_', 'id', 'Ġ=', 'ĠSite', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'current', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['site_id', 'Ġ=', 'ĠSite', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget_current', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "from_id = int ( request . POST . get ( , - 1 ) ) \n"
Original    (016): ['from_id', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', '-', '1', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'from', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['from', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['from_id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "to_id = int ( request . POST . get ( , None ) ) \n"
Original    (015): ['to_id', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', 'None', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'to', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['to', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['to_id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "from_districts = filter ( lambda d : True if d . district_id == from_id else False , all_districts to_district = filter ( lambda d : True if d . district_id == to_id else False , all_districts ) [ 0 ] \n"
Original    (041): ['from_districts', '=', 'filter', '(', 'lambda', 'd', ':', 'True', 'if', 'd', '.', 'district_id', '==', 'from_id', 'else', 'False', ',', 'all_districts', 'to_district', '=', 'filter', '(', 'lambda', 'd', ':', 'True', 'if', 'd', '.', 'district_id', '==', 'to_id', 'else', 'False', ',', 'all_districts', ')', '[', '0', ']', '\\n']
Tokenized   (067): ['<s>', 'from', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġfrom', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġto', '_', 'dist', 'rict', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġto', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (065): ['from', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġfrom', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġto', '_', 'dist', 'rict', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġto', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (041): ['from_districts', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict_id', 'Ġ==', 'Ġfrom_id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall_districts', 'Ġto_district', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict_id', 'Ġ==', 'Ġto_id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall_districts', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 65
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "inverse = request . REQUEST [ ] == if in request . REQUEST else False \n"
Original    (016): ['inverse', '=', 'request', '.', 'REQUEST', '[', ']', '==', 'if', 'in', 'request', '.', 'REQUEST', 'else', 'False', '\\n']
Tokenized   (022): ['<s>', 'in', 'verse', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġif', 'Ġin', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġelse', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['in', 'verse', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġif', 'Ġin', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġelse', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (016): ['inverse', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġif', 'Ġin', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġelse', 'ĠFalse', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "my_context . update ( plan . compute_splits ( layer , version = version , inverse = inverse , extended last_item = layer is layers [ - 1 ] \n"
Original    (029): ['my_context', '.', 'update', '(', 'plan', '.', 'compute_splits', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', ',', 'extended', 'last_item', '=', 'layer', 'is', 'layers', '[', '-', '1', ']', '\\n']
Tokenized   (039): ['<s>', 'my', '_', 'context', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġcompute', '_', 'spl', 'its', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġ,', 'Ġextended', 'Ġlast', '_', 'item', 'Ġ=', 'Ġlayer', 'Ġis', 'Ġlayers', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['my', '_', 'context', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġcompute', '_', 'spl', 'its', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġ,', 'Ġextended', 'Ġlast', '_', 'item', 'Ġ=', 'Ġlayer', 'Ġis', 'Ġlayers', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (029): ['my_context', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġcompute_splits', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġ,', 'Ġextended', 'Ġlast_item', 'Ġ=', 'Ġlayer', 'Ġis', 'Ġlayers', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "community_info = plan . get_community_type_info ( layer , version = version , inverse = inverse if community_info is not None : \n"
Original    (022): ['community_info', '=', 'plan', '.', 'get_community_type_info', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', 'if', 'community_info', 'is', 'not', 'None', ':', '\\n']
Tokenized   (035): ['<s>', 'community', '_', 'info', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġget', '_', 'community', '_', 'type', '_', 'info', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġif', 'Ġcommunity', '_', 'info', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['community', '_', 'info', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġget', '_', 'community', '_', 'type', '_', 'info', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġif', 'Ġcommunity', '_', 'info', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ:', 'Ġ\\', 'n']
Detokenized (022): ['community_info', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġget_community_type_info', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġif', 'Ġcommunity_info', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ:', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "html += report . render ( calc_context ) \n"
Original    (009): ['html', '+=', 'report', '.', 'render', '(', 'calc_context', ')', '\\n']
Tokenized   (014): ['<s>', 'html', 'Ġ+=', 'Ġreport', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġcalc', '_', 'context', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['html', 'Ġ+=', 'Ġreport', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġcalc', '_', 'context', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['html', 'Ġ+=', 'Ġreport', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġcalc_context', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "geounit_ids = string . split ( request . REQUEST [ "geounits" ] , "|" ) \n"
Original    (016): ['geounit_ids', '=', 'string', '.', 'split', '(', 'request', '.', 'REQUEST', '[', '"geounits"', ']', ',', '"|"', ')', '\\n']
Tokenized   (030): ['<s>', 'ge', 'oun', 'it', '_', 'ids', 'Ġ=', 'Ġstring', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'ge', 'oun', 'its', '"', 'Ġ]', 'Ġ,', 'Ġ"', '|', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['ge', 'oun', 'it', '_', 'ids', 'Ġ=', 'Ġstring', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'ge', 'oun', 'its', '"', 'Ġ]', 'Ġ,', 'Ġ"', '|', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['geounit_ids', 'Ġ=', 'Ġstring', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġ[', 'Ġ"geounits"', 'Ġ]', 'Ġ,', 'Ġ"|"', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "max_version = max ( [ d . version for d in districts ] ) \n"
Original    (015): ['max_version', '=', 'max', '(', '[', 'd', '.', 'version', 'for', 'd', 'in', 'districts', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'max', '_', 'version', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġversion', 'Ġfor', 'Ġd', 'Ġin', 'Ġdistricts', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['max', '_', 'version', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġversion', 'Ġfor', 'Ġd', 'Ġin', 'Ġdistricts', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['max_version', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġversion', 'Ġfor', 'Ġd', 'Ġin', 'Ġdistricts', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "can_undo = max_version > plan . min_version \n"
Original    (008): ['can_undo', '=', 'max_version', '>', 'plan', '.', 'min_version', '\\n']
Tokenized   (017): ['<s>', 'can', '_', 'undo', 'Ġ=', 'Ġmax', '_', 'version', 'Ġ>', 'Ġplan', 'Ġ.', 'Ġmin', '_', 'version', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['can', '_', 'undo', 'Ġ=', 'Ġmax', '_', 'version', 'Ġ>', 'Ġplan', 'Ġ.', 'Ġmin', '_', 'version', 'Ġ\\', 'n']
Detokenized (008): ['can_undo', 'Ġ=', 'Ġmax_version', 'Ġ>', 'Ġplan', 'Ġ.', 'Ġmin_version', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bbox = tuple ( map ( lambda x : float ( x ) , bbox . split ( ) ) ) \n"
Original    (022): ['bbox', '=', 'tuple', '(', 'map', '(', 'lambda', 'x', ':', 'float', '(', 'x', ')', ',', 'bbox', '.', 'split', '(', ')', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'b', 'box', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġb', 'box', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['b', 'box', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġb', 'box', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['bbox', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġbbox', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "wkt = wkt . replace ( , ) . replace ( , ) \n"
Original    (014): ['wkt', '=', 'wkt', '.', 'replace', '(', ',', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'w', 'kt', 'Ġ=', 'Ġw', 'kt', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['w', 'kt', 'Ġ=', 'Ġw', 'kt', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['wkt', 'Ġ=', 'Ġwkt', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "districts = [ d . id for d in plan . get_districts_at_version ( version , include_geom = True ) if locked = District . objects . filter ( id__in = districts ) . collect ( ) \n"
Original    (037): ['districts', '=', '[', 'd', '.', 'id', 'for', 'd', 'in', 'plan', '.', 'get_districts_at_version', '(', 'version', ',', 'include_geom', '=', 'True', ')', 'if', 'locked', '=', 'District', '.', 'objects', '.', 'filter', '(', 'id__in', '=', 'districts', ')', '.', 'collect', '(', ')', '\\n']
Tokenized   (055): ['<s>', 'dist', 'rict', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ.', 'Ġid', 'Ġfor', 'Ġd', 'Ġin', 'Ġplan', 'Ġ.', 'Ġget', '_', 'dist', 'rict', 's', '_', 'at', '_', 'version', 'Ġ(', 'Ġversion', 'Ġ,', 'Ġinclude', '_', 'ge', 'om', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġ=', 'ĠDistrict', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġid', '__', 'in', 'Ġ=', 'Ġdistricts', 'Ġ)', 'Ġ.', 'Ġcollect', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (053): ['dist', 'rict', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ.', 'Ġid', 'Ġfor', 'Ġd', 'Ġin', 'Ġplan', 'Ġ.', 'Ġget', '_', 'dist', 'rict', 's', '_', 'at', '_', 'version', 'Ġ(', 'Ġversion', 'Ġ,', 'Ġinclude', '_', 'ge', 'om', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġ=', 'ĠDistrict', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġid', '__', 'in', 'Ġ=', 'Ġdistricts', 'Ġ)', 'Ġ.', 'Ġcollect', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (037): ['districts', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ.', 'Ġid', 'Ġfor', 'Ġd', 'Ġin', 'Ġplan', 'Ġ.', 'Ġget_districts_at_version', 'Ġ(', 'Ġversion', 'Ġ,', 'Ġinclude_geom', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġ=', 'ĠDistrict', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġid__in', 'Ġ=', 'Ġdistricts', 'Ġ)', 'Ġ.', 'Ġcollect', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 53
===================================================================
Hidden states:  (13, 37, 768)
# Extracted words:  37
Sentence         : "locked_buffered = locked . simplify ( 100 , True ) . buffer ( 100 ) if locked else None \n"
Original    (020): ['locked_buffered', '=', 'locked', '.', 'simplify', '(', '100', ',', 'True', ')', '.', 'buffer', '(', '100', ')', 'if', 'locked', 'else', 'None', '\\n']
Tokenized   (026): ['<s>', 'locked', '_', 'buff', 'ered', 'Ġ=', 'Ġlocked', 'Ġ.', 'Ġsimplify', 'Ġ(', 'Ġ100', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġbuffer', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġelse', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['locked', '_', 'buff', 'ered', 'Ġ=', 'Ġlocked', 'Ġ.', 'Ġsimplify', 'Ġ(', 'Ġ100', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġbuffer', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġelse', 'ĠNone', 'Ġ\\', 'n']
Detokenized (020): ['locked_buffered', 'Ġ=', 'Ġlocked', 'Ġ.', 'Ġsimplify', 'Ġ(', 'Ġ100', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġbuffer', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġelse', 'ĠNone', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "filtered = Geolevel . objects . get ( id = geolevel ) . geounit_set . filter ( selection ) \n"
Original    (020): ['filtered', '=', 'Geolevel', '.', 'objects', '.', 'get', '(', 'id', '=', 'geolevel', ')', '.', 'geounit_set', '.', 'filter', '(', 'selection', ')', '\\n']
Tokenized   (032): ['<s>', 'fil', 'tered', 'Ġ=', 'ĠGe', 'ole', 'vel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġge', 'ole', 'vel', 'Ġ)', 'Ġ.', 'Ġge', 'oun', 'it', '_', 'set', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselection', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['fil', 'tered', 'Ġ=', 'ĠGe', 'ole', 'vel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġge', 'ole', 'vel', 'Ġ)', 'Ġ.', 'Ġge', 'oun', 'it', '_', 'set', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselection', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['filtered', 'Ġ=', 'ĠGeolevel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġgeolevel', 'Ġ)', 'Ġ.', 'Ġgeounit_set', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselection', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "pfilter = Q ( legislative_body = leg_body ) & Q ( is_valid = True ) \n"
Original    (016): ['pfilter', '=', 'Q', '(', 'legislative_body', '=', 'leg_body', ')', '&', 'Q', '(', 'is_valid', '=', 'True', ')', '\\n']
Tokenized   (026): ['<s>', 'p', 'filter', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġlegislative', '_', 'body', 'Ġ=', 'Ġleg', '_', 'body', 'Ġ)', 'Ġ&', 'ĠQ', 'Ġ(', 'Ġis', '_', 'valid', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['p', 'filter', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġlegislative', '_', 'body', 'Ġ=', 'Ġleg', '_', 'body', 'Ġ)', 'Ġ&', 'ĠQ', 'Ġ(', 'Ġis', '_', 'valid', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['pfilter', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġlegislative_body', 'Ġ=', 'Ġleg_body', 'Ġ)', 'Ġ&', 'ĠQ', 'Ġ(', 'Ġis_valid', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "panels = display . scorepanel_set . all ( ) . order_by ( ) \n"
Original    (014): ['panels', '=', 'display', '.', 'scorepanel_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', '\\n']
Tokenized   (023): ['<s>', 'pan', 'els', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['pan', 'els', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['panels', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġscorepanel_set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "writer . writerow ( [ , , ] + [ p . __unicode__ ( ) for p in panels ] ) \n"
Original    (022): ['writer', '.', 'writerow', '(', '[', ',', ',', ']', '+', '[', 'p', '.', '__unicode__', '(', ')', 'for', 'p', 'in', 'panels', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'writer', 'Ġ.', 'Ġwriter', 'ow', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ+', 'Ġ[', 'Ġp', 'Ġ.', 'Ġ__', 'unic', 'ode', '__', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpanels', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['writer', 'Ġ.', 'Ġwriter', 'ow', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ+', 'Ġ[', 'Ġp', 'Ġ.', 'Ġ__', 'unic', 'ode', '__', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpanels', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['writer', 'Ġ.', 'Ġwriterow', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ+', 'Ġ[', 'Ġp', 'Ġ.', 'Ġ__unicode__', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpanels', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "rows = int ( request . POST . get ( , 10 ) ) \n"
Original    (015): ['rows', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', '10', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'rows', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['rows', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['rows', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "sidx = request . POST . get ( , ) \n"
Original    (011): ['sidx', '=', 'request', '.', 'POST', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (015): ['<s>', 'sid', 'x', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['sid', 'x', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['sidx', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "owner_filter = request . POST . get ( ) ; \n"
Original    (011): ['owner_filter', '=', 'request', '.', 'POST', '.', 'get', '(', ')', ';', '\\n']
Tokenized   (016): ['<s>', 'owner', '_', 'filter', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['owner', '_', 'filter', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ;', 'Ġ\\', 'n']
Detokenized (011): ['owner_filter', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ;', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "body_pk = int ( body_pk ) if body_pk else body_pk ; \n"
Original    (012): ['body_pk', '=', 'int', '(', 'body_pk', ')', 'if', 'body_pk', 'else', 'body_pk', ';', '\\n']
Tokenized   (027): ['<s>', 'body', '_', 'p', 'k', 'Ġ=', 'Ġint', 'Ġ(', 'Ġbody', '_', 'p', 'k', 'Ġ)', 'Ġif', 'Ġbody', '_', 'p', 'k', 'Ġelse', 'Ġbody', '_', 'p', 'k', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['body', '_', 'p', 'k', 'Ġ=', 'Ġint', 'Ġ(', 'Ġbody', '_', 'p', 'k', 'Ġ)', 'Ġif', 'Ġbody', '_', 'p', 'k', 'Ġelse', 'Ġbody', '_', 'p', 'k', 'Ġ;', 'Ġ\\', 'n']
Detokenized (012): ['body_pk', 'Ġ=', 'Ġint', 'Ġ(', 'Ġbody_pk', 'Ġ)', 'Ġif', 'Ġbody_pk', 'Ġelse', 'Ġbody_pk', 'Ġ;', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "search = request . POST . get ( , False ) ; \n"
Original    (013): ['search', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'False', ')', ';', '\\n']
Tokenized   (016): ['<s>', 'search', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['search', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ;', 'Ġ\\', 'n']
Detokenized (013): ['search', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ;', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "search_string = request . POST . get ( , ) ; \n"
Original    (012): ['search_string', '=', 'request', '.', 'POST', '.', 'get', '(', ',', ')', ';', '\\n']
Tokenized   (017): ['<s>', 'search', '_', 'string', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['search', '_', 'string', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ;', 'Ġ\\', 'n']
Detokenized (012): ['search_string', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ;', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "is_community = request . POST . get ( , False ) == ; \n"
Original    (014): ['is_community', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'False', ')', '==', ';', '\\n']
Tokenized   (019): ['<s>', 'is', '_', 'community', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ==', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['is', '_', 'community', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ==', 'Ġ;', 'Ġ\\', 'n']
Detokenized (014): ['is_community', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ==', 'Ġ;', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "all_plans = Plan . objects . filter ( available , not_creating , search_filter , community_filter ) . order_by \n"
Original    (019): ['all_plans', '=', 'Plan', '.', 'objects', '.', 'filter', '(', 'available', ',', 'not_creating', ',', 'search_filter', ',', 'community_filter', ')', '.', 'order_by', '\\n']
Tokenized   (034): ['<s>', 'all', '_', 'pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġavailable', 'Ġ,', 'Ġnot', '_', 'creat', 'ing', 'Ġ,', 'Ġsearch', '_', 'filter', 'Ġ,', 'Ġcommunity', '_', 'filter', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['all', '_', 'pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġavailable', 'Ġ,', 'Ġnot', '_', 'creat', 'ing', 'Ġ,', 'Ġsearch', '_', 'filter', 'Ġ,', 'Ġcommunity', '_', 'filter', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ\\', 'n']
Detokenized (019): ['all_plans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġavailable', 'Ġ,', 'Ġnot_creating', 'Ġ,', 'Ġsearch_filter', 'Ġ,', 'Ġcommunity_filter', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "all_districts = ( ) \n"
Original    (005): ['all_districts', '=', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'all', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['all', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['all_districts', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "_ ( ) ) \n"
Original    (005): ['_', '(', ')', ')', '\\n']
Tokenized   (008): ['<s>', '_', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['_', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['_', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "user_functions = ScoreFunction . objects . filter ( selectable_bodies = plan . legislative_body ) . order_by for f in user_functions : \n"
Original    (022): ['user_functions', '=', 'ScoreFunction', '.', 'objects', '.', 'filter', '(', 'selectable_bodies', '=', 'plan', '.', 'legislative_body', ')', '.', 'order_by', 'for', 'f', 'in', 'user_functions', ':', '\\n']
Tokenized   (040): ['<s>', 'user', '_', 'fun', 'ctions', 'Ġ=', 'ĠScore', 'Function', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġfor', 'Ġf', 'Ġin', 'Ġuser', '_', 'fun', 'ctions', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['user', '_', 'fun', 'ctions', 'Ġ=', 'ĠScore', 'Function', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġfor', 'Ġf', 'Ġin', 'Ġuser', '_', 'fun', 'ctions', 'Ġ:', 'Ġ\\', 'n']
Detokenized (022): ['user_functions', 'Ġ=', 'ĠScoreFunction', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselectable_bodies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative_body', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġfor', 'Ġf', 'Ġin', 'Ġuser_functions', 'Ġ:', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : ""%s_sidebar_demo" % plan . legislative_body . name , \n"
Original    (009): ['"%s_sidebar_demo"', '%', 'plan', '.', 'legislative_body', '.', 'name', ',', '\\n']
Tokenized   (023): ['<s>', '"', '%', 's', '_', 'side', 'bar', '_', 'dem', 'o', '"', 'Ġ%', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', '%', 's', '_', 'side', 'bar', '_', 'dem', 'o', '"', 'Ġ%', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"%s_sidebar_demo"', 'Ġ%', 'Ġplan', 'Ġ.', 'Ġlegislative_body', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "plan . legislative_body . name ) \n"
Original    (007): ['plan', '.', 'legislative_body', '.', 'name', ')', '\\n']
Tokenized   (012): ['<s>', 'plan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['plan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['plan', 'Ġ.', 'Ġlegislative_body', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "functions = map ( lambda x : int ( x ) , functions ) \n"
Original    (015): ['functions', '=', 'map', '(', 'lambda', 'x', ':', 'int', '(', 'x', ')', ',', 'functions', ')', '\\n']
Tokenized   (019): ['<s>', 'fun', 'ctions', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfunctions', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['fun', 'ctions', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfunctions', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['functions', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfunctions', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "display = display . copy_from ( display = demo , title = request . POST . get ( ) , owner = result [ ] = True \n"
Original    (028): ['display', '=', 'display', '.', 'copy_from', '(', 'display', '=', 'demo', ',', 'title', '=', 'request', '.', 'POST', '.', 'get', '(', ')', ',', 'owner', '=', 'result', '[', ']', '=', 'True', '\\n']
Tokenized   (033): ['<s>', 'display', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġcopy', '_', 'from', 'Ġ(', 'Ġdisplay', 'Ġ=', 'Ġdemo', 'Ġ,', 'Ġtitle', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġowner', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['display', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġcopy', '_', 'from', 'Ġ(', 'Ġdisplay', 'Ġ=', 'Ġdemo', 'Ġ,', 'Ġtitle', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġowner', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n']
Detokenized (028): ['display', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġcopy_from', 'Ġ(', 'Ġdisplay', 'Ġ=', 'Ġdemo', 'Ġ,', 'Ġtitle', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġowner', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "version = min ( plan . version , int ( version ) ) \n"
Original    (014): ['version', '=', 'min', '(', 'plan', '.', 'version', ',', 'int', '(', 'version', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'version', 'Ġ=', 'Ġmin', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġint', 'Ġ(', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['version', 'Ġ=', 'Ġmin', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġint', 'Ġ(', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['version', 'Ġ=', 'Ġmin', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġint', 'Ġ(', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "Comment . objects . filter ( object_pk = district . id , content_type = ct ) . delete ( ) \n"
Original    (021): ['Comment', '.', 'objects', '.', 'filter', '(', 'object_pk', '=', 'district', '.', 'id', ',', 'content_type', '=', 'ct', ')', '.', 'delete', '(', ')', '\\n']
Tokenized   (030): ['<s>', 'Comment', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġobject', '_', 'p', 'k', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ,', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġc', 't', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['Comment', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġobject', '_', 'p', 'k', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ,', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġc', 't', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['Comment', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġobject_pk', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ,', 'Ġcontent_type', 'Ġ=', 'Ġct', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "TaggedItem . objects . filter ( tag__in = tset , object_id = district . id ) . delete ( ) \n"
Original    (021): ['TaggedItem', '.', 'objects', '.', 'filter', '(', 'tag__in', '=', 'tset', ',', 'object_id', '=', 'district', '.', 'id', ')', '.', 'delete', '(', ')', '\\n']
Tokenized   (031): ['<s>', 'T', 'agged', 'Item', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġtag', '__', 'in', 'Ġ=', 'Ġt', 'set', 'Ġ,', 'Ġobject', '_', 'id', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['T', 'agged', 'Item', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġtag', '__', 'in', 'Ġ=', 'Ġt', 'set', 'Ġ,', 'Ġobject', '_', 'id', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['TaggedItem', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġtag__in', 'Ġ=', 'Ġtset', 'Ġ,', 'Ġobject_id', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "geolevel = plans [ 0 ] . legislative_body . get_geolevels ( ) [ 0 ] \n"
Original    (016): ['geolevel', '=', 'plans', '[', '0', ']', '.', 'legislative_body', '.', 'get_geolevels', '(', ')', '[', '0', ']', '\\n']
Tokenized   (028): ['<s>', 'ge', 'ole', 'vel', 'Ġ=', 'Ġplans', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġget', '_', 'ge', 'ole', 'vel', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['ge', 'ole', 'vel', 'Ġ=', 'Ġplans', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġget', '_', 'ge', 'ole', 'vel', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['geolevel', 'Ġ=', 'Ġplans', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlegislative_body', 'Ġ.', 'Ġget_geolevels', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "plans = Plan . objects . filter ( is_shared = True ) . order_by ( ) [ 0 : 10 ] \n"
Original    (022): ['plans', '=', 'Plan', '.', 'objects', '.', 'filter', '(', 'is_shared', '=', 'True', ')', '.', 'order_by', '(', ')', '[', '0', ':', '10', ']', '\\n']
Tokenized   (030): ['<s>', 'pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġis', '_', 'shared', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġ10', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġis', '_', 'shared', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġ10', 'Ġ]', 'Ġ\\', 'n']
Detokenized (022): ['plans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġis_shared', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġ10', 'Ġ]', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "write_page = 0 if write_page == 1 else write_page + 1 \n"
Original    (012): ['write_page', '=', '0', 'if', 'write_page', '==', '1', 'else', 'write_page', '+', '1', '\\n']
Tokenized   (021): ['<s>', 'write', '_', 'page', 'Ġ=', 'Ġ0', 'Ġif', 'Ġwrite', '_', 'page', 'Ġ==', 'Ġ1', 'Ġelse', 'Ġwrite', '_', 'page', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['write', '_', 'page', 'Ġ=', 'Ġ0', 'Ġif', 'Ġwrite', '_', 'page', 'Ġ==', 'Ġ1', 'Ġelse', 'Ġwrite', '_', 'page', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (012): ['write_page', 'Ġ=', 'Ġ0', 'Ġif', 'Ġwrite_page', 'Ġ==', 'Ġ1', 'Ġelse', 'Ġwrite_page', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "init_sum = 1 if i == 0 else 0 \n"
Original    (010): ['init_sum', '=', '1', 'if', 'i', '==', '0', 'else', '0', '\\n']
Tokenized   (015): ['<s>', 'init', '_', 'sum', 'Ġ=', 'Ġ1', 'Ġif', 'Ġi', 'Ġ==', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['init', '_', 'sum', 'Ġ=', 'Ġ1', 'Ġif', 'Ġi', 'Ġ==', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n']
Detokenized (010): ['init_sum', 'Ġ=', 'Ġ1', 'Ġif', 'Ġi', 'Ġ==', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "mem_d0 . read_nonblocking ( 1 , write_addr , mesh_size - 2 ) \n"
Original    (013): ['mem_d0', '.', 'read_nonblocking', '(', '1', ',', 'write_addr', ',', 'mesh_size', '-', '2', ')', '\\n']
Tokenized   (026): ['<s>', 'mem', '_', 'd', '0', 'Ġ.', 'Ġread', '_', 'non', 'blocking', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġwrite', '_', 'addr', 'Ġ,', 'Ġmesh', '_', 'size', 'Ġ-', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['mem', '_', 'd', '0', 'Ġ.', 'Ġread', '_', 'non', 'blocking', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġwrite', '_', 'addr', 'Ġ,', 'Ġmesh', '_', 'size', 'Ġ-', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['mem_d0', 'Ġ.', 'Ġread_nonblocking', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġwrite_addr', 'Ġ,', 'Ġmesh_size', 'Ġ-', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "write_addr += mesh_size * DSIZE \n"
Original    (006): ['write_addr', '+=', 'mesh_size', '*', 'DSIZE', '\\n']
Tokenized   (014): ['<s>', 'write', '_', 'addr', 'Ġ+=', 'Ġmesh', '_', 'size', 'Ġ*', 'ĠD', 'SIZE', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['write', '_', 'addr', 'Ġ+=', 'Ġmesh', '_', 'size', 'Ġ*', 'ĠD', 'SIZE', 'Ġ\\', 'n']
Detokenized (006): ['write_addr', 'Ġ+=', 'Ġmesh_size', 'Ġ*', 'ĠDSIZE', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "sub_id_base = ( 10 if sub_id_m . group ( 1 ) . count ( "\'d" ) > 0 else \n"
Original    (020): ['sub_id_base', '=', '(', '10', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'d"', ')', '>', '0', 'else', '\\n']
Tokenized   (034): ['<s>', 'sub', '_', 'id', '_', 'base', 'Ġ=', 'Ġ(', 'Ġ10', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'd', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['sub', '_', 'id', '_', 'base', 'Ġ=', 'Ġ(', 'Ġ10', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'd', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n']
Detokenized (020): ['sub_id_base', 'Ġ=', 'Ġ(', 'Ġ10', 'Ġif', 'Ġsub_id_m', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\\'d"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "16 if sub_id_m . group ( 1 ) . count ( "\'h" ) > 0 else \n"
Original    (017): ['16', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'h"', ')', '>', '0', 'else', '\\n']
Tokenized   (027): ['<s>', '16', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'h', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['16', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'h', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n']
Detokenized (017): ['16', 'Ġif', 'Ġsub_id_m', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\\'h"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "10 ) \n"
Original    (003): ['10', ')', '\\n']
Tokenized   (006): ['<s>', '10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (004): ['10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (003): ['10', 'Ġ)', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "optparser . add_option ( "--noreorder" , action = "store_true" , dest = "noreorder" , \n"
Original    (015): ['optparser', '.', 'add_option', '(', '"--noreorder"', ',', 'action', '=', '"store_true"', ',', 'dest', '=', '"noreorder"', ',', '\\n']
Tokenized   (034): ['<s>', 'opt', 'parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ"', '--', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ"', 'store', '_', 'true', '"', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ"', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['opt', 'parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ"', '--', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ"', 'store', '_', 'true', '"', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ"', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['optparser', 'Ġ.', 'Ġadd_option', 'Ġ(', 'Ġ"--noreorder"', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ"store_true"', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ"noreorder"', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "truenode = replaceUndefined ( tree . truenode , termname ) \n"
Original    (011): ['truenode', '=', 'replaceUndefined', '(', 'tree', '.', 'truenode', ',', 'termname', ')', '\\n']
Tokenized   (022): ['<s>', 't', 'ru', 'en', 'ode', 'Ġ=', 'Ġreplace', 'Und', 'efined', 'Ġ(', 'Ġtree', 'Ġ.', 'Ġtru', 'en', 'ode', 'Ġ,', 'Ġterm', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['t', 'ru', 'en', 'ode', 'Ġ=', 'Ġreplace', 'Und', 'efined', 'Ġ(', 'Ġtree', 'Ġ.', 'Ġtru', 'en', 'ode', 'Ġ,', 'Ġterm', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['truenode', 'Ġ=', 'ĠreplaceUndefined', 'Ġ(', 'Ġtree', 'Ġ.', 'Ġtruenode', 'Ġ,', 'Ġtermname', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "codedir = os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) + \n"
Original    (033): ['codedir', '=', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'abspath', '(', '__file__', ')', ')', ')', ')', '+', '\\n']
Tokenized   (043): ['<s>', 'coded', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['coded', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (033): ['codedir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 33, 768)
# Extracted words:  33
Sentence         : "analyzer = VerilogDataflowAnalyzer ( filelist , topmodule , \n"
Original    (009): ['analyzer', '=', 'VerilogDataflowAnalyzer', '(', 'filelist', ',', 'topmodule', ',', '\\n']
Tokenized   (021): ['<s>', 'analy', 'zer', 'Ġ=', 'ĠVer', 'il', 'og', 'Data', 'flow', 'Analy', 'zer', 'Ġ(', 'Ġfile', 'list', 'Ġ,', 'Ġtop', 'module', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['analy', 'zer', 'Ġ=', 'ĠVer', 'il', 'og', 'Data', 'flow', 'Analy', 'zer', 'Ġ(', 'Ġfile', 'list', 'Ġ,', 'Ġtop', 'module', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['analyzer', 'Ġ=', 'ĠVerilogDataflowAnalyzer', 'Ġ(', 'Ġfilelist', 'Ġ,', 'Ġtopmodule', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "constlist = optimizer . getConstlist ( ) \n"
Original    (008): ['constlist', '=', 'optimizer', '.', 'getConstlist', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'const', 'list', 'Ġ=', 'Ġoptim', 'izer', 'Ġ.', 'Ġget', 'Const', 'list', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['const', 'list', 'Ġ=', 'Ġoptim', 'izer', 'Ġ.', 'Ġget', 'Const', 'list', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['constlist', 'Ġ=', 'Ġoptimizer', 'Ġ.', 'ĠgetConstlist', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "interval = m . Parameter ( , 16 ) \n"
Original    (010): ['interval', '=', 'm', '.', 'Parameter', '(', ',', '16', ')', '\\n']
Tokenized   (015): ['<s>', 'inter', 'val', 'Ġ=', 'Ġm', 'Ġ.', 'ĠParam', 'eter', 'Ġ(', 'Ġ,', 'Ġ16', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['inter', 'val', 'Ġ=', 'Ġm', 'Ġ.', 'ĠParam', 'eter', 'Ġ(', 'Ġ,', 'Ġ16', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['interval', 'Ġ=', 'Ġm', 'Ġ.', 'ĠParameter', 'Ġ(', 'Ġ,', 'Ġ16', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "led ( led + 1 ) , \n"
Original    (008): ['led', '(', 'led', '+', '1', ')', ',', '\\n']
Tokenized   (011): ['<s>', 'led', 'Ġ(', 'Ġled', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['led', 'Ġ(', 'Ġled', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['led', 'Ġ(', 'Ġled', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "SingleStatement ( SystemTask ( , , led ) ) \n"
Original    (010): ['SingleStatement', '(', 'SystemTask', '(', ',', ',', 'led', ')', ')', '\\n']
Tokenized   (015): ['<s>', 'Single', 'Statement', 'Ġ(', 'ĠSystem', 'Task', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġled', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Single', 'Statement', 'Ġ(', 'ĠSystem', 'Task', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġled', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['SingleStatement', 'Ġ(', 'ĠSystemTask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġled', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "y = dataflow . Variable ( , valid = , ready = , point = 4 ) \n"
Original    (018): ['y', '=', 'dataflow', '.', 'Variable', '(', ',', 'valid', '=', ',', 'ready', '=', ',', 'point', '=', '4', ')', '\\n']
Tokenized   (022): ['<s>', 'y', 'Ġ=', 'Ġdata', 'flow', 'Ġ.', 'ĠVariable', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ,', 'Ġpoint', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['y', 'Ġ=', 'Ġdata', 'flow', 'Ġ.', 'ĠVariable', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ,', 'Ġpoint', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['y', 'Ġ=', 'Ġdataflow', 'Ġ.', 'ĠVariable', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ,', 'Ġpoint', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "z . output ( , valid = , ready = ) \n"
Original    (012): ['z', '.', 'output', '(', ',', 'valid', '=', ',', 'ready', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'z', 'Ġ.', 'Ġoutput', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['z', 'Ġ.', 'Ġoutput', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['z', 'Ġ.', 'Ġoutput', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "xdata_orig = m . RegLike ( ports [ ] , name = , initval = 0 ) \n"
Original    (018): ['xdata_orig', '=', 'm', '.', 'RegLike', '(', 'ports', '[', ']', ',', 'name', '=', ',', 'initval', '=', '0', ')', '\\n']
Tokenized   (026): ['<s>', 'x', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['x', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['xdata_orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠRegLike', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ,', 'Ġinitval', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "zdata_orig = m . WireLike ( ports [ ] , name = ) \n"
Original    (014): ['zdata_orig', '=', 'm', '.', 'WireLike', '(', 'ports', '[', ']', ',', 'name', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'z', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['z', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['zdata_orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWireLike', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "params = m . connect_params ( main ) , \n"
Original    (010): ['params', '=', 'm', '.', 'connect_params', '(', 'main', ')', ',', '\\n']
Tokenized   (015): ['<s>', 'params', 'Ġ=', 'Ġm', 'Ġ.', 'Ġconnect', '_', 'params', 'Ġ(', 'Ġmain', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['params', 'Ġ=', 'Ġm', 'Ġ.', 'Ġconnect', '_', 'params', 'Ġ(', 'Ġmain', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['params', 'Ġ=', 'Ġm', 'Ġ.', 'Ġconnect_params', 'Ġ(', 'Ġmain', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "reset_stmt . append ( ydata_orig ( 0 ) ) \n"
Original    (010): ['reset_stmt', '.', 'append', '(', 'ydata_orig', '(', '0', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'reset', '_', 'st', 'mt', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġy', 'data', '_', 'orig', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['reset', '_', 'st', 'mt', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġy', 'data', '_', 'orig', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['reset_stmt', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġydata_orig', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "nclk ( clk ) , \n"
Original    (006): ['nclk', '(', 'clk', ')', ',', '\\n']
Tokenized   (012): ['<s>', 'n', 'cl', 'k', 'Ġ(', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['n', 'cl', 'k', 'Ġ(', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['nclk', 'Ġ(', 'Ġclk', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "send ( , ydata_orig , yvalid , yready , step = 1 , waitnum = 20 ) \n"
Original    (018): ['send', '(', ',', 'ydata_orig', ',', 'yvalid', ',', 'yready', ',', 'step', '=', '1', ',', 'waitnum', '=', '20', ')', '\\n']
Tokenized   (027): ['<s>', 'send', 'Ġ(', 'Ġ,', 'Ġy', 'data', '_', 'orig', 'Ġ,', 'Ġy', 'valid', 'Ġ,', 'Ġy', 'ready', 'Ġ,', 'Ġstep', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ20', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['send', 'Ġ(', 'Ġ,', 'Ġy', 'data', '_', 'orig', 'Ġ,', 'Ġy', 'valid', 'Ġ,', 'Ġy', 'ready', 'Ġ,', 'Ġstep', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ20', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['send', 'Ġ(', 'Ġ,', 'Ġydata_orig', 'Ġ,', 'Ġyvalid', 'Ġ,', 'Ġyready', 'Ġ,', 'Ġstep', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġwaitnum', 'Ġ=', 'Ġ20', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "receive ( , zdata , zvalid , zready , waitnum = 50 ) \n"
Original    (014): ['receive', '(', ',', 'zdata', ',', 'zvalid', ',', 'zready', ',', 'waitnum', '=', '50', ')', '\\n']
Tokenized   (022): ['<s>', 're', 'ceive', 'Ġ(', 'Ġ,', 'Ġz', 'data', 'Ġ,', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ50', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['re', 'ceive', 'Ġ(', 'Ġ,', 'Ġz', 'data', 'Ġ,', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ50', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['receive', 'Ġ(', 'Ġ,', 'Ġzdata', 'Ġ,', 'Ġzvalid', 'Ġ,', 'Ġzready', 'Ġ,', 'Ġwaitnum', 'Ġ=', 'Ġ50', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "If ( AndList ( zvalid , zready ) ) ( \n"
Original    (011): ['If', '(', 'AndList', '(', 'zvalid', ',', 'zready', ')', ')', '(', '\\n']
Tokenized   (017): ['<s>', 'If', 'Ġ(', 'ĠAnd', 'List', 'Ġ(', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ)', 'Ġ)', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['If', 'Ġ(', 'ĠAnd', 'List', 'Ġ(', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ)', 'Ġ)', 'Ġ(', 'Ġ\\', 'n']
Detokenized (011): ['If', 'Ġ(', 'ĠAndList', 'Ġ(', 'Ġzvalid', 'Ġ,', 'Ġzready', 'Ġ)', 'Ġ)', 'Ġ(', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Systask ( , , zdata_orig ) \n"
Original    (007): ['Systask', '(', ',', ',', 'zdata_orig', ')', '\\n']
Tokenized   (015): ['<s>', 'Sy', 'st', 'ask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġz', 'data', '_', 'orig', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Sy', 'st', 'ask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġz', 'data', '_', 'orig', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['Systask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġzdata_orig', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "count = m . Reg ( , width = 32 , initval = 0 ) \n"
Original    (016): ['count', '=', 'm', '.', 'Reg', '(', ',', 'width', '=', '32', ',', 'initval', '=', '0', ')', '\\n']
Tokenized   (020): ['<s>', 'count', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Ġ(', 'Ġ,', 'Ġwidth', 'Ġ=', 'Ġ32', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['count', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Ġ(', 'Ġ,', 'Ġwidth', 'Ġ=', 'Ġ32', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['count', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Ġ(', 'Ġ,', 'Ġwidth', 'Ġ=', 'Ġ32', 'Ġ,', 'Ġinitval', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "fsm . add ( valid ( down ) , cond = c , delay = 4 , eager_val = True , lazy_cond = True ) \n"
Original    (026): ['fsm', '.', 'add', '(', 'valid', '(', 'down', ')', ',', 'cond', '=', 'c', ',', 'delay', '=', '4', ',', 'eager_val', '=', 'True', ',', 'lazy_cond', '=', 'True', ')', '\\n']
Tokenized   (034): ['<s>', 'f', 'sm', 'Ġ.', 'Ġadd', 'Ġ(', 'Ġvalid', 'Ġ(', 'Ġdown', 'Ġ)', 'Ġ,', 'Ġcond', 'Ġ=', 'Ġc', 'Ġ,', 'Ġdelay', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġeager', '_', 'val', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġlazy', '_', 'cond', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['f', 'sm', 'Ġ.', 'Ġadd', 'Ġ(', 'Ġvalid', 'Ġ(', 'Ġdown', 'Ġ)', 'Ġ,', 'Ġcond', 'Ġ=', 'Ġc', 'Ġ,', 'Ġdelay', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġeager', '_', 'val', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġlazy', '_', 'cond', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['fsm', 'Ġ.', 'Ġadd', 'Ġ(', 'Ġvalid', 'Ġ(', 'Ġdown', 'Ġ)', 'Ġ,', 'Ġcond', 'Ġ=', 'Ġc', 'Ġ,', 'Ġdelay', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġeager_val', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġlazy_cond', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "uut = m . Instance ( mkLed ( ) , , \n"
Original    (012): ['uut', '=', 'm', '.', 'Instance', '(', 'mkLed', '(', ')', ',', ',', '\\n']
Tokenized   (018): ['<s>', 'u', 'ut', 'Ġ=', 'Ġm', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmk', 'Led', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['u', 'ut', 'Ġ=', 'Ġm', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmk', 'Led', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['uut', 'Ġ=', 'Ġm', 'Ġ.', 'ĠInstance', 'Ġ(', 'ĠmkLed', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "rslt = m . Wire ( , retwidth , signed = True ) \n"
Original    (014): ['rslt', '=', 'm', '.', 'Wire', '(', ',', 'retwidth', ',', 'signed', '=', 'True', ')', '\\n']
Tokenized   (019): ['<s>', 'rs', 'lt', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Ġ(', 'Ġ,', 'Ġret', 'width', 'Ġ,', 'Ġsigned', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rs', 'lt', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Ġ(', 'Ġ,', 'Ġret', 'width', 'Ġ,', 'Ġsigned', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['rslt', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Ġ(', 'Ġ,', 'Ġretwidth', 'Ġ,', 'Ġsigned', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "tmpval [ 0 ] ( rslt ) , \n"
Original    (009): ['tmpval', '[', '0', ']', '(', 'rslt', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'tmp', 'val', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ(', 'Ġrs', 'lt', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['tmp', 'val', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ(', 'Ġrs', 'lt', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['tmpval', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ(', 'Ġrslt', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "vtypes . If ( rst ) ( \n"
Original    (008): ['vtypes', '.', 'If', '(', 'rst', ')', '(', '\\n']
Tokenized   (013): ['<s>', 'v', 'types', 'Ġ.', 'ĠIf', 'Ġ(', 'Ġr', 'st', 'Ġ)', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['v', 'types', 'Ġ.', 'ĠIf', 'Ġ(', 'Ġr', 'st', 'Ġ)', 'Ġ(', 'Ġ\\', 'n']
Detokenized (008): ['vtypes', 'Ġ.', 'ĠIf', 'Ġ(', 'Ġrst', 'Ġ)', 'Ġ(', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ports = [ ( , clk ) , ( , update ) , ( , a ) , ( , b ) , ( , c ) ] \n"
Original    (029): ['ports', '=', '[', '(', ',', 'clk', ')', ',', '(', ',', 'update', ')', ',', '(', ',', 'a', ')', ',', '(', ',', 'b', ')', ',', '(', ',', 'c', ')', ']', '\\n']
Tokenized   (033): ['<s>', 'ports', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġupdate', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġc', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['ports', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġupdate', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġc', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (029): ['ports', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġclk', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġupdate', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġc', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "m . Instance ( mult , , ports = ports ) \n"
Original    (012): ['m', '.', 'Instance', '(', 'mult', ',', ',', 'ports', '=', 'ports', ')', '\\n']
Tokenized   (016): ['<s>', 'm', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmult', 'Ġ,', 'Ġ,', 'Ġports', 'Ġ=', 'Ġports', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['m', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmult', 'Ġ,', 'Ġ,', 'Ġports', 'Ġ=', 'Ġports', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['m', 'Ġ.', 'ĠInstance', 'Ġ(', 'Ġmult', 'Ġ,', 'Ġ,', 'Ġports', 'Ġ=', 'Ġports', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "stdout = subprocess . PIPE ) . stdout \n"
Original    (009): ['stdout', '=', 'subprocess', '.', 'PIPE', ')', '.', 'stdout', '\\n']
Tokenized   (017): ['<s>', 'std', 'out', 'Ġ=', 'Ġsub', 'process', 'Ġ.', 'ĠP', 'IP', 'E', 'Ġ)', 'Ġ.', 'Ġstd', 'out', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['std', 'out', 'Ġ=', 'Ġsub', 'process', 'Ġ.', 'ĠP', 'IP', 'E', 'Ġ)', 'Ġ.', 'Ġstd', 'out', 'Ġ\\', 'n']
Detokenized (009): ['stdout', 'Ġ=', 'Ġsubprocess', 'Ġ.', 'ĠPIPE', 'Ġ)', 'Ġ.', 'Ġstdout', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "line = [ l for l in sout ] [ 0 ] \n"
Original    (013): ['line', '=', '[', 'l', 'for', 'l', 'in', 'sout', ']', '[', '0', ']', '\\n']
Tokenized   (017): ['<s>', 'line', 'Ġ=', 'Ġ[', 'Ġl', 'Ġfor', 'Ġl', 'Ġin', 'Ġs', 'out', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['line', 'Ġ=', 'Ġ[', 'Ġl', 'Ġfor', 'Ġl', 'Ġin', 'Ġs', 'out', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['line', 'Ġ=', 'Ġ[', 'Ġl', 'Ġfor', 'Ġl', 'Ġin', 'Ġsout', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "round ( wmean , prec ) , "+-" , round ( wstd , prec ) ) \n"
Original    (017): ['round', '(', 'wmean', ',', 'prec', ')', ',', '"+-"', ',', 'round', '(', 'wstd', ',', 'prec', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'round', 'Ġ(', 'Ġw', 'mean', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ,', 'Ġ"+', '-"', 'Ġ,', 'Ġround', 'Ġ(', 'Ġw', 'std', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['round', 'Ġ(', 'Ġw', 'mean', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ,', 'Ġ"+', '-"', 'Ġ,', 'Ġround', 'Ġ(', 'Ġw', 'std', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['round', 'Ġ(', 'Ġwmean', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ,', 'Ġ"+-"', 'Ġ,', 'Ġround', 'Ġ(', 'Ġwstd', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "size = stop - start ) \n"
Original    (007): ['size', '=', 'stop', '-', 'start', ')', '\\n']
Tokenized   (010): ['<s>', 'size', 'Ġ=', 'Ġstop', 'Ġ-', 'Ġstart', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['size', 'Ġ=', 'Ġstop', 'Ġ-', 'Ġstart', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['size', 'Ġ=', 'Ġstop', 'Ġ-', 'Ġstart', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "rndbase = numpy . random . randint ( self . nrows , size = niter ) \n"
Original    (017): ['rndbase', '=', 'numpy', '.', 'random', '.', 'randint', '(', 'self', '.', 'nrows', ',', 'size', '=', 'niter', ')', '\\n']
Tokenized   (026): ['<s>', 'r', 'nd', 'base', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', 'rows', 'Ġ,', 'Ġsize', 'Ġ=', 'Ġn', 'iter', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['r', 'nd', 'base', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', 'rows', 'Ġ,', 'Ġsize', 'Ġ=', 'Ġn', 'iter', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['rndbase', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġrandint', 'Ġ(', 'Ġself', 'Ġ.', 'Ġnrows', 'Ġ,', 'Ġsize', 'Ġ=', 'Ġniter', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "rng = [ - 1000 , - 1000 ] \n"
Original    (010): ['rng', '=', '[', '-', '1000', ',', '-', '1000', ']', '\\n']
Tokenized   (014): ['<s>', 'r', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġ1000', 'Ġ,', 'Ġ-', 'Ġ1000', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['r', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġ1000', 'Ġ,', 'Ġ-', 'Ġ1000', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['rng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġ1000', 'Ġ,', 'Ġ-', 'Ġ1000', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "benchtime , stones = prof . run ( \n"
Original    (009): ['benchtime', ',', 'stones', '=', 'prof', '.', 'run', '(', '\\n']
Tokenized   (013): ['<s>', 'bench', 'time', 'Ġ,', 'Ġstones', 'Ġ=', 'Ġprof', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['bench', 'time', 'Ġ,', 'Ġstones', 'Ġ=', 'Ġprof', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['benchtime', 'Ġ,', 'Ġstones', 'Ġ=', 'Ġprof', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "db . rng = [ - rng / 2 , rng / 2 ] \n"
Original    (015): ['db', '.', 'rng', '=', '[', '-', 'rng', '/', '2', ',', 'rng', '/', '2', ']', '\\n']
Tokenized   (021): ['<s>', 'db', 'Ġ.', 'Ġr', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['db', 'Ġ.', 'Ġr', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['db', 'Ġ.', 'Ġrng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġrng', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġrng', 'Ġ/', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "MB_ = 1024 * KB_ \n"
Original    (006): ['MB_', '=', '1024', '*', 'KB_', '\\n']
Tokenized   (011): ['<s>', 'MB', '_', 'Ġ=', 'Ġ1024', 'Ġ*', 'ĠKB', '_', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['MB', '_', 'Ġ=', 'Ġ1024', 'Ġ*', 'ĠKB', '_', 'Ġ\\', 'n']
Detokenized (006): ['MB_', 'Ġ=', 'Ġ1024', 'Ġ*', 'ĠKB_', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "markers = [ , , , , , , , , , ] \n"
Original    (014): ['markers', '=', '[', ',', ',', ',', ',', ',', ',', ',', ',', ',', ']', '\\n']
Tokenized   (018): ['<s>', 'mark', 'ers', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['mark', 'ers', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['markers', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "memcpyw = float ( tmp . split ( ) [ 1 ] ) \n"
Original    (014): ['memcpyw', '=', 'float', '(', 'tmp', '.', 'split', '(', ')', '[', '1', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'mem', 'c', 'py', 'w', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġtmp', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['mem', 'c', 'py', 'w', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġtmp', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['memcpyw', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġtmp', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "values [ "memcpyr" ] . append ( memcpyr ) \n"
Original    (010): ['values', '[', '"memcpyr"', ']', '.', 'append', '(', 'memcpyr', ')', '\\n']
Tokenized   (019): ['<s>', 'values', 'Ġ[', 'Ġ"', 'mem', 'cp', 'yr', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġmem', 'cp', 'yr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['values', 'Ġ[', 'Ġ"', 'mem', 'cp', 'yr', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġmem', 'cp', 'yr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['values', 'Ġ[', 'Ġ"memcpyr"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġmemcpyr', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ratio = float ( line . split ( ) [ - 1 ] ) \n"
Original    (015): ['ratio', '=', 'float', '(', 'line', '.', 'split', '(', ')', '[', '-', '1', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'rat', 'io', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġline', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rat', 'io', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġline', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['ratio', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġline', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "xlim ( 0 , xmax ) \n"
Original    (007): ['xlim', '(', '0', ',', 'xmax', ')', '\\n']
Tokenized   (012): ['<s>', 'x', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġx', 'max', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['x', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġx', 'max', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['xlim', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġxmax', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ylim ( 0 , None ) \n"
Original    (007): ['ylim', '(', '0', ',', 'None', ')', '\\n']
Tokenized   (011): ['<s>', 'y', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['y', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['ylim', 'Ġ(', 'Ġ0', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "grid ( True ) \n"
Original    (005): ['grid', '(', 'True', ')', '\\n']
Tokenized   (008): ['<s>', 'grid', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['grid', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['grid', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "legend ( [ p [ 0 ] for p in plots \n"
Original    (012): ['legend', '(', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'plots', '\\n']
Tokenized   (016): ['<s>', 'leg', 'end', 'Ġ(', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġplots', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['leg', 'end', 'Ġ(', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġplots', 'Ġ\\', 'n']
Detokenized (012): ['legend', 'Ġ(', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġplots', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "savefig ( outfile , dpi = 64 ) \n"
Original    (009): ['savefig', '(', 'outfile', ',', 'dpi', '=', '64', ')', '\\n']
Tokenized   (015): ['<s>', 'save', 'fig', 'Ġ(', 'Ġout', 'file', 'Ġ,', 'Ġd', 'pi', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['save', 'fig', 'Ġ(', 'Ġout', 'file', 'Ġ,', 'Ġd', 'pi', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['savefig', 'Ġ(', 'Ġoutfile', 'Ġ,', 'Ġdpi', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "help = , ) \n"
Original    (005): ['help', '=', ',', ')', '\\n']
Tokenized   (008): ['<s>', 'help', 'Ġ=', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['help', 'Ġ=', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['help', 'Ġ=', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "parser . add_option ( , , action = , \n"
Original    (010): ['parser', '.', 'add_option', '(', ',', ',', 'action', '=', ',', '\\n']
Tokenized   (015): ['<s>', 'parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['parser', 'Ġ.', 'Ġadd_option', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "show_plot ( plots , yaxis , legends , gtitle , xmax = int ( options . xmax ) if \n"
Original    (020): ['show_plot', '(', 'plots', ',', 'yaxis', ',', 'legends', ',', 'gtitle', ',', 'xmax', '=', 'int', '(', 'options', '.', 'xmax', ')', 'if', '\\n']
Tokenized   (029): ['<s>', 'show', '_', 'plot', 'Ġ(', 'Ġplots', 'Ġ,', 'Ġy', 'axis', 'Ġ,', 'Ġlegends', 'Ġ,', 'Ġg', 'title', 'Ġ,', 'Ġx', 'max', 'Ġ=', 'Ġint', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġx', 'max', 'Ġ)', 'Ġif', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['show', '_', 'plot', 'Ġ(', 'Ġplots', 'Ġ,', 'Ġy', 'axis', 'Ġ,', 'Ġlegends', 'Ġ,', 'Ġg', 'title', 'Ġ,', 'Ġx', 'max', 'Ġ=', 'Ġint', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġx', 'max', 'Ġ)', 'Ġif', 'Ġ\\', 'n']
Detokenized (020): ['show_plot', 'Ġ(', 'Ġplots', 'Ġ,', 'Ġyaxis', 'Ġ,', 'Ġlegends', 'Ġ,', 'Ġgtitle', 'Ġ,', 'Ġxmax', 'Ġ=', 'Ġint', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġxmax', 'Ġ)', 'Ġif', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "options . xmax else None ) \n"
Original    (007): ['options', '.', 'xmax', 'else', 'None', ')', '\\n']
Tokenized   (011): ['<s>', 'options', 'Ġ.', 'Ġx', 'max', 'Ġelse', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['options', 'Ġ.', 'Ġx', 'max', 'Ġelse', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['options', 'Ġ.', 'Ġxmax', 'Ġelse', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "hdfarray . attrs . object = { "a" : 32.1 , "b" : 1 , "c" : [ 1 , 2 ] } \n"
Original    (024): ['hdfarray', '.', 'attrs', '.', 'object', '=', '{', '"a"', ':', '32.1', ',', '"b"', ':', '1', ',', '"c"', ':', '[', '1', ',', '2', ']', '}', '\\n']
Tokenized   (038): ['<s>', 'h', 'df', 'array', 'Ġ.', 'Ġatt', 'rs', 'Ġ.', 'Ġobject', 'Ġ=', 'Ġ{', 'Ġ"', 'a', '"', 'Ġ:', 'Ġ32', '.', '1', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ:', 'Ġ1', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['h', 'df', 'array', 'Ġ.', 'Ġatt', 'rs', 'Ġ.', 'Ġobject', 'Ġ=', 'Ġ{', 'Ġ"', 'a', '"', 'Ġ:', 'Ġ32', '.', '1', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ:', 'Ġ1', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ}', 'Ġ\\', 'n']
Detokenized (024): ['hdfarray', 'Ġ.', 'Ġattrs', 'Ġ.', 'Ġobject', 'Ġ=', 'Ġ{', 'Ġ"a"', 'Ġ:', 'Ġ32.1', 'Ġ,', 'Ġ"b"', 'Ġ:', 'Ġ1', 'Ġ,', 'Ġ"c"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ}', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "addr = hex ( id ( self ) ) \n"
Original    (010): ['addr', '=', 'hex', '(', 'id', '(', 'self', ')', ')', '\\n']
Tokenized   (013): ['<s>', 'addr', 'Ġ=', 'Ġhex', 'Ġ(', 'Ġid', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['addr', 'Ġ=', 'Ġhex', 'Ġ(', 'Ġid', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['addr', 'Ġ=', 'Ġhex', 'Ġ(', 'Ġid', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "node_manager . registry . pop ( pathname , None ) \n"
Original    (011): ['node_manager', '.', 'registry', '.', 'pop', '(', 'pathname', ',', 'None', ')', '\\n']
Tokenized   (017): ['<s>', 'node', '_', 'manager', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġpath', 'name', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['node', '_', 'manager', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġpath', 'name', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['node_manager', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġpathname', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "oldpathname , self . _v_pathname ) \n"
Original    (007): ['oldpathname', ',', 'self', '.', '_v_pathname', ')', '\\n']
Tokenized   (016): ['<s>', 'old', 'path', 'name', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['old', 'path', 'name', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['oldpathname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_v_pathname', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "recursive = False , _log = False , ** kwargs ) \n"
Original    (012): ['recursive', '=', 'False', ',', '_log', '=', 'False', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (019): ['<s>', 'rec', 'ursive', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ_', 'log', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rec', 'ursive', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ_', 'log', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['recursive', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ_log', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "% node . _v_pathname ) \n"
Original    (006): ['%', 'node', '.', '_v_pathname', ')', '\\n']
Tokenized   (013): ['<s>', '%', 'Ġnode', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['%', 'Ġnode', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['%', 'Ġnode', 'Ġ.', 'Ġ_v_pathname', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "or pathname . startswith ( mypathname + ) ) : \n"
Original    (011): ['or', 'pathname', '.', 'startswith', '(', 'mypathname', '+', ')', ')', ':', '\\n']
Tokenized   (019): ['<s>', 'or', 'Ġpath', 'name', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġmy', 'path', 'name', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['or', 'Ġpath', 'name', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġmy', 'path', 'name', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (011): ['or', 'Ġpathname', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġmypathname', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "newarr = self . h5file . create_array ( , , [ 1 ] ) \n"
Original    (015): ['newarr', '=', 'self', '.', 'h5file', '.', 'create_array', '(', ',', ',', '[', '1', ']', ')', '\\n']
Tokenized   (023): ['<s>', 'new', 'arr', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcreate', '_', 'array', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['new', 'arr', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcreate', '_', 'array', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['newarr', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ.', 'Ġcreate_array', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "with self . assertRaises ( tables . UndoRedoError ) : \n"
Original    (011): ['with', 'self', '.', 'assertRaises', '(', 'tables', '.', 'UndoRedoError', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'with', 'Ġself', 'Ġ.', 'Ġassert', 'Ra', 'ises', 'Ġ(', 'Ġtables', 'Ġ.', 'ĠUnd', 'o', 'Red', 'o', 'Error', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['with', 'Ġself', 'Ġ.', 'Ġassert', 'Ra', 'ises', 'Ġ(', 'Ġtables', 'Ġ.', 'ĠUnd', 'o', 'Red', 'o', 'Error', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (011): ['with', 'Ġself', 'Ġ.', 'ĠassertRaises', 'Ġ(', 'Ġtables', 'Ġ.', 'ĠUndoRedoError', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""/othergroup1/othergroup2/othergroup3" not in self . h5file ) \n"
Original    (008): ['"/othergroup1/othergroup2/othergroup3"', 'not', 'in', 'self', '.', 'h5file', ')', '\\n']
Tokenized   (026): ['<s>', '"', '/', 'other', 'group', '1', '/', 'other', 'group', '2', '/', 'other', 'group', '3', '"', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', '/', 'other', 'group', '1', '/', 'other', 'group', '2', '/', 'other', 'group', '3', '"', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['"/othergroup1/othergroup2/othergroup3"', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "var2 = BoolCol ( dflt = 0 , pos = 2 ) \n"
Original    (013): ['var2', '=', 'BoolCol', '(', 'dflt', '=', '0', ',', 'pos', '=', '2', ')', '\\n']
Tokenized   (020): ['<s>', 'var', '2', 'Ġ=', 'ĠB', 'ool', 'Col', 'Ġ(', 'Ġdf', 'lt', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġpos', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['var', '2', 'Ġ=', 'ĠB', 'ool', 'Col', 'Ġ(', 'Ġdf', 'lt', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġpos', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['var2', 'Ġ=', 'ĠBoolCol', 'Ġ(', 'Ġdflt', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġpos', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "None , nrows ) \n"
Original    (005): ['None', ',', 'nrows', ')', '\\n']
Tokenized   (009): ['<s>', 'None', 'Ġ,', 'Ġn', 'rows', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['None', 'Ġ,', 'Ġn', 'rows', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['None', 'Ġ,', 'Ġnrows', 'Ġ)', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "populateTable ( self . h5file . root , ) \n"
Original    (010): ['populateTable', '(', 'self', '.', 'h5file', '.', 'root', ',', ')', '\\n']
Tokenized   (017): ['<s>', 'pop', 'ulate', 'Table', 'Ġ(', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġroot', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['pop', 'ulate', 'Table', 'Ġ(', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġroot', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['populateTable', 'Ġ(', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ.', 'Ġroot', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "new_node = self . h5file . copy_children ( \n"
Original    (009): ['new_node', '=', 'self', '.', 'h5file', '.', 'copy_children', '(', '\\n']
Tokenized   (018): ['<s>', 'new', '_', 'node', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcopy', '_', 'children', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['new', '_', 'node', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcopy', '_', 'children', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['new_node', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ.', 'Ġcopy_children', 'Ġ(', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ", , recursive = 1 ) \n"
Original    (007): [',', ',', 'recursive', '=', '1', ')', '\\n']
Tokenized   (010): ['<s>', ',', 'Ġ,', 'Ġrecursive', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): [',', 'Ġ,', 'Ġrecursive', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): [',', 'Ġ,', 'Ġrecursive', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "setattr ( attrs , , 11 ) \n"
Original    (008): ['setattr', '(', 'attrs', ',', ',', '11', ')', '\\n']
Tokenized   (013): ['<s>', 'set', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ,', 'Ġ11', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['set', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ,', 'Ġ11', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['setattr', 'Ġ(', 'Ġattrs', 'Ġ,', 'Ġ,', 'Ġ11', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "delattr ( attrs , ) \n"
Original    (006): ['delattr', '(', 'attrs', ',', ')', '\\n']
Tokenized   (011): ['<s>', 'del', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['del', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['delattr', 'Ġ(', 'Ġattrs', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "arr . _v_attrs . foo = \n"
Original    (007): ['arr', '.', '_v_attrs', '.', 'foo', '=', '\\n']
Tokenized   (014): ['<s>', 'arr', 'Ġ.', 'Ġ_', 'v', '_', 'att', 'rs', 'Ġ.', 'Ġfoo', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['arr', 'Ġ.', 'Ġ_', 'v', '_', 'att', 'rs', 'Ġ.', 'Ġfoo', 'Ġ=', 'Ġ\\', 'n']
Detokenized (007): ['arr', 'Ġ.', 'Ġ_v_attrs', 'Ġ.', 'Ġfoo', 'Ġ=', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "assert response . header ( ) == \n"
Original    (008): ['assert', 'response', '.', 'header', '(', ')', '==', '\\n']
Tokenized   (011): ['<s>', 'assert', 'Ġresponse', 'Ġ.', 'Ġheader', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['assert', 'Ġresponse', 'Ġ.', 'Ġheader', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġ\\', 'n']
Detokenized (008): ['assert', 'Ġresponse', 'Ġ.', 'Ġheader', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "CHANGES = open ( os . path . join ( here , ) , encoding = "utf-8" ) . read ( ) \n"
Original    (023): ['CHANGES', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ',', 'encoding', '=', '"utf-8"', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (032): ['<s>', 'CH', 'ANG', 'ES', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ=', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['CH', 'ANG', 'ES', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ=', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['CHANGES', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ=', 'Ġ"utf-8"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "tests_require = requires + [ ] , \n"
Original    (008): ['tests_require', '=', 'requires', '+', '[', ']', ',', '\\n']
Tokenized   (013): ['<s>', 'tests', '_', 'require', 'Ġ=', 'Ġrequires', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['tests', '_', 'require', 'Ġ=', 'Ġrequires', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['tests_require', 'Ġ=', 'Ġrequires', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "user_id = Column ( Integer , primary_key = True ) \n"
Original    (011): ['user_id', '=', 'Column', '(', 'Integer', ',', 'primary_key', '=', 'True', ')', '\\n']
Tokenized   (018): ['<s>', 'user', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['user', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['user_id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġprimary_key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "username = Column ( Unicode ( 20 ) , unique = True ) \n"
Original    (014): ['username', '=', 'Column', '(', 'Unicode', '(', '20', ')', ',', 'unique', '=', 'True', ')', '\\n']
Tokenized   (017): ['<s>', 'username', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ20', 'Ġ)', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['username', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ20', 'Ġ)', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['username', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ20', 'Ġ)', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "hits = Column ( Integer , default = 0 ) \n"
Original    (011): ['hits', '=', 'Column', '(', 'Integer', ',', 'default', '=', '0', ')', '\\n']
Tokenized   (015): ['<s>', 'h', 'its', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['h', 'its', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['hits', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_password = Column ( , Unicode ( 60 ) ) \n"
Original    (011): ['_password', '=', 'Column', '(', ',', 'Unicode', '(', '60', ')', ')', '\\n']
Tokenized   (015): ['<s>', '_', 'password', 'Ġ=', 'ĠColumn', 'Ġ(', 'Ġ,', 'ĠUnicode', 'Ġ(', 'Ġ60', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['_', 'password', 'Ġ=', 'ĠColumn', 'Ġ(', 'Ġ,', 'ĠUnicode', 'Ġ(', 'Ġ60', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_password', 'Ġ=', 'ĠColumn', 'Ġ(', 'Ġ,', 'ĠUnicode', 'Ġ(', 'Ġ60', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Column ( , Integer , ForeignKey ( ) ) \n"
Original    (010): ['Column', '(', ',', 'Integer', ',', 'ForeignKey', '(', ')', ')', '\\n']
Tokenized   (014): ['<s>', 'Column', 'Ġ(', 'Ġ,', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Column', 'Ġ(', 'Ġ,', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['Column', 'Ġ(', 'Ġ,', 'ĠInteger', 'Ġ,', 'ĠForeignKey', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "target_id = Column ( Integer , ForeignKey ( ) ) \n"
Original    (011): ['target_id', '=', 'Column', '(', 'Integer', ',', 'ForeignKey', '(', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'target', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['target', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['target_id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'ĠForeignKey', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "comments = relation ( , cascade = "delete" , \n"
Original    (010): ['comments', '=', 'relation', '(', ',', 'cascade', '=', '"delete"', ',', '\\n']
Tokenized   (015): ['<s>', 'comments', 'Ġ=', 'Ġrelation', 'Ġ(', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['comments', 'Ġ=', 'Ġrelation', 'Ġ(', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['comments', 'Ġ=', 'Ġrelation', 'Ġ(', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"delete"', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "author = relation ( User , cascade = "delete" , backref = ) \n"
Original    (014): ['author', '=', 'relation', '(', 'User', ',', 'cascade', '=', '"delete"', ',', 'backref', '=', ')', '\\n']
Tokenized   (020): ['<s>', 'author', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['author', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['author', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"delete"', 'Ġ,', 'Ġbackref', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "tags = relation ( Tag , secondary = ideas_tags , backref = ) \n"
Original    (014): ['tags', '=', 'relation', '(', 'Tag', ',', 'secondary', '=', 'ideas_tags', ',', 'backref', '=', ')', '\\n']
Tokenized   (020): ['<s>', 'tags', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠTag', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġideas', '_', 'tags', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['tags', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠTag', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġideas', '_', 'tags', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['tags', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠTag', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġideas_tags', 'Ġ,', 'Ġbackref', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "voted_users = relation ( User , secondary = voted_users , lazy = , \n"
Original    (014): ['voted_users', '=', 'relation', '(', 'User', ',', 'secondary', '=', 'voted_users', ',', 'lazy', '=', ',', '\\n']
Tokenized   (022): ['<s>', 'v', 'oted', '_', 'users', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġvoted', '_', 'users', 'Ġ,', 'Ġlazy', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['v', 'oted', '_', 'users', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġvoted', '_', 'users', 'Ġ,', 'Ġlazy', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['voted_users', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġvoted_users', 'Ġ,', 'Ġlazy', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "total_votes = column_property ( ( hits + misses ) . label ( ) ) \n"
Original    (015): ['total_votes', '=', 'column_property', '(', '(', 'hits', '+', 'misses', ')', '.', 'label', '(', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'total', '_', 'votes', 'Ġ=', 'Ġcolumn', '_', 'property', 'Ġ(', 'Ġ(', 'Ġhits', 'Ġ+', 'Ġmisses', 'Ġ)', 'Ġ.', 'Ġlabel', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['total', '_', 'votes', 'Ġ=', 'Ġcolumn', '_', 'property', 'Ġ(', 'Ġ(', 'Ġhits', 'Ġ+', 'Ġmisses', 'Ġ)', 'Ġ.', 'Ġlabel', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['total_votes', 'Ġ=', 'Ġcolumn_property', 'Ġ(', 'Ġ(', 'Ġhits', 'Ġ+', 'Ġmisses', 'Ġ)', 'Ġ.', 'Ġlabel', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "query = query . filter ( cls . target == None ) . order_by ( order_by ) \n"
Original    (018): ['query', '=', 'query', '.', 'filter', '(', 'cls', '.', 'target', '==', 'None', ')', '.', 'order_by', '(', 'order_by', ')', '\\n']
Tokenized   (026): ['<s>', 'query', 'Ġ=', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġtarget', 'Ġ==', 'ĠNone', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġorder', '_', 'by', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['query', 'Ġ=', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġtarget', 'Ġ==', 'ĠNone', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġorder', '_', 'by', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['query', 'Ġ=', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġcls', 'Ġ.', 'Ġtarget', 'Ġ==', 'ĠNone', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġorder_by', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "mock_get_auditlog . side_effect = lambda c : auditlog \n"
Original    (009): ['mock_get_auditlog', '.', 'side_effect', '=', 'lambda', 'c', ':', 'auditlog', '\\n']
Tokenized   (022): ['<s>', 'm', 'ock', '_', 'get', '_', 'aud', 'it', 'log', 'Ġ.', 'Ġside', '_', 'effect', 'Ġ=', 'Ġlambda', 'Ġc', 'Ġ:', 'Ġaudit', 'log', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['m', 'ock', '_', 'get', '_', 'aud', 'it', 'log', 'Ġ.', 'Ġside', '_', 'effect', 'Ġ=', 'Ġlambda', 'Ġc', 'Ġ:', 'Ġaudit', 'log', 'Ġ\\', 'n']
Detokenized (009): ['mock_get_auditlog', 'Ġ.', 'Ġside_effect', 'Ġ=', 'Ġlambda', 'Ġc', 'Ġ:', 'Ġauditlog', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "json . loads ( entry [ 2 ] . payload ) , \n"
Original    (013): ['json', '.', 'loads', '(', 'entry', '[', '2', ']', '.', 'payload', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'json', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġentry', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġpayload', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['json', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġentry', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġpayload', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['json', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġentry', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġpayload', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : ": 5 \n"
Original    (003): [':', '5', '\\n']
Tokenized   (006): ['<s>', ':', 'Ġ5', 'Ġ\\', 'n', '</s>']
Filtered   (004): [':', 'Ġ5', 'Ġ\\', 'n']
Detokenized (003): [':', 'Ġ5', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "registry . content = DummyContentRegistry ( ) \n"
Original    (008): ['registry', '.', 'content', '=', 'DummyContentRegistry', '(', ')', '\\n']
Tokenized   (016): ['<s>', 'reg', 'istry', 'Ġ.', 'Ġcontent', 'Ġ=', 'ĠD', 'ummy', 'Content', 'Reg', 'istry', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['reg', 'istry', 'Ġ.', 'Ġcontent', 'Ġ=', 'ĠD', 'ummy', 'Content', 'Reg', 'istry', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['registry', 'Ġ.', 'Ġcontent', 'Ġ=', 'ĠDummyContentRegistry', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ep = DummyFunction ( True ) \n"
Original    (007): ['ep', '=', 'DummyFunction', '(', 'True', ')', '\\n']
Tokenized   (012): ['<s>', 'ep', 'Ġ=', 'ĠD', 'ummy', 'Function', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['ep', 'Ġ=', 'ĠD', 'ummy', 'Function', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['ep', 'Ġ=', 'ĠDummyFunction', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "name_node . validator ( node [ ] , filename ) \n"
Original    (011): ['name_node', '.', 'validator', '(', 'node', '[', ']', ',', 'filename', ')', '\\n']
Tokenized   (017): ['<s>', 'name', '_', 'node', 'Ġ.', 'Ġvalid', 'ator', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['name', '_', 'node', 'Ġ.', 'Ġvalid', 'ator', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['name_node', 'Ġ.', 'Ġvalidator', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "schema [ ] . missing = colander . null \n"
Original    (010): ['schema', '[', ']', '.', 'missing', '=', 'colander', '.', 'null', '\\n']
Tokenized   (015): ['<s>', 'sche', 'ma', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmissing', 'Ġ=', 'Ġcol', 'ander', 'Ġ.', 'Ġnull', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['sche', 'ma', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmissing', 'Ġ=', 'Ġcol', 'ander', 'Ġ.', 'Ġnull', 'Ġ\\', 'n']
Detokenized (010): ['schema', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmissing', 'Ġ=', 'Ġcolander', 'Ġ.', 'Ġnull', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "title = appstruct [ ] or None \n"
Original    (008): ['title', '=', 'appstruct', '[', ']', 'or', 'None', '\\n']
Tokenized   (012): ['<s>', 'title', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['title', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n']
Detokenized (008): ['title', 'Ġ=', 'Ġappstruct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mimetype = appstruct [ ] or USE_MAGIC \n"
Original    (008): ['mimetype', '=', 'appstruct', '[', ']', 'or', 'USE_MAGIC', '\\n']
Tokenized   (018): ['<s>', 'm', 'im', 'ety', 'pe', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠUSE', '_', 'MAG', 'IC', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['m', 'im', 'ety', 'pe', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠUSE', '_', 'MAG', 'IC', 'Ġ\\', 'n']
Detokenized (008): ['mimetype', 'Ġ=', 'Ġappstruct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠUSE_MAGIC', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "filedata = tempstore . get ( uid , { } ) \n"
Original    (012): ['filedata', '=', 'tempstore', '.', 'get', '(', 'uid', ',', '{', '}', ')', '\\n']
Tokenized   (019): ['<s>', 'f', 'iled', 'ata', 'Ġ=', 'Ġtemp', 'store', 'Ġ.', 'Ġget', 'Ġ(', 'Ġu', 'id', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['f', 'iled', 'ata', 'Ġ=', 'Ġtemp', 'store', 'Ġ.', 'Ġget', 'Ġ(', 'Ġu', 'id', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['filedata', 'Ġ=', 'Ġtempstore', 'Ġ.', 'Ġget', 'Ġ(', 'Ġuid', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "resource1 . __acl__ = [ ( None , , None ) , ( None , 1 , None ) ] \n"
Original    (021): ['resource1', '.', '__acl__', '=', '[', '(', 'None', ',', ',', 'None', ')', ',', '(', 'None', ',', '1', ',', 'None', ')', ']', '\\n']
Tokenized   (027): ['<s>', 'resource', '1', 'Ġ.', 'Ġ__', 'acl', '__', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['resource', '1', 'Ġ.', 'Ġ__', 'acl', '__', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['resource1', 'Ġ.', 'Ġ__acl__', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "new_acl = [ ( None , , None ) , ( None , 1 , None ) ] , \n"
Original    (020): ['new_acl', '=', '[', '(', 'None', ',', ',', 'None', ')', ',', '(', 'None', ',', '1', ',', 'None', ')', ']', ',', '\\n']
Tokenized   (025): ['<s>', 'new', '_', 'acl', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', '_', 'acl', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['new_acl', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "request . registry . notify ( LoggedIn ( login , user , context , request ) ) \n"
Original    (018): ['request', '.', 'registry', '.', 'notify', '(', 'LoggedIn', '(', 'login', ',', 'user', ',', 'context', ',', 'request', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'request', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġnotify', 'Ġ(', 'ĠLogged', 'In', 'Ġ(', 'Ġlogin', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġcontext', 'Ġ,', 'Ġrequest', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['request', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġnotify', 'Ġ(', 'ĠLogged', 'In', 'Ġ(', 'Ġlogin', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġcontext', 'Ġ,', 'Ġrequest', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['request', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġnotify', 'Ġ(', 'ĠLoggedIn', 'Ġ(', 'Ġlogin', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġcontext', 'Ġ,', 'Ġrequest', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "dirname , filename = os . path . split ( context . path ) \n"
Original    (015): ['dirname', ',', 'filename', '=', 'os', '.', 'path', '.', 'split', '(', 'context', '.', 'path', ')', '\\n']
Tokenized   (019): ['<s>', 'dir', 'name', 'Ġ,', 'Ġfilename', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['dir', 'name', 'Ġ,', 'Ġfilename', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['dirname', 'Ġ,', 'Ġfilename', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "response . content_type = mt or \n"
Original    (007): ['response', '.', 'content_type', '=', 'mt', 'or', '\\n']
Tokenized   (012): ['<s>', 'response', 'Ġ.', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġmt', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['response', 'Ġ.', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġmt', 'Ġor', 'Ġ\\', 'n']
Detokenized (007): ['response', 'Ġ.', 'Ġcontent_type', 'Ġ=', 'Ġmt', 'Ġor', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "getattr ( SkipCase ( ) , ) ) \n"
Original    (009): ['getattr', '(', 'SkipCase', '(', ')', ',', ')', ')', '\\n']
Tokenized   (014): ['<s>', 'get', 'attr', 'Ġ(', 'ĠSkip', 'Case', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['get', 'attr', 'Ġ(', 'ĠSkip', 'Case', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['getattr', 'Ġ(', 'ĠSkipCase', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "iterator . __class__ . __name__ ) ) \n"
Original    (008): ['iterator', '.', '__class__', '.', '__name__', ')', ')', '\\n']
Tokenized   (015): ['<s>', 'iterator', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['iterator', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['iterator', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "parts = super ( newbytes , self ) . splitlines ( keepends ) \n"
Original    (014): ['parts', '=', 'super', '(', 'newbytes', ',', 'self', ')', '.', 'splitlines', '(', 'keepends', ')', '\\n']
Tokenized   (020): ['<s>', 'parts', 'Ġ=', 'Ġsuper', 'Ġ(', 'Ġnew', 'bytes', 'Ġ,', 'Ġself', 'Ġ)', 'Ġ.', 'Ġsplit', 'lines', 'Ġ(', 'Ġkeep', 'ends', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['parts', 'Ġ=', 'Ġsuper', 'Ġ(', 'Ġnew', 'bytes', 'Ġ,', 'Ġself', 'Ġ)', 'Ġ.', 'Ġsplit', 'lines', 'Ġ(', 'Ġkeep', 'ends', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['parts', 'Ġ=', 'Ġsuper', 'Ġ(', 'Ġnewbytes', 'Ġ,', 'Ġself', 'Ġ)', 'Ġ.', 'Ġsplitlines', 'Ġ(', 'Ġkeepends', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pos = self . rfind ( sub , * args ) \n"
Original    (012): ['pos', '=', 'self', '.', 'rfind', '(', 'sub', ',', '*', 'args', ')', '\\n']
Tokenized   (016): ['<s>', 'pos', 'Ġ=', 'Ġself', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġsub', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['pos', 'Ġ=', 'Ġself', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġsub', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['pos', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrfind', 'Ġ(', 'Ġsub', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "replaced_builtins = . split ( ) \n"
Original    (007): ['replaced_builtins', '=', '.', 'split', '(', ')', '\\n']
Tokenized   (014): ['<s>', 're', 'placed', '_', 'built', 'ins', 'Ġ=', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['re', 'placed', '_', 'built', 'ins', 'Ġ=', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['replaced_builtins', 'Ġ=', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "expression = . join ( [ "name=\'{0}\'" . format ( name ) for name in replaced_builtins ] ) \n"
Original    (019): ['expression', '=', '.', 'join', '(', '[', '"name=\\\'{0}\\\'"', '.', 'format', '(', 'name', ')', 'for', 'name', 'in', 'replaced_builtins', ']', ')', '\\n']
Tokenized   (032): ['<s>', 'expression', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ"', 'name', '=', "\\'", '{', '0', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ)', 'Ġfor', 'Ġname', 'Ġin', 'Ġreplaced', '_', 'built', 'ins', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['expression', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ"', 'name', '=', "\\'", '{', '0', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ)', 'Ġfor', 'Ġname', 'Ġin', 'Ġreplaced', '_', 'built', 'ins', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['expression', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ"name=\\\'{0}\\\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ)', 'Ġfor', 'Ġname', 'Ġin', 'Ġreplaced_builtins', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "touch_import_top ( , name . value , node ) \n"
Original    (010): ['touch_import_top', '(', ',', 'name', '.', 'value', ',', 'node', ')', '\\n']
Tokenized   (017): ['<s>', 'touch', '_', 'import', '_', 'top', 'Ġ(', 'Ġ,', 'Ġname', 'Ġ.', 'Ġvalue', 'Ġ,', 'Ġnode', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['touch', '_', 'import', '_', 'top', 'Ġ(', 'Ġ,', 'Ġname', 'Ġ.', 'Ġvalue', 'Ġ,', 'Ġnode', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['touch_import_top', 'Ġ(', 'Ġ,', 'Ġname', 'Ġ.', 'Ġvalue', 'Ġ,', 'Ġnode', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "retcode = main ( [ self . textfilename ] ) \n"
Original    (011): ['retcode', '=', 'main', '(', '[', 'self', '.', 'textfilename', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'ret', 'code', 'Ġ=', 'Ġmain', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġtext', 'filename', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['ret', 'code', 'Ġ=', 'Ġmain', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġtext', 'filename', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['retcode', 'Ġ=', 'Ġmain', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġtextfilename', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "v = self . visit ( node . values [ i ] ) \n"
Original    (014): ['v', '=', 'self', '.', 'visit', '(', 'node', '.', 'values', '[', 'i', ']', ')', '\\n']
Tokenized   (017): ['<s>', 'v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġvalues', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġvalues', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġvalues', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "props . update ( self . _class_props [ p ] ) \n"
Original    (012): ['props', '.', 'update', '(', 'self', '.', '_class_props', '[', 'p', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'pro', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'class', '_', 'pro', 'ps', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['pro', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'class', '_', 'pro', 'ps', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['props', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_class_props', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "kwargs_init = [ % ( x . split ( ) [ 0 ] , x . split ( ) [ 0 ] ) for x in kwargs ] \n"
Original    (029): ['kwargs_init', '=', '[', '%', '(', 'x', '.', 'split', '(', ')', '[', '0', ']', ',', 'x', '.', 'split', '(', ')', '[', '0', ']', ')', 'for', 'x', 'in', 'kwargs', ']', '\\n']
Tokenized   (037): ['<s>', 'kw', 'args', '_', 'init', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġk', 'w', 'args', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['kw', 'args', '_', 'init', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġk', 'w', 'args', 'Ġ]', 'Ġ\\', 'n']
Detokenized (029): ['kwargs_init', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġkwargs', 'Ġ]', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "else : nargs = node . args . args \n"
Original    (010): ['else', ':', 'nargs', '=', 'node', '.', 'args', '.', 'args', '\\n']
Tokenized   (014): ['<s>', 'else', 'Ġ:', 'Ġn', 'args', 'Ġ=', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['else', 'Ġ:', 'Ġn', 'args', 'Ġ=', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ\\', 'n']
Detokenized (010): ['else', 'Ġ:', 'Ġnargs', 'Ġ=', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "kwargs . append ( % ( a , default_value ) ) \n"
Original    (012): ['kwargs', '.', 'append', '(', '%', '(', 'a', ',', 'default_value', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'kw', 'args', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġa', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['kw', 'args', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġa', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['kwargs', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġa', 'Ġ,', 'Ġdefault_value', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "offset = len ( node . args . args ) - len ( node . args . defaults ) \n"
Original    (020): ['offset', '=', 'len', '(', 'node', '.', 'args', '.', 'args', ')', '-', 'len', '(', 'node', '.', 'args', '.', 'defaults', ')', '\\n']
Tokenized   (023): ['<s>', 'offset', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġdefaults', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['offset', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġdefaults', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['offset', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġdefaults', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "varargs = [ % n for n in range ( 16 ) ] \n"
Original    (014): ['varargs', '=', '[', '%', 'n', 'for', 'n', 'in', 'range', '(', '16', ')', ']', '\\n']
Tokenized   (018): ['<s>', 'var', 'args', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġn', 'Ġfor', 'Ġn', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ16', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['var', 'args', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġn', 'Ġfor', 'Ġn', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ16', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['varargs', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġn', 'Ġfor', 'Ġn', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ16', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "buffer += % self . indent ( ) \n"
Original    (009): ['buffer', '+=', '%', 'self', '.', 'indent', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'buffer', 'Ġ+=', 'Ġ%', 'Ġself', 'Ġ.', 'Ġindent', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['buffer', 'Ġ+=', 'Ġ%', 'Ġself', 'Ġ.', 'Ġindent', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['buffer', 'Ġ+=', 'Ġ%', 'Ġself', 'Ġ.', 'Ġindent', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "arg_name = args = None \n"
Original    (006): ['arg_name', '=', 'args', '=', 'None', '\\n']
Tokenized   (011): ['<s>', 'arg', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['arg', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ\\', 'n']
Detokenized (006): ['arg_name', 'Ġ=', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "comp . append ( self . visit ( node . comparators [ i ] ) ) \n"
Original    (017): ['comp', '.', 'append', '(', 'self', '.', 'visit', '(', 'node', '.', 'comparators', '[', 'i', ']', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'comp', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġcompar', 'ators', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['comp', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġcompar', 'ators', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['comp', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġcomparators', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "testtime = time ( ) - starttime \n"
Original    (008): ['testtime', '=', 'time', '(', ')', '-', 'starttime', '\\n']
Tokenized   (013): ['<s>', 'test', 'time', 'Ġ=', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġstart', 'time', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['test', 'time', 'Ġ=', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġstart', 'time', 'Ġ\\', 'n']
Detokenized (008): ['testtime', 'Ġ=', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġstarttime', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "primes_per_sec = len ( seq ) * ( 1.0 / testtime ) \n"
Original    (013): ['primes_per_sec', '=', 'len', '(', 'seq', ')', '*', '(', '1.0', '/', 'testtime', ')', '\\n']
Tokenized   (024): ['<s>', 'pr', 'imes', '_', 'per', '_', 'sec', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġseq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġtest', 'time', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['pr', 'imes', '_', 'per', '_', 'sec', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġseq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġtest', 'time', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['primes_per_sec', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġseq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1.0', 'Ġ/', 'Ġtesttime', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "b = range ( 1 , 10 ) \n"
Original    (009): ['b', '=', 'range', '(', '1', ',', '10', ')', '\\n']
Tokenized   (012): ['<s>', 'b', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['b', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['b', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "w1 = threading . start_webworker ( worker , ( seq , , ) ) \n"
Original    (015): ['w1', '=', 'threading', '.', 'start_webworker', '(', 'worker', ',', '(', 'seq', ',', ',', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'w', '1', 'Ġ=', 'Ġthread', 'ing', 'Ġ.', 'Ġstart', '_', 'web', 'worker', 'Ġ(', 'Ġworker', 'Ġ,', 'Ġ(', 'Ġseq', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['w', '1', 'Ġ=', 'Ġthread', 'ing', 'Ġ.', 'Ġstart', '_', 'web', 'worker', 'Ġ(', 'Ġworker', 'Ġ,', 'Ġ(', 'Ġseq', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['w1', 'Ġ=', 'Ġthreading', 'Ġ.', 'Ġstart_webworker', 'Ġ(', 'Ġworker', 'Ġ,', 'Ġ(', 'Ġseq', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "TestError ( in seq ) \n"
Original    (006): ['TestError', '(', 'in', 'seq', ')', '\\n']
Tokenized   (010): ['<s>', 'Test', 'Error', 'Ġ(', 'Ġin', 'Ġseq', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Test', 'Error', 'Ġ(', 'Ġin', 'Ġseq', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['TestError', 'Ġ(', 'Ġin', 'Ġseq', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "del self . face_groups [ : ] \n"
Original    (008): ['del', 'self', '.', 'face_groups', '[', ':', ']', '\\n']
Tokenized   (013): ['<s>', 'del', 'Ġself', 'Ġ.', 'Ġface', '_', 'groups', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['del', 'Ġself', 'Ġ.', 'Ġface', '_', 'groups', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['del', 'Ġself', 'Ġ.', 'Ġface_groups', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mtllib_path = os . path . join ( model_path , data [ 0 ] ) \n"
Original    (016): ['mtllib_path', '=', 'os', '.', 'path', '.', 'join', '(', 'model_path', ',', 'data', '[', '0', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'mt', 'll', 'ib', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġmodel', '_', 'path', 'Ġ,', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['mt', 'll', 'ib', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġmodel', '_', 'path', 'Ġ,', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['mtllib_path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġmodel_path', 'Ġ,', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "vertex = ( float ( x ) , float ( y ) , float ( z ) ) \n"
Original    (019): ['vertex', '=', '(', 'float', '(', 'x', ')', ',', 'float', '(', 'y', ')', ',', 'float', '(', 'z', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'ver', 'tex', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġz', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['ver', 'tex', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġz', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['vertex', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġz', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "tex_coord = ( float ( s ) , float ( t ) ) \n"
Original    (014): ['tex_coord', '=', '(', 'float', '(', 's', ')', ',', 'float', '(', 't', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'tex', '_', 'coord', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġt', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['tex', '_', 'coord', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġt', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['tex_coord', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġt', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "indices = ( int ( vi ) - 1 , int ( ti ) - 1 , int ( ni ) - 1 ) \n"
Original    (025): ['indices', '=', '(', 'int', '(', 'vi', ')', '-', '1', ',', 'int', '(', 'ti', ')', '-', '1', ',', 'int', '(', 'ni', ')', '-', '1', ')', '\\n']
Tokenized   (029): ['<s>', 'ind', 'ices', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġvi', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġti', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġni', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['ind', 'ices', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġvi', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġti', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġni', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['indices', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġvi', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġti', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġni', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "glBindTexture ( GL_TEXTURE_2D , material . texture_id ) \n"
Original    (009): ['glBindTexture', '(', 'GL_TEXTURE_2D', ',', 'material', '.', 'texture_id', ')', '\\n']
Tokenized   (021): ['<s>', 'gl', 'Bind', 'Texture', 'Ġ(', 'ĠGL', '_', 'TEXTURE', '_', '2', 'D', 'Ġ,', 'Ġmaterial', 'Ġ.', 'Ġtexture', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['gl', 'Bind', 'Texture', 'Ġ(', 'ĠGL', '_', 'TEXTURE', '_', '2', 'D', 'Ġ,', 'Ġmaterial', 'Ġ.', 'Ġtexture', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['glBindTexture', 'Ġ(', 'ĠGL_TEXTURE_2D', 'Ġ,', 'Ġmaterial', 'Ġ.', 'Ġtexture_id', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "glPixelStorei ( GL_UNPACK_ALIGNMENT , 1 ) \n"
Original    (007): ['glPixelStorei', '(', 'GL_UNPACK_ALIGNMENT', ',', '1', ')', '\\n']
Tokenized   (021): ['<s>', 'gl', 'Pixel', 'Store', 'i', 'Ġ(', 'ĠGL', '_', 'UN', 'P', 'ACK', '_', 'AL', 'IGN', 'MENT', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['gl', 'Pixel', 'Store', 'i', 'Ġ(', 'ĠGL', '_', 'UN', 'P', 'ACK', '_', 'AL', 'IGN', 'MENT', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['glPixelStorei', 'Ġ(', 'ĠGL_UNPACK_ALIGNMENT', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "glNormal3fv ( normals [ ni ] ) \n"
Original    (008): ['glNormal3fv', '(', 'normals', '[', 'ni', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'gl', 'Normal', '3', 'f', 'v', 'Ġ(', 'Ġnorm', 'als', 'Ġ[', 'Ġni', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['gl', 'Normal', '3', 'f', 'v', 'Ġ(', 'Ġnorm', 'als', 'Ġ[', 'Ġni', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['glNormal3fv', 'Ġ(', 'Ġnormals', 'Ġ[', 'Ġni', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "picture = pygame . image . load ( picture_file ) . convert ( ) \n"
Original    (015): ['picture', '=', 'pygame', '.', 'image', '.', 'load', '(', 'picture_file', ')', '.', 'convert', '(', ')', '\\n']
Tokenized   (021): ['<s>', 'picture', 'Ġ=', 'Ġpy', 'game', 'Ġ.', 'Ġimage', 'Ġ.', 'Ġload', 'Ġ(', 'Ġpicture', '_', 'file', 'Ġ)', 'Ġ.', 'Ġconvert', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['picture', 'Ġ=', 'Ġpy', 'game', 'Ġ.', 'Ġimage', 'Ġ.', 'Ġload', 'Ġ(', 'Ġpicture', '_', 'file', 'Ġ)', 'Ġ.', 'Ġconvert', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['picture', 'Ġ=', 'Ġpygame', 'Ġ.', 'Ġimage', 'Ġ.', 'Ġload', 'Ġ(', 'Ġpicture_file', 'Ġ)', 'Ġ.', 'Ġconvert', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "screen . blit ( picture , ( - picture_pos . x , picture_pos . y ) ) \n"
Original    (018): ['screen', '.', 'blit', '(', 'picture', ',', '(', '-', 'picture_pos', '.', 'x', ',', 'picture_pos', '.', 'y', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'screen', 'Ġ.', 'Ġbl', 'it', 'Ġ(', 'Ġpicture', 'Ġ,', 'Ġ(', 'Ġ-', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġx', 'Ġ,', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġy', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['screen', 'Ġ.', 'Ġbl', 'it', 'Ġ(', 'Ġpicture', 'Ġ,', 'Ġ(', 'Ġ-', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġx', 'Ġ,', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġy', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['screen', 'Ġ.', 'Ġblit', 'Ġ(', 'Ġpicture', 'Ġ,', 'Ġ(', 'Ġ-', 'Ġpicture_pos', 'Ġ.', 'Ġx', 'Ġ,', 'Ġpicture_pos', 'Ġ.', 'Ġy', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "time_passed_seconds = time_passed / 1000.0 \n"
Original    (006): ['time_passed_seconds', '=', 'time_passed', '/', '1000.0', '\\n']
Tokenized   (019): ['<s>', 'time', '_', 'pass', 'ed', '_', 'seconds', 'Ġ=', 'Ġtime', '_', 'pass', 'ed', 'Ġ/', 'Ġ1000', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['time', '_', 'pass', 'ed', '_', 'seconds', 'Ġ=', 'Ġtime', '_', 'pass', 'ed', 'Ġ/', 'Ġ1000', '.', '0', 'Ġ\\', 'n']
Detokenized (006): ['time_passed_seconds', 'Ġ=', 'Ġtime_passed', 'Ġ/', 'Ġ1000.0', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "picture_pos += scroll_direction * scroll_speed * time_passed_seconds \n"
Original    (008): ['picture_pos', '+=', 'scroll_direction', '*', 'scroll_speed', '*', 'time_passed_seconds', '\\n']
Tokenized   (022): ['<s>', 'picture', '_', 'pos', 'Ġ+=', 'Ġscroll', '_', 'direction', 'Ġ*', 'Ġscroll', '_', 'speed', 'Ġ*', 'Ġtime', '_', 'pass', 'ed', '_', 'seconds', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['picture', '_', 'pos', 'Ġ+=', 'Ġscroll', '_', 'direction', 'Ġ*', 'Ġscroll', '_', 'speed', 'Ġ*', 'Ġtime', '_', 'pass', 'ed', '_', 'seconds', 'Ġ\\', 'n']
Detokenized (008): ['picture_pos', 'Ġ+=', 'Ġscroll_direction', 'Ġ*', 'Ġscroll_speed', 'Ġ*', 'Ġtime_passed_seconds', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "VERSION = open ( "version.txt" ) . readline ( ) . strip ( ) \n"
Original    (015): ['VERSION', '=', 'open', '(', '"version.txt"', ')', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '\\n']
Tokenized   (023): ['<s>', 'VERSION', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'version', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['VERSION', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'version', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['VERSION', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"version.txt"', 'Ġ)', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "DOWNLOAD_URL = DOWNLOAD_BASEURL + "dubbo-client-%s-py2.7.egg" % VERSION \n"
Original    (008): ['DOWNLOAD_URL', '=', 'DOWNLOAD_BASEURL', '+', '"dubbo-client-%s-py2.7.egg"', '%', 'VERSION', '\\n']
Tokenized   (036): ['<s>', 'DOWN', 'LOAD', '_', 'URL', 'Ġ=', 'ĠDOWN', 'LOAD', '_', 'B', 'ASE', 'URL', 'Ġ+', 'Ġ"', 'd', 'ub', 'bo', '-', 'client', '-', '%', 's', '-', 'py', '2', '.', '7', '.', 'egg', '"', 'Ġ%', 'ĠVERS', 'ION', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['DOWN', 'LOAD', '_', 'URL', 'Ġ=', 'ĠDOWN', 'LOAD', '_', 'B', 'ASE', 'URL', 'Ġ+', 'Ġ"', 'd', 'ub', 'bo', '-', 'client', '-', '%', 's', '-', 'py', '2', '.', '7', '.', 'egg', '"', 'Ġ%', 'ĠVERS', 'ION', 'Ġ\\', 'n']
Detokenized (008): ['DOWNLOAD_URL', 'Ġ=', 'ĠDOWNLOAD_BASEURL', 'Ġ+', 'Ġ"dubbo-client-%s-py2.7.egg"', 'Ġ%', 'ĠVERSION', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "long_description = open ( "README.md" ) . read ( ) , \n"
Original    (012): ['long_description', '=', 'open', '(', '"README.md"', ')', '.', 'read', '(', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'long', '_', 'description', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'READ', 'ME', '.', 'md', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['long', '_', 'description', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'READ', 'ME', '.', 'md', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['long_description', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"README.md"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "install_requires = [ "kazoo>=2.0" , "python-jsonrpc>=0.7.3" ] , \n"
Original    (009): ['install_requires', '=', '[', '"kazoo>=2.0"', ',', '"python-jsonrpc>=0.7.3"', ']', ',', '\\n']
Tokenized   (036): ['<s>', 'install', '_', 'requires', 'Ġ=', 'Ġ[', 'Ġ"', 'k', 'az', 'oo', '>', '=', '2', '.', '0', '"', 'Ġ,', 'Ġ"', 'python', '-', 'json', 'r', 'pc', '>', '=', '0', '.', '7', '.', '3', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['install', '_', 'requires', 'Ġ=', 'Ġ[', 'Ġ"', 'k', 'az', 'oo', '>', '=', '2', '.', '0', '"', 'Ġ,', 'Ġ"', 'python', '-', 'json', 'r', 'pc', '>', '=', '0', '.', '7', '.', '3', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['install_requires', 'Ġ=', 'Ġ[', 'Ġ"kazoo>=2.0"', 'Ġ,', 'Ġ"python-jsonrpc>=0.7.3"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "field = models . BooleanField ( default = False ) , \n"
Original    (012): ['field', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'field', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['field', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['field', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "args = [ in_path , user_out_path ] , env = [ "PATH=" + os . environ . get ( "PATH" , "" ) use_sandbox = True , use_nobody = True ) \n"
Original    (032): ['args', '=', '[', 'in_path', ',', 'user_out_path', ']', ',', 'env', '=', '[', '"PATH="', '+', 'os', '.', 'environ', '.', 'get', '(', '"PATH"', ',', '""', ')', 'use_sandbox', '=', 'True', ',', 'use_nobody', '=', 'True', ')', '\\n']
Tokenized   (052): ['<s>', 'args', 'Ġ=', 'Ġ[', 'Ġin', '_', 'path', 'Ġ,', 'Ġuser', '_', 'out', '_', 'path', 'Ġ]', 'Ġ,', 'Ġenv', 'Ġ=', 'Ġ[', 'Ġ"', 'PATH', '="', 'Ġ+', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'PATH', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġuse', '_', 'sand', 'box', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġuse', '_', 'nob', 'ody', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (050): ['args', 'Ġ=', 'Ġ[', 'Ġin', '_', 'path', 'Ġ,', 'Ġuser', '_', 'out', '_', 'path', 'Ġ]', 'Ġ,', 'Ġenv', 'Ġ=', 'Ġ[', 'Ġ"', 'PATH', '="', 'Ġ+', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'PATH', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġuse', '_', 'sand', 'box', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġuse', '_', 'nob', 'ody', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (032): ['args', 'Ġ=', 'Ġ[', 'Ġin_path', 'Ġ,', 'Ġuser_out_path', 'Ġ]', 'Ġ,', 'Ġenv', 'Ġ=', 'Ġ[', 'Ġ"PATH="', 'Ġ+', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"PATH"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġuse_sandbox', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġuse_nobody', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 50
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "print_skip = 5 , * args , ** kwargs ) : \n"
Original    (012): ['print_skip', '=', '5', ',', '*', 'args', ',', '**', 'kwargs', ')', ':', '\\n']
Tokenized   (019): ['<s>', 'print', '_', 'skip', 'Ġ=', 'Ġ5', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['print', '_', 'skip', 'Ġ=', 'Ġ5', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (012): ['print_skip', 'Ġ=', 'Ġ5', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "error = np . max ( np . abs ( new_v - v ) ) \n"
Original    (016): ['error', '=', 'np', '.', 'max', '(', 'np', '.', 'abs', '(', 'new_v', '-', 'v', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'error', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġabs', 'Ġ(', 'Ġnew', '_', 'v', 'Ġ-', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['error', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġabs', 'Ġ(', 'Ġnew', '_', 'v', 'Ġ-', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['error', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġabs', 'Ġ(', 'Ġnew_v', 'Ġ-', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "ac = ( a_0 - c ) / 2.0 \n"
Original    (010): ['ac', '=', '(', 'a_0', '-', 'c', ')', '/', '2.0', '\\n']
Tokenized   (017): ['<s>', 'ac', 'Ġ=', 'Ġ(', 'Ġa', '_', '0', 'Ġ-', 'Ġc', 'Ġ)', 'Ġ/', 'Ġ2', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['ac', 'Ġ=', 'Ġ(', 'Ġa', '_', '0', 'Ġ-', 'Ġc', 'Ġ)', 'Ġ/', 'Ġ2', '.', '0', 'Ġ\\', 'n']
Detokenized (010): ['ac', 'Ġ=', 'Ġ(', 'Ġa_0', 'Ġ-', 'Ġc', 'Ġ)', 'Ġ/', 'Ġ2.0', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "R = - R \n"
Original    (005): ['R', '=', '-', 'R', '\\n']
Tokenized   (008): ['<s>', 'R', 'Ġ=', 'Ġ-', 'ĠR', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['R', 'Ġ=', 'Ġ-', 'ĠR', 'Ġ\\', 'n']
Detokenized (005): ['R', 'Ġ=', 'Ġ-', 'ĠR', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "B = np . array ( [ [ 0. ] , \n"
Original    (012): ['B', '=', 'np', '.', 'array', '(', '[', '[', '0.', ']', ',', '\\n']
Tokenized   (016): ['<s>', 'B', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['B', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['B', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0.', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Fr , Kr , Pr = self . Fr , self . Kr , self . Pr \n"
Original    (018): ['Fr', ',', 'Kr', ',', 'Pr', '=', 'self', '.', 'Fr', ',', 'self', '.', 'Kr', ',', 'self', '.', 'Pr', '\\n']
Tokenized   (021): ['<s>', 'Fr', 'Ġ,', 'ĠKr', 'Ġ,', 'ĠPr', 'Ġ=', 'Ġself', 'Ġ.', 'ĠFr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠKr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠPr', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Fr', 'Ġ,', 'ĠKr', 'Ġ,', 'ĠPr', 'Ġ=', 'Ġself', 'Ġ.', 'ĠFr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠKr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠPr', 'Ġ\\', 'n']
Detokenized (018): ['Fr', 'Ġ,', 'ĠKr', 'Ġ,', 'ĠPr', 'Ġ=', 'Ġself', 'Ġ.', 'ĠFr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠKr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠPr', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "Fs , Ks , Ps = rblq . robust_rule_simple ( P_init = Pr , tol = 1e-12 ) \n"
Original    (019): ['Fs', ',', 'Ks', ',', 'Ps', '=', 'rblq', '.', 'robust_rule_simple', '(', 'P_init', '=', 'Pr', ',', 'tol', '=', '1e-12', ')', '\\n']
Tokenized   (035): ['<s>', 'Fs', 'Ġ,', 'ĠK', 's', 'Ġ,', 'ĠPs', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġrobust', '_', 'rule', '_', 'simple', 'Ġ(', 'ĠP', '_', 'init', 'Ġ=', 'ĠPr', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'Ġ1', 'e', '-', '12', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['Fs', 'Ġ,', 'ĠK', 's', 'Ġ,', 'ĠPs', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġrobust', '_', 'rule', '_', 'simple', 'Ġ(', 'ĠP', '_', 'init', 'Ġ=', 'ĠPr', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'Ġ1', 'e', '-', '12', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['Fs', 'Ġ,', 'ĠKs', 'Ġ,', 'ĠPs', 'Ġ=', 'Ġrblq', 'Ġ.', 'Ġrobust_rule_simple', 'Ġ(', 'ĠP_init', 'Ġ=', 'ĠPr', 'Ġ,', 'Ġtol', 'Ġ=', 'Ġ1e-12', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "Kf , Pf , df , Of , of = rblq . evaluate_F ( Fr ) \n"
Original    (017): ['Kf', ',', 'Pf', ',', 'df', ',', 'Of', ',', 'of', '=', 'rblq', '.', 'evaluate_F', '(', 'Fr', ')', '\\n']
Tokenized   (025): ['<s>', 'K', 'f', 'Ġ,', 'ĠPf', 'Ġ,', 'Ġdf', 'Ġ,', 'ĠOf', 'Ġ,', 'Ġof', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġevaluate', '_', 'F', 'Ġ(', 'ĠFr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['K', 'f', 'Ġ,', 'ĠPf', 'Ġ,', 'Ġdf', 'Ġ,', 'ĠOf', 'Ġ,', 'Ġof', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġevaluate', '_', 'F', 'Ġ(', 'ĠFr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['Kf', 'Ġ,', 'ĠPf', 'Ġ,', 'Ġdf', 'Ġ,', 'ĠOf', 'Ġ,', 'Ġof', 'Ġ=', 'Ġrblq', 'Ġ.', 'Ġevaluate_F', 'Ġ(', 'ĠFr', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "group = h5f . createGroup ( "/" , ) \n"
Original    (010): ['group', '=', 'h5f', '.', 'createGroup', '(', '"/"', ',', ')', '\\n']
Tokenized   (017): ['<s>', 'group', 'Ġ=', 'Ġh', '5', 'f', 'Ġ.', 'Ġcreate', 'Group', 'Ġ(', 'Ġ"/', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['group', 'Ġ=', 'Ġh', '5', 'f', 'Ġ.', 'Ġcreate', 'Group', 'Ġ(', 'Ġ"/', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['group', 'Ġ=', 'Ġh5f', 'Ġ.', 'ĠcreateGroup', 'Ġ(', 'Ġ"/"', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "global ctr \n"
Original    (003): ['global', 'ctr', '\\n']
Tokenized   (007): ['<s>', 'global', 'Ġc', 'tr', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['global', 'Ġc', 'tr', 'Ġ\\', 'n']
Detokenized (003): ['global', 'Ġctr', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "listOfInputPaths . append ( rootdir + "/Raw/Yahoo/US/NYSE/" ) \n"
Original    (009): ['listOfInputPaths', '.', 'append', '(', 'rootdir', '+', '"/Raw/Yahoo/US/NYSE/"', ')', '\\n']
Tokenized   (026): ['<s>', 'list', 'Of', 'Input', 'Path', 's', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġroot', 'dir', 'Ġ+', 'Ġ"/', 'Raw', '/', 'Y', 'ahoo', '/', 'US', '/', 'NYSE', '/"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['list', 'Of', 'Input', 'Path', 's', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġroot', 'dir', 'Ġ+', 'Ġ"/', 'Raw', '/', 'Y', 'ahoo', '/', 'US', '/', 'NYSE', '/"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['listOfInputPaths', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġrootdir', 'Ġ+', 'Ġ"/Raw/Yahoo/US/NYSE/"', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "filtered_names = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ 0 ] ) , filtered_names ) \n"
Original    (025): ['filtered_names', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'str', '(', 'fileExtensionToRemove', ')', ')', '[', '0', ']', ')', ',', 'filtered_names', ')', '\\n']
Tokenized   (037): ['<s>', 'fil', 'tered', '_', 'names', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġfiltered', '_', 'names', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['fil', 'tered', '_', 'names', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġfiltered', '_', 'names', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['filtered_names', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠfileExtensionToRemove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġfiltered_names', 'Ġ)', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "stock_data = np . loadtxt ( path + stock + ".csv" , np . float , None , "," , None , 1 , use_cols ) \n"
Original    (027): ['stock_data', '=', 'np', '.', 'loadtxt', '(', 'path', '+', 'stock', '+', '".csv"', ',', 'np', '.', 'float', ',', 'None', ',', '","', ',', 'None', ',', '1', ',', 'use_cols', ')', '\\n']
Tokenized   (039): ['<s>', 'stock', '_', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġload', 'txt', 'Ġ(', 'Ġpath', 'Ġ+', 'Ġstock', 'Ġ+', 'Ġ".', 'csv', '"', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ"', ',"', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġuse', '_', 'col', 's', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['stock', '_', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġload', 'txt', 'Ġ(', 'Ġpath', 'Ġ+', 'Ġstock', 'Ġ+', 'Ġ".', 'csv', '"', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ"', ',"', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġuse', '_', 'col', 's', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['stock_data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġloadtxt', 'Ġ(', 'Ġpath', 'Ġ+', 'Ġstock', 'Ġ+', 'Ġ".csv"', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ","', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġuse_cols', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "pkl . dump ( stock_data , f , - 1 ) \n"
Original    (012): ['pkl', '.', 'dump', '(', 'stock_data', ',', 'f', ',', '-', '1', ')', '\\n']
Tokenized   (018): ['<s>', 'p', 'kl', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġstock', '_', 'data', 'Ġ,', 'Ġf', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['p', 'kl', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġstock', '_', 'data', 'Ġ,', 'Ġf', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['pkl', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġstock_data', 'Ġ,', 'Ġf', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "startday = dt . datetime ( t [ 2 ] , t [ 0 ] , t [ 1 ] ) \n"
Original    (022): ['startday', '=', 'dt', '.', 'datetime', '(', 't', '[', '2', ']', ',', 't', '[', '0', ']', ',', 't', '[', '1', ']', ')', '\\n']
Tokenized   (028): ['<s>', 'start', 'day', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġt', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['start', 'day', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġt', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['startday', 'Ġ=', 'Ġdt', 'Ġ.', 'Ġdatetime', 'Ġ(', 'Ġt', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "t = map ( int , sys . argv [ 2 ] . split ( ) ) \n"
Original    (018): ['t', '=', 'map', '(', 'int', ',', 'sys', '.', 'argv', '[', '2', ']', '.', 'split', '(', ')', ')', '\\n']
Tokenized   (022): ['<s>', 't', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġint', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['t', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġint', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['t', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġint', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "historic = dataobj . get_data ( timestamps , symbols , "close" ) \n"
Original    (013): ['historic', '=', 'dataobj', '.', 'get_data', '(', 'timestamps', ',', 'symbols', ',', '"close"', ')', '\\n']
Tokenized   (023): ['<s>', 'historic', 'Ġ=', 'Ġdata', 'obj', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġtim', 'est', 'amps', 'Ġ,', 'Ġsymbols', 'Ġ,', 'Ġ"', 'close', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['historic', 'Ġ=', 'Ġdata', 'obj', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġtim', 'est', 'amps', 'Ġ,', 'Ġsymbols', 'Ġ,', 'Ġ"', 'close', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['historic', 'Ġ=', 'Ġdataobj', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġtimestamps', 'Ġ,', 'Ġsymbols', 'Ġ,', 'Ġ"close"', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "alloc = alloc . append ( DataMatrix ( index = [ historic . index [ date ] ] , data = [ alloc_val ] , columns = [ symbols ~~ alloc [ ] = 1 - alloc [ symbols [ 0 ] ] \n"
Original    (044): ['alloc', '=', 'alloc', '.', 'append', '(', 'DataMatrix', '(', 'index', '=', '[', 'historic', '.', 'index', '[', 'date', ']', ']', ',', 'data', '=', '[', 'alloc_val', ']', ',', 'columns', '=', '[', 'symbols', '~~', 'alloc', '[', ']', '=', '1', '-', 'alloc', '[', 'symbols', '[', '0', ']', ']', '\\n']
Tokenized   (051): ['<s>', 'alloc', 'Ġ=', 'Ġalloc', 'Ġ.', 'Ġappend', 'Ġ(', 'ĠData', 'Matrix', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġ[', 'Ġhistoric', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġdate', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġalloc', '_', 'val', 'Ġ]', 'Ġ,', 'Ġcolumns', 'Ġ=', 'Ġ[', 'Ġsymbols', 'Ġ', '~~', 'Ġalloc', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġalloc', 'Ġ[', 'Ġsymbols', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (049): ['alloc', 'Ġ=', 'Ġalloc', 'Ġ.', 'Ġappend', 'Ġ(', 'ĠData', 'Matrix', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġ[', 'Ġhistoric', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġdate', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġalloc', '_', 'val', 'Ġ]', 'Ġ,', 'Ġcolumns', 'Ġ=', 'Ġ[', 'Ġsymbols', 'Ġ', '~~', 'Ġalloc', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġalloc', 'Ġ[', 'Ġsymbols', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (044): ['alloc', 'Ġ=', 'Ġalloc', 'Ġ.', 'Ġappend', 'Ġ(', 'ĠDataMatrix', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġ[', 'Ġhistoric', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġdate', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġalloc_val', 'Ġ]', 'Ġ,', 'Ġcolumns', 'Ġ=', 'Ġ[', 'Ġsymbols', 'Ġ~~', 'Ġalloc', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġalloc', 'Ġ[', 'Ġsymbols', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 49
===================================================================
Hidden states:  (13, 44, 768)
# Extracted words:  44
Sentence         : "output = open ( sys . argv [ 3 ] , "wb" ) \n"
Original    (014): ['output', '=', 'open', '(', 'sys', '.', 'argv', '[', '3', ']', ',', '"wb"', ')', '\\n']
Tokenized   (020): ['<s>', 'output', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ"', 'wb', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['output', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ"', 'wb', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['output', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ"wb"', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "stocksAtThisPath = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ 0 ] ) , stocksAtThisPath \n"
Original    (024): ['stocksAtThisPath', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'str', '(', 'fileExtensionToRemove', ')', ')', '[', '0', ']', ')', ',', 'stocksAtThisPath', '\\n']
Tokenized   (037): ['<s>', 'stocks', 'At', 'This', 'Path', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġstocks', 'At', 'This', 'Path', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['stocks', 'At', 'This', 'Path', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġstocks', 'At', 'This', 'Path', 'Ġ\\', 'n']
Detokenized (024): ['stocksAtThisPath', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠfileExtensionToRemove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'ĠstocksAtThisPath', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "@ memoize_default ( None , evaluator_is_first_arg = True ) \n"
Original    (010): ['@', 'memoize_default', '(', 'None', ',', 'evaluator_is_first_arg', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', '@', 'Ġmemo', 'ize', '_', 'default', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġeval', 'u', 'ator', '_', 'is', '_', 'first', '_', 'arg', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['@', 'Ġmemo', 'ize', '_', 'default', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġeval', 'u', 'ator', '_', 'is', '_', 'first', '_', 'arg', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['@', 'Ġmemoize_default', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġevaluator_is_first_arg', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "param_str = _search_param_in_docstr ( func . raw_doc , str ( param . get_name ( ) ) ) \n"
Original    (018): ['param_str', '=', '_search_param_in_docstr', '(', 'func', '.', 'raw_doc', ',', 'str', '(', 'param', '.', 'get_name', '(', ')', ')', ')', '\\n']
Tokenized   (035): ['<s>', 'param', '_', 'str', 'Ġ=', 'Ġ_', 'search', '_', 'param', '_', 'in', '_', 'doc', 'str', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġraw', '_', 'doc', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġparam', 'Ġ.', 'Ġget', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['param', '_', 'str', 'Ġ=', 'Ġ_', 'search', '_', 'param', '_', 'in', '_', 'doc', 'str', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġraw', '_', 'doc', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġparam', 'Ġ.', 'Ġget', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['param_str', 'Ġ=', 'Ġ_search_param_in_docstr', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġraw_doc', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġparam', 'Ġ.', 'Ġget_name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "patterns = [ re . compile ( p % re . escape ( param_str ) ) \n"
Original    (017): ['patterns', '=', '[', 're', '.', 'compile', '(', 'p', '%', 're', '.', 'escape', '(', 'param_str', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'pattern', 's', 'Ġ=', 'Ġ[', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġp', 'Ġ%', 'Ġre', 'Ġ.', 'Ġescape', 'Ġ(', 'Ġparam', '_', 'str', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['pattern', 's', 'Ġ=', 'Ġ[', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġp', 'Ġ%', 'Ġre', 'Ġ.', 'Ġescape', 'Ġ(', 'Ġparam', '_', 'str', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['patterns', 'Ġ=', 'Ġ[', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġp', 'Ġ%', 'Ġre', 'Ġ.', 'Ġescape', 'Ġ(', 'Ġparam_str', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "it = ( evaluator . execute ( d ) for d in definitions ) \n"
Original    (015): ['it', '=', '(', 'evaluator', '.', 'execute', '(', 'd', ')', 'for', 'd', 'in', 'definitions', ')', '\\n']
Tokenized   (020): ['<s>', 'it', 'Ġ=', 'Ġ(', 'Ġeval', 'u', 'ator', 'Ġ.', 'Ġexecute', 'Ġ(', 'Ġd', 'Ġ)', 'Ġfor', 'Ġd', 'Ġin', 'Ġdefinitions', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['it', 'Ġ=', 'Ġ(', 'Ġeval', 'u', 'ator', 'Ġ.', 'Ġexecute', 'Ġ(', 'Ġd', 'Ġ)', 'Ġfor', 'Ġd', 'Ġin', 'Ġdefinitions', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['it', 'Ġ=', 'Ġ(', 'Ġevaluator', 'Ġ.', 'Ġexecute', 'Ġ(', 'Ġd', 'Ġ)', 'Ġfor', 'Ġd', 'Ġin', 'Ġdefinitions', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tok = parsed . module . subscopes [ 0 ] . statements [ 0 ] . _token_list [ 2 ] \n"
Original    (021): ['tok', '=', 'parsed', '.', 'module', '.', 'subscopes', '[', '0', ']', '.', 'statements', '[', '0', ']', '.', '_token_list', '[', '2', ']', '\\n']
Tokenized   (029): ['<s>', 't', 'ok', 'Ġ=', 'Ġparsed', 'Ġ.', 'Ġmodule', 'Ġ.', 'Ġsubsc', 'opes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġstatements', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġ_', 'token', '_', 'list', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['t', 'ok', 'Ġ=', 'Ġparsed', 'Ġ.', 'Ġmodule', 'Ġ.', 'Ġsubsc', 'opes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġstatements', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġ_', 'token', '_', 'list', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['tok', 'Ġ=', 'Ġparsed', 'Ġ.', 'Ġmodule', 'Ġ.', 'Ġsubscopes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġstatements', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġ_token_list', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "__slots__ = ( "graphVariable" , \n"
Original    (006): ['__slots__', '=', '(', '"graphVariable"', ',', '\\n']
Tokenized   (015): ['<s>', '__', 'sl', 'ots', '__', 'Ġ=', 'Ġ(', 'Ġ"', 'graph', 'Variable', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['__', 'sl', 'ots', '__', 'Ġ=', 'Ġ(', 'Ġ"', 'graph', 'Variable', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['__slots__', 'Ġ=', 'Ġ(', 'Ġ"graphVariable"', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "( None , \n"
Original    (004): ['(', 'None', ',', '\\n']
Tokenized   (007): ['<s>', '(', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['(', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['(', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "def __init__ ( self , patterns = [ ] , prolog = None ) : \n"
Original    (016): ['def', '__init__', '(', 'self', ',', 'patterns', '=', '[', ']', ',', 'prolog', '=', 'None', ')', ':', '\\n']
Tokenized   (022): ['<s>', 'def', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġpatterns', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġpro', 'log', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['def', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġpatterns', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġpro', 'log', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (016): ['def', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġpatterns', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġprolog', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "return term . n3 ( ) \n"
Original    (007): ['return', 'term', '.', 'n3', '(', ')', '\\n']
Tokenized   (011): ['<s>', 'return', 'Ġterm', 'Ġ.', 'Ġn', '3', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['return', 'Ġterm', 'Ġ.', 'Ġn', '3', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['return', 'Ġterm', 'Ġ.', 'Ġn3', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ". join ( [ + . join ( [ \n"
Original    (010): ['.', 'join', '(', '[', '+', '.', 'join', '(', '[', '\\n']
Tokenized   (013): ['<s>', '.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ+', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ+', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ\\', 'n']
Detokenized (010): ['.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ+', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "[ ( "a" , "?b" , 24 ) , ( "?r" , "?c" , 12345 ) , ( v1 , "?c" , 3333 ) , ( u1 , "?c" , 9999 ) ] ) \n"
Original    (035): ['[', '(', '"a"', ',', '"?b"', ',', '24', ')', ',', '(', '"?r"', ',', '"?c"', ',', '12345', ')', ',', '(', 'v1', ',', '"?c"', ',', '3333', ')', ',', '(', 'u1', ',', '"?c"', ',', '9999', ')', ']', ')', '\\n']
Tokenized   (060): ['<s>', '[', 'Ġ(', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', '?', 'b', '"', 'Ġ,', 'Ġ24', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ"', '?', 'r', '"', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ123', '45', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġv', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ3', '333', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġu', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ9', '999', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (058): ['[', 'Ġ(', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', '?', 'b', '"', 'Ġ,', 'Ġ24', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ"', '?', 'r', '"', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ123', '45', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġv', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ3', '333', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġu', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ9', '999', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (035): ['[', 'Ġ(', 'Ġ"a"', 'Ġ,', 'Ġ"?b"', 'Ġ,', 'Ġ24', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ"?r"', 'Ġ,', 'Ġ"?c"', 'Ġ,', 'Ġ12345', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġv1', 'Ġ,', 'Ġ"?c"', 'Ġ,', 'Ġ3333', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġu1', 'Ġ,', 'Ġ"?c"', 'Ġ,', 'Ġ9999', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 58
===================================================================
Hidden states:  (13, 35, 768)
# Extracted words:  35
Sentence         : "unittest . TextTestRunner ( verbosity = 3 ) . run ( suite ) \n"
Original    (014): ['unittest', '.', 'TextTestRunner', '(', 'verbosity', '=', '3', ')', '.', 'run', '(', 'suite', ')', '\\n']
Tokenized   (022): ['<s>', 'un', 'itt', 'est', 'Ġ.', 'ĠText', 'Test', 'Runner', 'Ġ(', 'Ġverb', 'osity', 'Ġ=', 'Ġ3', 'Ġ)', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġsuite', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['un', 'itt', 'est', 'Ġ.', 'ĠText', 'Test', 'Runner', 'Ġ(', 'Ġverb', 'osity', 'Ġ=', 'Ġ3', 'Ġ)', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġsuite', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['unittest', 'Ġ.', 'ĠTextTestRunner', 'Ġ(', 'Ġverbosity', 'Ġ=', 'Ġ3', 'Ġ)', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġsuite', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ") . parse ( "http://www.w3.org/People/Berners-Lee/card.rdf" ) \n"
Original    (007): [')', '.', 'parse', '(', '"http://www.w3.org/People/Berners-Lee/card.rdf"', ')', '\\n']
Tokenized   (031): ['<s>', ')', 'Ġ.', 'Ġparse', 'Ġ(', 'Ġ"', 'http', '://', 'www', '.', 'w', '3', '.', 'org', '/', 'People', '/', 'Bern', 'ers', '-', 'Lee', '/', 'card', '.', 'rd', 'f', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): [')', 'Ġ.', 'Ġparse', 'Ġ(', 'Ġ"', 'http', '://', 'www', '.', 'w', '3', '.', 'org', '/', 'People', '/', 'Bern', 'ers', '-', 'Lee', '/', 'card', '.', 'rd', 'f', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): [')', 'Ġ.', 'Ġparse', 'Ġ(', 'Ġ"http://www.w3.org/People/Berners-Lee/card.rdf"', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "graph . get_context ( URIRef ( ) \n"
Original    (008): ['graph', '.', 'get_context', '(', 'URIRef', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'graph', 'Ġ.', 'Ġget', '_', 'context', 'Ġ(', 'ĠUR', 'IR', 'ef', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['graph', 'Ġ.', 'Ġget', '_', 'context', 'Ġ(', 'ĠUR', 'IR', 'ef', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['graph', 'Ġ.', 'Ġget_context', 'Ġ(', 'ĠURIRef', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bob . set ( FOAF . name , Literal ( "Bob" ) ) \n"
Original    (014): ['bob', '.', 'set', '(', 'FOAF', '.', 'name', ',', 'Literal', '(', '"Bob"', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'b', 'ob', 'Ġ.', 'Ġset', 'Ġ(', 'ĠFO', 'AF', 'Ġ.', 'Ġname', 'Ġ,', 'ĠLit', 'eral', 'Ġ(', 'Ġ"', 'Bob', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['b', 'ob', 'Ġ.', 'Ġset', 'Ġ(', 'ĠFO', 'AF', 'Ġ.', 'Ġname', 'Ġ,', 'ĠLit', 'eral', 'Ġ(', 'Ġ"', 'Bob', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['bob', 'Ġ.', 'Ġset', 'Ġ(', 'ĠFOAF', 'Ġ.', 'Ġname', 'Ġ,', 'ĠLiteral', 'Ġ(', 'Ġ"Bob"', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "print g . serialize ( format = ) \n"
Original    (009): ['print', 'g', '.', 'serialize', '(', 'format', '=', ')', '\\n']
Tokenized   (013): ['<s>', 'print', 'Ġg', 'Ġ.', 'Ġserial', 'ize', 'Ġ(', 'Ġformat', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['print', 'Ġg', 'Ġ.', 'Ġserial', 'ize', 'Ġ(', 'Ġformat', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['print', 'Ġg', 'Ġ.', 'Ġserialize', 'Ġ(', 'Ġformat', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "context = self . uriref ( ) or self . nodeid ( ) or self . sink . identifier \n"
Original    (020): ['context', '=', 'self', '.', 'uriref', '(', ')', 'or', 'self', '.', 'nodeid', '(', ')', 'or', 'self', '.', 'sink', '.', 'identifier', '\\n']
Tokenized   (026): ['<s>', 'context', 'Ġ=', 'Ġself', 'Ġ.', 'Ġur', 'ire', 'f', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġnode', 'id', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġsink', 'Ġ.', 'Ġidentifier', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['context', 'Ġ=', 'Ġself', 'Ġ.', 'Ġur', 'ire', 'f', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġnode', 'id', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġsink', 'Ġ.', 'Ġidentifier', 'Ġ\\', 'n']
Detokenized (020): ['context', 'Ġ=', 'Ġself', 'Ġ.', 'Ġuriref', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġnodeid', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġsink', 'Ġ.', 'Ġidentifier', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "from rdflib . query import Result , ResultSerializer , ResultParser \n"
Original    (011): ['from', 'rdflib', '.', 'query', 'import', 'Result', ',', 'ResultSerializer', ',', 'ResultParser', '\\n']
Tokenized   (020): ['<s>', 'from', 'Ġr', 'd', 'fl', 'ib', 'Ġ.', 'Ġquery', 'Ġimport', 'ĠResult', 'Ġ,', 'ĠResult', 'Serial', 'izer', 'Ġ,', 'ĠResult', 'Parser', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['from', 'Ġr', 'd', 'fl', 'ib', 'Ġ.', 'Ġquery', 'Ġimport', 'ĠResult', 'Ġ,', 'ĠResult', 'Serial', 'izer', 'Ġ,', 'ĠResult', 'Parser', 'Ġ\\', 'n']
Detokenized (011): ['from', 'Ġrdflib', 'Ġ.', 'Ġquery', 'Ġimport', 'ĠResult', 'Ġ,', 'ĠResultSerializer', 'Ġ,', 'ĠResultParser', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "class CSVResultParser ( ResultParser ) : \n"
Original    (007): ['class', 'CSVResultParser', '(', 'ResultParser', ')', ':', '\\n']
Tokenized   (013): ['<s>', 'class', 'ĠCSV', 'Result', 'Parser', 'Ġ(', 'ĠResult', 'Parser', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['class', 'ĠCSV', 'Result', 'Parser', 'Ġ(', 'ĠResult', 'Parser', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (007): ['class', 'ĠCSVResultParser', 'Ġ(', 'ĠResultParser', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "r . bindings = [ ] \n"
Original    (007): ['r', '.', 'bindings', '=', '[', ']', '\\n']
Tokenized   (010): ['<s>', 'r', 'Ġ.', 'Ġbindings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['r', 'Ġ.', 'Ġbindings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['r', 'Ġ.', 'Ġbindings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "if result . type != "SELECT" : \n"
Original    (008): ['if', 'result', '.', 'type', '!=', '"SELECT"', ':', '\\n']
Tokenized   (013): ['<s>', 'if', 'Ġresult', 'Ġ.', 'Ġtype', 'Ġ!=', 'Ġ"', 'SELECT', '"', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['if', 'Ġresult', 'Ġ.', 'Ġtype', 'Ġ!=', 'Ġ"', 'SELECT', '"', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['if', 'Ġresult', 'Ġ.', 'Ġtype', 'Ġ!=', 'Ġ"SELECT"', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "stream = codecs . getwriter ( encoding ) ( stream ) \n"
Original    (012): ['stream', '=', 'codecs', '.', 'getwriter', '(', 'encoding', ')', '(', 'stream', ')', '\\n']
Tokenized   (017): ['<s>', 'stream', 'Ġ=', 'Ġcodec', 's', 'Ġ.', 'Ġget', 'writer', 'Ġ(', 'Ġencoding', 'Ġ)', 'Ġ(', 'Ġstream', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['stream', 'Ġ=', 'Ġcodec', 's', 'Ġ.', 'Ġget', 'writer', 'Ġ(', 'Ġencoding', 'Ġ)', 'Ġ(', 'Ġstream', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['stream', 'Ġ=', 'Ġcodecs', 'Ġ.', 'Ġgetwriter', 'Ġ(', 'Ġencoding', 'Ġ)', 'Ġ(', 'Ġstream', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "vs = [ self . serializeTerm ( v , encoding ) for v in self . result . vars ] \n"
Original    (021): ['vs', '=', '[', 'self', '.', 'serializeTerm', '(', 'v', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'vars', ']', '\\n']
Tokenized   (027): ['<s>', 'vs', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġserial', 'ize', 'Term', 'Ġ(', 'Ġv', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['vs', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġserial', 'ize', 'Term', 'Ġ(', 'Ġv', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['vs', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'ĠserializeTerm', 'Ġ(', 'Ġv', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġvars', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "for row in self . result . bindings : \n"
Original    (010): ['for', 'row', 'in', 'self', '.', 'result', '.', 'bindings', ':', '\\n']
Tokenized   (013): ['<s>', 'for', 'Ġrow', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġbindings', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['for', 'Ġrow', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġbindings', 'Ġ:', 'Ġ\\', 'n']
Detokenized (010): ['for', 'Ġrow', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġbindings', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "row . get ( v ) , encoding ) for v in self . result . vars ] ) \n"
Original    (020): ['row', '.', 'get', '(', 'v', ')', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'vars', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'row', 'Ġ.', 'Ġget', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['row', 'Ġ.', 'Ġget', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['row', 'Ġ.', 'Ġget', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġvars', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "try : import nose \n"
Original    (005): ['try', ':', 'import', 'nose', '\\n']
Tokenized   (008): ['<s>', 'try', 'Ġ:', 'Ġimport', 'Ġnose', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['try', 'Ġ:', 'Ġimport', 'Ġnose', 'Ġ\\', 'n']
Detokenized (005): ['try', 'Ġ:', 'Ġimport', 'Ġnose', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "~~~ argv += DEFAULT_DIRS \n"
Original    (005): ['~~~', 'argv', '+=', 'DEFAULT_DIRS', '\\n']
Tokenized   (014): ['<s>', '~~', '~', 'Ġarg', 'v', 'Ġ+=', 'ĠDE', 'FAULT', '_', 'DIR', 'S', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['~~', '~', 'Ġarg', 'v', 'Ġ+=', 'ĠDE', 'FAULT', '_', 'DIR', 'S', 'Ġ\\', 'n']
Detokenized (005): ['~~~', 'Ġargv', 'Ġ+=', 'ĠDEFAULT_DIRS', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "nose . run_exit ( argv = finalArgs ) \n"
Original    (009): ['nose', '.', 'run_exit', '(', 'argv', '=', 'finalArgs', ')', '\\n']
Tokenized   (017): ['<s>', 'n', 'ose', 'Ġ.', 'Ġrun', '_', 'exit', 'Ġ(', 'Ġarg', 'v', 'Ġ=', 'Ġfinal', 'Args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['n', 'ose', 'Ġ.', 'Ġrun', '_', 'exit', 'Ġ(', 'Ġarg', 'v', 'Ġ=', 'Ġfinal', 'Args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['nose', 'Ġ.', 'Ġrun_exit', 'Ġ(', 'Ġargv', 'Ġ=', 'ĠfinalArgs', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Loading model: microsoft/graphcodebert-base
Reading input corpus
Preparing output file
Extracting representations from model
Sentence         : "\n"
Original    (001): ['\\n']
Tokenized   (004): ['<s>', '\\', 'n', '</s>']
Filtered   (002): ['\\', 'n']
Detokenized (001): ['\\n']
Counter: 2
===================================================================
Hidden states:  (13, 1, 768)
# Extracted words:  1
Sentence         : "# \n"
Original    (002): ['#', '\\n']
Tokenized   (005): ['<s>', '#', 'Ġ\\', 'n', '</s>']
Filtered   (003): ['#', 'Ġ\\', 'n']
Detokenized (002): ['#', 'Ġ\\n']
Counter: 3
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "template_name = \n"
Original    (003): ['template_name', '=', '\\n']
Tokenized   (008): ['<s>', 'template', '_', 'name', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['template', '_', 'name', 'Ġ=', 'Ġ\\', 'n']
Detokenized (003): ['template_name', 'Ġ=', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "slug = "policy_profile" \n"
Original    (004): ['slug', '=', '"policy_profile"', '\\n']
Tokenized   (012): ['<s>', 'sl', 'ug', 'Ġ=', 'Ġ"', 'policy', '_', 'profile', '"', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['sl', 'ug', 'Ġ=', 'Ġ"', 'policy', '_', 'profile', '"', 'Ġ\\', 'n']
Detokenized (004): ['slug', 'Ġ=', 'Ġ"policy_profile"', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "preload = False \n"
Original    (004): ['preload', '=', 'False', '\\n']
Tokenized   (008): ['<s>', 'pre', 'load', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['pre', 'load', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (004): ['preload', 'Ġ=', 'ĠFalse', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "tabs = ( NetworkProfileTab , PolicyProfileTab ) \n"
Original    (008): ['tabs', '=', '(', 'NetworkProfileTab', ',', 'PolicyProfileTab', ')', '\\n']
Tokenized   (016): ['<s>', 'tab', 's', 'Ġ=', 'Ġ(', 'ĠNetwork', 'Profile', 'Tab', 'Ġ,', 'ĠPolicy', 'Profile', 'Tab', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['tab', 's', 'Ġ=', 'Ġ(', 'ĠNetwork', 'Profile', 'Tab', 'Ġ,', 'ĠPolicy', 'Profile', 'Tab', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['tabs', 'Ġ=', 'Ġ(', 'ĠNetworkProfileTab', 'Ġ,', 'ĠPolicyProfileTab', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "weak_store = WeakLocal ( ) \n"
Original    (006): ['weak_store', '=', 'WeakLocal', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'weak', '_', 'store', 'Ġ=', 'ĠWeak', 'Local', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['weak', '_', 'store', 'Ġ=', 'ĠWeak', 'Local', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['weak_store', 'Ġ=', 'ĠWeakLocal', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "strong_store = corolocal . local \n"
Original    (006): ['strong_store', '=', 'corolocal', '.', 'local', '\\n']
Tokenized   (013): ['<s>', 'strong', '_', 'store', 'Ġ=', 'Ġcor', 'ol', 'ocal', 'Ġ.', 'Ġlocal', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['strong', '_', 'store', 'Ġ=', 'Ġcor', 'ol', 'ocal', 'Ġ.', 'Ġlocal', 'Ġ\\', 'n']
Detokenized (006): ['strong_store', 'Ġ=', 'Ġcorolocal', 'Ġ.', 'Ġlocal', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "eventlet . monkey_patch ( ) \n"
Original    (006): ['eventlet', '.', 'monkey_patch', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'event', 'let', 'Ġ.', 'Ġmonkey', '_', 'patch', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['event', 'let', 'Ġ.', 'Ġmonkey', '_', 'patch', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['eventlet', 'Ġ.', 'Ġmonkey_patch', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "CONF . register_opts ( impl_zmq . zmq_opts ) \n"
Original    (009): ['CONF', '.', 'register_opts', '(', 'impl_zmq', '.', 'zmq_opts', ')', '\\n']
Tokenized   (025): ['<s>', 'CON', 'F', 'Ġ.', 'Ġregister', '_', 'op', 'ts', 'Ġ(', 'Ġimpl', '_', 'z', 'm', 'q', 'Ġ.', 'Ġz', 'm', 'q', '_', 'op', 'ts', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['CON', 'F', 'Ġ.', 'Ġregister', '_', 'op', 'ts', 'Ġ(', 'Ġimpl', '_', 'z', 'm', 'q', 'Ġ.', 'Ġz', 'm', 'q', '_', 'op', 'ts', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['CONF', 'Ġ.', 'Ġregister_opts', 'Ġ(', 'Ġimpl_zmq', 'Ġ.', 'Ġzmq_opts', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "vpnservices_dict = { : self . api_vpnservices . list ( ) } \n"
Original    (013): ['vpnservices_dict', '=', '{', ':', 'self', '.', 'api_vpnservices', '.', 'list', '(', ')', '}', '\\n']
Tokenized   (024): ['<s>', 'v', 'pn', 'services', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġapi', '_', 'v', 'pn', 'services', 'Ġ.', 'Ġlist', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['v', 'pn', 'services', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġapi', '_', 'v', 'pn', 'services', 'Ġ.', 'Ġlist', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (013): ['vpnservices_dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġapi_vpnservices', 'Ġ.', 'Ġlist', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "vpnservice [ ] [ ] ) \n"
Original    (007): ['vpnservice', '[', ']', '[', ']', ')', '\\n']
Tokenized   (012): ['<s>', 'v', 'pn', 'service', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['v', 'pn', 'service', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['vpnservice', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "form_data } ) . AndReturn ( ipsecsiteconnection ) \n"
Original    (009): ['form_data', '}', ')', '.', 'AndReturn', '(', 'ipsecsiteconnection', ')', '\\n']
Tokenized   (018): ['<s>', 'form', '_', 'data', 'Ġ}', 'Ġ)', 'Ġ.', 'ĠAnd', 'Return', 'Ġ(', 'Ġip', 'sec', 'site', 'connection', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['form', '_', 'data', 'Ġ}', 'Ġ)', 'Ġ.', 'ĠAnd', 'Return', 'Ġ(', 'Ġip', 'sec', 'site', 'connection', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['form_data', 'Ġ}', 'Ġ)', 'Ġ.', 'ĠAndReturn', 'Ġ(', 'Ġipsecsiteconnection', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "ipsecsiteconnections_dict ) \n"
Original    (003): ['ipsecsiteconnections_dict', ')', '\\n']
Tokenized   (012): ['<s>', 'ip', 'sec', 'site', 'connect', 'ions', '_', 'dict', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['ip', 'sec', 'site', 'connect', 'ions', '_', 'dict', 'Ġ)', 'Ġ\\', 'n']
Detokenized (003): ['ipsecsiteconnections_dict', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "ipsecsiteconnections [ ] ) : \n"
Original    (006): ['ipsecsiteconnections', '[', ']', ')', ':', '\\n']
Tokenized   (013): ['<s>', 'ip', 'sec', 'site', 'connect', 'ions', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['ip', 'sec', 'site', 'connect', 'ions', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['ipsecsiteconnections', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "neutronclient . show_ipsec_site_connection ( \n"
Original    (005): ['neutronclient', '.', 'show_ipsec_site_connection', '(', '\\n']
Tokenized   (018): ['<s>', 'ne', 'ut', 'ron', 'client', 'Ġ.', 'Ġshow', '_', 'ip', 'sec', '_', 'site', '_', 'connection', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['ne', 'ut', 'ron', 'client', 'Ġ.', 'Ġshow', '_', 'ip', 'sec', '_', 'site', '_', 'connection', 'Ġ(', 'Ġ\\', 'n']
Detokenized (005): ['neutronclient', 'Ġ.', 'Ġshow_ipsec_site_connection', 'Ġ(', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "ret_val = api . vpn . ipsecsiteconnection_get ( self . request , \n"
Original    (013): ['ret_val', '=', 'api', '.', 'vpn', '.', 'ipsecsiteconnection_get', '(', 'self', '.', 'request', ',', '\\n']
Tokenized   (024): ['<s>', 'ret', '_', 'val', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġv', 'pn', 'Ġ.', 'Ġip', 'sec', 'site', 'connection', '_', 'get', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrequest', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ret', '_', 'val', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġv', 'pn', 'Ġ.', 'Ġip', 'sec', 'site', 'connection', '_', 'get', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrequest', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['ret_val', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġvpn', 'Ġ.', 'Ġipsecsiteconnection_get', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrequest', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "response_kwargs . setdefault ( "filename" , "usage.csv" ) \n"
Original    (009): ['response_kwargs', '.', 'setdefault', '(', '"filename"', ',', '"usage.csv"', ')', '\\n']
Tokenized   (022): ['<s>', 'response', '_', 'kw', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ"', 'filename', '"', 'Ġ,', 'Ġ"', 'usage', '.', 'csv', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['response', '_', 'kw', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ"', 'filename', '"', 'Ġ,', 'Ġ"', 'usage', '.', 'csv', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['response_kwargs', 'Ġ.', 'Ġsetdefault', 'Ġ(', 'Ġ"filename"', 'Ġ,', 'Ġ"usage.csv"', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "BlendProbes = 1 \n"
Original    (004): ['BlendProbes', '=', '1', '\\n']
Tokenized   (010): ['<s>', 'Bl', 'end', 'Pro', 'bes', 'Ġ=', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Bl', 'end', 'Pro', 'bes', 'Ġ=', 'Ġ1', 'Ġ\\', 'n']
Detokenized (004): ['BlendProbes', 'Ġ=', 'Ġ1', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "lightmap_index = field ( "m_LightmapIndex" ) \n"
Original    (007): ['lightmap_index', '=', 'field', '(', '"m_LightmapIndex"', ')', '\\n']
Tokenized   (019): ['<s>', 'light', 'map', '_', 'index', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Light', 'map', 'Index', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['light', 'map', '_', 'index', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Light', 'map', 'Index', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['lightmap_index', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"m_LightmapIndex"', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "receive_shadows = field ( "m_ReceiveShadows" , bool ) \n"
Original    (009): ['receive_shadows', '=', 'field', '(', '"m_ReceiveShadows"', ',', 'bool', ')', '\\n']
Tokenized   (023): ['<s>', 're', 'ceive', '_', 'sh', 'adows', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Re', 'ceive', 'Sh', 'adows', '"', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['re', 'ceive', '_', 'sh', 'adows', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"', 'm', '_', 'Re', 'ceive', 'Sh', 'adows', '"', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['receive_shadows', 'Ġ=', 'Ġfield', 'Ġ(', 'Ġ"m_ReceiveShadows"', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "Config . parser . readfp ( sconf ) \n"
Original    (009): ['Config', '.', 'parser', '.', 'readfp', '(', 'sconf', ')', '\\n']
Tokenized   (015): ['<s>', 'Config', 'Ġ.', 'Ġparser', 'Ġ.', 'Ġread', 'fp', 'Ġ(', 'Ġsc', 'on', 'f', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Config', 'Ġ.', 'Ġparser', 'Ġ.', 'Ġread', 'fp', 'Ġ(', 'Ġsc', 'on', 'f', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['Config', 'Ġ.', 'Ġparser', 'Ġ.', 'Ġreadfp', 'Ġ(', 'Ġsconf', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "BBS_XMPP_CERT_FILE = BBS_ROOT + "xmpp.crt" \n"
Original    (006): ['BBS_XMPP_CERT_FILE', '=', 'BBS_ROOT', '+', '"xmpp.crt"', '\\n']
Tokenized   (030): ['<s>', 'B', 'BS', '_', 'X', 'MP', 'P', '_', 'C', 'ERT', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ"', 'x', 'm', 'pp', '.', 'cr', 't', '"', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['B', 'BS', '_', 'X', 'MP', 'P', '_', 'C', 'ERT', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ"', 'x', 'm', 'pp', '.', 'cr', 't', '"', 'Ġ\\', 'n']
Detokenized (006): ['BBS_XMPP_CERT_FILE', 'Ġ=', 'ĠBBS_ROOT', 'Ġ+', 'Ġ"xmpp.crt"', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "BOARDS_FILE = BBS_ROOT + \n"
Original    (005): ['BOARDS_FILE', '=', 'BBS_ROOT', '+', '\\n']
Tokenized   (015): ['<s>', 'BO', 'ARDS', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['BO', 'ARDS', '_', 'FILE', 'Ġ=', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ+', 'Ġ\\', 'n']
Detokenized (005): ['BOARDS_FILE', 'Ġ=', 'ĠBBS_ROOT', 'Ġ+', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "USHM_SIZE = MAXACTIVE + 10 \n"
Original    (006): ['USHM_SIZE', '=', 'MAXACTIVE', '+', '10', '\\n']
Tokenized   (014): ['<s>', 'USH', 'M', '_', 'SIZE', 'Ġ=', 'ĠMAX', 'ACT', 'IVE', 'Ġ+', 'Ġ10', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['USH', 'M', '_', 'SIZE', 'Ġ=', 'ĠMAX', 'ACT', 'IVE', 'Ġ+', 'Ġ10', 'Ġ\\', 'n']
Detokenized (006): ['USHM_SIZE', 'Ġ=', 'ĠMAXACTIVE', 'Ġ+', 'Ġ10', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "UTMP_HASHSIZE = USHM_SIZE * 4 \n"
Original    (006): ['UTMP_HASHSIZE', '=', 'USHM_SIZE', '*', '4', '\\n']
Tokenized   (018): ['<s>', 'UT', 'MP', '_', 'H', 'AS', 'HS', 'IZE', 'Ġ=', 'ĠUS', 'HM', '_', 'SIZE', 'Ġ*', 'Ġ4', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['UT', 'MP', '_', 'H', 'AS', 'HS', 'IZE', 'Ġ=', 'ĠUS', 'HM', '_', 'SIZE', 'Ġ*', 'Ġ4', 'Ġ\\', 'n']
Detokenized (006): ['UTMP_HASHSIZE', 'Ġ=', 'ĠUSHM_SIZE', 'Ġ*', 'Ġ4', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "SESSION_TIMEOUT = datetime . timedelta ( 30 ) \n"
Original    (009): ['SESSION_TIMEOUT', '=', 'datetime', '.', 'timedelta', '(', '30', ')', '\\n']
Tokenized   (018): ['<s>', 'S', 'ESSION', '_', 'TIME', 'OUT', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['S', 'ESSION', '_', 'TIME', 'OUT', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['SESSION_TIMEOUT', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "SESSION_TIMEOUT_SECONDS = 86400 * 30 \n"
Original    (006): ['SESSION_TIMEOUT_SECONDS', '=', '86400', '*', '30', '\\n']
Tokenized   (019): ['<s>', 'S', 'ESSION', '_', 'TIME', 'OUT', '_', 'SEC', 'ON', 'DS', 'Ġ=', 'Ġ8', '64', '00', 'Ġ*', 'Ġ30', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['S', 'ESSION', '_', 'TIME', 'OUT', '_', 'SEC', 'ON', 'DS', 'Ġ=', 'Ġ8', '64', '00', 'Ġ*', 'Ġ30', 'Ġ\\', 'n']
Detokenized (006): ['SESSION_TIMEOUT_SECONDS', 'Ġ=', 'Ġ86400', 'Ġ*', 'Ġ30', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "MAX_ATTACHSIZE = 20 * 1024 * 1024 \n"
Original    (008): ['MAX_ATTACHSIZE', '=', '20', '*', '1024', '*', '1024', '\\n']
Tokenized   (016): ['<s>', 'MAX', '_', 'ATT', 'AC', 'HS', 'IZE', 'Ġ=', 'Ġ20', 'Ġ*', 'Ġ1024', 'Ġ*', 'Ġ1024', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['MAX', '_', 'ATT', 'AC', 'HS', 'IZE', 'Ġ=', 'Ġ20', 'Ġ*', 'Ġ1024', 'Ġ*', 'Ġ1024', 'Ġ\\', 'n']
Detokenized (008): ['MAX_ATTACHSIZE', 'Ġ=', 'Ġ20', 'Ġ*', 'Ġ1024', 'Ġ*', 'Ġ1024', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "MAIL_SIZE_LIMIT = - 1 \n"
Original    (005): ['MAIL_SIZE_LIMIT', '=', '-', '1', '\\n']
Tokenized   (015): ['<s>', 'MA', 'IL', '_', 'SIZE', '_', 'L', 'IM', 'IT', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['MA', 'IL', '_', 'SIZE', '_', 'L', 'IM', 'IT', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (005): ['MAIL_SIZE_LIMIT', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "newparts = [ ] \n"
Original    (005): ['newparts', '=', '[', ']', '\\n']
Tokenized   (009): ['<s>', 'new', 'parts', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['new', 'parts', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (005): ['newparts', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "firstitem = self . GetItem ( user , route + [ start ] , has_perm , need_perm ) \n"
Original    (019): ['firstitem', '=', 'self', '.', 'GetItem', '(', 'user', ',', 'route', '+', '[', 'start', ']', ',', 'has_perm', ',', 'need_perm', ')', '\\n']
Tokenized   (028): ['<s>', 'first', 'item', 'Ġ=', 'Ġself', 'Ġ.', 'ĠGet', 'Item', 'Ġ(', 'Ġuser', 'Ġ,', 'Ġroute', 'Ġ+', 'Ġ[', 'Ġstart', 'Ġ]', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġneed', '_', 'perm', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['first', 'item', 'Ġ=', 'Ġself', 'Ġ.', 'ĠGet', 'Item', 'Ġ(', 'Ġuser', 'Ġ,', 'Ġroute', 'Ġ+', 'Ġ[', 'Ġstart', 'Ġ]', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġneed', '_', 'perm', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['firstitem', 'Ġ=', 'Ġself', 'Ġ.', 'ĠGetItem', 'Ġ(', 'Ġuser', 'Ġ,', 'Ġroute', 'Ġ+', 'Ġ[', 'Ġstart', 'Ġ]', 'Ġ,', 'Ġhas_perm', 'Ġ,', 'Ġneed_perm', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "_id = start - 1 \n"
Original    (006): ['_id', '=', 'start', '-', '1', '\\n']
Tokenized   (010): ['<s>', '_', 'id', 'Ġ=', 'Ġstart', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['_', 'id', 'Ġ=', 'Ġstart', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (006): ['_id', 'Ġ=', 'Ġstart', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "linkfile = "%s/boards/xattach/%s" % ( Config . BBS_ROOT , filename ) \n"
Original    (012): ['linkfile', '=', '"%s/boards/xattach/%s"', '%', '(', 'Config', '.', 'BBS_ROOT', ',', 'filename', ')', '\\n']
Tokenized   (030): ['<s>', 'link', 'file', 'Ġ=', 'Ġ"%', 's', '/', 'boards', '/', 'x', 'attach', '/', '%', 's', '"', 'Ġ%', 'Ġ(', 'ĠConfig', 'Ġ.', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['link', 'file', 'Ġ=', 'Ġ"%', 's', '/', 'boards', '/', 'x', 'attach', '/', '%', 's', '"', 'Ġ%', 'Ġ(', 'ĠConfig', 'Ġ.', 'ĠB', 'BS', '_', 'RO', 'OT', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['linkfile', 'Ġ=', 'Ġ"%s/boards/xattach/%s"', 'Ġ%', 'Ġ(', 'ĠConfig', 'Ġ.', 'ĠBBS_ROOT', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "boardname = svc . get_str ( params , , ) \n"
Original    (011): ['boardname', '=', 'svc', '.', 'get_str', '(', 'params', ',', ',', ')', '\\n']
Tokenized   (018): ['<s>', 'board', 'name', 'Ġ=', 'Ġs', 'vc', 'Ġ.', 'Ġget', '_', 'str', 'Ġ(', 'Ġparams', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['board', 'name', 'Ġ=', 'Ġs', 'vc', 'Ġ.', 'Ġget', '_', 'str', 'Ġ(', 'Ġparams', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['boardname', 'Ġ=', 'Ġsvc', 'Ġ.', 'Ġget_str', 'Ġ(', 'Ġparams', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "has_perm = user . IsDigestMgr ( ) \n"
Original    (008): ['has_perm', '=', 'user', '.', 'IsDigestMgr', '(', ')', '\\n']
Tokenized   (017): ['<s>', 'has', '_', 'perm', 'Ġ=', 'Ġuser', 'Ġ.', 'ĠIs', 'Dig', 'est', 'M', 'gr', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['has', '_', 'perm', 'Ġ=', 'Ġuser', 'Ġ.', 'ĠIs', 'Dig', 'est', 'M', 'gr', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['has_perm', 'Ġ=', 'Ġuser', 'Ġ.', 'ĠIsDigestMgr', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Digest . View ( svc , basenode , route , session , has_perm , start , count ) \n"
Original    (019): ['Digest', '.', 'View', '(', 'svc', ',', 'basenode', ',', 'route', ',', 'session', ',', 'has_perm', ',', 'start', ',', 'count', ')', '\\n']
Tokenized   (028): ['<s>', 'Dig', 'est', 'Ġ.', 'ĠView', 'Ġ(', 'Ġs', 'vc', 'Ġ,', 'Ġbas', 'en', 'ode', 'Ġ,', 'Ġroute', 'Ġ,', 'Ġsession', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġstart', 'Ġ,', 'Ġcount', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['Dig', 'est', 'Ġ.', 'ĠView', 'Ġ(', 'Ġs', 'vc', 'Ġ,', 'Ġbas', 'en', 'ode', 'Ġ,', 'Ġroute', 'Ġ,', 'Ġsession', 'Ġ,', 'Ġhas', '_', 'perm', 'Ġ,', 'Ġstart', 'Ġ,', 'Ġcount', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['Digest', 'Ġ.', 'ĠView', 'Ġ(', 'Ġsvc', 'Ġ,', 'Ġbasenode', 'Ġ,', 'Ġroute', 'Ġ,', 'Ġsession', 'Ġ,', 'Ġhas_perm', 'Ġ,', 'Ġstart', 'Ġ,', 'Ġcount', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "svc . writedata ( json . dumps ( result ) ) \n"
Original    (012): ['svc', '.', 'writedata', '(', 'json', '.', 'dumps', '(', 'result', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'sv', 'c', 'Ġ.', 'Ġwrit', 'ed', 'ata', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['sv', 'c', 'Ġ.', 'Ġwrit', 'ed', 'ata', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['svc', 'Ġ.', 'Ġwritedata', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "postinfo = Post . Post ( item . realpath ( ) , None ) \n"
Original    (015): ['postinfo', '=', 'Post', '.', 'Post', '(', 'item', '.', 'realpath', '(', ')', ',', 'None', ')', '\\n']
Tokenized   (020): ['<s>', 'post', 'info', 'Ġ=', 'ĠPost', 'Ġ.', 'ĠPost', 'Ġ(', 'Ġitem', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['post', 'info', 'Ġ=', 'ĠPost', 'Ġ.', 'ĠPost', 'Ġ(', 'Ġitem', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['postinfo', 'Ġ=', 'ĠPost', 'Ġ.', 'ĠPost', 'Ġ(', 'Ġitem', 'Ġ.', 'Ġrealpath', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "msg_count = msgbox . GetMsgCount ( all = False ) \n"
Original    (011): ['msg_count', '=', 'msgbox', '.', 'GetMsgCount', '(', 'all', '=', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'msg', '_', 'count', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠGet', 'Msg', 'Count', 'Ġ(', 'Ġall', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['msg', '_', 'count', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠGet', 'Msg', 'Count', 'Ġ(', 'Ġall', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['msg_count', 'Ġ=', 'Ġmsgbox', 'Ġ.', 'ĠGetMsgCount', 'Ġ(', 'Ġall', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "xmpp_read = self . rosters . get_xmpp_read ( self . _user . GetUID ( ) ) \n"
Original    (017): ['xmpp_read', '=', 'self', '.', 'rosters', '.', 'get_xmpp_read', '(', 'self', '.', '_user', '.', 'GetUID', '(', ')', ')', '\\n']
Tokenized   (032): ['<s>', 'x', 'm', 'pp', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'x', 'm', 'pp', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'user', 'Ġ.', 'ĠGet', 'UID', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['x', 'm', 'pp', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'x', 'm', 'pp', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'user', 'Ġ.', 'ĠGet', 'UID', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['xmpp_read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget_xmpp_read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_user', 'Ġ.', 'ĠGetUID', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "read_count = msg_count - msg_unread \n"
Original    (006): ['read_count', '=', 'msg_count', '-', 'msg_unread', '\\n']
Tokenized   (016): ['<s>', 'read', '_', 'count', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ-', 'Ġmsg', '_', 'un', 'read', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['read', '_', 'count', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ-', 'Ġmsg', '_', 'un', 'read', 'Ġ\\', 'n']
Detokenized (006): ['read_count', 'Ġ=', 'Ġmsg_count', 'Ġ-', 'Ġmsg_unread', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "term_read = self . rosters . get_term_read ( self . get_uid ( ) ) \n"
Original    (015): ['term_read', '=', 'self', '.', 'rosters', '.', 'get_term_read', '(', 'self', '.', 'get_uid', '(', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'term', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'term', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', '_', 'uid', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['term', '_', 'read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', '_', 'term', '_', 'read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', '_', 'uid', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['term_read', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget_term_read', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget_uid', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "new_unread [ msghead . topid ] = i \n"
Original    (009): ['new_unread', '[', 'msghead', '.', 'topid', ']', '=', 'i', '\\n']
Tokenized   (017): ['<s>', 'new', '_', 'un', 'read', 'Ġ[', 'Ġmsg', 'head', 'Ġ.', 'Ġtop', 'id', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['new', '_', 'un', 'read', 'Ġ[', 'Ġmsg', 'head', 'Ġ.', 'Ġtop', 'id', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n']
Detokenized (009): ['new_unread', 'Ġ[', 'Ġmsghead', 'Ġ.', 'Ġtopid', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "to_steal = { } \n"
Original    (005): ['to_steal', '=', '{', '}', '\\n']
Tokenized   (011): ['<s>', 'to', '_', 'st', 'eal', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['to', '_', 'st', 'eal', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n']
Detokenized (005): ['to_steal', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "to_steal_begin = msg_count \n"
Original    (004): ['to_steal_begin', '=', 'msg_count', '\\n']
Tokenized   (014): ['<s>', 'to', '_', 'st', 'eal', '_', 'begin', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['to', '_', 'st', 'eal', '_', 'begin', 'Ġ=', 'Ġmsg', '_', 'count', 'Ġ\\', 'n']
Detokenized (004): ['to_steal_begin', 'Ġ=', 'Ġmsg_count', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "pass \n"
Original    (002): ['pass', '\\n']
Tokenized   (005): ['<s>', 'pass', 'Ġ\\', 'n', '</s>']
Filtered   (003): ['pass', 'Ġ\\', 'n']
Detokenized (002): ['pass', 'Ġ\\n']
Counter: 3
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "final_unread [ pid ] = ( new_unread [ pid ] , 1 ) \n"
Original    (014): ['final_unread', '[', 'pid', ']', '=', '(', 'new_unread', '[', 'pid', ']', ',', '1', ')', '\\n']
Tokenized   (023): ['<s>', 'final', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['final', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', '_', 'un', 'read', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['final_unread', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew_unread', 'Ġ[', 'Ġpid', 'Ġ]', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "msgtext = msgbox . LoadMsgText ( msghead ) \n"
Original    (009): ['msgtext', '=', 'msgbox', '.', 'LoadMsgText', '(', 'msghead', ')', '\\n']
Tokenized   (017): ['<s>', 'msg', 'text', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠLoad', 'Msg', 'Text', 'Ġ(', 'Ġmsg', 'head', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['msg', 'text', 'Ġ=', 'Ġmsg', 'box', 'Ġ.', 'ĠLoad', 'Msg', 'Text', 'Ġ(', 'Ġmsg', 'head', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['msgtext', 'Ġ=', 'Ġmsgbox', 'Ġ.', 'ĠLoadMsgText', 'Ġ(', 'Ġmsghead', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "roster = self . rosters . get ( self ) \n"
Original    (011): ['roster', '=', 'self', '.', 'rosters', '.', 'get', '(', 'self', ')', '\\n']
Tokenized   (015): ['<s>', 'ro', 'ster', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ro', 'ster', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['roster', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrosters', 'Ġ.', 'Ġget', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "PYTHON_VERSION = sys . version_info [ : 3 ] \n"
Original    (010): ['PYTHON_VERSION', '=', 'sys', '.', 'version_info', '[', ':', '3', ']', '\\n']
Tokenized   (020): ['<s>', 'P', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġversion', '_', 'info', 'Ġ[', 'Ġ:', 'Ġ3', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['P', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġversion', '_', 'info', 'Ġ[', 'Ġ:', 'Ġ3', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['PYTHON_VERSION', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġversion_info', 'Ġ[', 'Ġ:', 'Ġ3', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "PY2 = ( PYTHON_VERSION [ 0 ] == 2 ) \n"
Original    (011): ['PY2', '=', '(', 'PYTHON_VERSION', '[', '0', ']', '==', '2', ')', '\\n']
Tokenized   (021): ['<s>', 'P', 'Y', '2', 'Ġ=', 'Ġ(', 'ĠP', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['P', 'Y', '2', 'Ġ=', 'Ġ(', 'ĠP', 'Y', 'TH', 'ON', '_', 'VERSION', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['PY2', 'Ġ=', 'Ġ(', 'ĠPYTHON_VERSION', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "sp_desc , \n"
Original    (003): ['sp_desc', ',', '\\n']
Tokenized   (008): ['<s>', 'sp', '_', 'desc', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['sp', '_', 'desc', 'Ġ,', 'Ġ\\', 'n']
Detokenized (003): ['sp_desc', 'Ġ,', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "con = hpov . connection ( args . host ) \n"
Original    (011): ['con', '=', 'hpov', '.', 'connection', '(', 'args', '.', 'host', ')', '\\n']
Tokenized   (015): ['<s>', 'con', 'Ġ=', 'Ġhp', 'ov', 'Ġ.', 'Ġconnection', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġhost', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['con', 'Ġ=', 'Ġhp', 'ov', 'Ġ.', 'Ġconnection', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġhost', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['con', 'Ġ=', 'Ġhpov', 'Ġ.', 'Ġconnection', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġhost', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "acceptEULA ( con ) \n"
Original    (005): ['acceptEULA', '(', 'con', ')', '\\n']
Tokenized   (011): ['<s>', 'accept', 'E', 'UL', 'A', 'Ġ(', 'Ġcon', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['accept', 'E', 'UL', 'A', 'Ġ(', 'Ġcon', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['acceptEULA', 'Ġ(', 'Ġcon', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "fw_settings = profile . make_firmware_dict ( sts , args . baseline ) \n"
Original    (013): ['fw_settings', '=', 'profile', '.', 'make_firmware_dict', '(', 'sts', ',', 'args', '.', 'baseline', ')', '\\n']
Tokenized   (024): ['<s>', 'fw', '_', 'settings', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'f', 'irm', 'ware', '_', 'dict', 'Ġ(', 'Ġsts', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġbaseline', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['fw', '_', 'settings', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'f', 'irm', 'ware', '_', 'dict', 'Ġ(', 'Ġsts', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġbaseline', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['fw_settings', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake_firmware_dict', 'Ġ(', 'Ġsts', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġbaseline', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "boot , bootmode = profile . make_boot_settings_dict ( srv , sht , args . disable_manage_boot , \n"
Original    (017): ['boot', ',', 'bootmode', '=', 'profile', '.', 'make_boot_settings_dict', '(', 'srv', ',', 'sht', ',', 'args', '.', 'disable_manage_boot', ',', '\\n']
Tokenized   (034): ['<s>', 'boot', 'Ġ,', 'Ġboot', 'mode', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'boot', '_', 'settings', '_', 'dict', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġsh', 't', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġdisable', '_', 'man', 'age', '_', 'boot', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['boot', 'Ġ,', 'Ġboot', 'mode', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake', '_', 'boot', '_', 'settings', '_', 'dict', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġsh', 't', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġdisable', '_', 'man', 'age', '_', 'boot', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['boot', 'Ġ,', 'Ġbootmode', 'Ġ=', 'Ġprofile', 'Ġ.', 'Ġmake_boot_settings_dict', 'Ġ(', 'Ġsrv', 'Ġ,', 'Ġsht', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġdisable_manage_boot', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "define_profile_template ( srv , \n"
Original    (005): ['define_profile_template', '(', 'srv', ',', '\\n']
Tokenized   (013): ['<s>', 'define', '_', 'profile', '_', 'template', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['define', '_', 'profile', '_', 'template', 'Ġ(', 'Ġsr', 'v', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['define_profile_template', 'Ġ(', 'Ġsrv', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "sht [ ] , \n"
Original    (005): ['sht', '[', ']', ',', '\\n']
Tokenized   (009): ['<s>', 'sh', 't', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['sh', 't', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['sht', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "credential = { : args . domain . upper ( ) , : args . user , : args . passwd } \n"
Original    (023): ['credential', '=', '{', ':', 'args', '.', 'domain', '.', 'upper', '(', ')', ',', ':', 'args', '.', 'user', ',', ':', 'args', '.', 'passwd', '}', '\\n']
Tokenized   (029): ['<s>', 'c', 'red', 'ential', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġdomain', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġuser', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġpass', 'wd', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['c', 'red', 'ential', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġdomain', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġuser', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġpass', 'wd', 'Ġ}', 'Ġ\\', 'n']
Detokenized (023): ['credential', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġdomain', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġuser', 'Ġ,', 'Ġ:', 'Ġargs', 'Ġ.', 'Ġpasswd', 'Ġ}', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "get_address_pools ( con , srv , args . types ) \n"
Original    (011): ['get_address_pools', '(', 'con', ',', 'srv', ',', 'args', '.', 'types', ')', '\\n']
Tokenized   (020): ['<s>', 'get', '_', 'address', '_', 'pool', 's', 'Ġ(', 'Ġcon', 'Ġ,', 'Ġsr', 'v', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġtypes', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['get', '_', 'address', '_', 'pool', 's', 'Ġ(', 'Ġcon', 'Ġ,', 'Ġsr', 'v', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġtypes', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['get_address_pools', 'Ġ(', 'Ġcon', 'Ġ,', 'Ġsrv', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġtypes', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "enclosure_group = None , server_profile = None ) : \n"
Original    (010): ['enclosure_group', '=', 'None', ',', 'server_profile', '=', 'None', ')', ':', '\\n']
Tokenized   (018): ['<s>', 'en', 'closure', '_', 'group', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġserver', '_', 'profile', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['en', 'closure', '_', 'group', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġserver', '_', 'profile', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (010): ['enclosure_group', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġserver_profile', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "biosSettings = None , \n"
Original    (005): ['biosSettings', '=', 'None', ',', '\\n']
Tokenized   (010): ['<s>', 'b', 'ios', 'Settings', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['b', 'ios', 'Settings', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['biosSettings', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "macType = , \n"
Original    (004): ['macType', '=', ',', '\\n']
Tokenized   (008): ['<s>', 'mac', 'Type', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['mac', 'Type', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['macType', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "localStorageSettingsV3 , macType , name , \n"
Original    (007): ['localStorageSettingsV3', ',', 'macType', ',', 'name', ',', '\\n']
Tokenized   (015): ['<s>', 'local', 'Storage', 'Settings', 'V', '3', 'Ġ,', 'Ġmac', 'Type', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['local', 'Storage', 'Settings', 'V', '3', 'Ġ,', 'Ġmac', 'Type', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['localStorageSettingsV3', 'Ġ,', 'ĠmacType', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "sanStorageV3 , serialNumber , \n"
Original    (005): ['sanStorageV3', ',', 'serialNumber', ',', '\\n']
Tokenized   (012): ['<s>', 'san', 'Storage', 'V', '3', 'Ġ,', 'Ġserial', 'Number', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['san', 'Storage', 'V', '3', 'Ġ,', 'Ġserial', 'Number', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['sanStorageV3', 'Ġ,', 'ĠserialNumber', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "serverProfileTemplateUri , uuid , wwnType ) \n"
Original    (007): ['serverProfileTemplateUri', ',', 'uuid', ',', 'wwnType', ')', '\\n']
Tokenized   (017): ['<s>', 'server', 'Profile', 'Template', 'U', 'ri', 'Ġ,', 'Ġu', 'uid', 'Ġ,', 'Ġw', 'wn', 'Type', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['server', 'Profile', 'Template', 'U', 'ri', 'Ġ,', 'Ġu', 'uid', 'Ġ,', 'Ġw', 'wn', 'Type', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['serverProfileTemplateUri', 'Ġ,', 'Ġuuid', 'Ġ,', 'ĠwwnType', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "profile_template = self . _con . get ( entity [ ] ) \n"
Original    (013): ['profile_template', '=', 'self', '.', '_con', '.', 'get', '(', 'entity', '[', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'profile', '_', 'template', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'con', 'Ġ.', 'Ġget', 'Ġ(', 'Ġentity', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['profile', '_', 'template', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'con', 'Ġ.', 'Ġget', 'Ġ(', 'Ġentity', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['profile_template', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_con', 'Ġ.', 'Ġget', 'Ġ(', 'Ġentity', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "powerMode = ) : \n"
Original    (005): ['powerMode', '=', ')', ':', '\\n']
Tokenized   (009): ['<s>', 'power', 'Mode', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['power', 'Mode', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (005): ['powerMode', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "egroup = make_EnclosureGroupV200 ( associatedLIGs , name , powerMode ) \n"
Original    (011): ['egroup', '=', 'make_EnclosureGroupV200', '(', 'associatedLIGs', ',', 'name', ',', 'powerMode', ')', '\\n']
Tokenized   (025): ['<s>', 'eg', 'roup', 'Ġ=', 'Ġmake', '_', 'En', 'closure', 'Group', 'V', '200', 'Ġ(', 'Ġassociated', 'L', 'IG', 's', 'Ġ,', 'Ġname', 'Ġ,', 'Ġpower', 'Mode', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['eg', 'roup', 'Ġ=', 'Ġmake', '_', 'En', 'closure', 'Group', 'V', '200', 'Ġ(', 'Ġassociated', 'L', 'IG', 's', 'Ġ,', 'Ġname', 'Ġ,', 'Ġpower', 'Mode', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['egroup', 'Ġ=', 'Ġmake_EnclosureGroupV200', 'Ġ(', 'ĠassociatedLIGs', 'Ġ,', 'Ġname', 'Ġ,', 'ĠpowerMode', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "allocatorBody = { : count } \n"
Original    (007): ['allocatorBody', '=', '{', ':', 'count', '}', '\\n']
Tokenized   (012): ['<s>', 'alloc', 'ator', 'Body', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġcount', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['alloc', 'ator', 'Body', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġcount', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['allocatorBody', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġcount', 'Ġ}', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "prange [ ] = False \n"
Original    (006): ['prange', '[', ']', '=', 'False', '\\n']
Tokenized   (010): ['<s>', 'pr', 'ange', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['pr', 'ange', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (006): ['prange', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠFalse', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tempstr = "hp-rest-classes-bios-" + romfamily + "-" + biosversion \n"
Original    (010): ['tempstr', '=', '"hp-rest-classes-bios-"', '+', 'romfamily', '+', '"-"', '+', 'biosversion', '\\n']
Tokenized   (026): ['<s>', 'temp', 'str', 'Ġ=', 'Ġ"', 'hp', '-', 'rest', '-', 'classes', '-', 'b', 'ios', '-"', 'Ġ+', 'Ġrom', 'family', 'Ġ+', 'Ġ"', '-"', 'Ġ+', 'Ġbios', 'version', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['temp', 'str', 'Ġ=', 'Ġ"', 'hp', '-', 'rest', '-', 'classes', '-', 'b', 'ios', '-"', 'Ġ+', 'Ġrom', 'family', 'Ġ+', 'Ġ"', '-"', 'Ġ+', 'Ġbios', 'version', 'Ġ\\', 'n']
Detokenized (010): ['tempstr', 'Ġ=', 'Ġ"hp-rest-classes-bios-"', 'Ġ+', 'Ġromfamily', 'Ġ+', 'Ġ"-"', 'Ġ+', 'Ġbiosversion', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "monolith = None ) : \n"
Original    (006): ['monolith', '=', 'None', ')', ':', '\\n']
Tokenized   (010): ['<s>', 'mon', 'olith', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['mon', 'olith', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['monolith', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "pathjoinstr ) ) : \n"
Original    (005): ['pathjoinstr', ')', ')', ':', '\\n']
Tokenized   (010): ['<s>', 'path', 'join', 'str', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['path', 'join', 'str', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (005): ['pathjoinstr', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "newclass . set_root ( root ) \n"
Original    (007): ['newclass', '.', 'set_root', '(', 'root', ')', '\\n']
Tokenized   (013): ['<s>', 'new', 'class', 'Ġ.', 'Ġset', '_', 'root', 'Ġ(', 'Ġroot', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['new', 'class', 'Ġ.', 'Ġset', '_', 'root', 'Ġ(', 'Ġroot', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['newclass', 'Ġ.', 'Ġset_root', 'Ġ(', 'Ġroot', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "folderentries = data [ "links" ] \n"
Original    (007): ['folderentries', '=', 'data', '[', '"links"', ']', '\\n']
Tokenized   (014): ['<s>', 'fold', 'erent', 'ries', 'Ġ=', 'Ġdata', 'Ġ[', 'Ġ"', 'links', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['fold', 'erent', 'ries', 'Ġ=', 'Ġdata', 'Ġ[', 'Ġ"', 'links', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['folderentries', 'Ġ=', 'Ġdata', 'Ġ[', 'Ġ"links"', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "datareturn . append ( self . load_file ( fqpath , root = root , biossection = True , registries = True , datareturn = True ) ) \n"
Original    (028): ['datareturn', '.', 'append', '(', 'self', '.', 'load_file', '(', 'fqpath', ',', 'root', '=', 'root', ',', 'biossection', '=', 'True', ',', 'registries', '=', 'True', ',', 'datareturn', '=', 'True', ')', ')', '\\n']
Tokenized   (041): ['<s>', 'dat', 'aret', 'urn', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġload', '_', 'file', 'Ġ(', 'Ġf', 'q', 'path', 'Ġ,', 'Ġroot', 'Ġ=', 'Ġroot', 'Ġ,', 'Ġbios', 'section', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġregist', 'ries', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġdat', 'aret', 'urn', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['dat', 'aret', 'urn', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġload', '_', 'file', 'Ġ(', 'Ġf', 'q', 'path', 'Ġ,', 'Ġroot', 'Ġ=', 'Ġroot', 'Ġ,', 'Ġbios', 'section', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġregist', 'ries', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġdat', 'aret', 'urn', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (028): ['datareturn', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġload_file', 'Ġ(', 'Ġfqpath', 'Ġ,', 'Ġroot', 'Ġ=', 'Ġroot', 'Ġ,', 'Ġbiossection', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġregistries', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġdatareturn', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "currdict = currdict , monolith = monolith , \n"
Original    (009): ['currdict', '=', 'currdict', ',', 'monolith', '=', 'monolith', ',', '\\n']
Tokenized   (018): ['<s>', 'cur', 'rd', 'ict', 'Ġ=', 'Ġcur', 'rd', 'ict', 'Ġ,', 'Ġmon', 'olith', 'Ġ=', 'Ġmon', 'olith', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['cur', 'rd', 'ict', 'Ġ=', 'Ġcur', 'rd', 'ict', 'Ġ,', 'Ġmon', 'olith', 'Ġ=', 'Ġmon', 'olith', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['currdict', 'Ġ=', 'Ġcurrdict', 'Ġ,', 'Ġmonolith', 'Ġ=', 'Ġmonolith', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newarg = newarg , checkall = checkall ) \n"
Original    (009): ['newarg', '=', 'newarg', ',', 'checkall', '=', 'checkall', ')', '\\n']
Tokenized   (016): ['<s>', 'new', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ,', 'Ġcheck', 'all', 'Ġ=', 'Ġcheck', 'all', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['new', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ,', 'Ġcheck', 'all', 'Ġ=', 'Ġcheck', 'all', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['newarg', 'Ġ=', 'Ġnewarg', 'Ġ,', 'Ġcheckall', 'Ġ=', 'Ġcheckall', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "attrreg = self . find_bios_registry ( regname = regname ) \n"
Original    (011): ['attrreg', '=', 'self', '.', 'find_bios_registry', '(', 'regname', '=', 'regname', ')', '\\n']
Tokenized   (023): ['<s>', 'attr', 'reg', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfind', '_', 'b', 'ios', '_', 'reg', 'istry', 'Ġ(', 'Ġreg', 'name', 'Ġ=', 'Ġreg', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['attr', 'reg', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfind', '_', 'b', 'ios', '_', 'reg', 'istry', 'Ġ(', 'Ġreg', 'name', 'Ġ=', 'Ġreg', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['attrreg', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfind_bios_registry', 'Ġ(', 'Ġregname', 'Ġ=', 'Ġregname', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "schlink = schlink [ len ( schlink ) - 2 ] \n"
Original    (012): ['schlink', '=', 'schlink', '[', 'len', '(', 'schlink', ')', '-', '2', ']', '\\n']
Tokenized   (018): ['<s>', 'sch', 'link', 'Ġ=', 'Ġsch', 'link', 'Ġ[', 'Ġlen', 'Ġ(', 'Ġsch', 'link', 'Ġ)', 'Ġ-', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['sch', 'link', 'Ġ=', 'Ġsch', 'link', 'Ġ[', 'Ġlen', 'Ġ(', 'Ġsch', 'link', 'Ġ)', 'Ġ-', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['schlink', 'Ġ=', 'Ġschlink', 'Ġ[', 'Ġlen', 'Ġ(', 'Ġschlink', 'Ġ)', 'Ġ-', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "schname . lower ( ) ) : \n"
Original    (008): ['schname', '.', 'lower', '(', ')', ')', ':', '\\n']
Tokenized   (013): ['<s>', 's', 'chn', 'ame', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['s', 'chn', 'ame', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['schname', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "xref = os . path . normpath ( currloc . Uri . extref ) . lstrip ( os . path . sep ) \n"
Original    (024): ['xref', '=', 'os', '.', 'path', '.', 'normpath', '(', 'currloc', '.', 'Uri', '.', 'extref', ')', '.', 'lstrip', '(', 'os', '.', 'path', '.', 'sep', ')', '\\n']
Tokenized   (033): ['<s>', 'x', 'ref', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġnorm', 'path', 'Ġ(', 'Ġcur', 'r', 'loc', 'Ġ.', 'ĠUri', 'Ġ.', 'Ġext', 'ref', 'Ġ)', 'Ġ.', 'Ġl', 'strip', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['x', 'ref', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġnorm', 'path', 'Ġ(', 'Ġcur', 'r', 'loc', 'Ġ.', 'ĠUri', 'Ġ.', 'Ġext', 'ref', 'Ġ)', 'Ġ.', 'Ġl', 'strip', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['xref', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġnormpath', 'Ġ(', 'Ġcurrloc', 'Ġ.', 'ĠUri', 'Ġ.', 'Ġextref', 'Ġ)', 'Ġ.', 'Ġlstrip', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "fqpath = os . path . join ( root , xref ) \n"
Original    (013): ['fqpath', '=', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'xref', ')', '\\n']
Tokenized   (019): ['<s>', 'f', 'q', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġx', 'ref', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['f', 'q', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġx', 'ref', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['fqpath', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġxref', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "langcode = list ( locale . getdefaultlocale ( ) ) \n"
Original    (011): ['langcode', '=', 'list', '(', 'locale', '.', 'getdefaultlocale', '(', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'lang', 'code', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġlocale', 'Ġ.', 'Ġget', 'default', 'loc', 'ale', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['lang', 'code', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġlocale', 'Ġ.', 'Ġget', 'default', 'loc', 'ale', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['langcode', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġlocale', 'Ġ.', 'Ġgetdefaultlocale', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "locationlanguage = locationlanguage . replace ( "-" , "_" ) \n"
Original    (011): ['locationlanguage', '=', 'locationlanguage', '.', 'replace', '(', '"-"', ',', '"_"', ')', '\\n']
Tokenized   (018): ['<s>', 'location', 'language', 'Ġ=', 'Ġlocation', 'language', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '-"', 'Ġ,', 'Ġ"_', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['location', 'language', 'Ġ=', 'Ġlocation', 'language', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '-"', 'Ġ,', 'Ġ"_', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['locationlanguage', 'Ġ=', 'Ġlocationlanguage', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"-"', 'Ġ,', 'Ġ"_"', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "currtype = currtype . split ( ) [ 0 ] + \n"
Original    (012): ['currtype', '=', 'currtype', '.', 'split', '(', ')', '[', '0', ']', '+', '\\n']
Tokenized   (019): ['<s>', 'cur', 'r', 'type', 'Ġ=', 'Ġcur', 'r', 'type', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['cur', 'r', 'type', 'Ġ=', 'Ġcur', 'r', 'type', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n']
Detokenized (012): ['currtype', 'Ġ=', 'Ġcurrtype', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "insttype = instance . resp . dict [ "title" ] . split ( ) [ : 1 ] \n"
Original    (019): ['insttype', '=', 'instance', '.', 'resp', '.', 'dict', '[', '"title"', ']', '.', 'split', '(', ')', '[', ':', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'inst', 'type', 'Ġ=', 'Ġinstance', 'Ġ.', 'Ġresp', 'Ġ.', 'Ġdict', 'Ġ[', 'Ġ"', 'title', '"', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['inst', 'type', 'Ġ=', 'Ġinstance', 'Ġ.', 'Ġresp', 'Ġ.', 'Ġdict', 'Ġ[', 'Ġ"', 'title', '"', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (019): ['insttype', 'Ġ=', 'Ġinstance', 'Ġ.', 'Ġresp', 'Ġ.', 'Ġdict', 'Ġ[', 'Ġ"title"', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "nextarg = newarg [ newarg . index ( arg ) + 1 ] \n"
Original    (014): ['nextarg', '=', 'newarg', '[', 'newarg', '.', 'index', '(', 'arg', ')', '+', '1', ']', '\\n']
Tokenized   (020): ['<s>', 'next', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ[', 'Ġnew', 'arg', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['next', 'arg', 'Ġ=', 'Ġnew', 'arg', 'Ġ[', 'Ġnew', 'arg', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['nextarg', 'Ġ=', 'Ġnewarg', 'Ġ[', 'Ġnewarg', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "regcopy [ nextarg ] = patterninfo \n"
Original    (007): ['regcopy', '[', 'nextarg', ']', '=', 'patterninfo', '\\n']
Tokenized   (013): ['<s>', 'reg', 'copy', 'Ġ[', 'Ġnext', 'arg', 'Ġ]', 'Ġ=', 'Ġpattern', 'info', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['reg', 'copy', 'Ġ[', 'Ġnext', 'arg', 'Ġ]', 'Ġ=', 'Ġpattern', 'info', 'Ġ\\', 'n']
Detokenized (007): ['regcopy', 'Ġ[', 'Ġnextarg', 'Ġ]', 'Ġ=', 'Ġpatterninfo', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "validictory . validate ( tdict , jsonsch ) \n"
Original    (009): ['validictory', '.', 'validate', '(', 'tdict', ',', 'jsonsch', ')', '\\n']
Tokenized   (017): ['<s>', 'valid', 'ict', 'ory', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġt', 'dict', 'Ġ,', 'Ġjs', 'ons', 'ch', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['valid', 'ict', 'ory', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġt', 'dict', 'Ġ,', 'Ġjs', 'ons', 'ch', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['validictory', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġtdict', 'Ġ,', 'Ġjsonsch', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "wrapper . subsequent_indent = * 4 \n"
Original    (007): ['wrapper', '.', 'subsequent_indent', '=', '*', '4', '\\n']
Tokenized   (013): ['<s>', 'wrapper', 'Ġ.', 'Ġsubsequent', '_', 'ind', 'ent', 'Ġ=', 'Ġ*', 'Ġ4', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['wrapper', 'Ġ.', 'Ġsubsequent', '_', 'ind', 'ent', 'Ġ=', 'Ġ*', 'Ġ4', 'Ġ\\', 'n']
Detokenized (007): ['wrapper', 'Ġ.', 'Ġsubsequent_indent', 'Ġ=', 'Ġ*', 'Ġ4', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "RegistryValidationError ( \n"
Original    (003): ['RegistryValidationError', '(', '\\n']
Tokenized   (010): ['<s>', 'Reg', 'istry', 'Val', 'idation', 'Error', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Reg', 'istry', 'Val', 'idation', 'Error', 'Ġ(', 'Ġ\\', 'n']
Detokenized (003): ['RegistryValidationError', 'Ġ(', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "regentry = self \n"
Original    (004): ['regentry', '=', 'self', '\\n']
Tokenized   (008): ['<s>', 'reg', 'entry', 'Ġ=', 'Ġself', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['reg', 'entry', 'Ġ=', 'Ġself', 'Ġ\\', 'n']
Detokenized (004): ['regentry', 'Ġ=', 'Ġself', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""\'%(ValueExpression)s\'" % ( self ) , regentry = self ) ) \n"
Original    (012): ['"\\\'%(ValueExpression)s\\\'"', '%', '(', 'self', ')', ',', 'regentry', '=', 'self', ')', ')', '\\n']
Tokenized   (026): ['<s>', '"', "\\'", '%', '(', 'Value', 'Exp', 'ression', ')', 's', '\\', '\'"', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ,', 'Ġreg', 'entry', 'Ġ=', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', "\\'", '%', '(', 'Value', 'Exp', 'ression', ')', 's', '\\', '\'"', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ,', 'Ġreg', 'entry', 'Ġ=', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['"\\\'%(ValueExpression)s\\\'"', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ,', 'Ġregentry', 'Ġ=', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "intval = int ( newval ) \n"
Original    (007): ['intval', '=', 'int', '(', 'newval', ')', '\\n']
Tokenized   (012): ['<s>', 'int', 'val', 'Ġ=', 'Ġint', 'Ġ(', 'Ġnew', 'val', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['int', 'val', 'Ġ=', 'Ġint', 'Ġ(', 'Ġnew', 'val', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['intval', 'Ġ=', 'Ġint', 'Ġ(', 'Ġnewval', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "MICROS_TRANSLATIONS = ( \n"
Original    (004): ['MICROS_TRANSLATIONS', '=', '(', '\\n']
Tokenized   (014): ['<s>', 'MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġ=', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġ=', 'Ġ(', 'Ġ\\', 'n']
Detokenized (004): ['MICROS_TRANSLATIONS', 'Ġ=', 'Ġ(', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "MICROS_TRANSLATION_HASH = dict ( ( alt , v ) for k , v in MICROS_TRANSLATIONS for alt in k ) \n"
Original    (021): ['MICROS_TRANSLATION_HASH', '=', 'dict', '(', '(', 'alt', ',', 'v', ')', 'for', 'k', ',', 'v', 'in', 'MICROS_TRANSLATIONS', 'for', 'alt', 'in', 'k', ')', '\\n']
Tokenized   (041): ['<s>', 'MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATION', '_', 'H', 'ASH', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġalt', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'ĠMIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġfor', 'Ġalt', 'Ġin', 'Ġk', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['MIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATION', '_', 'H', 'ASH', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġalt', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'ĠMIC', 'R', 'OS', '_', 'TR', 'AN', 'SL', 'ATIONS', 'Ġfor', 'Ġalt', 'Ġin', 'Ġk', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['MICROS_TRANSLATION_HASH', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġalt', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'ĠMICROS_TRANSLATIONS', 'Ġfor', 'Ġalt', 'Ġin', 'Ġk', 'Ġ)', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "epoch_milliseconds = epoch_millis = milliseconds = millis = ms \n"
Original    (010): ['epoch_milliseconds', '=', 'epoch_millis', '=', 'milliseconds', '=', 'millis', '=', 'ms', '\\n']
Tokenized   (022): ['<s>', 'ep', 'och', '_', 'mill', 'isec', 'onds', 'Ġ=', 'Ġepoch', '_', 'mill', 'is', 'Ġ=', 'Ġmilliseconds', 'Ġ=', 'Ġmill', 'is', 'Ġ=', 'Ġms', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['ep', 'och', '_', 'mill', 'isec', 'onds', 'Ġ=', 'Ġepoch', '_', 'mill', 'is', 'Ġ=', 'Ġmilliseconds', 'Ġ=', 'Ġmill', 'is', 'Ġ=', 'Ġms', 'Ġ\\', 'n']
Detokenized (010): ['epoch_milliseconds', 'Ġ=', 'Ġepoch_millis', 'Ġ=', 'Ġmilliseconds', 'Ġ=', 'Ġmillis', 'Ġ=', 'Ġms', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "epoch_microseconds = epoch_micros = microseconds = micros \n"
Original    (008): ['epoch_microseconds', '=', 'epoch_micros', '=', 'microseconds', '=', 'micros', '\\n']
Tokenized   (020): ['<s>', 'ep', 'och', '_', 'micro', 'seconds', 'Ġ=', 'Ġepoch', '_', 'micro', 's', 'Ġ=', 'Ġmicro', 'seconds', 'Ġ=', 'Ġmicro', 's', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['ep', 'och', '_', 'micro', 'seconds', 'Ġ=', 'Ġepoch', '_', 'micro', 's', 'Ġ=', 'Ġmicro', 'seconds', 'Ġ=', 'Ġmicro', 's', 'Ġ\\', 'n']
Detokenized (008): ['epoch_microseconds', 'Ġ=', 'Ġepoch_micros', 'Ġ=', 'Ġmicroseconds', 'Ġ=', 'Ġmicros', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "micros = u".%06d" % dt . microsecond if dt . microsecond else \n"
Original    (013): ['micros', '=', 'u".%06d"', '%', 'dt', '.', 'microsecond', 'if', 'dt', '.', 'microsecond', 'else', '\\n']
Tokenized   (026): ['<s>', 'micro', 's', 'Ġ=', 'Ġu', '".', '%', '06', 'd', '"', 'Ġ%', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġif', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġelse', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['micro', 's', 'Ġ=', 'Ġu', '".', '%', '06', 'd', '"', 'Ġ%', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġif', 'Ġd', 't', 'Ġ.', 'Ġmicro', 'second', 'Ġelse', 'Ġ\\', 'n']
Detokenized (013): ['micros', 'Ġ=', 'Ġu".%06d"', 'Ġ%', 'Ġdt', 'Ġ.', 'Ġmicrosecond', 'Ġif', 'Ġdt', 'Ġ.', 'Ġmicrosecond', 'Ġelse', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "datastore_owner_uuid = request . REQUEST [ "datastore_owner__uuid" ] \n"
Original    (009): ['datastore_owner_uuid', '=', 'request', '.', 'REQUEST', '[', '"datastore_owner__uuid"', ']', '\\n']
Tokenized   (029): ['<s>', 'dat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'dat', 'ast', 'ore', '_', 'owner', '__', 'uu', 'id', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['dat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'dat', 'ast', 'ore', '_', 'owner', '__', 'uu', 'id', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['datastore_owner_uuid', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġ[', 'Ġ"datastore_owner__uuid"', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "datastore_owner , ds_owner_created = Profile . objects . get_or_create ( uuid = datastore_owner_uuid ) \n"
Original    (015): ['datastore_owner', ',', 'ds_owner_created', '=', 'Profile', '.', 'objects', '.', 'get_or_create', '(', 'uuid', '=', 'datastore_owner_uuid', ')', '\\n']
Tokenized   (039): ['<s>', 'dat', 'ast', 'ore', '_', 'owner', 'Ġ,', 'Ġd', 's', '_', 'owner', '_', 'created', 'Ġ=', 'ĠProfile', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'or', '_', 'create', 'Ġ(', 'Ġu', 'uid', 'Ġ=', 'Ġdat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['dat', 'ast', 'ore', '_', 'owner', 'Ġ,', 'Ġd', 's', '_', 'owner', '_', 'created', 'Ġ=', 'ĠProfile', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'or', '_', 'create', 'Ġ(', 'Ġu', 'uid', 'Ġ=', 'Ġdat', 'ast', 'ore', '_', 'owner', '_', 'uu', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['datastore_owner', 'Ġ,', 'Ġds_owner_created', 'Ġ=', 'ĠProfile', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget_or_create', 'Ġ(', 'Ġuuid', 'Ġ=', 'Ġdatastore_owner_uuid', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "port = db . Column ( db . Integer , nullable = False ) \n"
Original    (015): ['port', '=', 'db', '.', 'Column', '(', 'db', '.', 'Integer', ',', 'nullable', '=', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'port', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['port', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['port', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnullable', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "eru_container_id = db . Column ( db . String ( 64 ) , index = True ) \n"
Original    (018): ['eru_container_id', '=', 'db', '.', 'Column', '(', 'db', '.', 'String', '(', '64', ')', ',', 'index', '=', 'True', ')', '\\n']
Tokenized   (026): ['<s>', 'er', 'u', '_', 'container', '_', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠString', 'Ġ(', 'Ġ64', 'Ġ)', 'Ġ,', 'Ġindex', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['er', 'u', '_', 'container', '_', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠString', 'Ġ(', 'Ġ64', 'Ġ)', 'Ġ,', 'Ġindex', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['eru_container_id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠString', 'Ġ(', 'Ġ64', 'Ġ)', 'Ġ,', 'Ġindex', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "suppress_alert = db . Column ( db . Integer , nullable = False , default = 1 ) \n"
Original    (019): ['suppress_alert', '=', 'db', '.', 'Column', '(', 'db', '.', 'Integer', ',', 'nullable', '=', 'False', ',', 'default', '=', '1', ')', '\\n']
Tokenized   (026): ['<s>', 'supp', 'ress', '_', 'alert', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['supp', 'ress', '_', 'alert', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['suppress_alert', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠInteger', 'Ġ,', 'Ġnullable', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "__table_args__ = ( db . Index ( , , , unique = True ) , ) \n"
Original    (017): ['__table_args__', '=', '(', 'db', '.', 'Index', '(', ',', ',', ',', 'unique', '=', 'True', ')', ',', ')', '\\n']
Tokenized   (024): ['<s>', '__', 'table', '_', 'args', '__', 'Ġ=', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠIndex', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['__', 'table', '_', 'args', '__', 'Ġ=', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠIndex', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['__table_args__', 'Ġ=', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠIndex', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "cluster_id = cluster_id ) \n"
Original    (005): ['cluster_id', '=', 'cluster_id', ')', '\\n']
Tokenized   (013): ['<s>', 'cl', 'uster', '_', 'id', 'Ġ=', 'Ġcluster', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['cl', 'uster', '_', 'id', 'Ġ=', 'Ġcluster', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['cluster_id', 'Ġ=', 'Ġcluster_id', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "Proxy . id . desc ( ) ) . offset ( offset ) . limit ( limit ) . all ( ) \n"
Original    (023): ['Proxy', '.', 'id', '.', 'desc', '(', ')', ')', '.', 'offset', '(', 'offset', ')', '.', 'limit', '(', 'limit', ')', '.', 'all', '(', ')', '\\n']
Tokenized   (026): ['<s>', 'Proxy', 'Ġ.', 'Ġid', 'Ġ.', 'Ġdesc', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġoffset', 'Ġ(', 'Ġoffset', 'Ġ)', 'Ġ.', 'Ġlimit', 'Ġ(', 'Ġlimit', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['Proxy', 'Ġ.', 'Ġid', 'Ġ.', 'Ġdesc', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġoffset', 'Ġ(', 'Ġoffset', 'Ġ)', 'Ġ.', 'Ġlimit', 'Ġ(', 'Ġlimit', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['Proxy', 'Ġ.', 'Ġid', 'Ġ.', 'Ġdesc', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġoffset', 'Ġ(', 'Ġoffset', 'Ġ)', 'Ġ.', 'Ġlimit', 'Ġ(', 'Ġlimit', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "iou_as_issuer . issue_funds ( amount_issued , ) \n"
Original    (008): ['iou_as_issuer', '.', 'issue_funds', '(', 'amount_issued', ',', ')', '\\n']
Tokenized   (022): ['<s>', 'i', 'ou', '_', 'as', '_', 'iss', 'uer', 'Ġ.', 'Ġissue', '_', 'fund', 's', 'Ġ(', 'Ġamount', '_', 'issued', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['i', 'ou', '_', 'as', '_', 'iss', 'uer', 'Ġ.', 'Ġissue', '_', 'fund', 's', 'Ġ(', 'Ġamount', '_', 'issued', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['iou_as_issuer', 'Ġ.', 'Ġissue_funds', 'Ġ(', 'Ġamount_issued', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "github_info_json = urllib2 . urlopen ( latest ) . read ( ) \n"
Original    (013): ['github_info_json', '=', 'urllib2', '.', 'urlopen', '(', 'latest', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'github', '_', 'info', '_', 'json', 'Ġ=', 'Ġur', 'll', 'ib', '2', 'Ġ.', 'Ġurl', 'open', 'Ġ(', 'Ġlatest', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['github', '_', 'info', '_', 'json', 'Ġ=', 'Ġur', 'll', 'ib', '2', 'Ġ.', 'Ġurl', 'open', 'Ġ(', 'Ġlatest', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['github_info_json', 'Ġ=', 'Ġurllib2', 'Ġ.', 'Ġurlopen', 'Ġ(', 'Ġlatest', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "drawing_tool . set_window_title ( update_notifier , watching_player = twitch_username , updates_queued = len ( new_states_queue ) , read_delay = opt . read_delay ) \n"
Original    (024): ['drawing_tool', '.', 'set_window_title', '(', 'update_notifier', ',', 'watching_player', '=', 'twitch_username', ',', 'updates_queued', '=', 'len', '(', 'new_states_queue', ')', ',', 'read_delay', '=', 'opt', '.', 'read_delay', ')', '\\n']
Tokenized   (052): ['<s>', 'draw', 'ing', '_', 'tool', 'Ġ.', 'Ġset', '_', 'window', '_', 'title', 'Ġ(', 'Ġupdate', '_', 'not', 'ifier', 'Ġ,', 'Ġwatching', '_', 'player', 'Ġ=', 'Ġtwitch', '_', 'username', 'Ġ,', 'Ġupdates', '_', 'que', 'ued', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnew', '_', 'states', '_', 'queue', 'Ġ)', 'Ġ,', 'Ġread', '_', 'delay', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġread', '_', 'delay', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (050): ['draw', 'ing', '_', 'tool', 'Ġ.', 'Ġset', '_', 'window', '_', 'title', 'Ġ(', 'Ġupdate', '_', 'not', 'ifier', 'Ġ,', 'Ġwatching', '_', 'player', 'Ġ=', 'Ġtwitch', '_', 'username', 'Ġ,', 'Ġupdates', '_', 'que', 'ued', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnew', '_', 'states', '_', 'queue', 'Ġ)', 'Ġ,', 'Ġread', '_', 'delay', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġread', '_', 'delay', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['drawing_tool', 'Ġ.', 'Ġset_window_title', 'Ġ(', 'Ġupdate_notifier', 'Ġ,', 'Ġwatching_player', 'Ġ=', 'Ġtwitch_username', 'Ġ,', 'Ġupdates_queued', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnew_states_queue', 'Ġ)', 'Ġ,', 'Ġread_delay', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġread_delay', 'Ġ)', 'Ġ\\n']
Counter: 50
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "put_url = opt . trackerserver_url + "/tracker/api/update/" + opt . trackerserver_authkey \n"
Original    (012): ['put_url', '=', 'opt', '.', 'trackerserver_url', '+', '"/tracker/api/update/"', '+', 'opt', '.', 'trackerserver_authkey', '\\n']
Tokenized   (033): ['<s>', 'put', '_', 'url', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'url', 'Ġ+', 'Ġ"/', 'tr', 'acker', '/', 'api', '/', 'update', '/"', 'Ġ+', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'auth', 'key', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['put', '_', 'url', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'url', 'Ġ+', 'Ġ"/', 'tr', 'acker', '/', 'api', '/', 'update', '/"', 'Ġ+', 'Ġopt', 'Ġ.', 'Ġtrack', 'ers', 'erver', '_', 'auth', 'key', 'Ġ\\', 'n']
Detokenized (012): ['put_url', 'Ġ=', 'Ġopt', 'Ġ.', 'Ġtrackerserver_url', 'Ġ+', 'Ġ"/tracker/api/update/"', 'Ġ+', 'Ġopt', 'Ġ.', 'Ġtrackerserver_authkey', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "json_string = json . dumps ( state , cls = TrackerStateEncoder , sort_keys = True ) \n"
Original    (017): ['json_string', '=', 'json', '.', 'dumps', '(', 'state', ',', 'cls', '=', 'TrackerStateEncoder', ',', 'sort_keys', '=', 'True', ')', '\\n']
Tokenized   (028): ['<s>', 'json', '_', 'string', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġstate', 'Ġ,', 'Ġcl', 's', 'Ġ=', 'ĠTracker', 'State', 'Enc', 'oder', 'Ġ,', 'Ġsort', '_', 'keys', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['json', '_', 'string', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġstate', 'Ġ,', 'Ġcl', 's', 'Ġ=', 'ĠTracker', 'State', 'Enc', 'oder', 'Ġ,', 'Ġsort', '_', 'keys', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['json_string', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġstate', 'Ġ,', 'Ġcls', 'Ġ=', 'ĠTrackerStateEncoder', 'Ġ,', 'Ġsort_keys', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "new_states_queue . pop ( 0 ) \n"
Original    (007): ['new_states_queue', '.', 'pop', '(', '0', ')', '\\n']
Tokenized   (014): ['<s>', 'new', '_', 'states', '_', 'queue', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['new', '_', 'states', '_', 'queue', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['new_states_queue', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "framecount += 1 \n"
Original    (004): ['framecount', '+=', '1', '\\n']
Tokenized   (008): ['<s>', 'frame', 'count', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['frame', 'count', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n']
Detokenized (004): ['framecount', 'Ġ+=', 'Ġ1', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "decay = decay , \n"
Original    (005): ['decay', '=', 'decay', ',', '\\n']
Tokenized   (009): ['<s>', 'dec', 'ay', 'Ġ=', 'Ġdecay', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['dec', 'ay', 'Ġ=', 'Ġdecay', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['decay', 'Ġ=', 'Ġdecay', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "expected_kwargs = { , } \n"
Original    (006): ['expected_kwargs', '=', '{', ',', '}', '\\n']
Tokenized   (012): ['<s>', 'expected', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['expected', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n']
Detokenized (006): ['expected_kwargs', 'Ġ=', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "outputs [ ] = in_shapes [ ] \n"
Original    (008): ['outputs', '[', ']', '=', 'in_shapes', '[', ']', '\\n']
Tokenized   (015): ['<s>', 'output', 's', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['output', 's', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['outputs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġin_shapes', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "buf = BufferStructure ( self . in_shapes [ ] . feature_shape [ - 1 ] ) \n"
Original    (017): ['buf', '=', 'BufferStructure', '(', 'self', '.', 'in_shapes', '[', ']', '.', 'feature_shape', '[', '-', '1', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'buf', 'Ġ=', 'ĠBuffer', 'St', 'ructure', 'Ġ(', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġfeature', '_', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['buf', 'Ġ=', 'ĠBuffer', 'St', 'ructure', 'Ġ(', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġfeature', '_', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['buf', 'Ġ=', 'ĠBufferStructure', 'Ġ(', 'Ġself', 'Ġ.', 'Ġin_shapes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġfeature_shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "internals [ ] = self . in_shapes [ ] \n"
Original    (010): ['internals', '[', ']', '=', 'self', '.', 'in_shapes', '[', ']', '\\n']
Tokenized   (017): ['<s>', 'intern', 'als', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['intern', 'als', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġin', '_', 'sh', 'apes', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['internals', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġin_shapes', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sigma_b , centered , x_hat = buffers . internals \n"
Original    (010): ['sigma_b', ',', 'centered', ',', 'x_hat', '=', 'buffers', '.', 'internals', '\\n']
Tokenized   (019): ['<s>', 's', 'igma', '_', 'b', 'Ġ,', 'Ġcentered', 'Ġ,', 'Ġx', '_', 'hat', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġintern', 'als', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['s', 'igma', '_', 'b', 'Ġ,', 'Ġcentered', 'Ġ,', 'Ġx', '_', 'hat', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġintern', 'als', 'Ġ\\', 'n']
Detokenized (010): ['sigma_b', 'Ġ,', 'Ġcentered', 'Ġ,', 'Ġx_hat', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġinternals', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "dgamma = buffers . gradients . gamma \n"
Original    (008): ['dgamma', '=', 'buffers', '.', 'gradients', '.', 'gamma', '\\n']
Tokenized   (014): ['<s>', 'd', 'gam', 'ma', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġgrad', 'ients', 'Ġ.', 'Ġgamma', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['d', 'gam', 'ma', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġgrad', 'ients', 'Ġ.', 'Ġgamma', 'Ġ\\', 'n']
Detokenized (008): ['dgamma', 'Ġ=', 'Ġbuffers', 'Ġ.', 'Ġgradients', 'Ġ.', 'Ġgamma', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "outdeltas = flatten_all_but_last ( buffers . output_deltas . default ) \n"
Original    (011): ['outdeltas', '=', 'flatten_all_but_last', '(', 'buffers', '.', 'output_deltas', '.', 'default', ')', '\\n']
Tokenized   (028): ['<s>', 'out', 'd', 'elt', 'as', 'Ġ=', 'Ġflatt', 'en', '_', 'all', '_', 'but', '_', 'last', 'Ġ(', 'Ġbuffers', 'Ġ.', 'Ġoutput', '_', 'd', 'elt', 'as', 'Ġ.', 'Ġdefault', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['out', 'd', 'elt', 'as', 'Ġ=', 'Ġflatt', 'en', '_', 'all', '_', 'but', '_', 'last', 'Ġ(', 'Ġbuffers', 'Ġ.', 'Ġoutput', '_', 'd', 'elt', 'as', 'Ġ.', 'Ġdefault', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['outdeltas', 'Ġ=', 'Ġflatten_all_but_last', 'Ġ(', 'Ġbuffers', 'Ġ.', 'Ġoutput_deltas', 'Ġ.', 'Ġdefault', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_h . add_tt ( term4 , indeltas , indeltas ) \n"
Original    (011): ['_h', '.', 'add_tt', '(', 'term4', ',', 'indeltas', ',', 'indeltas', ')', '\\n']
Tokenized   (022): ['<s>', '_', 'h', 'Ġ.', 'Ġadd', '_', 'tt', 'Ġ(', 'Ġterm', '4', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'h', 'Ġ.', 'Ġadd', '_', 'tt', 'Ġ(', 'Ġterm', '4', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ,', 'Ġind', 'elt', 'as', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_h', 'Ġ.', 'Ġadd_tt', 'Ġ(', 'Ġterm4', 'Ġ,', 'Ġindeltas', 'Ġ,', 'Ġindeltas', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "targets_name = , mask_name = ) : \n"
Original    (008): ['targets_name', '=', ',', 'mask_name', '=', ')', ':', '\\n']
Tokenized   (017): ['<s>', 't', 'arg', 'ets', '_', 'name', 'Ġ=', 'Ġ,', 'Ġmask', '_', 'name', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['t', 'arg', 'ets', '_', 'name', 'Ġ=', 'Ġ,', 'Ġmask', '_', 'name', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['targets_name', 'Ġ=', 'Ġ,', 'Ġmask_name', 'Ġ=', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mask_name = , name = None ) : \n"
Original    (009): ['mask_name', '=', ',', 'name', '=', 'None', ')', ':', '\\n']
Tokenized   (014): ['<s>', 'mask', '_', 'name', 'Ġ=', 'Ġ,', 'Ġname', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['mask', '_', 'name', 'Ġ=', 'Ġ,', 'Ġname', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (009): ['mask_name', 'Ġ=', 'Ġ,', 'Ġname', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "true_labels ) . astype ( np . float ) \n"
Original    (010): ['true_labels', ')', '.', 'astype', '(', 'np', '.', 'float', ')', '\\n']
Tokenized   (017): ['<s>', 'true', '_', 'lab', 'els', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['true', '_', 'lab', 'els', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['true_labels', 'Ġ)', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "epochs = [ 0 ] * 4 + [ 1 ] * 4 + [ 2 ] * 4 \n"
Original    (020): ['epochs', '=', '[', '0', ']', '*', '4', '+', '[', '1', ']', '*', '4', '+', '[', '2', ']', '*', '4', '\\n']
Tokenized   (025): ['<s>', 'ep', 'och', 's', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['ep', 'och', 's', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ\\', 'n']
Detokenized (020): ['epochs', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ+', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ*', 'Ġ4', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "on_rtd = os . environ . get ( , None ) == \n"
Original    (013): ['on_rtd', '=', 'os', '.', 'environ', '.', 'get', '(', ',', 'None', ')', '==', '\\n']
Tokenized   (020): ['<s>', 'on', '_', 'r', 'td', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ==', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['on', '_', 'r', 'td', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ==', 'Ġ\\', 'n']
Detokenized (013): ['on_rtd', 'Ġ=', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ==', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "html_theme_path = [ sphinx_rtd_theme . get_html_theme_path ( ) ] \n"
Original    (010): ['html_theme_path', '=', '[', 'sphinx_rtd_theme', '.', 'get_html_theme_path', '(', ')', ']', '\\n']
Tokenized   (030): ['<s>', 'html', '_', 'theme', '_', 'path', 'Ġ=', 'Ġ[', 'Ġsp', 'hin', 'x', '_', 'r', 'td', '_', 'theme', 'Ġ.', 'Ġget', '_', 'html', '_', 'theme', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['html', '_', 'theme', '_', 'path', 'Ġ=', 'Ġ[', 'Ġsp', 'hin', 'x', '_', 'r', 'td', '_', 'theme', 'Ġ.', 'Ġget', '_', 'html', '_', 'theme', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['html_theme_path', 'Ġ=', 'Ġ[', 'Ġsphinx_rtd_theme', 'Ġ.', 'Ġget_html_theme_path', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "latex_elements = { \n"
Original    (004): ['latex_elements', '=', '{', '\\n']
Tokenized   (011): ['<s>', 'late', 'x', '_', 'e', 'lements', 'Ġ=', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['late', 'x', '_', 'e', 'lements', 'Ġ=', 'Ġ{', 'Ġ\\', 'n']
Detokenized (004): ['latex_elements', 'Ġ=', 'Ġ{', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "latex_documents = [ \n"
Original    (004): ['latex_documents', '=', '[', '\\n']
Tokenized   (011): ['<s>', 'late', 'x', '_', 'doc', 'uments', 'Ġ=', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['late', 'x', '_', 'doc', 'uments', 'Ġ=', 'Ġ[', 'Ġ\\', 'n']
Detokenized (004): ['latex_documents', 'Ġ=', 'Ġ[', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "ignored_fallbacks = ( ) ) : \n"
Original    (007): ['ignored_fallbacks', '=', '(', ')', ')', ':', '\\n']
Tokenized   (014): ['<s>', 'ign', 'ored', '_', 'fall', 'backs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['ign', 'ored', '_', 'fall', 'backs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (007): ['ignored_fallbacks', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""b" : 2.0 , \n"
Original    (005): ['"b"', ':', '2.0', ',', '\\n']
Tokenized   (012): ['<s>', '"', 'b', '"', 'Ġ:', 'Ġ2', '.', '0', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['"', 'b', '"', 'Ġ:', 'Ġ2', '.', '0', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"b"', 'Ġ:', 'Ġ2.0', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""c" : True , \n"
Original    (005): ['"c"', ':', 'True', ',', '\\n']
Tokenized   (010): ['<s>', '"', 'c', '"', 'Ġ:', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'c', '"', 'Ġ:', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"c"', 'Ġ:', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""d" : , \n"
Original    (004): ['"d"', ':', ',', '\\n']
Tokenized   (009): ['<s>', '"', 'd', '"', 'Ġ:', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'd', '"', 'Ġ:', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['"d"', 'Ġ:', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""e" : [ 1 , 2 , 3 ] , \n"
Original    (011): ['"e"', ':', '[', '1', ',', '2', ',', '3', ']', ',', '\\n']
Tokenized   (016): ['<s>', '"', 'e', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['"', 'e', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"e"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""f" : { : , : } , \n"
Original    (009): ['"f"', ':', '{', ':', ',', ':', '}', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'f', '"', 'Ġ:', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'f', '"', 'Ġ:', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"f"', 'Ġ:', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""answer" : 42 \n"
Original    (004): ['"answer"', ':', '42', '\\n']
Tokenized   (009): ['<s>', '"', 'answer', '"', 'Ġ:', 'Ġ42', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'answer', '"', 'Ġ:', 'Ġ42', 'Ġ\\', 'n']
Detokenized (004): ['"answer"', 'Ġ:', 'Ġ42', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "p_error = self . kp * current_error \n"
Original    (008): ['p_error', '=', 'self', '.', 'kp', '*', 'current_error', '\\n']
Tokenized   (016): ['<s>', 'p', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'p', 'Ġ*', 'Ġcurrent', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['p', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'p', 'Ġ*', 'Ġcurrent', '_', 'error', 'Ġ\\', 'n']
Detokenized (008): ['p_error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġkp', 'Ġ*', 'Ġcurrent_error', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "d_error = self . kd * ( current_error - self . previous_error ) / timestep \n"
Original    (016): ['d_error', '=', 'self', '.', 'kd', '*', '(', 'current_error', '-', 'self', '.', 'previous_error', ')', '/', 'timestep', '\\n']
Tokenized   (028): ['<s>', 'd', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'd', 'Ġ*', 'Ġ(', 'Ġcurrent', '_', 'error', 'Ġ-', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġtim', 'est', 'ep', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['d', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġk', 'd', 'Ġ*', 'Ġ(', 'Ġcurrent', '_', 'error', 'Ġ-', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġtim', 'est', 'ep', 'Ġ\\', 'n']
Detokenized (016): ['d_error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġkd', 'Ġ*', 'Ġ(', 'Ġcurrent_error', 'Ġ-', 'Ġself', 'Ġ.', 'Ġprevious_error', 'Ġ)', 'Ġ/', 'Ġtimestep', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "current_error + self . previous_error ) / 2 + self . integral_error \n"
Original    (013): ['current_error', '+', 'self', '.', 'previous_error', ')', '/', '2', '+', 'self', '.', 'integral_error', '\\n']
Tokenized   (022): ['<s>', 'current', '_', 'error', 'Ġ+', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġ2', 'Ġ+', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['current', '_', 'error', 'Ġ+', 'Ġself', 'Ġ.', 'Ġprevious', '_', 'error', 'Ġ)', 'Ġ/', 'Ġ2', 'Ġ+', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n']
Detokenized (013): ['current_error', 'Ġ+', 'Ġself', 'Ġ.', 'Ġprevious_error', 'Ġ)', 'Ġ/', 'Ġ2', 'Ġ+', 'Ġself', 'Ġ.', 'Ġintegral_error', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "i_error = self . ki * self . integral_error \n"
Original    (010): ['i_error', '=', 'self', '.', 'ki', '*', 'self', '.', 'integral_error', '\\n']
Tokenized   (017): ['<s>', 'i', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġki', 'Ġ*', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['i', '_', 'error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġki', 'Ġ*', 'Ġself', 'Ġ.', 'Ġintegral', '_', 'error', 'Ġ\\', 'n']
Detokenized (010): ['i_error', 'Ġ=', 'Ġself', 'Ġ.', 'Ġki', 'Ġ*', 'Ġself', 'Ġ.', 'Ġintegral_error', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "total_error = p_error + d_error + i_error \n"
Original    (008): ['total_error', '=', 'p_error', '+', 'd_error', '+', 'i_error', '\\n']
Tokenized   (019): ['<s>', 'total', '_', 'error', 'Ġ=', 'Ġp', '_', 'error', 'Ġ+', 'Ġd', '_', 'error', 'Ġ+', 'Ġi', '_', 'error', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['total', '_', 'error', 'Ġ=', 'Ġp', '_', 'error', 'Ġ+', 'Ġd', '_', 'error', 'Ġ+', 'Ġi', '_', 'error', 'Ġ\\', 'n']
Detokenized (008): ['total_error', 'Ġ=', 'Ġp_error', 'Ġ+', 'Ġd_error', 'Ġ+', 'Ġi_error', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "cmd_match_names = cmd . Cmd . completenames ( self , text , * ignored ) \n"
Original    (016): ['cmd_match_names', '=', 'cmd', '.', 'Cmd', '.', 'completenames', '(', 'self', ',', 'text', ',', '*', 'ignored', ')', '\\n']
Tokenized   (026): ['<s>', 'cmd', '_', 'match', '_', 'names', 'Ġ=', 'Ġcmd', 'Ġ.', 'ĠC', 'md', 'Ġ.', 'Ġcomple', 'ten', 'ames', 'Ġ(', 'Ġself', 'Ġ,', 'Ġtext', 'Ġ,', 'Ġ*', 'Ġignored', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['cmd', '_', 'match', '_', 'names', 'Ġ=', 'Ġcmd', 'Ġ.', 'ĠC', 'md', 'Ġ.', 'Ġcomple', 'ten', 'ames', 'Ġ(', 'Ġself', 'Ġ,', 'Ġtext', 'Ġ,', 'Ġ*', 'Ġignored', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['cmd_match_names', 'Ġ=', 'Ġcmd', 'Ġ.', 'ĠCmd', 'Ġ.', 'Ġcompletenames', 'Ġ(', 'Ġself', 'Ġ,', 'Ġtext', 'Ġ,', 'Ġ*', 'Ġignored', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "obj_names = self . ctrl_client . objects . keys ( ) \n"
Original    (012): ['obj_names', '=', 'self', '.', 'ctrl_client', '.', 'objects', '.', 'keys', '(', ')', '\\n']
Tokenized   (020): ['<s>', 'obj', '_', 'names', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['obj', '_', 'names', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['obj_names', 'Ġ=', 'Ġself', 'Ġ.', 'Ġctrl_client', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "api_match_names = [ x for x in obj_names if x . startswith ( text ) ] \n"
Original    (017): ['api_match_names', '=', '[', 'x', 'for', 'x', 'in', 'obj_names', 'if', 'x', '.', 'startswith', '(', 'text', ')', ']', '\\n']
Tokenized   (028): ['<s>', 'api', '_', 'match', '_', 'names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġobj', '_', 'names', 'Ġif', 'Ġx', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['api', '_', 'match', '_', 'names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġobj', '_', 'names', 'Ġif', 'Ġx', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['api_match_names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġobj_names', 'Ġif', 'Ġx', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "reply_time = self . ctrl_client . ping ( ) \n"
Original    (010): ['reply_time', '=', 'self', '.', 'ctrl_client', '.', 'ping', '(', ')', '\\n']
Tokenized   (018): ['<s>', 'reply', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġping', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['reply', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġc', 'trl', '_', 'client', 'Ġ.', 'Ġping', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['reply_time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġctrl_client', 'Ġ.', 'Ġping', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sub_addr = sys . argv [ 2 ] \n"
Original    (009): ['sub_addr', '=', 'sys', '.', 'argv', '[', '2', ']', '\\n']
Tokenized   (015): ['<s>', 'sub', '_', 'addr', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['sub', '_', 'addr', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['sub_addr', 'Ġ=', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "CLI ( ctrl_addr , sub_addr ) . cmdloop ( ) \n"
Original    (011): ['CLI', '(', 'ctrl_addr', ',', 'sub_addr', ')', '.', 'cmdloop', '(', ')', '\\n']
Tokenized   (021): ['<s>', 'CL', 'I', 'Ġ(', 'Ġc', 'trl', '_', 'addr', 'Ġ,', 'Ġsub', '_', 'addr', 'Ġ)', 'Ġ.', 'Ġcmd', 'loop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['CL', 'I', 'Ġ(', 'Ġc', 'trl', '_', 'addr', 'Ġ,', 'Ġsub', '_', 'addr', 'Ġ)', 'Ġ.', 'Ġcmd', 'loop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['CLI', 'Ġ(', 'Ġctrl_addr', 'Ġ,', 'Ġsub_addr', 'Ġ)', 'Ġ.', 'Ġcmdloop', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "duty = int ( cur_pwm [ "duty_ns" ] ) \n"
Original    (010): ['duty', '=', 'int', '(', 'cur_pwm', '[', '"duty_ns"', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'duty', 'Ġ=', 'Ġint', 'Ġ(', 'Ġcur', '_', 'p', 'wm', 'Ġ[', 'Ġ"', 'duty', '_', 'ns', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['duty', 'Ġ=', 'Ġint', 'Ġ(', 'Ġcur', '_', 'p', 'wm', 'Ġ[', 'Ġ"', 'duty', '_', 'ns', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['duty', 'Ġ=', 'Ġint', 'Ġ(', 'Ġcur_pwm', 'Ġ[', 'Ġ"duty_ns"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "read_pos = int ( round ( ( ( duty - 580000 ) / 2320000. ) * 180 ) ) \n"
Original    (020): ['read_pos', '=', 'int', '(', 'round', '(', '(', '(', 'duty', '-', '580000', ')', '/', '2320000.', ')', '*', '180', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'read', '_', 'pos', 'Ġ=', 'Ġint', 'Ġ(', 'Ġround', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġduty', 'Ġ-', 'Ġ58', '0000', 'Ġ)', 'Ġ/', 'Ġ23', '200', '00', '.', 'Ġ)', 'Ġ*', 'Ġ180', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['read', '_', 'pos', 'Ġ=', 'Ġint', 'Ġ(', 'Ġround', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġduty', 'Ġ-', 'Ġ58', '0000', 'Ġ)', 'Ġ/', 'Ġ23', '200', '00', '.', 'Ġ)', 'Ġ*', 'Ġ180', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['read_pos', 'Ġ=', 'Ġint', 'Ġ(', 'Ġround', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġduty', 'Ġ-', 'Ġ580000', 'Ġ)', 'Ġ/', 'Ġ2320000.', 'Ġ)', 'Ġ*', 'Ġ180', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "create_login_url , create_logout_url \n"
Original    (004): ['create_login_url', ',', 'create_logout_url', '\\n']
Tokenized   (016): ['<s>', 'create', '_', 'login', '_', 'url', 'Ġ,', 'Ġcreate', '_', 'log', 'out', '_', 'url', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['create', '_', 'login', '_', 'url', 'Ġ,', 'Ġcreate', '_', 'log', 'out', '_', 'url', 'Ġ\\', 'n']
Detokenized (004): ['create_login_url', 'Ġ,', 'Ġcreate_logout_url', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "create_logout_url ( request . url ) \n"
Original    (007): ['create_logout_url', '(', 'request', '.', 'url', ')', '\\n']
Tokenized   (015): ['<s>', 'create', '_', 'log', 'out', '_', 'url', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġurl', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['create', '_', 'log', 'out', '_', 'url', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġurl', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['create_logout_url', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġurl', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_value = _options_header_vkw ( _value , kw ) \n"
Original    (009): ['_value', '=', '_options_header_vkw', '(', '_value', ',', 'kw', ')', '\\n']
Tokenized   (021): ['<s>', '_', 'value', 'Ġ=', 'Ġ_', 'options', '_', 'header', '_', 'v', 'kw', 'Ġ(', 'Ġ_', 'value', 'Ġ,', 'Ġk', 'w', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['_', 'value', 'Ġ=', 'Ġ_', 'options', '_', 'header', '_', 'v', 'kw', 'Ġ(', 'Ġ_', 'value', 'Ġ,', 'Ġk', 'w', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['_value', 'Ġ=', 'Ġ_options_header_vkw', 'Ġ(', 'Ġ_value', 'Ġ,', 'Ġkw', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "value_type == value_subtype == ) or \n"
Original    (007): ['value_type', '==', 'value_subtype', '==', ')', 'or', '\\n']
Tokenized   (015): ['<s>', 'value', '_', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ==', 'Ġ)', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['value', '_', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ==', 'Ġ)', 'Ġor', 'Ġ\\', 'n']
Detokenized (007): ['value_type', 'Ġ==', 'Ġvalue_subtype', 'Ġ==', 'Ġ)', 'Ġor', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "value_subtype == or \n"
Original    (004): ['value_subtype', '==', 'or', '\\n']
Tokenized   (010): ['<s>', 'value', '_', 'sub', 'type', 'Ġ==', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['value', '_', 'sub', 'type', 'Ġ==', 'Ġor', 'Ġ\\', 'n']
Detokenized (004): ['value_subtype', 'Ġ==', 'Ġor', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "item_subtype == value_subtype ) ) \n"
Original    (006): ['item_subtype', '==', 'value_subtype', ')', ')', '\\n']
Tokenized   (015): ['<s>', 'item', '_', 'sub', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['item', '_', 'sub', 'type', 'Ġ==', 'Ġvalue', '_', 'sub', 'type', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['item_subtype', 'Ġ==', 'Ġvalue_subtype', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "no_cache = cache_property ( , , None ) \n"
Original    (009): ['no_cache', '=', 'cache_property', '(', ',', ',', 'None', ')', '\\n']
Tokenized   (016): ['<s>', 'no', '_', 'cache', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['no', '_', 'cache', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['no_cache', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "no_store = cache_property ( , None , bool ) \n"
Original    (010): ['no_store', '=', 'cache_property', '(', ',', 'None', ',', 'bool', ')', '\\n']
Tokenized   (017): ['<s>', 'no', '_', 'store', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['no', '_', 'store', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['no_store', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġbool', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "max_age = cache_property ( , - 1 , int ) \n"
Original    (011): ['max_age', '=', 'cache_property', '(', ',', '-', '1', ',', 'int', ')', '\\n']
Tokenized   (018): ['<s>', 'max', '_', 'age', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['max', '_', 'age', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['max_age', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "no_transform = cache_property ( , None , None ) \n"
Original    (010): ['no_transform', '=', 'cache_property', '(', ',', 'None', ',', 'None', ')', '\\n']
Tokenized   (017): ['<s>', 'no', '_', 'transform', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['no', '_', 'transform', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['no_transform', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "max_stale = cache_property ( , , int ) \n"
Original    (009): ['max_stale', '=', 'cache_property', '(', ',', ',', 'int', ')', '\\n']
Tokenized   (017): ['<s>', 'max', '_', 'st', 'ale', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['max', '_', 'st', 'ale', 'Ġ=', 'Ġcache', '_', 'property', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['max_stale', 'Ġ=', 'Ġcache_property', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġint', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "etag , weak = unquote_etag ( etag ) \n"
Original    (009): ['etag', ',', 'weak', '=', 'unquote_etag', '(', 'etag', ')', '\\n']
Tokenized   (018): ['<s>', 'et', 'ag', 'Ġ,', 'Ġweak', 'Ġ=', 'Ġun', 'quote', '_', 'et', 'ag', 'Ġ(', 'Ġet', 'ag', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['et', 'ag', 'Ġ,', 'Ġweak', 'Ġ=', 'Ġun', 'quote', '_', 'et', 'ag', 'Ġ(', 'Ġet', 'ag', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['etag', 'Ġ,', 'Ġweak', 'Ġ=', 'Ġunquote_etag', 'Ġ(', 'Ġetag', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "uri = property ( lambda x : x . get ( ) , doc = ) \n"
Original    (017): ['uri', '=', 'property', '(', 'lambda', 'x', ':', 'x', '.', 'get', '(', ')', ',', 'doc', '=', ')', '\\n']
Tokenized   (020): ['<s>', 'uri', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['uri', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['uri', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "_require_quoting = frozenset ( [ , , , ] ) \n"
Original    (011): ['_require_quoting', '=', 'frozenset', '(', '[', ',', ',', ',', ']', ')', '\\n']
Tokenized   (020): ['<s>', '_', 'require', '_', 'qu', 'oting', 'Ġ=', 'Ġfro', 'zens', 'et', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['_', 'require', '_', 'qu', 'oting', 'Ġ=', 'Ġfro', 'zens', 'et', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_require_quoting', 'Ġ=', 'Ġfrozenset', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "auth_type = d . pop ( , None ) or \n"
Original    (011): ['auth_type', '=', 'd', '.', 'pop', '(', ',', 'None', ')', 'or', '\\n']
Tokenized   (016): ['<s>', 'auth', '_', 'type', 'Ġ=', 'Ġd', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['auth', '_', 'type', 'Ġ=', 'Ġd', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġor', 'Ġ\\', 'n']
Detokenized (011): ['auth_type', 'Ġ=', 'Ġd', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġor', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "allow_token = key not in self . _require_quoting ) ) \n"
Original    (011): ['allow_token', '=', 'key', 'not', 'in', 'self', '.', '_require_quoting', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'allow', '_', 'token', 'Ġ=', 'Ġkey', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġ_', 'require', '_', 'qu', 'oting', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['allow', '_', 'token', 'Ġ=', 'Ġkey', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġ_', 'require', '_', 'qu', 'oting', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['allow_token', 'Ġ=', 'Ġkey', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġ_require_quoting', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "realm = auth_property ( , doc = ) \n"
Original    (009): ['realm', '=', 'auth_property', '(', ',', 'doc', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'real', 'm', 'Ġ=', 'Ġauth', '_', 'property', 'Ġ(', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['real', 'm', 'Ġ=', 'Ġauth', '_', 'property', 'Ġ(', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['realm', 'Ġ=', 'Ġauth_property', 'Ġ(', 'Ġ,', 'Ġdoc', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rshell , shell , clear_datastore , create_user , \n"
Original    (009): ['rshell', ',', 'shell', ',', 'clear_datastore', ',', 'create_user', ',', '\\n']
Tokenized   (019): ['<s>', 'rs', 'hell', 'Ġ,', 'Ġshell', 'Ġ,', 'Ġclear', '_', 'dat', 'ast', 'ore', 'Ġ,', 'Ġcreate', '_', 'user', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rs', 'hell', 'Ġ,', 'Ġshell', 'Ġ,', 'Ġclear', '_', 'dat', 'ast', 'ore', 'Ġ,', 'Ġcreate', '_', 'user', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['rshell', 'Ġ,', 'Ġshell', 'Ġ,', 'Ġclear_datastore', 'Ġ,', 'Ġcreate_user', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "Rule ( , endpoint = , \n"
Original    (007): ['Rule', '(', ',', 'endpoint', '=', ',', '\\n']
Tokenized   (010): ['<s>', 'Rule', 'Ġ(', 'Ġ,', 'Ġendpoint', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Rule', 'Ġ(', 'Ġ,', 'Ġendpoint', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['Rule', 'Ġ(', 'Ġ,', 'Ġendpoint', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "data_field = db . StringProperty ( required = True , \n"
Original    (011): ['data_field', '=', 'db', '.', 'StringProperty', '(', 'required', '=', 'True', ',', '\\n']
Tokenized   (017): ['<s>', 'data', '_', 'field', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠString', 'Property', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['data', '_', 'field', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠString', 'Property', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['data_field', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠStringProperty', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dst_name = path . join ( dst_path , filename ) \n"
Original    (011): ['dst_name', '=', 'path', '.', 'join', '(', 'dst_path', ',', 'filename', ')', '\\n']
Tokenized   (019): ['<s>', 'd', 'st', '_', 'name', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdst', '_', 'path', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['d', 'st', '_', 'name', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdst', '_', 'path', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['dst_name', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdst_path', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "modifiable_problem_fields = [ "description" ] \n"
Original    (006): ['modifiable_problem_fields', '=', '[', '"description"', ']', '\\n']
Tokenized   (016): ['<s>', 'mod', 'ifiable', '_', 'problem', '_', 'fields', 'Ġ=', 'Ġ[', 'Ġ"', 'description', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['mod', 'ifiable', '_', 'problem', '_', 'fields', 'Ġ=', 'Ġ[', 'Ġ"', 'description', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['modifiable_problem_fields', 'Ġ=', 'Ġ[', 'Ġ"description"', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "problem = api . problem . get_problem ( pid = pid ) \n"
Original    (013): ['problem', '=', 'api', '.', 'problem', '.', 'get_problem', '(', 'pid', '=', 'pid', ')', '\\n']
Tokenized   (018): ['<s>', 'problem', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġproblem', 'Ġ.', 'Ġget', '_', 'problem', 'Ġ(', 'Ġpid', 'Ġ=', 'Ġpid', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['problem', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġproblem', 'Ġ.', 'Ġget', '_', 'problem', 'Ġ(', 'Ġpid', 'Ġ=', 'Ġpid', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['problem', 'Ġ=', 'Ġapi', 'Ġ.', 'Ġproblem', 'Ġ.', 'Ġget_problem', 'Ġ(', 'Ġpid', 'Ġ=', 'Ġpid', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "build = get_generator ( pid ) . generate ( random , pid , api . autogen_tools , n ) \n"
Original    (020): ['build', '=', 'get_generator', '(', 'pid', ')', '.', 'generate', '(', 'random', ',', 'pid', ',', 'api', '.', 'autogen_tools', ',', 'n', ')', '\\n']
Tokenized   (029): ['<s>', 'build', 'Ġ=', 'Ġget', '_', 'gener', 'ator', 'Ġ(', 'Ġpid', 'Ġ)', 'Ġ.', 'Ġgenerate', 'Ġ(', 'Ġrandom', 'Ġ,', 'Ġpid', 'Ġ,', 'Ġapi', 'Ġ.', 'Ġaut', 'ogen', '_', 'tools', 'Ġ,', 'Ġn', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['build', 'Ġ=', 'Ġget', '_', 'gener', 'ator', 'Ġ(', 'Ġpid', 'Ġ)', 'Ġ.', 'Ġgenerate', 'Ġ(', 'Ġrandom', 'Ġ,', 'Ġpid', 'Ġ,', 'Ġapi', 'Ġ.', 'Ġaut', 'ogen', '_', 'tools', 'Ġ,', 'Ġn', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['build', 'Ġ=', 'Ġget_generator', 'Ġ(', 'Ġpid', 'Ġ)', 'Ġ.', 'Ġgenerate', 'Ġ(', 'Ġrandom', 'Ġ,', 'Ġpid', 'Ġ,', 'Ġapi', 'Ġ.', 'Ġautogen_tools', 'Ġ,', 'Ġn', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "autogen_instance_path = get_instance_path ( pid , n = n ) \n"
Original    (011): ['autogen_instance_path', '=', 'get_instance_path', '(', 'pid', ',', 'n', '=', 'n', ')', '\\n']
Tokenized   (023): ['<s>', 'aut', 'ogen', '_', 'instance', '_', 'path', 'Ġ=', 'Ġget', '_', 'instance', '_', 'path', 'Ġ(', 'Ġpid', 'Ġ,', 'Ġn', 'Ġ=', 'Ġn', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['aut', 'ogen', '_', 'instance', '_', 'path', 'Ġ=', 'Ġget', '_', 'instance', '_', 'path', 'Ġ(', 'Ġpid', 'Ġ,', 'Ġn', 'Ġ=', 'Ġn', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['autogen_instance_path', 'Ġ=', 'Ġget_instance_path', 'Ġ(', 'Ġpid', 'Ġ,', 'Ġn', 'Ġ=', 'Ġn', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""resource_files" : { \n"
Original    (004): ['"resource_files"', ':', '{', '\\n']
Tokenized   (011): ['<s>', '"', 'resource', '_', 'files', '"', 'Ġ:', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['"', 'resource', '_', 'files', '"', 'Ġ:', 'Ġ{', 'Ġ\\', 'n']
Detokenized (004): ['"resource_files"', 'Ġ:', 'Ġ{', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "instance_path = path . join ( path . dirname ( generator_path ) , "instances" , name , str ( n ) ) \n"
Original    (023): ['instance_path', '=', 'path', '.', 'join', '(', 'path', '.', 'dirname', '(', 'generator_path', ')', ',', '"instances"', ',', 'name', ',', 'str', '(', 'n', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'instance', '_', 'path', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġgenerator', '_', 'path', 'Ġ)', 'Ġ,', 'Ġ"', 'inst', 'ances', '"', 'Ġ,', 'Ġname', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġn', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['instance', '_', 'path', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġgenerator', '_', 'path', 'Ġ)', 'Ġ,', 'Ġ"', 'inst', 'ances', '"', 'Ġ,', 'Ġname', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġn', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['instance_path', 'Ġ=', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġgenerator_path', 'Ġ)', 'Ġ,', 'Ġ"instances"', 'Ġ,', 'Ġname', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġn', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : ""correct" : correct , \n"
Original    (005): ['"correct"', ':', 'correct', ',', '\\n']
Tokenized   (010): ['<s>', '"', 'correct', '"', 'Ġ:', 'Ġcorrect', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'correct', '"', 'Ġ:', 'Ġcorrect', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"correct"', 'Ġ:', 'Ġcorrect', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""points" : problem [ "score" ] , \n"
Original    (008): ['"points"', ':', 'problem', '[', '"score"', ']', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'points', '"', 'Ġ:', 'Ġproblem', 'Ġ[', 'Ġ"', 'score', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'points', '"', 'Ġ:', 'Ġproblem', 'Ġ[', 'Ġ"', 'score', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['"points"', 'Ġ:', 'Ġproblem', 'Ġ[', 'Ġ"score"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""message" : message \n"
Original    (004): ['"message"', ':', 'message', '\\n']
Tokenized   (009): ['<s>', '"', 'message', '"', 'Ġ:', 'Ġmessage', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'message', '"', 'Ġ:', 'Ġmessage', 'Ġ\\', 'n']
Detokenized (004): ['"message"', 'Ġ:', 'Ġmessage', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "k = str ( random . randint ( 0 , 1000 ) ) \n"
Original    (014): ['k', '=', 'str', '(', 'random', '.', 'randint', '(', '0', ',', '1000', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'k', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['k', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['k', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġrandom', 'Ġ.', 'Ġrandint', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1000', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""public" : [ ( "/tmp/key" , "public_static" ) ] , \n"
Original    (011): ['"public"', ':', '[', '(', '"/tmp/key"', ',', '"public_static"', ')', ']', ',', '\\n']
Tokenized   (024): ['<s>', '"', 'public', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'public', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'public', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'public', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"public"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/tmp/key"', 'Ġ,', 'Ġ"public_static"', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""private" : [ ( "/tmp/key" , "private_static" ) ] \n"
Original    (010): ['"private"', ':', '[', '(', '"/tmp/key"', ',', '"private_static"', ')', ']', '\\n']
Tokenized   (023): ['<s>', '"', 'private', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'private', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', 'private', '"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/', 'tmp', '/', 'key', '"', 'Ġ,', 'Ġ"', 'private', '_', 'static', '"', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['"private"', 'Ġ:', 'Ġ[', 'Ġ(', 'Ġ"/tmp/key"', 'Ġ,', 'Ġ"private_static"', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "layout = eval ( scriptWindow . setLayout ( layout ) \n"
Original    (011): ['layout', '=', 'eval', '(', 'scriptWindow', '.', 'setLayout', '(', 'layout', ')', '\\n']
Tokenized   (016): ['<s>', 'layout', 'Ġ=', 'Ġeval', 'Ġ(', 'Ġscript', 'Window', 'Ġ.', 'Ġset', 'Layout', 'Ġ(', 'Ġlayout', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['layout', 'Ġ=', 'Ġeval', 'Ġ(', 'Ġscript', 'Window', 'Ġ.', 'Ġset', 'Layout', 'Ġ(', 'Ġlayout', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['layout', 'Ġ=', 'Ġeval', 'Ġ(', 'ĠscriptWindow', 'Ġ.', 'ĠsetLayout', 'Ġ(', 'Ġlayout', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "scriptWindow . _Widget__qtWidget . resize ( 995 , 500 ) \n"
Original    (011): ['scriptWindow', '.', '_Widget__qtWidget', '.', 'resize', '(', '995', ',', '500', ')', '\\n']
Tokenized   (020): ['<s>', 'script', 'Window', 'Ġ.', 'Ġ_', 'Widget', '__', 'qt', 'Widget', 'Ġ.', 'Ġresize', 'Ġ(', 'Ġ9', '95', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['script', 'Window', 'Ġ.', 'Ġ_', 'Widget', '__', 'qt', 'Widget', 'Ġ.', 'Ġresize', 'Ġ(', 'Ġ9', '95', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['scriptWindow', 'Ġ.', 'Ġ_Widget__qtWidget', 'Ġ.', 'Ġresize', 'Ġ(', 'Ġ995', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""inputSequence" , \n"
Original    (003): ['"inputSequence"', ',', '\\n']
Tokenized   (010): ['<s>', '"', 'input', 'Sequ', 'ence', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'input', 'Sequ', 'ence', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (003): ['"inputSequence"', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "defaultValue = "" , \n"
Original    (005): ['defaultValue', '=', '""', ',', '\\n']
Tokenized   (009): ['<s>', 'default', 'Value', 'Ġ=', 'Ġ""', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['default', 'Value', 'Ġ=', 'Ġ""', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['defaultValue', 'Ġ=', 'Ġ""', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "dc . write ( "-" + objectName , "bound" , b ) \n"
Original    (013): ['dc', '.', 'write', '(', '"-"', '+', 'objectName', ',', '"bound"', ',', 'b', ')', '\\n']
Tokenized   (020): ['<s>', 'dc', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"', '-"', 'Ġ+', 'Ġobject', 'Name', 'Ġ,', 'Ġ"', 'bound', '"', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['dc', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"', '-"', 'Ġ+', 'Ġobject', 'Name', 'Ġ,', 'Ġ"', 'bound', '"', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['dc', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"-"', 'Ġ+', 'ĠobjectName', 'Ġ,', 'Ġ"bound"', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "additionalTerminalPlugTypes = ( GafferScene . ScenePlug , ) \n"
Original    (009): ['additionalTerminalPlugTypes', '=', '(', 'GafferScene', '.', 'ScenePlug', ',', ')', '\\n']
Tokenized   (020): ['<s>', 'add', 'itional', 'Termin', 'al', 'Plug', 'Types', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Ġ.', 'ĠScene', 'Plug', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['add', 'itional', 'Termin', 'al', 'Plug', 'Types', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Ġ.', 'ĠScene', 'Plug', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['additionalTerminalPlugTypes', 'Ġ=', 'Ġ(', 'ĠGafferScene', 'Ġ.', 'ĠScenePlug', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "replace = context . get ( "textWriter:replace" , IECore . StringVectorData ( ) ) \n"
Original    (015): ['replace', '=', 'context', '.', 'get', '(', '"textWriter:replace"', ',', 'IECore', '.', 'StringVectorData', '(', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'replace', 'Ġ=', 'Ġcontext', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'text', 'Writer', ':', 'replace', '"', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['replace', 'Ġ=', 'Ġcontext', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'text', 'Writer', ':', 'replace', '"', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['replace', 'Ġ=', 'Ġcontext', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"textWriter:replace"', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠStringVectorData', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "inMetadata = r [ "out" ] [ "metadata" ] . getValue ( ) \n"
Original    (014): ['inMetadata', '=', 'r', '[', '"out"', ']', '[', '"metadata"', ']', '.', 'getValue', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'in', 'Met', 'adata', 'Ġ=', 'Ġr', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'metadata', '"', 'Ġ]', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['in', 'Met', 'adata', 'Ġ=', 'Ġr', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'metadata', '"', 'Ġ]', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['inMetadata', 'Ġ=', 'Ġr', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ[', 'Ġ"metadata"', 'Ġ]', 'Ġ.', 'ĠgetValue', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "negFileName = os . path . expandvars ( "$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr" \n"
Original    (010): ['negFileName', '=', 'os', '.', 'path', '.', 'expandvars', '(', '"$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr"', '\\n']
Tokenized   (047): ['<s>', 'neg', 'File', 'Name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'v', 'ars', 'Ġ(', 'Ġ"$', 'GA', 'FFER', '_', 'RO', 'OT', '/', 'python', '/', 'G', 'affer', 'Image', 'Test', '/', 'images', '/', 'check', 'er', 'With', 'Neg', 'ative', 'Data', 'Window', '.', '200', 'x', '150', '.', 'ex', 'r', '"', 'Ġ\\', 'n', '</s>']
Filtered   (045): ['neg', 'File', 'Name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'v', 'ars', 'Ġ(', 'Ġ"$', 'GA', 'FFER', '_', 'RO', 'OT', '/', 'python', '/', 'G', 'affer', 'Image', 'Test', '/', 'images', '/', 'check', 'er', 'With', 'Neg', 'ative', 'Data', 'Window', '.', '200', 'x', '150', '.', 'ex', 'r', '"', 'Ġ\\', 'n']
Detokenized (010): ['negFileName', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpandvars', 'Ġ(', 'Ġ"$GAFFER_ROOT/python/GafferImageTest/images/checkerWithNegativeDataWindow.200x150.exr"', 'Ġ\\n']
Counter: 45
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "GafferImage . Display , \n"
Original    (005): ['GafferImage', '.', 'Display', ',', '\\n']
Tokenized   (010): ['<s>', 'G', 'affer', 'Image', 'Ġ.', 'ĠDisplay', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['G', 'affer', 'Image', 'Ġ.', 'ĠDisplay', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['GafferImage', 'Ġ.', 'ĠDisplay', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""port" : [ \n"
Original    (004): ['"port"', ':', '[', '\\n']
Tokenized   (009): ['<s>', '"', 'port', '"', 'Ġ:', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', 'port', '"', 'Ġ:', 'Ġ[', 'Ġ\\', 'n']
Detokenized (004): ['"port"', 'Ġ:', 'Ġ[', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "updateCountPlug . setValue ( updateCountPlug . getValue ( ) + 1 ) \n"
Original    (013): ['updateCountPlug', '.', 'setValue', '(', 'updateCountPlug', '.', 'getValue', '(', ')', '+', '1', ')', '\\n']
Tokenized   (022): ['<s>', 'update', 'Count', 'Plug', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġupdate', 'Count', 'Plug', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['update', 'Count', 'Plug', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġupdate', 'Count', 'Plug', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['updateCountPlug', 'Ġ.', 'ĠsetValue', 'Ġ(', 'ĠupdateCountPlug', 'Ġ.', 'ĠgetValue', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "__import__ ( "IECore" ) . loadConfig ( "GAFFER_STARTUP_PATHS" , { } , subdirectory = "GafferImageUI" ) \n"
Original    (017): ['__import__', '(', '"IECore"', ')', '.', 'loadConfig', '(', '"GAFFER_STARTUP_PATHS"', ',', '{', '}', ',', 'subdirectory', '=', '"GafferImageUI"', ')', '\\n']
Tokenized   (044): ['<s>', '__', 'import', '__', 'Ġ(', 'Ġ"', 'I', 'EC', 'ore', '"', 'Ġ)', 'Ġ.', 'Ġload', 'Config', 'Ġ(', 'Ġ"', 'GA', 'FFER', '_', 'ST', 'ART', 'UP', '_', 'P', 'AT', 'HS', '"', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġsub', 'directory', 'Ġ=', 'Ġ"', 'G', 'affer', 'Image', 'UI', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['__', 'import', '__', 'Ġ(', 'Ġ"', 'I', 'EC', 'ore', '"', 'Ġ)', 'Ġ.', 'Ġload', 'Config', 'Ġ(', 'Ġ"', 'GA', 'FFER', '_', 'ST', 'ART', 'UP', '_', 'P', 'AT', 'HS', '"', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġsub', 'directory', 'Ġ=', 'Ġ"', 'G', 'affer', 'Image', 'UI', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['__import__', 'Ġ(', 'Ġ"IECore"', 'Ġ)', 'Ġ.', 'ĠloadConfig', 'Ġ(', 'Ġ"GAFFER_STARTUP_PATHS"', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġsubdirectory', 'Ġ=', 'Ġ"GafferImageUI"', 'Ġ)', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "GafferRenderMan . RenderManShader . shaderLoader ( ) . clear ( ) \n"
Original    (012): ['GafferRenderMan', '.', 'RenderManShader', '.', 'shaderLoader', '(', ')', '.', 'clear', '(', ')', '\\n']
Tokenized   (022): ['<s>', 'G', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ.', 'Ġshader', 'Loader', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġclear', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['G', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ.', 'Ġshader', 'Loader', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġclear', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['GafferRenderMan', 'Ġ.', 'ĠRenderManShader', 'Ġ.', 'ĠshaderLoader', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġclear', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "coshader = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/coshader.sl" ) \n"
Original    (018): ['coshader', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/coshader.sl"', ')', '\\n']
Tokenized   (037): ['<s>', 'c', 'osh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', '.', 'sl', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['c', 'osh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', '.', 'sl', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['coshader', 'Ġ=', 'Ġself', 'Ġ.', 'ĠcompileShader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ+', 'Ġ"/shaders/coshader.sl"', 'Ġ)', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "nn [ "outString" ] = Gaffer . StringPlug ( direction = Gaffer . Plug . Direction . Out ) \n"
Original    (020): ['nn', '[', '"outString"', ']', '=', 'Gaffer', '.', 'StringPlug', '(', 'direction', '=', 'Gaffer', '.', 'Plug', '.', 'Direction', '.', 'Out', ')', '\\n']
Tokenized   (029): ['<s>', 'nn', 'Ġ[', 'Ġ"', 'out', 'String', '"', 'Ġ]', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠString', 'Plug', 'Ġ(', 'Ġdirection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['nn', 'Ġ[', 'Ġ"', 'out', 'String', '"', 'Ġ]', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠString', 'Plug', 'Ġ(', 'Ġdirection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['nn', 'Ġ[', 'Ġ"outString"', 'Ġ]', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠStringPlug', 'Ġ(', 'Ġdirection', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "shader2 = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/version2.sl" , shaderName = "unversioned" \n"
Original    (021): ['shader2', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/version2.sl"', ',', 'shaderName', '=', '"unversioned"', '\\n']
Tokenized   (044): ['<s>', 'sh', 'ader', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'version', '2', '.', 'sl', '"', 'Ġ,', 'Ġshader', 'Name', 'Ġ=', 'Ġ"', 'un', 'version', 'ed', '"', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['sh', 'ader', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'version', '2', '.', 'sl', '"', 'Ġ,', 'Ġshader', 'Name', 'Ġ=', 'Ġ"', 'un', 'version', 'ed', '"', 'Ġ\\', 'n']
Detokenized (021): ['shader2', 'Ġ=', 'Ġself', 'Ġ.', 'ĠcompileShader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ+', 'Ġ"/shaders/version2.sl"', 'Ġ,', 'ĠshaderName', 'Ġ=', 'Ġ"unversioned"', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "assignment [ "shader" ] . setInput ( shaderNode [ "out" ] ) \n"
Original    (013): ['assignment', '[', '"shader"', ']', '.', 'setInput', '(', 'shaderNode', '[', '"out"', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'ass', 'ignment', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġshader', 'Node', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ass', 'ignment', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġshader', 'Node', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['assignment', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ.', 'ĠsetInput', 'Ġ(', 'ĠshaderNode', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "dirtiedNames = [ x [ 0 ] . fullName ( ) for x in cs ] \n"
Original    (017): ['dirtiedNames', '=', '[', 'x', '[', '0', ']', '.', 'fullName', '(', ')', 'for', 'x', 'in', 'cs', ']', '\\n']
Tokenized   (024): ['<s>', 'd', 'irt', 'ied', 'Names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġcs', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['d', 'irt', 'ied', 'Names', 'Ġ=', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġcs', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['dirtiedNames', 'Ġ=', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'ĠfullName', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġcs', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : ""dynamicFloatArray" : IECore . FloatVectorData ( [ ] ) , \n"
Original    (011): ['"dynamicFloatArray"', ':', 'IECore', '.', 'FloatVectorData', '(', '[', ']', ')', ',', '\\n']
Tokenized   (023): ['<s>', '"', 'd', 'ynamic', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', 'd', 'ynamic', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"dynamicFloatArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠFloatVectorData', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""fixedFloatArray" : IECore . FloatVectorData ( [ 1 , 2 , 3 , 4 ] ) , \n"
Original    (018): ['"fixedFloatArray"', ':', 'IECore', '.', 'FloatVectorData', '(', '[', '1', ',', '2', ',', '3', ',', '4', ']', ')', ',', '\\n']
Tokenized   (029): ['<s>', '"', 'fixed', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['"', 'fixed', 'Float', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠFloat', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (018): ['"fixedFloatArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠFloatVectorData', 'Ġ(', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : ""dynamicStringArray" : IECore . StringVectorData ( [ "dynamic" , "arrays" , "can" , "still" , "have" , "defaults" "fixedStringArray" : IECore . StringVectorData ( [ "hello" , "goodbye" ] ) , \n"
Original    (032): ['"dynamicStringArray"', ':', 'IECore', '.', 'StringVectorData', '(', '[', '"dynamic"', ',', '"arrays"', ',', '"can"', ',', '"still"', ',', '"have"', ',', '"defaults"', '"fixedStringArray"', ':', 'IECore', '.', 'StringVectorData', '(', '[', '"hello"', ',', '"goodbye"', ']', ')', ',', '\\n']
Tokenized   (072): ['<s>', '"', 'd', 'ynamic', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'd', 'ynamic', '"', 'Ġ,', 'Ġ"', 'arr', 'ays', '"', 'Ġ,', 'Ġ"', 'can', '"', 'Ġ,', 'Ġ"', 'still', '"', 'Ġ,', 'Ġ"', 'have', '"', 'Ġ,', 'Ġ"', 'default', 's', '"', 'Ġ"', 'fixed', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'hello', '"', 'Ġ,', 'Ġ"', 'good', 'bye', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (070): ['"', 'd', 'ynamic', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'd', 'ynamic', '"', 'Ġ,', 'Ġ"', 'arr', 'ays', '"', 'Ġ,', 'Ġ"', 'can', '"', 'Ġ,', 'Ġ"', 'still', '"', 'Ġ,', 'Ġ"', 'have', '"', 'Ġ,', 'Ġ"', 'default', 's', '"', 'Ġ"', 'fixed', 'String', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠString', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ"', 'hello', '"', 'Ġ,', 'Ġ"', 'good', 'bye', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (032): ['"dynamicStringArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠStringVectorData', 'Ġ(', 'Ġ[', 'Ġ"dynamic"', 'Ġ,', 'Ġ"arrays"', 'Ġ,', 'Ġ"can"', 'Ġ,', 'Ġ"still"', 'Ġ,', 'Ġ"have"', 'Ġ,', 'Ġ"defaults"', 'Ġ"fixedStringArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠStringVectorData', 'Ġ(', 'Ġ[', 'Ġ"hello"', 'Ġ,', 'Ġ"goodbye"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 70
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : ""dynamicColorArray" : IECore . Color3fVectorData ( [ IECore . Color3f ( 1 ) , IECore . Color3f ( 2 ) ] ) , \n"
Original    (024): ['"dynamicColorArray"', ':', 'IECore', '.', 'Color3fVectorData', '(', '[', 'IECore', '.', 'Color3f', '(', '1', ')', ',', 'IECore', '.', 'Color3f', '(', '2', ')', ']', ')', ',', '\\n']
Tokenized   (046): ['<s>', '"', 'd', 'ynamic', 'Color', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['"', 'd', 'ynamic', 'Color', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠColor', '3', 'f', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (024): ['"dynamicColorArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠColor3fVectorData', 'Ġ(', 'Ġ[', 'ĠIECore', 'Ġ.', 'ĠColor3f', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠColor3f', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : ""dynamicVectorArray" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Vector ) , \n"
Original    (019): ['"dynamicVectorArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', ']', ',', 'IECore', '.', 'GeometricData', '.', 'Interpretation', '.', 'Vector', ')', ',', '\\n']
Tokenized   (038): ['<s>', '"', 'd', 'ynamic', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠVector', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['"', 'd', 'ynamic', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠVector', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['"dynamicVectorArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ.', 'ĠInterpretation', 'Ġ.', 'ĠVector', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : ""fixedVectorArray" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( 1 , 6 ) ] , IECore . GeometricData "dynamicPointArray" : IECore . V3fVectorData ( [ ] , IECore . GeometricData . Interpretation . Point ) , \n"
Original    (046): ['"fixedVectorArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', 'IECore', '.', 'V3f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'IECore', '.', 'GeometricData', '"dynamicPointArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', ']', ',', 'IECore', '.', 'GeometricData', '.', 'Interpretation', '.', 'Point', ')', ',', '\\n']
Tokenized   (083): ['<s>', '"', 'fixed', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ"', 'd', 'ynamic', 'Point', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠPoint', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (081): ['"', 'fixed', 'Vector', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ"', 'd', 'ynamic', 'Point', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ.', 'ĠInterpret', 'ation', 'Ġ.', 'ĠPoint', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (046): ['"fixedVectorArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'ĠIECore', 'Ġ.', 'ĠV3f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ"dynamicPointArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ.', 'ĠInterpretation', 'Ġ.', 'ĠPoint', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 81
===================================================================
Hidden states:  (13, 46, 768)
# Extracted words:  46
Sentence         : ""fixedNormalArray" : IECore . V3fVectorData ( [ IECore . V3f ( x ) for x in range ( 1 , 6 ) ] , IECore . GeometricData } \n"
Original    (029): ['"fixedNormalArray"', ':', 'IECore', '.', 'V3fVectorData', '(', '[', 'IECore', '.', 'V3f', '(', 'x', ')', 'for', 'x', 'in', 'range', '(', '1', ',', '6', ')', ']', ',', 'IECore', '.', 'GeometricData', '}', '\\n']
Tokenized   (050): ['<s>', '"', 'fixed', 'Normal', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (048): ['"', 'fixed', 'Normal', 'Array', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Vector', 'Data', 'Ġ(', 'Ġ[', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠV', '3', 'f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠGe', 'ometric', 'Data', 'Ġ}', 'Ġ\\', 'n']
Detokenized (029): ['"fixedNormalArray"', 'Ġ:', 'ĠIECore', 'Ġ.', 'ĠV3fVectorData', 'Ġ(', 'Ġ[', 'ĠIECore', 'Ġ.', 'ĠV3f', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ6', 'Ġ)', 'Ġ]', 'Ġ,', 'ĠIECore', 'Ġ.', 'ĠGeometricData', 'Ġ}', 'Ġ\\n']
Counter: 48
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "arrayShader = self . compileShader ( os . path . dirname ( __file__ ) + "/shaders/coshaderArrayParameters.sl" n4 = GafferRenderMan . RenderManShader ( ) \n"
Original    (024): ['arrayShader', '=', 'self', '.', 'compileShader', '(', 'os', '.', 'path', '.', 'dirname', '(', '__file__', ')', '+', '"/shaders/coshaderArrayParameters.sl"', 'n4', '=', 'GafferRenderMan', '.', 'RenderManShader', '(', ')', '\\n']
Tokenized   (052): ['<s>', 'array', 'Sh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', 'Array', 'Parameters', '.', 'sl', '"', 'Ġn', '4', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (050): ['array', 'Sh', 'ader', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcompile', 'Sh', 'ader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ+', 'Ġ"/', 'sh', 'aders', '/', 'c', 'osh', 'ader', 'Array', 'Parameters', '.', 'sl', '"', 'Ġn', '4', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['arrayShader', 'Ġ=', 'Ġself', 'Ġ.', 'ĠcompileShader', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ+', 'Ġ"/shaders/coshaderArrayParameters.sl"', 'Ġn4', 'Ġ=', 'ĠGafferRenderMan', 'Ġ.', 'ĠRenderManShader', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 50
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "coshaderNode [ "enabled" ] . setValue ( False ) \n"
Original    (010): ['coshaderNode', '[', '"enabled"', ']', '.', 'setValue', '(', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'c', 'osh', 'ader', 'Node', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['c', 'osh', 'ader', 'Node', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['coshaderNode', 'Ġ[', 'Ġ"enabled"', 'Ġ]', 'Ġ.', 'ĠsetValue', 'Ġ(', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "floatValue = IECore . Splineff ( \n"
Original    (007): ['floatValue', '=', 'IECore', '.', 'Splineff', '(', '\\n']
Tokenized   (015): ['<s>', 'float', 'Value', 'Ġ=', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠSpl', 'ine', 'ff', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['float', 'Value', 'Ġ=', 'ĠI', 'EC', 'ore', 'Ġ.', 'ĠSpl', 'ine', 'ff', 'Ġ(', 'Ġ\\', 'n']
Detokenized (007): ['floatValue', 'Ġ=', 'ĠIECore', 'Ġ.', 'ĠSplineff', 'Ġ(', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "S [ "parameters" ] [ "coshaderParameter" ] . setInput ( D2 [ "out" ] ) \n"
Original    (016): ['S', '[', '"parameters"', ']', '[', '"coshaderParameter"', ']', '.', 'setInput', '(', 'D2', '[', '"out"', ']', ')', '\\n']
Tokenized   (031): ['<s>', 'S', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'c', 'osh', 'ader', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'ĠD', '2', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['S', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'c', 'osh', 'ader', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'ĠD', '2', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['S', 'Ġ[', 'Ġ"parameters"', 'Ġ]', 'Ġ[', 'Ġ"coshaderParameter"', 'Ġ]', 'Ġ.', 'ĠsetInput', 'Ġ(', 'ĠD2', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "coshaderNode0 [ "parameters" ] [ "floatParameter" ] . setValue ( 0 ) \n"
Original    (013): ['coshaderNode0', '[', '"parameters"', ']', '[', '"floatParameter"', ']', '.', 'setValue', '(', '0', ')', '\\n']
Tokenized   (027): ['<s>', 'c', 'osh', 'ader', 'Node', '0', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'float', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['c', 'osh', 'ader', 'Node', '0', 'Ġ[', 'Ġ"', 'param', 'eters', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'float', 'Parameter', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Value', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['coshaderNode0', 'Ġ[', 'Ġ"parameters"', 'Ġ]', 'Ġ[', 'Ġ"floatParameter"', 'Ġ]', 'Ġ.', 'ĠsetValue', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sn1 = GafferRenderMan . RenderManShader ( "Shader1" ) \n"
Original    (009): ['sn1', '=', 'GafferRenderMan', '.', 'RenderManShader', '(', '"Shader1"', ')', '\\n']
Tokenized   (023): ['<s>', 'sn', '1', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'Sh', 'ader', '1', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['sn', '1', 'Ġ=', 'ĠG', 'affer', 'Render', 'Man', 'Ġ.', 'ĠRender', 'Man', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'Sh', 'ader', '1', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['sn1', 'Ġ=', 'ĠGafferRenderMan', 'Ġ.', 'ĠRenderManShader', 'Ġ(', 'Ġ"Shader1"', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "script [ "assignment" ] [ "shader" ] . setInput ( script [ "shader" ] [ "out" ] ) \n"
Original    (019): ['script', '[', '"assignment"', ']', '[', '"shader"', ']', '.', 'setInput', '(', 'script', '[', '"shader"', ']', '[', '"out"', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'script', 'Ġ[', 'Ġ"', 'ass', 'ignment', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['script', 'Ġ[', 'Ġ"', 'ass', 'ignment', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġset', 'Input', 'Ġ(', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ[', 'Ġ"', 'out', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['script', 'Ġ[', 'Ġ"assignment"', 'Ġ]', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ.', 'ĠsetInput', 'Ġ(', 'Ġscript', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ[', 'Ġ"out"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "traverseConnection = Gaffer . ScopedConnection ( GafferSceneTest . connectTraverseSceneToPlugDirtiedSignal script [ "shader" ] . loadShader ( "matte" ) \n"
Original    (019): ['traverseConnection', '=', 'Gaffer', '.', 'ScopedConnection', '(', 'GafferSceneTest', '.', 'connectTraverseSceneToPlugDirtiedSignal', 'script', '[', '"shader"', ']', '.', 'loadShader', '(', '"matte"', ')', '\\n']
Tokenized   (048): ['<s>', 'tra', 'verse', 'Connection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠSc', 'oped', 'Connection', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Test', 'Ġ.', 'Ġconnect', 'Tra', 'verse', 'Scene', 'To', 'Plug', 'D', 'irt', 'ied', 'Sign', 'al', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġload', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'mat', 'te', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['tra', 'verse', 'Connection', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠSc', 'oped', 'Connection', 'Ġ(', 'ĠG', 'affer', 'Scene', 'Test', 'Ġ.', 'Ġconnect', 'Tra', 'verse', 'Scene', 'To', 'Plug', 'D', 'irt', 'ied', 'Sign', 'al', 'Ġscript', 'Ġ[', 'Ġ"', 'sh', 'ader', '"', 'Ġ]', 'Ġ.', 'Ġload', 'Sh', 'ader', 'Ġ(', 'Ġ"', 'mat', 'te', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['traverseConnection', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠScopedConnection', 'Ġ(', 'ĠGafferSceneTest', 'Ġ.', 'ĠconnectTraverseSceneToPlugDirtiedSignal', 'Ġscript', 'Ġ[', 'Ġ"shader"', 'Ġ]', 'Ġ.', 'ĠloadShader', 'Ġ(', 'Ġ"matte"', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "current = s [ "render" ] . hash ( c ) \n"
Original    (012): ['current', '=', 's', '[', '"render"', ']', '.', 'hash', '(', 'c', ')', '\\n']
Tokenized   (017): ['<s>', 'current', 'Ġ=', 'Ġs', 'Ġ[', 'Ġ"', 'render', '"', 'Ġ]', 'Ġ.', 'Ġhash', 'Ġ(', 'Ġc', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['current', 'Ġ=', 'Ġs', 'Ġ[', 'Ġ"', 'render', '"', 'Ġ]', 'Ġ.', 'Ġhash', 'Ġ(', 'Ġc', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['current', 'Ġ=', 'Ġs', 'Ġ[', 'Ġ"render"', 'Ġ]', 'Ġ.', 'Ġhash', 'Ġ(', 'Ġc', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""layout:section" , "Transform" , \n"
Original    (005): ['"layout:section"', ',', '"Transform"', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'layout', ':', 'section', '"', 'Ġ,', 'Ġ"', 'Transform', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'layout', ':', 'section', '"', 'Ġ,', 'Ġ"', 'Transform', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"layout:section"', 'Ġ,', 'Ġ"Transform"', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""toolbarLayout:index" , 2 , \n"
Original    (005): ['"toolbarLayout:index"', ',', '2', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'tool', 'bar', 'Layout', ':', 'index', '"', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'tool', 'bar', 'Layout', ':', 'index', '"', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"toolbarLayout:index"', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""toolbarLayout:divider" , True , \n"
Original    (005): ['"toolbarLayout:divider"', ',', 'True', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'tool', 'bar', 'Layout', ':', 'div', 'ider', '"', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'tool', 'bar', 'Layout', ':', 'div', 'ider', '"', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"toolbarLayout:divider"', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "currentName = self . getPlug ( ) . getValue ( ) \n"
Original    (012): ['currentName', '=', 'self', '.', 'getPlug', '(', ')', '.', 'getValue', '(', ')', '\\n']
Tokenized   (018): ['<s>', 'current', 'Name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['current', 'Name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Value', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['currentName', 'Ġ=', 'Ġself', 'Ġ.', 'ĠgetPlug', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠgetValue', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "menuButton = GafferUI . MenuButton ( menu = menu , image = "grid.png" , hasFrame = False ) \n"
Original    (019): ['menuButton', '=', 'GafferUI', '.', 'MenuButton', '(', 'menu', '=', 'menu', ',', 'image', '=', '"grid.png"', ',', 'hasFrame', '=', 'False', ')', '\\n']
Tokenized   (031): ['<s>', 'menu', 'Button', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Button', 'Ġ(', 'Ġmenu', 'Ġ=', 'Ġmenu', 'Ġ,', 'Ġimage', 'Ġ=', 'Ġ"', 'grid', '.', 'png', '"', 'Ġ,', 'Ġhas', 'Frame', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['menu', 'Button', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Button', 'Ġ(', 'Ġmenu', 'Ġ=', 'Ġmenu', 'Ġ,', 'Ġimage', 'Ġ=', 'Ġ"', 'grid', '.', 'png', '"', 'Ġ,', 'Ġhas', 'Frame', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['menuButton', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠMenuButton', 'Ġ(', 'Ġmenu', 'Ġ=', 'Ġmenu', 'Ġ,', 'Ġimage', 'Ġ=', 'Ġ"grid.png"', 'Ġ,', 'ĠhasFrame', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "p3 = Gaffer . IntPlug ( "sum" , Gaffer . Plug . Direction . Out ) \n"
Original    (017): ['p3', '=', 'Gaffer', '.', 'IntPlug', '(', '"sum"', ',', 'Gaffer', '.', 'Plug', '.', 'Direction', '.', 'Out', ')', '\\n']
Tokenized   (026): ['<s>', 'p', '3', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠInt', 'Plug', 'Ġ(', 'Ġ"', 'sum', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['p', '3', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠInt', 'Plug', 'Ġ(', 'Ġ"', 'sum', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['p3', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠIntPlug', 'Ġ(', 'Ġ"sum"', 'Ġ,', 'ĠGaffer', 'Ġ.', 'ĠPlug', 'Ġ.', 'ĠDirection', 'Ġ.', 'ĠOut', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "childrenStrings = [ str ( c ) for c in children ] \n"
Original    (013): ['childrenStrings', '=', '[', 'str', '(', 'c', ')', 'for', 'c', 'in', 'children', ']', '\\n']
Tokenized   (018): ['<s>', 'children', 'Str', 'ings', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġc', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġchildren', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['children', 'Str', 'ings', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġc', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġchildren', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['childrenStrings', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġc', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġchildren', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "c2 = [ str ( p ) for p in path2 . children ( ) ] \n"
Original    (017): ['c2', '=', '[', 'str', '(', 'p', ')', 'for', 'p', 'in', 'path2', '.', 'children', '(', ')', ']', '\\n']
Tokenized   (022): ['<s>', 'c', '2', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpath', '2', 'Ġ.', 'Ġchildren', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['c', '2', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpath', '2', 'Ġ.', 'Ġchildren', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['c2', 'Ġ=', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpath2', 'Ġ.', 'Ġchildren', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "horizontalAlignment = GafferUI . Label . HorizontalAlignment . Right , \n"
Original    (011): ['horizontalAlignment', '=', 'GafferUI', '.', 'Label', '.', 'HorizontalAlignment', '.', 'Right', ',', '\\n']
Tokenized   (022): ['<s>', 'hor', 'izontal', 'Al', 'ignment', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠLabel', 'Ġ.', 'ĠHor', 'izontal', 'Al', 'ignment', 'Ġ.', 'ĠRight', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['hor', 'izontal', 'Al', 'ignment', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠLabel', 'Ġ.', 'ĠHor', 'izontal', 'Al', 'ignment', 'Ġ.', 'ĠRight', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['horizontalAlignment', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠLabel', 'Ġ.', 'ĠHorizontalAlignment', 'Ġ.', 'ĠRight', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "nameWidget . textWidget ( ) . _qtWidget ( ) . setFixedWidth ( GafferUI . PlugWidget . labelWidth ( ) ) \n"
Original    (021): ['nameWidget', '.', 'textWidget', '(', ')', '.', '_qtWidget', '(', ')', '.', 'setFixedWidth', '(', 'GafferUI', '.', 'PlugWidget', '.', 'labelWidth', '(', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'name', 'Widget', 'Ġ.', 'Ġtext', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'Fixed', 'Width', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPlug', 'Widget', 'Ġ.', 'Ġlabel', 'Width', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['name', 'Widget', 'Ġ.', 'Ġtext', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'Fixed', 'Width', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPlug', 'Widget', 'Ġ.', 'Ġlabel', 'Width', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['nameWidget', 'Ġ.', 'ĠtextWidget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġ_qtWidget', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠsetFixedWidth', 'Ġ(', 'ĠGafferUI', 'Ġ.', 'ĠPlugWidget', 'Ġ.', 'ĠlabelWidth', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "childPlug [ "enabled" ] , \n"
Original    (006): ['childPlug', '[', '"enabled"', ']', ',', '\\n']
Tokenized   (012): ['<s>', 'child', 'Plug', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['child', 'Plug', 'Ġ[', 'Ġ"', 'enabled', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['childPlug', 'Ġ[', 'Ġ"enabled"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "memberPlug = memberPlug if memberPlug is not None else plug . ancestor ( Gaffer . CompoundDataPlug . MemberPlug if memberPlug is None : \n"
Original    (024): ['memberPlug', '=', 'memberPlug', 'if', 'memberPlug', 'is', 'not', 'None', 'else', 'plug', '.', 'ancestor', '(', 'Gaffer', '.', 'CompoundDataPlug', '.', 'MemberPlug', 'if', 'memberPlug', 'is', 'None', ':', '\\n']
Tokenized   (036): ['<s>', 'member', 'Plug', 'Ġ=', 'Ġmember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'Ġnot', 'ĠNone', 'Ġelse', 'Ġplug', 'Ġ.', 'Ġancestor', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠComp', 'ound', 'Data', 'Plug', 'Ġ.', 'ĠMember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'ĠNone', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['member', 'Plug', 'Ġ=', 'Ġmember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'Ġnot', 'ĠNone', 'Ġelse', 'Ġplug', 'Ġ.', 'Ġancestor', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠComp', 'ound', 'Data', 'Plug', 'Ġ.', 'ĠMember', 'Plug', 'Ġif', 'Ġmember', 'Plug', 'Ġis', 'ĠNone', 'Ġ:', 'Ġ\\', 'n']
Detokenized (024): ['memberPlug', 'Ġ=', 'ĠmemberPlug', 'Ġif', 'ĠmemberPlug', 'Ġis', 'Ġnot', 'ĠNone', 'Ġelse', 'Ġplug', 'Ġ.', 'Ġancestor', 'Ġ(', 'ĠGaffer', 'Ġ.', 'ĠCompoundDataPlug', 'Ġ.', 'ĠMemberPlug', 'Ġif', 'ĠmemberPlug', 'Ġis', 'ĠNone', 'Ġ:', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "menuDefinition . append ( "/Delete" , { "command" : IECore . curry ( __deletePlug , memberPlug ) , "active" \n"
Original    (020): ['menuDefinition', '.', 'append', '(', '"/Delete"', ',', '{', '"command"', ':', 'IECore', '.', 'curry', '(', '__deletePlug', ',', 'memberPlug', ')', ',', '"active"', '\\n']
Tokenized   (035): ['<s>', 'menu', 'Definition', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ"/', 'Delete', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'command', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'Ġcurry', 'Ġ(', 'Ġ__', 'delete', 'Plug', 'Ġ,', 'Ġmember', 'Plug', 'Ġ)', 'Ġ,', 'Ġ"', 'active', '"', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['menu', 'Definition', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ"/', 'Delete', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'command', '"', 'Ġ:', 'ĠI', 'EC', 'ore', 'Ġ.', 'Ġcurry', 'Ġ(', 'Ġ__', 'delete', 'Plug', 'Ġ,', 'Ġmember', 'Plug', 'Ġ)', 'Ġ,', 'Ġ"', 'active', '"', 'Ġ\\', 'n']
Detokenized (020): ['menuDefinition', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ"/Delete"', 'Ġ,', 'Ġ{', 'Ġ"command"', 'Ġ:', 'ĠIECore', 'Ġ.', 'Ġcurry', 'Ġ(', 'Ġ__deletePlug', 'Ġ,', 'ĠmemberPlug', 'Ġ)', 'Ġ,', 'Ġ"active"', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "includeSequences = Gaffer . Metadata . plugValue ( self . getPlug ( ) , "fileSystemPathPlugValueWidget:includeSequences" \n"
Original    (016): ['includeSequences', '=', 'Gaffer', '.', 'Metadata', '.', 'plugValue', '(', 'self', '.', 'getPlug', '(', ')', ',', '"fileSystemPathPlugValueWidget:includeSequences"', '\\n']
Tokenized   (036): ['<s>', 'include', 'Sequ', 'ences', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'file', 'System', 'Path', 'Plug', 'Value', 'Widget', ':', 'include', 'Sequ', 'ences', '"', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['include', 'Sequ', 'ences', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'file', 'System', 'Path', 'Plug', 'Value', 'Widget', ':', 'include', 'Sequ', 'ences', '"', 'Ġ\\', 'n']
Detokenized (016): ['includeSequences', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠMetadata', 'Ġ.', 'ĠplugValue', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"fileSystemPathPlugValueWidget:includeSequences"', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "reuse = reuseUntil is not None \n"
Original    (007): ['reuse', '=', 'reuseUntil', 'is', 'not', 'None', '\\n']
Tokenized   (012): ['<s>', 're', 'use', 'Ġ=', 'Ġreuse', 'Until', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['re', 'use', 'Ġ=', 'Ġreuse', 'Until', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ\\', 'n']
Detokenized (007): ['reuse', 'Ġ=', 'ĠreuseUntil', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_MultiLineStringMetadataWidget ( key = "description" ) \n"
Original    (007): ['_MultiLineStringMetadataWidget', '(', 'key', '=', '"description"', ')', '\\n']
Tokenized   (018): ['<s>', '_', 'Multi', 'Line', 'String', 'Met', 'adata', 'Widget', 'Ġ(', 'Ġkey', 'Ġ=', 'Ġ"', 'description', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['_', 'Multi', 'Line', 'String', 'Met', 'adata', 'Widget', 'Ġ(', 'Ġkey', 'Ġ=', 'Ġ"', 'description', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['_MultiLineStringMetadataWidget', 'Ġ(', 'Ġkey', 'Ġ=', 'Ġ"description"', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""active" : isinstance ( node , Gaffer . Box ) or nodeEditor . nodeUI ( ) . plugValueWidget ( node [ "user" ] ) } \n"
Original    (026): ['"active"', ':', 'isinstance', '(', 'node', ',', 'Gaffer', '.', 'Box', ')', 'or', 'nodeEditor', '.', 'nodeUI', '(', ')', '.', 'plugValueWidget', '(', 'node', '[', '"user"', ']', ')', '}', '\\n']
Tokenized   (039): ['<s>', '"', 'active', '"', 'Ġ:', 'Ġis', 'instance', 'Ġ(', 'Ġnode', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠBox', 'Ġ)', 'Ġor', 'Ġnode', 'Editor', 'Ġ.', 'Ġnode', 'UI', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġplug', 'Value', 'Widget', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ"', 'user', '"', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['"', 'active', '"', 'Ġ:', 'Ġis', 'instance', 'Ġ(', 'Ġnode', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠBox', 'Ġ)', 'Ġor', 'Ġnode', 'Editor', 'Ġ.', 'Ġnode', 'UI', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġplug', 'Value', 'Widget', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ"', 'user', '"', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (026): ['"active"', 'Ġ:', 'Ġisinstance', 'Ġ(', 'Ġnode', 'Ġ,', 'ĠGaffer', 'Ġ.', 'ĠBox', 'Ġ)', 'Ġor', 'ĠnodeEditor', 'Ġ.', 'ĠnodeUI', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠplugValueWidget', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ"user"', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "dialogue = GafferUI . ColorChooserDialogue ( color = color , useDisplayTransform = False ) \n"
Original    (015): ['dialogue', '=', 'GafferUI', '.', 'ColorChooserDialogue', '(', 'color', '=', 'color', ',', 'useDisplayTransform', '=', 'False', ')', '\\n']
Tokenized   (026): ['<s>', 'dial', 'ogue', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠColor', 'Cho', 'oser', 'Dialogue', 'Ġ(', 'Ġcolor', 'Ġ=', 'Ġcolor', 'Ġ,', 'Ġuse', 'Display', 'Transform', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['dial', 'ogue', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠColor', 'Cho', 'oser', 'Dialogue', 'Ġ(', 'Ġcolor', 'Ġ=', 'Ġcolor', 'Ġ,', 'Ġuse', 'Display', 'Transform', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['dialogue', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠColorChooserDialogue', 'Ġ(', 'Ġcolor', 'Ġ=', 'Ġcolor', 'Ġ,', 'ĠuseDisplayTransform', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "editor . plugEditor ( ) . reveal ( ) \n"
Original    (010): ['editor', '.', 'plugEditor', '(', ')', '.', 'reveal', '(', ')', '\\n']
Tokenized   (014): ['<s>', 'editor', 'Ġ.', 'Ġplug', 'Editor', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreveal', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['editor', 'Ġ.', 'Ġplug', 'Editor', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreveal', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['editor', 'Ġ.', 'ĠplugEditor', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreveal', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_MetadataWidget . __init__ ( self , self . __menuButton , key , target , parenting = parenting ) \n"
Original    (019): ['_MetadataWidget', '.', '__init__', '(', 'self', ',', 'self', '.', '__menuButton', ',', 'key', ',', 'target', ',', 'parenting', '=', 'parenting', ')', '\\n']
Tokenized   (029): ['<s>', '_', 'Met', 'adata', 'Widget', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'menu', 'Button', 'Ġ,', 'Ġkey', 'Ġ,', 'Ġtarget', 'Ġ,', 'Ġparenting', 'Ġ=', 'Ġparenting', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['_', 'Met', 'adata', 'Widget', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'menu', 'Button', 'Ġ,', 'Ġkey', 'Ġ,', 'Ġtarget', 'Ġ,', 'Ġparenting', 'Ġ=', 'Ġparenting', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['_MetadataWidget', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__menuButton', 'Ġ,', 'Ġkey', 'Ġ,', 'Ġtarget', 'Ġ,', 'Ġparenting', 'Ġ=', 'Ġparenting', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : ""checkBox" : value == self . __currentValue \n"
Original    (008): ['"checkBox"', ':', 'value', '==', 'self', '.', '__currentValue', '\\n']
Tokenized   (016): ['<s>', '"', 'check', 'Box', '"', 'Ġ:', 'Ġvalue', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ__', 'current', 'Value', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['"', 'check', 'Box', '"', 'Ġ:', 'Ġvalue', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ__', 'current', 'Value', 'Ġ\\', 'n']
Detokenized (008): ['"checkBox"', 'Ġ:', 'Ġvalue', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ__currentValue', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "child . __parent = None \n"
Original    (006): ['child', '.', '__parent', '=', 'None', '\\n']
Tokenized   (010): ['<s>', 'child', 'Ġ.', 'Ġ__', 'parent', 'Ġ=', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['child', 'Ġ.', 'Ġ__', 'parent', 'Ġ=', 'ĠNone', 'Ġ\\', 'n']
Detokenized (006): ['child', 'Ġ.', 'Ġ__parent', 'Ġ=', 'ĠNone', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "columns = ( GafferUI . PathListingWidget . defaultNameColumn , ) , \n"
Original    (012): ['columns', '=', '(', 'GafferUI', '.', 'PathListingWidget', '.', 'defaultNameColumn', ',', ')', ',', '\\n']
Tokenized   (023): ['<s>', 'column', 's', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPath', 'List', 'ing', 'Widget', 'Ġ.', 'Ġdefault', 'Name', 'Column', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['column', 's', 'Ġ=', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠPath', 'List', 'ing', 'Widget', 'Ġ.', 'Ġdefault', 'Name', 'Column', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['columns', 'Ġ=', 'Ġ(', 'ĠGafferUI', 'Ġ.', 'ĠPathListingWidget', 'Ġ.', 'ĠdefaultNameColumn', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "definition = Gaffer . WeakMethod ( self . __addMenuDefinition ) \n"
Original    (011): ['definition', '=', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__addMenuDefinition', ')', '\\n']
Tokenized   (019): ['<s>', 'definition', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'add', 'Menu', 'Definition', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['definition', 'Ġ=', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'add', 'Menu', 'Definition', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['definition', 'Ġ=', 'ĠGaffer', 'Ġ.', 'ĠWeakMethod', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__addMenuDefinition', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "newIndex = 0 if event . line . p0 . y < 1 else len ( newParent ) \n"
Original    (019): ['newIndex', '=', '0', 'if', 'event', '.', 'line', '.', 'p0', '.', 'y', '<', '1', 'else', 'len', '(', 'newParent', ')', '\\n']
Tokenized   (025): ['<s>', 'new', 'Index', 'Ġ=', 'Ġ0', 'Ġif', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ.', 'Ġy', 'Ġ<', 'Ġ1', 'Ġelse', 'Ġlen', 'Ġ(', 'Ġnew', 'Parent', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', 'Index', 'Ġ=', 'Ġ0', 'Ġif', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ.', 'Ġy', 'Ġ<', 'Ġ1', 'Ġelse', 'Ġlen', 'Ġ(', 'Ġnew', 'Parent', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['newIndex', 'Ġ=', 'Ġ0', 'Ġif', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp0', 'Ġ.', 'Ġy', 'Ġ<', 'Ġ1', 'Ġelse', 'Ġlen', 'Ġ(', 'ĠnewParent', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "newParent . insert ( newIndex , self . __dragItem ) \n"
Original    (011): ['newParent', '.', 'insert', '(', 'newIndex', ',', 'self', '.', '__dragItem', ')', '\\n']
Tokenized   (019): ['<s>', 'new', 'Parent', 'Ġ.', 'Ġinsert', 'Ġ(', 'Ġnew', 'Index', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['new', 'Parent', 'Ġ.', 'Ġinsert', 'Ġ(', 'Ġnew', 'Index', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['newParent', 'Ġ.', 'Ġinsert', 'Ġ(', 'ĠnewIndex', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ__dragItem', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "selection [ : ] = self . __dragItem . fullName ( ) . split ( "." ) \n"
Original    (018): ['selection', '[', ':', ']', '=', 'self', '.', '__dragItem', '.', 'fullName', '(', ')', '.', 'split', '(', '"."', ')', '\\n']
Tokenized   (026): ['<s>', 'selection', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ"', '."', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['selection', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'dr', 'ag', 'Item', 'Ġ.', 'Ġfull', 'Name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ"', '."', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['selection', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__dragItem', 'Ġ.', 'ĠfullName', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ"."', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "_registerMetadata ( plug , "nodule:type" , "" ) \n"
Original    (009): ['_registerMetadata', '(', 'plug', ',', '"nodule:type"', ',', '""', ')', '\\n']
Tokenized   (021): ['<s>', '_', 'register', 'Met', 'adata', 'Ġ(', 'Ġplug', 'Ġ,', 'Ġ"', 'n', 'od', 'ule', ':', 'type', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['_', 'register', 'Met', 'adata', 'Ġ(', 'Ġplug', 'Ġ,', 'Ġ"', 'n', 'od', 'ule', ':', 'type', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['_registerMetadata', 'Ġ(', 'Ġplug', 'Ġ,', 'Ġ"nodule:type"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "parentItem \n"
Original    (002): ['parentItem', '\\n']
Tokenized   (006): ['<s>', 'parent', 'Item', 'Ġ\\', 'n', '</s>']
Filtered   (004): ['parent', 'Item', 'Ġ\\', 'n']
Detokenized (002): ['parentItem', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "existingSectionNames = set ( c . name ( ) for c in rootItem if isinstance ( c , _SectionLayoutItem ) ) \n"
Original    (022): ['existingSectionNames', '=', 'set', '(', 'c', '.', 'name', '(', ')', 'for', 'c', 'in', 'rootItem', 'if', 'isinstance', '(', 'c', ',', '_SectionLayoutItem', ')', ')', '\\n']
Tokenized   (032): ['<s>', 'existing', 'Section', 'Names', 'Ġ=', 'Ġset', 'Ġ(', 'Ġc', 'Ġ.', 'Ġname', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġroot', 'Item', 'Ġif', 'Ġis', 'instance', 'Ġ(', 'Ġc', 'Ġ,', 'Ġ_', 'Section', 'Layout', 'Item', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['existing', 'Section', 'Names', 'Ġ=', 'Ġset', 'Ġ(', 'Ġc', 'Ġ.', 'Ġname', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'Ġroot', 'Item', 'Ġif', 'Ġis', 'instance', 'Ġ(', 'Ġc', 'Ġ,', 'Ġ_', 'Section', 'Layout', 'Item', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['existingSectionNames', 'Ġ=', 'Ġset', 'Ġ(', 'Ġc', 'Ġ.', 'Ġname', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġc', 'Ġin', 'ĠrootItem', 'Ġif', 'Ġisinstance', 'Ġ(', 'Ġc', 'Ġ,', 'Ġ_SectionLayoutItem', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "Gaffer . Metadata . plugValue ( self . getPlug ( ) , "preset:" + selectedPaths [ 0 ] [ 0 ] ) \n"
Original    (023): ['Gaffer', '.', 'Metadata', '.', 'plugValue', '(', 'self', '.', 'getPlug', '(', ')', ',', '"preset:"', '+', 'selectedPaths', '[', '0', ']', '[', '0', ']', ')', '\\n']
Tokenized   (035): ['<s>', 'G', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'pres', 'et', ':"', 'Ġ+', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['G', 'affer', 'Ġ.', 'ĠMet', 'adata', 'Ġ.', 'Ġplug', 'Value', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"', 'pres', 'et', ':"', 'Ġ+', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['Gaffer', 'Ġ.', 'ĠMetadata', 'Ġ.', 'ĠplugValue', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlug', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ"preset:"', 'Ġ+', 'ĠselectedPaths', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "srcPath = self . __pathListing . getPath ( ) . copy ( ) . setFromString ( event . data [ 0 ] ) \n"
Original    (024): ['srcPath', '=', 'self', '.', '__pathListing', '.', 'getPath', '(', ')', '.', 'copy', '(', ')', '.', 'setFromString', '(', 'event', '.', 'data', '[', '0', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'src', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Path', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcopy', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'From', 'String', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['src', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Path', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcopy', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġset', 'From', 'String', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['srcPath', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__pathListing', 'Ġ.', 'ĠgetPath', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcopy', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠsetFromString', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "srcIndex = d . keys ( ) . index ( srcPath [ 0 ] ) \n"
Original    (016): ['srcIndex', '=', 'd', '.', 'keys', '(', ')', '.', 'index', '(', 'srcPath', '[', '0', ']', ')', '\\n']
Tokenized   (021): ['<s>', 'src', 'Index', 'Ġ=', 'Ġd', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġsrc', 'Path', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['src', 'Index', 'Ġ=', 'Ġd', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġsrc', 'Path', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['srcIndex', 'Ġ=', 'Ġd', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġindex', 'Ġ(', 'ĠsrcPath', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "targetPath = self . __pathListing . pathAt ( event . line . p0 ) \n"
Original    (015): ['targetPath', '=', 'self', '.', '__pathListing', '.', 'pathAt', '(', 'event', '.', 'line', '.', 'p0', ')', '\\n']
Tokenized   (024): ['<s>', 'target', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġpath', 'At', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['target', 'Path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġpath', 'At', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp', '0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['targetPath', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__pathListing', 'Ġ.', 'ĠpathAt', 'Ġ(', 'Ġevent', 'Ġ.', 'Ġline', 'Ġ.', 'Ġp0', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "item = items [ srcIndex ] \n"
Original    (007): ['item', '=', 'items', '[', 'srcIndex', ']', '\\n']
Tokenized   (011): ['<s>', 'item', 'Ġ=', 'Ġitems', 'Ġ[', 'Ġsrc', 'Index', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['item', 'Ġ=', 'Ġitems', 'Ġ[', 'Ġsrc', 'Index', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['item', 'Ġ=', 'Ġitems', 'Ġ[', 'ĠsrcIndex', 'Ġ]', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "selectedPreset = self . __pathListing . getSelectedPaths ( ) [ 0 ] [ 0 ] \n"
Original    (016): ['selectedPreset', '=', 'self', '.', '__pathListing', '.', 'getSelectedPaths', '(', ')', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (028): ['<s>', 'selected', 'Pres', 'et', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Se', 'lected', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['selected', 'Pres', 'et', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__', 'path', 'List', 'ing', 'Ġ.', 'Ġget', 'Se', 'lected', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['selectedPreset', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ__pathListing', 'Ġ.', 'ĠgetSelectedPaths', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "selectedIndex = [ p [ 0 ] for p in paths ] . index ( selectedPreset ) \n"
Original    (018): ['selectedIndex', '=', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'paths', ']', '.', 'index', '(', 'selectedPreset', ')', '\\n']
Tokenized   (024): ['<s>', 'selected', 'Index', 'Ġ=', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġpaths', 'Ġ]', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġselected', 'Pres', 'et', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['selected', 'Index', 'Ġ=', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġpaths', 'Ġ]', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġselected', 'Pres', 'et', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['selectedIndex', 'Ġ=', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġpaths', 'Ġ]', 'Ġ.', 'Ġindex', 'Ġ(', 'ĠselectedPreset', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "preset = selectedPaths [ 0 ] [ 0 ] \n"
Original    (010): ['preset', '=', 'selectedPaths', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (016): ['<s>', 'pres', 'et', 'Ġ=', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['pres', 'et', 'Ġ=', 'Ġselected', 'Path', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['preset', 'Ġ=', 'ĠselectedPaths', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "scrolledContainer . setChild ( GafferUI . ListContainer ( spacing = 4 ) ) \n"
Original    (014): ['scrolledContainer', '.', 'setChild', '(', 'GafferUI', '.', 'ListContainer', '(', 'spacing', '=', '4', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'sc', 'rolled', 'Container', 'Ġ.', 'Ġset', 'Child', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠList', 'Container', 'Ġ(', 'Ġspacing', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['sc', 'rolled', 'Container', 'Ġ.', 'Ġset', 'Child', 'Ġ(', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠList', 'Container', 'Ġ(', 'Ġspacing', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['scrolledContainer', 'Ġ.', 'ĠsetChild', 'Ġ(', 'ĠGafferUI', 'Ġ.', 'ĠListContainer', 'Ġ(', 'Ġspacing', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "menu = GafferUI . Menu ( Gaffer . WeakMethod ( self . __gadgetMenuDefinition ) ) \n"
Original    (016): ['menu', '=', 'GafferUI', '.', 'Menu', '(', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__gadgetMenuDefinition', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'menu', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'g', 'ad', 'get', 'Menu', 'Definition', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['menu', 'Ġ=', 'ĠG', 'affer', 'UI', 'Ġ.', 'ĠMenu', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'g', 'ad', 'get', 'Menu', 'Definition', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['menu', 'Ġ=', 'ĠGafferUI', 'Ġ.', 'ĠMenu', 'Ġ(', 'ĠGaffer', 'Ġ.', 'ĠWeakMethod', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__gadgetMenuDefinition', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""/" + g . label , \n"
Original    (007): ['"/"', '+', 'g', '.', 'label', ',', '\\n']
Tokenized   (011): ['<s>', '"', '/"', 'Ġ+', 'Ġg', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['"', '/"', 'Ġ+', 'Ġg', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"/"', 'Ġ+', 'Ġg', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""command" : functools . partial ( Gaffer . WeakMethod ( self . __registerOrDeregisterMetadata ) , key = "checkBox" : metadata == g . metadata , \n"
Original    (026): ['"command"', ':', 'functools', '.', 'partial', '(', 'Gaffer', '.', 'WeakMethod', '(', 'self', '.', '__registerOrDeregisterMetadata', ')', ',', 'key', '=', '"checkBox"', ':', 'metadata', '==', 'g', '.', 'metadata', ',', '\\n']
Tokenized   (046): ['<s>', '"', 'command', '"', 'Ġ:', 'Ġfun', 'ct', 'ools', 'Ġ.', 'Ġpartial', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'register', 'Or', 'D', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ)', 'Ġ,', 'Ġkey', 'Ġ=', 'Ġ"', 'check', 'Box', '"', 'Ġ:', 'Ġmetadata', 'Ġ==', 'Ġg', 'Ġ.', 'Ġmetadata', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['"', 'command', '"', 'Ġ:', 'Ġfun', 'ct', 'ools', 'Ġ.', 'Ġpartial', 'Ġ(', 'ĠG', 'affer', 'Ġ.', 'ĠWeak', 'Method', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'register', 'Or', 'D', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ)', 'Ġ,', 'Ġkey', 'Ġ=', 'Ġ"', 'check', 'Box', '"', 'Ġ:', 'Ġmetadata', 'Ġ==', 'Ġg', 'Ġ.', 'Ġmetadata', 'Ġ,', 'Ġ\\', 'n']
Detokenized (026): ['"command"', 'Ġ:', 'Ġfunctools', 'Ġ.', 'Ġpartial', 'Ġ(', 'ĠGaffer', 'Ġ.', 'ĠWeakMethod', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__registerOrDeregisterMetadata', 'Ġ)', 'Ġ,', 'Ġkey', 'Ġ=', 'Ġ"checkBox"', 'Ġ:', 'Ġmetadata', 'Ġ==', 'Ġg', 'Ġ.', 'Ġmetadata', 'Ġ,', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "__WidgetDefinition ( "None" , Gaffer . Plug , "" ) , \n"
Original    (012): ['__WidgetDefinition', '(', '"None"', ',', 'Gaffer', '.', 'Plug', ',', '""', ')', ',', '\\n']
Tokenized   (020): ['<s>', '__', 'Widget', 'Definition', 'Ġ(', 'Ġ"', 'None', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['__', 'Widget', 'Definition', 'Ġ(', 'Ġ"', 'None', '"', 'Ġ,', 'ĠG', 'affer', 'Ġ.', 'ĠPlug', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['__WidgetDefinition', 'Ġ(', 'Ġ"None"', 'Ġ,', 'ĠGaffer', 'Ġ.', 'ĠPlug', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "__MetadataDefinition = collections . namedtuple ( "MetadataDefinition" , ( "key" , "label" , "metadataWidgetType" __metadataDefinitions = ( \n"
Original    (018): ['__MetadataDefinition', '=', 'collections', '.', 'namedtuple', '(', '"MetadataDefinition"', ',', '(', '"key"', ',', '"label"', ',', '"metadataWidgetType"', '__metadataDefinitions', '=', '(', '\\n']
Tokenized   (041): ['<s>', '__', 'Met', 'adata', 'Definition', 'Ġ=', 'Ġcollections', 'Ġ.', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'Met', 'adata', 'Definition', '"', 'Ġ,', 'Ġ(', 'Ġ"', 'key', '"', 'Ġ,', 'Ġ"', 'label', '"', 'Ġ,', 'Ġ"', 'metadata', 'Widget', 'Type', '"', 'Ġ__', 'metadata', 'Def', 'initions', 'Ġ=', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['__', 'Met', 'adata', 'Definition', 'Ġ=', 'Ġcollections', 'Ġ.', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'Met', 'adata', 'Definition', '"', 'Ġ,', 'Ġ(', 'Ġ"', 'key', '"', 'Ġ,', 'Ġ"', 'label', '"', 'Ġ,', 'Ġ"', 'metadata', 'Widget', 'Type', '"', 'Ġ__', 'metadata', 'Def', 'initions', 'Ġ=', 'Ġ(', 'Ġ\\', 'n']
Detokenized (018): ['__MetadataDefinition', 'Ġ=', 'Ġcollections', 'Ġ.', 'Ġnamedtuple', 'Ġ(', 'Ġ"MetadataDefinition"', 'Ġ,', 'Ġ(', 'Ġ"key"', 'Ġ,', 'Ġ"label"', 'Ġ,', 'Ġ"metadataWidgetType"', 'Ġ__metadataDefinitions', 'Ġ=', 'Ġ(', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "newSectionPath [ - 1 ] = nameWidget . getText ( ) . replace ( "." , "" ) \n"
Original    (019): ['newSectionPath', '[', '-', '1', ']', '=', 'nameWidget', '.', 'getText', '(', ')', '.', 'replace', '(', '"."', ',', '""', ')', '\\n']
Tokenized   (027): ['<s>', 'new', 'Section', 'Path', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġname', 'Widget', 'Ġ.', 'Ġget', 'Text', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '."', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['new', 'Section', 'Path', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġname', 'Widget', 'Ġ.', 'Ġget', 'Text', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"', '."', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['newSectionPath', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'ĠnameWidget', 'Ġ.', 'ĠgetText', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"."', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "_metadata ( self . getPlugParent ( ) , name ) \n"
Original    (011): ['_metadata', '(', 'self', '.', 'getPlugParent', '(', ')', ',', 'name', ')', '\\n']
Tokenized   (017): ['<s>', '_', 'metadata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['_', 'metadata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_metadata', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlugParent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_deregisterMetadata ( self . getPlugParent ( ) , name ) \n"
Original    (011): ['_deregisterMetadata', '(', 'self', '.', 'getPlugParent', '(', ')', ',', 'name', ')', '\\n']
Tokenized   (022): ['<s>', '_', 'd', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'd', 'ere', 'g', 'ister', 'Met', 'adata', 'Ġ(', 'Ġself', 'Ġ.', 'Ġget', 'Plug', 'Parent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_deregisterMetadata', 'Ġ(', 'Ġself', 'Ġ.', 'ĠgetPlugParent', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "wr2 = weakref . ref ( w . _qtWidget ( ) ) \n"
Original    (013): ['wr2', '=', 'weakref', '.', 'ref', '(', 'w', '.', '_qtWidget', '(', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'wr', '2', 'Ġ=', 'Ġweak', 'ref', 'Ġ.', 'Ġref', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['wr', '2', 'Ġ=', 'Ġweak', 'ref', 'Ġ.', 'Ġref', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['wr2', 'Ġ=', 'Ġweakref', 'Ġ.', 'Ġref', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_qtWidget', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "WidgetTest . signalsEmitted = 0 \n"
Original    (006): ['WidgetTest', '.', 'signalsEmitted', '=', '0', '\\n']
Tokenized   (012): ['<s>', 'Widget', 'Test', 'Ġ.', 'Ġsignals', 'E', 'mitted', 'Ġ=', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Widget', 'Test', 'Ġ.', 'Ġsignals', 'E', 'mitted', 'Ġ=', 'Ġ0', 'Ġ\\', 'n']
Detokenized (006): ['WidgetTest', 'Ġ.', 'ĠsignalsEmitted', 'Ġ=', 'Ġ0', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "QtGui . QApplication . instance ( ) . sendEvent ( w . _qtWidget ( ) , event ) \n"
Original    (019): ['QtGui', '.', 'QApplication', '.', 'instance', '(', ')', '.', 'sendEvent', '(', 'w', '.', '_qtWidget', '(', ')', ',', 'event', ')', '\\n']
Tokenized   (029): ['<s>', 'Q', 't', 'Gu', 'i', 'Ġ.', 'ĠQ', 'Application', 'Ġ.', 'Ġinstance', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsend', 'Event', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġevent', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['Q', 't', 'Gu', 'i', 'Ġ.', 'ĠQ', 'Application', 'Ġ.', 'Ġinstance', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsend', 'Event', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_', 'qt', 'Widget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġevent', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['QtGui', 'Ġ.', 'ĠQApplication', 'Ġ.', 'Ġinstance', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠsendEvent', 'Ġ(', 'Ġw', 'Ġ.', 'Ġ_qtWidget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġevent', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "GafferUI . BoxUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition ) \n"
Original    (013): ['GafferUI', '.', 'BoxUI', '.', 'appendNodeEditorToolMenuDefinitions', '(', 'nodeEditor', ',', 'node', ',', 'menuDefinition', ')', '\\n']
Tokenized   (027): ['<s>', 'G', 'affer', 'UI', 'Ġ.', 'ĠBox', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['G', 'affer', 'UI', 'Ġ.', 'ĠBox', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['GafferUI', 'Ġ.', 'ĠBoxUI', 'Ġ.', 'ĠappendNodeEditorToolMenuDefinitions', 'Ġ(', 'ĠnodeEditor', 'Ġ,', 'Ġnode', 'Ġ,', 'ĠmenuDefinition', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "GafferSceneUI . FilteredSceneProcessorUI . appendNodeEditorToolMenuDefinitions ( nodeEditor , node , menuDefinition \n"
Original    (012): ['GafferSceneUI', '.', 'FilteredSceneProcessorUI', '.', 'appendNodeEditorToolMenuDefinitions', '(', 'nodeEditor', ',', 'node', ',', 'menuDefinition', '\\n']
Tokenized   (031): ['<s>', 'G', 'affer', 'Scene', 'UI', 'Ġ.', 'ĠFil', 'tered', 'Scene', 'Process', 'or', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['G', 'affer', 'Scene', 'UI', 'Ġ.', 'ĠFil', 'tered', 'Scene', 'Process', 'or', 'UI', 'Ġ.', 'Ġappend', 'Node', 'Editor', 'Tool', 'Menu', 'Def', 'initions', 'Ġ(', 'Ġnode', 'Editor', 'Ġ,', 'Ġnode', 'Ġ,', 'Ġmenu', 'Definition', 'Ġ\\', 'n']
Detokenized (012): ['GafferSceneUI', 'Ġ.', 'ĠFilteredSceneProcessorUI', 'Ġ.', 'ĠappendNodeEditorToolMenuDefinitions', 'Ġ(', 'ĠnodeEditor', 'Ġ,', 'Ġnode', 'Ġ,', 'ĠmenuDefinition', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "yappi . print_stats ( sort_type = yappi . SORTTYPE_TTOT , limit = 30 , thread_stats_on = False ) \n"
Original    (019): ['yappi', '.', 'print_stats', '(', 'sort_type', '=', 'yappi', '.', 'SORTTYPE_TTOT', ',', 'limit', '=', '30', ',', 'thread_stats_on', '=', 'False', ')', '\\n']
Tokenized   (039): ['<s>', 'y', 'app', 'i', 'Ġ.', 'Ġprint', '_', 'stats', 'Ġ(', 'Ġsort', '_', 'type', 'Ġ=', 'Ġy', 'app', 'i', 'Ġ.', 'ĠS', 'ORT', 'TYPE', '_', 'TT', 'OT', 'Ġ,', 'Ġlimit', 'Ġ=', 'Ġ30', 'Ġ,', 'Ġthread', '_', 'stats', '_', 'on', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['y', 'app', 'i', 'Ġ.', 'Ġprint', '_', 'stats', 'Ġ(', 'Ġsort', '_', 'type', 'Ġ=', 'Ġy', 'app', 'i', 'Ġ.', 'ĠS', 'ORT', 'TYPE', '_', 'TT', 'OT', 'Ġ,', 'Ġlimit', 'Ġ=', 'Ġ30', 'Ġ,', 'Ġthread', '_', 'stats', '_', 'on', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['yappi', 'Ġ.', 'Ġprint_stats', 'Ġ(', 'Ġsort_type', 'Ġ=', 'Ġyappi', 'Ġ.', 'ĠSORTTYPE_TTOT', 'Ġ,', 'Ġlimit', 'Ġ=', 'Ġ30', 'Ġ,', 'Ġthread_stats_on', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "SAMPLE_EXTRACT_METRICS_PAGE = os . path . join ( datadir , "monthly_download" ) \n"
Original    (013): ['SAMPLE_EXTRACT_METRICS_PAGE', '=', 'os', '.', 'path', '.', 'join', '(', 'datadir', ',', '"monthly_download"', ')', '\\n']
Tokenized   (035): ['<s>', 'SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['SAMPLE_EXTRACT_METRICS_PAGE', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdatadir', 'Ġ,', 'Ġ"monthly_download"', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH = os . path . join ( datadir , "monthly_download_different_month" \n"
Original    (012): ['SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', '=', 'os', '.', 'path', '.', 'join', '(', 'datadir', ',', '"monthly_download_different_month"', '\\n']
Tokenized   (046): ['<s>', 'SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '_', 'different', '_', 'month', '"', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['SAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdat', 'ad', 'ir', 'Ġ,', 'Ġ"', 'month', 'ly', '_', 'download', '_', 'different', '_', 'month', '"', 'Ġ\\', 'n']
Detokenized (012): ['SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdatadir', 'Ġ,', 'Ġ"monthly_download_different_month"', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "testitem_aliases = ( "pmid" , TEST_PMID ) \n"
Original    (008): ['testitem_aliases', '=', '(', '"pmid"', ',', 'TEST_PMID', ')', '\\n']
Tokenized   (021): ['<s>', 'test', 'item', '_', 'ali', 'ases', 'Ġ=', 'Ġ(', 'Ġ"', 'pm', 'id', '"', 'Ġ,', 'ĠTEST', '_', 'PM', 'ID', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['test', 'item', '_', 'ali', 'ases', 'Ġ=', 'Ġ(', 'Ġ"', 'pm', 'id', '"', 'Ġ,', 'ĠTEST', '_', 'PM', 'ID', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['testitem_aliases', 'Ġ=', 'Ġ(', 'Ġ"pmid"', 'Ġ,', 'ĠTEST_PMID', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sample_data_dump = open ( SAMPLE_EXTRACT_METRICS_PAGE , "r" ) . read ( ) \n"
Original    (013): ['sample_data_dump', '=', 'open', '(', 'SAMPLE_EXTRACT_METRICS_PAGE', ',', '"r"', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (034): ['<s>', 'sample', '_', 'data', '_', 'dump', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['sample', '_', 'data', '_', 'dump', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['sample_data_dump', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAMPLE_EXTRACT_METRICS_PAGE', 'Ġ,', 'Ġ"r"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sample_data_dump_different_month = open ( SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH , "r" ) . read \n"
Original    (011): ['sample_data_dump_different_month', '=', 'open', '(', 'SAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', ',', '"r"', ')', '.', 'read', '\\n']
Tokenized   (044): ['<s>', 'sample', '_', 'data', '_', 'dump', '_', 'different', '_', 'month', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['sample', '_', 'data', '_', 'dump', '_', 'different', '_', 'month', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAM', 'PLE', '_', 'EX', 'TR', 'ACT', '_', 'MET', 'R', 'ICS', '_', 'PA', 'GE', '_', 'D', 'IF', 'FER', 'ENT', '_', 'MON', 'TH', 'Ġ,', 'Ġ"', 'r', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ\\', 'n']
Detokenized (011): ['sample_data_dump_different_month', 'Ġ=', 'Ġopen', 'Ġ(', 'ĠSAMPLE_EXTRACT_METRICS_PAGE_DIFFERENT_MONTH', 'Ġ,', 'Ġ"r"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""max_event_date" : "2012-01-31T07:34:01.126892" \n"
Original    (004): ['"max_event_date"', ':', '"2012-01-31T07:34:01.126892"', '\\n']
Tokenized   (029): ['<s>', '"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '01', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '01', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ\\', 'n']
Detokenized (004): ['"max_event_date"', 'Ġ:', 'Ġ"2012-01-31T07:34:01.126892"', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : ""_id" : "abc123" , \n"
Original    (005): ['"_id"', ':', '"abc123"', ',', '\\n']
Tokenized   (014): ['<s>', '"', '_', 'id', '"', 'Ġ:', 'Ġ"', 'abc', '123', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', '_', 'id', '"', 'Ġ:', 'Ġ"', 'abc', '123', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['"_id"', 'Ġ:', 'Ġ"abc123"', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""raw" : "max_event_date" : "2012-10-31T07:34:01.126892" , \n"
Original    (007): ['"raw"', ':', '"max_event_date"', ':', '"2012-10-31T07:34:01.126892"', ',', '\\n']
Tokenized   (034): ['<s>', '"', 'raw', '"', 'Ġ:', 'Ġ"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '10', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['"', 'raw', '"', 'Ġ:', 'Ġ"', 'max', '_', 'event', '_', 'date', '"', 'Ġ:', 'Ġ"', '2012', '-', '10', '-', '31', 'T', '07', ':', '34', ':', '01', '.', '12', '68', '92', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"raw"', 'Ġ:', 'Ġ"max_event_date"', 'Ġ:', 'Ġ"2012-10-31T07:34:01.126892"', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""23110252" \n"
Original    (002): ['"23110252"', '\\n']
Tokenized   (009): ['<s>', '"', '23', '110', '252', '"', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['"', '23', '110', '252', '"', 'Ġ\\', 'n']
Detokenized (002): ['"23110252"', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "cache_client = redis . from_url ( os . getenv ( "REDIS_URL" ) , REDIS_CACHE_DATABASE_NUMBER ) \n"
Original    (016): ['cache_client', '=', 'redis', '.', 'from_url', '(', 'os', '.', 'getenv', '(', '"REDIS_URL"', ')', ',', 'REDIS_CACHE_DATABASE_NUMBER', ')', '\\n']
Tokenized   (043): ['<s>', 'cache', '_', 'client', 'Ġ=', 'Ġred', 'is', 'Ġ.', 'Ġfrom', '_', 'url', 'Ġ(', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'RED', 'IS', '_', 'URL', '"', 'Ġ)', 'Ġ,', 'ĠRED', 'IS', '_', 'C', 'AC', 'HE', '_', 'D', 'AT', 'AB', 'ASE', '_', 'NUM', 'BER', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['cache', '_', 'client', 'Ġ=', 'Ġred', 'is', 'Ġ.', 'Ġfrom', '_', 'url', 'Ġ(', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'RED', 'IS', '_', 'URL', '"', 'Ġ)', 'Ġ,', 'ĠRED', 'IS', '_', 'C', 'AC', 'HE', '_', 'D', 'AT', 'AB', 'ASE', '_', 'NUM', 'BER', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['cache_client', 'Ġ=', 'Ġredis', 'Ġ.', 'Ġfrom_url', 'Ġ(', 'Ġos', 'Ġ.', 'Ġgetenv', 'Ġ(', 'Ġ"REDIS_URL"', 'Ġ)', 'Ġ,', 'ĠREDIS_CACHE_DATABASE_NUMBER', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "MAX_CACHE_SIZE_BYTES = 100 * 1000 * 1000 #100mb \n"
Original    (009): ['MAX_CACHE_SIZE_BYTES', '=', '100', '*', '1000', '*', '1000', '#100mb', '\\n']
Tokenized   (024): ['<s>', 'MAX', '_', 'C', 'AC', 'HE', '_', 'SIZE', '_', 'BY', 'T', 'ES', 'Ġ=', 'Ġ100', 'Ġ*', 'Ġ1000', 'Ġ*', 'Ġ1000', 'Ġ#', '100', 'mb', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['MAX', '_', 'C', 'AC', 'HE', '_', 'SIZE', '_', 'BY', 'T', 'ES', 'Ġ=', 'Ġ100', 'Ġ*', 'Ġ1000', 'Ġ*', 'Ġ1000', 'Ġ#', '100', 'mb', 'Ġ\\', 'n']
Detokenized (009): ['MAX_CACHE_SIZE_BYTES', 'Ġ=', 'Ġ100', 'Ġ*', 'Ġ1000', 'Ġ*', 'Ġ1000', 'Ġ#100mb', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "set_response = mc . set ( hash_key , json . dumps ( data ) ) \n"
Original    (016): ['set_response', '=', 'mc', '.', 'set', '(', 'hash_key', ',', 'json', '.', 'dumps', '(', 'data', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'set', '_', 'response', 'Ġ=', 'Ġmc', 'Ġ.', 'Ġset', 'Ġ(', 'Ġhash', '_', 'key', 'Ġ,', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġdata', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['set', '_', 'response', 'Ġ=', 'Ġmc', 'Ġ.', 'Ġset', 'Ġ(', 'Ġhash', '_', 'key', 'Ġ,', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġdata', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['set_response', 'Ġ=', 'Ġmc', 'Ġ.', 'Ġset', 'Ġ(', 'Ġhash_key', 'Ġ,', 'Ġjson', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġdata', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "metrics_url_template = "http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key=" provenance_url_template = "http://dx.doi.org/%s" \n"
Original    (007): ['metrics_url_template', '=', '"http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key="', 'provenance_url_template', '=', '"http://dx.doi.org/%s"', '\\n']
Tokenized   (063): ['<s>', 'met', 'rics', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'alm', '.', 'pl', 'os', '.', 'org', '/', 'api', '/', 'v', '3', '/', 'articles', '?', 'ids', '=', '%', 's', '&', 'source', '=', 'c', 'itations', ',', 'counter', '&', 'api', '_', 'key', '="', 'Ġproven', 'ance', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'dx', '.', 'doi', '.', 'org', '/', '%', 's', '"', 'Ġ\\', 'n', '</s>']
Filtered   (061): ['met', 'rics', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'alm', '.', 'pl', 'os', '.', 'org', '/', 'api', '/', 'v', '3', '/', 'articles', '?', 'ids', '=', '%', 's', '&', 'source', '=', 'c', 'itations', ',', 'counter', '&', 'api', '_', 'key', '="', 'Ġproven', 'ance', '_', 'url', '_', 'template', 'Ġ=', 'Ġ"', 'http', '://', 'dx', '.', 'doi', '.', 'org', '/', '%', 's', '"', 'Ġ\\', 'n']
Detokenized (007): ['metrics_url_template', 'Ġ=', 'Ġ"http://alm.plos.org/api/v3/articles?ids=%s&source=citations,counter&api_key="', 'Ġprovenance_url_template', 'Ġ=', 'Ġ"http://dx.doi.org/%s"', 'Ġ\\n']
Counter: 61
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "relevant = ( ( "doi" == namespace ) and ( "10.1371/" in nid ) ) \n"
Original    (016): ['relevant', '=', '(', '(', '"doi"', '==', 'namespace', ')', 'and', '(', '"10.1371/"', 'in', 'nid', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'relevant', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ"', 'doi', '"', 'Ġ==', 'Ġnamespace', 'Ġ)', 'Ġand', 'Ġ(', 'Ġ"', '10', '.', '13', '71', '/"', 'Ġin', 'Ġn', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['relevant', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ"', 'doi', '"', 'Ġ==', 'Ġnamespace', 'Ġ)', 'Ġand', 'Ġ(', 'Ġ"', '10', '.', '13', '71', '/"', 'Ġin', 'Ġn', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['relevant', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ"doi"', 'Ġ==', 'Ġnamespace', 'Ġ)', 'Ġand', 'Ġ(', 'Ġ"10.1371/"', 'Ġin', 'Ġnid', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "this_article = json_response [ 0 ] [ "sources" ] [ 0 ] [ "metrics" ] \n"
Original    (016): ['this_article', '=', 'json_response', '[', '0', ']', '[', '"sources"', ']', '[', '0', ']', '[', '"metrics"', ']', '\\n']
Tokenized   (029): ['<s>', 'this', '_', 'article', 'Ġ=', 'Ġjson', '_', 'response', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 's', 'ources', '"', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 'met', 'rics', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['this', '_', 'article', 'Ġ=', 'Ġjson', '_', 'response', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 's', 'ources', '"', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"', 'met', 'rics', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['this_article', 'Ġ=', 'Ġjson_response', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"sources"', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ"metrics"', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "redis_url = os . environ . get ( , "redis://127.0.0.1:6379/" ) \n"
Original    (012): ['redis_url', '=', 'os', '.', 'environ', '.', 'get', '(', ',', '"redis://127.0.0.1:6379/"', ')', '\\n']
Tokenized   (033): ['<s>', 'red', 'is', '_', 'url', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ"', 'red', 'is', '://', '127', '.', '0', '.', '0', '.', '1', ':', '6', '379', '/"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['red', 'is', '_', 'url', 'Ġ=', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ"', 'red', 'is', '://', '127', '.', '0', '.', '0', '.', '1', ':', '6', '379', '/"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['redis_url', 'Ġ=', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ"redis://127.0.0.1:6379/"', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Queue ( , routing_key = ) \n"
Original    (007): ['Queue', '(', ',', 'routing_key', '=', ')', '\\n']
Tokenized   (012): ['<s>', 'Queue', 'Ġ(', 'Ġ,', 'Ġrouting', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Queue', 'Ġ(', 'Ġ,', 'Ġrouting', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['Queue', 'Ġ(', 'Ġ,', 'Ġrouting_key', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "CELERY_ACCEPT_CONTENT = [ , ] \n"
Original    (006): ['CELERY_ACCEPT_CONTENT', '=', '[', ',', ']', '\\n']
Tokenized   (017): ['<s>', 'C', 'EL', 'ERY', '_', 'AC', 'CEPT', '_', 'CONT', 'ENT', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['C', 'EL', 'ERY', '_', 'AC', 'CEPT', '_', 'CONT', 'ENT', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['CELERY_ACCEPT_CONTENT', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "CELERY_IMPORTS = ( "core_tasks" , ) \n"
Original    (007): ['CELERY_IMPORTS', '=', '(', '"core_tasks"', ',', ')', '\\n']
Tokenized   (021): ['<s>', 'C', 'EL', 'ERY', '_', 'IM', 'P', 'ORTS', 'Ġ=', 'Ġ(', 'Ġ"', 'core', '_', 't', 'asks', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['C', 'EL', 'ERY', '_', 'IM', 'P', 'ORTS', 'Ġ=', 'Ġ(', 'Ġ"', 'core', '_', 't', 'asks', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['CELERY_IMPORTS', 'Ġ=', 'Ġ(', 'Ġ"core_tasks"', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "sampledir = os . path . join ( os . path . split ( __file__ ) [ 0 ] , "../../../extras/sample_provider_pages/" ) \n"
Original    (023): ['sampledir', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'split', '(', '__file__', ')', '[', '0', ']', ',', '"../../../extras/sample_provider_pages/"', ')', '\\n']
Tokenized   (043): ['<s>', 'sam', 'pled', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ"', '../', '../', '../', 'ext', 'ras', '/', 'sample', '_', 'prov', 'ider', '_', 'pages', '/"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['sam', 'pled', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ"', '../', '../', '../', 'ext', 'ras', '/', 'sample', '_', 'prov', 'ider', '_', 'pages', '/"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['sampledir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ"../../../extras/sample_provider_pages/"', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "TEST_XML = open ( os . path . join ( sampledir , "facebook" , "metrics" ) ) . read ( ) \n"
Original    (022): ['TEST_XML', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'sampledir', ',', '"facebook"', ',', '"metrics"', ')', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (035): ['<s>', 'T', 'EST', '_', 'X', 'ML', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġsampled', 'ir', 'Ġ,', 'Ġ"', 'facebook', '"', 'Ġ,', 'Ġ"', 'met', 'rics', '"', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['T', 'EST', '_', 'X', 'ML', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġsampled', 'ir', 'Ġ,', 'Ġ"', 'facebook', '"', 'Ġ,', 'Ġ"', 'met', 'rics', '"', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['TEST_XML', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġsampledir', 'Ġ,', 'Ġ"facebook"', 'Ġ,', 'Ġ"metrics"', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "provider_names = [ provider . __class__ . __name__ for provider in providers ] \n"
Original    (014): ['provider_names', '=', '[', 'provider', '.', '__class__', '.', '__name__', 'for', 'provider', 'in', 'providers', ']', '\\n']
Tokenized   (024): ['<s>', 'prov', 'ider', '_', 'names', 'Ġ=', 'Ġ[', 'Ġprovider', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġfor', 'Ġprovider', 'Ġin', 'Ġproviders', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['prov', 'ider', '_', 'names', 'Ġ=', 'Ġ[', 'Ġprovider', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġfor', 'Ġprovider', 'Ġin', 'Ġproviders', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['provider_names', 'Ġ=', 'Ġ[', 'Ġprovider', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġfor', 'Ġprovider', 'Ġin', 'Ġproviders', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "assert_equals ( md [ "pubmed" ] [ ] , ) \n"
Original    (011): ['assert_equals', '(', 'md', '[', '"pubmed"', ']', '[', ']', ',', ')', '\\n']
Tokenized   (020): ['<s>', 'assert', '_', 'equ', 'als', 'Ġ(', 'Ġmd', 'Ġ[', 'Ġ"', 'pub', 'med', '"', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['assert', '_', 'equ', 'als', 'Ġ(', 'Ġmd', 'Ġ[', 'Ġ"', 'pub', 'med', '"', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['assert_equals', 'Ġ(', 'Ġmd', 'Ġ[', 'Ġ"pubmed"', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tiid = db . Column ( db . Text , db . ForeignKey ( ) , primary_key = True ) \n"
Original    (021): ['tiid', '=', 'db', '.', 'Column', '(', 'db', '.', 'Text', ',', 'db', '.', 'ForeignKey', '(', ')', ',', 'primary_key', '=', 'True', ')', '\\n']
Tokenized   (028): ['<s>', 'ti', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠText', 'Ġ,', 'Ġdb', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['ti', 'id', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠText', 'Ġ,', 'Ġdb', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['tiid', 'Ġ=', 'Ġdb', 'Ġ.', 'ĠColumn', 'Ġ(', 'Ġdb', 'Ġ.', 'ĠText', 'Ġ,', 'Ġdb', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġprimary_key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "tweet_ids_with_response = [ tweet [ "id_str" ] for tweet in data ] \n"
Original    (013): ['tweet_ids_with_response', '=', '[', 'tweet', '[', '"id_str"', ']', 'for', 'tweet', 'in', 'data', ']', '\\n']
Tokenized   (027): ['<s>', 't', 'weet', '_', 'ids', '_', 'with', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ[', 'Ġ"', 'id', '_', 'str', '"', 'Ġ]', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġdata', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['t', 'weet', '_', 'ids', '_', 'with', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ[', 'Ġ"', 'id', '_', 'str', '"', 'Ġ]', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġdata', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['tweet_ids_with_response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ[', 'Ġ"id_str"', 'Ġ]', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġdata', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "tweet_ids_without_response = [ tweet for tweet in tweet_ids if tweet not in tweet_ids_with_response flag_deleted_tweets ( tweet_ids_without_response ) \n"
Original    (018): ['tweet_ids_without_response', '=', '[', 'tweet', 'for', 'tweet', 'in', 'tweet_ids', 'if', 'tweet', 'not', 'in', 'tweet_ids_with_response', 'flag_deleted_tweets', '(', 'tweet_ids_without_response', ')', '\\n']
Tokenized   (049): ['<s>', 't', 'weet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweet', '_', 'ids', 'Ġif', 'Ġtweet', 'Ġnot', 'Ġin', 'Ġtweet', '_', 'ids', '_', 'with', '_', 'response', 'Ġflag', '_', 'de', 'leted', '_', 't', 'we', 'ets', 'Ġ(', 'Ġtweet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (047): ['t', 'weet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweet', '_', 'ids', 'Ġif', 'Ġtweet', 'Ġnot', 'Ġin', 'Ġtweet', '_', 'ids', '_', 'with', '_', 'response', 'Ġflag', '_', 'de', 'leted', '_', 't', 'we', 'ets', 'Ġ(', 'Ġtweet', '_', 'ids', '_', 'without', '_', 'response', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['tweet_ids_without_response', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweet_ids', 'Ġif', 'Ġtweet', 'Ġnot', 'Ġin', 'Ġtweet_ids_with_response', 'Ġflag_deleted_tweets', 'Ġ(', 'Ġtweet_ids_without_response', 'Ġ)', 'Ġ\\n']
Counter: 47
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "access_token = os . getenv ( "TWITTER_ACCESS_TOKEN" ) \n"
Original    (009): ['access_token', '=', 'os', '.', 'getenv', '(', '"TWITTER_ACCESS_TOKEN"', ')', '\\n']
Tokenized   (025): ['<s>', 'access', '_', 'token', 'Ġ=', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'TW', 'IT', 'TER', '_', 'ACC', 'ESS', '_', 'TO', 'KEN', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['access', '_', 'token', 'Ġ=', 'Ġos', 'Ġ.', 'Ġget', 'env', 'Ġ(', 'Ġ"', 'TW', 'IT', 'TER', '_', 'ACC', 'ESS', '_', 'TO', 'KEN', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['access_token', 'Ġ=', 'Ġos', 'Ġ.', 'Ġgetenv', 'Ġ(', 'Ġ"TWITTER_ACCESS_TOKEN"', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "num = len ( tweets ) ) ) \n"
Original    (009): ['num', '=', 'len', '(', 'tweets', ')', ')', ')', '\\n']
Tokenized   (012): ['<s>', 'num', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['num', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['num', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "list_of_groups = [ tweets [ i : i + group_size ] for i in range ( 0 , len ( tweets ) , group_size ) ] \n"
Original    (027): ['list_of_groups', '=', '[', 'tweets', '[', 'i', ':', 'i', '+', 'group_size', ']', 'for', 'i', 'in', 'range', '(', '0', ',', 'len', '(', 'tweets', ')', ',', 'group_size', ')', ']', '\\n']
Tokenized   (038): ['<s>', 'list', '_', 'of', '_', 'groups', 'Ġ=', 'Ġ[', 'Ġtweets', 'Ġ[', 'Ġi', 'Ġ:', 'Ġi', 'Ġ+', 'Ġgroup', '_', 'size', 'Ġ]', 'Ġfor', 'Ġi', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ,', 'Ġgroup', '_', 'size', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['list', '_', 'of', '_', 'groups', 'Ġ=', 'Ġ[', 'Ġtweets', 'Ġ[', 'Ġi', 'Ġ:', 'Ġi', 'Ġ+', 'Ġgroup', '_', 'size', 'Ġ]', 'Ġfor', 'Ġi', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ,', 'Ġgroup', '_', 'size', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (027): ['list_of_groups', 'Ġ=', 'Ġ[', 'Ġtweets', 'Ġ[', 'Ġi', 'Ġ:', 'Ġi', 'Ġ+', 'Ġgroup_size', 'Ġ]', 'Ġfor', 'Ġi', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġlen', 'Ġ(', 'Ġtweets', 'Ġ)', 'Ġ,', 'Ġgroup_size', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "handle_all_tweets ( response . data , tweet_subset ) \n"
Original    (009): ['handle_all_tweets', '(', 'response', '.', 'data', ',', 'tweet_subset', ')', '\\n']
Tokenized   (021): ['<s>', 'handle', '_', 'all', '_', 't', 'we', 'ets', 'Ġ(', 'Ġresponse', 'Ġ.', 'Ġdata', 'Ġ,', 'Ġtweet', '_', 'sub', 'set', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['handle', '_', 'all', '_', 't', 'we', 'ets', 'Ġ(', 'Ġresponse', 'Ġ.', 'Ġdata', 'Ġ,', 'Ġtweet', '_', 'sub', 'set', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['handle_all_tweets', 'Ġ(', 'Ġresponse', 'Ġ.', 'Ġdata', 'Ġ,', 'Ġtweet_subset', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "tweets = Tweet . query . filter ( Tweet . profile_id == profile_id ) \n"
Original    (015): ['tweets', '=', 'Tweet', '.', 'query', '.', 'filter', '(', 'Tweet', '.', 'profile_id', '==', 'profile_id', ')', '\\n']
Tokenized   (024): ['<s>', 't', 'we', 'ets', 'Ġ=', 'ĠTweet', 'Ġ.', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'ĠTweet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ==', 'Ġprofile', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', 'we', 'ets', 'Ġ=', 'ĠTweet', 'Ġ.', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'ĠTweet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ==', 'Ġprofile', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['tweets', 'Ġ=', 'ĠTweet', 'Ġ.', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'ĠTweet', 'Ġ.', 'Ġprofile_id', 'Ġ==', 'Ġprofile_id', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tweet_dict = dict ( [ ( ( tweet . tweet_id , tweet . tiid ) , tweet ) for tweet in tweets ] ) \n"
Original    (025): ['tweet_dict', '=', 'dict', '(', '[', '(', '(', 'tweet', '.', 'tweet_id', ',', 'tweet', '.', 'tiid', ')', ',', 'tweet', ')', 'for', 'tweet', 'in', 'tweets', ']', ')', '\\n']
Tokenized   (034): ['<s>', 't', 'weet', '_', 'dict', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġ(', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġtweet', 'Ġ.', 'Ġti', 'id', 'Ġ)', 'Ġ,', 'Ġtweet', 'Ġ)', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['t', 'weet', '_', 'dict', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġ(', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġtweet', 'Ġ.', 'Ġti', 'id', 'Ġ)', 'Ġ,', 'Ġtweet', 'Ġ)', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['tweet_dict', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġ(', 'Ġtweet', 'Ġ.', 'Ġtweet_id', 'Ġ,', 'Ġtweet', 'Ġ.', 'Ġtiid', 'Ġ)', 'Ġ,', 'Ġtweet', 'Ġ)', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "tweet . profile_id = profile_id \n"
Original    (006): ['tweet', '.', 'profile_id', '=', 'profile_id', '\\n']
Tokenized   (014): ['<s>', 't', 'weet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ=', 'Ġprofile', '_', 'id', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['t', 'weet', 'Ġ.', 'Ġprofile', '_', 'id', 'Ġ=', 'Ġprofile', '_', 'id', 'Ġ\\', 'n']
Detokenized (006): ['tweet', 'Ġ.', 'Ġprofile_id', 'Ġ=', 'Ġprofile_id', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tweet_ids = [ tweet . tweet_id for tweet in tweets_to_hydrate_from_twitter ] \n"
Original    (012): ['tweet_ids', '=', '[', 'tweet', '.', 'tweet_id', 'for', 'tweet', 'in', 'tweets_to_hydrate_from_twitter', ']', '\\n']
Tokenized   (029): ['<s>', 't', 'weet', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', '_', 'to', '_', 'hyd', 'rate', '_', 'from', '_', 'twitter', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['t', 'weet', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets', '_', 'to', '_', 'hyd', 'rate', '_', 'from', '_', 'twitter', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['tweet_ids', 'Ġ=', 'Ġ[', 'Ġtweet', 'Ġ.', 'Ġtweet_id', 'Ġfor', 'Ġtweet', 'Ġin', 'Ġtweets_to_hydrate_from_twitter', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "display_url = url_info [ "display_url" ] \n"
Original    (007): ['display_url', '=', 'url_info', '[', '"display_url"', ']', '\\n']
Tokenized   (018): ['<s>', 'display', '_', 'url', 'Ġ=', 'Ġurl', '_', 'info', 'Ġ[', 'Ġ"', 'display', '_', 'url', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['display', '_', 'url', 'Ġ=', 'Ġurl', '_', 'info', 'Ġ[', 'Ġ"', 'display', '_', 'url', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['display_url', 'Ġ=', 'Ġurl_info', 'Ġ[', 'Ġ"display_url"', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "tweet_id = self . tweet_id , \n"
Original    (007): ['tweet_id', '=', 'self', '.', 'tweet_id', ',', '\\n']
Tokenized   (015): ['<s>', 't', 'weet', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['t', 'weet', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtweet', '_', 'id', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['tweet_id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtweet_id', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "file_loc = os . path . dirname ( os . path . realpath ( __file__ ) ) \n"
Original    (018): ['file_loc', '=', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'realpath', '(', '__file__', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'file', '_', 'loc', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['file', '_', 'loc', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['file_loc', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġrealpath', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "urllib . urlretrieve ( url + fname , fname ) \n"
Original    (011): ['urllib', '.', 'urlretrieve', '(', 'url', '+', 'fname', ',', 'fname', ')', '\\n']
Tokenized   (020): ['<s>', 'ur', 'll', 'ib', 'Ġ.', 'Ġurl', 'ret', 'rieve', 'Ġ(', 'Ġurl', 'Ġ+', 'Ġf', 'name', 'Ġ,', 'Ġf', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['ur', 'll', 'ib', 'Ġ.', 'Ġurl', 'ret', 'rieve', 'Ġ(', 'Ġurl', 'Ġ+', 'Ġf', 'name', 'Ġ,', 'Ġf', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['urllib', 'Ġ.', 'Ġurlretrieve', 'Ġ(', 'Ġurl', 'Ġ+', 'Ġfname', 'Ġ,', 'Ġfname', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "loaded = np . fromstring ( fd . read ( ) , dtype = np . uint8 ) \n"
Original    (019): ['loaded', '=', 'np', '.', 'fromstring', '(', 'fd', '.', 'read', '(', ')', ',', 'dtype', '=', 'np', '.', 'uint8', ')', '\\n']
Tokenized   (026): ['<s>', 'loaded', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġfrom', 'string', 'Ġ(', 'Ġf', 'd', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġuint', '8', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['loaded', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġfrom', 'string', 'Ġ(', 'Ġf', 'd', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġuint', '8', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['loaded', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġfromstring', 'Ġ(', 'Ġfd', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġuint8', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "fd = gzip . open ( os . path . join ( data_dir , ) ) \n"
Original    (017): ['fd', '=', 'gzip', '.', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'data_dir', ',', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'fd', 'Ġ=', 'Ġg', 'zip', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['fd', 'Ġ=', 'Ġg', 'zip', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['fd', 'Ġ=', 'Ġgzip', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġdata_dir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "trY = loaded [ 8 : ] . reshape ( ( 60000 ) ) \n"
Original    (015): ['trY', '=', 'loaded', '[', '8', ':', ']', '.', 'reshape', '(', '(', '60000', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'tr', 'Y', 'Ġ=', 'Ġloaded', 'Ġ[', 'Ġ8', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ6', '0000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['tr', 'Y', 'Ġ=', 'Ġloaded', 'Ġ[', 'Ġ8', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ6', '0000', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['trY', 'Ġ=', 'Ġloaded', 'Ġ[', 'Ġ8', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġ(', 'Ġ60000', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "trX = trX . reshape ( - 1 , 28 , 28 ) \n"
Original    (014): ['trX', '=', 'trX', '.', 'reshape', '(', '-', '1', ',', '28', ',', '28', ')', '\\n']
Tokenized   (020): ['<s>', 'tr', 'X', 'Ġ=', 'Ġtr', 'X', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ28', 'Ġ,', 'Ġ28', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['tr', 'X', 'Ġ=', 'Ġtr', 'X', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ28', 'Ġ,', 'Ġ28', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['trX', 'Ġ=', 'ĠtrX', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ28', 'Ġ,', 'Ġ28', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dirpath = os . path . join ( self . repo . path , "unused_directory" ) \n"
Original    (017): ['dirpath', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'repo', '.', 'path', ',', '"unused_directory"', ')', '\\n']
Tokenized   (026): ['<s>', 'dir', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'un', 'used', '_', 'directory', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['dir', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'un', 'used', '_', 'directory', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['dirpath', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"unused_directory"', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "subpath = os . path . join ( self . repo . path , "a" , "b" , "c" ) \n"
Original    (021): ['subpath', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'repo', '.', 'path', ',', '"a"', ',', '"b"', ',', '"c"', ')', '\\n']
Tokenized   (031): ['<s>', 'sub', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['sub', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['subpath', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġrepo', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ"a"', 'Ġ,', 'Ġ"b"', 'Ġ,', 'Ġ"c"', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "handle = self . profile . username , \n"
Original    (009): ['handle', '=', 'self', '.', 'profile', '.', 'username', ',', '\\n']
Tokenized   (012): ['<s>', 'handle', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprofile', 'Ġ.', 'Ġusername', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['handle', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprofile', 'Ġ.', 'Ġusername', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['handle', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprofile', 'Ġ.', 'Ġusername', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "id_key = ) \n"
Original    (004): ['id_key', '=', ')', '\\n']
Tokenized   (009): ['<s>', 'id', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['id', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['id_key', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "message_thread = model . MessageThread ( okc_id = self . thread . id , \n"
Original    (015): ['message_thread', '=', 'model', '.', 'MessageThread', '(', 'okc_id', '=', 'self', '.', 'thread', '.', 'id', ',', '\\n']
Tokenized   (024): ['<s>', 'message', '_', 'thread', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Thread', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['message', '_', 'thread', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Thread', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['message_thread', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessageThread', 'Ġ(', 'Ġokc_id', 'Ġ=', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "new_messages = [ message for message in self . thread . messages \n"
Original    (013): ['new_messages', '=', '[', 'message', 'for', 'message', 'in', 'self', '.', 'thread', '.', 'messages', '\\n']
Tokenized   (019): ['<s>', 'new', '_', 'mess', 'ages', 'Ġ=', 'Ġ[', 'Ġmessage', 'Ġfor', 'Ġmessage', 'Ġin', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġmessages', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['new', '_', 'mess', 'ages', 'Ġ=', 'Ġ[', 'Ġmessage', 'Ġfor', 'Ġmessage', 'Ġin', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġmessages', 'Ġ\\', 'n']
Detokenized (013): ['new_messages', 'Ġ=', 'Ġ[', 'Ġmessage', 'Ġfor', 'Ġmessage', 'Ġin', 'Ġself', 'Ġ.', 'Ġthread', 'Ġ.', 'Ġmessages', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "new_message_model = model . Message ( okc_id = new_message . id , \n"
Original    (013): ['new_message_model', '=', 'model', '.', 'Message', '(', 'okc_id', '=', 'new_message', '.', 'id', ',', '\\n']
Tokenized   (025): ['<s>', 'new', '_', 'message', '_', 'model', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', '_', 'message', '_', 'model', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Ġ(', 'Ġok', 'c', '_', 'id', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['new_message_model', 'Ġ=', 'Ġmodel', 'Ġ.', 'ĠMessage', 'Ġ(', 'Ġokc_id', 'Ġ=', 'Ġnew_message', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "time_sent = new_message . time_sent ) \n"
Original    (007): ['time_sent', '=', 'new_message', '.', 'time_sent', ')', '\\n']
Tokenized   (016): ['<s>', 'time', '_', 'sent', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġtime', '_', 'sent', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['time', '_', 'sent', 'Ġ=', 'Ġnew', '_', 'message', 'Ġ.', 'Ġtime', '_', 'sent', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['time_sent', 'Ġ=', 'Ġnew_message', 'Ġ.', 'Ġtime_sent', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "mailbox . Sync ( user ) . all ( ) \n"
Original    (011): ['mailbox', '.', 'Sync', '(', 'user', ')', '.', 'all', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'mail', 'box', 'Ġ.', 'ĠSync', 'Ġ(', 'Ġuser', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['mail', 'box', 'Ġ.', 'ĠSync', 'Ġ(', 'Ġuser', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['mailbox', 'Ġ.', 'ĠSync', 'Ġ(', 'Ġuser', 'Ġ)', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "user_model . upsert_model ( id_key = ) \n"
Original    (008): ['user_model', '.', 'upsert_model', '(', 'id_key', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'user', '_', 'model', 'Ġ.', 'Ġups', 'ert', '_', 'model', 'Ġ(', 'Ġid', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['user', '_', 'model', 'Ġ.', 'Ġups', 'ert', '_', 'model', 'Ġ(', 'Ġid', '_', 'key', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['user_model', 'Ġ.', 'Ġupsert_model', 'Ġ(', 'Ġid_key', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "response_dict = user . photo . upload_and_confirm ( user . quickmatch ( ) . photo_infos [ 0 ] ) \n"
Original    (020): ['response_dict', '=', 'user', '.', 'photo', '.', 'upload_and_confirm', '(', 'user', '.', 'quickmatch', '(', ')', '.', 'photo_infos', '[', '0', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'response', '_', 'dict', 'Ġ=', 'Ġuser', 'Ġ.', 'Ġphoto', 'Ġ.', 'Ġupload', '_', 'and', '_', 'conf', 'irm', 'Ġ(', 'Ġuser', 'Ġ.', 'Ġquick', 'match', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġphoto', '_', 'inf', 'os', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['response', '_', 'dict', 'Ġ=', 'Ġuser', 'Ġ.', 'Ġphoto', 'Ġ.', 'Ġupload', '_', 'and', '_', 'conf', 'irm', 'Ġ(', 'Ġuser', 'Ġ.', 'Ġquick', 'match', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġphoto', '_', 'inf', 'os', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['response_dict', 'Ġ=', 'Ġuser', 'Ġ.', 'Ġphoto', 'Ġ.', 'Ġupload_and_confirm', 'Ġ(', 'Ġuser', 'Ġ.', 'Ġquickmatch', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġphoto_infos', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "vcr_live_sleep ( 2 ) \n"
Original    (005): ['vcr_live_sleep', '(', '2', ')', '\\n']
Tokenized   (013): ['<s>', 'v', 'cr', '_', 'live', '_', 'sleep', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['v', 'cr', '_', 'live', '_', 'sleep', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['vcr_live_sleep', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "b2_h = shared_zeros ( ( self . hp . batch_size , n_h ) ) \n"
Original    (015): ['b2_h', '=', 'shared_zeros', '(', '(', 'self', '.', 'hp', '.', 'batch_size', ',', 'n_h', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'b', '2', '_', 'h', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġself', 'Ġ.', 'Ġhp', 'Ġ.', 'Ġbatch', '_', 'size', 'Ġ,', 'Ġn', '_', 'h', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['b', '2', '_', 'h', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġself', 'Ġ.', 'Ġhp', 'Ġ.', 'Ġbatch', '_', 'size', 'Ġ,', 'Ġn', '_', 'h', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['b2_h', 'Ġ=', 'Ġshared_zeros', 'Ġ(', 'Ġ(', 'Ġself', 'Ġ.', 'Ġhp', 'Ġ.', 'Ġbatch_size', 'Ġ,', 'Ġn_h', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "W1 = shared_normal ( ( n_h , n_h * gates ) , scale = scale * 1.5 ) \n"
Original    (019): ['W1', '=', 'shared_normal', '(', '(', 'n_h', ',', 'n_h', '*', 'gates', ')', ',', 'scale', '=', 'scale', '*', '1.5', ')', '\\n']
Tokenized   (031): ['<s>', 'W', '1', 'Ġ=', 'Ġshared', '_', 'normal', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ,', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ,', 'Ġscale', 'Ġ=', 'Ġscale', 'Ġ*', 'Ġ1', '.', '5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['W', '1', 'Ġ=', 'Ġshared', '_', 'normal', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ,', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ,', 'Ġscale', 'Ġ=', 'Ġscale', 'Ġ*', 'Ġ1', '.', '5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['W1', 'Ġ=', 'Ġshared_normal', 'Ġ(', 'Ġ(', 'Ġn_h', 'Ġ,', 'Ġn_h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ,', 'Ġscale', 'Ġ=', 'Ġscale', 'Ġ*', 'Ġ1.5', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "b1 = shared_zeros ( ( n_h * gates ) ) \n"
Original    (011): ['b1', '=', 'shared_zeros', '(', '(', 'n_h', '*', 'gates', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'b', '1', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['b', '1', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['b1', 'Ġ=', 'Ġshared_zeros', 'Ġ(', 'Ġ(', 'Ġn_h', 'Ġ*', 'Ġgates', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "b2 = shared_zeros ( ( n_h * gates , ) ) \n"
Original    (012): ['b2', '=', 'shared_zeros', '(', '(', 'n_h', '*', 'gates', ',', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'b', '2', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['b', '2', 'Ġ=', 'Ġshared', '_', 'zer', 'os', 'Ġ(', 'Ġ(', 'Ġn', '_', 'h', 'Ġ*', 'Ġgates', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['b2', 'Ġ=', 'Ġshared_zeros', 'Ġ(', 'Ġ(', 'Ġn_h', 'Ġ*', 'Ġgates', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "i_on = T . nnet . sigmoid ( g_on [ : , : n_h ] ) \n"
Original    (017): ['i_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', ':', 'n_h', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'i', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['i', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['i_on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġsigmoid', 'Ġ(', 'Ġg_on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "f_on = T . nnet . sigmoid ( g_on [ : , n_h : 2 * n_h ] ) \n"
Original    (020): ['f_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Tokenized   (034): ['<s>', 'f', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['f', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['f_on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġsigmoid', 'Ġ(', 'Ġg_on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "o_on = T . nnet . sigmoid ( g_on [ : , 2 * n_h : 3 * n_h ] ) \n"
Original    (022): ['o_on', '=', 'T', '.', 'nnet', '.', 'sigmoid', '(', 'g_on', '[', ':', ',', '2', '*', 'n_h', ':', '3', '*', 'n_h', ']', ')', '\\n']
Tokenized   (036): ['<s>', 'o', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ3', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['o', '_', 'on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġs', 'igm', 'oid', 'Ġ(', 'Ġg', '_', 'on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ3', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['o_on', 'Ġ=', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġsigmoid', 'Ġ(', 'Ġg_on', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ3', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "h_t = T . tanh ( T . dot ( X , W [ : , 1 * n_h : 2 * n_h ] ) + T . dot ( h , U [ : , 1 * n_h : 2 * n_h ] ) + b [ 1 * n_h : 2 * n_h ] ) \n"
Original    (058): ['h_t', '=', 'T', '.', 'tanh', '(', 'T', '.', 'dot', '(', 'X', ',', 'W', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 'T', '.', 'dot', '(', 'h', ',', 'U', '[', ':', ',', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '+', 'b', '[', '1', '*', 'n_h', ':', '2', '*', 'n_h', ']', ')', '\\n']
Tokenized   (076): ['<s>', 'h', '_', 't', 'Ġ=', 'ĠT', 'Ġ.', 'Ġtan', 'h', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠX', 'Ġ,', 'ĠW', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', 'Ġ,', 'ĠU', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'Ġb', 'Ġ[', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (074): ['h', '_', 't', 'Ġ=', 'ĠT', 'Ġ.', 'Ġtan', 'h', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠX', 'Ġ,', 'ĠW', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', 'Ġ,', 'ĠU', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ+', 'Ġb', 'Ġ[', 'Ġ1', 'Ġ*', 'Ġn', '_', 'h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn', '_', 'h', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (058): ['h_t', 'Ġ=', 'ĠT', 'Ġ.', 'Ġtanh', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠX', 'Ġ,', 'ĠW', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ+', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', 'Ġ,', 'ĠU', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ+', 'Ġb', 'Ġ[', 'Ġ1', 'Ġ*', 'Ġn_h', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġn_h', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 74
===================================================================
Hidden states:  (13, 58, 768)
# Extracted words:  58
Sentence         : "te_cost , te_h_updates = model ( self . X , self . params , 0. ) \n"
Original    (017): ['te_cost', ',', 'te_h_updates', '=', 'model', '(', 'self', '.', 'X', ',', 'self', '.', 'params', ',', '0.', ')', '\\n']
Tokenized   (028): ['<s>', 'te', '_', 'cost', 'Ġ,', 'Ġte', '_', 'h', '_', 'up', 'dates', 'Ġ=', 'Ġmodel', 'Ġ(', 'Ġself', 'Ġ.', 'ĠX', 'Ġ,', 'Ġself', 'Ġ.', 'Ġparams', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['te', '_', 'cost', 'Ġ,', 'Ġte', '_', 'h', '_', 'up', 'dates', 'Ġ=', 'Ġmodel', 'Ġ(', 'Ġself', 'Ġ.', 'ĠX', 'Ġ,', 'Ġself', 'Ġ.', 'Ġparams', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['te_cost', 'Ġ,', 'Ġte_h_updates', 'Ġ=', 'Ġmodel', 'Ġ(', 'Ġself', 'Ġ.', 'ĠX', 'Ġ,', 'Ġself', 'Ġ.', 'Ġparams', 'Ġ,', 'Ġ0.', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "csvWriter = csv . writer ( sys . stdout , delimiter = separator , quotechar = quote , \n"
Original    (019): ['csvWriter', '=', 'csv', '.', 'writer', '(', 'sys', '.', 'stdout', ',', 'delimiter', '=', 'separator', ',', 'quotechar', '=', 'quote', ',', '\\n']
Tokenized   (028): ['<s>', 'csv', 'Writer', 'Ġ=', 'Ġc', 'sv', 'Ġ.', 'Ġwriter', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġstd', 'out', 'Ġ,', 'Ġdelim', 'iter', 'Ġ=', 'Ġsepar', 'ator', 'Ġ,', 'Ġquote', 'char', 'Ġ=', 'Ġquote', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['csv', 'Writer', 'Ġ=', 'Ġc', 'sv', 'Ġ.', 'Ġwriter', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġstd', 'out', 'Ġ,', 'Ġdelim', 'iter', 'Ġ=', 'Ġsepar', 'ator', 'Ġ,', 'Ġquote', 'char', 'Ġ=', 'Ġquote', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['csvWriter', 'Ġ=', 'Ġcsv', 'Ġ.', 'Ġwriter', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġstdout', 'Ġ,', 'Ġdelimiter', 'Ġ=', 'Ġseparator', 'Ġ,', 'Ġquotechar', 'Ġ=', 'Ġquote', 'Ġ,', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "IColumnProvider_Methods = IPersist_Methods + [ "Initialize" , "GetColumnInfo" , "GetItemData" ] \n"
Original    (012): ['IColumnProvider_Methods', '=', 'IPersist_Methods', '+', '[', '"Initialize"', ',', '"GetColumnInfo"', ',', '"GetItemData"', ']', '\\n']
Tokenized   (035): ['<s>', 'IC', 'ol', 'umn', 'Provider', '_', 'Methods', 'Ġ=', 'ĠIP', 'ers', 'ist', '_', 'Methods', 'Ġ+', 'Ġ[', 'Ġ"', 'Initial', 'ize', '"', 'Ġ,', 'Ġ"', 'Get', 'Column', 'Info', '"', 'Ġ,', 'Ġ"', 'Get', 'Item', 'Data', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['IC', 'ol', 'umn', 'Provider', '_', 'Methods', 'Ġ=', 'ĠIP', 'ers', 'ist', '_', 'Methods', 'Ġ+', 'Ġ[', 'Ġ"', 'Initial', 'ize', '"', 'Ġ,', 'Ġ"', 'Get', 'Column', 'Info', '"', 'Ġ,', 'Ġ"', 'Get', 'Item', 'Data', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['IColumnProvider_Methods', 'Ġ=', 'ĠIPersist_Methods', 'Ġ+', 'Ġ[', 'Ġ"Initialize"', 'Ġ,', 'Ġ"GetColumnInfo"', 'Ġ,', 'Ġ"GetItemData"', 'Ġ]', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "_com_interfaces_ = [ pythoncom . IID_IPersist , \n"
Original    (008): ['_com_interfaces_', '=', '[', 'pythoncom', '.', 'IID_IPersist', ',', '\\n']
Tokenized   (022): ['<s>', '_', 'com', '_', 'inter', 'faces', '_', 'Ġ=', 'Ġ[', 'Ġpython', 'com', 'Ġ.', 'ĠI', 'ID', '_', 'IP', 'ers', 'ist', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'com', '_', 'inter', 'faces', '_', 'Ġ=', 'Ġ[', 'Ġpython', 'com', 'Ġ.', 'ĠI', 'ID', '_', 'IP', 'ers', 'ist', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['_com_interfaces_', 'Ġ=', 'Ġ[', 'Ġpythoncom', 'Ġ.', 'ĠIID_IPersist', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "20 , #cChars \n"
Original    (004): ['20', ',', '#cChars', '\\n']
Tokenized   (010): ['<s>', '20', 'Ġ,', 'Ġ#', 'c', 'Ch', 'ars', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['20', 'Ġ,', 'Ġ#', 'c', 'Ch', 'ars', 'Ġ\\', 'n']
Detokenized (004): ['20', 'Ġ,', 'Ġ#cChars', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "fmt_id == self . _reg_clsid_ \n"
Original    (006): ['fmt_id', '==', 'self', '.', '_reg_clsid_', '\\n']
Tokenized   (017): ['<s>', 'f', 'mt', '_', 'id', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['f', 'mt', '_', 'id', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ\\', 'n']
Detokenized (006): ['fmt_id', 'Ġ==', 'Ġself', 'Ġ.', 'Ġ_reg_clsid_', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : ""Folder\\\\ShellEx\\\\ColumnHandlers\\\\" + str ( ColumnProvider . _reg_clsid_ ) ) \n"
Original    (010): ['"Folder\\\\\\\\ShellEx\\\\\\\\ColumnHandlers\\\\\\\\"', '+', 'str', '(', 'ColumnProvider', '.', '_reg_clsid_', ')', ')', '\\n']
Tokenized   (029): ['<s>', '"', 'Folder', '\\\\\\\\', 'Shell', 'Ex', '\\\\\\\\', 'Column', 'Hand', 'lers', '\\\\\\\\', '"', 'Ġ+', 'Ġstr', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['"', 'Folder', '\\\\\\\\', 'Shell', 'Ex', '\\\\\\\\', 'Column', 'Hand', 'lers', '\\\\\\\\', '"', 'Ġ+', 'Ġstr', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'cl', 'sid', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['"Folder\\\\\\\\ShellEx\\\\\\\\ColumnHandlers\\\\\\\\"', 'Ġ+', 'Ġstr', 'Ġ(', 'ĠColumnProvider', 'Ġ.', 'Ġ_reg_clsid_', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_winreg . SetValueEx ( key , None , 0 , _winreg . REG_SZ , ColumnProvider . _reg_desc_ ) \n"
Original    (019): ['_winreg', '.', 'SetValueEx', '(', 'key', ',', 'None', ',', '0', ',', '_winreg', '.', 'REG_SZ', ',', 'ColumnProvider', '.', '_reg_desc_', ')', '\\n']
Tokenized   (036): ['<s>', '_', 'win', 'reg', 'Ġ.', 'ĠSet', 'Value', 'Ex', 'Ġ(', 'Ġkey', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ_', 'win', 'reg', 'Ġ.', 'ĠREG', '_', 'S', 'Z', 'Ġ,', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'desc', '_', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['_', 'win', 'reg', 'Ġ.', 'ĠSet', 'Value', 'Ex', 'Ġ(', 'Ġkey', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ_', 'win', 'reg', 'Ġ.', 'ĠREG', '_', 'S', 'Z', 'Ġ,', 'ĠColumn', 'Provider', 'Ġ.', 'Ġ_', 'reg', '_', 'desc', '_', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['_winreg', 'Ġ.', 'ĠSetValueEx', 'Ġ(', 'Ġkey', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ_winreg', 'Ġ.', 'ĠREG_SZ', 'Ġ,', 'ĠColumnProvider', 'Ġ.', 'Ġ_reg_desc_', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "register . UseCommandLine ( ColumnProvider , \n"
Original    (007): ['register', '.', 'UseCommandLine', '(', 'ColumnProvider', ',', '\\n']
Tokenized   (013): ['<s>', 'register', 'Ġ.', 'ĠUse', 'Command', 'Line', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['register', 'Ġ.', 'ĠUse', 'Command', 'Line', 'Ġ(', 'ĠColumn', 'Provider', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['register', 'Ġ.', 'ĠUseCommandLine', 'Ġ(', 'ĠColumnProvider', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "aliases = MultipleValueField ( required = False ) \n"
Original    (009): ['aliases', '=', 'MultipleValueField', '(', 'required', '=', 'False', ')', '\\n']
Tokenized   (015): ['<s>', 'ali', 'ases', 'Ġ=', 'ĠMultiple', 'Value', 'Field', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ali', 'ases', 'Ġ=', 'ĠMultiple', 'Value', 'Field', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['aliases', 'Ġ=', 'ĠMultipleValueField', 'Ġ(', 'Ġrequired', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "StoredQueryParameter = namedtuple ( "StoredQueryParameter" , ( , , , , \n"
Original    (012): ['StoredQueryParameter', '=', 'namedtuple', '(', '"StoredQueryParameter"', ',', '(', ',', ',', ',', ',', '\\n']
Tokenized   (025): ['<s>', 'St', 'ored', 'Query', 'Parameter', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'St', 'ored', 'Query', 'Parameter', '"', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['St', 'ored', 'Query', 'Parameter', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'St', 'ored', 'Query', 'Parameter', '"', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['StoredQueryParameter', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ"StoredQueryParameter"', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fts = list ( self . models . keys ( ) ) \n"
Original    (013): ['fts', '=', 'list', '(', 'self', '.', 'models', '.', 'keys', '(', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'fts', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġself', 'Ġ.', 'Ġmodels', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['fts', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġself', 'Ġ.', 'Ġmodels', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['fts', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġself', 'Ġ.', 'Ġmodels', 'Ġ.', 'Ġkeys', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "sort_by = parms . cleaned_data [ ] \n"
Original    (008): ['sort_by', '=', 'parms', '.', 'cleaned_data', '[', ']', '\\n']
Tokenized   (016): ['<s>', 'sort', '_', 'by', 'Ġ=', 'Ġpar', 'ms', 'Ġ.', 'Ġcleaned', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['sort', '_', 'by', 'Ġ=', 'Ġpar', 'ms', 'Ġ.', 'Ġcleaned', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['sort_by', 'Ġ=', 'Ġparms', 'Ġ.', 'Ġcleaned_data', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "geometry_field = self . geometries [ type_names [ 0 ] ] \n"
Original    (012): ['geometry_field', '=', 'self', '.', 'geometries', '[', 'type_names', '[', '0', ']', ']', '\\n']
Tokenized   (022): ['<s>', 'ge', 'ometry', '_', 'field', 'Ġ=', 'Ġself', 'Ġ.', 'Ġge', 'omet', 'ries', 'Ġ[', 'Ġtype', '_', 'names', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['ge', 'ometry', '_', 'field', 'Ġ=', 'Ġself', 'Ġ.', 'Ġge', 'omet', 'ries', 'Ġ[', 'Ġtype', '_', 'names', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['geometry_field', 'Ġ=', 'Ġself', 'Ġ.', 'Ġgeometries', 'Ġ[', 'Ġtype_names', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mxy = mxy ) \n"
Original    (005): ['mxy', '=', 'mxy', ')', '\\n']
Tokenized   (010): ['<s>', 'm', 'xy', 'Ġ=', 'Ġm', 'xy', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['m', 'xy', 'Ġ=', 'Ġm', 'xy', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['mxy', 'Ġ=', 'Ġmxy', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "query_set = query_set . order_by ( * sort_by ) \n"
Original    (010): ['query_set', '=', 'query_set', '.', 'order_by', '(', '*', 'sort_by', ')', '\\n']
Tokenized   (021): ['<s>', 'query', '_', 'set', 'Ġ=', 'Ġquery', '_', 'set', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ*', 'Ġsort', '_', 'by', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['query', '_', 'set', 'Ġ=', 'Ġquery', '_', 'set', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ*', 'Ġsort', '_', 'by', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['query_set', 'Ġ=', 'Ġquery_set', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ*', 'Ġsort_by', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "output_format = root . get ( , ) \n"
Original    (009): ['output_format', '=', 'root', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (014): ['<s>', 'output', '_', 'format', 'Ġ=', 'Ġroot', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['output', '_', 'format', 'Ġ=', 'Ġroot', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['output_format', 'Ġ=', 'Ġroot', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "type_names . append ( ( namespace , name ) ) \n"
Original    (011): ['type_names', '.', 'append', '(', '(', 'namespace', ',', 'name', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'type', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġnamespace', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['type', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġnamespace', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['type_names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġnamespace', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""schema" : feature_type . schema , \n"
Original    (007): ['"schema"', ':', 'feature_type', '.', 'schema', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'sche', 'ma', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġschema', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'sche', 'ma', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġschema', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"schema"', 'Ġ:', 'Ġfeature_type', 'Ġ.', 'Ġschema', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""ns_name" : feature_type . ns_name \n"
Original    (006): ['"ns_name"', ':', 'feature_type', '.', 'ns_name', '\\n']
Tokenized   (017): ['<s>', '"', 'ns', '_', 'name', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġns', '_', 'name', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['"', 'ns', '_', 'name', '"', 'Ġ:', 'Ġfeature', '_', 'type', 'Ġ.', 'Ġns', '_', 'name', 'Ġ\\', 'n']
Detokenized (006): ['"ns_name"', 'Ġ:', 'Ġfeature_type', 'Ġ.', 'Ġns_name', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "db_params = settings . DATABASES [ response . db ] \n"
Original    (011): ['db_params', '=', 'settings', '.', 'DATABASES', '[', 'response', '.', 'db', ']', '\\n']
Tokenized   (020): ['<s>', 'db', '_', 'params', 'Ġ=', 'Ġsettings', 'Ġ.', 'ĠD', 'AT', 'AB', 'AS', 'ES', 'Ġ[', 'Ġresponse', 'Ġ.', 'Ġdb', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['db', '_', 'params', 'Ġ=', 'Ġsettings', 'Ġ.', 'ĠD', 'AT', 'AB', 'AS', 'ES', 'Ġ[', 'Ġresponse', 'Ġ.', 'Ġdb', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['db_params', 'Ġ=', 'Ġsettings', 'Ġ.', 'ĠDATABASES', 'Ġ[', 'Ġresponse', 'Ġ.', 'Ġdb', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "parameters = tuple ( [ adapt ( p ) for p in parameters ] ) \n"
Original    (016): ['parameters', '=', 'tuple', '(', '[', 'adapt', '(', 'p', ')', 'for', 'p', 'in', 'parameters', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'param', 'eters', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġ[', 'Ġadapt', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġparameters', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['param', 'eters', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġ[', 'Ġadapt', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġparameters', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['parameters', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġ[', 'Ġadapt', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġparameters', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "connection_string = "PG:dbname=\'{db}\'" . format ( db = db_params [ ] ) \n"
Original    (013): ['connection_string', '=', '"PG:dbname=\\\'{db}\\\'"', '.', 'format', '(', 'db', '=', 'db_params', '[', ']', ')', '\\n']
Tokenized   (030): ['<s>', 'connection', '_', 'string', 'Ġ=', 'Ġ"', 'PG', ':', 'db', 'name', '=', "\\'", '{', 'db', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġdb', 'Ġ=', 'Ġdb', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['connection', '_', 'string', 'Ġ=', 'Ġ"', 'PG', ':', 'db', 'name', '=', "\\'", '{', 'db', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġdb', 'Ġ=', 'Ġdb', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['connection_string', 'Ġ=', 'Ġ"PG:dbname=\\\'{db}\\\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġdb', 'Ġ=', 'Ġdb_params', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "etree . SubElement ( p , ) . text = parameter . abstractS \n"
Original    (014): ['etree', '.', 'SubElement', '(', 'p', ',', ')', '.', 'text', '=', 'parameter', '.', 'abstractS', '\\n']
Tokenized   (020): ['<s>', 'et', 'ree', 'Ġ.', 'ĠSub', 'Element', 'Ġ(', 'Ġp', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġabstract', 'S', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['et', 'ree', 'Ġ.', 'ĠSub', 'Element', 'Ġ(', 'Ġp', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġabstract', 'S', 'Ġ\\', 'n']
Detokenized (014): ['etree', 'Ġ.', 'ĠSubElement', 'Ġ(', 'Ġp', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'ĠabstractS', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""isPrivate" : parameter . query_expression . private == True , \n"
Original    (011): ['"isPrivate"', ':', 'parameter', '.', 'query_expression', '.', 'private', '==', 'True', ',', '\\n']
Tokenized   (019): ['<s>', '"', 'is', 'Private', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġprivate', 'Ġ==', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['"', 'is', 'Private', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġprivate', 'Ġ==', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"isPrivate"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġprivate', 'Ġ==', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""language" : parameter . query_expression . language , \n"
Original    (009): ['"language"', ':', 'parameter', '.', 'query_expression', '.', 'language', ',', '\\n']
Tokenized   (016): ['<s>', '"', 'language', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġlanguage', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['"', 'language', '"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġlanguage', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"language"', 'Ġ:', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġlanguage', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""returnFeatureTypes" : . join ( parameter . query_expression . return_feature_types } ) . text = parameter . query_expression . text \n"
Original    (021): ['"returnFeatureTypes"', ':', '.', 'join', '(', 'parameter', '.', 'query_expression', '.', 'return_feature_types', '}', ')', '.', 'text', '=', 'parameter', '.', 'query_expression', '.', 'text', '\\n']
Tokenized   (036): ['<s>', '"', 'return', 'Feature', 'Types', '"', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġreturn', '_', 'feature', '_', 'types', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġtext', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['"', 'return', 'Feature', 'Types', '"', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġreturn', '_', 'feature', '_', 'types', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġquery', '_', 'expression', 'Ġ.', 'Ġtext', 'Ġ\\', 'n']
Detokenized (021): ['"returnFeatureTypes"', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġreturn_feature_types', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ=', 'Ġparameter', 'Ġ.', 'Ġquery_expression', 'Ġ.', 'Ġtext', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : ""endpoint" : request . build_absolute_uri ( ) . split ( ) [ 0 ] , \n"
Original    (016): ['"endpoint"', ':', 'request', '.', 'build_absolute_uri', '(', ')', '.', 'split', '(', ')', '[', '0', ']', ',', '\\n']
Tokenized   (026): ['<s>', '"', 'end', 'point', '"', 'Ġ:', 'Ġrequest', 'Ġ.', 'Ġbuild', '_', 'absolute', '_', 'uri', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', 'end', 'point', '"', 'Ġ:', 'Ġrequest', 'Ġ.', 'Ġbuild', '_', 'absolute', '_', 'uri', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['"endpoint"', 'Ġ:', 'Ġrequest', 'Ġ.', 'Ġbuild_absolute_uri', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""output_formats" : [ ogr . GetDriver ( drv ) . GetName ( ) for drv in range ( ogr . GetDriverCount ( ) ) "addr_street" : self . addr_street , \n"
Original    (031): ['"output_formats"', ':', '[', 'ogr', '.', 'GetDriver', '(', 'drv', ')', '.', 'GetName', '(', ')', 'for', 'drv', 'in', 'range', '(', 'ogr', '.', 'GetDriverCount', '(', ')', ')', '"addr_street"', ':', 'self', '.', 'addr_street', ',', '\\n']
Tokenized   (053): ['<s>', '"', 'output', '_', 'form', 'ats', '"', 'Ġ:', 'Ġ[', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Ġ(', 'Ġdr', 'v', 'Ġ)', 'Ġ.', 'ĠGet', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġdr', 'v', 'Ġin', 'Ġrange', 'Ġ(', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Count', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ"', 'addr', '_', 'street', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġaddr', '_', 'street', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (051): ['"', 'output', '_', 'form', 'ats', '"', 'Ġ:', 'Ġ[', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Ġ(', 'Ġdr', 'v', 'Ġ)', 'Ġ.', 'ĠGet', 'Name', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġdr', 'v', 'Ġin', 'Ġrange', 'Ġ(', 'Ġo', 'gr', 'Ġ.', 'ĠGet', 'Driver', 'Count', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ"', 'addr', '_', 'street', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġaddr', '_', 'street', 'Ġ,', 'Ġ\\', 'n']
Detokenized (031): ['"output_formats"', 'Ġ:', 'Ġ[', 'Ġogr', 'Ġ.', 'ĠGetDriver', 'Ġ(', 'Ġdrv', 'Ġ)', 'Ġ.', 'ĠGetName', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġdrv', 'Ġin', 'Ġrange', 'Ġ(', 'Ġogr', 'Ġ.', 'ĠGetDriverCount', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ"addr_street"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġaddr_street', 'Ġ,', 'Ġ\\n']
Counter: 51
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : ""feature_versioning" : self . adapter . supports_feature_versioning ( ) , \n"
Original    (011): ['"feature_versioning"', ':', 'self', '.', 'adapter', '.', 'supports_feature_versioning', '(', ')', ',', '\\n']
Tokenized   (024): ['<s>', '"', 'feature', '_', 'version', 'ing', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġadapter', 'Ġ.', 'Ġsupports', '_', 'feature', '_', 'version', 'ing', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'feature', '_', 'version', 'ing', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġadapter', 'Ġ.', 'Ġsupports', '_', 'feature', '_', 'version', 'ing', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['"feature_versioning"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġadapter', 'Ġ.', 'Ġsupports_feature_versioning', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""date" : datetime . now ( ) , \n"
Original    (009): ['"date"', ':', 'datetime', '.', 'now', '(', ')', ',', '\\n']
Tokenized   (015): ['<s>', '"', 'date', '"', 'Ġ:', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'date', '"', 'Ġ:', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"date"', 'Ġ:', 'Ġdatetime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "matchItem . setText ( 3 , unicode ( self . data [ "Matches" ] ) ) \n"
Original    (017): ['matchItem', '.', 'setText', '(', '3', ',', 'unicode', '(', 'self', '.', 'data', '[', '"Matches"', ']', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'match', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġself', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ"', 'Mat', 'ches', '"', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['match', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġself', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ"', 'Mat', 'ches', '"', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['matchItem', 'Ġ.', 'ĠsetText', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunicode', 'Ġ(', 'Ġself', 'Ġ.', 'Ġdata', 'Ġ[', 'Ġ"Matches"', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "roundItem . setText ( 3 , unicode ( opponent [ 2 ] ) ) \n"
Original    (015): ['roundItem', '.', 'setText', '(', '3', ',', 'unicode', '(', 'opponent', '[', '2', ']', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'round', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġopponent', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['round', 'Item', 'Ġ.', 'Ġset', 'Text', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġopponent', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['roundItem', 'Ġ.', 'ĠsetText', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġunicode', 'Ġ(', 'Ġopponent', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "opponent [ 3 ] = roundItem \n"
Original    (007): ['opponent', '[', '3', ']', '=', 'roundItem', '\\n']
Tokenized   (012): ['<s>', 'opp', 'onent', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ=', 'Ġround', 'Item', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['opp', 'onent', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ=', 'Ġround', 'Item', 'Ġ\\', 'n']
Detokenized (007): ['opponent', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ=', 'ĠroundItem', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "M = np . matrix ( [ [ 2 , 3 , 4 ] , \n"
Original    (016): ['M', '=', 'np', '.', 'matrix', '(', '[', '[', '2', ',', '3', ',', '4', ']', ',', '\\n']
Tokenized   (019): ['<s>', 'M', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmatrix', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['M', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmatrix', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['M', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmatrix', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "matrix = Matrix ( M , mtype = ) \n"
Original    (010): ['matrix', '=', 'Matrix', '(', 'M', ',', 'mtype', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'mat', 'rix', 'Ġ=', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ,', 'Ġm', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['mat', 'rix', 'Ġ=', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ,', 'Ġm', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['matrix', 'Ġ=', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ,', 'Ġmtype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "math = Math ( data = [ , vec_name , , Matrix ( M * a ) ] ) \n"
Original    (020): ['math', '=', 'Math', '(', 'data', '=', '[', ',', 'vec_name', ',', ',', 'Matrix', '(', 'M', '*', 'a', ')', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'math', 'Ġ=', 'ĠMath', 'Ġ(', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġvec', '_', 'name', 'Ġ,', 'Ġ,', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ*', 'Ġa', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['math', 'Ġ=', 'ĠMath', 'Ġ(', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġvec', '_', 'name', 'Ġ,', 'Ġ,', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ*', 'Ġa', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['math', 'Ġ=', 'ĠMath', 'Ġ(', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġvec_name', 'Ġ,', 'Ġ,', 'ĠMatrix', 'Ġ(', 'ĠM', 'Ġ*', 'Ġa', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "q2 = Quantity ( v , format_cb = lambda x : str ( int ( x ) ) ) \n"
Original    (020): ['q2', '=', 'Quantity', '(', 'v', ',', 'format_cb', '=', 'lambda', 'x', ':', 'str', '(', 'int', '(', 'x', ')', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'q', '2', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġformat', '_', 'cb', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['q', '2', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġformat', '_', 'cb', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['q2', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġformat_cb', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "q3 = Quantity ( v , options = { : } ) \n"
Original    (013): ['q3', '=', 'Quantity', '(', 'v', ',', 'options', '=', '{', ':', '}', ')', '\\n']
Tokenized   (017): ['<s>', 'q', '3', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġoptions', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['q', '3', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġoptions', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['q3', 'Ġ=', 'ĠQuantity', 'Ġ(', 'Ġv', 'Ġ,', 'Ġoptions', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "test_dimensionality_to_siunitx ( ) \n"
Original    (004): ['test_dimensionality_to_siunitx', '(', ')', '\\n']
Tokenized   (016): ['<s>', 'test', '_', 'dimension', 'ality', '_', 'to', '_', 'si', 'unit', 'x', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['test', '_', 'dimension', 'ality', '_', 'to', '_', 'si', 'unit', 'x', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['test_dimensionality_to_siunitx', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "ph = put_handler . put_handler ( fs , ) \n"
Original    (010): ['ph', '=', 'put_handler', '.', 'put_handler', '(', 'fs', ',', ')', '\\n']
Tokenized   (017): ['<s>', 'ph', 'Ġ=', 'Ġput', '_', 'handler', 'Ġ.', 'Ġput', '_', 'handler', 'Ġ(', 'Ġfs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['ph', 'Ġ=', 'Ġput', '_', 'handler', 'Ġ.', 'Ġput', '_', 'handler', 'Ġ(', 'Ġfs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['ph', 'Ġ=', 'Ġput_handler', 'Ġ.', 'Ġput_handler', 'Ġ(', 'Ġfs', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "hs = http_server . http_server ( ip = , port = 8080 ) \n"
Original    (014): ['hs', '=', 'http_server', '.', 'http_server', '(', 'ip', '=', ',', 'port', '=', '8080', ')', '\\n']
Tokenized   (022): ['<s>', 'hs', 'Ġ=', 'Ġhttp', '_', 'server', 'Ġ.', 'Ġhttp', '_', 'server', 'Ġ(', 'Ġip', 'Ġ=', 'Ġ,', 'Ġport', 'Ġ=', 'Ġ80', '80', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['hs', 'Ġ=', 'Ġhttp', '_', 'server', 'Ġ.', 'Ġhttp', '_', 'server', 'Ġ(', 'Ġip', 'Ġ=', 'Ġ,', 'Ġport', 'Ġ=', 'Ġ80', '80', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['hs', 'Ġ=', 'Ġhttp_server', 'Ġ.', 'Ġhttp_server', 'Ġ(', 'Ġip', 'Ġ=', 'Ġ,', 'Ġport', 'Ġ=', 'Ġ8080', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "num_trans = num_requests * num_conns \n"
Original    (006): ['num_trans', '=', 'num_requests', '*', 'num_conns', '\\n']
Tokenized   (017): ['<s>', 'num', '_', 'trans', 'Ġ=', 'Ġnum', '_', 'requ', 'ests', 'Ġ*', 'Ġnum', '_', 'con', 'ns', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['num', '_', 'trans', 'Ġ=', 'Ġnum', '_', 'requ', 'ests', 'Ġ*', 'Ġnum', '_', 'con', 'ns', 'Ġ\\', 'n']
Detokenized (006): ['num_trans', 'Ġ=', 'Ġnum_requests', 'Ġ*', 'Ġnum_conns', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "trans_per_sec = num_trans / total_time \n"
Original    (006): ['trans_per_sec', '=', 'num_trans', '/', 'total_time', '\\n']
Tokenized   (017): ['<s>', 'trans', '_', 'per', '_', 'sec', 'Ġ=', 'Ġnum', '_', 'trans', 'Ġ/', 'Ġtotal', '_', 'time', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['trans', '_', 'per', '_', 'sec', 'Ġ=', 'Ġnum', '_', 'trans', 'Ġ/', 'Ġtotal', '_', 'time', 'Ġ\\', 'n']
Detokenized (006): ['trans_per_sec', 'Ġ=', 'Ġnum_trans', 'Ġ/', 'Ġtotal_time', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "map ( str , ( num_conns , num_requests , request_size , throughput , trans_per_sec ) \n"
Original    (016): ['map', '(', 'str', ',', '(', 'num_conns', ',', 'num_requests', ',', 'request_size', ',', 'throughput', ',', 'trans_per_sec', ')', '\\n']
Tokenized   (031): ['<s>', 'map', 'Ġ(', 'Ġstr', 'Ġ,', 'Ġ(', 'Ġnum', '_', 'con', 'ns', 'Ġ,', 'Ġnum', '_', 'requ', 'ests', 'Ġ,', 'Ġrequest', '_', 'size', 'Ġ,', 'Ġthroughput', 'Ġ,', 'Ġtrans', '_', 'per', '_', 'sec', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['map', 'Ġ(', 'Ġstr', 'Ġ,', 'Ġ(', 'Ġnum', '_', 'con', 'ns', 'Ġ,', 'Ġnum', '_', 'requ', 'ests', 'Ġ,', 'Ġrequest', '_', 'size', 'Ġ,', 'Ġthroughput', 'Ġ,', 'Ġtrans', '_', 'per', '_', 'sec', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['map', 'Ġ(', 'Ġstr', 'Ġ,', 'Ġ(', 'Ġnum_conns', 'Ġ,', 'Ġnum_requests', 'Ġ,', 'Ġrequest_size', 'Ġ,', 'Ġthroughput', 'Ġ,', 'Ġtrans_per_sec', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "queue . add_task ( task , 3 ) \n"
Original    (009): ['queue', '.', 'add_task', '(', 'task', ',', '3', ')', '\\n']
Tokenized   (014): ['<s>', 'queue', 'Ġ.', 'Ġadd', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['queue', 'Ġ.', 'Ġadd', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['queue', 'Ġ.', 'Ġadd_task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "futures . append ( queue . yield_task ( task , 3 ) ) \n"
Original    (014): ['futures', '.', 'append', '(', 'queue', '.', 'yield_task', '(', 'task', ',', '3', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'f', 'ut', 'ures', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġqueue', 'Ġ.', 'Ġyield', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['f', 'ut', 'ures', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġqueue', 'Ġ.', 'Ġyield', '_', 'task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['futures', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġqueue', 'Ġ.', 'Ġyield_task', 'Ġ(', 'Ġtask', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "task_results [ : ] = res \n"
Original    (007): ['task_results', '[', ':', ']', '=', 'res', '\\n']
Tokenized   (012): ['<s>', 'task', '_', 'results', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġres', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['task', '_', 'results', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġres', 'Ġ\\', 'n']
Detokenized (007): ['task_results', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġres', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "shuffle ( self . __queued_servers ) \n"
Original    (007): ['shuffle', '(', 'self', '.', '__queued_servers', ')', '\\n']
Tokenized   (016): ['<s>', 'sh', 'uffle', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'que', 'ued', '_', 'ser', 'vers', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['sh', 'uffle', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'que', 'ued', '_', 'ser', 'vers', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['shuffle', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__queued_servers', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "event_name = event [ ] \n"
Original    (006): ['event_name', '=', 'event', '[', ']', '\\n']
Tokenized   (011): ['<s>', 'event', '_', 'name', 'Ġ=', 'Ġevent', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['event', '_', 'name', 'Ġ=', 'Ġevent', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['event_name', 'Ġ=', 'Ġevent', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "event_data = zlib . compress ( pickle . dumps ( event ) ) \n"
Original    (014): ['event_data', '=', 'zlib', '.', 'compress', '(', 'pickle', '.', 'dumps', '(', 'event', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'event', '_', 'data', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'Ġcompress', 'Ġ(', 'Ġpick', 'le', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġevent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['event', '_', 'data', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'Ġcompress', 'Ġ(', 'Ġpick', 'le', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġevent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['event_data', 'Ġ=', 'Ġzlib', 'Ġ.', 'Ġcompress', 'Ġ(', 'Ġpickle', 'Ġ.', 'Ġdumps', 'Ġ(', 'Ġevent', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "path_only , query = self . _split_path ( path ) \n"
Original    (011): ['path_only', ',', 'query', '=', 'self', '.', '_split_path', '(', 'path', ')', '\\n']
Tokenized   (019): ['<s>', 'path', '_', 'only', 'Ġ,', 'Ġquery', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'split', '_', 'path', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['path', '_', 'only', 'Ġ,', 'Ġquery', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'split', '_', 'path', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['path_only', 'Ġ,', 'Ġquery', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_split_path', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "break ; \n"
Original    (003): ['break', ';', '\\n']
Tokenized   (006): ['<s>', 'break', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (004): ['break', 'Ġ;', 'Ġ\\', 'n']
Detokenized (003): ['break', 'Ġ;', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "u . email = user [ 2 ] \n"
Original    (009): ['u', '.', 'email', '=', 'user', '[', '2', ']', '\\n']
Tokenized   (012): ['<s>', 'u', 'Ġ.', 'Ġemail', 'Ġ=', 'Ġuser', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['u', 'Ġ.', 'Ġemail', 'Ġ=', 'Ġuser', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['u', 'Ġ.', 'Ġemail', 'Ġ=', 'Ġuser', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "trac_components = list ( [ ] ) \n"
Original    (008): ['trac_components', '=', 'list', '(', '[', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'tr', 'ac', '_', 'comp', 'onents', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['tr', 'ac', '_', 'comp', 'onents', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['trac_components', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "component . owner = self . _get_user_login ( component . owner ) \n"
Original    (013): ['component', '.', 'owner', '=', 'self', '.', '_get_user_login', '(', 'component', '.', 'owner', ')', '\\n']
Tokenized   (021): ['<s>', 'component', 'Ġ.', 'Ġowner', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'user', '_', 'login', 'Ġ(', 'Ġcomponent', 'Ġ.', 'Ġowner', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['component', 'Ġ.', 'Ġowner', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'user', '_', 'login', 'Ġ(', 'Ġcomponent', 'Ġ.', 'Ġowner', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['component', 'Ġ.', 'Ġowner', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_get_user_login', 'Ġ(', 'Ġcomponent', 'Ġ.', 'Ġowner', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "networks [ pkt . pduSource ] . append ( pkt . wirtnNetwork ) \n"
Original    (014): ['networks', '[', 'pkt', '.', 'pduSource', ']', '.', 'append', '(', 'pkt', '.', 'wirtnNetwork', ')', '\\n']
Tokenized   (025): ['<s>', 'net', 'works', 'Ġ[', 'Ġp', 'kt', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġp', 'kt', 'Ġ.', 'Ġw', 'irt', 'n', 'Network', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['net', 'works', 'Ġ[', 'Ġp', 'kt', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġp', 'kt', 'Ġ.', 'Ġw', 'irt', 'n', 'Network', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['networks', 'Ġ[', 'Ġpkt', 'Ġ.', 'ĠpduSource', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġpkt', 'Ġ.', 'ĠwirtnNetwork', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "filterSource = Address ( sys . argv [ i + 1 ] ) \n"
Original    (014): ['filterSource', '=', 'Address', '(', 'sys', '.', 'argv', '[', 'i', '+', '1', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'filter', 'Source', 'Ġ=', 'ĠAddress', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['filter', 'Source', 'Ġ=', 'ĠAddress', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['filterSource', 'Ġ=', 'ĠAddress', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "net_count . sort ( lambda x , y : cmp ( y [ 1 ] , x [ 1 ] ) ) \n"
Original    (023): ['net_count', '.', 'sort', '(', 'lambda', 'x', ',', 'y', ':', 'cmp', '(', 'y', '[', '1', ']', ',', 'x', '[', '1', ']', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'net', '_', 'count', 'Ġ.', 'Ġsort', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ,', 'Ġy', 'Ġ:', 'Ġc', 'mp', 'Ġ(', 'Ġy', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['net', '_', 'count', 'Ġ.', 'Ġsort', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ,', 'Ġy', 'Ġ:', 'Ġc', 'mp', 'Ġ(', 'Ġy', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['net_count', 'Ġ.', 'Ġsort', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ,', 'Ġy', 'Ġ:', 'Ġcmp', 'Ġ(', 'Ġy', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "strm = StringIO ( self . pickleBuffer ) \n"
Original    (009): ['strm', '=', 'StringIO', '(', 'self', '.', 'pickleBuffer', ')', '\\n']
Tokenized   (016): ['<s>', 'str', 'm', 'Ġ=', 'ĠString', 'IO', 'Ġ(', 'Ġself', 'Ġ.', 'Ġpick', 'le', 'Buffer', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['str', 'm', 'Ġ=', 'ĠString', 'IO', 'Ġ(', 'Ġself', 'Ġ.', 'Ġpick', 'le', 'Buffer', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['strm', 'Ġ=', 'ĠStringIO', 'Ġ(', 'Ġself', 'Ġ.', 'ĠpickleBuffer', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pdu . pduSource = self . peer \n"
Original    (008): ['pdu', '.', 'pduSource', '=', 'self', '.', 'peer', '\\n']
Tokenized   (014): ['<s>', 'p', 'du', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ=', 'Ġself', 'Ġ.', 'Ġpeer', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['p', 'du', 'Ġ.', 'Ġp', 'du', 'Source', 'Ġ=', 'Ġself', 'Ġ.', 'Ġpeer', 'Ġ\\', 'n']
Detokenized (008): ['pdu', 'Ġ.', 'ĠpduSource', 'Ġ=', 'Ġself', 'Ġ.', 'Ġpeer', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "connect_task . install_task ( _time ( ) + self . reconnect [ actor . peer ] ) \n"
Original    (018): ['connect_task', '.', 'install_task', '(', '_time', '(', ')', '+', 'self', '.', 'reconnect', '[', 'actor', '.', 'peer', ']', ')', '\\n']
Tokenized   (026): ['<s>', 'connect', '_', 'task', 'Ġ.', 'Ġinstall', '_', 'task', 'Ġ(', 'Ġ_', 'time', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġreconnect', 'Ġ[', 'Ġactor', 'Ġ.', 'Ġpeer', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['connect', '_', 'task', 'Ġ.', 'Ġinstall', '_', 'task', 'Ġ(', 'Ġ_', 'time', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġreconnect', 'Ġ[', 'Ġactor', 'Ġ.', 'Ġpeer', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['connect_task', 'Ġ.', 'Ġinstall_task', 'Ġ(', 'Ġ_time', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġreconnect', 'Ġ[', 'Ġactor', 'Ġ.', 'Ġpeer', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "asyncore . dispatcher . __init__ ( self , sock ) \n"
Original    (011): ['asyncore', '.', 'dispatcher', '.', '__init__', '(', 'self', ',', 'sock', ')', '\\n']
Tokenized   (018): ['<s>', 'as', 'yn', 'core', 'Ġ.', 'Ġdispatcher', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġsock', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['as', 'yn', 'core', 'Ġ.', 'Ġdispatcher', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġsock', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['asyncore', 'Ġ.', 'Ġdispatcher', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġsock', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "TCPServerDirector . _warning ( , err ) \n"
Original    (008): ['TCPServerDirector', '.', '_warning', '(', ',', 'err', ')', '\\n']
Tokenized   (015): ['<s>', 'TC', 'PS', 'erver', 'Director', 'Ġ.', 'Ġ_', 'warning', 'Ġ(', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['TC', 'PS', 'erver', 'Director', 'Ġ.', 'Ġ_', 'warning', 'Ġ(', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['TCPServerDirector', 'Ġ.', 'Ġ_warning', 'Ġ(', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "buff = packet [ 1 ] \n"
Original    (007): ['buff', '=', 'packet', '[', '1', ']', '\\n']
Tokenized   (010): ['<s>', 'buff', 'Ġ=', 'Ġpacket', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['buff', 'Ġ=', 'Ġpacket', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['buff', 'Ġ=', 'Ġpacket', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "fileIdentifier = ( obj_type , obj_inst ) , \n"
Original    (009): ['fileIdentifier', '=', '(', 'obj_type', ',', 'obj_inst', ')', ',', '\\n']
Tokenized   (018): ['<s>', 'file', 'Ident', 'ifier', 'Ġ=', 'Ġ(', 'Ġobj', '_', 'type', 'Ġ,', 'Ġobj', '_', 'inst', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['file', 'Ident', 'ifier', 'Ġ=', 'Ġ(', 'Ġobj', '_', 'type', 'Ġ,', 'Ġobj', '_', 'inst', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['fileIdentifier', 'Ġ=', 'Ġ(', 'Ġobj_type', 'Ġ,', 'Ġobj_inst', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "record_data = list ( args [ 4 : ] ) \n"
Original    (011): ['record_data', '=', 'list', '(', 'args', '[', '4', ':', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'record', '_', 'data', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ4', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['record', '_', 'data', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ4', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['record_data', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ4', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "accessMethod = AtomicWriteFileRequestAccessMethodChoice ( \n"
Original    (005): ['accessMethod', '=', 'AtomicWriteFileRequestAccessMethodChoice', '(', '\\n']
Tokenized   (015): ['<s>', 'access', 'Method', 'Ġ=', 'ĠAtomic', 'Write', 'File', 'Request', 'Access', 'Method', 'Choice', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['access', 'Method', 'Ġ=', 'ĠAtomic', 'Write', 'File', 'Request', 'Access', 'Method', 'Choice', 'Ġ(', 'Ġ\\', 'n']
Detokenized (005): ['accessMethod', 'Ġ=', 'ĠAtomicWriteFileRequestAccessMethodChoice', 'Ġ(', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "objectIdentifier = int ( args . ini . objectidentifier ) , \n"
Original    (012): ['objectIdentifier', '=', 'int', '(', 'args', '.', 'ini', '.', 'objectidentifier', ')', ',', '\\n']
Tokenized   (020): ['<s>', 'object', 'Ident', 'ifier', 'Ġ=', 'Ġint', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġobject', 'ident', 'ifier', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['object', 'Ident', 'ifier', 'Ġ=', 'Ġint', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġobject', 'ident', 'ifier', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['objectIdentifier', 'Ġ=', 'Ġint', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġini', 'Ġ.', 'Ġobjectidentifier', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "this_application = TestApplication ( this_device , args . ini . address ) \n"
Original    (013): ['this_application', '=', 'TestApplication', '(', 'this_device', ',', 'args', '.', 'ini', '.', 'address', ')', '\\n']
Tokenized   (022): ['<s>', 'this', '_', 'application', 'Ġ=', 'ĠTest', 'Application', 'Ġ(', 'Ġthis', '_', 'device', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġaddress', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['this', '_', 'application', 'Ġ=', 'ĠTest', 'Application', 'Ġ(', 'Ġthis', '_', 'device', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġin', 'i', 'Ġ.', 'Ġaddress', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['this_application', 'Ġ=', 'ĠTestApplication', 'Ġ(', 'Ġthis_device', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġini', 'Ġ.', 'Ġaddress', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_log . debug ( "running" ) \n"
Original    (007): ['_log', '.', 'debug', '(', '"running"', ')', '\\n']
Tokenized   (013): ['<s>', '_', 'log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ"', 'running', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['_', 'log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ"', 'running', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['_log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ"running"', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Status . FAILED_TO_ADD_TO_CLIENT : % ( COLOR_FAILED_TO_ADD_TO_CLIENT , Color . ENDC ) , \n"
Original    (014): ['Status', '.', 'FAILED_TO_ADD_TO_CLIENT', ':', '%', '(', 'COLOR_FAILED_TO_ADD_TO_CLIENT', ',', 'Color', '.', 'ENDC', ')', ',', '\\n']
Tokenized   (043): ['<s>', 'Status', 'Ġ.', 'ĠFA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ:', 'Ġ%', 'Ġ(', 'ĠCOL', 'OR', '_', 'FA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ,', 'ĠColor', 'Ġ.', 'ĠEND', 'C', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['Status', 'Ġ.', 'ĠFA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ:', 'Ġ%', 'Ġ(', 'ĠCOL', 'OR', '_', 'FA', 'IL', 'ED', '_', 'TO', '_', 'ADD', '_', 'TO', '_', 'CL', 'IENT', 'Ġ,', 'ĠColor', 'Ġ.', 'ĠEND', 'C', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['Status', 'Ġ.', 'ĠFAILED_TO_ADD_TO_CLIENT', 'Ġ:', 'Ġ%', 'Ġ(', 'ĠCOLOR_FAILED_TO_ADD_TO_CLIENT', 'Ġ,', 'ĠColor', 'Ġ.', 'ĠENDC', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "end_size += f [ ] \n"
Original    (006): ['end_size', '+=', 'f', '[', ']', '\\n']
Tokenized   (011): ['<s>', 'end', '_', 'size', 'Ġ+=', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['end', '_', 'size', 'Ġ+=', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['end_size', 'Ġ+=', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "files_to_check += self . db . find_hash_varying_size ( f [ ] ) \n"
Original    (013): ['files_to_check', '+=', 'self', '.', 'db', '.', 'find_hash_varying_size', '(', 'f', '[', ']', ')', '\\n']
Tokenized   (028): ['<s>', 'files', '_', 'to', '_', 'check', 'Ġ+=', 'Ġself', 'Ġ.', 'Ġdb', 'Ġ.', 'Ġfind', '_', 'hash', '_', 'v', 'ary', 'ing', '_', 'size', 'Ġ(', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['files', '_', 'to', '_', 'check', 'Ġ+=', 'Ġself', 'Ġ.', 'Ġdb', 'Ġ.', 'Ġfind', '_', 'hash', '_', 'v', 'ary', 'ing', '_', 'size', 'Ġ(', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['files_to_check', 'Ġ+=', 'Ġself', 'Ġ.', 'Ġdb', 'Ġ.', 'Ġfind_hash_varying_size', 'Ġ(', 'Ġf', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "match_start , match_end = pieces . match_file ( db_file , start_size , end_size ) \n"
Original    (015): ['match_start', ',', 'match_end', '=', 'pieces', '.', 'match_file', '(', 'db_file', ',', 'start_size', ',', 'end_size', ')', '\\n']
Tokenized   (030): ['<s>', 'match', '_', 'start', 'Ġ,', 'Ġmatch', '_', 'end', 'Ġ=', 'Ġpieces', 'Ġ.', 'Ġmatch', '_', 'file', 'Ġ(', 'Ġdb', '_', 'file', 'Ġ,', 'Ġstart', '_', 'size', 'Ġ,', 'Ġend', '_', 'size', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['match', '_', 'start', 'Ġ,', 'Ġmatch', '_', 'end', 'Ġ=', 'Ġpieces', 'Ġ.', 'Ġmatch', '_', 'file', 'Ġ(', 'Ġdb', '_', 'file', 'Ġ,', 'Ġstart', '_', 'size', 'Ġ,', 'Ġend', '_', 'size', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['match_start', 'Ġ,', 'Ġmatch_end', 'Ġ=', 'Ġpieces', 'Ġ.', 'Ġmatch_file', 'Ġ(', 'Ġdb_file', 'Ġ,', 'Ġstart_size', 'Ġ,', 'Ġend_size', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "path_files [ os . path . join ( * path ) ] . append ( { \n"
Original    (017): ['path_files', '[', 'os', '.', 'path', '.', 'join', '(', '*', 'path', ')', ']', '.', 'append', '(', '{', '\\n']
Tokenized   (022): ['<s>', 'path', '_', 'files', 'Ġ[', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ*', 'Ġpath', 'Ġ)', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['path', '_', 'files', 'Ġ[', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ*', 'Ġpath', 'Ġ)', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ\\', 'n']
Detokenized (017): ['path_files', 'Ġ[', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ*', 'Ġpath', 'Ġ)', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "files_sorted [ . join ( orig_path ) ] = i \n"
Original    (011): ['files_sorted', '[', '.', 'join', '(', 'orig_path', ')', ']', '=', 'i', '\\n']
Tokenized   (019): ['<s>', 'files', '_', 's', 'orted', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġorig', '_', 'path', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['files', '_', 's', 'orted', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġorig', '_', 'path', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\', 'n']
Detokenized (011): ['files_sorted', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġorig_path', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġi', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "found_size , missing_size = 0 , 0 \n"
Original    (008): ['found_size', ',', 'missing_size', '=', '0', ',', '0', '\\n']
Tokenized   (015): ['<s>', 'found', '_', 'size', 'Ġ,', 'Ġmissing', '_', 'size', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['found', '_', 'size', 'Ġ,', 'Ġmissing', '_', 'size', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ\\', 'n']
Detokenized (008): ['found_size', 'Ġ,', 'Ġmissing_size', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "output_fp . write ( * write_bytes ) \n"
Original    (008): ['output_fp', '.', 'write', '(', '*', 'write_bytes', ')', '\\n']
Tokenized   (015): ['<s>', 'output', '_', 'fp', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ*', 'Ġwrite', '_', 'bytes', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['output', '_', 'fp', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ*', 'Ġwrite', '_', 'bytes', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['output_fp', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ*', 'Ġwrite_bytes', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bytes_written += read_bytes \n"
Original    (004): ['bytes_written', '+=', 'read_bytes', '\\n']
Tokenized   (011): ['<s>', 'bytes', '_', 'written', 'Ġ+=', 'Ġread', '_', 'bytes', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['bytes', '_', 'written', 'Ġ+=', 'Ġread', '_', 'bytes', 'Ġ\\', 'n']
Detokenized (004): ['bytes_written', 'Ġ+=', 'Ġread_bytes', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "missing_percent = ( missing_size / ( found_size + missing_size ) ) * 100 \n"
Original    (014): ['missing_percent', '=', '(', 'missing_size', '/', '(', 'found_size', '+', 'missing_size', ')', ')', '*', '100', '\\n']
Tokenized   (025): ['<s>', 'missing', '_', 'percent', 'Ġ=', 'Ġ(', 'Ġmissing', '_', 'size', 'Ġ/', 'Ġ(', 'Ġfound', '_', 'size', 'Ġ+', 'Ġmissing', '_', 'size', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ100', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['missing', '_', 'percent', 'Ġ=', 'Ġ(', 'Ġmissing', '_', 'size', 'Ġ/', 'Ġ(', 'Ġfound', '_', 'size', 'Ġ+', 'Ġmissing', '_', 'size', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ100', 'Ġ\\', 'n']
Detokenized (014): ['missing_percent', 'Ġ=', 'Ġ(', 'Ġmissing_size', 'Ġ/', 'Ġ(', 'Ġfound_size', 'Ġ+', 'Ġmissing_size', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ100', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "found_percent = 100 - missing_percent \n"
Original    (006): ['found_percent', '=', '100', '-', 'missing_percent', '\\n']
Tokenized   (013): ['<s>', 'found', '_', 'percent', 'Ġ=', 'Ġ100', 'Ġ-', 'Ġmissing', '_', 'percent', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['found', '_', 'percent', 'Ġ=', 'Ġ100', 'Ġ-', 'Ġmissing', '_', 'percent', 'Ġ\\', 'n']
Detokenized (006): ['found_percent', 'Ġ=', 'Ġ100', 'Ġ-', 'Ġmissing_percent', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "would_not_add = missing_size and missing_percent > self . add_limit_percent or missing_size > \n"
Original    (013): ['would_not_add', '=', 'missing_size', 'and', 'missing_percent', '>', 'self', '.', 'add_limit_percent', 'or', 'missing_size', '>', '\\n']
Tokenized   (030): ['<s>', 'would', '_', 'not', '_', 'add', 'Ġ=', 'Ġmissing', '_', 'size', 'Ġand', 'Ġmissing', '_', 'percent', 'Ġ>', 'Ġself', 'Ġ.', 'Ġadd', '_', 'limit', '_', 'percent', 'Ġor', 'Ġmissing', '_', 'size', 'Ġ>', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['would', '_', 'not', '_', 'add', 'Ġ=', 'Ġmissing', '_', 'size', 'Ġand', 'Ġmissing', '_', 'percent', 'Ġ>', 'Ġself', 'Ġ.', 'Ġadd', '_', 'limit', '_', 'percent', 'Ġor', 'Ġmissing', '_', 'size', 'Ġ>', 'Ġ\\', 'n']
Detokenized (013): ['would_not_add', 'Ġ=', 'Ġmissing_size', 'Ġand', 'Ġmissing_percent', 'Ġ>', 'Ġself', 'Ġ.', 'Ġadd_limit_percent', 'Ġor', 'Ġmissing_size', 'Ġ>', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "LEGO_PALETTE = ( , , , , , , ) \n"
Original    (011): ['LEGO_PALETTE', '=', '(', ',', ',', ',', ',', ',', ',', ')', '\\n']
Tokenized   (020): ['<s>', 'LE', 'GO', '_', 'P', 'AL', 'ET', 'TE', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['LE', 'GO', '_', 'P', 'AL', 'ET', 'TE', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['LEGO_PALETTE', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Draft4Validator , RefResolver , create , extend , validator_for , validate , \n"
Original    (013): ['Draft4Validator', ',', 'RefResolver', ',', 'create', ',', 'extend', ',', 'validator_for', ',', 'validate', ',', '\\n']
Tokenized   (024): ['<s>', 'Draft', '4', 'Valid', 'ator', 'Ġ,', 'ĠRef', 'Res', 'olver', 'Ġ,', 'Ġcreate', 'Ġ,', 'Ġextend', 'Ġ,', 'Ġvalid', 'ator', '_', 'for', 'Ġ,', 'Ġvalidate', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['Draft', '4', 'Valid', 'ator', 'Ġ,', 'ĠRef', 'Res', 'olver', 'Ġ,', 'Ġcreate', 'Ġ,', 'Ġextend', 'Ġ,', 'Ġvalid', 'ator', '_', 'for', 'Ġ,', 'Ġvalidate', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['Draft4Validator', 'Ġ,', 'ĠRefResolver', 'Ġ,', 'Ġcreate', 'Ġ,', 'Ġextend', 'Ġ,', 'Ġvalidator_for', 'Ġ,', 'Ġvalidate', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "u"enum" : [ [ "a" , "b" , "c" ] , [ "d" , "e" , "f" ] ] , \n"
Original    (021): ['u"enum"', ':', '[', '[', '"a"', ',', '"b"', ',', '"c"', ']', ',', '[', '"d"', ',', '"e"', ',', '"f"', ']', ']', ',', '\\n']
Tokenized   (039): ['<s>', 'u', '"', 'enum', '"', 'Ġ:', 'Ġ[', 'Ġ[', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ"', 'd', '"', 'Ġ,', 'Ġ"', 'e', '"', 'Ġ,', 'Ġ"', 'f', '"', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['u', '"', 'enum', '"', 'Ġ:', 'Ġ[', 'Ġ[', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ"', 'd', '"', 'Ġ,', 'Ġ"', 'e', '"', 'Ġ,', 'Ġ"', 'f', '"', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (021): ['u"enum"', 'Ġ:', 'Ġ[', 'Ġ[', 'Ġ"a"', 'Ġ,', 'Ġ"b"', 'Ġ,', 'Ġ"c"', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ"d"', 'Ġ,', 'Ġ"e"', 'Ġ,', 'Ġ"f"', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "got = ( e . message for e in self . validator . iter_errors ( instance , schema ) ) \n"
Original    (021): ['got', '=', '(', 'e', '.', 'message', 'for', 'e', 'in', 'self', '.', 'validator', '.', 'iter_errors', '(', 'instance', ',', 'schema', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'got', 'Ġ=', 'Ġ(', 'Ġe', 'Ġ.', 'Ġmessage', 'Ġfor', 'Ġe', 'Ġin', 'Ġself', 'Ġ.', 'Ġvalid', 'ator', 'Ġ.', 'Ġiter', '_', 'errors', 'Ġ(', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['got', 'Ġ=', 'Ġ(', 'Ġe', 'Ġ.', 'Ġmessage', 'Ġfor', 'Ġe', 'Ġin', 'Ġself', 'Ġ.', 'Ġvalid', 'ator', 'Ġ.', 'Ġiter', '_', 'errors', 'Ġ(', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['got', 'Ġ=', 'Ġ(', 'Ġe', 'Ġ.', 'Ġmessage', 'Ġfor', 'Ġe', 'Ġin', 'Ġself', 'Ġ.', 'Ġvalidator', 'Ġ.', 'Ġiter_errors', 'Ġ(', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "checker . checks ( u"thing" ) ( check_fn ) \n"
Original    (010): ['checker', '.', 'checks', '(', 'u"thing"', ')', '(', 'check_fn', ')', '\\n']
Tokenized   (019): ['<s>', 'check', 'er', 'Ġ.', 'Ġchecks', 'Ġ(', 'Ġu', '"', 'thing', '"', 'Ġ)', 'Ġ(', 'Ġcheck', '_', 'fn', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['check', 'er', 'Ġ.', 'Ġchecks', 'Ġ(', 'Ġu', '"', 'thing', '"', 'Ġ)', 'Ġ(', 'Ġcheck', '_', 'fn', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['checker', 'Ġ.', 'Ġchecks', 'Ġ(', 'Ġu"thing"', 'Ġ)', 'Ġ(', 'Ġcheck_fn', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "deque ( [ "type" , 1 , "properties" , "foo" , "enum" ] ) , \n"
Original    (016): ['deque', '(', '[', '"type"', ',', '1', ',', '"properties"', ',', '"foo"', ',', '"enum"', ']', ')', ',', '\\n']
Tokenized   (028): ['<s>', 'de', 'que', 'Ġ(', 'Ġ[', 'Ġ"', 'type', '"', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ"', 'properties', '"', 'Ġ,', 'Ġ"', 'foo', '"', 'Ġ,', 'Ġ"', 'enum', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['de', 'que', 'Ġ(', 'Ġ[', 'Ġ"', 'type', '"', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ"', 'properties', '"', 'Ġ,', 'Ġ"', 'foo', '"', 'Ġ,', 'Ġ"', 'enum', '"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['deque', 'Ġ(', 'Ġ[', 'Ġ"type"', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ"properties"', 'Ġ,', 'Ġ"foo"', 'Ġ,', 'Ġ"enum"', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""baz" : { "minItems" : 2 } , \n"
Original    (009): ['"baz"', ':', '{', '"minItems"', ':', '2', '}', ',', '\\n']
Tokenized   (018): ['<s>', '"', 'b', 'az', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'min', 'Items', '"', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'b', 'az', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'min', 'Items', '"', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"baz"', 'Ġ:', 'Ġ{', 'Ġ"minItems"', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""required" : [ "root" ] , \n"
Original    (007): ['"required"', ':', '[', '"root"', ']', ',', '\\n']
Tokenized   (014): ['<s>', '"', 'required', '"', 'Ġ:', 'Ġ[', 'Ġ"', 'root', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['"', 'required', '"', 'Ġ:', 'Ġ[', 'Ġ"', 'root', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['"required"', 'Ġ:', 'Ġ[', 'Ġ"root"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "e2 . absolute_schema_path , deque ( \n"
Original    (007): ['e2', '.', 'absolute_schema_path', ',', 'deque', '(', '\\n']
Tokenized   (017): ['<s>', 'e', '2', 'Ġ.', 'Ġabsolute', '_', 'sche', 'ma', '_', 'path', 'Ġ,', 'Ġde', 'que', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['e', '2', 'Ġ.', 'Ġabsolute', '_', 'sche', 'ma', '_', 'path', 'Ġ,', 'Ġde', 'que', 'Ġ(', 'Ġ\\', 'n']
Detokenized (007): ['e2', 'Ġ.', 'Ġabsolute_schema_path', 'Ġ,', 'Ġdeque', 'Ġ(', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ""additionalProperties" : { "type" : "integer" , "minimum" : 5 } \n"
Original    (012): ['"additionalProperties"', ':', '{', '"type"', ':', '"integer"', ',', '"minimum"', ':', '5', '}', '\\n']
Tokenized   (026): ['<s>', '"', 'add', 'itional', 'Pro', 'perties', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'integer', '"', 'Ġ,', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', 'add', 'itional', 'Pro', 'perties', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'integer', '"', 'Ġ,', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n']
Detokenized (012): ['"additionalProperties"', 'Ġ:', 'Ġ{', 'Ġ"type"', 'Ġ:', 'Ġ"integer"', 'Ġ,', 'Ġ"minimum"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""bar" : { "type" : "string" } , \n"
Original    (009): ['"bar"', ':', '{', '"type"', ':', '"string"', '}', ',', '\\n']
Tokenized   (018): ['<s>', '"', 'bar', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'string', '"', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'bar', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'type', '"', 'Ġ:', 'Ġ"', 'string', '"', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"bar"', 'Ġ:', 'Ġ{', 'Ġ"type"', 'Ġ:', 'Ġ"string"', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""foo" : { "minimum" : 5 } \n"
Original    (008): ['"foo"', ':', '{', '"minimum"', ':', '5', '}', '\\n']
Tokenized   (015): ['<s>', '"', 'foo', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', 'foo', '"', 'Ġ:', 'Ġ{', 'Ġ"', 'minimum', '"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['"foo"', 'Ġ:', 'Ġ{', 'Ġ"minimum"', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""items" : [ { } ] , \n"
Original    (008): ['"items"', ':', '[', '{', '}', ']', ',', '\\n']
Tokenized   (013): ['<s>', '"', 'items', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['"', 'items', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['"items"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "validate ( instance = instance , schema = { my_property : my_value } ) \n"
Original    (015): ['validate', '(', 'instance', '=', 'instance', ',', 'schema', '=', '{', 'my_property', ':', 'my_value', '}', ')', '\\n']
Tokenized   (023): ['<s>', 'valid', 'ate', 'Ġ(', 'Ġinstance', 'Ġ=', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ=', 'Ġ{', 'Ġmy', '_', 'property', 'Ġ:', 'Ġmy', '_', 'value', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['valid', 'ate', 'Ġ(', 'Ġinstance', 'Ġ=', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ=', 'Ġ{', 'Ġmy', '_', 'property', 'Ġ:', 'Ġmy', '_', 'value', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['validate', 'Ġ(', 'Ġinstance', 'Ġ=', 'Ġinstance', 'Ġ,', 'Ġschema', 'Ġ=', 'Ġ{', 'Ġmy_property', 'Ġ:', 'Ġmy_value', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "chk_schema . assert_called_once_with ( { } ) \n"
Original    (008): ['chk_schema', '.', 'assert_called_once_with', '(', '{', '}', ')', '\\n']
Tokenized   (021): ['<s>', 'ch', 'k', '_', 'sche', 'ma', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['ch', 'k', '_', 'sche', 'ma', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['chk_schema', 'Ġ.', 'Ġassert_called_once_with', 'Ġ(', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "stored_schema = { "stored" : "schema" } \n"
Original    (008): ['stored_schema', '=', '{', '"stored"', ':', '"schema"', '}', '\\n']
Tokenized   (021): ['<s>', 'st', 'ored', '_', 'sche', 'ma', 'Ġ=', 'Ġ{', 'Ġ"', 'st', 'ored', '"', 'Ġ:', 'Ġ"', 'sche', 'ma', '"', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['st', 'ored', '_', 'sche', 'ma', 'Ġ=', 'Ġ{', 'Ġ"', 'st', 'ored', '"', 'Ġ:', 'Ġ"', 'sche', 'ma', '"', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['stored_schema', 'Ġ=', 'Ġ{', 'Ġ"stored"', 'Ġ:', 'Ġ"schema"', 'Ġ}', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""ports" : \n"
Original    (003): ['"ports"', ':', '\\n']
Tokenized   (008): ['<s>', '"', 'ports', '"', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['"', 'ports', '"', 'Ġ:', 'Ġ\\', 'n']
Detokenized (003): ['"ports"', 'Ġ:', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "l2Report . generateReport ( pod . id , True , False ) \n"
Original    (013): ['l2Report', '.', 'generateReport', '(', 'pod', '.', 'id', ',', 'True', ',', 'False', ')', '\\n']
Tokenized   (019): ['<s>', 'l', '2', 'Report', 'Ġ.', 'Ġgenerate', 'Report', 'Ġ(', 'Ġpod', 'Ġ.', 'Ġid', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['l', '2', 'Report', 'Ġ.', 'Ġgenerate', 'Report', 'Ġ(', 'Ġpod', 'Ġ.', 'Ġid', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['l2Report', 'Ġ.', 'ĠgenerateReport', 'Ġ(', 'Ġpod', 'Ġ.', 'Ġid', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_YAML_ = splitext ( __file__ ) [ 0 ] + \n"
Original    (011): ['_YAML_', '=', 'splitext', '(', '__file__', ')', '[', '0', ']', '+', '\\n']
Tokenized   (022): ['<s>', '_', 'Y', 'AM', 'L', '_', 'Ġ=', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['_', 'Y', 'AM', 'L', '_', 'Ġ=', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\', 'n']
Detokenized (011): ['_YAML_', 'Ġ=', 'Ġsplitext', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "globals ( ) . update ( loadyaml ( _YAML_ ) ) \n"
Original    (012): ['globals', '(', ')', '.', 'update', '(', 'loadyaml', '(', '_YAML_', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'gl', 'ob', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġload', 'y', 'aml', 'Ġ(', 'Ġ_', 'Y', 'AM', 'L', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['gl', 'ob', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġload', 'y', 'aml', 'Ġ(', 'Ġ_', 'Y', 'AM', 'L', '_', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['globals', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġloadyaml', 'Ġ(', 'Ġ_YAML_', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "gather_facts = False ) \n"
Original    (005): ['gather_facts', '=', 'False', ')', '\\n']
Tokenized   (011): ['<s>', 'g', 'ather', '_', 'facts', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['g', 'ather', '_', 'facts', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['gather_facts', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "DEFAULT_API_URLS = ( , \n"
Original    (005): ['DEFAULT_API_URLS', '=', '(', ',', '\\n']
Tokenized   (014): ['<s>', 'DE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['DE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['DEFAULT_API_URLS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "BAD_STATUS_CODES = [ , , , \n"
Original    (007): ['BAD_STATUS_CODES', '=', '[', ',', ',', ',', '\\n']
Tokenized   (018): ['<s>', 'B', 'AD', '_', 'STAT', 'US', '_', 'C', 'OD', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['B', 'AD', '_', 'STAT', 'US', '_', 'C', 'OD', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['BAD_STATUS_CODES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "translate_otp = True , api_urls = DEFAULT_API_URLS , \n"
Original    (009): ['translate_otp', '=', 'True', ',', 'api_urls', '=', 'DEFAULT_API_URLS', ',', '\\n']
Tokenized   (025): ['<s>', 'trans', 'late', '_', 'ot', 'p', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġapi', '_', 'url', 's', 'Ġ=', 'ĠDE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['trans', 'late', '_', 'ot', 'p', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġapi', '_', 'url', 's', 'Ġ=', 'ĠDE', 'FAULT', '_', 'API', '_', 'UR', 'LS', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['translate_otp', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġapi_urls', 'Ġ=', 'ĠDEFAULT_API_URLS', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rand_str = b ( os . urandom ( 30 ) ) \n"
Original    (012): ['rand_str', '=', 'b', '(', 'os', '.', 'urandom', '(', '30', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'rand', '_', 'str', 'Ġ=', 'Ġb', 'Ġ(', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['rand', '_', 'str', 'Ġ=', 'Ġb', 'Ġ(', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['rand_str', 'Ġ=', 'Ġb', 'Ġ(', 'Ġos', 'Ġ.', 'Ġurandom', 'Ġ(', 'Ġ30', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "nonce = base64 . b64encode ( rand_str , b ( ) ) [ : 25 ] . decode ( ) \n"
Original    (021): ['nonce', '=', 'base64', '.', 'b64encode', '(', 'rand_str', ',', 'b', '(', ')', ')', '[', ':', '25', ']', '.', 'decode', '(', ')', '\\n']
Tokenized   (031): ['<s>', 'non', 'ce', 'Ġ=', 'Ġbase', '64', 'Ġ.', 'Ġb', '64', 'en', 'code', 'Ġ(', 'Ġrand', '_', 'str', 'Ġ,', 'Ġb', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ25', 'Ġ]', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['non', 'ce', 'Ġ=', 'Ġbase', '64', 'Ġ.', 'Ġb', '64', 'en', 'code', 'Ġ(', 'Ġrand', '_', 'str', 'Ġ,', 'Ġb', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ25', 'Ġ]', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['nonce', 'Ġ=', 'Ġbase64', 'Ġ.', 'Ġb64encode', 'Ġ(', 'Ġrand_str', 'Ġ,', 'Ġb', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ25', 'Ġ]', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "otp . otp , nonce , \n"
Original    (007): ['otp', '.', 'otp', ',', 'nonce', ',', '\\n']
Tokenized   (013): ['<s>', 'ot', 'p', 'Ġ.', 'Ġot', 'p', 'Ġ,', 'Ġnon', 'ce', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['ot', 'p', 'Ġ.', 'Ġot', 'p', 'Ġ,', 'Ġnon', 'ce', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['otp', 'Ġ.', 'Ġotp', 'Ġ,', 'Ġnonce', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "pairs_string = . join ( [ . join ( pair ) for pair in pairs_sorted ] ) \n"
Original    (018): ['pairs_string', '=', '.', 'join', '(', '[', '.', 'join', '(', 'pair', ')', 'for', 'pair', 'in', 'pairs_sorted', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'p', 'airs', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpair', 'Ġ)', 'Ġfor', 'Ġpair', 'Ġin', 'Ġpairs', '_', 's', 'orted', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['p', 'airs', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpair', 'Ġ)', 'Ġfor', 'Ġpair', 'Ġin', 'Ġpairs', '_', 's', 'orted', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['pairs_string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġpair', 'Ġ)', 'Ġfor', 'Ġpair', 'Ġin', 'Ġpairs_sorted', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "digest = hmac . new ( self . key , b ( pairs_string ) , hashlib . sha1 ) . digest ( ) \n"
Original    (024): ['digest', '=', 'hmac', '.', 'new', '(', 'self', '.', 'key', ',', 'b', '(', 'pairs_string', ')', ',', 'hashlib', '.', 'sha1', ')', '.', 'digest', '(', ')', '\\n']
Tokenized   (034): ['<s>', 'dig', 'est', 'Ġ=', 'Ġh', 'mac', 'Ġ.', 'Ġnew', 'Ġ(', 'Ġself', 'Ġ.', 'Ġkey', 'Ġ,', 'Ġb', 'Ġ(', 'Ġpairs', '_', 'string', 'Ġ)', 'Ġ,', 'Ġhash', 'lib', 'Ġ.', 'Ġsh', 'a', '1', 'Ġ)', 'Ġ.', 'Ġdigest', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['dig', 'est', 'Ġ=', 'Ġh', 'mac', 'Ġ.', 'Ġnew', 'Ġ(', 'Ġself', 'Ġ.', 'Ġkey', 'Ġ,', 'Ġb', 'Ġ(', 'Ġpairs', '_', 'string', 'Ġ)', 'Ġ,', 'Ġhash', 'lib', 'Ġ.', 'Ġsh', 'a', '1', 'Ġ)', 'Ġ.', 'Ġdigest', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['digest', 'Ġ=', 'Ġhmac', 'Ġ.', 'Ġnew', 'Ġ(', 'Ġself', 'Ġ.', 'Ġkey', 'Ġ,', 'Ġb', 'Ġ(', 'Ġpairs_string', 'Ġ)', 'Ġ,', 'Ġhashlib', 'Ġ.', 'Ġsha1', 'Ġ)', 'Ġ.', 'Ġdigest', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "signature = ( [ unquote ( v ) for k , v in pairs if k == ] or [ None ] ) [ 0 ] \n"
Original    (027): ['signature', '=', '(', '[', 'unquote', '(', 'v', ')', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '==', ']', 'or', '[', 'None', ']', ')', '[', '0', ']', '\\n']
Tokenized   (032): ['<s>', 'sign', 'ature', 'Ġ=', 'Ġ(', 'Ġ[', 'Ġun', 'quote', 'Ġ(', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ==', 'Ġ]', 'Ġor', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['sign', 'ature', 'Ġ=', 'Ġ(', 'Ġ[', 'Ġun', 'quote', 'Ġ(', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ==', 'Ġ]', 'Ġor', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (027): ['signature', 'Ġ=', 'Ġ(', 'Ġ[', 'Ġunquote', 'Ġ(', 'Ġv', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ==', 'Ġ]', 'Ġor', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "query_string = . join ( [ k + + v for k , v in pairs if k != ] ) \n"
Original    (022): ['query_string', '=', '.', 'join', '(', '[', 'k', '+', '+', 'v', 'for', 'k', ',', 'v', 'in', 'pairs', 'if', 'k', '!=', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'query', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġk', 'Ġ+', 'Ġ+', 'Ġv', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ!=', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['query', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġk', 'Ġ+', 'Ġ+', 'Ġv', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ!=', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['query_string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġk', 'Ġ+', 'Ġ+', 'Ġv', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġpairs', 'Ġif', 'Ġk', 'Ġ!=', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "pairs = ( x . split ( , 1 ) for x in query_string . split ( ) ) \n"
Original    (020): ['pairs', '=', '(', 'x', '.', 'split', '(', ',', '1', ')', 'for', 'x', 'in', 'query_string', '.', 'split', '(', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'p', 'airs', 'Ġ=', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġquery', '_', 'string', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['p', 'airs', 'Ġ=', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġquery', '_', 'string', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['pairs', 'Ġ=', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġquery_string', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "py_modules = [ ] , \n"
Original    (006): ['py_modules', '=', '[', ']', ',', '\\n']
Tokenized   (011): ['<s>', 'py', '_', 'modules', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['py', '_', 'modules', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['py_modules', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "submitter , msg = result [ 0 ] \n"
Original    (009): ['submitter', ',', 'msg', '=', 'result', '[', '0', ']', '\\n']
Tokenized   (013): ['<s>', 'sub', 'mitter', 'Ġ,', 'Ġmsg', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['sub', 'mitter', 'Ġ,', 'Ġmsg', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['submitter', 'Ġ,', 'Ġmsg', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "contact = self . line_interface . _get_contact_by_id ( me . id ) \n"
Original    (013): ['contact', '=', 'self', '.', 'line_interface', '.', '_get_contact_by_id', '(', 'me', '.', 'id', ')', '\\n']
Tokenized   (025): ['<s>', 'contact', 'Ġ=', 'Ġself', 'Ġ.', 'Ġline', '_', 'interface', 'Ġ.', 'Ġ_', 'get', '_', 'contact', '_', 'by', '_', 'id', 'Ġ(', 'Ġme', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['contact', 'Ġ=', 'Ġself', 'Ġ.', 'Ġline', '_', 'interface', 'Ġ.', 'Ġ_', 'get', '_', 'contact', '_', 'by', '_', 'id', 'Ġ(', 'Ġme', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['contact', 'Ġ=', 'Ġself', 'Ġ.', 'Ġline_interface', 'Ġ.', 'Ġ_get_contact_by_id', 'Ġ(', 'Ġme', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ok_ ( me_display_name == me . name ) \n"
Original    (009): ['ok_', '(', 'me_display_name', '==', 'me', '.', 'name', ')', '\\n']
Tokenized   (017): ['<s>', 'ok', '_', 'Ġ(', 'Ġme', '_', 'display', '_', 'name', 'Ġ==', 'Ġme', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['ok', '_', 'Ġ(', 'Ġme', '_', 'display', '_', 'name', 'Ġ==', 'Ġme', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['ok_', 'Ġ(', 'Ġme_display_name', 'Ġ==', 'Ġme', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "transport . get_extra_info . return_value = None \n"
Original    (008): ['transport', '.', 'get_extra_info', '.', 'return_value', '=', 'None', '\\n']
Tokenized   (018): ['<s>', 'trans', 'port', 'Ġ.', 'Ġget', '_', 'extra', '_', 'info', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['trans', 'port', 'Ġ.', 'Ġget', '_', 'extra', '_', 'info', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'ĠNone', 'Ġ\\', 'n']
Detokenized (008): ['transport', 'Ġ.', 'Ġget_extra_info', 'Ġ.', 'Ġreturn_value', 'Ġ=', 'ĠNone', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ShortenerSettings = namedtuple ( , [ \n"
Original    (007): ['ShortenerSettings', '=', 'namedtuple', '(', ',', '[', '\\n']
Tokenized   (014): ['<s>', 'Short', 'ener', 'Settings', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Short', 'ener', 'Settings', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ\\', 'n']
Detokenized (007): ['ShortenerSettings', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "right_to_left = [ , ] , \n"
Original    (007): ['right_to_left', '=', '[', ',', ']', ',', '\\n']
Tokenized   (014): ['<s>', 'right', '_', 'to', '_', 'left', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['right', '_', 'to', '_', 'left', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['right_to_left', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "shortener = { } , \n"
Original    (006): ['shortener', '=', '{', '}', ',', '\\n']
Tokenized   (010): ['<s>', 'short', 'ener', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['short', 'ener', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['shortener', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "workers_pool = 10 , \n"
Original    (005): ['workers_pool', '=', '10', ',', '\\n']
Tokenized   (010): ['<s>', 'workers', '_', 'pool', 'Ġ=', 'Ġ10', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['workers', '_', 'pool', 'Ġ=', 'Ġ10', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['workers_pool', 'Ġ=', 'Ġ10', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "cms_service_host = "http://localhost:5001" \n"
Original    (004): ['cms_service_host', '=', '"http://localhost:5001"', '\\n']
Tokenized   (018): ['<s>', 'cms', '_', 'service', '_', 'host', 'Ġ=', 'Ġ"', 'http', '://', 'localhost', ':', '500', '1', '"', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['cms', '_', 'service', '_', 'host', 'Ġ=', 'Ġ"', 'http', '://', 'localhost', ':', '500', '1', '"', 'Ġ\\', 'n']
Detokenized (004): ['cms_service_host', 'Ġ=', 'Ġ"http://localhost:5001"', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "subparsers = args . add_subparsers ( help = , dest = ) \n"
Original    (013): ['subparsers', '=', 'args', '.', 'add_subparsers', '(', 'help', '=', ',', 'dest', '=', ')', '\\n']
Tokenized   (024): ['<s>', 'sub', 'p', 'ars', 'ers', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġadd', '_', 'sub', 'p', 'ars', 'ers', 'Ġ(', 'Ġhelp', 'Ġ=', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['sub', 'p', 'ars', 'ers', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġadd', '_', 'sub', 'p', 'ars', 'ers', 'Ġ(', 'Ġhelp', 'Ġ=', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['subparsers', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġadd_subparsers', 'Ġ(', 'Ġhelp', 'Ġ=', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "template_parser . add_argument ( , \n"
Original    (006): ['template_parser', '.', 'add_argument', '(', ',', '\\n']
Tokenized   (013): ['<s>', 'template', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['template', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['template_parser', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "config_parser . add_argument ( , help = ) \n"
Original    (009): ['config_parser', '.', 'add_argument', '(', ',', 'help', '=', ')', '\\n']
Tokenized   (016): ['<s>', 'config', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['config', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['config_parser', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "gui_parser . add_argument ( , , type = str , help = ) \n"
Original    (014): ['gui_parser', '.', 'add_argument', '(', ',', ',', 'type', '=', 'str', ',', 'help', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'gui', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġstr', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['gui', '_', 'parser', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġstr', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['gui_parser', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġstr', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "changePwdResult = conn . extend . microsoft . modify_password ( user_dn , newpassword ) \n"
Original    (015): ['changePwdResult', '=', 'conn', '.', 'extend', '.', 'microsoft', '.', 'modify_password', '(', 'user_dn', ',', 'newpassword', ')', '\\n']
Tokenized   (027): ['<s>', 'change', 'P', 'wd', 'Result', 'Ġ=', 'Ġconn', 'Ġ.', 'Ġextend', 'Ġ.', 'Ġmicro', 'soft', 'Ġ.', 'Ġmodify', '_', 'password', 'Ġ(', 'Ġuser', '_', 'dn', 'Ġ,', 'Ġnew', 'password', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['change', 'P', 'wd', 'Result', 'Ġ=', 'Ġconn', 'Ġ.', 'Ġextend', 'Ġ.', 'Ġmicro', 'soft', 'Ġ.', 'Ġmodify', '_', 'password', 'Ġ(', 'Ġuser', '_', 'dn', 'Ġ,', 'Ġnew', 'password', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['changePwdResult', 'Ġ=', 'Ġconn', 'Ġ.', 'Ġextend', 'Ġ.', 'Ġmicrosoft', 'Ġ.', 'Ġmodify_password', 'Ġ(', 'Ġuser_dn', 'Ġ,', 'Ġnewpassword', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "cap_path = os . path . join ( caps_directory , ) \n"
Original    (012): ['cap_path', '=', 'os', '.', 'path', '.', 'join', '(', 'caps_directory', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'cap', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġcaps', '_', 'directory', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['cap', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġcaps', '_', 'directory', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['cap_path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġcaps_directory', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "cap . eventloop . stop ( ) \n"
Original    (008): ['cap', '.', 'eventloop', '.', 'stop', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'cap', 'Ġ.', 'Ġevent', 'loop', 'Ġ.', 'Ġstop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['cap', 'Ġ.', 'Ġevent', 'loop', 'Ġ.', 'Ġstop', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['cap', 'Ġ.', 'Ġeventloop', 'Ġ.', 'Ġstop', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "flush = Service ( name = , \n"
Original    (008): ['flush', '=', 'Service', '(', 'name', '=', ',', '\\n']
Tokenized   (011): ['<s>', 'flush', 'Ġ=', 'ĠService', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['flush', 'Ġ=', 'ĠService', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['flush', 'Ġ=', 'ĠService', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sourceIds = [ d [ ] for d in response . json ] \n"
Original    (014): ['sourceIds', '=', '[', 'd', '[', ']', 'for', 'd', 'in', 'response', '.', 'json', ']', '\\n']
Tokenized   (019): ['<s>', 'source', 'Id', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġd', 'Ġin', 'Ġresponse', 'Ġ.', 'Ġjson', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['source', 'Id', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġd', 'Ġin', 'Ġresponse', 'Ġ.', 'Ġjson', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['sourceIds', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġd', 'Ġin', 'Ġresponse', 'Ġ.', 'Ġjson', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ""folder." ) \n"
Original    (003): ['"folder."', ')', '\\n']
Tokenized   (008): ['<s>', '"', 'folder', '."', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['"', 'folder', '."', 'Ġ)', 'Ġ\\', 'n']
Detokenized (003): ['"folder."', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "minerva_metadata [ ] = { \n"
Original    (006): ['minerva_metadata', '[', ']', '=', '{', '\\n']
Tokenized   (012): ['<s>', 'min', 'erva', '_', 'metadata', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['min', 'erva', '_', 'metadata', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ\\', 'n']
Detokenized (006): ['minerva_metadata', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "Description ( ) \n"
Original    (004): ['Description', '(', ')', '\\n']
Tokenized   (007): ['<s>', 'Description', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['Description', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['Description', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "matches = re . findall ( "(\'|\\")(\\S+)(\'|\\")" , text ) \n"
Original    (011): ['matches', '=', 're', '.', 'findall', '(', '"(\\\'|\\\\")(\\\\S+)(\\\'|\\\\")"', ',', 'text', ')', '\\n']
Tokenized   (030): ['<s>', 'mat', 'ches', 'Ġ=', 'Ġre', 'Ġ.', 'Ġfind', 'all', 'Ġ(', 'Ġ"(', "\\'", '|', '\\\\', '")', '(', '\\\\', 'S', '+', ')(', "\\'", '|', '\\\\', '")', '"', 'Ġ,', 'Ġtext', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['mat', 'ches', 'Ġ=', 'Ġre', 'Ġ.', 'Ġfind', 'all', 'Ġ(', 'Ġ"(', "\\'", '|', '\\\\', '")', '(', '\\\\', 'S', '+', ')(', "\\'", '|', '\\\\', '")', '"', 'Ġ,', 'Ġtext', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['matches', 'Ġ=', 'Ġre', 'Ġ.', 'Ġfindall', 'Ġ(', 'Ġ"(\\\'|\\\\")(\\\\S+)(\\\'|\\\\")"', 'Ġ,', 'Ġtext', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "package_data = { : [ ] } , \n"
Original    (009): ['package_data', '=', '{', ':', '[', ']', '}', ',', '\\n']
Tokenized   (014): ['<s>', 'package', '_', 'data', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['package', '_', 'data', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['package_data', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "list_permissions = [ , , , ] \n"
Original    (008): ['list_permissions', '=', '[', ',', ',', ',', ']', '\\n']
Tokenized   (014): ['<s>', 'list', '_', 'per', 'missions', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['list', '_', 'per', 'missions', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['list_permissions', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "option_list = BaseCommand . option_list + ( \n"
Original    (008): ['option_list', '=', 'BaseCommand', '.', 'option_list', '+', '(', '\\n']
Tokenized   (016): ['<s>', 'option', '_', 'list', 'Ġ=', 'ĠBase', 'Command', 'Ġ.', 'Ġoption', '_', 'list', 'Ġ+', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['option', '_', 'list', 'Ġ=', 'ĠBase', 'Command', 'Ġ.', 'Ġoption', '_', 'list', 'Ġ+', 'Ġ(', 'Ġ\\', 'n']
Detokenized (008): ['option_list', 'Ġ=', 'ĠBaseCommand', 'Ġ.', 'Ġoption_list', 'Ġ+', 'Ġ(', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "make_option ( , \n"
Original    (004): ['make_option', '(', ',', '\\n']
Tokenized   (009): ['<s>', 'make', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['make', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['make_option', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "confirm_token = Column ( Unicode ( 100 ) ) \n"
Original    (010): ['confirm_token', '=', 'Column', '(', 'Unicode', '(', '100', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'conf', 'irm', '_', 'token', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['conf', 'irm', '_', 'token', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['confirm_token', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "creation_date = Column ( DateTime ( ) , nullable = False ) \n"
Original    (013): ['creation_date', '=', 'Column', '(', 'DateTime', '(', ')', ',', 'nullable', '=', 'False', ')', '\\n']
Tokenized   (020): ['<s>', 'creation', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['creation', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġnull', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['creation_date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDateTime', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġnullable', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "last_login_date = Column ( DateTime ( ) ) \n"
Original    (009): ['last_login_date', '=', 'Column', '(', 'DateTime', '(', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'last', '_', 'login', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['last', '_', 'login', '_', 'date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDate', 'Time', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['last_login_date', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠDateTime', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "SHARING_ROLES = [ , , ] \n"
Original    (007): ['SHARING_ROLES', '=', '[', ',', ',', ']', '\\n']
Tokenized   (016): ['<s>', 'SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['SHARING_ROLES', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "USER_MANAGEMENT_ROLES = SHARING_ROLES + [ ] \n"
Original    (007): ['USER_MANAGEMENT_ROLES', '=', 'SHARING_ROLES', '+', '[', ']', '\\n']
Tokenized   (023): ['<s>', 'USER', '_', 'MAN', 'AG', 'EMENT', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['USER', '_', 'MAN', 'AG', 'EMENT', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['USER_MANAGEMENT_ROLES', 'Ġ=', 'ĠSHARING_ROLES', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_DEFAULT_SHARING_ROLES = SHARING_ROLES [ : ] \n"
Original    (007): ['_DEFAULT_SHARING_ROLES', '=', 'SHARING_ROLES', '[', ':', ']', '\\n']
Tokenized   (025): ['<s>', '_', 'DE', 'FAULT', '_', 'SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['_', 'DE', 'FAULT', '_', 'SH', 'AR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ=', 'ĠSHAR', 'ING', '_', 'R', 'OL', 'ES', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['_DEFAULT_SHARING_ROLES', 'Ġ=', 'ĠSHARING_ROLES', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "principal = get_principals ( ) . get ( name ) \n"
Original    (011): ['principal', '=', 'get_principals', '(', ')', '.', 'get', '(', 'name', ')', '\\n']
Tokenized   (021): ['<s>', 'pr', 'inc', 'ipal', 'Ġ=', 'Ġget', '_', 'pr', 'inc', 'ip', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['pr', 'inc', 'ipal', 'Ġ=', 'Ġget', '_', 'pr', 'inc', 'ip', 'als', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['principal', 'Ġ=', 'Ġget_principals', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "lg for lg in context . local_groups \n"
Original    (008): ['lg', 'for', 'lg', 'in', 'context', '.', 'local_groups', '\\n']
Tokenized   (015): ['<s>', 'l', 'g', 'Ġfor', 'Ġl', 'g', 'Ġin', 'Ġcontext', 'Ġ.', 'Ġlocal', '_', 'groups', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['l', 'g', 'Ġfor', 'Ġl', 'g', 'Ġin', 'Ġcontext', 'Ġ.', 'Ġlocal', '_', 'groups', 'Ġ\\', 'n']
Detokenized (008): ['lg', 'Ġfor', 'Ġlg', 'Ġin', 'Ġcontext', 'Ġ.', 'Ġlocal_groups', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "LocalGroup ( context , name , unicode ( group_name ) ) \n"
Original    (012): ['LocalGroup', '(', 'context', ',', 'name', ',', 'unicode', '(', 'group_name', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'Local', 'Group', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġname', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġgroup', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['Local', 'Group', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġname', 'Ġ,', 'Ġunic', 'ode', 'Ġ(', 'Ġgroup', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['LocalGroup', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġname', 'Ġ,', 'Ġunicode', 'Ġ(', 'Ġgroup_name', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "filters . append ( func . lower ( col ) . like ( value ) ) \n"
Original    (017): ['filters', '.', 'append', '(', 'func', '.', 'lower', '(', 'col', ')', '.', 'like', '(', 'value', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'fil', 'ters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġcol', 'Ġ)', 'Ġ.', 'Ġlike', 'Ġ(', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['fil', 'ters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġcol', 'Ġ)', 'Ġ.', 'Ġlike', 'Ġ(', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['filters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġcol', 'Ġ)', 'Ġ.', 'Ġlike', 'Ġ(', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "bcrypt . hashpw ( password . encode ( ) , hashed . encode ( ) ) ) \n"
Original    (018): ['bcrypt', '.', 'hashpw', '(', 'password', '.', 'encode', '(', ')', ',', 'hashed', '.', 'encode', '(', ')', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'bc', 'rypt', 'Ġ.', 'Ġhash', 'p', 'w', 'Ġ(', 'Ġpassword', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġhas', 'hed', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['bc', 'rypt', 'Ġ.', 'Ġhash', 'p', 'w', 'Ġ(', 'Ġpassword', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġhas', 'hed', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['bcrypt', 'Ġ.', 'Ġhashpw', 'Ġ(', 'Ġpassword', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġhashed', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "browser . open ( . format ( BASE_URL ) ) \n"
Original    (011): ['browser', '.', 'open', '(', '.', 'format', '(', 'BASE_URL', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'browser', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠBASE', '_', 'URL', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['browser', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠBASE', '_', 'URL', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['browser', 'Ġ.', 'Ġopen', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠBASE_URL', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "AUTHORS = open ( os . path . join ( here , ) ) . read ( ) \n"
Original    (019): ['AUTHORS', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'A', 'UTH', 'ORS', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['A', 'UTH', 'ORS', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['AUTHORS', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "fixed_boxes ) : \n"
Original    (004): ['fixed_boxes', ')', ':', '\\n']
Tokenized   (009): ['<s>', 'fixed', '_', 'boxes', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['fixed', '_', 'boxes', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (004): ['fixed_boxes', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "resolve_percentages ( box , ( containing_block . width , containing_block . height ) ) \n"
Original    (015): ['resolve_percentages', '(', 'box', ',', '(', 'containing_block', '.', 'width', ',', 'containing_block', '.', 'height', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'res', 'olve', '_', 'percent', 'ages', 'Ġ(', 'Ġbox', 'Ġ,', 'Ġ(', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġwidth', 'Ġ,', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġheight', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['res', 'olve', '_', 'percent', 'ages', 'Ġ(', 'Ġbox', 'Ġ,', 'Ġ(', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġwidth', 'Ġ,', 'Ġcontaining', '_', 'block', 'Ġ.', 'Ġheight', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['resolve_percentages', 'Ġ(', 'Ġbox', 'Ġ,', 'Ġ(', 'Ġcontaining_block', 'Ġ.', 'Ġwidth', 'Ġ,', 'Ġcontaining_block', 'Ġ.', 'Ġheight', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "box , _ , _ , _ , _ = block_container_layout ( \n"
Original    (013): ['box', ',', '_', ',', '_', ',', '_', ',', '_', '=', 'block_container_layout', '(', '\\n']
Tokenized   (020): ['<s>', 'box', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ=', 'Ġblock', '_', 'container', '_', 'layout', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['box', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ=', 'Ġblock', '_', 'container', '_', 'layout', 'Ġ(', 'Ġ\\', 'n']
Detokenized (013): ['box', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġ_', 'Ġ=', 'Ġblock_container_layout', 'Ġ(', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "skip_stack = None , device_size = device_size , page_is_empty = False , \n"
Original    (013): ['skip_stack', '=', 'None', ',', 'device_size', '=', 'device_size', ',', 'page_is_empty', '=', 'False', ',', '\\n']
Tokenized   (026): ['<s>', 'skip', '_', 'stack', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdevice', '_', 'size', 'Ġ=', 'Ġdevice', '_', 'size', 'Ġ,', 'Ġpage', '_', 'is', '_', 'empty', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['skip', '_', 'stack', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdevice', '_', 'size', 'Ġ=', 'Ġdevice', '_', 'size', 'Ġ,', 'Ġpage', '_', 'is', '_', 'empty', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['skip_stack', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdevice_size', 'Ġ=', 'Ġdevice_size', 'Ġ,', 'Ġpage_is_empty', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "list_marker_layout ( context , box ) \n"
Original    (007): ['list_marker_layout', '(', 'context', ',', 'box', ')', '\\n']
Tokenized   (015): ['<s>', 'list', '_', 'mark', 'er', '_', 'layout', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġbox', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['list', '_', 'mark', 'er', '_', 'layout', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġbox', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['list_marker_layout', 'Ġ(', 'Ġcontext', 'Ġ,', 'Ġbox', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "hypothetical_position = box . position_y + collapsed_margin \n"
Original    (008): ['hypothetical_position', '=', 'box', '.', 'position_y', '+', 'collapsed_margin', '\\n']
Tokenized   (019): ['<s>', 'hyp', 'ot', 'hetical', '_', 'position', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġcollapsed', '_', 'margin', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['hyp', 'ot', 'hetical', '_', 'position', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġcollapsed', '_', 'margin', 'Ġ\\', 'n']
Detokenized (008): ['hypothetical_position', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġposition_y', 'Ġ+', 'Ġcollapsed_margin', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "box_width = box . margin_width ( ) if outer else box . border_width ( ) \n"
Original    (016): ['box_width', '=', 'box', '.', 'margin_width', '(', ')', 'if', 'outer', 'else', 'box', '.', 'border_width', '(', ')', '\\n']
Tokenized   (025): ['<s>', 'box', '_', 'width', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'width', 'Ġ(', 'Ġ)', 'Ġif', 'Ġouter', 'Ġelse', 'Ġbox', 'Ġ.', 'Ġborder', '_', 'width', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['box', '_', 'width', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'width', 'Ġ(', 'Ġ)', 'Ġif', 'Ġouter', 'Ġelse', 'Ġbox', 'Ġ.', 'Ġborder', '_', 'width', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['box_width', 'Ġ=', 'Ġbox', 'Ġ.', 'Ġmargin_width', 'Ġ(', 'Ġ)', 'Ġif', 'Ġouter', 'Ġelse', 'Ġbox', 'Ġ.', 'Ġborder_width', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "max_right_bound -= box . margin_right \n"
Original    (006): ['max_right_bound', '-=', 'box', '.', 'margin_right', '\\n']
Tokenized   (015): ['<s>', 'max', '_', 'right', '_', 'bound', 'Ġ-=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'right', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['max', '_', 'right', '_', 'bound', 'Ġ-=', 'Ġbox', 'Ġ.', 'Ġmargin', '_', 'right', 'Ġ\\', 'n']
Detokenized (006): ['max_right_bound', 'Ġ-=', 'Ġbox', 'Ġ.', 'Ġmargin_right', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "shape . position_y + shape . margin_height ( ) \n"
Original    (010): ['shape', '.', 'position_y', '+', 'shape', '.', 'margin_height', '(', ')', '\\n']
Tokenized   (017): ['<s>', 'shape', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġshape', 'Ġ.', 'Ġmargin', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['shape', 'Ġ.', 'Ġposition', '_', 'y', 'Ġ+', 'Ġshape', 'Ġ.', 'Ġmargin', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['shape', 'Ġ.', 'Ġposition_y', 'Ġ+', 'Ġshape', 'Ġ.', 'Ġmargin_height', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "urlpatterns = patterns ( , \n"
Original    (006): ['urlpatterns', '=', 'patterns', '(', ',', '\\n']
Tokenized   (011): ['<s>', 'url', 'pattern', 's', 'Ġ=', 'Ġpatterns', 'Ġ(', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['url', 'pattern', 's', 'Ġ=', 'Ġpatterns', 'Ġ(', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['urlpatterns', 'Ġ=', 'Ġpatterns', 'Ġ(', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "obj1 , obj2 = qs \n"
Original    (006): ['obj1', ',', 'obj2', '=', 'qs', '\\n']
Tokenized   (012): ['<s>', 'obj', '1', 'Ġ,', 'Ġobj', '2', 'Ġ=', 'Ġq', 's', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['obj', '1', 'Ġ,', 'Ġobj', '2', 'Ġ=', 'Ġq', 's', 'Ġ\\', 'n']
Detokenized (006): ['obj1', 'Ġ,', 'Ġobj2', 'Ġ=', 'Ġqs', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "n1 = Normal . objects . language ( ) . get ( pk = self . normal_id [ 1 ] ) \n"
Original    (022): ['n1', '=', 'Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'pk', '=', 'self', '.', 'normal_id', '[', '1', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'n', '1', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnormal', '_', 'id', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['n', '1', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnormal', '_', 'id', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['n1', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnormal_id', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "shared_field = NEW_SHARED , translated_field = NEW_TRANSLATED \n"
Original    (008): ['shared_field', '=', 'NEW_SHARED', ',', 'translated_field', '=', 'NEW_TRANSLATED', '\\n']
Tokenized   (024): ['<s>', 'shared', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'SH', 'AR', 'ED', 'Ġ,', 'Ġtranslated', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'TR', 'AN', 'SL', 'ATED', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['shared', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'SH', 'AR', 'ED', 'Ġ,', 'Ġtranslated', '_', 'field', 'Ġ=', 'ĠNEW', '_', 'TR', 'AN', 'SL', 'ATED', 'Ġ\\', 'n']
Detokenized (008): ['shared_field', 'Ġ=', 'ĠNEW_SHARED', 'Ġ,', 'Ġtranslated_field', 'Ġ=', 'ĠNEW_TRANSLATED', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "NORMAL [ 2 ] . shared_field ] ) \n"
Original    (009): ['NORMAL', '[', '2', ']', '.', 'shared_field', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'NOR', 'MAL', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['NOR', 'MAL', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['NORMAL', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġshared_field', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "ja = Normal . objects . language ( ) . get ( pk = en . pk ) \n"
Original    (019): ['ja', '=', 'Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'get', '(', 'pk', '=', 'en', '.', 'pk', ')', '\\n']
Tokenized   (024): ['<s>', 'ja', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġen', 'Ġ.', 'Ġp', 'k', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ja', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġen', 'Ġ.', 'Ġp', 'k', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['ja', 'Ġ=', 'ĠNormal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġen', 'Ġ.', 'Ġpk', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "AggregateModel . objects . language ( "en" ) . create ( number = 0 , translated_number = 0 ) \n"
Original    (020): ['AggregateModel', '.', 'objects', '.', 'language', '(', '"en"', ')', '.', 'create', '(', 'number', '=', '0', ',', 'translated_number', '=', '0', ')', '\\n']
Tokenized   (029): ['<s>', 'Agg', 'regate', 'Model', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ"', 'en', '"', 'Ġ)', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġnumber', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġtranslated', '_', 'number', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['Agg', 'regate', 'Model', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ"', 'en', '"', 'Ġ)', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġnumber', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġtranslated', '_', 'number', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['AggregateModel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ"en"', 'Ġ)', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġnumber', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġtranslated_number', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "shared_contains_two = Q ( shared_field__contains = ) \n"
Original    (008): ['shared_contains_two', '=', 'Q', '(', 'shared_field__contains', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'shared', '_', 'cont', 'ains', '_', 'two', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġshared', '_', 'field', '__', 'cont', 'ains', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['shared', '_', 'cont', 'ains', '_', 'two', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġshared', '_', 'field', '__', 'cont', 'ains', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['shared_contains_two', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġshared_field__contains', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "normal_one = Q ( normal_field = STANDARD [ 1 ] . normal_field ) \n"
Original    (014): ['normal_one', '=', 'Q', '(', 'normal_field', '=', 'STANDARD', '[', '1', ']', '.', 'normal_field', ')', '\\n']
Tokenized   (024): ['<s>', 'normal', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '_', 'field', 'Ġ=', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', '_', 'field', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['normal', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '_', 'field', 'Ġ=', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', '_', 'field', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['normal_one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal_field', 'Ġ=', 'ĠSTANDARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal_field', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "shared_one = Q ( normal__shared_field = NORMAL [ STANDARD [ 1 ] . normal ] . shared_field ) \n"
Original    (019): ['shared_one', '=', 'Q', '(', 'normal__shared_field', '=', 'NORMAL', '[', 'STANDARD', '[', '1', ']', '.', 'normal', ']', '.', 'shared_field', ')', '\\n']
Tokenized   (032): ['<s>', 'shared', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'shared', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['shared', '_', 'one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'shared', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġshared', '_', 'field', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['shared_one', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal__shared_field', 'Ġ=', 'ĠNORMAL', 'Ġ[', 'ĠSTANDARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġshared_field', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "translated_one_en = Q ( normal__translated_field = NORMAL [ STANDARD [ 1 ] . normal ] . translated_field [ translated_two_en = Q ( normal__translated_field = NORMAL [ STANDARD [ 2 ] . normal ] . translated_field [ \n"
Original    (037): ['translated_one_en', '=', 'Q', '(', 'normal__translated_field', '=', 'NORMAL', '[', 'STANDARD', '[', '1', ']', '.', 'normal', ']', '.', 'translated_field', '[', 'translated_two_en', '=', 'Q', '(', 'normal__translated_field', '=', 'NORMAL', '[', 'STANDARD', '[', '2', ']', '.', 'normal', ']', '.', 'translated_field', '[', '\\n']
Tokenized   (067): ['<s>', 'trans', 'lated', '_', 'one', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (065): ['trans', 'lated', '_', 'one', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal', '__', 'trans', 'lated', '_', 'field', 'Ġ=', 'ĠNOR', 'MAL', 'Ġ[', 'ĠSTAND', 'ARD', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated', '_', 'field', 'Ġ[', 'Ġ\\', 'n']
Detokenized (037): ['translated_one_en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal__translated_field', 'Ġ=', 'ĠNORMAL', 'Ġ[', 'ĠSTANDARD', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated_field', 'Ġ[', 'Ġtranslated_two_en', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġnormal__translated_field', 'Ġ=', 'ĠNORMAL', 'Ġ[', 'ĠSTANDARD', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġnormal', 'Ġ]', 'Ġ.', 'Ġtranslated_field', 'Ġ[', 'Ġ\\n']
Counter: 65
===================================================================
Hidden states:  (13, 37, 768)
# Extracted words:  37
Sentence         : "qs = manager . filter ( shared_one & ~ translated_two_en ) \n"
Original    (012): ['qs', '=', 'manager', '.', 'filter', '(', 'shared_one', '&', '~', 'translated_two_en', ')', '\\n']
Tokenized   (021): ['<s>', 'qs', 'Ġ=', 'Ġmanager', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġshared', '_', 'one', 'Ġ&', 'Ġ~', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['qs', 'Ġ=', 'Ġmanager', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġshared', '_', 'one', 'Ġ&', 'Ġ~', 'Ġtranslated', '_', 'two', '_', 'en', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['qs', 'Ġ=', 'Ġmanager', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġshared_one', 'Ġ&', 'Ġ~', 'Ġtranslated_two_en', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Normal . objects . language ( ) . complex_filter , \n"
Original    (011): ['Normal', '.', 'objects', '.', 'language', '(', ')', '.', 'complex_filter', ',', '\\n']
Tokenized   (016): ['<s>', 'Normal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcomplex', '_', 'filter', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['Normal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcomplex', '_', 'filter', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['Normal', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġlanguage', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcomplex_filter', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "analytics . track ( user_id , "Activate" , { \n"
Original    (010): ['analytics', '.', 'track', '(', 'user_id', ',', '"Activate"', ',', '{', '\\n']
Tokenized   (019): ['<s>', 'analy', 'tics', 'Ġ.', 'Ġtrack', 'Ġ(', 'Ġuser', '_', 'id', 'Ġ,', 'Ġ"', 'Activ', 'ate', '"', 'Ġ,', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['analy', 'tics', 'Ġ.', 'Ġtrack', 'Ġ(', 'Ġuser', '_', 'id', 'Ġ,', 'Ġ"', 'Activ', 'ate', '"', 'Ġ,', 'Ġ{', 'Ġ\\', 'n']
Detokenized (010): ['analytics', 'Ġ.', 'Ġtrack', 'Ġ(', 'Ġuser_id', 'Ġ,', 'Ġ"Activate"', 'Ġ,', 'Ġ{', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sublime_plugin . WindowCommand . __init__ ( self , * args , ** kwargs ) \n"
Original    (015): ['sublime_plugin', '.', 'WindowCommand', '.', '__init__', '(', 'self', ',', '*', 'args', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (026): ['<s>', 'sub', 'lime', '_', 'plugin', 'Ġ.', 'ĠWindow', 'Command', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['sub', 'lime', '_', 'plugin', 'Ġ.', 'ĠWindow', 'Command', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sublime_plugin', 'Ġ.', 'ĠWindowCommand', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : ""show_response" , { "title" : title , "text" : text } ) \n"
Original    (013): ['"show_response"', ',', '{', '"title"', ':', 'title', ',', '"text"', ':', 'text', '}', ')', '\\n']
Tokenized   (024): ['<s>', '"', 'show', '_', 'response', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'title', '"', 'Ġ:', 'Ġtitle', 'Ġ,', 'Ġ"', 'text', '"', 'Ġ:', 'Ġtext', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'show', '_', 'response', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'title', '"', 'Ġ:', 'Ġtitle', 'Ġ,', 'Ġ"', 'text', '"', 'Ġ:', 'Ġtext', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['"show_response"', 'Ġ,', 'Ġ{', 'Ġ"title"', 'Ġ:', 'Ġtitle', 'Ġ,', 'Ġ"text"', 'Ġ:', 'Ġtext', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ensure_ascii = False \n"
Original    (004): ['ensure_ascii', '=', 'False', '\\n']
Tokenized   (012): ['<s>', 'ens', 'ure', '_', 'as', 'ci', 'i', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['ens', 'ure', '_', 'as', 'ci', 'i', 'Ġ=', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (004): ['ensure_ascii', 'Ġ=', 'ĠFalse', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "syntax = "Packages/JavaScript/JSON.tmLanguage" ) \n"
Original    (005): ['syntax', '=', '"Packages/JavaScript/JSON.tmLanguage"', ')', '\\n']
Tokenized   (020): ['<s>', 'sy', 'ntax', 'Ġ=', 'Ġ"', 'Pack', 'ages', '/', 'Java', 'Script', '/', 'JSON', '.', 'tm', 'Language', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['sy', 'ntax', 'Ġ=', 'Ġ"', 'Pack', 'ages', '/', 'Java', 'Script', '/', 'JSON', '.', 'tm', 'Language', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['syntax', 'Ġ=', 'Ġ"Packages/JavaScript/JSON.tmLanguage"', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "scroll = self . settings . scroll_size \n"
Original    (008): ['scroll', '=', 'self', '.', 'settings', '.', 'scroll_size', '\\n']
Tokenized   (013): ['<s>', 'scroll', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsettings', 'Ġ.', 'Ġscroll', '_', 'size', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['scroll', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsettings', 'Ġ.', 'Ġscroll', '_', 'size', 'Ġ\\', 'n']
Detokenized (008): ['scroll', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsettings', 'Ġ.', 'Ġscroll_size', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""show_panel" , { "panel" : "output.elasticsearch" } ) \n"
Original    (009): ['"show_panel"', ',', '{', '"panel"', ':', '"output.elasticsearch"', '}', ')', '\\n']
Tokenized   (024): ['<s>', '"', 'show', '_', 'panel', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'panel', '"', 'Ġ:', 'Ġ"', 'output', '.', 'el', 'astic', 'search', '"', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['"', 'show', '_', 'panel', '"', 'Ġ,', 'Ġ{', 'Ġ"', 'panel', '"', 'Ġ:', 'Ġ"', 'output', '.', 'el', 'astic', 'search', '"', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['"show_panel"', 'Ġ,', 'Ġ{', 'Ġ"panel"', 'Ġ:', 'Ġ"output.elasticsearch"', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "panel . set_read_only ( True ) \n"
Original    (007): ['panel', '.', 'set_read_only', '(', 'True', ')', '\\n']
Tokenized   (014): ['<s>', 'panel', 'Ġ.', 'Ġset', '_', 'read', '_', 'only', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['panel', 'Ġ.', 'Ġset', '_', 'read', '_', 'only', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['panel', 'Ġ.', 'Ġset_read_only', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "400 : RequestError , \n"
Original    (005): ['400', ':', 'RequestError', ',', '\\n']
Tokenized   (009): ['<s>', '400', 'Ġ:', 'ĠRequest', 'Error', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['400', 'Ġ:', 'ĠRequest', 'Error', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['400', 'Ġ:', 'ĠRequestError', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "TestConfigFileSource . ConcreteConfigFileSource ) \n"
Original    (005): ['TestConfigFileSource', '.', 'ConcreteConfigFileSource', ')', '\\n']
Tokenized   (015): ['<s>', 'Test', 'Config', 'File', 'Source', 'Ġ.', 'ĠCon', 'crete', 'Config', 'File', 'Source', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Test', 'Config', 'File', 'Source', 'Ġ.', 'ĠCon', 'crete', 'Config', 'File', 'Source', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['TestConfigFileSource', 'Ġ.', 'ĠConcreteConfigFileSource', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "ReferenceReachabilityTester . TwoWayScopeReferenceAttacher . attach ( self . _scope_tree ) \n"
Original    (011): ['ReferenceReachabilityTester', '.', 'TwoWayScopeReferenceAttacher', '.', 'attach', '(', 'self', '.', '_scope_tree', ')', '\\n']
Tokenized   (027): ['<s>', 'Reference', 'Re', 'ach', 'ability', 'T', 'ester', 'Ġ.', 'ĠTwo', 'Way', 'Scope', 'Reference', 'Att', 'acher', 'Ġ.', 'Ġattach', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'scope', '_', 'tree', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['Reference', 'Re', 'ach', 'ability', 'T', 'ester', 'Ġ.', 'ĠTwo', 'Way', 'Scope', 'Reference', 'Att', 'acher', 'Ġ.', 'Ġattach', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'scope', '_', 'tree', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['ReferenceReachabilityTester', 'Ġ.', 'ĠTwoWayScopeReferenceAttacher', 'Ġ.', 'Ġattach', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_scope_tree', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "declaring_id_node [ REFERECED_FLAG ] = True \n"
Original    (007): ['declaring_id_node', '[', 'REFERECED_FLAG', ']', '=', 'True', '\\n']
Tokenized   (020): ['<s>', 'decl', 'aring', '_', 'id', '_', 'node', 'Ġ[', 'ĠRE', 'FER', 'EC', 'ED', '_', 'FLAG', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['decl', 'aring', '_', 'id', '_', 'node', 'Ġ[', 'ĠRE', 'FER', 'EC', 'ED', '_', 'FLAG', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n']
Detokenized (007): ['declaring_id_node', 'Ġ[', 'ĠREFERECED_FLAG', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "node_type = NodeType ( node [ ] ) \n"
Original    (009): ['node_type', '=', 'NodeType', '(', 'node', '[', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'node', '_', 'type', 'Ġ=', 'ĠNode', 'Type', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['node', '_', 'type', 'Ġ=', 'ĠNode', 'Type', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['node_type', 'Ġ=', 'ĠNodeType', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "is_set_cmd = excmd_node [ ] [ ] . get ( ) in SetCommandFamily \n"
Original    (014): ['is_set_cmd', '=', 'excmd_node', '[', ']', '[', ']', '.', 'get', '(', ')', 'in', 'SetCommandFamily', '\\n']
Tokenized   (026): ['<s>', 'is', '_', 'set', '_', 'cmd', 'Ġ=', 'Ġexc', 'md', '_', 'node', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġin', 'ĠSet', 'Command', 'Family', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['is', '_', 'set', '_', 'cmd', 'Ġ=', 'Ġexc', 'md', '_', 'node', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġin', 'ĠSet', 'Command', 'Family', 'Ġ\\', 'n']
Detokenized (014): ['is_set_cmd', 'Ġ=', 'Ġexcmd_node', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġin', 'ĠSetCommandFamily', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "option_name = re . match ( , option_expr ) . group ( 0 ) \n"
Original    (015): ['option_name', '=', 're', '.', 'match', '(', ',', 'option_expr', ')', '.', 'group', '(', '0', ')', '\\n']
Tokenized   (022): ['<s>', 'option', '_', 'name', 'Ġ=', 'Ġre', 'Ġ.', 'Ġmatch', 'Ġ(', 'Ġ,', 'Ġoption', '_', 'expr', 'Ġ)', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['option', '_', 'name', 'Ġ=', 'Ġre', 'Ġ.', 'Ġmatch', 'Ġ(', 'Ġ,', 'Ġoption', '_', 'expr', 'Ġ)', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['option_name', 'Ġ=', 'Ġre', 'Ġ.', 'Ġmatch', 'Ġ(', 'Ġ,', 'Ġoption_expr', 'Ġ)', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "is_valid = option_name not in AbbreviationsIncludingInvertPrefix \n"
Original    (007): ['is_valid', '=', 'option_name', 'not', 'in', 'AbbreviationsIncludingInvertPrefix', '\\n']
Tokenized   (023): ['<s>', 'is', '_', 'valid', 'Ġ=', 'Ġoption', '_', 'name', 'Ġnot', 'Ġin', 'ĠAb', 'bre', 'vi', 'ations', 'In', 'cluding', 'In', 'vert', 'Pref', 'ix', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['is', '_', 'valid', 'Ġ=', 'Ġoption', '_', 'name', 'Ġnot', 'Ġin', 'ĠAb', 'bre', 'vi', 'ations', 'In', 'cluding', 'In', 'vert', 'Pref', 'ix', 'Ġ\\', 'n']
Detokenized (007): ['is_valid', 'Ġ=', 'Ġoption_name', 'Ġnot', 'Ġin', 'ĠAbbreviationsIncludingInvertPrefix', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "stderr . setFormatter ( logging . Formatter ( \n"
Original    (009): ['stderr', '.', 'setFormatter', '(', 'logging', '.', 'Formatter', '(', '\\n']
Tokenized   (017): ['<s>', 'st', 'der', 'r', 'Ġ.', 'Ġset', 'Form', 'atter', 'Ġ(', 'Ġlogging', 'Ġ.', 'ĠForm', 'atter', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['st', 'der', 'r', 'Ġ.', 'Ġset', 'Form', 'atter', 'Ġ(', 'Ġlogging', 'Ġ.', 'ĠForm', 'atter', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['stderr', 'Ġ.', 'ĠsetFormatter', 'Ġ(', 'Ġlogging', 'Ġ.', 'ĠFormatter', 'Ġ(', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "level = level if level else os . environ . get ( , ) \n"
Original    (015): ['level', '=', 'level', 'if', 'level', 'else', 'os', '.', 'environ', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'level', 'Ġ=', 'Ġlevel', 'Ġif', 'Ġlevel', 'Ġelse', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['level', 'Ġ=', 'Ġlevel', 'Ġif', 'Ġlevel', 'Ġelse', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['level', 'Ġ=', 'Ġlevel', 'Ġif', 'Ġlevel', 'Ġelse', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "g_s = g0 * g_c * g_R * g_D * g_T * g_M \n"
Original    (014): ['g_s', '=', 'g0', '*', 'g_c', '*', 'g_R', '*', 'g_D', '*', 'g_T', '*', 'g_M', '\\n']
Tokenized   (030): ['<s>', 'g', '_', 's', 'Ġ=', 'Ġg', '0', 'Ġ*', 'Ġg', '_', 'c', 'Ġ*', 'Ġg', '_', 'R', 'Ġ*', 'Ġg', '_', 'D', 'Ġ*', 'Ġg', '_', 'T', 'Ġ*', 'Ġg', '_', 'M', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['g', '_', 's', 'Ġ=', 'Ġg', '0', 'Ġ*', 'Ġg', '_', 'c', 'Ġ*', 'Ġg', '_', 'R', 'Ġ*', 'Ġg', '_', 'D', 'Ġ*', 'Ġg', '_', 'T', 'Ġ*', 'Ġg', '_', 'M', 'Ġ\\', 'n']
Detokenized (014): ['g_s', 'Ġ=', 'Ġg0', 'Ġ*', 'Ġg_c', 'Ġ*', 'Ġg_R', 'Ġ*', 'Ġg_D', 'Ġ*', 'Ġg_T', 'Ġ*', 'Ġg_M', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "g_T = ( ( TK - TL ) * ( TH - TK ) ** alpha_T ) / ( ( T0 - TL ) * ( TH - T0 ) ** alpha_T ) \n"
Original    (034): ['g_T', '=', '(', '(', 'TK', '-', 'TL', ')', '*', '(', 'TH', '-', 'TK', ')', '**', 'alpha_T', ')', '/', '(', '(', 'T0', '-', 'TL', ')', '*', '(', 'TH', '-', 'T0', ')', '**', 'alpha_T', ')', '\\n']
Tokenized   (047): ['<s>', 'g', '_', 'T', 'Ġ=', 'Ġ(', 'Ġ(', 'ĠT', 'K', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', 'K', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġ(', 'ĠT', '0', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', '0', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (045): ['g', '_', 'T', 'Ġ=', 'Ġ(', 'Ġ(', 'ĠT', 'K', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', 'K', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġ(', 'ĠT', '0', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT', '0', 'Ġ)', 'Ġ**', 'Ġalpha', '_', 'T', 'Ġ)', 'Ġ\\', 'n']
Detokenized (034): ['g_T', 'Ġ=', 'Ġ(', 'Ġ(', 'ĠTK', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠTK', 'Ġ)', 'Ġ**', 'Ġalpha_T', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġ(', 'ĠT0', 'Ġ-', 'ĠTL', 'Ġ)', 'Ġ*', 'Ġ(', 'ĠTH', 'Ġ-', 'ĠT0', 'Ġ)', 'Ġ**', 'Ġalpha_T', 'Ġ)', 'Ġ\\n']
Counter: 45
===================================================================
Hidden states:  (13, 34, 768)
# Extracted words:  34
Sentence         : "r_a = AeroReist ( um , zm , z0 , d ) \n"
Original    (013): ['r_a', '=', 'AeroReist', '(', 'um', ',', 'zm', ',', 'z0', ',', 'd', ')', '\\n']
Tokenized   (022): ['<s>', 'r', '_', 'a', 'Ġ=', 'ĠAero', 'Re', 'ist', 'Ġ(', 'Ġum', 'Ġ,', 'Ġz', 'm', 'Ġ,', 'Ġz', '0', 'Ġ,', 'Ġd', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['r', '_', 'a', 'Ġ=', 'ĠAero', 'Re', 'ist', 'Ġ(', 'Ġum', 'Ġ,', 'Ġz', 'm', 'Ġ,', 'Ġz', '0', 'Ġ,', 'Ġd', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['r_a', 'Ġ=', 'ĠAeroReist', 'Ġ(', 'Ġum', 'Ġ,', 'Ġzm', 'Ġ,', 'Ġz0', 'Ġ,', 'Ġd', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "r_s = SurfResist ( g0 , S , D , Tc , SM , SM0 ) \n"
Original    (017): ['r_s', '=', 'SurfResist', '(', 'g0', ',', 'S', ',', 'D', ',', 'Tc', ',', 'SM', ',', 'SM0', ')', '\\n']
Tokenized   (027): ['<s>', 'r', '_', 's', 'Ġ=', 'ĠSurf', 'Res', 'ist', 'Ġ(', 'Ġg', '0', 'Ġ,', 'ĠS', 'Ġ,', 'ĠD', 'Ġ,', 'ĠT', 'c', 'Ġ,', 'ĠSM', 'Ġ,', 'ĠSM', '0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['r', '_', 's', 'Ġ=', 'ĠSurf', 'Res', 'ist', 'Ġ(', 'Ġg', '0', 'Ġ,', 'ĠS', 'Ġ,', 'ĠD', 'Ġ,', 'ĠT', 'c', 'Ġ,', 'ĠSM', 'Ġ,', 'ĠSM', '0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['r_s', 'Ġ=', 'ĠSurfResist', 'Ġ(', 'Ġg0', 'Ġ,', 'ĠS', 'Ġ,', 'ĠD', 'Ġ,', 'ĠTc', 'Ġ,', 'ĠSM', 'Ġ,', 'ĠSM0', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "LE = ( delta * Rn + ( rho_a * cP * D ) / r_a ) / ( delta + gamma * ( 1.0 + r_s / r_a ) ) \n"
Original    (032): ['LE', '=', '(', 'delta', '*', 'Rn', '+', '(', 'rho_a', '*', 'cP', '*', 'D', ')', '/', 'r_a', ')', '/', '(', 'delta', '+', 'gamma', '*', '(', '1.0', '+', 'r_s', '/', 'r_a', ')', ')', '\\n']
Tokenized   (048): ['<s>', 'LE', 'Ġ=', 'Ġ(', 'Ġdelta', 'Ġ*', 'ĠR', 'n', 'Ġ+', 'Ġ(', 'Ġr', 'ho', '_', 'a', 'Ġ*', 'Ġc', 'P', 'Ġ*', 'ĠD', 'Ġ)', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġdelta', 'Ġ+', 'Ġgamma', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ+', 'Ġr', '_', 's', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['LE', 'Ġ=', 'Ġ(', 'Ġdelta', 'Ġ*', 'ĠR', 'n', 'Ġ+', 'Ġ(', 'Ġr', 'ho', '_', 'a', 'Ġ*', 'Ġc', 'P', 'Ġ*', 'ĠD', 'Ġ)', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġdelta', 'Ġ+', 'Ġgamma', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ+', 'Ġr', '_', 's', 'Ġ/', 'Ġr', '_', 'a', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (032): ['LE', 'Ġ=', 'Ġ(', 'Ġdelta', 'Ġ*', 'ĠRn', 'Ġ+', 'Ġ(', 'Ġrho_a', 'Ġ*', 'ĠcP', 'Ġ*', 'ĠD', 'Ġ)', 'Ġ/', 'Ġr_a', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġdelta', 'Ġ+', 'Ġgamma', 'Ġ*', 'Ġ(', 'Ġ1.0', 'Ġ+', 'Ġr_s', 'Ġ/', 'Ġr_a', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "glClearColor ( * background_color ) \n"
Original    (006): ['glClearColor', '(', '*', 'background_color', ')', '\\n']
Tokenized   (013): ['<s>', 'gl', 'Clear', 'Color', 'Ġ(', 'Ġ*', 'Ġbackground', '_', 'color', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['gl', 'Clear', 'Color', 'Ġ(', 'Ġ*', 'Ġbackground', '_', 'color', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['glClearColor', 'Ġ(', 'Ġ*', 'Ġbackground_color', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "glScissor ( x , y , width , height ) \n"
Original    (011): ['glScissor', '(', 'x', ',', 'y', ',', 'width', ',', 'height', ')', '\\n']
Tokenized   (017): ['<s>', 'gl', 'Sc', 'iss', 'or', 'Ġ(', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġwidth', 'Ġ,', 'Ġheight', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['gl', 'Sc', 'iss', 'or', 'Ġ(', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġwidth', 'Ġ,', 'Ġheight', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['glScissor', 'Ġ(', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġwidth', 'Ġ,', 'Ġheight', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "glOrtho ( x , x + width , y , y + height , - 1 , 1 ) \n"
Original    (020): ['glOrtho', '(', 'x', ',', 'x', '+', 'width', ',', 'y', ',', 'y', '+', 'height', ',', '-', '1', ',', '1', ')', '\\n']
Tokenized   (026): ['<s>', 'gl', 'Or', 'th', 'o', 'Ġ(', 'Ġx', 'Ġ,', 'Ġx', 'Ġ+', 'Ġwidth', 'Ġ,', 'Ġy', 'Ġ,', 'Ġy', 'Ġ+', 'Ġheight', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['gl', 'Or', 'th', 'o', 'Ġ(', 'Ġx', 'Ġ,', 'Ġx', 'Ġ+', 'Ġwidth', 'Ġ,', 'Ġy', 'Ġ,', 'Ġy', 'Ġ+', 'Ġheight', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['glOrtho', 'Ġ(', 'Ġx', 'Ġ,', 'Ġx', 'Ġ+', 'Ġwidth', 'Ġ,', 'Ġy', 'Ġ,', 'Ġy', 'Ġ+', 'Ġheight', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "glNormal3f ( 0 , 1. , 0 ) \n"
Original    (009): ['glNormal3f', '(', '0', ',', '1.', ',', '0', ')', '\\n']
Tokenized   (016): ['<s>', 'gl', 'Normal', '3', 'f', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1', '.', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['gl', 'Normal', '3', 'f', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1', '.', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['glNormal3f', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ1.', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "glVertex ( n , n , p ) \n"
Original    (009): ['glVertex', '(', 'n', ',', 'n', ',', 'p', ')', '\\n']
Tokenized   (014): ['<s>', 'gl', 'Ver', 'tex', 'Ġ(', 'Ġn', 'Ġ,', 'Ġn', 'Ġ,', 'Ġp', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['gl', 'Ver', 'tex', 'Ġ(', 'Ġn', 'Ġ,', 'Ġn', 'Ġ,', 'Ġp', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['glVertex', 'Ġ(', 'Ġn', 'Ġ,', 'Ġn', 'Ġ,', 'Ġp', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "companies = [ path for path in paths \n"
Original    (009): ['companies', '=', '[', 'path', 'for', 'path', 'in', 'paths', '\\n']
Tokenized   (013): ['<s>', 'compan', 'ies', 'Ġ=', 'Ġ[', 'Ġpath', 'Ġfor', 'Ġpath', 'Ġin', 'Ġpaths', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['compan', 'ies', 'Ġ=', 'Ġ[', 'Ġpath', 'Ġfor', 'Ġpath', 'Ġin', 'Ġpaths', 'Ġ\\', 'n']
Detokenized (009): ['companies', 'Ġ=', 'Ġ[', 'Ġpath', 'Ġfor', 'Ġpath', 'Ġin', 'Ġpaths', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "and os . path . exists ( os . path . join ( folder , path , ) ) ] \n"
Original    (021): ['and', 'os', '.', 'path', '.', 'exists', '(', 'os', '.', 'path', '.', 'join', '(', 'folder', ',', 'path', ',', ')', ')', ']', '\\n']
Tokenized   (024): ['<s>', 'and', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexists', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġfolder', 'Ġ,', 'Ġpath', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['and', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexists', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġfolder', 'Ġ,', 'Ġpath', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['and', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexists', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġfolder', 'Ġ,', 'Ġpath', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "folder = os . path . join ( root_folder , , , ) \n"
Original    (014): ['folder', '=', 'os', '.', 'path', '.', 'join', '(', 'root_folder', ',', ',', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'folder', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', '_', 'folder', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['folder', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', '_', 'folder', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['folder', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot_folder', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "scripts = [ , \n"
Original    (005): ['scripts', '=', '[', ',', '\\n']
Tokenized   (008): ['<s>', 'scripts', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['scripts', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ\\', 'n']
Detokenized (005): ['scripts', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "pro2 . predict ( ) from collections import OrderedDict \n"
Original    (010): ['pro2', '.', 'predict', '(', ')', 'from', 'collections', 'import', 'OrderedDict', '\\n']
Tokenized   (017): ['<s>', 'pro', '2', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġcollections', 'Ġimport', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['pro', '2', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġcollections', 'Ġimport', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ\\', 'n']
Detokenized (010): ['pro2', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġcollections', 'Ġimport', 'ĠOrderedDict', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : ""dimensions." % ( self . __class__ . __name__ , shape ) ) \n"
Original    (013): ['"dimensions."', '%', '(', 'self', '.', '__class__', '.', '__name__', ',', 'shape', ')', ')', '\\n']
Tokenized   (023): ['<s>', '"', 'dim', 'ensions', '."', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġshape', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', 'dim', 'ensions', '."', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġshape', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['"dimensions."', 'Ġ%', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġ,', 'Ġshape', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "only = set ( tag for tag , value in tags . items ( ) if value ) \n"
Original    (019): ['only', '=', 'set', '(', 'tag', 'for', 'tag', ',', 'value', 'in', 'tags', '.', 'items', '(', ')', 'if', 'value', ')', '\\n']
Tokenized   (022): ['<s>', 'only', 'Ġ=', 'Ġset', 'Ġ(', 'Ġtag', 'Ġfor', 'Ġtag', 'Ġ,', 'Ġvalue', 'Ġin', 'Ġtags', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['only', 'Ġ=', 'Ġset', 'Ġ(', 'Ġtag', 'Ġfor', 'Ġtag', 'Ġ,', 'Ġvalue', 'Ġin', 'Ġtags', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['only', 'Ġ=', 'Ġset', 'Ġ(', 'Ġtag', 'Ġfor', 'Ġtag', 'Ġ,', 'Ġvalue', 'Ġin', 'Ġtags', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġvalue', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "crop1 = [ None , , , ] \n"
Original    (009): ['crop1', '=', '[', 'None', ',', ',', ',', ']', '\\n']
Tokenized   (013): ['<s>', 'crop', '1', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['crop', '1', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['crop1', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "outs = [ o . eval ( ) for o in outs ] \n"
Original    (014): ['outs', '=', '[', 'o', '.', 'eval', '(', ')', 'for', 'o', 'in', 'outs', ']', '\\n']
Tokenized   (017): ['<s>', 'outs', 'Ġ=', 'Ġ[', 'Ġo', 'Ġ.', 'Ġeval', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġo', 'Ġin', 'Ġouts', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['outs', 'Ġ=', 'Ġ[', 'Ġo', 'Ġ.', 'Ġeval', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġo', 'Ġin', 'Ġouts', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['outs', 'Ġ=', 'Ġ[', 'Ġo', 'Ġ.', 'Ġeval', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġo', 'Ġin', 'Ġouts', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "crop_test ( crop_x , [ x0 , x1 , x2 , x0 , x1 , x2 ] , \n"
Original    (019): ['crop_test', '(', 'crop_x', ',', '[', 'x0', ',', 'x1', ',', 'x2', ',', 'x0', ',', 'x1', ',', 'x2', ']', ',', '\\n']
Tokenized   (032): ['<s>', 'crop', '_', 'test', 'Ġ(', 'Ġcrop', '_', 'x', 'Ġ,', 'Ġ[', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['crop', '_', 'test', 'Ġ(', 'Ġcrop', '_', 'x', 'Ġ,', 'Ġ[', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġx', '1', 'Ġ,', 'Ġx', '2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['crop_test', 'Ġ(', 'Ġcrop_x', 'Ġ,', 'Ġ[', 'Ġx0', 'Ġ,', 'Ġx1', 'Ġ,', 'Ġx2', 'Ġ,', 'Ġx0', 'Ġ,', 'Ġx1', 'Ġ,', 'Ġx2', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "cropping = [ ] * 2 ) \n"
Original    (008): ['cropping', '=', '[', ']', '*', '2', ')', '\\n']
Tokenized   (012): ['<s>', 'cro', 'pping', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ*', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['cro', 'pping', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ*', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['cropping', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ*', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "desired_result_0 = numpy . concatenate ( [ x0 [ : , : 2 ] , x1 [ : , : 2 ] ] , axis = 0 ) \n"
Original    (029): ['desired_result_0', '=', 'numpy', '.', 'concatenate', '(', '[', 'x0', '[', ':', ',', ':', '2', ']', ',', 'x1', '[', ':', ',', ':', '2', ']', ']', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (042): ['<s>', 'des', 'ired', '_', 'result', '_', '0', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['des', 'ired', '_', 'result', '_', '0', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (029): ['desired_result_0', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġconcatenate', 'Ġ(', 'Ġ[', 'Ġx0', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġx1', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "desired_result_1 = numpy . concatenate ( [ x0 [ : 4 , : ] , x1 [ : 4 , : ] ] , axis = 1 ) \n"
Original    (029): ['desired_result_1', '=', 'numpy', '.', 'concatenate', '(', '[', 'x0', '[', ':', '4', ',', ':', ']', ',', 'x1', '[', ':', '4', ',', ':', ']', ']', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (042): ['<s>', 'des', 'ired', '_', 'result', '_', '1', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['des', 'ired', '_', 'result', '_', '1', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ[', 'Ġx', '0', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ,', 'Ġx', '1', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (029): ['desired_result_1', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġconcatenate', 'Ġ(', 'Ġ[', 'Ġx0', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ,', 'Ġx1', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "inputs = [ theano . shared ( a ) , \n"
Original    (011): ['inputs', '=', '[', 'theano', '.', 'shared', '(', 'a', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'input', 's', 'Ġ=', 'Ġ[', 'Ġthe', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['input', 's', 'Ġ=', 'Ġ[', 'Ġthe', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['inputs', 'Ġ=', 'Ġ[', 'Ġtheano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "theano . shared ( b ) ] \n"
Original    (008): ['theano', '.', 'shared', '(', 'b', ')', ']', '\\n']
Tokenized   (012): ['<s>', 'the', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġb', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['the', 'ano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġb', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['theano', 'Ġ.', 'Ġshared', 'Ġ(', 'Ġb', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mask = os . urandom ( 4 ) if mask else None \n"
Original    (013): ['mask', '=', 'os', '.', 'urandom', '(', '4', ')', 'if', 'mask', 'else', 'None', '\\n']
Tokenized   (017): ['<s>', 'mask', 'Ġ=', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ4', 'Ġ)', 'Ġif', 'Ġmask', 'Ġelse', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['mask', 'Ġ=', 'Ġos', 'Ġ.', 'Ġur', 'andom', 'Ġ(', 'Ġ4', 'Ġ)', 'Ġif', 'Ġmask', 'Ġelse', 'ĠNone', 'Ġ\\', 'n']
Detokenized (013): ['mask', 'Ġ=', 'Ġos', 'Ġ.', 'Ġurandom', 'Ġ(', 'Ġ4', 'Ġ)', 'Ġif', 'Ġmask', 'Ġelse', 'ĠNone', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "masking_key = mask , fin = 1 ) . build ( ) \n"
Original    (013): ['masking_key', '=', 'mask', ',', 'fin', '=', '1', ')', '.', 'build', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'mask', 'ing', '_', 'key', 'Ġ=', 'Ġmask', 'Ġ,', 'Ġfin', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mask', 'ing', '_', 'key', 'Ġ=', 'Ġmask', 'Ġ,', 'Ġfin', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['masking_key', 'Ġ=', 'Ġmask', 'Ġ,', 'Ġfin', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "fin = fin ) . build ( ) \n"
Original    (009): ['fin', '=', 'fin', ')', '.', 'build', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'fin', 'Ġ=', 'Ġfin', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['fin', 'Ġ=', 'Ġfin', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['fin', 'Ġ=', 'Ġfin', 'Ġ)', 'Ġ.', 'Ġbuild', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "flags = unpack ( , msg [ idx : idx + 4 ] ) [ 0 ] \n"
Original    (018): ['flags', '=', 'unpack', '(', ',', 'msg', '[', 'idx', ':', 'idx', '+', '4', ']', ')', '[', '0', ']', '\\n']
Tokenized   (024): ['<s>', 'flags', 'Ġ=', 'Ġun', 'pack', 'Ġ(', 'Ġ,', 'Ġmsg', 'Ġ[', 'Ġid', 'x', 'Ġ:', 'Ġid', 'x', 'Ġ+', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['flags', 'Ġ=', 'Ġun', 'pack', 'Ġ(', 'Ġ,', 'Ġmsg', 'Ġ[', 'Ġid', 'x', 'Ġ:', 'Ġid', 'x', 'Ġ+', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['flags', 'Ġ=', 'Ġunpack', 'Ġ(', 'Ġ,', 'Ġmsg', 'Ġ[', 'Ġidx', 'Ġ:', 'Ġidx', 'Ġ+', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "pdc = req . get_options ( ) [ ] \n"
Original    (010): ['pdc', '=', 'req', '.', 'get_options', '(', ')', '[', ']', '\\n']
Tokenized   (016): ['<s>', 'p', 'dc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['p', 'dc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['pdc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget_options', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "bdc = req . get_options ( ) . get ( , False ) \n"
Original    (014): ['bdc', '=', 'req', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 'False', ')', '\\n']
Tokenized   (020): ['<s>', 'bd', 'c', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['bd', 'c', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['bdc', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget_options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "decoded_path = urllib . unquote ( url . path ) [ 1 : ] \n"
Original    (015): ['decoded_path', '=', 'urllib', '.', 'unquote', '(', 'url', '.', 'path', ')', '[', '1', ':', ']', '\\n']
Tokenized   (024): ['<s>', 'dec', 'oded', '_', 'path', 'Ġ=', 'Ġur', 'll', 'ib', 'Ġ.', 'Ġun', 'quote', 'Ġ(', 'Ġurl', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['dec', 'oded', '_', 'path', 'Ġ=', 'Ġur', 'll', 'ib', 'Ġ.', 'Ġun', 'quote', 'Ġ(', 'Ġurl', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['decoded_path', 'Ġ=', 'Ġurllib', 'Ġ.', 'Ġunquote', 'Ġ(', 'Ġurl', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rules = . join ( req . requires ( ) ) . strip ( ) \n"
Original    (016): ['rules', '=', '.', 'join', '(', 'req', '.', 'requires', '(', ')', ')', '.', 'strip', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'rules', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġreq', 'Ġ.', 'Ġrequires', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rules', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġreq', 'Ġ.', 'Ġrequires', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['rules', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġreq', 'Ġ.', 'Ġrequires', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "domain = req . get_options ( ) . get ( , req . auth_name ( ) ) \n"
Original    (018): ['domain', '=', 'req', '.', 'get_options', '(', ')', '.', 'get', '(', ',', 'req', '.', 'auth_name', '(', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'domain', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġreq', 'Ġ.', 'Ġauth', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['domain', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget', '_', 'options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġreq', 'Ġ.', 'Ġauth', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['domain', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġget_options', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġreq', 'Ġ.', 'Ġauth_name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "auth_headers = req . headers_in . get ( , [ ] ) \n"
Original    (013): ['auth_headers', '=', 'req', '.', 'headers_in', '.', 'get', '(', ',', '[', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'auth', '_', 'headers', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġheaders', '_', 'in', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['auth', '_', 'headers', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġheaders', '_', 'in', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['auth_headers', 'Ġ=', 'Ġreq', 'Ġ.', 'Ġheaders_in', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "set_remote_user ( req , ah_data [ 1 ] , domain ) \n"
Original    (012): ['set_remote_user', '(', 'req', ',', 'ah_data', '[', '1', ']', ',', 'domain', ')', '\\n']
Tokenized   (021): ['<s>', 'set', '_', 'remote', '_', 'user', 'Ġ(', 'Ġreq', 'Ġ,', 'Ġah', '_', 'data', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġdomain', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['set', '_', 'remote', '_', 'user', 'Ġ(', 'Ġreq', 'Ġ,', 'Ġah', '_', 'data', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġdomain', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['set_remote_user', 'Ġ(', 'Ġreq', 'Ġ,', 'Ġah_data', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġdomain', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "dict = json . loads ( request . data . decode ( ) ) \n"
Original    (015): ['dict', '=', 'json', '.', 'loads', '(', 'request', '.', 'data', '.', 'decode', '(', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'dict', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġdata', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['dict', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġdata', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['dict', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġrequest', 'Ġ.', 'Ġdata', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rv = self . app . delete ( . format ( id ) ) \n"
Original    (015): ['rv', '=', 'self', '.', 'app', '.', 'delete', '(', '.', 'format', '(', 'id', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'r', 'v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġapp', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġid', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['r', 'v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġapp', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġid', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['rv', 'Ġ=', 'Ġself', 'Ġ.', 'Ġapp', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġid', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "configure_logging ( "index_pages_logging.config" , "index_pages.log" ) \n"
Original    (007): ['configure_logging', '(', '"index_pages_logging.config"', ',', '"index_pages.log"', ')', '\\n']
Tokenized   (029): ['<s>', 'config', 'ure', '_', 'log', 'ging', 'Ġ(', 'Ġ"', 'index', '_', 'pages', '_', 'log', 'ging', '.', 'config', '"', 'Ġ,', 'Ġ"', 'index', '_', 'pages', '.', 'log', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['config', 'ure', '_', 'log', 'ging', 'Ġ(', 'Ġ"', 'index', '_', 'pages', '_', 'log', 'ging', '.', 'config', '"', 'Ġ,', 'Ġ"', 'index', '_', 'pages', '.', 'log', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['configure_logging', 'Ġ(', 'Ġ"index_pages_logging.config"', 'Ġ,', 'Ġ"index_pages.log"', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ocr_file = join ( dir , ) \n"
Original    (008): ['ocr_file', '=', 'join', '(', 'dir', ',', ')', '\\n']
Tokenized   (013): ['<s>', 'ocr', '_', 'file', 'Ġ=', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['ocr', '_', 'file', 'Ġ=', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['ocr_file', 'Ġ=', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "expected_text = { "eng" : file ( join ( dir , ) ) . read ( ) . decode ( ) } \n"
Original    (023): ['expected_text', '=', '{', '"eng"', ':', 'file', '(', 'join', '(', 'dir', ',', ')', ')', '.', 'read', '(', ')', '.', 'decode', '(', ')', '}', '\\n']
Tokenized   (030): ['<s>', 'expected', '_', 'text', 'Ġ=', 'Ġ{', 'Ġ"', 'eng', '"', 'Ġ:', 'Ġfile', 'Ġ(', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['expected', '_', 'text', 'Ġ=', 'Ġ{', 'Ġ"', 'eng', '"', 'Ġ:', 'Ġfile', 'Ġ(', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (023): ['expected_text', 'Ġ=', 'Ġ{', 'Ġ"eng"', 'Ġ:', 'Ġfile', 'Ġ(', 'Ġjoin', 'Ġ(', 'Ġdir', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "tuples . append ( ( os . path . join ( root , pair [ 0 ] ) , np . int32 ( pair [ 1 ] ) ) ) \n"
Original    (031): ['tuples', '.', 'append', '(', '(', 'os', '.', 'path', '.', 'join', '(', 'root', ',', 'pair', '[', '0', ']', ')', ',', 'np', '.', 'int32', '(', 'pair', '[', '1', ']', ')', ')', ')', '\\n']
Tokenized   (036): ['<s>', 'tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġpair', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġint', '32', 'Ġ(', 'Ġpair', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġpair', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġint', '32', 'Ġ(', 'Ġpair', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (031): ['tuples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġroot', 'Ġ,', 'Ġpair', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġint32', 'Ġ(', 'Ġpair', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "val_list = load_image_list ( args . val , args . root ) \n"
Original    (013): ['val_list', '=', 'load_image_list', '(', 'args', '.', 'val', ',', 'args', '.', 'root', ')', '\\n']
Tokenized   (022): ['<s>', 'val', '_', 'list', 'Ġ=', 'Ġload', '_', 'image', '_', 'list', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġval', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġroot', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['val', '_', 'list', 'Ġ=', 'Ġload', '_', 'image', '_', 'list', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġval', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġroot', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['val_list', 'Ġ=', 'Ġload_image_list', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġval', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġroot', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "mean_image = pickle . load ( open ( args . mean , ) ) \n"
Original    (015): ['mean_image', '=', 'pickle', '.', 'load', '(', 'open', '(', 'args', '.', 'mean', ',', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'mean', '_', 'image', 'Ġ=', 'Ġpick', 'le', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġmean', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['mean', '_', 'image', 'Ġ=', 'Ġpick', 'le', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġmean', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['mean_image', 'Ġ=', 'Ġpickle', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġmean', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "cropwidth = 256 - model . insize \n"
Original    (008): ['cropwidth', '=', '256', '-', 'model', '.', 'insize', '\\n']
Tokenized   (013): ['<s>', 'crop', 'width', 'Ġ=', 'Ġ256', 'Ġ-', 'Ġmodel', 'Ġ.', 'Ġins', 'ize', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['crop', 'width', 'Ġ=', 'Ġ256', 'Ġ-', 'Ġmodel', 'Ġ.', 'Ġins', 'ize', 'Ġ\\', 'n']
Detokenized (008): ['cropwidth', 'Ġ=', 'Ġ256', 'Ġ-', 'Ġmodel', 'Ġ.', 'Ġinsize', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "left = random . randint ( 0 , cropwidth - 1 ) \n"
Original    (013): ['left', '=', 'random', '.', 'randint', '(', '0', ',', 'cropwidth', '-', '1', ')', '\\n']
Tokenized   (018): ['<s>', 'left', 'Ġ=', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġcrop', 'width', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['left', 'Ġ=', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġcrop', 'width', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['left', 'Ġ=', 'Ġrandom', 'Ġ.', 'Ġrandint', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġcropwidth', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "image /= 255 \n"
Original    (004): ['image', '/=', '255', '\\n']
Tokenized   (008): ['<s>', 'image', 'Ġ/', '=', 'Ġ255', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['image', 'Ġ/', '=', 'Ġ255', 'Ġ\\', 'n']
Detokenized (004): ['image', 'Ġ/=', 'Ġ255', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "val_batch_pool = [ None ] * args . val_batchsize \n"
Original    (010): ['val_batch_pool', '=', '[', 'None', ']', '*', 'args', '.', 'val_batchsize', '\\n']
Tokenized   (020): ['<s>', 'val', '_', 'batch', '_', 'pool', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['val', '_', 'batch', '_', 'pool', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ\\', 'n']
Detokenized (010): ['val_batch_pool', 'Ġ=', 'Ġ[', 'ĠNone', 'Ġ]', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval_batchsize', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "perm = np . random . permutation ( len ( train_list ) ) \n"
Original    (014): ['perm', '=', 'np', '.', 'random', '.', 'permutation', '(', 'len', '(', 'train_list', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'perm', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġperm', 'utation', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġtrain', '_', 'list', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['perm', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġperm', 'utation', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġtrain', '_', 'list', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['perm', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġpermutation', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġtrain_list', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "batch_pool [ i ] = pool . apply_async ( read_image , ( path , False , True ) ) \n"
Original    (020): ['batch_pool', '[', 'i', ']', '=', 'pool', '.', 'apply_async', '(', 'read_image', ',', '(', 'path', ',', 'False', ',', 'True', ')', ')', '\\n']
Tokenized   (030): ['<s>', 'batch', '_', 'pool', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġpool', 'Ġ.', 'Ġapply', '_', 'as', 'ync', 'Ġ(', 'Ġread', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠFalse', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['batch', '_', 'pool', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġpool', 'Ġ.', 'Ġapply', '_', 'as', 'ync', 'Ġ(', 'Ġread', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠFalse', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['batch_pool', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġpool', 'Ġ.', 'Ġapply_async', 'Ġ(', 'Ġread_image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠFalse', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "read_image , ( path , True , False ) ) \n"
Original    (011): ['read_image', ',', '(', 'path', ',', 'True', ',', 'False', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'read', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['read', '_', 'image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['read_image', 'Ġ,', 'Ġ(', 'Ġpath', 'Ġ,', 'ĠTrue', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "val_count = val_loss = val_accuracy = 0 \n"
Original    (008): ['val_count', '=', 'val_loss', '=', 'val_accuracy', '=', '0', '\\n']
Tokenized   (018): ['<s>', 'val', '_', 'count', 'Ġ=', 'Ġval', '_', 'loss', 'Ġ=', 'Ġval', '_', 'acc', 'uracy', 'Ġ=', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['val', '_', 'count', 'Ġ=', 'Ġval', '_', 'loss', 'Ġ=', 'Ġval', '_', 'acc', 'uracy', 'Ġ=', 'Ġ0', 'Ġ\\', 'n']
Detokenized (008): ['val_count', 'Ġ=', 'Ġval_loss', 'Ġ=', 'Ġval_accuracy', 'Ġ=', 'Ġ0', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "duration = time . time ( ) - val_begin_at \n"
Original    (010): ['duration', '=', 'time', '.', 'time', '(', ')', '-', 'val_begin_at', '\\n']
Tokenized   (017): ['<s>', 'duration', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġval', '_', 'begin', '_', 'at', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['duration', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġval', '_', 'begin', '_', 'at', 'Ġ\\', 'n']
Detokenized (010): ['duration', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġval_begin_at', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "mean_error = 1 - val_accuracy * args . val_batchsize / 50000 \n"
Original    (012): ['mean_error', '=', '1', '-', 'val_accuracy', '*', 'args', '.', 'val_batchsize', '/', '50000', '\\n']
Tokenized   (024): ['<s>', 'mean', '_', 'error', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġval', '_', 'acc', 'uracy', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ/', 'Ġ5', '0000', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['mean', '_', 'error', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġval', '_', 'acc', 'uracy', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval', '_', 'batch', 'size', 'Ġ/', 'Ġ5', '0000', 'Ġ\\', 'n']
Detokenized (012): ['mean_error', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġval_accuracy', 'Ġ*', 'Ġargs', 'Ġ.', 'Ġval_batchsize', 'Ġ/', 'Ġ50000', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "serializers . save_hdf5 ( args . outstate , optimizer ) \n"
Original    (011): ['serializers', '.', 'save_hdf5', '(', 'args', '.', 'outstate', ',', 'optimizer', ')', '\\n']
Tokenized   (021): ['<s>', 'serial', 'izers', 'Ġ.', 'Ġsave', '_', 'h', 'df', '5', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġout', 'state', 'Ġ,', 'Ġoptim', 'izer', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['serial', 'izers', 'Ġ.', 'Ġsave', '_', 'h', 'df', '5', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġout', 'state', 'Ġ,', 'Ġoptim', 'izer', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['serializers', 'Ġ.', 'Ġsave_hdf5', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġoutstate', 'Ġ,', 'Ġoptimizer', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "boards_name = [ slugify ( b [ ] ) for b in SETTINGS . get ( , { } ) . values ( ) ] \n"
Original    (026): ['boards_name', '=', '[', 'slugify', '(', 'b', '[', ']', ')', 'for', 'b', 'in', 'SETTINGS', '.', 'get', '(', ',', '{', '}', ')', '.', 'values', '(', ')', ']', '\\n']
Tokenized   (034): ['<s>', 'boards', '_', 'name', 'Ġ=', 'Ġ[', 'Ġslug', 'ify', 'Ġ(', 'Ġb', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġb', 'Ġin', 'ĠSET', 'T', 'INGS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['boards', '_', 'name', 'Ġ=', 'Ġ[', 'Ġslug', 'ify', 'Ġ(', 'Ġb', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġb', 'Ġin', 'ĠSET', 'T', 'INGS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (026): ['boards_name', 'Ġ=', 'Ġ[', 'Ġslugify', 'Ġ(', 'Ġb', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġb', 'Ġin', 'ĠSETTINGS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "LOGGING . info ( . format ( board_name , result ) ) \n"
Original    (013): ['LOGGING', '.', 'info', '(', '.', 'format', '(', 'board_name', ',', 'result', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'LOG', 'G', 'ING', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġboard', '_', 'name', 'Ġ,', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['LOG', 'G', 'ING', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġboard', '_', 'name', 'Ġ,', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['LOGGING', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġboard_name', 'Ġ,', 'Ġresult', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_py2 = _ver [ 0 ] == 2 \n"
Original    (009): ['is_py2', '=', '_ver', '[', '0', ']', '==', '2', '\\n']
Tokenized   (016): ['<s>', 'is', '_', 'py', '2', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['is', '_', 'py', '2', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ\\', 'n']
Detokenized (009): ['is_py2', 'Ġ=', 'Ġ_ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ==', 'Ġ2', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "is_py2_7_9_or_later = _ver [ 0 ] >= 2 and _ver [ 1 ] >= 7 and _ver [ 2 ] >= 9 \n"
Original    (023): ['is_py2_7_9_or_later', '=', '_ver', '[', '0', ']', '>=', '2', 'and', '_ver', '[', '1', ']', '>=', '7', 'and', '_ver', '[', '2', ']', '>=', '9', '\\n']
Tokenized   (040): ['<s>', 'is', '_', 'py', '2', '_', '7', '_', '9', '_', 'or', '_', 'later', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ>=', 'Ġ2', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ>=', 'Ġ7', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ>=', 'Ġ9', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['is', '_', 'py', '2', '_', '7', '_', '9', '_', 'or', '_', 'later', 'Ġ=', 'Ġ_', 'ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ>=', 'Ġ2', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ>=', 'Ġ7', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ>=', 'Ġ9', 'Ġ\\', 'n']
Detokenized (023): ['is_py2_7_9_or_later', 'Ġ=', 'Ġ_ver', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ>=', 'Ġ2', 'Ġand', 'Ġ_ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ>=', 'Ġ7', 'Ġand', 'Ġ_ver', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ>=', 'Ġ9', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "is_py3_3 = is_py3 and _ver [ 1 ] == 3 \n"
Original    (011): ['is_py3_3', '=', 'is_py3', 'and', '_ver', '[', '1', ']', '==', '3', '\\n']
Tokenized   (023): ['<s>', 'is', '_', 'py', '3', '_', '3', 'Ġ=', 'Ġis', '_', 'py', '3', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ==', 'Ġ3', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['is', '_', 'py', '3', '_', '3', 'Ġ=', 'Ġis', '_', 'py', '3', 'Ġand', 'Ġ_', 'ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ==', 'Ġ3', 'Ġ\\', 'n']
Detokenized (011): ['is_py3_3', 'Ġ=', 'Ġis_py3', 'Ġand', 'Ġ_ver', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ==', 'Ġ3', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "strategy = zlib . Z_DEFAULT_STRATEGY ) : \n"
Original    (008): ['strategy', '=', 'zlib', '.', 'Z_DEFAULT_STRATEGY', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'str', 'ategy', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'ĠZ', '_', 'DE', 'FAULT', '_', 'STR', 'ATE', 'GY', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['str', 'ategy', 'Ġ=', 'Ġz', 'lib', 'Ġ.', 'ĠZ', '_', 'DE', 'FAULT', '_', 'STR', 'ATE', 'GY', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['strategy', 'Ġ=', 'Ġzlib', 'Ġ.', 'ĠZ_DEFAULT_STRATEGY', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "secure = self . secure \n"
Original    (006): ['secure', '=', 'self', '.', 'secure', '\\n']
Tokenized   (009): ['<s>', 'secure', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsecure', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['secure', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsecure', 'Ġ\\', 'n']
Detokenized (006): ['secure', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsecure', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "e . huffman_coder = HuffmanEncoder ( REQUEST_CODES , REQUEST_CODES_LENGTH ) \n"
Original    (011): ['e', '.', 'huffman_coder', '=', 'HuffmanEncoder', '(', 'REQUEST_CODES', ',', 'REQUEST_CODES_LENGTH', ')', '\\n']
Tokenized   (035): ['<s>', 'e', 'Ġ.', 'Ġh', 'uff', 'man', '_', 'c', 'oder', 'Ġ=', 'ĠHuff', 'man', 'Enc', 'oder', 'Ġ(', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', 'Ġ,', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', '_', 'L', 'ENGTH', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['e', 'Ġ.', 'Ġh', 'uff', 'man', '_', 'c', 'oder', 'Ġ=', 'ĠHuff', 'man', 'Enc', 'oder', 'Ġ(', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', 'Ġ,', 'ĠRE', 'QUEST', '_', 'C', 'OD', 'ES', '_', 'L', 'ENGTH', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['e', 'Ġ.', 'Ġhuffman_coder', 'Ġ=', 'ĠHuffmanEncoder', 'Ġ(', 'ĠREQUEST_CODES', 'Ġ,', 'ĠREQUEST_CODES_LENGTH', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "train_seq = corpus . read_sequence_list_conll ( input_data , max_sent_len = 15 , max_nr_sent = 1000 ) \n"
Original    (017): ['train_seq', '=', 'corpus', '.', 'read_sequence_list_conll', '(', 'input_data', ',', 'max_sent_len', '=', '15', ',', 'max_nr_sent', '=', '1000', ')', '\\n']
Tokenized   (039): ['<s>', 'train', '_', 'seq', 'Ġ=', 'Ġcorpus', 'Ġ.', 'Ġread', '_', 'sequence', '_', 'list', '_', 'con', 'll', 'Ġ(', 'Ġinput', '_', 'data', 'Ġ,', 'Ġmax', '_', 'sent', '_', 'len', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġmax', '_', 'nr', '_', 'sent', 'Ġ=', 'Ġ1000', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['train', '_', 'seq', 'Ġ=', 'Ġcorpus', 'Ġ.', 'Ġread', '_', 'sequence', '_', 'list', '_', 'con', 'll', 'Ġ(', 'Ġinput', '_', 'data', 'Ġ,', 'Ġmax', '_', 'sent', '_', 'len', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġmax', '_', 'nr', '_', 'sent', 'Ġ=', 'Ġ1000', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['train_seq', 'Ġ=', 'Ġcorpus', 'Ġ.', 'Ġread_sequence_list_conll', 'Ġ(', 'Ġinput_data', 'Ġ,', 'Ġmax_sent_len', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġmax_nr_sent', 'Ġ=', 'Ġ1000', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "pickle . dump ( ( corpus . word_dict , corpus . tag_dict ) , open ( , ) ) \n"
Original    (020): ['pickle', '.', 'dump', '(', '(', 'corpus', '.', 'word_dict', ',', 'corpus', '.', 'tag_dict', ')', ',', 'open', '(', ',', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'pick', 'le', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġ(', 'Ġcorpus', 'Ġ.', 'Ġword', '_', 'dict', 'Ġ,', 'Ġcorpus', 'Ġ.', 'Ġtag', '_', 'dict', 'Ġ)', 'Ġ,', 'Ġopen', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['pick', 'le', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġ(', 'Ġcorpus', 'Ġ.', 'Ġword', '_', 'dict', 'Ġ,', 'Ġcorpus', 'Ġ.', 'Ġtag', '_', 'dict', 'Ġ)', 'Ġ,', 'Ġopen', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['pickle', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġ(', 'Ġcorpus', 'Ġ.', 'Ġword_dict', 'Ġ,', 'Ġcorpus', 'Ġ.', 'Ġtag_dict', 'Ġ)', 'Ġ,', 'Ġopen', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "total = np . zeros ( self . features . n_feats ) \n"
Original    (013): ['total', '=', 'np', '.', 'zeros', '(', 'self', '.', 'features', '.', 'n_feats', ')', '\\n']
Tokenized   (020): ['<s>', 'total', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġn', '_', 'fe', 'ats', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['total', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġn', '_', 'fe', 'ats', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['total', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġzeros', 'Ġ(', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġn_feats', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "scores = self . features . compute_scores ( feats , self . weights ) \n"
Original    (015): ['scores', '=', 'self', '.', 'features', '.', 'compute_scores', '(', 'feats', ',', 'self', '.', 'weights', ')', '\\n']
Tokenized   (022): ['<s>', 'sc', 'ores', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġcompute', '_', 'sc', 'ores', 'Ġ(', 'Ġfeats', 'Ġ,', 'Ġself', 'Ġ.', 'Ġweights', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['sc', 'ores', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġcompute', '_', 'sc', 'ores', 'Ġ(', 'Ġfeats', 'Ġ,', 'Ġself', 'Ġ.', 'Ġweights', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['scores', 'Ġ=', 'Ġself', 'Ġ.', 'Ġfeatures', 'Ġ.', 'Ġcompute_scores', 'Ġ(', 'Ġfeats', 'Ġ,', 'Ġself', 'Ġ.', 'Ġweights', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "t0 = 1.0 / ( sigma * eta0 ) \n"
Original    (010): ['t0', '=', '1.0', '/', '(', 'sigma', '*', 'eta0', ')', '\\n']
Tokenized   (019): ['<s>', 't', '0', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ(', 'Ġs', 'igma', 'Ġ*', 'Ġet', 'a', '0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['t', '0', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ(', 'Ġs', 'igma', 'Ġ*', 'Ġet', 'a', '0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['t0', 'Ġ=', 'Ġ1.0', 'Ġ/', 'Ġ(', 'Ġsigma', 'Ġ*', 'Ġeta0', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "marginals , logZ = self . decoder . parse_marginals_nonproj ( scores ) \n"
Original    (013): ['marginals', ',', 'logZ', '=', 'self', '.', 'decoder', '.', 'parse_marginals_nonproj', '(', 'scores', ')', '\\n']
Tokenized   (026): ['<s>', 'marg', 'inals', 'Ġ,', 'Ġlog', 'Z', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdec', 'oder', 'Ġ.', 'Ġparse', '_', 'marg', 'inals', '_', 'non', 'pro', 'j', 'Ġ(', 'Ġscores', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['marg', 'inals', 'Ġ,', 'Ġlog', 'Z', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdec', 'oder', 'Ġ.', 'Ġparse', '_', 'marg', 'inals', '_', 'non', 'pro', 'j', 'Ġ(', 'Ġscores', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['marginals', 'Ġ,', 'ĠlogZ', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdecoder', 'Ġ.', 'Ġparse_marginals_nonproj', 'Ġ(', 'Ġscores', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "score_corr += scores [ h , m ] \n"
Original    (009): ['score_corr', '+=', 'scores', '[', 'h', ',', 'm', ']', '\\n']
Tokenized   (015): ['<s>', 'score', '_', 'cor', 'r', 'Ġ+=', 'Ġscores', 'Ġ[', 'Ġh', 'Ġ,', 'Ġm', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['score', '_', 'cor', 'r', 'Ġ+=', 'Ġscores', 'Ġ[', 'Ġh', 'Ġ,', 'Ġm', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['score_corr', 'Ġ+=', 'Ġscores', 'Ġ[', 'Ġh', 'Ġ,', 'Ġm', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "features = self . add_final_features ( sequence , sequence . y [ - 1 ] , features ) \n"
Original    (019): ['features', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'sequence', '.', 'y', '[', '-', '1', ']', ',', 'features', ')', '\\n']
Tokenized   (026): ['<s>', 'features', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġsequence', 'Ġ.', 'Ġy', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġfeatures', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['features', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġsequence', 'Ġ.', 'Ġy', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġfeatures', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['features', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd_final_features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġsequence', 'Ġ.', 'Ġy', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġfeatures', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "node_idx = self . add_emission_features ( sequence , pos , y , node_idx ) \n"
Original    (015): ['node_idx', '=', 'self', '.', 'add_emission_features', '(', 'sequence', ',', 'pos', ',', 'y', ',', 'node_idx', ')', '\\n']
Tokenized   (029): ['<s>', 'node', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'em', 'ission', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġpos', 'Ġ,', 'Ġy', 'Ġ,', 'Ġnode', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['node', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'em', 'ission', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġpos', 'Ġ,', 'Ġy', 'Ġ,', 'Ġnode', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['node_idx', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd_emission_features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġpos', 'Ġ,', 'Ġy', 'Ġ,', 'Ġnode_idx', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "edge_idx = self . add_final_features ( sequence , y_prev , edge_idx ) \n"
Original    (013): ['edge_idx', '=', 'self', '.', 'add_final_features', '(', 'sequence', ',', 'y_prev', ',', 'edge_idx', ')', '\\n']
Tokenized   (028): ['<s>', 'edge', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġy', '_', 'prev', 'Ġ,', 'Ġedge', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['edge', '_', 'id', 'x', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd', '_', 'final', '_', 'features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġy', '_', 'prev', 'Ġ,', 'Ġedge', '_', 'id', 'x', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['edge_idx', 'Ġ=', 'Ġself', 'Ġ.', 'Ġadd_final_features', 'Ġ(', 'Ġsequence', 'Ġ,', 'Ġy_prev', 'Ġ,', 'Ġedge_idx', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "y_name = self . dataset . y_dict . get_label_name ( y ) \n"
Original    (013): ['y_name', '=', 'self', '.', 'dataset', '.', 'y_dict', '.', 'get_label_name', '(', 'y', ')', '\\n']
Tokenized   (024): ['<s>', 'y', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdataset', 'Ġ.', 'Ġy', '_', 'dict', 'Ġ.', 'Ġget', '_', 'label', '_', 'name', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['y', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdataset', 'Ġ.', 'Ġy', '_', 'dict', 'Ġ.', 'Ġget', '_', 'label', '_', 'name', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['y_name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġdataset', 'Ġ.', 'Ġy_dict', 'Ġ.', 'Ġget_label_name', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "feat_name = "prev_tag:%s::%s" % ( y_prev_name , y_name ) \n"
Original    (010): ['feat_name', '=', '"prev_tag:%s::%s"', '%', '(', 'y_prev_name', ',', 'y_name', ')', '\\n']
Tokenized   (031): ['<s>', 'feat', '_', 'name', 'Ġ=', 'Ġ"', 'prev', '_', 'tag', ':', '%', 's', '::', '%', 's', '"', 'Ġ%', 'Ġ(', 'Ġy', '_', 'prev', '_', 'name', 'Ġ,', 'Ġy', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['feat', '_', 'name', 'Ġ=', 'Ġ"', 'prev', '_', 'tag', ':', '%', 's', '::', '%', 's', '"', 'Ġ%', 'Ġ(', 'Ġy', '_', 'prev', '_', 'name', 'Ġ,', 'Ġy', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['feat_name', 'Ġ=', 'Ġ"prev_tag:%s::%s"', 'Ġ%', 'Ġ(', 'Ġy_prev_name', 'Ġ,', 'Ġy_name', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "point_geom . AddPoint ( point [ 0 ] , point [ 1 ] ) \n"
Original    (015): ['point_geom', '.', 'AddPoint', '(', 'point', '[', '0', ']', ',', 'point', '[', '1', ']', ')', '\\n']
Tokenized   (022): ['<s>', 'point', '_', 'ge', 'om', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġpoint', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġpoint', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['point', '_', 'ge', 'om', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġpoint', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġpoint', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['point_geom', 'Ġ.', 'ĠAddPoint', 'Ġ(', 'Ġpoint', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġpoint', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "longitudes = [ 100 , 110 , 120 , 130 , 140 ] \n"
Original    (014): ['longitudes', '=', '[', '100', ',', '110', ',', '120', ',', '130', ',', '140', ']', '\\n']
Tokenized   (018): ['<s>', 'long', 'itudes', 'Ġ=', 'Ġ[', 'Ġ100', 'Ġ,', 'Ġ110', 'Ġ,', 'Ġ120', 'Ġ,', 'Ġ130', 'Ġ,', 'Ġ140', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['long', 'itudes', 'Ġ=', 'Ġ[', 'Ġ100', 'Ġ,', 'Ġ110', 'Ġ,', 'Ġ120', 'Ġ,', 'Ġ130', 'Ġ,', 'Ġ140', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['longitudes', 'Ġ=', 'Ġ[', 'Ġ100', 'Ġ,', 'Ġ110', 'Ġ,', 'Ġ120', 'Ġ,', 'Ġ130', 'Ġ,', 'Ġ140', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "point_1 . AddPoint ( longitudes [ 0 ] , latitudes [ 0 ] , elevation ) \n"
Original    (017): ['point_1', '.', 'AddPoint', '(', 'longitudes', '[', '0', ']', ',', 'latitudes', '[', '0', ']', ',', 'elevation', ')', '\\n']
Tokenized   (025): ['<s>', 'point', '_', '1', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġlong', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġlat', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġelevation', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['point', '_', '1', 'Ġ.', 'ĠAdd', 'Point', 'Ġ(', 'Ġlong', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġlat', 'itudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġelevation', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['point_1', 'Ġ.', 'ĠAddPoint', 'Ġ(', 'Ġlongitudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġlatitudes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġelevation', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "di = np . array ( [ x for x in range ( projected_X . shape [ 1 ] ) ] ) \n"
Original    (023): ['di', '=', 'np', '.', 'array', '(', '[', 'x', 'for', 'x', 'in', 'range', '(', 'projected_X', '.', 'shape', '[', '1', ']', ')', ']', ')', '\\n']
Tokenized   (028): ['<s>', 'di', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġprojected', '_', 'X', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['di', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġprojected', '_', 'X', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['di', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġprojected_X', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "projected_X = np . c_ [ ids , projected_X ] \n"
Original    (011): ['projected_X', '=', 'np', '.', 'c_', '[', 'ids', ',', 'projected_X', ']', '\\n']
Tokenized   (021): ['<s>', 'project', 'ed', '_', 'X', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġc', '_', 'Ġ[', 'Ġ', 'ids', 'Ġ,', 'Ġprojected', '_', 'X', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['project', 'ed', '_', 'X', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġc', '_', 'Ġ[', 'Ġ', 'ids', 'Ġ,', 'Ġprojected', '_', 'X', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['projected_X', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġc_', 'Ġ[', 'Ġids', 'Ġ,', 'Ġprojected_X', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "clusterer . fit ( inverse_x [ : , 1 : ] ) \n"
Original    (013): ['clusterer', '.', 'fit', '(', 'inverse_x', '[', ':', ',', '1', ':', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'cl', 'ust', 'erer', 'Ġ.', 'Ġfit', 'Ġ(', 'Ġinverse', '_', 'x', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['cl', 'ust', 'erer', 'Ġ.', 'Ġfit', 'Ġ(', 'Ġinverse', '_', 'x', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['clusterer', 'Ġ.', 'Ġfit', 'Ġ(', 'Ġinverse_x', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "complex [ "meta" ] = self . projection \n"
Original    (009): ['complex', '[', '"meta"', ']', '=', 'self', '.', 'projection', '\\n']
Tokenized   (014): ['<s>', 'complex', 'Ġ[', 'Ġ"', 'meta', '"', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprojection', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['complex', 'Ġ[', 'Ġ"', 'meta', '"', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprojection', 'Ġ\\', 'n']
Detokenized (009): ['complex', 'Ġ[', 'Ġ"meta"', 'Ġ]', 'Ġ=', 'Ġself', 'Ġ.', 'Ġprojection', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "json_s [ "nodes" ] . append ( { "name" : str ( k ) , "tooltip" : tooltip_s , "group" : 2 * int ( np . log ( len ( complex ~~ k2e [ k ] = e \n"
Original    (040): ['json_s', '[', '"nodes"', ']', '.', 'append', '(', '{', '"name"', ':', 'str', '(', 'k', ')', ',', '"tooltip"', ':', 'tooltip_s', ',', '"group"', ':', '2', '*', 'int', '(', 'np', '.', 'log', '(', 'len', '(', 'complex', '~~', 'k2e', '[', 'k', ']', '=', 'e', '\\n']
Tokenized   (060): ['<s>', 'json', '_', 's', 'Ġ[', 'Ġ"', 'n', 'odes', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ"', 'name', '"', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġk', 'Ġ)', 'Ġ,', 'Ġ"', 'tool', 'tip', '"', 'Ġ:', 'Ġtooltip', '_', 's', 'Ġ,', 'Ġ"', 'group', '"', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġint', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġlog', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġcomplex', 'Ġ', '~~', 'Ġk', '2', 'e', 'Ġ[', 'Ġk', 'Ġ]', 'Ġ=', 'Ġe', 'Ġ\\', 'n', '</s>']
Filtered   (058): ['json', '_', 's', 'Ġ[', 'Ġ"', 'n', 'odes', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ"', 'name', '"', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġk', 'Ġ)', 'Ġ,', 'Ġ"', 'tool', 'tip', '"', 'Ġ:', 'Ġtooltip', '_', 's', 'Ġ,', 'Ġ"', 'group', '"', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġint', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġlog', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġcomplex', 'Ġ', '~~', 'Ġk', '2', 'e', 'Ġ[', 'Ġk', 'Ġ]', 'Ġ=', 'Ġe', 'Ġ\\', 'n']
Detokenized (040): ['json_s', 'Ġ[', 'Ġ"nodes"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ{', 'Ġ"name"', 'Ġ:', 'Ġstr', 'Ġ(', 'Ġk', 'Ġ)', 'Ġ,', 'Ġ"tooltip"', 'Ġ:', 'Ġtooltip_s', 'Ġ,', 'Ġ"group"', 'Ġ:', 'Ġ2', 'Ġ*', 'Ġint', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġlog', 'Ġ(', 'Ġlen', 'Ġ(', 'Ġcomplex', 'Ġ~~', 'Ġk2e', 'Ġ[', 'Ġk', 'Ġ]', 'Ġ=', 'Ġe', 'Ġ\\n']
Counter: 58
===================================================================
Hidden states:  (13, 40, 768)
# Extracted words:  40
Sentence         : "width_js = "%s" % width_html \n"
Original    (006): ['width_js', '=', '"%s"', '%', 'width_html', '\\n']
Tokenized   (015): ['<s>', 'width', '_', 'js', 'Ġ=', 'Ġ"%', 's', '"', 'Ġ%', 'Ġwidth', '_', 'html', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['width', '_', 'js', 'Ġ=', 'Ġ"%', 's', '"', 'Ġ%', 'Ġwidth', '_', 'html', 'Ġ\\', 'n']
Detokenized (006): ['width_js', 'Ġ=', 'Ġ"%s"', 'Ġ%', 'Ġwidth_html', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "new_settings [ interface ] [ ] [ % protocol ] = server \n"
Original    (013): ['new_settings', '[', 'interface', ']', '[', ']', '[', '%', 'protocol', ']', '=', 'server', '\\n']
Tokenized   (018): ['<s>', 'new', '_', 'settings', 'Ġ[', 'Ġinterface', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ%', 'Ġprotocol', 'Ġ]', 'Ġ=', 'Ġserver', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['new', '_', 'settings', 'Ġ[', 'Ġinterface', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ%', 'Ġprotocol', 'Ġ]', 'Ġ=', 'Ġserver', 'Ġ\\', 'n']
Detokenized (013): ['new_settings', 'Ġ[', 'Ġinterface', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ%', 'Ġprotocol', 'Ġ]', 'Ġ=', 'Ġserver', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "setups = ( less_setup , sass_setup , stylus_setup , sass_erb_setup ) \n"
Original    (012): ['setups', '=', '(', 'less_setup', ',', 'sass_setup', ',', 'stylus_setup', ',', 'sass_erb_setup', ')', '\\n']
Tokenized   (029): ['<s>', 'set', 'ups', 'Ġ=', 'Ġ(', 'Ġless', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'setup', 'Ġ,', 'Ġstyl', 'us', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'erb', '_', 'setup', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['set', 'ups', 'Ġ=', 'Ġ(', 'Ġless', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'setup', 'Ġ,', 'Ġstyl', 'us', '_', 'setup', 'Ġ,', 'Ġs', 'ass', '_', 'erb', '_', 'setup', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['setups', 'Ġ=', 'Ġ(', 'Ġless_setup', 'Ġ,', 'Ġsass_setup', 'Ġ,', 'Ġstylus_setup', 'Ġ,', 'Ġsass_erb_setup', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fn = self . view . file_name ( ) . encode ( "utf_8" ) \n"
Original    (015): ['fn', '=', 'self', '.', 'view', '.', 'file_name', '(', ')', '.', 'encode', '(', '"utf_8"', ')', '\\n']
Tokenized   (024): ['<s>', 'fn', 'Ġ=', 'Ġself', 'Ġ.', 'Ġview', 'Ġ.', 'Ġfile', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ"', 'utf', '_', '8', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['fn', 'Ġ=', 'Ġself', 'Ġ.', 'Ġview', 'Ġ.', 'Ġfile', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ"', 'utf', '_', '8', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['fn', 'Ġ=', 'Ġself', 'Ġ.', 'Ġview', 'Ġ.', 'Ġfile_name', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġencode', 'Ġ(', 'Ġ"utf_8"', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "compiled_regex = re . compile ( chosen_setup . regex , re . MULTILINE ) \n"
Original    (015): ['compiled_regex', '=', 're', '.', 'compile', '(', 'chosen_setup', '.', 'regex', ',', 're', '.', 'MULTILINE', ')', '\\n']
Tokenized   (027): ['<s>', 'comp', 'iled', '_', 're', 'gex', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġchosen', '_', 'setup', 'Ġ.', 'Ġregex', 'Ġ,', 'Ġre', 'Ġ.', 'ĠM', 'ULT', 'IL', 'INE', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['comp', 'iled', '_', 're', 'gex', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġchosen', '_', 'setup', 'Ġ.', 'Ġregex', 'Ġ,', 'Ġre', 'Ġ.', 'ĠM', 'ULT', 'IL', 'INE', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['compiled_regex', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġchosen_setup', 'Ġ.', 'Ġregex', 'Ġ,', 'Ġre', 'Ġ.', 'ĠMULTILINE', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "file_dir = os . path . dirname ( fn ) . decode ( "utf-8" ) \n"
Original    (016): ['file_dir', '=', 'os', '.', 'path', '.', 'dirname', '(', 'fn', ')', '.', 'decode', '(', '"utf-8"', ')', '\\n']
Tokenized   (026): ['<s>', 'file', '_', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġfn', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['file', '_', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġfn', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['file_dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġfn', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"utf-8"', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "partial_filename = fn_split [ 0 ] + "/_" + fn_split [ 1 ] \n"
Original    (014): ['partial_filename', '=', 'fn_split', '[', '0', ']', '+', '"/_"', '+', 'fn_split', '[', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'partial', '_', 'filename', 'Ġ=', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ"/', '_', '"', 'Ġ+', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['partial', '_', 'filename', 'Ġ=', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ"/', '_', '"', 'Ġ+', 'Ġfn', '_', 'split', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['partial_filename', 'Ġ=', 'Ġfn_split', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ"/_"', 'Ġ+', 'Ġfn_split', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "imported_vars = imported_vars + m \n"
Original    (006): ['imported_vars', '=', 'imported_vars', '+', 'm', '\\n']
Tokenized   (016): ['<s>', 'im', 'ported', '_', 'v', 'ars', 'Ġ=', 'Ġimported', '_', 'v', 'ars', 'Ġ+', 'Ġm', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['im', 'ported', '_', 'v', 'ars', 'Ġ=', 'Ġimported', '_', 'v', 'ars', 'Ġ+', 'Ġm', 'Ġ\\', 'n']
Detokenized (006): ['imported_vars', 'Ġ=', 'Ġimported_vars', 'Ġ+', 'Ġm', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : ""params" : [ { \n"
Original    (005): ['"params"', ':', '[', '{', '\\n']
Tokenized   (010): ['<s>', '"', 'params', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['"', 'params', '"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ\\', 'n']
Detokenized (005): ['"params"', 'Ġ:', 'Ġ[', 'Ġ{', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "LAT_MAX = + 90.0 \n"
Original    (005): ['LAT_MAX', '=', '+', '90.0', '\\n']
Tokenized   (013): ['<s>', 'L', 'AT', '_', 'MAX', 'Ġ=', 'Ġ+', 'Ġ90', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['L', 'AT', '_', 'MAX', 'Ġ=', 'Ġ+', 'Ġ90', '.', '0', 'Ġ\\', 'n']
Detokenized (005): ['LAT_MAX', 'Ġ=', 'Ġ+', 'Ġ90.0', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : ""purple" , "teal" , "lightgray" ] \n"
Original    (007): ['"purple"', ',', '"teal"', ',', '"lightgray"', ']', '\\n']
Tokenized   (019): ['<s>', '"', 'pur', 'ple', '"', 'Ġ,', 'Ġ"', 'te', 'al', '"', 'Ġ,', 'Ġ"', 'light', 'gray', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['"', 'pur', 'ple', '"', 'Ġ,', 'Ġ"', 'te', 'al', '"', 'Ġ,', 'Ġ"', 'light', 'gray', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['"purple"', 'Ġ,', 'Ġ"teal"', 'Ġ,', 'Ġ"lightgray"', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "numrange = None , default = None , max_width = 72 ) : \n"
Original    (014): ['numrange', '=', 'None', ',', 'default', '=', 'None', ',', 'max_width', '=', '72', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'num', 'range', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdefault', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġmax', '_', 'width', 'Ġ=', 'Ġ72', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['num', 'range', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdefault', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġmax', '_', 'width', 'Ġ=', 'Ġ72', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (014): ['numrange', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġdefault', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġmax_width', 'Ġ=', 'Ġ72', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "found_letter . lower ( ) == default . lower ( ) ) ) : \n"
Original    (015): ['found_letter', '.', 'lower', '(', ')', '==', 'default', '.', 'lower', '(', ')', ')', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'found', '_', 'letter', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġdefault', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['found', '_', 'letter', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġdefault', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (015): ['found_letter', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġdefault', 'Ġ.', 'Ġlower', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "option [ : index ] + show_letter + option [ index + 1 : ] \n"
Original    (016): ['option', '[', ':', 'index', ']', '+', 'show_letter', '+', 'option', '[', 'index', '+', '1', ':', ']', '\\n']
Tokenized   (021): ['<s>', 'option', 'Ġ[', 'Ġ:', 'Ġindex', 'Ġ]', 'Ġ+', 'Ġshow', '_', 'letter', 'Ġ+', 'Ġoption', 'Ġ[', 'Ġindex', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['option', 'Ġ[', 'Ġ:', 'Ġindex', 'Ġ]', 'Ġ+', 'Ġshow', '_', 'letter', 'Ġ+', 'Ġoption', 'Ġ[', 'Ġindex', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['option', 'Ġ[', 'Ġ:', 'Ġindex', 'Ġ]', 'Ġ+', 'Ġshow_letter', 'Ġ+', 'Ġoption', 'Ġ[', 'Ġindex', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "display_letters . append ( found_letter . upper ( ) ) \n"
Original    (011): ['display_letters', '.', 'append', '(', 'found_letter', '.', 'upper', '(', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'display', '_', 'letters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfound', '_', 'letter', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['display', '_', 'letters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfound', '_', 'letter', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['display_letters', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġfound_letter', 'Ġ.', 'Ġupper', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "default_name = self . colorize ( , default_name ) \n"
Original    (010): ['default_name', '=', 'self', '.', 'colorize', '(', ',', 'default_name', ')', '\\n']
Tokenized   (018): ['<s>', 'default', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġ,', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['default', '_', 'name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġ,', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['default_name', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcolorize', 'Ġ(', 'Ġ,', 'Ġdefault_name', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "prompt_parts . append ( tmpl % default_name ) \n"
Original    (009): ['prompt_parts', '.', 'append', '(', 'tmpl', '%', 'default_name', ')', '\\n']
Tokenized   (019): ['<s>', 'prom', 'pt', '_', 'parts', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġt', 'm', 'pl', 'Ġ%', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['prom', 'pt', '_', 'parts', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġt', 'm', 'pl', 'Ġ%', 'Ġdefault', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['prompt_parts', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġtmpl', 'Ġ%', 'Ġdefault_name', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "matcher = SequenceMatcher ( lambda x : False , a , b ) \n"
Original    (014): ['matcher', '=', 'SequenceMatcher', '(', 'lambda', 'x', ':', 'False', ',', 'a', ',', 'b', ')', '\\n']
Tokenized   (020): ['<s>', 'mat', 'cher', 'Ġ=', 'ĠSequence', 'Mat', 'cher', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'ĠFalse', 'Ġ,', 'Ġa', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['mat', 'cher', 'Ġ=', 'ĠSequence', 'Mat', 'cher', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'ĠFalse', 'Ġ,', 'Ġa', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['matcher', 'Ġ=', 'ĠSequenceMatcher', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'ĠFalse', 'Ġ,', 'Ġa', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "b_out . append ( self . colorize ( color , b [ b_start : b_end ] ) ) \n"
Original    (019): ['b_out', '.', 'append', '(', 'self', '.', 'colorize', '(', 'color', ',', 'b', '[', 'b_start', ':', 'b_end', ']', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'b', '_', 'out', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġcolor', 'Ġ,', 'Ġb', 'Ġ[', 'Ġb', '_', 'start', 'Ġ:', 'Ġb', '_', 'end', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['b', '_', 'out', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcolor', 'ize', 'Ġ(', 'Ġcolor', 'Ġ,', 'Ġb', 'Ġ[', 'Ġb', '_', 'start', 'Ġ:', 'Ġb', '_', 'end', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['b_out', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcolorize', 'Ġ(', 'Ġcolor', 'Ġ,', 'Ġb', 'Ġ[', 'Ġb_start', 'Ġ:', 'Ġb_end', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "variable = % varname \n"
Original    (005): ['variable', '=', '%', 'varname', '\\n']
Tokenized   (009): ['<s>', 'variable', 'Ġ=', 'Ġ%', 'Ġvar', 'name', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['variable', 'Ġ=', 'Ġ%', 'Ġvar', 'name', 'Ġ\\', 'n']
Detokenized (005): ['variable', 'Ġ=', 'Ġ%', 'Ġvarname', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "62 : , \n"
Original    (004): ['62', ':', ',', '\\n']
Tokenized   (007): ['<s>', '62', 'Ġ:', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['62', 'Ġ:', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['62', 'Ġ:', 'Ġ,', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "_push . update ( { \n"
Original    (006): ['_push', '.', 'update', '(', '{', '\\n']
Tokenized   (010): ['<s>', '_', 'push', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['_', 'push', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ{', 'Ġ\\', 'n']
Detokenized (006): ['_push', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ{', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_readonly = Entity . _readonly | { , } \n"
Original    (010): ['_readonly', '=', 'Entity', '.', '_readonly', '|', '{', ',', '}', '\\n']
Tokenized   (017): ['<s>', '_', 'read', 'only', 'Ġ=', 'ĠEntity', 'Ġ.', 'Ġ_', 'read', 'only', 'Ġ|', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['_', 'read', 'only', 'Ġ=', 'ĠEntity', 'Ġ.', 'Ġ_', 'read', 'only', 'Ġ|', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\', 'n']
Detokenized (010): ['_readonly', 'Ġ=', 'ĠEntity', 'Ġ.', 'Ġ_readonly', 'Ġ|', 'Ġ{', 'Ġ,', 'Ġ}', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "remove_ids = [ 6 , 7 ] \n"
Original    (008): ['remove_ids', '=', '[', '6', ',', '7', ']', '\\n']
Tokenized   (013): ['<s>', 'remove', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ6', 'Ġ,', 'Ġ7', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['remove', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ6', 'Ġ,', 'Ġ7', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['remove_ids', 'Ġ=', 'Ġ[', 'Ġ6', 'Ġ,', 'Ġ7', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "remove_advertiser_ids = [ 8 , 9 , 10 ] \n"
Original    (010): ['remove_advertiser_ids', '=', '[', '8', ',', '9', ',', '10', ']', '\\n']
Tokenized   (019): ['<s>', 'remove', '_', 'ad', 'vertis', 'er', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ,', 'Ġ9', 'Ġ,', 'Ġ10', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['remove', '_', 'ad', 'vertis', 'er', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ,', 'Ġ9', 'Ġ,', 'Ġ10', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['remove_advertiser_ids', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ,', 'Ġ9', 'Ġ,', 'Ġ10', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "num_users , num_items = dataset . shape \n"
Original    (008): ['num_users', ',', 'num_items', '=', 'dataset', '.', 'shape', '\\n']
Tokenized   (015): ['<s>', 'num', '_', 'users', 'Ġ,', 'Ġnum', '_', 'items', 'Ġ=', 'Ġdataset', 'Ġ.', 'Ġshape', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['num', '_', 'users', 'Ġ,', 'Ġnum', '_', 'items', 'Ġ=', 'Ġdataset', 'Ġ.', 'Ġshape', 'Ġ\\', 'n']
Detokenized (008): ['num_users', 'Ġ,', 'Ġnum_items', 'Ġ=', 'Ġdataset', 'Ġ.', 'Ġshape', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "async_job = view . map_async ( process , tasks , retries = 2 ) \n"
Original    (015): ['async_job', '=', 'view', '.', 'map_async', '(', 'process', ',', 'tasks', ',', 'retries', '=', '2', ')', '\\n']
Tokenized   (025): ['<s>', 'as', 'ync', '_', 'job', 'Ġ=', 'Ġview', 'Ġ.', 'Ġmap', '_', 'as', 'ync', 'Ġ(', 'Ġprocess', 'Ġ,', 'Ġtasks', 'Ġ,', 'Ġret', 'ries', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['as', 'ync', '_', 'job', 'Ġ=', 'Ġview', 'Ġ.', 'Ġmap', '_', 'as', 'ync', 'Ġ(', 'Ġprocess', 'Ġ,', 'Ġtasks', 'Ġ,', 'Ġret', 'ries', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['async_job', 'Ġ=', 'Ġview', 'Ġ.', 'Ġmap_async', 'Ġ(', 'Ġprocess', 'Ġ,', 'Ġtasks', 'Ġ,', 'Ġretries', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "remaining = len ( tasks ) - len ( done ) \n"
Original    (012): ['remaining', '=', 'len', '(', 'tasks', ')', '-', 'len', '(', 'done', ')', '\\n']
Tokenized   (016): ['<s>', 'rem', 'aining', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtasks', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġdone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['rem', 'aining', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtasks', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġdone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['remaining', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġtasks', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġdone', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "num_items , type ( model ) . __name__ , simsfile ) \n"
Original    (012): ['num_items', ',', 'type', '(', 'model', ')', '.', '__name__', ',', 'simsfile', ')', '\\n']
Tokenized   (021): ['<s>', 'num', '_', 'items', 'Ġ,', 'Ġtype', 'Ġ(', 'Ġmodel', 'Ġ)', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġsim', 's', 'file', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['num', '_', 'items', 'Ġ,', 'Ġtype', 'Ġ(', 'Ġmodel', 'Ġ)', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ,', 'Ġsim', 's', 'file', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['num_items', 'Ġ,', 'Ġtype', 'Ġ(', 'Ġmodel', 'Ġ)', 'Ġ.', 'Ġ__name__', 'Ġ,', 'Ġsimsfile', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "before = text [ : len ( text ) - len ( like ) ] \n"
Original    (016): ['before', '=', 'text', '[', ':', 'len', '(', 'text', ')', '-', 'len', '(', 'like', ')', ']', '\\n']
Tokenized   (019): ['<s>', 'before', 'Ġ=', 'Ġtext', 'Ġ[', 'Ġ:', 'Ġlen', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġlike', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['before', 'Ġ=', 'Ġtext', 'Ġ[', 'Ġ:', 'Ġlen', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġlike', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['before', 'Ġ=', 'Ġtext', 'Ġ[', 'Ġ:', 'Ġlen', 'Ġ(', 'Ġtext', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġlike', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "Version = namedtuple ( , ) \n"
Original    (007): ['Version', '=', 'namedtuple', '(', ',', ')', '\\n']
Tokenized   (012): ['<s>', 'Version', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Version', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['Version', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "_defaults = collections . OrderedDict ( [ \n"
Original    (008): ['_defaults', '=', 'collections', '.', 'OrderedDict', '(', '[', '\\n']
Tokenized   (016): ['<s>', '_', 'default', 's', 'Ġ=', 'Ġcollections', 'Ġ.', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ(', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['_', 'default', 's', 'Ġ=', 'Ġcollections', 'Ġ.', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ(', 'Ġ[', 'Ġ\\', 'n']
Detokenized (008): ['_defaults', 'Ġ=', 'Ġcollections', 'Ġ.', 'ĠOrderedDict', 'Ġ(', 'Ġ[', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "rootDirectory = os . path . join ( os . path . dirname ( os . path . realpath ( __file__ ) ) , , ) \n"
Original    (027): ['rootDirectory', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'realpath', '(', '__file__', ')', ')', ',', ',', ')', '\\n']
Tokenized   (035): ['<s>', 'root', 'Directory', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['root', 'Directory', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġreal', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['rootDirectory', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġrealpath', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "httpd . handle_request ( ) from . import TestEnable # \n"
Original    (011): ['httpd', '.', 'handle_request', '(', ')', 'from', '.', 'import', 'TestEnable', '#', '\\n']
Tokenized   (018): ['<s>', 'http', 'd', 'Ġ.', 'Ġhandle', '_', 'request', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġ.', 'Ġimport', 'ĠTest', 'Enable', 'Ġ#', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['http', 'd', 'Ġ.', 'Ġhandle', '_', 'request', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġ.', 'Ġimport', 'ĠTest', 'Enable', 'Ġ#', 'Ġ\\', 'n']
Detokenized (011): ['httpd', 'Ġ.', 'Ġhandle_request', 'Ġ(', 'Ġ)', 'Ġfrom', 'Ġ.', 'Ġimport', 'ĠTestEnable', 'Ġ#', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "field_names = tuple ( field_names ) , \n"
Original    (008): ['field_names', '=', 'tuple', '(', 'field_names', ')', ',', '\\n']
Tokenized   (015): ['<s>', 'field', '_', 'names', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['field', '_', 'names', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['field_names', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġfield_names', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "arg_list = repr ( tuple ( field_names ) ) . replace ( "\'" , "" ) [ 1 : - 1 ] , \n"
Original    (024): ['arg_list', '=', 'repr', '(', 'tuple', '(', 'field_names', ')', ')', '.', 'replace', '(', '"\\\'"', ',', '""', ')', '[', '1', ':', '-', '1', ']', ',', '\\n']
Tokenized   (032): ['<s>', 'arg', '_', 'list', 'Ġ=', 'Ġrepr', 'Ġ(', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"\\', '\'"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['arg', '_', 'list', 'Ġ=', 'Ġrepr', 'Ġ(', 'Ġtuple', 'Ġ(', 'Ġfield', '_', 'names', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"\\', '\'"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (024): ['arg_list', 'Ġ=', 'Ġrepr', 'Ġ(', 'Ġtuple', 'Ġ(', 'Ġfield_names', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ"\\\'"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "repr_fmt = . join ( _repr_template . format ( name = name ) \n"
Original    (014): ['repr_fmt', '=', '.', 'join', '(', '_repr_template', '.', 'format', '(', 'name', '=', 'name', ')', '\\n']
Tokenized   (025): ['<s>', 're', 'pr', '_', 'f', 'mt', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 're', 'pr', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['re', 'pr', '_', 'f', 'mt', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 're', 'pr', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['repr_fmt', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_repr_template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "field_defs = . join ( _field_template . format ( index = index , name = name ) \n"
Original    (018): ['field_defs', '=', '.', 'join', '(', '_field_template', '.', 'format', '(', 'index', '=', 'index', ',', 'name', '=', 'name', ')', '\\n']
Tokenized   (027): ['<s>', 'field', '_', 'def', 's', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 'field', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġindex', 'Ġ,', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['field', '_', 'def', 's', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_', 'field', '_', 'template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġindex', 'Ġ,', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['field_defs', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ_field_template', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġindex', 'Ġ,', 'Ġname', 'Ġ=', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "OrderedDict = OrderedDict , _property = property , _tuple = tuple ) \n"
Original    (013): ['OrderedDict', '=', 'OrderedDict', ',', '_property', '=', 'property', ',', '_tuple', '=', 'tuple', ')', '\\n']
Tokenized   (025): ['<s>', 'Ord', 'ered', 'D', 'ict', 'Ġ=', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ,', 'Ġ_', 'property', 'Ġ=', 'Ġproperty', 'Ġ,', 'Ġ_', 't', 'uple', 'Ġ=', 'Ġtuple', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['Ord', 'ered', 'D', 'ict', 'Ġ=', 'ĠOrd', 'ered', 'D', 'ict', 'Ġ,', 'Ġ_', 'property', 'Ġ=', 'Ġproperty', 'Ġ,', 'Ġ_', 't', 'uple', 'Ġ=', 'Ġtuple', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['OrderedDict', 'Ġ=', 'ĠOrderedDict', 'Ġ,', 'Ġ_property', 'Ġ=', 'Ġproperty', 'Ġ,', 'Ġ_tuple', 'Ġ=', 'Ġtuple', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "xx = Xdf [ ] . values \n"
Original    (008): ['xx', '=', 'Xdf', '[', ']', '.', 'values', '\\n']
Tokenized   (012): ['<s>', 'xx', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġvalues', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['xx', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġvalues', 'Ġ\\', 'n']
Detokenized (008): ['xx', 'Ġ=', 'ĠXdf', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġvalues', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "X_CD13 , Y_CD13 = util . get_data ( cd13 , y_names = [ , ] ) \n"
Original    (017): ['X_CD13', ',', 'Y_CD13', '=', 'util', '.', 'get_data', '(', 'cd13', ',', 'y_names', '=', '[', ',', ']', ')', '\\n']
Tokenized   (031): ['<s>', 'X', '_', 'CD', '13', 'Ġ,', 'ĠY', '_', 'CD', '13', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '13', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['X', '_', 'CD', '13', 'Ġ,', 'ĠY', '_', 'CD', '13', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '13', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['X_CD13', 'Ġ,', 'ĠY_CD13', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġcd13', 'Ġ,', 'Ġy_names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "cd33 = human_data . xs ( , level = , drop_level = False ) \n"
Original    (015): ['cd33', '=', 'human_data', '.', 'xs', '(', ',', 'level', '=', ',', 'drop_level', '=', 'False', ')', '\\n']
Tokenized   (024): ['<s>', 'cd', '33', 'Ġ=', 'Ġhuman', '_', 'data', 'Ġ.', 'Ġx', 's', 'Ġ(', 'Ġ,', 'Ġlevel', 'Ġ=', 'Ġ,', 'Ġdrop', '_', 'level', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['cd', '33', 'Ġ=', 'Ġhuman', '_', 'data', 'Ġ.', 'Ġx', 's', 'Ġ(', 'Ġ,', 'Ġlevel', 'Ġ=', 'Ġ,', 'Ġdrop', '_', 'level', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['cd33', 'Ġ=', 'Ġhuman_data', 'Ġ.', 'Ġxs', 'Ġ(', 'Ġ,', 'Ġlevel', 'Ġ=', 'Ġ,', 'Ġdrop_level', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "X_CD33 , Y_CD33 = util . get_data ( cd33 , y_names = [ , , ] ) \n"
Original    (018): ['X_CD33', ',', 'Y_CD33', '=', 'util', '.', 'get_data', '(', 'cd33', ',', 'y_names', '=', '[', ',', ',', ']', ')', '\\n']
Tokenized   (032): ['<s>', 'X', '_', 'CD', '33', 'Ġ,', 'ĠY', '_', 'CD', '33', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '33', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['X', '_', 'CD', '33', 'Ġ,', 'ĠY', '_', 'CD', '33', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '33', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['X_CD33', 'Ġ,', 'ĠY_CD33', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġcd33', 'Ġ,', 'Ġy_names', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "X_CD15 , Y_CD15 = util . get_data ( cd15 , y_names = [ ] ) \n"
Original    (016): ['X_CD15', ',', 'Y_CD15', '=', 'util', '.', 'get_data', '(', 'cd15', ',', 'y_names', '=', '[', ']', ')', '\\n']
Tokenized   (030): ['<s>', 'X', '_', 'CD', '15', 'Ġ,', 'ĠY', '_', 'CD', '15', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '15', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['X', '_', 'CD', '15', 'Ġ,', 'ĠY', '_', 'CD', '15', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġcd', '15', 'Ġ,', 'Ġy', '_', 'names', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['X_CD15', 'Ġ,', 'ĠY_CD15', 'Ġ=', 'Ġutil', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġcd15', 'Ġ,', 'Ġy_names', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "mouse_Y = pandas . concat ( [ mouse_Y , Y ] , axis = 0 ) \n"
Original    (017): ['mouse_Y', '=', 'pandas', '.', 'concat', '(', '[', 'mouse_Y', ',', 'Y', ']', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (026): ['<s>', 'mouse', '_', 'Y', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ[', 'Ġmouse', '_', 'Y', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['mouse', '_', 'Y', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ[', 'Ġmouse', '_', 'Y', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['mouse_Y', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġconcat', 'Ġ(', 'Ġ[', 'Ġmouse_Y', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "mouse_data = pandas . read_excel ( data_file , sheetname = 1 , index_col = [ 0 , 1 ] ) \n"
Original    (021): ['mouse_data', '=', 'pandas', '.', 'read_excel', '(', 'data_file', ',', 'sheetname', '=', '1', ',', 'index_col', '=', '[', '0', ',', '1', ']', ')', '\\n']
Tokenized   (035): ['<s>', 'mouse', '_', 'data', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġread', '_', 'ex', 'cel', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġsheet', 'name', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġindex', '_', 'col', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['mouse', '_', 'data', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġread', '_', 'ex', 'cel', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġsheet', 'name', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġindex', '_', 'col', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['mouse_data', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġread_excel', 'Ġ(', 'Ġdata_file', 'Ġ,', 'Ġsheetname', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġindex_col', 'Ġ=', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "data_efficient [ ] = 1. \n"
Original    (006): ['data_efficient', '[', ']', '=', '1.', '\\n']
Tokenized   (012): ['<s>', 'data', '_', 'efficient', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', '.', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['data', '_', 'efficient', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', '.', 'Ġ\\', 'n']
Detokenized (006): ['data_efficient', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1.', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "exp_data [ ] = exp_data . groupby ( ) [ ] . transform ( exp_data [ ] = exp_data . groupby ( ) [ ] . transform ( \n"
Original    (029): ['exp_data', '[', ']', '=', 'exp_data', '.', 'groupby', '(', ')', '[', ']', '.', 'transform', '(', 'exp_data', '[', ']', '=', 'exp_data', '.', 'groupby', '(', ')', '[', ']', '.', 'transform', '(', '\\n']
Tokenized   (042): ['<s>', 'exp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġexp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['exp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġexp', '_', 'data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp', '_', 'data', 'Ġ.', 'Ġgroup', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġ\\', 'n']
Detokenized (029): ['exp_data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp_data', 'Ġ.', 'Ġgroupby', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġexp_data', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġexp_data', 'Ġ.', 'Ġgroupby', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġtransform', 'Ġ(', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "aggregated [ ] = aggregated [ [ , ] ] . mean ( axis = 1 ) \n"
Original    (018): ['aggregated', '[', ']', '=', 'aggregated', '[', '[', ',', ']', ']', '.', 'mean', '(', 'axis', '=', '1', ')', '\\n']
Tokenized   (024): ['<s>', 'agg', 'reg', 'ated', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġaggreg', 'ated', 'Ġ[', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ]', 'Ġ.', 'Ġmean', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['agg', 'reg', 'ated', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġaggreg', 'ated', 'Ġ[', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ]', 'Ġ.', 'Ġmean', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['aggregated', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġaggregated', 'Ġ[', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ]', 'Ġ.', 'Ġmean', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "known_pairs = { : [ , , , ] , \n"
Original    (011): ['known_pairs', '=', '{', ':', '[', ',', ',', ',', ']', ',', '\\n']
Tokenized   (017): ['<s>', 'known', '_', 'p', 'airs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['known', '_', 'p', 'airs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['known_pairs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "drugs_to_genes [ ] . extend ( [ , , , , , \n"
Original    (013): ['drugs_to_genes', '[', ']', '.', 'extend', '(', '[', ',', ',', ',', ',', ',', '\\n']
Tokenized   (022): ['<s>', 'drug', 's', '_', 'to', '_', 'gen', 'es', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['drug', 's', '_', 'to', '_', 'gen', 'es', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['drugs_to_genes', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Xtmp [ ] = drug \n"
Original    (006): ['Xtmp', '[', ']', '=', 'drug', '\\n']
Tokenized   (010): ['<s>', 'X', 'tmp', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdrug', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['X', 'tmp', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdrug', 'Ġ\\', 'n']
Detokenized (006): ['Xtmp', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdrug', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "y_rank = pandas . concat ( ( y_rank , y_ranktmp ) , axis = 0 ) \n"
Original    (017): ['y_rank', '=', 'pandas', '.', 'concat', '(', '(', 'y_rank', ',', 'y_ranktmp', ')', ',', 'axis', '=', '0', ')', '\\n']
Tokenized   (029): ['<s>', 'y', '_', 'rank', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġy', '_', 'rank', 'Ġ,', 'Ġy', '_', 'rank', 'tmp', 'Ġ)', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['y', '_', 'rank', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġy', '_', 'rank', 'Ġ,', 'Ġy', '_', 'rank', 'tmp', 'Ġ)', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['y_rank', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġconcat', 'Ġ(', 'Ġ(', 'Ġy_rank', 'Ġ,', 'Ġy_ranktmp', 'Ġ)', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "experiments [ ] = [ , , , ] \n"
Original    (010): ['experiments', '[', ']', '=', '[', ',', ',', ',', ']', '\\n']
Tokenized   (014): ['<s>', 'exper', 'iments', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['exper', 'iments', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['experiments', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "data_tmp [ "variance" ] = np . var ( data_tmp . values , axis = 1 ) \n"
Original    (018): ['data_tmp', '[', '"variance"', ']', '=', 'np', '.', 'var', '(', 'data_tmp', '.', 'values', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (028): ['<s>', 'data', '_', 'tmp', 'Ġ[', 'Ġ"', 'vari', 'ance', '"', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġvar', 'Ġ(', 'Ġdata', '_', 'tmp', 'Ġ.', 'Ġvalues', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['data', '_', 'tmp', 'Ġ[', 'Ġ"', 'vari', 'ance', '"', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġvar', 'Ġ(', 'Ġdata', '_', 'tmp', 'Ġ.', 'Ġvalues', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['data_tmp', 'Ġ[', 'Ġ"variance"', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġvar', 'Ġ(', 'Ġdata_tmp', 'Ġ.', 'Ġvalues', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "gene_position_xu , target_genes_xu , Xdf_xu , Y_xu = read_xu_et_al ( data_file3 , learn_options ) \n"
Original    (015): ['gene_position_xu', ',', 'target_genes_xu', ',', 'Xdf_xu', ',', 'Y_xu', '=', 'read_xu_et_al', '(', 'data_file3', ',', 'learn_options', ')', '\\n']
Tokenized   (049): ['<s>', 'g', 'ene', '_', 'position', '_', 'x', 'u', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '_', 'x', 'u', 'Ġ,', 'ĠX', 'df', '_', 'x', 'u', 'Ġ,', 'ĠY', '_', 'x', 'u', 'Ġ=', 'Ġread', '_', 'x', 'u', '_', 'et', '_', 'al', 'Ġ(', 'Ġdata', '_', 'file', '3', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (047): ['g', 'ene', '_', 'position', '_', 'x', 'u', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '_', 'x', 'u', 'Ġ,', 'ĠX', 'df', '_', 'x', 'u', 'Ġ,', 'ĠY', '_', 'x', 'u', 'Ġ=', 'Ġread', '_', 'x', 'u', '_', 'et', '_', 'al', 'Ġ(', 'Ġdata', '_', 'file', '3', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['gene_position_xu', 'Ġ,', 'Ġtarget_genes_xu', 'Ġ,', 'ĠXdf_xu', 'Ġ,', 'ĠY_xu', 'Ġ=', 'Ġread_xu_et_al', 'Ġ(', 'Ġdata_file3', 'Ġ,', 'Ġlearn_options', 'Ġ)', 'Ġ\\n']
Counter: 47
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "annotations , gene_position1 , target_genes1 , Xdf1 , Y1 = read_V1_data ( data_file , learn_options ) \n"
Original    (017): ['annotations', ',', 'gene_position1', ',', 'target_genes1', ',', 'Xdf1', ',', 'Y1', '=', 'read_V1_data', '(', 'data_file', ',', 'learn_options', ')', '\\n']
Tokenized   (040): ['<s>', 'annot', 'ations', 'Ġ,', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '1', 'Ġ,', 'ĠX', 'df', '1', 'Ġ,', 'ĠY', '1', 'Ġ=', 'Ġread', '_', 'V', '1', '_', 'data', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['annot', 'ations', 'Ġ,', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġtarget', '_', 'gen', 'es', '1', 'Ġ,', 'ĠX', 'df', '1', 'Ġ,', 'ĠY', '1', 'Ġ=', 'Ġread', '_', 'V', '1', '_', 'data', 'Ġ(', 'Ġdata', '_', 'file', 'Ġ,', 'Ġlearn', '_', 'options', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['annotations', 'Ġ,', 'Ġgene_position1', 'Ġ,', 'Ġtarget_genes1', 'Ġ,', 'ĠXdf1', 'Ġ,', 'ĠY1', 'Ġ=', 'Ġread_V1_data', 'Ġ(', 'Ġdata_file', 'Ġ,', 'Ġlearn_options', 'Ġ)', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "Y_cols_to_keep = np . unique ( [ , , , \n"
Original    (011): ['Y_cols_to_keep', '=', 'np', '.', 'unique', '(', '[', ',', ',', ',', '\\n']
Tokenized   (021): ['<s>', 'Y', '_', 'col', 's', '_', 'to', '_', 'keep', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Y', '_', 'col', 's', '_', 'to', '_', 'keep', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['Y_cols_to_keep', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "gene_position = pandas . concat ( ( gene_position1 , gene_position2 ) ) \n"
Original    (013): ['gene_position', '=', 'pandas', '.', 'concat', '(', '(', 'gene_position1', ',', 'gene_position2', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'g', 'ene', '_', 'position', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġgene', '_', 'position', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['g', 'ene', '_', 'position', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'Ġconc', 'at', 'Ġ(', 'Ġ(', 'Ġgene', '_', 'position', '1', 'Ġ,', 'Ġgene', '_', 'position', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['gene_position', 'Ġ=', 'Ġpandas', 'Ġ.', 'Ġconcat', 'Ġ(', 'Ġ(', 'Ġgene_position1', 'Ġ,', 'Ġgene_position2', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "onedupind = np . where ( Y . index . duplicated ( ) ) [ 0 ] [ 0 ] \n"
Original    (021): ['onedupind', '=', 'np', '.', 'where', '(', 'Y', '.', 'index', '.', 'duplicated', '(', ')', ')', '[', '0', ']', '[', '0', ']', '\\n']
Tokenized   (027): ['<s>', 'oned', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġdupl', 'icated', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['oned', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġdupl', 'icated', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['onedupind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġduplicated', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "alldupind = np . where ( Y . index . get_level_values ( 0 ) . values == Y . index [ onedupind ] [ 0 ] ) [ 0 ] \n"
Original    (031): ['alldupind', '=', 'np', '.', 'where', '(', 'Y', '.', 'index', '.', 'get_level_values', '(', '0', ')', '.', 'values', '==', 'Y', '.', 'index', '[', 'onedupind', ']', '[', '0', ']', ')', '[', '0', ']', '\\n']
Tokenized   (044): ['<s>', 'al', 'ld', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġget', '_', 'level', '_', 'values', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ==', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['al', 'ld', 'up', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġget', '_', 'level', '_', 'values', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ==', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (031): ['alldupind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġwhere', 'Ġ(', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġget_level_values', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ.', 'Ġvalues', 'Ġ==', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "newindex [ onedupind ] = ( newindex [ onedupind ] [ 0 ] , newindex [ onedupind ] [ 1 ] , "nodrug2" ) \n"
Original    (025): ['newindex', '[', 'onedupind', ']', '=', '(', 'newindex', '[', 'onedupind', ']', '[', '0', ']', ',', 'newindex', '[', 'onedupind', ']', '[', '1', ']', ',', '"nodrug2"', ')', '\\n']
Tokenized   (045): ['<s>', 'new', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ"', 'n', 'od', 'rug', '2', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (043): ['new', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġnew', 'index', 'Ġ[', 'Ġon', 'ed', 'up', 'ind', 'Ġ]', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ"', 'n', 'od', 'rug', '2', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['newindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnewindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġnewindex', 'Ġ[', 'Ġonedupind', 'Ġ]', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ"nodrug2"', 'Ġ)', 'Ġ\\n']
Counter: 43
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "Xdf . index = pandas . MultiIndex . from_tuples ( newindex , names = Y . index . names ) \n"
Original    (021): ['Xdf', '.', 'index', '=', 'pandas', '.', 'MultiIndex', '.', 'from_tuples', '(', 'newindex', ',', 'names', '=', 'Y', '.', 'index', '.', 'names', ')', '\\n']
Tokenized   (031): ['<s>', 'X', 'df', 'Ġ.', 'Ġindex', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'ĠMulti', 'Index', 'Ġ.', 'Ġfrom', '_', 'tu', 'ples', 'Ġ(', 'Ġnew', 'index', 'Ġ,', 'Ġnames', 'Ġ=', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġnames', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['X', 'df', 'Ġ.', 'Ġindex', 'Ġ=', 'Ġpand', 'as', 'Ġ.', 'ĠMulti', 'Index', 'Ġ.', 'Ġfrom', '_', 'tu', 'ples', 'Ġ(', 'Ġnew', 'index', 'Ġ,', 'Ġnames', 'Ġ=', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġnames', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['Xdf', 'Ġ.', 'Ġindex', 'Ġ=', 'Ġpandas', 'Ġ.', 'ĠMultiIndex', 'Ġ.', 'Ġfrom_tuples', 'Ġ(', 'Ġnewindex', 'Ġ,', 'Ġnames', 'Ġ=', 'ĠY', 'Ġ.', 'Ġindex', 'Ġ.', 'Ġnames', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "mouse_genes = Xdf [ Xdf [ ] == ] [ ] . unique ( ) \n"
Original    (016): ['mouse_genes', '=', 'Xdf', '[', 'Xdf', '[', ']', '==', ']', '[', ']', '.', 'unique', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'mouse', '_', 'gen', 'es', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['mouse', '_', 'gen', 'es', 'Ġ=', 'ĠX', 'df', 'Ġ[', 'ĠX', 'df', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['mouse_genes', 'Ġ=', 'ĠXdf', 'Ġ[', 'ĠXdf', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġunique', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "all_genes = get_V3_genes ( None , None ) return np . setdiff1d ( all_genes , mouse_genes ) \n"
Original    (018): ['all_genes', '=', 'get_V3_genes', '(', 'None', ',', 'None', ')', 'return', 'np', '.', 'setdiff1d', '(', 'all_genes', ',', 'mouse_genes', ')', '\\n']
Tokenized   (039): ['<s>', 'all', '_', 'gen', 'es', 'Ġ=', 'Ġget', '_', 'V', '3', '_', 'gen', 'es', 'Ġ(', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġreturn', 'Ġnp', 'Ġ.', 'Ġset', 'diff', '1', 'd', 'Ġ(', 'Ġall', '_', 'gen', 'es', 'Ġ,', 'Ġmouse', '_', 'gen', 'es', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['all', '_', 'gen', 'es', 'Ġ=', 'Ġget', '_', 'V', '3', '_', 'gen', 'es', 'Ġ(', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġreturn', 'Ġnp', 'Ġ.', 'Ġset', 'diff', '1', 'd', 'Ġ(', 'Ġall', '_', 'gen', 'es', 'Ġ,', 'Ġmouse', '_', 'gen', 'es', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['all_genes', 'Ġ=', 'Ġget_V3_genes', 'Ġ(', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġreturn', 'Ġnp', 'Ġ.', 'Ġsetdiff1d', 'Ġ(', 'Ġall_genes', 'Ġ,', 'Ġmouse_genes', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "option_value = self . cfg . migrate [ self . option_name ] \n"
Original    (013): ['option_value', '=', 'self', '.', 'cfg', '.', 'migrate', '[', 'self', '.', 'option_name', ']', '\\n']
Tokenized   (021): ['<s>', 'option', '_', 'value', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcf', 'g', 'Ġ.', 'Ġmigrate', 'Ġ[', 'Ġself', 'Ġ.', 'Ġoption', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['option', '_', 'value', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcf', 'g', 'Ġ.', 'Ġmigrate', 'Ġ[', 'Ġself', 'Ġ.', 'Ġoption', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['option_value', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcfg', 'Ġ.', 'Ġmigrate', 'Ġ[', 'Ġself', 'Ġ.', 'Ġoption_name', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "search_opts_tenant = kwargs . get ( , { } ) \n"
Original    (011): ['search_opts_tenant', '=', 'kwargs', '.', 'get', '(', ',', '{', '}', ')', '\\n']
Tokenized   (022): ['<s>', 'search', '_', 'op', 'ts', '_', 'ten', 'ant', 'Ġ=', 'Ġk', 'w', 'args', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['search', '_', 'op', 'ts', '_', 'ten', 'ant', 'Ġ=', 'Ġk', 'w', 'args', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['search_opts_tenant', 'Ġ=', 'Ġkwargs', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tenants_without_quotas = self . get_tenants_without_quotas ( tenants_src , \n"
Original    (009): ['tenants_without_quotas', '=', 'self', '.', 'get_tenants_without_quotas', '(', 'tenants_src', ',', '\\n']
Tokenized   (030): ['<s>', 'ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ(', 'Ġtenants', '_', 'src', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'ten', 'ants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ(', 'Ġtenants', '_', 'src', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['tenants_without_quotas', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget_tenants_without_quotas', 'Ġ(', 'Ġtenants_src', 'Ġ,', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "quot = network_src . show_quota ( tenants_without_quotas [ 0 ] ) \n"
Original    (012): ['quot', '=', 'network_src', '.', 'show_quota', '(', 'tenants_without_quotas', '[', '0', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'qu', 'ot', 'Ġ=', 'Ġnetwork', '_', 'src', 'Ġ.', 'Ġshow', '_', 'qu', 'ota', 'Ġ(', 'Ġtenants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['qu', 'ot', 'Ġ=', 'Ġnetwork', '_', 'src', 'Ġ.', 'Ġshow', '_', 'qu', 'ota', 'Ġ(', 'Ġtenants', '_', 'without', '_', 'qu', 'ot', 'as', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['quot', 'Ġ=', 'Ġnetwork_src', 'Ġ.', 'Ġshow_quota', 'Ġ(', 'Ġtenants_without_quotas', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "quot_default_dst [ item_quot ] ) \n"
Original    (006): ['quot_default_dst', '[', 'item_quot', ']', ')', '\\n']
Tokenized   (018): ['<s>', 'qu', 'ot', '_', 'default', '_', 'd', 'st', 'Ġ[', 'Ġitem', '_', 'qu', 'ot', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['qu', 'ot', '_', 'default', '_', 'd', 'st', 'Ġ[', 'Ġitem', '_', 'qu', 'ot', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['quot_default_dst', 'Ġ[', 'Ġitem_quot', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "tenants = [ identity_src . keystone_client . tenants . find ( id = tnt_id ) for \n"
Original    (017): ['tenants', '=', '[', 'identity_src', '.', 'keystone_client', '.', 'tenants', '.', 'find', '(', 'id', '=', 'tnt_id', ')', 'for', '\\n']
Tokenized   (029): ['<s>', 'ten', 'ants', 'Ġ=', 'Ġ[', 'Ġidentity', '_', 'src', 'Ġ.', 'Ġkey', 'stone', '_', 'client', 'Ġ.', 'Ġtenants', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġid', 'Ġ=', 'Ġt', 'nt', '_', 'id', 'Ġ)', 'Ġfor', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['ten', 'ants', 'Ġ=', 'Ġ[', 'Ġidentity', '_', 'src', 'Ġ.', 'Ġkey', 'stone', '_', 'client', 'Ġ.', 'Ġtenants', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġid', 'Ġ=', 'Ġt', 'nt', '_', 'id', 'Ġ)', 'Ġfor', 'Ġ\\', 'n']
Detokenized (017): ['tenants', 'Ġ=', 'Ġ[', 'Ġidentity_src', 'Ġ.', 'Ġkeystone_client', 'Ġ.', 'Ġtenants', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġid', 'Ġ=', 'Ġtnt_id', 'Ġ)', 'Ġfor', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "tnt_id in filter_tenants_ids_list ] \n"
Original    (005): ['tnt_id', 'in', 'filter_tenants_ids_list', ']', '\\n']
Tokenized   (018): ['<s>', 't', 'nt', '_', 'id', 'Ġin', 'Ġfilter', '_', 'ten', 'ants', '_', 'ids', '_', 'list', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['t', 'nt', '_', 'id', 'Ġin', 'Ġfilter', '_', 'ten', 'ants', '_', 'ids', '_', 'list', 'Ġ]', 'Ġ\\', 'n']
Detokenized (005): ['tnt_id', 'Ġin', 'Ġfilter_tenants_ids_list', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "instance [ ] [ ] , instance [ ] [ ] ) \n"
Original    (013): ['instance', '[', ']', '[', ']', ',', 'instance', '[', ']', '[', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'instance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġinstance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['instance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġinstance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['instance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġinstance', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "vol [ ] , storage_resource . get_status , , \n"
Original    (010): ['vol', '[', ']', ',', 'storage_resource', '.', 'get_status', ',', ',', '\\n']
Tokenized   (017): ['<s>', 'vol', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġstorage', '_', 'resource', 'Ġ.', 'Ġget', '_', 'status', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['vol', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġstorage', '_', 'resource', 'Ġ.', 'Ġget', '_', 'status', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['vol', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġstorage_resource', 'Ġ.', 'Ġget_status', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "inst_name = libvirt_instance_name ) ) \n"
Original    (006): ['inst_name', '=', 'libvirt_instance_name', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'inst', '_', 'name', 'Ġ=', 'Ġlib', 'virt', '_', 'instance', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['inst', '_', 'name', 'Ġ=', 'Ġlib', 'virt', '_', 'instance', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['inst_name', 'Ġ=', 'Ġlibvirt_instance_name', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "dst = instance_image_path ( instance_id ) ) \n"
Original    (008): ['dst', '=', 'instance_image_path', '(', 'instance_id', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'd', 'st', 'Ġ=', 'Ġinstance', '_', 'image', '_', 'path', 'Ġ(', 'Ġinstance', '_', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['d', 'st', 'Ġ=', 'Ġinstance', '_', 'image', '_', 'path', 'Ġ(', 'Ġinstance', '_', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['dst', 'Ġ=', 'Ġinstance_image_path', 'Ġ(', 'Ġinstance_id', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "interface . find ( ) ) \n"
Original    (007): ['interface', '.', 'find', '(', ')', ')', '\\n']
Tokenized   (010): ['<s>', 'interface', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['interface', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['interface', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "mac = self . mac , src = self . source_iface , dst = self . target_iface ) \n"
Original    (019): ['mac', '=', 'self', '.', 'mac', ',', 'src', '=', 'self', '.', 'source_iface', ',', 'dst', '=', 'self', '.', 'target_iface', ')', '\\n']
Tokenized   (028): ['<s>', 'mac', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmac', 'Ġ,', 'Ġsrc', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsource', '_', 'if', 'ace', 'Ġ,', 'Ġdst', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtarget', '_', 'if', 'ace', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['mac', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmac', 'Ġ,', 'Ġsrc', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsource', '_', 'if', 'ace', 'Ġ,', 'Ġdst', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtarget', '_', 'if', 'ace', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['mac', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmac', 'Ġ,', 'Ġsrc', 'Ġ=', 'Ġself', 'Ġ.', 'Ġsource_iface', 'Ġ,', 'Ġdst', 'Ġ=', 'Ġself', 'Ġ.', 'Ġtarget_iface', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "element . attrib = { attr : value } \n"
Original    (010): ['element', '.', 'attrib', '=', '{', 'attr', ':', 'value', '}', '\\n']
Tokenized   (015): ['<s>', 'element', 'Ġ.', 'Ġatt', 'rib', 'Ġ=', 'Ġ{', 'Ġatt', 'r', 'Ġ:', 'Ġvalue', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['element', 'Ġ.', 'Ġatt', 'rib', 'Ġ=', 'Ġ{', 'Ġatt', 'r', 'Ġ:', 'Ġvalue', 'Ġ}', 'Ġ\\', 'n']
Detokenized (010): ['element', 'Ġ.', 'Ġattrib', 'Ġ=', 'Ġ{', 'Ġattr', 'Ġ:', 'Ġvalue', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "rr . run ( copy . format ( src_file = source_object . path , \n"
Original    (015): ['rr', '.', 'run', '(', 'copy', '.', 'format', '(', 'src_file', '=', 'source_object', '.', 'path', ',', '\\n']
Tokenized   (022): ['<s>', 'rr', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġcopy', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġsrc', '_', 'file', 'Ġ=', 'Ġsource', '_', 'object', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['rr', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġcopy', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġsrc', '_', 'file', 'Ġ=', 'Ġsource', '_', 'object', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['rr', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġcopy', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġsrc_file', 'Ġ=', 'Ġsource_object', 'Ġ.', 'Ġpath', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "max_bytes = sizeof_format . parse_size ( kwargs . pop ( , 0 ) ) \n"
Original    (015): ['max_bytes', '=', 'sizeof_format', '.', 'parse_size', '(', 'kwargs', '.', 'pop', '(', ',', '0', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'max', '_', 'bytes', 'Ġ=', 'Ġsizeof', '_', 'format', 'Ġ.', 'Ġparse', '_', 'size', 'Ġ(', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['max', '_', 'bytes', 'Ġ=', 'Ġsizeof', '_', 'format', 'Ġ.', 'Ġparse', '_', 'size', 'Ġ(', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['max_bytes', 'Ġ=', 'Ġsizeof_format', 'Ġ.', 'Ġparse_size', 'Ġ(', 'Ġkwargs', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "scenario = os . path . splitext ( scenario_filename ) [ 0 ] \n"
Original    (014): ['scenario', '=', 'os', '.', 'path', '.', 'splitext', '(', 'scenario_filename', ')', '[', '0', ']', '\\n']
Tokenized   (022): ['<s>', 'sc', 'enario', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġscenario', '_', 'filename', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['sc', 'enario', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġspl', 'ite', 'xt', 'Ġ(', 'Ġscenario', '_', 'filename', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['scenario', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplitext', 'Ġ(', 'Ġscenario_filename', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "file_name = config . rollback_params [ ] [ ] \n"
Original    (010): ['file_name', '=', 'config', '.', 'rollback_params', '[', ']', '[', ']', '\\n']
Tokenized   (018): ['<s>', 'file', '_', 'name', 'Ġ=', 'Ġconfig', 'Ġ.', 'Ġroll', 'back', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['file', '_', 'name', 'Ġ=', 'Ġconfig', 'Ġ.', 'Ġroll', 'back', '_', 'params', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['file_name', 'Ġ=', 'Ġconfig', 'Ġ.', 'Ġrollback_params', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "pre_file_path = os . path . join ( self . cloudferry_dir , file_name ) \n"
Original    (015): ['pre_file_path', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'cloudferry_dir', ',', 'file_name', ')', '\\n']
Tokenized   (028): ['<s>', 'pre', '_', 'file', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcloud', 'fer', 'ry', '_', 'dir', 'Ġ,', 'Ġfile', '_', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['pre', '_', 'file', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcloud', 'fer', 'ry', '_', 'dir', 'Ġ,', 'Ġfile', '_', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['pre_file_path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcloudferry_dir', 'Ġ,', 'Ġfile_name', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "o2 = C ( 2 ) \n"
Original    (007): ['o2', '=', 'C', '(', '2', ')', '\\n']
Tokenized   (011): ['<s>', 'o', '2', 'Ġ=', 'ĠC', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['o', '2', 'Ġ=', 'ĠC', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['o2', 'Ġ=', 'ĠC', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "org_tag = request . user . get_profile ( ) . org_tag \n"
Original    (012): ['org_tag', '=', 'request', '.', 'user', '.', 'get_profile', '(', ')', '.', 'org_tag', '\\n']
Tokenized   (021): ['<s>', 'org', '_', 'tag', 'Ġ=', 'Ġrequest', 'Ġ.', 'Ġuser', 'Ġ.', 'Ġget', '_', 'profile', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorg', '_', 'tag', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['org', '_', 'tag', 'Ġ=', 'Ġrequest', 'Ġ.', 'Ġuser', 'Ġ.', 'Ġget', '_', 'profile', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorg', '_', 'tag', 'Ġ\\', 'n']
Detokenized (012): ['org_tag', 'Ġ=', 'Ġrequest', 'Ġ.', 'Ġuser', 'Ġ.', 'Ġget_profile', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorg_tag', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "featureset = Recording . objects . filter ( lat__lt = ne_lat , lat__gt = sw_lat , lon__lt = ne_lon , lon__gt = sw_lon \n"
Original    (024): ['featureset', '=', 'Recording', '.', 'objects', '.', 'filter', '(', 'lat__lt', '=', 'ne_lat', ',', 'lat__gt', '=', 'sw_lat', ',', 'lon__lt', '=', 'ne_lon', ',', 'lon__gt', '=', 'sw_lon', '\\n']
Tokenized   (046): ['<s>', 'features', 'et', 'Ġ=', 'ĠRecording', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġlat', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lat', 'Ġ,', 'Ġlat', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lat', 'Ġ,', 'Ġl', 'on', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lon', 'Ġ,', 'Ġl', 'on', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lon', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['features', 'et', 'Ġ=', 'ĠRecording', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġlat', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lat', 'Ġ,', 'Ġlat', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lat', 'Ġ,', 'Ġl', 'on', '__', 'lt', 'Ġ=', 'Ġne', '_', 'lon', 'Ġ,', 'Ġl', 'on', '__', 'gt', 'Ġ=', 'Ġsw', '_', 'lon', 'Ġ\\', 'n']
Detokenized (024): ['featureset', 'Ġ=', 'ĠRecording', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġlat__lt', 'Ġ=', 'Ġne_lat', 'Ġ,', 'Ġlat__gt', 'Ġ=', 'Ġsw_lat', 'Ġ,', 'Ġlon__lt', 'Ġ=', 'Ġne_lon', 'Ġ,', 'Ġlon__gt', 'Ġ=', 'Ġsw_lon', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "httpresponse_kwargs = { : kwargs . pop ( , None ) } \n"
Original    (013): ['httpresponse_kwargs', '=', '{', ':', 'kwargs', '.', 'pop', '(', ',', 'None', ')', '}', '\\n']
Tokenized   (022): ['<s>', 'http', 'response', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['http', 'response', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġk', 'w', 'args', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (013): ['httpresponse_kwargs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġkwargs', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_testing = in sys . argv \n"
Original    (007): ['is_testing', '=', 'in', 'sys', '.', 'argv', '\\n']
Tokenized   (013): ['<s>', 'is', '_', 'testing', 'Ġ=', 'Ġin', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['is', '_', 'testing', 'Ġ=', 'Ġin', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ\\', 'n']
Detokenized (007): ['is_testing', 'Ġ=', 'Ġin', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "up_time = end_time - self . start_time \n"
Original    (008): ['up_time', '=', 'end_time', '-', 'self', '.', 'start_time', '\\n']
Tokenized   (017): ['<s>', 'up', '_', 'time', 'Ġ=', 'Ġend', '_', 'time', 'Ġ-', 'Ġself', 'Ġ.', 'Ġstart', '_', 'time', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['up', '_', 'time', 'Ġ=', 'Ġend', '_', 'time', 'Ġ-', 'Ġself', 'Ġ.', 'Ġstart', '_', 'time', 'Ġ\\', 'n']
Detokenized (008): ['up_time', 'Ġ=', 'Ġend_time', 'Ġ-', 'Ġself', 'Ġ.', 'Ġstart_time', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "remaining_time = self . count_down_total - datetime . timedelta ( seconds = ( int ( up_time ) ) ) \n"
Original    (020): ['remaining_time', '=', 'self', '.', 'count_down_total', '-', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '(', 'int', '(', 'up_time', ')', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'rem', 'aining', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcount', '_', 'down', '_', 'total', 'Ġ-', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġup', '_', 'time', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['rem', 'aining', '_', 'time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcount', '_', 'down', '_', 'total', 'Ġ-', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġup', '_', 'time', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['remaining_time', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcount_down_total', 'Ġ-', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġup_time', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "abort_time = time . time ( ) + timeout \n"
Original    (010): ['abort_time', '=', 'time', '.', 'time', '(', ')', '+', 'timeout', '\\n']
Tokenized   (016): ['<s>', 'ab', 'ort', '_', 'time', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġtimeout', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['ab', 'ort', '_', 'time', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġtimeout', 'Ġ\\', 'n']
Detokenized (010): ['abort_time', 'Ġ=', 'Ġtime', 'Ġ.', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġtimeout', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "elif not stanza . getID ( ) : \n"
Original    (009): ['elif', 'not', 'stanza', '.', 'getID', '(', ')', ':', '\\n']
Tokenized   (015): ['<s>', 'el', 'if', 'Ġnot', 'Ġst', 'anza', 'Ġ.', 'Ġget', 'ID', 'Ġ(', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['el', 'if', 'Ġnot', 'Ġst', 'anza', 'Ġ.', 'Ġget', 'ID', 'Ġ(', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (009): ['elif', 'Ġnot', 'Ġstanza', 'Ġ.', 'ĠgetID', 'Ġ(', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_ID = ` ID ` \n"
Original    (006): ['_ID', '=', '`', 'ID', '`', '\\n']
Tokenized   (010): ['<s>', '_', 'ID', 'Ġ=', 'Ġ`', 'ĠID', 'Ġ`', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['_', 'ID', 'Ġ=', 'Ġ`', 'ĠID', 'Ġ`', 'Ġ\\', 'n']
Detokenized (006): ['_ID', 'Ġ=', 'Ġ`', 'ĠID', 'Ġ`', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "__description__ = , \n"
Original    (004): ['__description__', '=', ',', '\\n']
Tokenized   (009): ['<s>', '__', 'description', '__', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['__', 'description', '__', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['__description__', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "REQUIRES = [ i . strip ( ) for i in open ( "requirements.txt" ) . readlines ( ) ] \n"
Original    (021): ['REQUIRES', '=', '[', 'i', '.', 'strip', '(', ')', 'for', 'i', 'in', 'open', '(', '"requirements.txt"', ')', '.', 'readlines', '(', ')', ']', '\\n']
Tokenized   (033): ['<s>', 'RE', 'QU', 'IR', 'ES', 'Ġ=', 'Ġ[', 'Ġi', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġi', 'Ġin', 'Ġopen', 'Ġ(', 'Ġ"', 'requ', 'irements', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'lines', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['RE', 'QU', 'IR', 'ES', 'Ġ=', 'Ġ[', 'Ġi', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġi', 'Ġin', 'Ġopen', 'Ġ(', 'Ġ"', 'requ', 'irements', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'lines', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['REQUIRES', 'Ġ=', 'Ġ[', 'Ġi', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġi', 'Ġin', 'Ġopen', 'Ġ(', 'Ġ"requirements.txt"', 'Ġ)', 'Ġ.', 'Ġreadlines', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "BaseField . __init__ ( self , ** kwargs ) \n"
Original    (010): ['BaseField', '.', '__init__', '(', 'self', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (018): ['<s>', 'Base', 'Field', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['Base', 'Field', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['BaseField', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "is_list = not hasattr ( items , ) \n"
Original    (009): ['is_list', '=', 'not', 'hasattr', '(', 'items', ',', ')', '\\n']
Tokenized   (015): ['<s>', 'is', '_', 'list', 'Ġ=', 'Ġnot', 'Ġhas', 'attr', 'Ġ(', 'Ġitems', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['is', '_', 'list', 'Ġ=', 'Ġnot', 'Ġhas', 'attr', 'Ġ(', 'Ġitems', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['is_list', 'Ġ=', 'Ġnot', 'Ġhasattr', 'Ġ(', 'Ġitems', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "object_map [ ( collection , doc . id ) ] = doc \n"
Original    (013): ['object_map', '[', '(', 'collection', ',', 'doc', '.', 'id', ')', ']', '=', 'doc', '\\n']
Tokenized   (018): ['<s>', 'object', '_', 'map', 'Ġ[', 'Ġ(', 'Ġcollection', 'Ġ,', 'Ġdoc', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġdoc', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['object', '_', 'map', 'Ġ[', 'Ġ(', 'Ġcollection', 'Ġ,', 'Ġdoc', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġdoc', 'Ġ\\', 'n']
Detokenized (013): ['object_map', 'Ġ[', 'Ġ(', 'Ġcollection', 'Ġ,', 'Ġdoc', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ=', 'Ġdoc', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "_cls = doc . _data . pop ( , None ) \n"
Original    (012): ['_cls', '=', 'doc', '.', '_data', '.', 'pop', '(', ',', 'None', ')', '\\n']
Tokenized   (018): ['<s>', '_', 'cl', 's', 'Ġ=', 'Ġdoc', 'Ġ.', 'Ġ_', 'data', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['_', 'cl', 's', 'Ġ=', 'Ġdoc', 'Ġ.', 'Ġ_', 'data', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['_cls', 'Ġ=', 'Ġdoc', 'Ġ.', 'Ġ_data', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "81.4471435546875 , \n"
Original    (003): ['81.4471435546875', ',', '\\n']
Tokenized   (013): ['<s>', '81', '.', '447', '14', '35', '54', '68', '75', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['81', '.', '447', '14', '35', '54', '68', '75', 'Ġ,', 'Ġ\\', 'n']
Detokenized (003): ['81.4471435546875', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "23.61432859499169 \n"
Original    (002): ['23.61432859499169', '\\n']
Tokenized   (012): ['<s>', '23', '.', '6', '143', '28', '59', '499', '169', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['23', '.', '6', '143', '28', '59', '499', '169', 'Ġ\\', 'n']
Detokenized (002): ['23.61432859499169', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 2, 768)
# Extracted words:  2
Sentence         : "invalid_coords = [ [ [ [ 1 , 2 ] , [ 3 , 4 ] ] ] ] \n"
Original    (020): ['invalid_coords', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ']', ']', ']', '\\n']
Tokenized   (027): ['<s>', 'in', 'valid', '_', 'co', 'ords', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['in', 'valid', '_', 'co', 'ords', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (020): ['invalid_coords', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "Location ( loc = [ [ [ [ 1 , 2 ] , [ 3 , 4 ] , [ 5 , 6 ] , [ 1 , 2 ] ] ] ] ) . validate ( ) \n"
Original    (039): ['Location', '(', 'loc', '=', '[', '[', '[', '[', '1', ',', '2', ']', ',', '[', '3', ',', '4', ']', ',', '[', '5', ',', '6', ']', ',', '[', '1', ',', '2', ']', ']', ']', ']', ')', '.', 'validate', '(', ')', '\\n']
Tokenized   (042): ['<s>', 'Location', 'Ġ(', 'Ġloc', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ5', 'Ġ,', 'Ġ6', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['Location', 'Ġ(', 'Ġloc', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ5', 'Ġ,', 'Ġ6', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (039): ['Location', 'Ġ(', 'Ġloc', 'Ġ=', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ4', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ5', 'Ġ,', 'Ġ6', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġvalidate', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 39, 768)
# Extracted words:  39
Sentence         : "Parent ( name = ) . save ( ) \n"
Original    (010): ['Parent', '(', 'name', '=', ')', '.', 'save', '(', ')', '\\n']
Tokenized   (013): ['<s>', 'Parent', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['Parent', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['Parent', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "echo_payload = Struct ( "echo_payload" , \n"
Original    (007): ['echo_payload', '=', 'Struct', '(', '"echo_payload"', ',', '\\n']
Tokenized   (018): ['<s>', 'echo', '_', 'pay', 'load', 'Ġ=', 'ĠStruct', 'Ġ(', 'Ġ"', 'echo', '_', 'pay', 'load', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['echo', '_', 'pay', 'load', 'Ġ=', 'ĠStruct', 'Ġ(', 'Ġ"', 'echo', '_', 'pay', 'load', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['echo_payload', 'Ġ=', 'ĠStruct', 'Ġ(', 'Ġ"echo_payload"', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Padding ( 2 ) , \n"
Original    (006): ['Padding', '(', '2', ')', ',', '\\n']
Tokenized   (010): ['<s>', 'P', 'adding', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['P', 'adding', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['Padding', 'Ġ(', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "IpAddress ( "host" ) , \n"
Original    (006): ['IpAddress', '(', '"host"', ')', ',', '\\n']
Tokenized   (013): ['<s>', 'I', 'p', 'Address', 'Ġ(', 'Ġ"', 'host', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['I', 'p', 'Address', 'Ġ(', 'Ġ"', 'host', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['IpAddress', 'Ġ(', 'Ġ"host"', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "Bytes ( "echo" , 8 ) , \n"
Original    (008): ['Bytes', '(', '"echo"', ',', '8', ')', ',', '\\n']
Tokenized   (013): ['<s>', 'Bytes', 'Ġ(', 'Ġ"', 'echo', '"', 'Ġ,', 'Ġ8', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['Bytes', 'Ġ(', 'Ġ"', 'echo', '"', 'Ġ,', 'Ġ8', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['Bytes', 'Ġ(', 'Ġ"echo"', 'Ġ,', 'Ġ8', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "dest_unreachable_code = Enum ( Byte ( "code" ) , \n"
Original    (010): ['dest_unreachable_code', '=', 'Enum', '(', 'Byte', '(', '"code"', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'dest', '_', 'un', 'reach', 'able', '_', 'code', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'code', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['dest', '_', 'un', 'reach', 'able', '_', 'code', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'code', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['dest_unreachable_code', 'Ġ=', 'ĠEnum', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"code"', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "Enum ( Byte ( "type" ) , \n"
Original    (008): ['Enum', '(', 'Byte', '(', '"type"', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'En', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'type', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['En', 'um', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"', 'type', '"', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['Enum', 'Ġ(', 'ĠByte', 'Ġ(', 'Ġ"type"', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Switch ( "payload" , lambda ctx : ctx . type , \n"
Original    (012): ['Switch', '(', '"payload"', ',', 'lambda', 'ctx', ':', 'ctx', '.', 'type', ',', '\\n']
Tokenized   (020): ['<s>', 'Switch', 'Ġ(', 'Ġ"', 'pay', 'load', '"', 'Ġ,', 'Ġlambda', 'Ġc', 'tx', 'Ġ:', 'Ġc', 'tx', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['Switch', 'Ġ(', 'Ġ"', 'pay', 'load', '"', 'Ġ,', 'Ġlambda', 'Ġc', 'tx', 'Ġ:', 'Ġc', 'tx', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['Switch', 'Ġ(', 'Ġ"payload"', 'Ġ,', 'Ġlambda', 'Ġctx', 'Ġ:', 'Ġctx', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""63646566676869" ) . decode ( "hex" ) \n"
Original    (008): ['"63646566676869"', ')', '.', 'decode', '(', '"hex"', ')', '\\n']
Tokenized   (021): ['<s>', '"', '63', '64', '65', '66', '67', '68', '69', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['"', '63', '64', '65', '66', '67', '68', '69', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['"63646566676869"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"hex"', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "cap2 = ( "0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162" \n"
Original    (005): ['cap2', '=', '(', '"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', '\\n']
Tokenized   (044): ['<s>', 'cap', '2', 'Ġ=', 'Ġ(', 'Ġ"', '0000', '385', 'c', '0', '2001', 'b', '006', '16', '26', '364', '65', '66', '67', '68', '696', 'a', '6', 'b', '6', 'c', '6', 'd', '6', 'e', '6', 'f', '707', '17', '27', '374', '75', '767', '76', '162', '"', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['cap', '2', 'Ġ=', 'Ġ(', 'Ġ"', '0000', '385', 'c', '0', '2001', 'b', '006', '16', '26', '364', '65', '66', '67', '68', '696', 'a', '6', 'b', '6', 'c', '6', 'd', '6', 'e', '6', 'f', '707', '17', '27', '374', '75', '767', '76', '162', '"', 'Ġ\\', 'n']
Detokenized (005): ['cap2', 'Ġ=', 'Ġ(', 'Ġ"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "cap3 = ( "0301000000001122aabbccdd0102030405060708" ) . decode ( "hex" ) \n"
Original    (011): ['cap3', '=', '(', '"0301000000001122aabbccdd0102030405060708"', ')', '.', 'decode', '(', '"hex"', ')', '\\n']
Tokenized   (034): ['<s>', 'cap', '3', 'Ġ=', 'Ġ(', 'Ġ"', '03', '01', '00000000', '112', '2', 'a', 'abb', 'cc', 'dd', '010', '20', '30', '40', '50', '60', '708', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['cap', '3', 'Ġ=', 'Ġ(', 'Ġ"', '03', '01', '00000000', '112', '2', 'a', 'abb', 'cc', 'dd', '010', '20', '30', '40', '50', '60', '708', '"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'hex', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['cap3', 'Ġ=', 'Ġ(', 'Ġ"0301000000001122aabbccdd0102030405060708"', 'Ġ)', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"hex"', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "intps [ ] = dest_target . vlan \n"
Original    (008): ['intps', '[', ']', '=', 'dest_target', '.', 'vlan', '\\n']
Tokenized   (015): ['<s>', 'int', 'ps', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdest', '_', 'target', 'Ġ.', 'Ġv', 'lan', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['int', 'ps', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdest', '_', 'target', 'Ġ.', 'Ġv', 'lan', 'Ġ\\', 'n']
Detokenized (008): ['intps', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdest_target', 'Ġ.', 'Ġvlan', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "router , interface = ri . split ( ) \n"
Original    (010): ['router', ',', 'interface', '=', 'ri', '.', 'split', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'rou', 'ter', 'Ġ,', 'Ġinterface', 'Ġ=', 'Ġr', 'i', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['rou', 'ter', 'Ġ,', 'Ġinterface', 'Ġ=', 'Ġr', 'i', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['router', 'Ġ,', 'Ġinterface', 'Ġ=', 'Ġri', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "cm = NCSVPNConnectionManager ( ncs_services_url , user , password , port_map , name ) \n"
Original    (015): ['cm', '=', 'NCSVPNConnectionManager', '(', 'ncs_services_url', ',', 'user', ',', 'password', ',', 'port_map', ',', 'name', ')', '\\n']
Tokenized   (029): ['<s>', 'cm', 'Ġ=', 'ĠN', 'CS', 'VPN', 'Connection', 'Manager', 'Ġ(', 'Ġn', 'cs', '_', 'services', '_', 'url', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġpassword', 'Ġ,', 'Ġport', '_', 'map', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['cm', 'Ġ=', 'ĠN', 'CS', 'VPN', 'Connection', 'Manager', 'Ġ(', 'Ġn', 'cs', '_', 'services', '_', 'url', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġpassword', 'Ġ,', 'Ġport', '_', 'map', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['cm', 'Ġ=', 'ĠNCSVPNConnectionManager', 'Ġ(', 'Ġncs_services_url', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġpassword', 'Ġ,', 'Ġport_map', 'Ġ,', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "soap_resource . registerDecoder ( actions . QUERY_RECURSIVE , self . queryRecursive ) \n"
Original    (013): ['soap_resource', '.', 'registerDecoder', '(', 'actions', '.', 'QUERY_RECURSIVE', ',', 'self', '.', 'queryRecursive', ')', '\\n']
Tokenized   (029): ['<s>', 'so', 'ap', '_', 'resource', 'Ġ.', 'Ġregister', 'Dec', 'oder', 'Ġ(', 'Ġactions', 'Ġ.', 'ĠQU', 'ERY', '_', 'REC', 'UR', 'S', 'IVE', 'Ġ,', 'Ġself', 'Ġ.', 'Ġquery', 'Rec', 'ursive', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['so', 'ap', '_', 'resource', 'Ġ.', 'Ġregister', 'Dec', 'oder', 'Ġ(', 'Ġactions', 'Ġ.', 'ĠQU', 'ERY', '_', 'REC', 'UR', 'S', 'IVE', 'Ġ,', 'Ġself', 'Ġ.', 'Ġquery', 'Rec', 'ursive', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['soap_resource', 'Ġ.', 'ĠregisterDecoder', 'Ġ(', 'Ġactions', 'Ġ.', 'ĠQUERY_RECURSIVE', 'Ġ,', 'Ġself', 'Ġ.', 'ĠqueryRecursive', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "soap_fault = soapresource . SOAPFault ( err . getErrorMessage ( ) , ex_element ) \n"
Original    (015): ['soap_fault', '=', 'soapresource', '.', 'SOAPFault', '(', 'err', '.', 'getErrorMessage', '(', ')', ',', 'ex_element', ')', '\\n']
Tokenized   (030): ['<s>', 'so', 'ap', '_', 'f', 'ault', 'Ġ=', 'Ġsoap', 'resource', 'Ġ.', 'ĠSO', 'AP', 'F', 'ault', 'Ġ(', 'Ġerr', 'Ġ.', 'Ġget', 'Error', 'Message', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġex', '_', 'element', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['so', 'ap', '_', 'f', 'ault', 'Ġ=', 'Ġsoap', 'resource', 'Ġ.', 'ĠSO', 'AP', 'F', 'ault', 'Ġ(', 'Ġerr', 'Ġ.', 'Ġget', 'Error', 'Message', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġex', '_', 'element', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['soap_fault', 'Ġ=', 'Ġsoapresource', 'Ġ.', 'ĠSOAPFault', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠgetErrorMessage', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġex_element', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "symmetric = p2ps . symmetricPath or False sd = nsa . Point2PointService ( src_stp , dst_stp , p2ps . capacity , p2ps . directionality , symmetric , \n"
Original    (028): ['symmetric', '=', 'p2ps', '.', 'symmetricPath', 'or', 'False', 'sd', '=', 'nsa', '.', 'Point2PointService', '(', 'src_stp', ',', 'dst_stp', ',', 'p2ps', '.', 'capacity', ',', 'p2ps', '.', 'directionality', ',', 'symmetric', ',', '\\n']
Tokenized   (053): ['<s>', 'sy', 'mm', 'etric', 'Ġ=', 'Ġp', '2', 'ps', 'Ġ.', 'Ġsymm', 'etric', 'Path', 'Ġor', 'ĠFalse', 'Ġsd', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠPoint', '2', 'Point', 'Service', 'Ġ(', 'Ġsrc', '_', 'st', 'p', 'Ġ,', 'Ġdst', '_', 'st', 'p', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġcapacity', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġdirection', 'ality', 'Ġ,', 'Ġsymm', 'etric', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (051): ['sy', 'mm', 'etric', 'Ġ=', 'Ġp', '2', 'ps', 'Ġ.', 'Ġsymm', 'etric', 'Path', 'Ġor', 'ĠFalse', 'Ġsd', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠPoint', '2', 'Point', 'Service', 'Ġ(', 'Ġsrc', '_', 'st', 'p', 'Ġ,', 'Ġdst', '_', 'st', 'p', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġcapacity', 'Ġ,', 'Ġp', '2', 'ps', 'Ġ.', 'Ġdirection', 'ality', 'Ġ,', 'Ġsymm', 'etric', 'Ġ,', 'Ġ\\', 'n']
Detokenized (028): ['symmetric', 'Ġ=', 'Ġp2ps', 'Ġ.', 'ĠsymmetricPath', 'Ġor', 'ĠFalse', 'Ġsd', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠPoint2PointService', 'Ġ(', 'Ġsrc_stp', 'Ġ,', 'Ġdst_stp', 'Ġ,', 'Ġp2ps', 'Ġ.', 'Ġcapacity', 'Ġ,', 'Ġp2ps', 'Ġ.', 'Ġdirectionality', 'Ġ,', 'Ġsymmetric', 'Ġ,', 'Ġ\\n']
Counter: 51
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "crt = nsa . Criteria ( criteria . version , schedule , sd ) \n"
Original    (015): ['crt', '=', 'nsa', '.', 'Criteria', '(', 'criteria', '.', 'version', ',', 'schedule', ',', 'sd', ')', '\\n']
Tokenized   (021): ['<s>', 'cr', 't', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠCrit', 'eria', 'Ġ(', 'Ġcriteria', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġschedule', 'Ġ,', 'Ġsd', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['cr', 't', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠCrit', 'eria', 'Ġ(', 'Ġcriteria', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġschedule', 'Ġ,', 'Ġsd', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['crt', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠCriteria', 'Ġ(', 'Ġcriteria', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġschedule', 'Ġ,', 'Ġsd', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tc = json . load ( open ( tcf ) ) \n"
Original    (012): ['tc', '=', 'json', '.', 'load', '(', 'open', '(', 'tcf', ')', ')', '\\n']
Tokenized   (016): ['<s>', 'tc', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġt', 'cf', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['tc', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġt', 'cf', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['tc', 'Ġ=', 'Ġjson', 'Ġ.', 'Ġload', 'Ġ(', 'Ġopen', 'Ġ(', 'Ġtcf', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "source_stp = nsa . STP ( , , labels = [ nsa . Label ( nml . ETHERNET_VLAN , dest_stp = nsa . STP ( , , labels = [ nsa . Label ( nml . ETHERNET_VLAN , start_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = 2 ) \n"
Original    (057): ['source_stp', '=', 'nsa', '.', 'STP', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'Label', '(', 'nml', '.', 'ETHERNET_VLAN', ',', 'dest_stp', '=', 'nsa', '.', 'STP', '(', ',', ',', 'labels', '=', '[', 'nsa', '.', 'Label', '(', 'nml', '.', 'ETHERNET_VLAN', ',', 'start_time', '=', 'datetime', '.', 'datetime', '.', 'utcnow', '(', ')', '+', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '2', ')', '\\n']
Tokenized   (092): ['<s>', 'source', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġdest', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġstart', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (090): ['source', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġdest', '_', 'st', 'p', 'Ġ=', 'Ġn', 'sa', 'Ġ.', 'ĠST', 'P', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġn', 'sa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġn', 'ml', 'Ġ.', 'ĠE', 'THER', 'NET', '_', 'V', 'LAN', 'Ġ,', 'Ġstart', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (057): ['source_stp', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠSTP', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġnsa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġnml', 'Ġ.', 'ĠETHERNET_VLAN', 'Ġ,', 'Ġdest_stp', 'Ġ=', 'Ġnsa', 'Ġ.', 'ĠSTP', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġlabels', 'Ġ=', 'Ġ[', 'Ġnsa', 'Ġ.', 'ĠLabel', 'Ġ(', 'Ġnml', 'Ġ.', 'ĠETHERNET_VLAN', 'Ġ,', 'Ġstart_time', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġdatetime', 'Ġ.', 'Ġutcnow', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 90
===================================================================
Hidden states:  (13, 57, 768)
# Extracted words:  57
Sentence         : "end_time = datetime . datetime . utcnow ( ) + datetime . timedelta ( seconds = 30 ) \n"
Original    (019): ['end_time', '=', 'datetime', '.', 'datetime', '.', 'utcnow', '(', ')', '+', 'datetime', '.', 'timedelta', '(', 'seconds', '=', '30', ')', '\\n']
Tokenized   (030): ['<s>', 'end', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ30', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['end', '_', 'time', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġdat', 'etime', 'Ġ.', 'Ġut', 'c', 'now', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdat', 'etime', 'Ġ.', 'Ġtimed', 'elta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ30', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['end_time', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġdatetime', 'Ġ.', 'Ġutcnow', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġdatetime', 'Ġ.', 'Ġtimedelta', 'Ġ(', 'Ġseconds', 'Ġ=', 'Ġ30', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "connection_id , active , version_consistent , version , timestamp = yield d_down \n"
Original    (013): ['connection_id', ',', 'active', ',', 'version_consistent', ',', 'version', ',', 'timestamp', '=', 'yield', 'd_down', '\\n']
Tokenized   (023): ['<s>', 'connection', '_', 'id', 'Ġ,', 'Ġactive', 'Ġ,', 'Ġversion', '_', 'cons', 'istent', 'Ġ,', 'Ġversion', 'Ġ,', 'Ġtimestamp', 'Ġ=', 'Ġyield', 'Ġd', '_', 'down', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['connection', '_', 'id', 'Ġ,', 'Ġactive', 'Ġ,', 'Ġversion', '_', 'cons', 'istent', 'Ġ,', 'Ġversion', 'Ġ,', 'Ġtimestamp', 'Ġ=', 'Ġyield', 'Ġd', '_', 'down', 'Ġ\\', 'n']
Detokenized (013): ['connection_id', 'Ġ,', 'Ġactive', 'Ġ,', 'Ġversion_consistent', 'Ġ,', 'Ġversion', 'Ġ,', 'Ġtimestamp', 'Ġ=', 'Ġyield', 'Ġd_down', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "scheduler = digits . scheduler . Scheduler ( config_value ( ) , True ) \n"
Original    (015): ['scheduler', '=', 'digits', '.', 'scheduler', '.', 'Scheduler', '(', 'config_value', '(', ')', ',', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'sc', 'hed', 'uler', 'Ġ=', 'Ġdigits', 'Ġ.', 'Ġsched', 'uler', 'Ġ.', 'ĠSched', 'uler', 'Ġ(', 'Ġconfig', '_', 'value', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['sc', 'hed', 'uler', 'Ġ=', 'Ġdigits', 'Ġ.', 'Ġsched', 'uler', 'Ġ.', 'ĠSched', 'uler', 'Ġ(', 'Ġconfig', '_', 'value', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['scheduler', 'Ġ=', 'Ġdigits', 'Ġ.', 'Ġscheduler', 'Ġ.', 'ĠScheduler', 'Ġ(', 'Ġconfig_value', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "row_index = int ( params [ ] [ 0 ] ) \n"
Original    (012): ['row_index', '=', 'int', '(', 'params', '[', ']', '[', '0', ']', ')', '\\n']
Tokenized   (017): ['<s>', 'row', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['row', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['row_index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "char_index = int ( params [ ] [ 0 ] ) - 1 \n"
Original    (014): ['char_index', '=', 'int', '(', 'params', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Tokenized   (019): ['<s>', 'char', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['char', '_', 'index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (014): ['char_index', 'Ġ=', 'Ġint', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "comparator = comparators . index ( params [ ] [ 0 ] ) - 1 \n"
Original    (016): ['comparator', '=', 'comparators', '.', 'index', '(', 'params', '[', ']', '[', '0', ']', ')', '-', '1', '\\n']
Tokenized   (022): ['<s>', 'com', 'par', 'ator', 'Ġ=', 'Ġcompar', 'ators', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['com', 'par', 'ator', 'Ġ=', 'Ġcompar', 'ators', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (016): ['comparator', 'Ġ=', 'Ġcomparators', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġparams', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "truth = ( cmp ( ord ( current_character ) , test_char ) == comparator ) \n"
Original    (016): ['truth', '=', '(', 'cmp', '(', 'ord', '(', 'current_character', ')', ',', 'test_char', ')', '==', 'comparator', ')', '\\n']
Tokenized   (025): ['<s>', 'truth', 'Ġ=', 'Ġ(', 'Ġc', 'mp', 'Ġ(', 'Ġord', 'Ġ(', 'Ġcurrent', '_', 'character', 'Ġ)', 'Ġ,', 'Ġtest', '_', 'char', 'Ġ)', 'Ġ==', 'Ġcompar', 'ator', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['truth', 'Ġ=', 'Ġ(', 'Ġc', 'mp', 'Ġ(', 'Ġord', 'Ġ(', 'Ġcurrent', '_', 'character', 'Ġ)', 'Ġ,', 'Ġtest', '_', 'char', 'Ġ)', 'Ġ==', 'Ġcompar', 'ator', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['truth', 'Ġ=', 'Ġ(', 'Ġcmp', 'Ġ(', 'Ġord', 'Ġ(', 'Ġcurrent_character', 'Ġ)', 'Ġ,', 'Ġtest_char', 'Ġ)', 'Ġ==', 'Ġcomparator', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "start_response ( , [ ( , ) ] ) \n"
Original    (010): ['start_response', '(', ',', '[', '(', ',', ')', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'start', '_', 'response', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['start', '_', 'response', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['start_response', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "CHARSET = [ chr ( x ) for x in xrange ( 32 , 127 ) ] \n"
Original    (018): ['CHARSET', '=', '[', 'chr', '(', 'x', ')', 'for', 'x', 'in', 'xrange', '(', '32', ',', '127', ')', ']', '\\n']
Tokenized   (025): ['<s>', 'CH', 'ARS', 'ET', 'Ġ=', 'Ġ[', 'Ġch', 'r', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġx', 'range', 'Ġ(', 'Ġ32', 'Ġ,', 'Ġ127', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['CH', 'ARS', 'ET', 'Ġ=', 'Ġ[', 'Ġch', 'r', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġx', 'range', 'Ġ(', 'Ġ32', 'Ġ,', 'Ġ127', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['CHARSET', 'Ġ=', 'Ġ[', 'Ġchr', 'Ġ(', 'Ġx', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġxrange', 'Ġ(', 'Ġ32', 'Ġ,', 'Ġ127', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "obj_struct [ ] = [ int ( bbox . find ( ) . text ) , \n"
Original    (017): ['obj_struct', '[', ']', '=', '[', 'int', '(', 'bbox', '.', 'find', '(', ')', '.', 'text', ')', ',', '\\n']
Tokenized   (023): ['<s>', 'obj', '_', 'struct', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġint', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['obj', '_', 'struct', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġint', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['obj_struct', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġint', 'Ġ(', 'Ġbbox', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "int ( bbox . find ( ) . text ) ] \n"
Original    (012): ['int', '(', 'bbox', '.', 'find', '(', ')', '.', 'text', ')', ']', '\\n']
Tokenized   (016): ['<s>', 'int', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['int', 'Ġ(', 'Ġb', 'box', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['int', 'Ġ(', 'Ġbbox', 'Ġ.', 'Ġfind', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġtext', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mpre = np . concatenate ( ( [ 0. ] , prec , [ 0. ] ) ) \n"
Original    (019): ['mpre', '=', 'np', '.', 'concatenate', '(', '(', '[', '0.', ']', ',', 'prec', ',', '[', '0.', ']', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'mp', 're', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġprec', 'Ġ,', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['mp', 're', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġconc', 'aten', 'ate', 'Ġ(', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġprec', 'Ġ,', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['mpre', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġconcatenate', 'Ġ(', 'Ġ(', 'Ġ[', 'Ġ0.', 'Ġ]', 'Ġ,', 'Ġprec', 'Ġ,', 'Ġ[', 'Ġ0.', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "difficult = np . array ( [ x [ ] for x in R ] ) . astype ( np . bool ) \n"
Original    (024): ['difficult', '=', 'np', '.', 'array', '(', '[', 'x', '[', ']', 'for', 'x', 'in', 'R', ']', ')', '.', 'astype', '(', 'np', '.', 'bool', ')', '\\n']
Tokenized   (029): ['<s>', 'diff', 'icult', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'ĠR', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġbool', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['diff', 'icult', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'ĠR', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġbool', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['difficult', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġx', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'ĠR', 'Ġ]', 'Ġ)', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġbool', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "det = [ False ] * len ( R ) \n"
Original    (011): ['det', '=', '[', 'False', ']', '*', 'len', '(', 'R', ')', '\\n']
Tokenized   (014): ['<s>', 'det', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġ]', 'Ġ*', 'Ġlen', 'Ġ(', 'ĠR', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['det', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġ]', 'Ġ*', 'Ġlen', 'Ġ(', 'ĠR', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['det', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġ]', 'Ġ*', 'Ġlen', 'Ġ(', 'ĠR', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "npos = npos + sum ( ~ difficult ) \n"
Original    (010): ['npos', '=', 'npos', '+', 'sum', '(', '~', 'difficult', ')', '\\n']
Tokenized   (015): ['<s>', 'n', 'pos', 'Ġ=', 'Ġn', 'pos', 'Ġ+', 'Ġsum', 'Ġ(', 'Ġ~', 'Ġdifficult', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['n', 'pos', 'Ġ=', 'Ġn', 'pos', 'Ġ+', 'Ġsum', 'Ġ(', 'Ġ~', 'Ġdifficult', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['npos', 'Ġ=', 'Ġnpos', 'Ġ+', 'Ġsum', 'Ġ(', 'Ġ~', 'Ġdifficult', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "class_recs [ imagename ] = { : bbox , \n"
Original    (010): ['class_recs', '[', 'imagename', ']', '=', '{', ':', 'bbox', ',', '\\n']
Tokenized   (018): ['<s>', 'class', '_', 're', 'cs', 'Ġ[', 'Ġimag', 'ename', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġb', 'box', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['class', '_', 're', 'cs', 'Ġ[', 'Ġimag', 'ename', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġb', 'box', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['class_recs', 'Ġ[', 'Ġimagename', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġbbox', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "confidence = np . array ( [ float ( x [ 1 ] ) for x in splitlines ] ) \n"
Original    (021): ['confidence', '=', 'np', '.', 'array', '(', '[', 'float', '(', 'x', '[', '1', ']', ')', 'for', 'x', 'in', 'splitlines', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'confidence', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġsplit', 'lines', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['confidence', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġsplit', 'lines', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['confidence', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġsplitlines', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "sorted_ind = np . argsort ( - confidence ) \n"
Original    (010): ['sorted_ind', '=', 'np', '.', 'argsort', '(', '-', 'confidence', ')', '\\n']
Tokenized   (017): ['<s>', 's', 'orted', '_', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġargs', 'ort', 'Ġ(', 'Ġ-', 'Ġconfidence', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['s', 'orted', '_', 'ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġargs', 'ort', 'Ġ(', 'Ġ-', 'Ġconfidence', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['sorted_ind', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġargsort', 'Ġ(', 'Ġ-', 'Ġconfidence', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "BB = BB [ sorted_ind , : ] \n"
Original    (009): ['BB', '=', 'BB', '[', 'sorted_ind', ',', ':', ']', '\\n']
Tokenized   (014): ['<s>', 'BB', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġsorted', '_', 'ind', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['BB', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġsorted', '_', 'ind', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['BB', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġsorted_ind', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "image_ids = [ image_ids [ x ] for x in sorted_ind ] \n"
Original    (013): ['image_ids', '=', '[', 'image_ids', '[', 'x', ']', 'for', 'x', 'in', 'sorted_ind', ']', '\\n']
Tokenized   (022): ['<s>', 'image', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġimage', '_', 'ids', 'Ġ[', 'Ġx', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'Ġsorted', '_', 'ind', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['image', '_', 'ids', 'Ġ=', 'Ġ[', 'Ġimage', '_', 'ids', 'Ġ[', 'Ġx', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'Ġsorted', '_', 'ind', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['image_ids', 'Ġ=', 'Ġ[', 'Ġimage_ids', 'Ġ[', 'Ġx', 'Ġ]', 'Ġfor', 'Ġx', 'Ġin', 'Ġsorted_ind', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "bb = BB [ d , : ] . astype ( float ) \n"
Original    (014): ['bb', '=', 'BB', '[', 'd', ',', ':', ']', '.', 'astype', '(', 'float', ')', '\\n']
Tokenized   (018): ['<s>', 'bb', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġd', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['bb', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġd', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['bb', 'Ġ=', 'ĠBB', 'Ġ[', 'Ġd', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "BBGT = R [ ] . astype ( float ) \n"
Original    (011): ['BBGT', '=', 'R', '[', ']', '.', 'astype', '(', 'float', ')', '\\n']
Tokenized   (016): ['<s>', 'BB', 'GT', 'Ġ=', 'ĠR', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['BB', 'GT', 'Ġ=', 'ĠR', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['BBGT', 'Ġ=', 'ĠR', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġfloat', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "iymin = np . maximum ( BBGT [ : , 1 ] , bb [ 1 ] ) \n"
Original    (019): ['iymin', '=', 'np', '.', 'maximum', '(', 'BBGT', '[', ':', ',', '1', ']', ',', 'bb', '[', '1', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'iy', 'min', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'ĠBB', 'GT', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['iy', 'min', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'ĠBB', 'GT', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['iymin', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'ĠBBGT', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġbb', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "iw = np . maximum ( ixmax - ixmin + 1. , 0. ) \n"
Original    (015): ['iw', '=', 'np', '.', 'maximum', '(', 'ixmax', '-', 'ixmin', '+', '1.', ',', '0.', ')', '\\n']
Tokenized   (024): ['<s>', 'iw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'Ġ', 'ix', 'max', 'Ġ-', 'Ġ', 'ix', 'min', 'Ġ+', 'Ġ1', '.', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['iw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'Ġ', 'ix', 'max', 'Ġ-', 'Ġ', 'ix', 'min', 'Ġ+', 'Ġ1', '.', 'Ġ,', 'Ġ0', '.', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['iw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmaximum', 'Ġ(', 'Ġixmax', 'Ġ-', 'Ġixmin', 'Ġ+', 'Ġ1.', 'Ġ,', 'Ġ0.', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "uni = ( ( bb [ 2 ] - bb [ 0 ] + 1. ) * ( bb [ 3 ] - bb [ 1 ] + 1. ) + \n"
Original    (032): ['uni', '=', '(', '(', 'bb', '[', '2', ']', '-', 'bb', '[', '0', ']', '+', '1.', ')', '*', '(', 'bb', '[', '3', ']', '-', 'bb', '[', '1', ']', '+', '1.', ')', '+', '\\n']
Tokenized   (041): ['<s>', 'uni', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['uni', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġb', 'b', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ-', 'Ġb', 'b', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ+', 'Ġ1', '.', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (032): ['uni', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġbb', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ-', 'Ġbb', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ+', 'Ġ1.', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġbb', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ-', 'Ġbb', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ+', 'Ġ1.', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "rec = tp / float ( npos ) \n"
Original    (009): ['rec', '=', 'tp', '/', 'float', '(', 'npos', ')', '\\n']
Tokenized   (014): ['<s>', 'rec', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġn', 'pos', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['rec', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġn', 'pos', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['rec', 'Ġ=', 'Ġtp', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġnpos', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "prec = tp / ( tp + fp + 1e-10 ) \n"
Original    (012): ['prec', '=', 'tp', '/', '(', 'tp', '+', 'fp', '+', '1e-10', ')', '\\n']
Tokenized   (022): ['<s>', 'pre', 'c', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġ(', 'Ġt', 'p', 'Ġ+', 'Ġf', 'p', 'Ġ+', 'Ġ1', 'e', '-', '10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['pre', 'c', 'Ġ=', 'Ġt', 'p', 'Ġ/', 'Ġ(', 'Ġt', 'p', 'Ġ+', 'Ġf', 'p', 'Ġ+', 'Ġ1', 'e', '-', '10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['prec', 'Ġ=', 'Ġtp', 'Ġ/', 'Ġ(', 'Ġtp', 'Ġ+', 'Ġfp', 'Ġ+', 'Ġ1e-10', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "scale = strip_mantissa ( maxval ) / float ( 1 << ( bits - sign - 1 ) ) \n"
Original    (020): ['scale', '=', 'strip_mantissa', '(', 'maxval', ')', '/', 'float', '(', '1', '<<', '(', 'bits', '-', 'sign', '-', '1', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'scale', 'Ġ=', 'Ġstrip', '_', 'm', 'ant', 'issa', 'Ġ(', 'Ġmax', 'val', 'Ġ)', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġ1', 'Ġ<<', 'Ġ(', 'Ġbits', 'Ġ-', 'Ġsign', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['scale', 'Ġ=', 'Ġstrip', '_', 'm', 'ant', 'issa', 'Ġ(', 'Ġmax', 'val', 'Ġ)', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġ1', 'Ġ<<', 'Ġ(', 'Ġbits', 'Ġ-', 'Ġsign', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['scale', 'Ġ=', 'Ġstrip_mantissa', 'Ġ(', 'Ġmaxval', 'Ġ)', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġ1', 'Ġ<<', 'Ġ(', 'Ġbits', 'Ġ-', 'Ġsign', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "ary = np . around ( ary * ( 1.0 / scale ) ) . astype ( np . int64 ) \n"
Original    (022): ['ary', '=', 'np', '.', 'around', '(', 'ary', '*', '(', '1.0', '/', 'scale', ')', ')', '.', 'astype', '(', 'np', '.', 'int64', ')', '\\n']
Tokenized   (030): ['<s>', 'ary', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġaround', 'Ġ(', 'Ġa', 'ry', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġscale', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġint', '64', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['ary', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġaround', 'Ġ(', 'Ġa', 'ry', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġscale', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġast', 'ype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġint', '64', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['ary', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġaround', 'Ġ(', 'Ġary', 'Ġ*', 'Ġ(', 'Ġ1.0', 'Ġ/', 'Ġscale', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġastype', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġint64', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "f2 -= dif \n"
Original    (004): ['f2', '-=', 'dif', '\\n']
Tokenized   (009): ['<s>', 'f', '2', 'Ġ-=', 'Ġd', 'if', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['f', '2', 'Ġ-=', 'Ġd', 'if', 'Ġ\\', 'n']
Detokenized (004): ['f2', 'Ġ-=', 'Ġdif', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "slicedF = F [ : , sliceR , sliceS , : ] . reshape ( ( - 1 , K ) ) \n"
Original    (023): ['slicedF', '=', 'F', '[', ':', ',', 'sliceR', ',', 'sliceS', ',', ':', ']', '.', 'reshape', '(', '(', '-', '1', ',', 'K', ')', ')', '\\n']
Tokenized   (032): ['<s>', 's', 'lic', 'ed', 'F', 'Ġ=', 'ĠF', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġslice', 'R', 'Ġ,', 'Ġslice', 'S', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['s', 'lic', 'ed', 'F', 'Ġ=', 'ĠF', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġslice', 'R', 'Ġ,', 'Ġslice', 'S', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['slicedF', 'Ġ=', 'ĠF', 'Ġ[', 'Ġ:', 'Ġ,', 'ĠsliceR', 'Ġ,', 'ĠsliceS', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġ(', 'Ġ-', 'Ġ1', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "K , P , Q , N = E . shape \n"
Original    (012): ['K', ',', 'P', ',', 'Q', ',', 'N', '=', 'E', '.', 'shape', '\\n']
Tokenized   (015): ['<s>', 'K', 'Ġ,', 'ĠP', 'Ġ,', 'ĠQ', 'Ġ,', 'ĠN', 'Ġ=', 'ĠE', 'Ġ.', 'Ġshape', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['K', 'Ġ,', 'ĠP', 'Ġ,', 'ĠQ', 'Ġ,', 'ĠN', 'Ġ=', 'ĠE', 'Ġ.', 'Ġshape', 'Ġ\\', 'n']
Detokenized (012): ['K', 'Ġ,', 'ĠP', 'Ġ,', 'ĠQ', 'Ġ,', 'ĠN', 'Ġ=', 'ĠE', 'Ġ.', 'Ġshape', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "qSlice = [ fconv_slice ( q , S , X , padding [ 0 ] , strides [ 0 ] ) for q in range ( Q ) ] \n"
Original    (030): ['qSlice', '=', '[', 'fconv_slice', '(', 'q', ',', 'S', ',', 'X', ',', 'padding', '[', '0', ']', ',', 'strides', '[', '0', ']', ')', 'for', 'q', 'in', 'range', '(', 'Q', ')', ']', '\\n']
Tokenized   (038): ['<s>', 'q', 'Sl', 'ice', 'Ġ=', 'Ġ[', 'Ġf', 'conv', '_', 'slice', 'Ġ(', 'Ġq', 'Ġ,', 'ĠS', 'Ġ,', 'ĠX', 'Ġ,', 'Ġpadding', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġq', 'Ġin', 'Ġrange', 'Ġ(', 'ĠQ', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['q', 'Sl', 'ice', 'Ġ=', 'Ġ[', 'Ġf', 'conv', '_', 'slice', 'Ġ(', 'Ġq', 'Ġ,', 'ĠS', 'Ġ,', 'ĠX', 'Ġ,', 'Ġpadding', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġq', 'Ġin', 'Ġrange', 'Ġ(', 'ĠQ', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (030): ['qSlice', 'Ġ=', 'Ġ[', 'Ġfconv_slice', 'Ġ(', 'Ġq', 'Ġ,', 'ĠS', 'Ġ,', 'ĠX', 'Ġ,', 'Ġpadding', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġq', 'Ġin', 'Ġrange', 'Ġ(', 'ĠQ', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 30, 768)
# Extracted words:  30
Sentence         : "slicedE = E [ : , p , q , : ] \n"
Original    (013): ['slicedE', '=', 'E', '[', ':', ',', 'p', ',', 'q', ',', ':', ']', '\\n']
Tokenized   (019): ['<s>', 's', 'lic', 'ed', 'E', 'Ġ=', 'ĠE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġp', 'Ġ,', 'Ġq', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['s', 'lic', 'ed', 'E', 'Ġ=', 'ĠE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġp', 'Ġ,', 'Ġq', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['slicedE', 'Ġ=', 'ĠE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġp', 'Ġ,', 'Ġq', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "rcp3 = 1.0 / 3.0 \n"
Original    (006): ['rcp3', '=', '1.0', '/', '3.0', '\\n']
Tokenized   (015): ['<s>', 'rc', 'p', '3', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ3', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['rc', 'p', '3', 'Ġ=', 'Ġ1', '.', '0', 'Ġ/', 'Ġ3', '.', '0', 'Ġ\\', 'n']
Detokenized (006): ['rcp3', 'Ġ=', 'Ġ1.0', 'Ġ/', 'Ġ3.0', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "t3 = I [ 1 , : ] + I [ 3 , : ] * 4.0 \n"
Original    (018): ['t3', '=', 'I', '[', '1', ',', ':', ']', '+', 'I', '[', '3', ',', ':', ']', '*', '4.0', '\\n']
Tokenized   (024): ['<s>', 't', '3', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ+', 'ĠI', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ*', 'Ġ4', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', '3', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ+', 'ĠI', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ*', 'Ġ4', '.', '0', 'Ġ\\', 'n']
Detokenized (018): ['t3', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ+', 'ĠI', 'Ġ[', 'Ġ3', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ*', 'Ġ4.0', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "T1 = np . empty ( ( 3 , 3 ) ) \n"
Original    (013): ['T1', '=', 'np', '.', 'empty', '(', '(', '3', ',', '3', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'T', '1', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['T', '1', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['T1', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Fw = np . empty ( ( D , D , C , K ) ) \n"
Original    (017): ['Fw', '=', 'np', '.', 'empty', '(', '(', 'D', ',', 'D', ',', 'C', ',', 'K', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'F', 'w', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'ĠD', 'Ġ,', 'ĠD', 'Ġ,', 'ĠC', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['F', 'w', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'ĠD', 'Ġ,', 'ĠD', 'Ġ,', 'ĠC', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['Fw', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġempty', 'Ġ(', 'Ġ(', 'ĠD', 'Ġ,', 'ĠD', 'Ġ,', 'ĠC', 'Ġ,', 'ĠK', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sliceI = I [ : , start_y : stop_y , start_x : stop_x , : ] \n"
Original    (017): ['sliceI', '=', 'I', '[', ':', ',', 'start_y', ':', 'stop_y', ',', 'start_x', ':', 'stop_x', ',', ':', ']', '\\n']
Tokenized   (029): ['<s>', 'slice', 'I', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġstart', '_', 'y', 'Ġ:', 'Ġstop', '_', 'y', 'Ġ,', 'Ġstart', '_', 'x', 'Ġ:', 'Ġstop', '_', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['slice', 'I', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġstart', '_', 'y', 'Ġ:', 'Ġstop', '_', 'y', 'Ġ,', 'Ġstart', '_', 'x', 'Ġ:', 'Ġstop', '_', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['sliceI', 'Ġ=', 'ĠI', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġstart_y', 'Ġ:', 'Ġstop_y', 'Ġ,', 'Ġstart_x', 'Ġ:', 'Ġstop_x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "O [ k , p0 : p1 , q0 : q1 , n ] = Out [ 0 : plen , 0 : qlen ] \n"
Original    (026): ['O', '[', 'k', ',', 'p0', ':', 'p1', ',', 'q0', ':', 'q1', ',', 'n', ']', '=', 'Out', '[', '0', ':', 'plen', ',', '0', ':', 'qlen', ']', '\\n']
Tokenized   (035): ['<s>', 'O', 'Ġ[', 'Ġk', 'Ġ,', 'Ġp', '0', 'Ġ:', 'Ġp', '1', 'Ġ,', 'Ġq', '0', 'Ġ:', 'Ġq', '1', 'Ġ,', 'Ġn', 'Ġ]', 'Ġ=', 'ĠOut', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġpl', 'en', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġq', 'len', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['O', 'Ġ[', 'Ġk', 'Ġ,', 'Ġp', '0', 'Ġ:', 'Ġp', '1', 'Ġ,', 'Ġq', '0', 'Ġ:', 'Ġq', '1', 'Ġ,', 'Ġn', 'Ġ]', 'Ġ=', 'ĠOut', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġpl', 'en', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġq', 'len', 'Ġ]', 'Ġ\\', 'n']
Detokenized (026): ['O', 'Ġ[', 'Ġk', 'Ġ,', 'Ġp0', 'Ġ:', 'Ġp1', 'Ġ,', 'Ġq0', 'Ġ:', 'Ġq1', 'Ġ,', 'Ġn', 'Ġ]', 'Ġ=', 'ĠOut', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġplen', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġqlen', 'Ġ]', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "start_p , stop_p , pad_p = image_slice ( y , P , B , B ) \n"
Original    (017): ['start_p', ',', 'stop_p', ',', 'pad_p', '=', 'image_slice', '(', 'y', ',', 'P', ',', 'B', ',', 'B', ')', '\\n']
Tokenized   (028): ['<s>', 'start', '_', 'p', 'Ġ,', 'Ġstop', '_', 'p', 'Ġ,', 'Ġpad', '_', 'p', 'Ġ=', 'Ġimage', '_', 'slice', 'Ġ(', 'Ġy', 'Ġ,', 'ĠP', 'Ġ,', 'ĠB', 'Ġ,', 'ĠB', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['start', '_', 'p', 'Ġ,', 'Ġstop', '_', 'p', 'Ġ,', 'Ġpad', '_', 'p', 'Ġ=', 'Ġimage', '_', 'slice', 'Ġ(', 'Ġy', 'Ġ,', 'ĠP', 'Ġ,', 'ĠB', 'Ġ,', 'ĠB', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['start_p', 'Ġ,', 'Ġstop_p', 'Ġ,', 'Ġpad_p', 'Ġ=', 'Ġimage_slice', 'Ġ(', 'Ġy', 'Ġ,', 'ĠP', 'Ġ,', 'ĠB', 'Ġ,', 'ĠB', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "trans = ( 2 , 2 ) \n"
Original    (008): ['trans', '=', '(', '2', ',', '2', ')', '\\n']
Tokenized   (011): ['<s>', 'trans', 'Ġ=', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['trans', 'Ġ=', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['trans', 'Ġ=', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "E = np . random . uniform ( - 1.0 , 1.0 , dimO ) \n"
Original    (016): ['E', '=', 'np', '.', 'random', '.', 'uniform', '(', '-', '1.0', ',', '1.0', ',', 'dimO', ')', '\\n']
Tokenized   (024): ['<s>', 'E', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġuniform', 'Ġ(', 'Ġ-', 'Ġ1', '.', '0', 'Ġ,', 'Ġ1', '.', '0', 'Ġ,', 'Ġdim', 'O', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['E', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġuniform', 'Ġ(', 'Ġ-', 'Ġ1', '.', '0', 'Ġ,', 'Ġ1', '.', '0', 'Ġ,', 'Ġdim', 'O', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['E', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġuniform', 'Ġ(', 'Ġ-', 'Ġ1.0', 'Ġ,', 'Ġ1.0', 'Ġ,', 'ĠdimO', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "xprop_direct ( E , F , Bd , padding , strides , backward = True ) \n"
Original    (017): ['xprop_direct', '(', 'E', ',', 'F', ',', 'Bd', ',', 'padding', ',', 'strides', ',', 'backward', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'x', 'prop', '_', 'direct', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['x', 'prop', '_', 'direct', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['xprop_direct', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠBd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "xprop_winograd ( E , F , Bw , padding , minimal = minimal , trans = trans , backward = True ) \n"
Original    (023): ['xprop_winograd', '(', 'E', ',', 'F', ',', 'Bw', ',', 'padding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ',', 'backward', '=', 'True', ')', '\\n']
Tokenized   (032): ['<s>', 'x', 'prop', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['x', 'prop', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠB', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['xprop_winograd', 'Ġ(', 'ĠE', 'Ġ,', 'ĠF', 'Ġ,', 'ĠBw', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ,', 'Ġbackward', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "updat_direct ( I , E , Ud , padding , strides ) \n"
Original    (013): ['updat_direct', '(', 'I', ',', 'E', ',', 'Ud', ',', 'padding', ',', 'strides', ')', '\\n']
Tokenized   (019): ['<s>', 'up', 'dat', '_', 'direct', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['up', 'dat', '_', 'direct', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['updat_direct', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUd', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "updat_winograd ( I , E , Uw , padding , minimal = minimal , trans = trans ) \n"
Original    (019): ['updat_winograd', '(', 'I', ',', 'E', ',', 'Uw', ',', 'padding', ',', 'minimal', '=', 'minimal', ',', 'trans', '=', 'trans', ')', '\\n']
Tokenized   (028): ['<s>', 'up', 'dat', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠU', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['up', 'dat', '_', 'win', 'og', 'rad', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠU', 'w', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['updat_winograd', 'Ġ(', 'ĠI', 'Ġ,', 'ĠE', 'Ġ,', 'ĠUw', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġminimal', 'Ġ=', 'Ġminimal', 'Ġ,', 'Ġtrans', 'Ġ=', 'Ġtrans', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "BranchNode , SkipNode , LRN , ColorNoise ) \n"
Original    (009): ['BranchNode', ',', 'SkipNode', ',', 'LRN', ',', 'ColorNoise', ')', '\\n']
Tokenized   (018): ['<s>', 'B', 'ranch', 'Node', 'Ġ,', 'ĠSkip', 'Node', 'Ġ,', 'ĠLR', 'N', 'Ġ,', 'ĠColor', 'No', 'ise', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['B', 'ranch', 'Node', 'Ġ,', 'ĠSkip', 'Node', 'Ġ,', 'ĠLR', 'N', 'Ġ,', 'ĠColor', 'No', 'ise', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['BranchNode', 'Ġ,', 'ĠSkipNode', 'Ġ,', 'ĠLRN', 'Ġ,', 'ĠColorNoise', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "img_set_options = dict ( repo_dir = args . data_dir , \n"
Original    (011): ['img_set_options', '=', 'dict', '(', 'repo_dir', '=', 'args', '.', 'data_dir', ',', '\\n']
Tokenized   (022): ['<s>', 'img', '_', 'set', '_', 'options', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġrepo', '_', 'dir', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['img', '_', 'set', '_', 'options', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġrepo', '_', 'dir', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġdata', '_', 'dir', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['img_set_options', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġrepo_dir', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġdata_dir', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "subset_pct = 0.09990891117239205 ) \n"
Original    (005): ['subset_pct', '=', '0.09990891117239205', ')', '\\n']
Tokenized   (020): ['<s>', 'sub', 'set', '_', 'p', 'ct', 'Ġ=', 'Ġ0', '.', '0', '999', '08', '911', '17', '239', '205', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['sub', 'set', '_', 'p', 'ct', 'Ġ=', 'Ġ0', '.', '0', '999', '08', '911', '17', '239', '205', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['subset_pct', 'Ġ=', 'Ġ0.09990891117239205', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "do_transforms = False , ** img_set_options ) \n"
Original    (008): ['do_transforms', '=', 'False', ',', '**', 'img_set_options', ')', '\\n']
Tokenized   (018): ['<s>', 'do', '_', 'trans', 'forms', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġimg', '_', 'set', '_', 'options', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['do', '_', 'trans', 'forms', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġimg', '_', 'set', '_', 'options', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['do_transforms', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġimg_set_options', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "test = ImageLoader ( set_name = , scale_range = ( 256 , 384 ) , shuffle = False , \n"
Original    (020): ['test', '=', 'ImageLoader', '(', 'set_name', '=', ',', 'scale_range', '=', '(', '256', ',', '384', ')', ',', 'shuffle', '=', 'False', ',', '\\n']
Tokenized   (028): ['<s>', 'test', 'Ġ=', 'ĠImage', 'Loader', 'Ġ(', 'Ġset', '_', 'name', 'Ġ=', 'Ġ,', 'Ġscale', '_', 'range', 'Ġ=', 'Ġ(', 'Ġ256', 'Ġ,', 'Ġ384', 'Ġ)', 'Ġ,', 'Ġshuffle', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['test', 'Ġ=', 'ĠImage', 'Loader', 'Ġ(', 'Ġset', '_', 'name', 'Ġ=', 'Ġ,', 'Ġscale', '_', 'range', 'Ġ=', 'Ġ(', 'Ġ256', 'Ġ,', 'Ġ384', 'Ġ)', 'Ġ,', 'Ġshuffle', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['test', 'Ġ=', 'ĠImageLoader', 'Ġ(', 'Ġset_name', 'Ġ=', 'Ġ,', 'Ġscale_range', 'Ġ=', 'Ġ(', 'Ġ256', 'Ġ,', 'Ġ384', 'Ġ)', 'Ġ,', 'Ġshuffle', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "Pooling ( 3 , strides = 2 ) , \n"
Original    (010): ['Pooling', '(', '3', ',', 'strides', '=', '2', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'Pool', 'ing', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġstrides', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Pool', 'ing', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġstrides', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['Pooling', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġstrides', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "activation = Rectlin ( ) , padding = 1 ) , \n"
Original    (012): ['activation', '=', 'Rectlin', '(', ')', ',', 'padding', '=', '1', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'activation', 'Ġ=', 'ĠRect', 'lin', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġpadding', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['activation', 'Ġ=', 'ĠRect', 'lin', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġpadding', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['activation', 'Ġ=', 'ĠRectlin', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġpadding', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Conv ( ( 3 , 3 , 256 ) , init = Gaussian ( scale = 0.03 ) , bias = Constant ( 1 ) , \n"
Original    (027): ['Conv', '(', '(', '3', ',', '3', ',', '256', ')', ',', 'init', '=', 'Gaussian', '(', 'scale', '=', '0.03', ')', ',', 'bias', '=', 'Constant', '(', '1', ')', ',', '\\n']
Tokenized   (034): ['<s>', 'Con', 'v', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ256', 'Ġ)', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '03', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['Con', 'v', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ256', 'Ġ)', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '03', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (027): ['Conv', 'Ġ(', 'Ġ(', 'Ġ3', 'Ġ,', 'Ġ3', 'Ġ,', 'Ġ256', 'Ġ)', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGaussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0.03', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "Dropout ( keep = 1.0 ) , \n"
Original    (008): ['Dropout', '(', 'keep', '=', '1.0', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'Drop', 'out', 'Ġ(', 'Ġkeep', 'Ġ=', 'Ġ1', '.', '0', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Drop', 'out', 'Ġ(', 'Ġkeep', 'Ġ=', 'Ġ1', '.', '0', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['Dropout', 'Ġ(', 'Ġkeep', 'Ġ=', 'Ġ1.0', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "Affine ( nout = 1000 , init = Gaussian ( scale = 0.01 ) , bias = Constant ( - 7 ) , activation = Softmax ( ) ) ] \n"
Original    (031): ['Affine', '(', 'nout', '=', '1000', ',', 'init', '=', 'Gaussian', '(', 'scale', '=', '0.01', ')', ',', 'bias', '=', 'Constant', '(', '-', '7', ')', ',', 'activation', '=', 'Softmax', '(', ')', ')', ']', '\\n']
Tokenized   (040): ['<s>', 'Aff', 'ine', 'Ġ(', 'Ġn', 'out', 'Ġ=', 'Ġ1000', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '01', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ-', 'Ġ7', 'Ġ)', 'Ġ,', 'Ġactivation', 'Ġ=', 'ĠSoft', 'max', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['Aff', 'ine', 'Ġ(', 'Ġn', 'out', 'Ġ=', 'Ġ1000', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGa', 'ussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0', '.', '01', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ-', 'Ġ7', 'Ġ)', 'Ġ,', 'Ġactivation', 'Ġ=', 'ĠSoft', 'max', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (031): ['Affine', 'Ġ(', 'Ġnout', 'Ġ=', 'Ġ1000', 'Ġ,', 'Ġinit', 'Ġ=', 'ĠGaussian', 'Ġ(', 'Ġscale', 'Ġ=', 'Ġ0.01', 'Ġ)', 'Ġ,', 'Ġbias', 'Ġ=', 'ĠConstant', 'Ġ(', 'Ġ-', 'Ġ7', 'Ġ)', 'Ġ,', 'Ġactivation', 'Ġ=', 'ĠSoftmax', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 31, 768)
# Extracted words:  31
Sentence         : "weight_sched = Schedule ( [ 22 , 44 , 65 ] , ( 1 / 250. ) ** ( 1 / 3. ) ) \n"
Original    (025): ['weight_sched', '=', 'Schedule', '(', '[', '22', ',', '44', ',', '65', ']', ',', '(', '1', '/', '250.', ')', '**', '(', '1', '/', '3.', ')', ')', '\\n']
Tokenized   (033): ['<s>', 'weight', '_', 'sc', 'hed', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ22', 'Ġ,', 'Ġ44', 'Ġ,', 'Ġ65', 'Ġ]', 'Ġ,', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ250', '.', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ3', '.', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['weight', '_', 'sc', 'hed', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ22', 'Ġ,', 'Ġ44', 'Ġ,', 'Ġ65', 'Ġ]', 'Ġ,', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ250', '.', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ3', '.', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['weight_sched', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ22', 'Ġ,', 'Ġ44', 'Ġ,', 'Ġ65', 'Ġ]', 'Ġ,', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ250.', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ1', 'Ġ/', 'Ġ3.', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "opt_gdm = GradientDescentMomentum ( 0.01 / 10 , 0.9 , wdecay = 0.0005 , schedule = weight_sched , \n"
Original    (019): ['opt_gdm', '=', 'GradientDescentMomentum', '(', '0.01', '/', '10', ',', '0.9', ',', 'wdecay', '=', '0.0005', ',', 'schedule', '=', 'weight_sched', ',', '\\n']
Tokenized   (043): ['<s>', 'opt', '_', 'gd', 'm', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '01', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġw', 'dec', 'ay', 'Ġ=', 'Ġ0', '.', '000', '5', 'Ġ,', 'Ġschedule', 'Ġ=', 'Ġweight', '_', 'sc', 'hed', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['opt', '_', 'gd', 'm', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '01', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġw', 'dec', 'ay', 'Ġ=', 'Ġ0', '.', '000', '5', 'Ġ,', 'Ġschedule', 'Ġ=', 'Ġweight', '_', 'sc', 'hed', 'Ġ,', 'Ġ\\', 'n']
Detokenized (019): ['opt_gdm', 'Ġ=', 'ĠGradientDescentMomentum', 'Ġ(', 'Ġ0.01', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0.9', 'Ġ,', 'Ġwdecay', 'Ġ=', 'Ġ0.0005', 'Ġ,', 'Ġschedule', 'Ġ=', 'Ġweight_sched', 'Ġ,', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "opt_biases = GradientDescentMomentum ( 0.02 / 10 , 0.9 , schedule = Schedule ( [ 44 ] , 0.1 ) , \n"
Original    (022): ['opt_biases', '=', 'GradientDescentMomentum', '(', '0.02', '/', '10', ',', '0.9', ',', 'schedule', '=', 'Schedule', '(', '[', '44', ']', ',', '0.1', ')', ',', '\\n']
Tokenized   (040): ['<s>', 'opt', '_', 'bi', 'ases', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '02', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġschedule', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ44', 'Ġ]', 'Ġ,', 'Ġ0', '.', '1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['opt', '_', 'bi', 'ases', 'Ġ=', 'ĠGrad', 'ient', 'Des', 'cent', 'Mom', 'ent', 'um', 'Ġ(', 'Ġ0', '.', '02', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0', '.', '9', 'Ġ,', 'Ġschedule', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ44', 'Ġ]', 'Ġ,', 'Ġ0', '.', '1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (022): ['opt_biases', 'Ġ=', 'ĠGradientDescentMomentum', 'Ġ(', 'Ġ0.02', 'Ġ/', 'Ġ10', 'Ġ,', 'Ġ0.9', 'Ġ,', 'Ġschedule', 'Ġ=', 'ĠSchedule', 'Ġ(', 'Ġ[', 'Ġ44', 'Ġ]', 'Ġ,', 'Ġ0.1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "valmetric = TopKMisclassification ( k = 5 ) \n"
Original    (009): ['valmetric', '=', 'TopKMisclassification', '(', 'k', '=', '5', ')', '\\n']
Tokenized   (018): ['<s>', 'val', 'met', 'ric', 'Ġ=', 'ĠTop', 'K', 'Mis', 'class', 'ification', 'Ġ(', 'Ġk', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['val', 'met', 'ric', 'Ġ=', 'ĠTop', 'K', 'Mis', 'class', 'ification', 'Ġ(', 'Ġk', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['valmetric', 'Ġ=', 'ĠTopKMisclassification', 'Ġ(', 'Ġk', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "nifm_rng = [ 8 ] \n"
Original    (006): ['nifm_rng', '=', '[', '8', ']', '\\n']
Tokenized   (014): ['<s>', 'n', 'if', 'm', '_', 'r', 'ng', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['n', 'if', 'm', '_', 'r', 'ng', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['nifm_rng', 'Ġ=', 'Ġ[', 'Ġ8', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "fargs_ . append ( itt . product ( fs_rng , nifm_rng , pad_rng , stride_rng , in_sz_rng , bsz_rng ) ) \n"
Original    (022): ['fargs_', '.', 'append', '(', 'itt', '.', 'product', '(', 'fs_rng', ',', 'nifm_rng', ',', 'pad_rng', ',', 'stride_rng', ',', 'in_sz_rng', ',', 'bsz_rng', ')', ')', '\\n']
Tokenized   (053): ['<s>', 'f', 'args', '_', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġit', 't', 'Ġ.', 'Ġproduct', 'Ġ(', 'Ġfs', '_', 'r', 'ng', 'Ġ,', 'Ġn', 'if', 'm', '_', 'r', 'ng', 'Ġ,', 'Ġpad', '_', 'r', 'ng', 'Ġ,', 'Ġstride', '_', 'r', 'ng', 'Ġ,', 'Ġin', '_', 's', 'z', '_', 'r', 'ng', 'Ġ,', 'Ġb', 's', 'z', '_', 'r', 'ng', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (051): ['f', 'args', '_', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġit', 't', 'Ġ.', 'Ġproduct', 'Ġ(', 'Ġfs', '_', 'r', 'ng', 'Ġ,', 'Ġn', 'if', 'm', '_', 'r', 'ng', 'Ġ,', 'Ġpad', '_', 'r', 'ng', 'Ġ,', 'Ġstride', '_', 'r', 'ng', 'Ġ,', 'Ġin', '_', 's', 'z', '_', 'r', 'ng', 'Ġ,', 'Ġb', 's', 'z', '_', 'r', 'ng', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['fargs_', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġitt', 'Ġ.', 'Ġproduct', 'Ġ(', 'Ġfs_rng', 'Ġ,', 'Ġnifm_rng', 'Ġ,', 'Ġpad_rng', 'Ġ,', 'Ġstride_rng', 'Ġ,', 'Ġin_sz_rng', 'Ġ,', 'Ġbsz_rng', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 51
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "bsz = inp . shape [ - 1 ] \n"
Original    (010): ['bsz', '=', 'inp', '.', 'shape', '[', '-', '1', ']', '\\n']
Tokenized   (015): ['<s>', 'bs', 'z', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['bs', 'z', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['bsz', 'Ġ=', 'Ġinp', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "check_inds = check_inds [ 0 : ncheck ] \n"
Original    (009): ['check_inds', '=', 'check_inds', '[', '0', ':', 'ncheck', ']', '\\n']
Tokenized   (019): ['<s>', 'check', '_', 'ind', 's', 'Ġ=', 'Ġcheck', '_', 'ind', 's', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġn', 'check', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['check', '_', 'ind', 's', 'Ġ=', 'Ġcheck', '_', 'ind', 's', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġn', 'check', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['check_inds', 'Ġ=', 'Ġcheck_inds', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġncheck', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "inpa = inp . get ( ) . reshape ( inp_lshape ) \n"
Original    (013): ['inpa', '=', 'inp', '.', 'get', '(', ')', '.', 'reshape', '(', 'inp_lshape', ')', '\\n']
Tokenized   (023): ['<s>', 'in', 'pa', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['in', 'pa', 'Ġ=', 'Ġin', 'p', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['inpa', 'Ġ=', 'Ġinp', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġinp_lshape', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "outshape = ( inp_lshape [ 0 ] , \n"
Original    (009): ['outshape', '=', '(', 'inp_lshape', '[', '0', ']', ',', '\\n']
Tokenized   (017): ['<s>', 'out', 'shape', 'Ġ=', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['out', 'shape', 'Ġ=', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['outshape', 'Ġ=', 'Ġ(', 'Ġinp_lshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "be . output_dim ( inp_lshape [ 2 ] , fshape [ 1 ] , padding , strides [ 1 ] , pooling = True ) , \n"
Original    (027): ['be', '.', 'output_dim', '(', 'inp_lshape', '[', '2', ']', ',', 'fshape', '[', '1', ']', ',', 'padding', ',', 'strides', '[', '1', ']', ',', 'pooling', '=', 'True', ')', ',', '\\n']
Tokenized   (038): ['<s>', 'be', 'Ġ.', 'Ġoutput', '_', 'dim', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġf', 'shape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpool', 'ing', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['be', 'Ġ.', 'Ġoutput', '_', 'dim', 'Ġ(', 'Ġin', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġf', 'shape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpool', 'ing', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (027): ['be', 'Ġ.', 'Ġoutput_dim', 'Ġ(', 'Ġinp_lshape', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġfshape', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpadding', 'Ġ,', 'Ġstrides', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġpooling', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "inp_lshape [ - 1 ] ) \n"
Original    (007): ['inp_lshape', '[', '-', '1', ']', ')', '\\n']
Tokenized   (014): ['<s>', 'in', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['in', 'p', '_', 'l', 'shape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['inp_lshape', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "inp_pad [ : , padding : - padding , padding : - padding , : ] = inpa [ : , 0 : , 0 : , : ] \n"
Original    (030): ['inp_pad', '[', ':', ',', 'padding', ':', '-', 'padding', ',', 'padding', ':', '-', 'padding', ',', ':', ']', '=', 'inpa', '[', ':', ',', '0', ':', ',', '0', ':', ',', ':', ']', '\\n']
Tokenized   (037): ['<s>', 'in', 'p', '_', 'pad', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġin', 'pa', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['in', 'p', '_', 'pad', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġin', 'pa', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (030): ['inp_pad', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġpadding', 'Ġ:', 'Ġ-', 'Ġpadding', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġinpa', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ0', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 30, 768)
# Extracted words:  30
Sentence         : "out_exp [ indC , indh , indw , cnt ] = np . max ( inp_check ) \n"
Original    (018): ['out_exp', '[', 'indC', ',', 'indh', ',', 'indw', ',', 'cnt', ']', '=', 'np', '.', 'max', '(', 'inp_check', ')', '\\n']
Tokenized   (030): ['<s>', 'out', '_', 'exp', 'Ġ[', 'Ġind', 'C', 'Ġ,', 'Ġind', 'h', 'Ġ,', 'Ġind', 'w', 'Ġ,', 'Ġc', 'nt', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġin', 'p', '_', 'check', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['out', '_', 'exp', 'Ġ[', 'Ġind', 'C', 'Ġ,', 'Ġind', 'h', 'Ġ,', 'Ġind', 'w', 'Ġ,', 'Ġc', 'nt', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġin', 'p', '_', 'check', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['out_exp', 'Ġ[', 'ĠindC', 'Ġ,', 'Ġindh', 'Ġ,', 'Ġindw', 'Ġ,', 'Ġcnt', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġinp_check', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "NervanaObject . be . bsz = batch_size \n"
Original    (008): ['NervanaObject', '.', 'be', '.', 'bsz', '=', 'batch_size', '\\n']
Tokenized   (018): ['<s>', 'N', 'erv', 'ana', 'Object', 'Ġ.', 'Ġbe', 'Ġ.', 'Ġb', 's', 'z', 'Ġ=', 'Ġbatch', '_', 'size', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['N', 'erv', 'ana', 'Object', 'Ġ.', 'Ġbe', 'Ġ.', 'Ġb', 's', 'z', 'Ġ=', 'Ġbatch', '_', 'size', 'Ġ\\', 'n']
Detokenized (008): ['NervanaObject', 'Ġ.', 'Ġbe', 'Ġ.', 'Ġbsz', 'Ġ=', 'Ġbatch_size', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "inshape = ( nifm , in_sz , in_sz ) \n"
Original    (010): ['inshape', '=', '(', 'nifm', ',', 'in_sz', ',', 'in_sz', ')', '\\n']
Tokenized   (023): ['<s>', 'ins', 'h', 'ape', 'Ġ=', 'Ġ(', 'Ġn', 'if', 'm', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['ins', 'h', 'ape', 'Ġ=', 'Ġ(', 'Ġn', 'if', 'm', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ,', 'Ġin', '_', 's', 'z', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['inshape', 'Ġ=', 'Ġ(', 'Ġnifm', 'Ġ,', 'Ġin_sz', 'Ġ,', 'Ġin_sz', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "src = "img/file-icon.jpg" , ** kw ) ] \n"
Original    (009): ['src', '=', '"img/file-icon.jpg"', ',', '**', 'kw', ')', ']', '\\n']
Tokenized   (021): ['<s>', 'src', 'Ġ=', 'Ġ"', 'img', '/', 'file', '-', 'icon', '.', 'jpg', '"', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['src', 'Ġ=', 'Ġ"', 'img', '/', 'file', '-', 'icon', '.', 'jpg', '"', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['src', 'Ġ=', 'Ġ"img/file-icon.jpg"', 'Ġ,', 'Ġ**', 'Ġkw', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "render = lambda r : r . div ( comp . render ( r , model = None ) , r . script ( component_to_update = + self . comp_id , \n"
Original    (032): ['render', '=', 'lambda', 'r', ':', 'r', '.', 'div', '(', 'comp', '.', 'render', '(', 'r', ',', 'model', '=', 'None', ')', ',', 'r', '.', 'script', '(', 'component_to_update', '=', '+', 'self', '.', 'comp_id', ',', '\\n']
Tokenized   (041): ['<s>', 'render', 'Ġ=', 'Ġlambda', 'Ġr', 'Ġ:', 'Ġr', 'Ġ.', 'Ġdiv', 'Ġ(', 'Ġcomp', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġr', 'Ġ,', 'Ġmodel', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġr', 'Ġ.', 'Ġscript', 'Ġ(', 'Ġcomponent', '_', 'to', '_', 'update', 'Ġ=', 'Ġ+', 'Ġself', 'Ġ.', 'Ġcomp', '_', 'id', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['render', 'Ġ=', 'Ġlambda', 'Ġr', 'Ġ:', 'Ġr', 'Ġ.', 'Ġdiv', 'Ġ(', 'Ġcomp', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġr', 'Ġ,', 'Ġmodel', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġr', 'Ġ.', 'Ġscript', 'Ġ(', 'Ġcomponent', '_', 'to', '_', 'update', 'Ġ=', 'Ġ+', 'Ġself', 'Ġ.', 'Ġcomp', '_', 'id', 'Ġ,', 'Ġ\\', 'n']
Detokenized (032): ['render', 'Ġ=', 'Ġlambda', 'Ġr', 'Ġ:', 'Ġr', 'Ġ.', 'Ġdiv', 'Ġ(', 'Ġcomp', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġr', 'Ġ,', 'Ġmodel', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġr', 'Ġ.', 'Ġscript', 'Ġ(', 'Ġcomponent_to_update', 'Ġ=', 'Ġ+', 'Ġself', 'Ġ.', 'Ġcomp_id', 'Ġ,', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "ajax . py2js ( self . crop_height ( ) ) \n"
Original    (011): ['ajax', '.', 'py2js', '(', 'self', '.', 'crop_height', '(', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'aj', 'ax', 'Ġ.', 'Ġpy', '2', 'js', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcrop', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['aj', 'ax', 'Ġ.', 'Ġpy', '2', 'js', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcrop', '_', 'height', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['ajax', 'Ġ.', 'Ġpy2js', 'Ġ(', 'Ġself', 'Ġ.', 'Ġcrop_height', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "local_handler = getattr ( self , , None ) \n"
Original    (010): ['local_handler', '=', 'getattr', '(', 'self', ',', ',', 'None', ')', '\\n']
Tokenized   (016): ['<s>', 'local', '_', 'handler', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['local', '_', 'handler', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['local_handler', 'Ġ=', 'Ġgetattr', 'Ġ(', 'Ġself', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "genie2 . client . wrapper . RetryPolicy ( \n"
Original    (009): ['genie2', '.', 'client', '.', 'wrapper', '.', 'RetryPolicy', '(', '\\n']
Tokenized   (016): ['<s>', 'gen', 'ie', '2', 'Ġ.', 'Ġclient', 'Ġ.', 'Ġwrapper', 'Ġ.', 'ĠRet', 'ry', 'Policy', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['gen', 'ie', '2', 'Ġ.', 'Ġclient', 'Ġ.', 'Ġwrapper', 'Ġ.', 'ĠRet', 'ry', 'Policy', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['genie2', 'Ġ.', 'Ġclient', 'Ġ.', 'Ġwrapper', 'Ġ.', 'ĠRetryPolicy', 'Ġ(', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "tries = 8 , none_on_404 = True , no_retry_http_codes = range ( 400 , 500 ) ) \n"
Original    (018): ['tries', '=', '8', ',', 'none_on_404', '=', 'True', ',', 'no_retry_http_codes', '=', 'range', '(', '400', ',', '500', ')', ')', '\\n']
Tokenized   (033): ['<s>', 't', 'ries', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġnone', '_', 'on', '_', '404', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġno', '_', 'ret', 'ry', '_', 'http', '_', 'codes', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ400', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['t', 'ries', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġnone', '_', 'on', '_', '404', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġno', '_', 'ret', 'ry', '_', 'http', '_', 'codes', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ400', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['tries', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġnone_on_404', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġno_retry_http_codes', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ400', 'Ġ,', 'Ġ500', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "tagging . add_argument ( , , dest = , action = conf_action ( context . ami ) , help = \n"
Original    (021): ['tagging', '.', 'add_argument', '(', ',', ',', 'dest', '=', ',', 'action', '=', 'conf_action', '(', 'context', '.', 'ami', ')', ',', 'help', '=', '\\n']
Tokenized   (030): ['<s>', 'tag', 'ging', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġconf', '_', 'action', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġam', 'i', 'Ġ)', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['tag', 'ging', 'Ġ.', 'Ġadd', '_', 'argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġconf', '_', 'action', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġam', 'i', 'Ġ)', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ\\', 'n']
Detokenized (021): ['tagging', 'Ġ.', 'Ġadd_argument', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġconf_action', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġami', 'Ġ)', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "BASE_URL = . format ( FQDN ) \n"
Original    (008): ['BASE_URL', '=', '.', 'format', '(', 'FQDN', ')', '\\n']
Tokenized   (016): ['<s>', 'B', 'ASE', '_', 'URL', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠF', 'Q', 'DN', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['B', 'ASE', '_', 'URL', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠF', 'Q', 'DN', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['BASE_URL', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'ĠFQDN', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test" , config ElasticSearchServiceItem ( region = "us-west-2" , account = "TEST_ACCOUNT" , name = "es_test_2" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_3" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_4" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_5" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_6" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_7" , config ElasticSearchServiceItem ( region = "eu-west-1" , account = "TEST_ACCOUNT" , name = "es_test_8" , config ElasticSearchServiceItem ( region = "us-east-1" , account = "TEST_ACCOUNT" , name = "es_test_9" , config ] \n"
Original    (137): ['ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-west-2"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_2"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_3"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_4"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_5"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_6"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_7"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"eu-west-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_8"', ',', 'config', 'ElasticSearchServiceItem', '(', 'region', '=', '"us-east-1"', ',', 'account', '=', '"TEST_ACCOUNT"', ',', 'name', '=', '"es_test_9"', ',', 'config', ']', '\\n']
Tokenized   (328): ['<s>', 'El', 'astic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'west', '-', '2', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '2', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '3', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '4', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '5', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '6', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '7', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '8', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '9', '"', 'Ġ,', 'Ġconfig', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (326): ['El', 'astic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'west', '-', '2', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '2', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '3', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '4', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '5', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '6', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '7', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'eu', '-', 'west', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '8', '"', 'Ġ,', 'Ġconfig', 'ĠElastic', 'Search', 'Service', 'Item', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"', 'us', '-', 'east', '-', '1', '"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"', 'es', '_', 'test', '_', '9', '"', 'Ġ,', 'Ġconfig', 'Ġ]', 'Ġ\\', 'n']
Detokenized (137): ['ElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-west-2"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_2"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_3"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_4"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_5"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_6"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_7"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"eu-west-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_8"', 'Ġ,', 'Ġconfig', 'ĠElasticSearchServiceItem', 'Ġ(', 'Ġregion', 'Ġ=', 'Ġ"us-east-1"', 'Ġ,', 'Ġaccount', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ"es_test_9"', 'Ġ,', 'Ġconfig', 'Ġ]', 'Ġ\\n']
Counter: 326
===================================================================
Hidden states:  (13, 137, 768)
# Extracted words:  137
Sentence         : "test_account . role_name = "TEST_ACCOUNT" \n"
Original    (006): ['test_account', '.', 'role_name', '=', '"TEST_ACCOUNT"', '\\n']
Tokenized   (019): ['<s>', 'test', '_', 'account', 'Ġ.', 'Ġrole', '_', 'name', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['test', '_', 'account', 'Ġ.', 'Ġrole', '_', 'name', 'Ġ=', 'Ġ"', 'T', 'EST', '_', 'ACC', 'OUNT', '"', 'Ġ\\', 'n']
Detokenized (006): ['test_account', 'Ġ.', 'Ġrole_name', 'Ġ=', 'Ġ"TEST_ACCOUNT"', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "all_clusters . extend ( response [ ] [ if response [ ] [ ] [ ] ~~~ marker = response [ ] [ ] [ ~~ else : \n"
Original    (029): ['all_clusters', '.', 'extend', '(', 'response', '[', ']', '[', 'if', 'response', '[', ']', '[', ']', '[', ']', '~~~', 'marker', '=', 'response', '[', ']', '[', ']', '[', '~~', 'else', ':', '\\n']
Tokenized   (038): ['<s>', 'all', '_', 'cl', 'usters', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġif', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ', '~~', '~', 'Ġmarker', 'Ġ=', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['all', '_', 'cl', 'usters', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġif', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ', '~~', '~', 'Ġmarker', 'Ġ=', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n']
Detokenized (029): ['all_clusters', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġif', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ~~~', 'Ġmarker', 'Ġ=', 'Ġresponse', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ~~', 'Ġelse', 'Ġ:', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "_container_child_objects = ( , ) \n"
Original    (006): ['_container_child_objects', '=', '(', ',', ')', '\\n']
Tokenized   (014): ['<s>', '_', 'container', '_', 'child', '_', 'objects', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['_', 'container', '_', 'child', '_', 'objects', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['_container_child_objects', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_recommended_attrs = ( ( ( , np . ndarray , 1 , np . dtype ( ) ) , \n"
Original    (020): ['_recommended_attrs', '=', '(', '(', '(', ',', 'np', '.', 'ndarray', ',', '1', ',', 'np', '.', 'dtype', '(', ')', ')', ',', '\\n']
Tokenized   (031): ['<s>', '_', 'recomm', 'ended', '_', 'att', 'rs', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġn', 'd', 'array', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġd', 'type', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['_', 'recomm', 'ended', '_', 'att', 'rs', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġn', 'd', 'array', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġd', 'type', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['_recommended_attrs', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġndarray', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġdtype', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "errstr = . format ( errno , pszMsgBuffer . value ) \n"
Original    (012): ['errstr', '=', '.', 'format', '(', 'errno', ',', 'pszMsgBuffer', '.', 'value', ')', '\\n']
Tokenized   (020): ['<s>', 'err', 'str', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġerr', 'no', 'Ġ,', 'Ġps', 'z', 'Msg', 'Buffer', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['err', 'str', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġerr', 'no', 'Ġ,', 'Ġps', 'z', 'Msg', 'Buffer', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['errstr', 'Ġ=', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġerrno', 'Ġ,', 'ĠpszMsgBuffer', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "supported_objects = [ Segment , AnalogSignal , EventArray , SpikeTrain ] \n"
Original    (012): ['supported_objects', '=', '[', 'Segment', ',', 'AnalogSignal', ',', 'EventArray', ',', 'SpikeTrain', ']', '\\n']
Tokenized   (022): ['<s>', 'supported', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ,', 'ĠAnalog', 'Sign', 'al', 'Ġ,', 'ĠEvent', 'Array', 'Ġ,', 'ĠSpike', 'Train', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['supported', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ,', 'ĠAnalog', 'Sign', 'al', 'Ġ,', 'ĠEvent', 'Array', 'Ġ,', 'ĠSpike', 'Train', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['supported_objects', 'Ġ=', 'Ġ[', 'ĠSegment', 'Ġ,', 'ĠAnalogSignal', 'Ġ,', 'ĠEventArray', 'Ġ,', 'ĠSpikeTrain', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "readable_objects = [ Segment ] \n"
Original    (006): ['readable_objects', '=', '[', 'Segment', ']', '\\n']
Tokenized   (012): ['<s>', 'readable', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['readable', '_', 'objects', 'Ġ=', 'Ġ[', 'ĠSe', 'gment', 'Ġ]', 'Ġ\\', 'n']
Detokenized (006): ['readable_objects', 'Ġ=', 'Ġ[', 'ĠSegment', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "read_params = { Segment : [ ] } \n"
Original    (009): ['read_params', '=', '{', 'Segment', ':', '[', ']', '}', '\\n']
Tokenized   (015): ['<s>', 'read', '_', 'params', 'Ġ=', 'Ġ{', 'ĠSe', 'gment', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['read', '_', 'params', 'Ġ=', 'Ġ{', 'ĠSe', 'gment', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ\\', 'n']
Detokenized (009): ['read_params', 'Ġ=', 'Ġ{', 'ĠSegment', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "labels . append ( str ( pData . value ) ) \n"
Original    (012): ['labels', '.', 'append', '(', 'str', '(', 'pData', '.', 'value', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'lab', 'els', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġp', 'Data', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['lab', 'els', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġp', 'Data', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['labels', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠpData', 'Ġ.', 'Ġvalue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ea . labels = np . array ( labels , dtype = ) \n"
Original    (014): ['ea', '.', 'labels', '=', 'np', '.', 'array', '(', 'labels', ',', 'dtype', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'ea', 'Ġ.', 'Ġlabels', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġlabels', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['ea', 'Ġ.', 'Ġlabels', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġlabels', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['ea', 'Ġ.', 'Ġlabels', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġlabels', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dwStopIndex , ctypes . byref ( pdwContCount ) , pData [ total_read : ] . ctypes total_read += pdwContCount . value \n"
Original    (022): ['dwStopIndex', ',', 'ctypes', '.', 'byref', '(', 'pdwContCount', ')', ',', 'pData', '[', 'total_read', ':', ']', '.', 'ctypes', 'total_read', '+=', 'pdwContCount', '.', 'value', '\\n']
Tokenized   (044): ['<s>', 'd', 'w', 'Stop', 'Index', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ)', 'Ġ,', 'Ġp', 'Data', 'Ġ[', 'Ġtotal', '_', 'read', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġc', 'types', 'Ġtotal', '_', 'read', 'Ġ+=', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ.', 'Ġvalue', 'Ġ\\', 'n', '</s>']
Filtered   (042): ['d', 'w', 'Stop', 'Index', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ)', 'Ġ,', 'Ġp', 'Data', 'Ġ[', 'Ġtotal', '_', 'read', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġc', 'types', 'Ġtotal', '_', 'read', 'Ġ+=', 'Ġp', 'd', 'w', 'Cont', 'Count', 'Ġ.', 'Ġvalue', 'Ġ\\', 'n']
Detokenized (022): ['dwStopIndex', 'Ġ,', 'Ġctypes', 'Ġ.', 'Ġbyref', 'Ġ(', 'ĠpdwContCount', 'Ġ)', 'Ġ,', 'ĠpData', 'Ġ[', 'Ġtotal_read', 'Ġ:', 'Ġ]', 'Ġ.', 'Ġctypes', 'Ġtotal_read', 'Ġ+=', 'ĠpdwContCount', 'Ġ.', 'Ġvalue', 'Ġ\\n']
Counter: 42
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "anaSig . annotate ( probe_info = str ( pAnalogInfo . szProbeInfo ) ) \n"
Original    (014): ['anaSig', '.', 'annotate', '(', 'probe_info', '=', 'str', '(', 'pAnalogInfo', '.', 'szProbeInfo', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'ana', 'S', 'ig', 'Ġ.', 'Ġannot', 'ate', 'Ġ(', 'Ġprobe', '_', 'info', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'An', 'alog', 'Info', 'Ġ.', 'Ġs', 'z', 'Pro', 'be', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['ana', 'S', 'ig', 'Ġ.', 'Ġannot', 'ate', 'Ġ(', 'Ġprobe', '_', 'info', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'An', 'alog', 'Info', 'Ġ.', 'Ġs', 'z', 'Pro', 'be', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['anaSig', 'Ġ.', 'Ġannotate', 'Ġ(', 'Ġprobe_info', 'Ġ=', 'Ġstr', 'Ġ(', 'ĠpAnalogInfo', 'Ġ.', 'ĠszProbeInfo', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pData = np . zeros ( ( dwDataBufferSize ) , dtype = ) \n"
Original    (014): ['pData', '=', 'np', '.', 'zeros', '(', '(', 'dwDataBufferSize', ')', ',', 'dtype', '=', ')', '\\n']
Tokenized   (023): ['<s>', 'p', 'Data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġ(', 'Ġdw', 'Data', 'Buffer', 'Size', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['p', 'Data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġ(', 'Ġdw', 'Data', 'Buffer', 'Size', 'Ġ)', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['pData', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġzeros', 'Ġ(', 'Ġ(', 'ĠdwDataBufferSize', 'Ġ)', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "waveforms = pq . Quantity ( waveforms , units = str ( pdwSegmentInfo left_sweep = nsample / 2. / float ( pdwSegmentInfo . dSampleRate ) * pq sampling_rate = float ( pdwSegmentInfo . dSampleRate ) * pq . Hz , \n"
Original    (041): ['waveforms', '=', 'pq', '.', 'Quantity', '(', 'waveforms', ',', 'units', '=', 'str', '(', 'pdwSegmentInfo', 'left_sweep', '=', 'nsample', '/', '2.', '/', 'float', '(', 'pdwSegmentInfo', '.', 'dSampleRate', ')', '*', 'pq', 'sampling_rate', '=', 'float', '(', 'pdwSegmentInfo', '.', 'dSampleRate', ')', '*', 'pq', '.', 'Hz', ',', '\\n']
Tokenized   (075): ['<s>', 'wave', 'forms', 'Ġ=', 'Ġp', 'q', 'Ġ.', 'ĠQuantity', 'Ġ(', 'Ġwave', 'forms', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġleft', '_', 'swe', 'ep', 'Ġ=', 'Ġns', 'ample', 'Ġ/', 'Ġ2', '.', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġsampling', '_', 'rate', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (073): ['wave', 'forms', 'Ġ=', 'Ġp', 'q', 'Ġ.', 'ĠQuantity', 'Ġ(', 'Ġwave', 'forms', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġstr', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġleft', '_', 'swe', 'ep', 'Ġ=', 'Ġns', 'ample', 'Ġ/', 'Ġ2', '.', 'Ġ/', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġsampling', '_', 'rate', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġp', 'd', 'w', 'Seg', 'ment', 'Info', 'Ġ.', 'Ġd', 'Sample', 'Rate', 'Ġ)', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n']
Detokenized (041): ['waveforms', 'Ġ=', 'Ġpq', 'Ġ.', 'ĠQuantity', 'Ġ(', 'Ġwaveforms', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġstr', 'Ġ(', 'ĠpdwSegmentInfo', 'Ġleft_sweep', 'Ġ=', 'Ġnsample', 'Ġ/', 'Ġ2.', 'Ġ/', 'Ġfloat', 'Ġ(', 'ĠpdwSegmentInfo', 'Ġ.', 'ĠdSampleRate', 'Ġ)', 'Ġ*', 'Ġpq', 'Ġsampling_rate', 'Ġ=', 'Ġfloat', 'Ġ(', 'ĠpdwSegmentInfo', 'Ġ.', 'ĠdSampleRate', 'Ġ)', 'Ġ*', 'Ġpq', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\n']
Counter: 73
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "ctypes . byref ( pNeuralInfo ) , ctypes . sizeof ( pNeuralInfo ) ) \n"
Original    (015): ['ctypes', '.', 'byref', '(', 'pNeuralInfo', ')', ',', 'ctypes', '.', 'sizeof', '(', 'pNeuralInfo', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'ct', 'ypes', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġsizeof', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['ct', 'ypes', 'Ġ.', 'Ġby', 'ref', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ,', 'Ġc', 'types', 'Ġ.', 'Ġsizeof', 'Ġ(', 'Ġp', 'Ne', 'ural', 'Info', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['ctypes', 'Ġ.', 'Ġbyref', 'Ġ(', 'ĠpNeuralInfo', 'Ġ)', 'Ġ,', 'Ġctypes', 'Ġ.', 'Ġsizeof', 'Ġ(', 'ĠpNeuralInfo', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "neuroshare . ns_GetNeuralData ( hFile , dwEntityID , dwStartIndex , \n"
Original    (011): ['neuroshare', '.', 'ns_GetNeuralData', '(', 'hFile', ',', 'dwEntityID', ',', 'dwStartIndex', ',', '\\n']
Tokenized   (026): ['<s>', 'ne', 'uro', 'share', 'Ġ.', 'Ġns', '_', 'Get', 'Ne', 'ural', 'Data', 'Ġ(', 'Ġh', 'File', 'Ġ,', 'Ġdw', 'Entity', 'ID', 'Ġ,', 'Ġdw', 'Start', 'Index', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['ne', 'uro', 'share', 'Ġ.', 'Ġns', '_', 'Get', 'Ne', 'ural', 'Data', 'Ġ(', 'Ġh', 'File', 'Ġ,', 'Ġdw', 'Entity', 'ID', 'Ġ,', 'Ġdw', 'Start', 'Index', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['neuroshare', 'Ġ.', 'Ġns_GetNeuralData', 'Ġ(', 'ĠhFile', 'Ġ,', 'ĠdwEntityID', 'Ġ,', 'ĠdwStartIndex', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dwIndexCount , pData . ctypes . data_as ( ctypes . POINTER ( ctypes . c_double ) ) ) \n"
Original    (019): ['dwIndexCount', ',', 'pData', '.', 'ctypes', '.', 'data_as', '(', 'ctypes', '.', 'POINTER', '(', 'ctypes', '.', 'c_double', ')', ')', ')', '\\n']
Tokenized   (034): ['<s>', 'd', 'w', 'Index', 'Count', 'Ġ,', 'Ġp', 'Data', 'Ġ.', 'Ġc', 'types', 'Ġ.', 'Ġdata', '_', 'as', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'ĠPO', 'INTER', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'Ġc', '_', 'double', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['d', 'w', 'Index', 'Count', 'Ġ,', 'Ġp', 'Data', 'Ġ.', 'Ġc', 'types', 'Ġ.', 'Ġdata', '_', 'as', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'ĠPO', 'INTER', 'Ġ(', 'Ġc', 'types', 'Ġ.', 'Ġc', '_', 'double', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['dwIndexCount', 'Ġ,', 'ĠpData', 'Ġ.', 'Ġctypes', 'Ġ.', 'Ġdata_as', 'Ġ(', 'Ġctypes', 'Ġ.', 'ĠPOINTER', 'Ġ(', 'Ġctypes', 'Ġ.', 'Ġc_double', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "times = pData * pq . s \n"
Original    (008): ['times', '=', 'pData', '*', 'pq', '.', 's', '\\n']
Tokenized   (013): ['<s>', 'times', 'Ġ=', 'Ġp', 'Data', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'Ġs', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['times', 'Ġ=', 'Ġp', 'Data', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'Ġs', 'Ġ\\', 'n']
Detokenized (008): ['times', 'Ġ=', 'ĠpData', 'Ġ*', 'Ġpq', 'Ġ.', 'Ġs', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "clone_object , TEST_ANNOTATIONS ) \n"
Original    (005): ['clone_object', ',', 'TEST_ANNOTATIONS', ')', '\\n']
Tokenized   (014): ['<s>', 'clone', '_', 'object', 'Ġ,', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['clone', '_', 'object', 'Ġ,', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['clone_object', 'Ġ,', 'ĠTEST_ANNOTATIONS', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "range ( len ( TEST_ANNOTATIONS ) ) ] ) \n"
Original    (010): ['range', '(', 'len', '(', 'TEST_ANNOTATIONS', ')', ')', ']', ')', '\\n']
Tokenized   (017): ['<s>', 'range', 'Ġ(', 'Ġlen', 'Ġ(', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['range', 'Ġ(', 'Ġlen', 'Ġ(', 'ĠTEST', '_', 'AN', 'NOT', 'ATIONS', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['range', 'Ġ(', 'Ġlen', 'Ġ(', 'ĠTEST_ANNOTATIONS', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "file_datetime = get_fake_value ( , datetime , seed = 0 ) \n"
Original    (012): ['file_datetime', '=', 'get_fake_value', '(', ',', 'datetime', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (023): ['<s>', 'file', '_', 'dat', 'etime', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['file', '_', 'dat', 'etime', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['file_datetime', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġdatetime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "file_origin = get_fake_value ( , str ) \n"
Original    (008): ['file_origin', '=', 'get_fake_value', '(', ',', 'str', ')', '\\n']
Tokenized   (017): ['<s>', 'file', '_', 'origin', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['file', '_', 'origin', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['file_origin', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "attrs1 = { : file_datetime , \n"
Original    (007): ['attrs1', '=', '{', ':', 'file_datetime', ',', '\\n']
Tokenized   (015): ['<s>', 'att', 'rs', '1', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġfile', '_', 'dat', 'etime', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['att', 'rs', '1', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġfile', '_', 'dat', 'etime', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['attrs1', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġfile_datetime', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "res21 = get_fake_values ( Segment , annotate = True , seed = 0 ) \n"
Original    (015): ['res21', '=', 'get_fake_values', '(', 'Segment', ',', 'annotate', '=', 'True', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (025): ['<s>', 'res', '21', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'ĠSe', 'gment', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['res', '21', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'ĠSe', 'gment', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['res21', 'Ġ=', 'Ġget_fake_values', 'Ġ(', 'ĠSegment', 'Ġ,', 'Ġannotate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "res22 = get_fake_values ( , annotate = True , seed = 0 ) \n"
Original    (014): ['res22', '=', 'get_fake_values', '(', ',', 'annotate', '=', 'True', ',', 'seed', '=', '0', ')', '\\n']
Tokenized   (023): ['<s>', 'res', '22', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['res', '22', 'Ġ=', 'Ġget', '_', 'fake', '_', 'values', 'Ġ(', 'Ġ,', 'Ġannot', 'ate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['res22', 'Ġ=', 'Ġget_fake_values', 'Ġ(', 'Ġ,', 'Ġannotate', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "targ0 = get_fake_value ( , datetime , seed = seed + 0 ) \n"
Original    (014): ['targ0', '=', 'get_fake_value', '(', ',', 'datetime', ',', 'seed', '=', 'seed', '+', '0', ')', '\\n']
Tokenized   (024): ['<s>', 't', 'arg', '0', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', 'arg', '0', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġdat', 'etime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['targ0', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġdatetime', 'Ġ,', 'Ġseed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "targ4 = get_fake_value ( , str , \n"
Original    (008): ['targ4', '=', 'get_fake_value', '(', ',', 'str', ',', '\\n']
Tokenized   (017): ['<s>', 't', 'arg', '4', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['t', 'arg', '4', 'Ġ=', 'Ġget', '_', 'fake', '_', 'value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['targ4', 'Ġ=', 'Ġget_fake_value', 'Ġ(', 'Ġ,', 'Ġstr', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "seed = seed + 4 , obj = Segment ) \n"
Original    (011): ['seed', '=', 'seed', '+', '4', ',', 'obj', '=', 'Segment', ')', '\\n']
Tokenized   (015): ['<s>', 'seed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ4', 'Ġ,', 'Ġobj', 'Ġ=', 'ĠSe', 'gment', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['seed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ4', 'Ġ,', 'Ġobj', 'Ġ=', 'ĠSe', 'gment', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['seed', 'Ġ=', 'Ġseed', 'Ġ+', 'Ġ4', 'Ġ,', 'Ġobj', 'Ġ=', 'ĠSegment', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "childobjs = ( , , \n"
Original    (006): ['childobjs', '=', '(', ',', ',', '\\n']
Tokenized   (011): ['<s>', 'child', 'ob', 'js', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['child', 'ob', 'js', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['childobjs', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "children = ( self . sigs1a + self . sigarrs1a + \n"
Original    (012): ['children', '=', '(', 'self', '.', 'sigs1a', '+', 'self', '.', 'sigarrs1a', '+', '\\n']
Tokenized   (022): ['<s>', 'children', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġs', 'igs', '1', 'a', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['children', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġs', 'igs', '1', 'a', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ+', 'Ġ\\', 'n']
Detokenized (012): ['children', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsigs1a', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsigarrs1a', 'Ġ+', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : ""analogsignals" : self . nchildren ** 2 , \n"
Original    (009): ['"analogsignals"', ':', 'self', '.', 'nchildren', '**', '2', ',', '\\n']
Tokenized   (018): ['<s>', '"', 'an', 'alog', 'sign', 'als', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ**', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'an', 'alog', 'sign', 'als', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ**', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"analogsignals"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ**', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ""epocharrays" : self . nchildren , "eventarrays" : self . nchildren , \n"
Original    (013): ['"epocharrays"', ':', 'self', '.', 'nchildren', ',', '"eventarrays"', ':', 'self', '.', 'nchildren', ',', '\\n']
Tokenized   (027): ['<s>', '"', 'ep', 'och', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ"', 'event', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['"', 'ep', 'och', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ"', 'event', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['"epocharrays"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ,', 'Ġ"eventarrays"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ,', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : ""analogsignalarrays" : self . nchildren } \n"
Original    (007): ['"analogsignalarrays"', ':', 'self', '.', 'nchildren', '}', '\\n']
Tokenized   (018): ['<s>', '"', 'an', 'alog', 'sign', 'al', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['"', 'an', 'alog', 'sign', 'al', 'arr', 'ays', '"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġn', 'children', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['"analogsignalarrays"', 'Ġ:', 'Ġself', 'Ġ.', 'Ġnchildren', 'Ġ}', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "targdict = { : 5 } ) \n"
Original    (008): ['targdict', '=', '{', ':', '5', '}', ')', '\\n']
Tokenized   (013): ['<s>', 't', 'arg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['t', 'arg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['targdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "res6 = filterdata ( data , name = self . epcs2 [ 0 ] . name , j = 5 ) \n"
Original    (022): ['res6', '=', 'filterdata', '(', 'data', ',', 'name', '=', 'self', '.', 'epcs2', '[', '0', ']', '.', 'name', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (029): ['<s>', 'res', '6', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['res', '6', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['res6', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "res7 = filterdata ( data , { : self . epcs2 [ 1 ] . name , : 5 } ) \n"
Original    (022): ['res7', '=', 'filterdata', '(', 'data', ',', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Tokenized   (029): ['<s>', 'res', '7', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['res', '7', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['res7', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "res8 = filterdata ( data , targdict = { : self . epcs2 [ 1 ] . name , : 5 } ) \n"
Original    (024): ['res8', '=', 'filterdata', '(', 'data', ',', 'targdict', '=', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', ':', '5', '}', ')', '\\n']
Tokenized   (032): ['<s>', 'res', '8', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['res', '8', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['res8', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtargdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "res9 = filterdata ( data , { : self . epcs2 [ 1 ] . name } , j = 5 ) \n"
Original    (023): ['res9', '=', 'filterdata', '(', 'data', ',', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (030): ['<s>', 'res', '9', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['res', '9', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['res9', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "res10 = filterdata ( data , targdict = { : self . epcs2 [ 1 ] . name } , j = 5 ) \n"
Original    (025): ['res10', '=', 'filterdata', '(', 'data', ',', 'targdict', '=', '{', ':', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', '}', ',', 'j', '=', '5', ')', '\\n']
Tokenized   (033): ['<s>', 'res', '10', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['res', '10', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['res10', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġtargdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ}', 'Ġ,', 'Ġj', 'Ġ=', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "res11 = filterdata ( data , name = self . epcs2 [ 1 ] . name , targdict = { : 5 } ) \n"
Original    (025): ['res11', '=', 'filterdata', '(', 'data', ',', 'name', '=', 'self', '.', 'epcs2', '[', '1', ']', '.', 'name', ',', 'targdict', '=', '{', ':', '5', '}', ')', '\\n']
Tokenized   (033): ['<s>', 'res', '11', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['res', '11', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġep', 'cs', '2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġtarg', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['res11', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġname', 'Ġ=', 'Ġself', 'Ġ.', 'Ġepcs2', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ.', 'Ġname', 'Ġ,', 'Ġtargdict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ5', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "targ = [ self . epcs1a [ 1 ] ] \n"
Original    (011): ['targ', '=', '[', 'self', '.', 'epcs1a', '[', '1', ']', ']', '\\n']
Tokenized   (018): ['<s>', 't', 'arg', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġep', 'cs', '1', 'a', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['t', 'arg', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġep', 'cs', '1', 'a', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['targ', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġepcs1a', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "res3 = filterdata ( data , [ { : 1 } , { : 2 } ] ) \n"
Original    (019): ['res3', '=', 'filterdata', '(', 'data', ',', '[', '{', ':', '1', '}', ',', '{', ':', '2', '}', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'res', '3', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['res', '3', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['res3', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ2', 'Ġ}', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "res4 = filterdata ( data , { : 1 } , i = 2 ) \n"
Original    (016): ['res4', '=', 'filterdata', '(', 'data', ',', '{', ':', '1', '}', ',', 'i', '=', '2', ')', '\\n']
Tokenized   (021): ['<s>', 'res', '4', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['res', '4', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['res4', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "res5 = filterdata ( data , [ { : 1 } ] , i = 2 ) \n"
Original    (018): ['res5', '=', 'filterdata', '(', 'data', ',', '[', '{', ':', '1', '}', ']', ',', 'i', '=', '2', ')', '\\n']
Tokenized   (023): ['<s>', 'res', '5', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['res', '5', 'Ġ=', 'Ġfilter', 'data', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['res5', 'Ġ=', 'Ġfilterdata', 'Ġ(', 'Ġdata', 'Ġ,', 'Ġ[', 'Ġ{', 'Ġ:', 'Ġ1', 'Ġ}', 'Ġ]', 'Ġ,', 'Ġi', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "ann = pretty ( ann ) . replace ( , ) \n"
Original    (012): ['ann', '=', 'pretty', '(', 'ann', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (015): ['<s>', 'ann', 'Ġ=', 'Ġpretty', 'Ġ(', 'Ġann', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ann', 'Ġ=', 'Ġpretty', 'Ġ(', 'Ġann', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['ann', 'Ġ=', 'Ġpretty', 'Ġ(', 'Ġann', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "unit_with_sig = np . array ( [ 0 , 2 , 5 ] ) \n"
Original    (015): ['unit_with_sig', '=', 'np', '.', 'array', '(', '[', '0', ',', '2', ',', '5', ']', ')', '\\n']
Tokenized   (023): ['<s>', 'unit', '_', 'with', '_', 's', 'ig', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ5', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['unit', '_', 'with', '_', 's', 'ig', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ5', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['unit_with_sig', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ5', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "rcgs = [ RecordingChannelGroup ( name = , \n"
Original    (009): ['rcgs', '=', '[', 'RecordingChannelGroup', '(', 'name', '=', ',', '\\n']
Tokenized   (015): ['<s>', 'rc', 'gs', 'Ġ=', 'Ġ[', 'ĠRecording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['rc', 'gs', 'Ġ=', 'Ġ[', 'ĠRecording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['rcgs', 'Ġ=', 'Ġ[', 'ĠRecordingChannelGroup', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "RecordingChannelGroup ( name = , \n"
Original    (006): ['RecordingChannelGroup', '(', 'name', '=', ',', '\\n']
Tokenized   (012): ['<s>', 'Rec', 'ording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['Rec', 'ording', 'Channel', 'Group', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['RecordingChannelGroup', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "t_start = 0. , t_stop = 10 ) \n"
Original    (009): ['t_start', '=', '0.', ',', 't_stop', '=', '10', ')', '\\n']
Tokenized   (017): ['<s>', 't', '_', 'start', 'Ġ=', 'Ġ0', '.', 'Ġ,', 'Ġt', '_', 'stop', 'Ġ=', 'Ġ10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['t', '_', 'start', 'Ġ=', 'Ġ0', '.', 'Ġ,', 'Ġt', '_', 'stop', 'Ġ=', 'Ġ10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['t_start', 'Ġ=', 'Ġ0.', 'Ġ,', 'Ġt_stop', 'Ġ=', 'Ġ10', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "st . unit = all_unit [ j ] \n"
Original    (009): ['st', '.', 'unit', '=', 'all_unit', '[', 'j', ']', '\\n']
Tokenized   (014): ['<s>', 'st', 'Ġ.', 'Ġunit', 'Ġ=', 'Ġall', '_', 'unit', 'Ġ[', 'Ġj', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['st', 'Ġ.', 'Ġunit', 'Ġ=', 'Ġall', '_', 'unit', 'Ġ[', 'Ġj', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['st', 'Ġ.', 'Ġunit', 'Ġ=', 'Ġall_unit', 'Ġ[', 'Ġj', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "sampling_rate = 1000. * pq . Hz , \n"
Original    (009): ['sampling_rate', '=', '1000.', '*', 'pq', '.', 'Hz', ',', '\\n']
Tokenized   (017): ['<s>', 'sam', 'pling', '_', 'rate', 'Ġ=', 'Ġ1000', '.', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['sam', 'pling', '_', 'rate', 'Ġ=', 'Ġ1000', '.', 'Ġ*', 'Ġp', 'q', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['sampling_rate', 'Ġ=', 'Ġ1000.', 'Ġ*', 'Ġpq', 'Ġ.', 'ĠHz', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newseg = seg . construct_subsegment_by_unit ( all_unit [ : 4 ] ) \n"
Original    (013): ['newseg', '=', 'seg', '.', 'construct_subsegment_by_unit', '(', 'all_unit', '[', ':', '4', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'new', 'se', 'g', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġconstruct', '_', 'sub', 'se', 'gment', '_', 'by', '_', 'unit', 'Ġ(', 'Ġall', '_', 'unit', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['new', 'se', 'g', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġconstruct', '_', 'sub', 'se', 'gment', '_', 'by', '_', 'unit', 'Ġ(', 'Ġall', '_', 'unit', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['newseg', 'Ġ=', 'Ġseg', 'Ġ.', 'Ġconstruct_subsegment_by_unit', 'Ġ(', 'Ġall_unit', 'Ġ[', 'Ġ:', 'Ġ4', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "ind2 = self . unit2 . channel_indexes [ 0 ] \n"
Original    (011): ['ind2', '=', 'self', '.', 'unit2', '.', 'channel_indexes', '[', '0', ']', '\\n']
Tokenized   (019): ['<s>', 'ind', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġunit', '2', 'Ġ.', 'Ġchannel', '_', 'index', 'es', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['ind', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġunit', '2', 'Ġ.', 'Ġchannel', '_', 'index', 'es', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['ind2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġunit2', 'Ġ.', 'Ġchannel_indexes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "result22 = self . seg1 . take_analogsignal_by_channelindex ( [ ind2 ] ) \n"
Original    (013): ['result22', '=', 'self', '.', 'seg1', '.', 'take_analogsignal_by_channelindex', '(', '[', 'ind2', ']', ')', '\\n']
Tokenized   (030): ['<s>', 'result', '22', 'Ġ=', 'Ġself', 'Ġ.', 'Ġse', 'g', '1', 'Ġ.', 'Ġtake', '_', 'an', 'alog', 'sign', 'al', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['result', '22', 'Ġ=', 'Ġself', 'Ġ.', 'Ġse', 'g', '1', 'Ġ.', 'Ġtake', '_', 'an', 'alog', 'sign', 'al', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['result22', 'Ġ=', 'Ġself', 'Ġ.', 'Ġseg1', 'Ġ.', 'Ġtake_analogsignal_by_channelindex', 'Ġ(', 'Ġ[', 'Ġind2', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "targ1 = [ self . sigarrs1a [ 0 ] [ : , np . array ( [ True ] ) ] , \n"
Original    (023): ['targ1', '=', '[', 'self', '.', 'sigarrs1a', '[', '0', ']', '[', ':', ',', 'np', '.', 'array', '(', '[', 'True', ']', ')', ']', ',', '\\n']
Tokenized   (032): ['<s>', 't', 'arg', '1', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'ĠTrue', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['t', 'arg', '1', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġsig', 'arr', 's', '1', 'a', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'ĠTrue', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (023): ['targ1', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġsigarrs1a', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'ĠTrue', 'Ġ]', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "result21 = seg . take_slice_of_analogsignalarray_by_channelindex ( [ ind1 ] ) \n"
Original    (011): ['result21', '=', 'seg', '.', 'take_slice_of_analogsignalarray_by_channelindex', '(', '[', 'ind1', ']', ')', '\\n']
Tokenized   (032): ['<s>', 'result', '21', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġtake', '_', 'slice', '_', 'of', '_', 'an', 'alog', 'sign', 'al', 'array', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['result', '21', 'Ġ=', 'Ġse', 'g', 'Ġ.', 'Ġtake', '_', 'slice', '_', 'of', '_', 'an', 'alog', 'sign', 'al', 'array', '_', 'by', '_', 'channel', 'index', 'Ġ(', 'Ġ[', 'Ġind', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['result21', 'Ġ=', 'Ġseg', 'Ġ.', 'Ġtake_slice_of_analogsignalarray_by_channelindex', 'Ġ(', 'Ġ[', 'Ġind1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "json_content = json_content . decode ( "utf-8" ) . replace ( , ) \n"
Original    (014): ['json_content', '=', 'json_content', '.', 'decode', '(', '"utf-8"', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (025): ['<s>', 'json', '_', 'content', 'Ġ=', 'Ġjson', '_', 'content', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['json', '_', 'content', 'Ġ=', 'Ġjson', '_', 'content', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['json_content', 'Ġ=', 'Ġjson_content', 'Ġ.', 'Ġdecode', 'Ġ(', 'Ġ"utf-8"', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "Image1 = StatisticMap ( name = , collection = self . Collection1 , file = , Image1 . file = SimpleUploadedFile ( , file ( os . path . join ( self . test_path , Image1 . save ( ) \n"
Original    (041): ['Image1', '=', 'StatisticMap', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'Collection1', ',', 'file', '=', ',', 'Image1', '.', 'file', '=', 'SimpleUploadedFile', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'Image1', '.', 'save', '(', ')', '\\n']
Tokenized   (055): ['<s>', 'Image', '1', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '1', 'Ġ,', 'Ġfile', 'Ġ=', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (053): ['Image', '1', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '1', 'Ġ,', 'Ġfile', 'Ġ=', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '1', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (041): ['Image1', 'Ġ=', 'ĠStatisticMap', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection1', 'Ġ,', 'Ġfile', 'Ġ=', 'Ġ,', 'ĠImage1', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimpleUploadedFile', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest_path', 'Ġ,', 'ĠImage1', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 53
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "fname = os . path . basename ( os . path . join ( self . test_path , ) ) file_dict = { : SimpleUploadedFile ( fname , zip_file . read ( ) ) } \n"
Original    (036): ['fname', '=', 'os', '.', 'path', '.', 'basename', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', ')', ')', 'file_dict', '=', '{', ':', 'SimpleUploadedFile', '(', 'fname', ',', 'zip_file', '.', 'read', '(', ')', ')', '}', '\\n']
Tokenized   (051): ['<s>', 'f', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġbas', 'ename', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġfile', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġf', 'name', 'Ġ,', 'Ġzip', '_', 'file', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (049): ['f', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġbas', 'ename', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġfile', '_', 'dict', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġf', 'name', 'Ġ,', 'Ġzip', '_', 'file', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (036): ['fname', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġbasename', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest_path', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġfile_dict', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠSimpleUploadedFile', 'Ġ(', 'Ġfname', 'Ġ,', 'Ġzip_file', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 49
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "Image2ss = StatisticMap ( name = , collection = self . Collection3 , file = Image2ss . file = SimpleUploadedFile ( , file ( os . path . join ( self . test_path , Image2ss . save ( ) \n"
Original    (040): ['Image2ss', '=', 'StatisticMap', '(', 'name', '=', ',', 'collection', '=', 'self', '.', 'Collection3', ',', 'file', '=', 'Image2ss', '.', 'file', '=', 'SimpleUploadedFile', '(', ',', 'file', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'test_path', ',', 'Image2ss', '.', 'save', '(', ')', '\\n']
Tokenized   (057): ['<s>', 'Image', '2', 'ss', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '3', 'Ġ,', 'Ġfile', 'Ġ=', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (055): ['Image', '2', 'ss', 'Ġ=', 'ĠStat', 'istic', 'Map', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection', '3', 'Ġ,', 'Ġfile', 'Ġ=', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimple', 'Upload', 'ed', 'File', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest', '_', 'path', 'Ġ,', 'ĠImage', '2', 'ss', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (040): ['Image2ss', 'Ġ=', 'ĠStatisticMap', 'Ġ(', 'Ġname', 'Ġ=', 'Ġ,', 'Ġcollection', 'Ġ=', 'Ġself', 'Ġ.', 'ĠCollection3', 'Ġ,', 'Ġfile', 'Ġ=', 'ĠImage2ss', 'Ġ.', 'Ġfile', 'Ġ=', 'ĠSimpleUploadedFile', 'Ġ(', 'Ġ,', 'Ġfile', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtest_path', 'Ġ,', 'ĠImage2ss', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 55
===================================================================
Hidden states:  (13, 40, 768)
# Extracted words:  40
Sentence         : "acc_new = rho * acc + ( 1 - rho ) * g ** 2 \n"
Original    (016): ['acc_new', '=', 'rho', '*', 'acc', '+', '(', '1', '-', 'rho', ')', '*', 'g', '**', '2', '\\n']
Tokenized   (023): ['<s>', 'acc', '_', 'new', 'Ġ=', 'Ġr', 'ho', 'Ġ*', 'Ġacc', 'Ġ+', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġr', 'ho', 'Ġ)', 'Ġ*', 'Ġg', 'Ġ**', 'Ġ2', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['acc', '_', 'new', 'Ġ=', 'Ġr', 'ho', 'Ġ*', 'Ġacc', 'Ġ+', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġr', 'ho', 'Ġ)', 'Ġ*', 'Ġg', 'Ġ**', 'Ġ2', 'Ġ\\', 'n']
Detokenized (016): ['acc_new', 'Ġ=', 'Ġrho', 'Ġ*', 'Ġacc', 'Ġ+', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġrho', 'Ġ)', 'Ġ*', 'Ġg', 'Ġ**', 'Ġ2', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "gradient_scaling = T . sqrt ( acc_new + epsilon ) \n"
Original    (011): ['gradient_scaling', '=', 'T', '.', 'sqrt', '(', 'acc_new', '+', 'epsilon', ')', '\\n']
Tokenized   (022): ['<s>', 'gradient', '_', 'sc', 'aling', 'Ġ=', 'ĠT', 'Ġ.', 'Ġsq', 'rt', 'Ġ(', 'Ġacc', '_', 'new', 'Ġ+', 'Ġe', 'ps', 'ilon', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['gradient', '_', 'sc', 'aling', 'Ġ=', 'ĠT', 'Ġ.', 'Ġsq', 'rt', 'Ġ(', 'Ġacc', '_', 'new', 'Ġ+', 'Ġe', 'ps', 'ilon', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['gradient_scaling', 'Ġ=', 'ĠT', 'Ġ.', 'Ġsqrt', 'Ġ(', 'Ġacc_new', 'Ġ+', 'Ġepsilon', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "py_x = softmax ( T . dot ( h2 , w_o ) ) \n"
Original    (014): ['py_x', '=', 'softmax', '(', 'T', '.', 'dot', '(', 'h2', ',', 'w_o', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'py', '_', 'x', 'Ġ=', 'Ġsoft', 'max', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['py', '_', 'x', 'Ġ=', 'Ġsoft', 'max', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['py_x', 'Ġ=', 'Ġsoftmax', 'Ġ(', 'ĠT', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġh2', 'Ġ,', 'Ġw_o', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "w_h = init_weights ( ( 784 , 625 ) ) \n"
Original    (011): ['w_h', '=', 'init_weights', '(', '(', '784', ',', '625', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'w', '_', 'h', 'Ġ=', 'Ġinit', '_', 'weights', 'Ġ(', 'Ġ(', 'Ġ7', '84', 'Ġ,', 'Ġ625', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['w', '_', 'h', 'Ġ=', 'Ġinit', '_', 'weights', 'Ġ(', 'Ġ(', 'Ġ7', '84', 'Ġ,', 'Ġ625', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['w_h', 'Ġ=', 'Ġinit_weights', 'Ġ(', 'Ġ(', 'Ġ784', 'Ġ,', 'Ġ625', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "noise_h , noise_h2 , noise_py_x = model ( X , w_h , w_h2 , w_o , 0.2 , 0.5 ) \n"
Original    (021): ['noise_h', ',', 'noise_h2', ',', 'noise_py_x', '=', 'model', '(', 'X', ',', 'w_h', ',', 'w_h2', ',', 'w_o', ',', '0.2', ',', '0.5', ')', '\\n']
Tokenized   (045): ['<s>', 'no', 'ise', '_', 'h', 'Ġ,', 'Ġnoise', '_', 'h', '2', 'Ġ,', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ=', 'Ġmodel', 'Ġ(', 'ĠX', 'Ġ,', 'Ġw', '_', 'h', 'Ġ,', 'Ġw', '_', 'h', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (043): ['no', 'ise', '_', 'h', 'Ġ,', 'Ġnoise', '_', 'h', '2', 'Ġ,', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ=', 'Ġmodel', 'Ġ(', 'ĠX', 'Ġ,', 'Ġw', '_', 'h', 'Ġ,', 'Ġw', '_', 'h', '2', 'Ġ,', 'Ġw', '_', 'o', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['noise_h', 'Ġ,', 'Ġnoise_h2', 'Ġ,', 'Ġnoise_py_x', 'Ġ=', 'Ġmodel', 'Ġ(', 'ĠX', 'Ġ,', 'Ġw_h', 'Ġ,', 'Ġw_h2', 'Ġ,', 'Ġw_o', 'Ġ,', 'Ġ0.2', 'Ġ,', 'Ġ0.5', 'Ġ)', 'Ġ\\n']
Counter: 43
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "y_x = T . argmax ( py_x , axis = 1 ) \n"
Original    (013): ['y_x', '=', 'T', '.', 'argmax', '(', 'py_x', ',', 'axis', '=', '1', ')', '\\n']
Tokenized   (021): ['<s>', 'y', '_', 'x', 'Ġ=', 'ĠT', 'Ġ.', 'Ġarg', 'max', 'Ġ(', 'Ġpy', '_', 'x', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['y', '_', 'x', 'Ġ=', 'ĠT', 'Ġ.', 'Ġarg', 'max', 'Ġ(', 'Ġpy', '_', 'x', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['y_x', 'Ġ=', 'ĠT', 'Ġ.', 'Ġargmax', 'Ġ(', 'Ġpy_x', 'Ġ,', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "cost = T . mean ( T . nnet . categorical_crossentropy ( noise_py_x , Y ) ) \n"
Original    (018): ['cost', '=', 'T', '.', 'mean', '(', 'T', '.', 'nnet', '.', 'categorical_crossentropy', '(', 'noise_py_x', ',', 'Y', ')', ')', '\\n']
Tokenized   (031): ['<s>', 'cost', 'Ġ=', 'ĠT', 'Ġ.', 'Ġmean', 'Ġ(', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġcateg', 'orical', '_', 'cross', 'ent', 'ropy', 'Ġ(', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['cost', 'Ġ=', 'ĠT', 'Ġ.', 'Ġmean', 'Ġ(', 'ĠT', 'Ġ.', 'Ġn', 'net', 'Ġ.', 'Ġcateg', 'orical', '_', 'cross', 'ent', 'ropy', 'Ġ(', 'Ġnoise', '_', 'py', '_', 'x', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['cost', 'Ġ=', 'ĠT', 'Ġ.', 'Ġmean', 'Ġ(', 'ĠT', 'Ġ.', 'Ġnnet', 'Ġ.', 'Ġcategorical_crossentropy', 'Ġ(', 'Ġnoise_py_x', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "updates = RMSprop ( cost , params , lr = 0.001 ) \n"
Original    (013): ['updates', '=', 'RMSprop', '(', 'cost', ',', 'params', ',', 'lr', '=', '0.001', ')', '\\n']
Tokenized   (022): ['<s>', 'up', 'dates', 'Ġ=', 'ĠR', 'MS', 'prop', 'Ġ(', 'Ġcost', 'Ġ,', 'Ġparams', 'Ġ,', 'Ġl', 'r', 'Ġ=', 'Ġ0', '.', '001', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['up', 'dates', 'Ġ=', 'ĠR', 'MS', 'prop', 'Ġ(', 'Ġcost', 'Ġ,', 'Ġparams', 'Ġ,', 'Ġl', 'r', 'Ġ=', 'Ġ0', '.', '001', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['updates', 'Ġ=', 'ĠRMSprop', 'Ġ(', 'Ġcost', 'Ġ,', 'Ġparams', 'Ġ,', 'Ġlr', 'Ġ=', 'Ġ0.001', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "train = theano . function ( inputs = [ X , Y ] , outputs = cost , updates = updates , allow_input_downcast = True ) \n"
Original    (027): ['train', '=', 'theano', '.', 'function', '(', 'inputs', '=', '[', 'X', ',', 'Y', ']', ',', 'outputs', '=', 'cost', ',', 'updates', '=', 'updates', ',', 'allow_input_downcast', '=', 'True', ')', '\\n']
Tokenized   (036): ['<s>', 'train', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġcost', 'Ġ,', 'Ġupdates', 'Ġ=', 'Ġupdates', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['train', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġcost', 'Ġ,', 'Ġupdates', 'Ġ=', 'Ġupdates', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['train', 'Ġ=', 'Ġtheano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ,', 'ĠY', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġcost', 'Ġ,', 'Ġupdates', 'Ġ=', 'Ġupdates', 'Ġ,', 'Ġallow_input_downcast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "predict = theano . function ( inputs = [ X ] , outputs = y_x , allow_input_downcast = True ) \n"
Original    (021): ['predict', '=', 'theano', '.', 'function', '(', 'inputs', '=', '[', 'X', ']', ',', 'outputs', '=', 'y_x', ',', 'allow_input_downcast', '=', 'True', ')', '\\n']
Tokenized   (033): ['<s>', 'p', 'redict', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġy', '_', 'x', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['p', 'redict', 'Ġ=', 'Ġthe', 'ano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġy', '_', 'x', 'Ġ,', 'Ġallow', '_', 'input', '_', 'down', 'cast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['predict', 'Ġ=', 'Ġtheano', 'Ġ.', 'Ġfunction', 'Ġ(', 'Ġinputs', 'Ġ=', 'Ġ[', 'ĠX', 'Ġ]', 'Ġ,', 'Ġoutputs', 'Ġ=', 'Ġy_x', 'Ġ,', 'Ġallow_input_downcast', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "settings . DATABASE_CONFIG_DICT [ ] ) \n"
Original    (007): ['settings', '.', 'DATABASE_CONFIG_DICT', '[', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'settings', 'Ġ.', 'ĠD', 'AT', 'AB', 'ASE', '_', 'CON', 'FIG', '_', 'D', 'ICT', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['settings', 'Ġ.', 'ĠD', 'AT', 'AB', 'ASE', '_', 'CON', 'FIG', '_', 'D', 'ICT', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['settings', 'Ġ.', 'ĠDATABASE_CONFIG_DICT', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "TEMPLATES [ 0 ] [ ] [ ] = DEBUG \n"
Original    (011): ['TEMPLATES', '[', '0', ']', '[', ']', '[', ']', '=', 'DEBUG', '\\n']
Tokenized   (017): ['<s>', 'T', 'EM', 'PL', 'ATES', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠDEBUG', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['T', 'EM', 'PL', 'ATES', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠDEBUG', 'Ġ\\', 'n']
Detokenized (011): ['TEMPLATES', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠDEBUG', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "SECRET_KEY = env ( "DJANGO_SECRET_KEY" , default = ) \n"
Original    (010): ['SECRET_KEY', '=', 'env', '(', '"DJANGO_SECRET_KEY"', ',', 'default', '=', ')', '\\n']
Tokenized   (025): ['<s>', 'SEC', 'RET', '_', 'KEY', 'Ġ=', 'Ġenv', 'Ġ(', 'Ġ"', 'DJ', 'AN', 'GO', '_', 'SEC', 'RET', '_', 'KEY', '"', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['SEC', 'RET', '_', 'KEY', 'Ġ=', 'Ġenv', 'Ġ(', 'Ġ"', 'DJ', 'AN', 'GO', '_', 'SEC', 'RET', '_', 'KEY', '"', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['SECRET_KEY', 'Ġ=', 'Ġenv', 'Ġ(', 'Ġ"DJANGO_SECRET_KEY"', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "MIDDLEWARE_CLASSES += ( , ) \n"
Original    (006): ['MIDDLEWARE_CLASSES', '+=', '(', ',', ')', '\\n']
Tokenized   (016): ['<s>', 'M', 'ID', 'D', 'LE', 'WARE', '_', 'CLASS', 'ES', 'Ġ+=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['M', 'ID', 'D', 'LE', 'WARE', '_', 'CLASS', 'ES', 'Ġ+=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['MIDDLEWARE_CLASSES', 'Ġ+=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "INTERNAL_IPS = ( , , ) \n"
Original    (007): ['INTERNAL_IPS', '=', '(', ',', ',', ')', '\\n']
Tokenized   (014): ['<s>', 'IN', 'TERN', 'AL', '_', 'IPS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['IN', 'TERN', 'AL', '_', 'IPS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['INTERNAL_IPS', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "redirect_url = request . POST . get ( ) or \n"
Original    (011): ['redirect_url', '=', 'request', '.', 'POST', '.', 'get', '(', ')', 'or', '\\n']
Tokenized   (017): ['<s>', 'red', 'irect', '_', 'url', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['red', 'irect', '_', 'url', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġor', 'Ġ\\', 'n']
Detokenized (011): ['redirect_url', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġor', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "icon = self . get_plugin_icon ( ) , \n"
Original    (009): ['icon', '=', 'self', '.', 'get_plugin_icon', '(', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'icon', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'plugin', '_', 'icon', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['icon', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'plugin', '_', 'icon', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['icon', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget_plugin_icon', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "memoryprofiler_act . setEnabled ( is_memoryprofiler_installed ( ) ) \n"
Original    (009): ['memoryprofiler_act', '.', 'setEnabled', '(', 'is_memoryprofiler_installed', '(', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'memory', 'prof', 'iler', '_', 'act', 'Ġ.', 'Ġset', 'Enabled', 'Ġ(', 'Ġis', '_', 'memory', 'prof', 'iler', '_', 'installed', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['memory', 'prof', 'iler', '_', 'act', 'Ġ.', 'Ġset', 'Enabled', 'Ġ(', 'Ġis', '_', 'memory', 'prof', 'iler', '_', 'installed', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['memoryprofiler_act', 'Ġ.', 'ĠsetEnabled', 'Ġ(', 'Ġis_memoryprofiler_installed', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "wdir , args = None , None \n"
Original    (008): ['wdir', ',', 'args', '=', 'None', ',', 'None', '\\n']
Tokenized   (012): ['<s>', 'w', 'dir', 'Ġ,', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['w', 'dir', 'Ġ,', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ\\', 'n']
Detokenized (008): ['wdir', 'Ġ,', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ,', 'ĠNone', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "use_colors = self . get_option ( , True ) ) \n"
Original    (011): ['use_colors', '=', 'self', '.', 'get_option', '(', ',', 'True', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'use', '_', 'col', 'ors', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'option', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['use', '_', 'col', 'ors', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget', '_', 'option', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['use_colors', 'Ġ=', 'Ġself', 'Ġ.', 'Ġget_option', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "message_type = None , enum_type = None , containing_type = None , \n"
Original    (013): ['message_type', '=', 'None', ',', 'enum_type', '=', 'None', ',', 'containing_type', '=', 'None', ',', '\\n']
Tokenized   (022): ['<s>', 'message', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġenum', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcontaining', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['message', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġenum', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcontaining', '_', 'type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['message_type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġenum_type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcontaining_type', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "is_extension = False , extension_scope = None , \n"
Original    (009): ['is_extension', '=', 'False', ',', 'extension_scope', '=', 'None', ',', '\\n']
Tokenized   (017): ['<s>', 'is', '_', 'ext', 'ension', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġextension', '_', 'scope', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['is', '_', 'ext', 'ension', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġextension', '_', 'scope', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['is_extension', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġextension_scope', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_BATCHNOTIFICATIONREQUEST . fields_by_name [ ] . message_type = _PUSHNOTIFICATION \n"
Original    (010): ['_BATCHNOTIFICATIONREQUEST', '.', 'fields_by_name', '[', ']', '.', 'message_type', '=', '_PUSHNOTIFICATION', '\\n']
Tokenized   (031): ['<s>', '_', 'B', 'ATCH', 'NOT', 'IFIC', 'ATION', 'RE', 'QUEST', 'Ġ.', 'Ġfields', '_', 'by', '_', 'name', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmessage', '_', 'type', 'Ġ=', 'Ġ_', 'P', 'USH', 'NOT', 'IFIC', 'ATION', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['_', 'B', 'ATCH', 'NOT', 'IFIC', 'ATION', 'RE', 'QUEST', 'Ġ.', 'Ġfields', '_', 'by', '_', 'name', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmessage', '_', 'type', 'Ġ=', 'Ġ_', 'P', 'USH', 'NOT', 'IFIC', 'ATION', 'Ġ\\', 'n']
Detokenized (010): ['_BATCHNOTIFICATIONREQUEST', 'Ġ.', 'Ġfields_by_name', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmessage_type', 'Ġ=', 'Ġ_PUSHNOTIFICATION', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "expected_zip_content = [ "manifest.json" , "sd_bl.bin" , "sd_bl.dat" ] \n"
Original    (010): ['expected_zip_content', '=', '[', '"manifest.json"', ',', '"sd_bl.bin"', ',', '"sd_bl.dat"', ']', '\\n']
Tokenized   (034): ['<s>', 'expected', '_', 'zip', '_', 'content', 'Ġ=', 'Ġ[', 'Ġ"', 'man', 'ifest', '.', 'json', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'bin', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'dat', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['expected', '_', 'zip', '_', 'content', 'Ġ=', 'Ġ[', 'Ġ"', 'man', 'ifest', '.', 'json', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'bin', '"', 'Ġ,', 'Ġ"', 'sd', '_', 'bl', '.', 'dat', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['expected_zip_content', 'Ġ=', 'Ġ[', 'Ġ"manifest.json"', 'Ġ,', 'Ġ"sd_bl.bin"', 'Ġ,', 'Ġ"sd_bl.dat"', 'Ġ]', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sd_req = [ 0x1000 , 0xffff ] , \n"
Original    (009): ['sd_req', '=', '[', '0x1000', ',', '0xffff', ']', ',', '\\n']
Tokenized   (018): ['<s>', 'sd', '_', 'req', 'Ġ=', 'Ġ[', 'Ġ0', 'x', '1000', 'Ġ,', 'Ġ0', 'x', 'ffff', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['sd', '_', 'req', 'Ġ=', 'Ġ[', 'Ġ0', 'x', '1000', 'Ġ,', 'Ġ0', 'x', 'ffff', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['sd_req', 'Ġ=', 'Ġ[', 'Ġ0x1000', 'Ġ,', 'Ġ0xffff', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pkg_name = os . path . join ( self . work_directory , "mypackage.zip" ) \n"
Original    (015): ['pkg_name', '=', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', '"mypackage.zip"', ')', '\\n']
Tokenized   (027): ['<s>', 'pkg', '_', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġ"', 'my', 'package', '.', 'zip', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['pkg', '_', 'name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġ"', 'my', 'package', '.', 'zip', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['pkg_name', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork_directory', 'Ġ,', 'Ġ"mypackage.zip"', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "manifest = self . p . unpack_package ( os . path . join ( self . work_directory , pkg_name ) , unpacked_dir ) \n"
Original    (024): ['manifest', '=', 'self', '.', 'p', '.', 'unpack_package', '(', 'os', '.', 'path', '.', 'join', '(', 'self', '.', 'work_directory', ',', 'pkg_name', ')', ',', 'unpacked_dir', ')', '\\n']
Tokenized   (039): ['<s>', 'man', 'ifest', 'Ġ=', 'Ġself', 'Ġ.', 'Ġp', 'Ġ.', 'Ġun', 'pack', '_', 'package', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġp', 'kg', '_', 'name', 'Ġ)', 'Ġ,', 'Ġunp', 'acked', '_', 'dir', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['man', 'ifest', 'Ġ=', 'Ġself', 'Ġ.', 'Ġp', 'Ġ.', 'Ġun', 'pack', '_', 'package', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork', '_', 'directory', 'Ġ,', 'Ġp', 'kg', '_', 'name', 'Ġ)', 'Ġ,', 'Ġunp', 'acked', '_', 'dir', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['manifest', 'Ġ=', 'Ġself', 'Ġ.', 'Ġp', 'Ġ.', 'Ġunpack_package', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġself', 'Ġ.', 'Ġwork_directory', 'Ġ,', 'Ġpkg_name', 'Ġ)', 'Ġ,', 'Ġunpacked_dir', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "style = wx . richtext . RE_MULTILINE , value = ) \n"
Original    (012): ['style', '=', 'wx', '.', 'richtext', '.', 'RE_MULTILINE', ',', 'value', '=', ')', '\\n']
Tokenized   (022): ['<s>', 'style', 'Ġ=', 'Ġw', 'x', 'Ġ.', 'Ġrich', 'text', 'Ġ.', 'ĠRE', '_', 'M', 'ULT', 'IL', 'INE', 'Ġ,', 'Ġvalue', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['style', 'Ġ=', 'Ġw', 'x', 'Ġ.', 'Ġrich', 'text', 'Ġ.', 'ĠRE', '_', 'M', 'ULT', 'IL', 'INE', 'Ġ,', 'Ġvalue', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['style', 'Ġ=', 'Ġwx', 'Ġ.', 'Ġrichtext', 'Ġ.', 'ĠRE_MULTILINE', 'Ġ,', 'Ġvalue', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fgSizer1 . Add ( self . lblChangelt , 0 , wx . ALL , 5 ) \n"
Original    (017): ['fgSizer1', '.', 'Add', '(', 'self', '.', 'lblChangelt', ',', '0', ',', 'wx', '.', 'ALL', ',', '5', ')', '\\n']
Tokenized   (028): ['<s>', 'fg', 'S', 'izer', '1', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġl', 'bl', 'Ch', 'ang', 'elt', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['fg', 'S', 'izer', '1', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġl', 'bl', 'Ch', 'ang', 'elt', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['fgSizer1', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'ĠlblChangelt', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġwx', 'Ġ.', 'ĠALL', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sbThreshold . Add ( fgSizer1 , 0 , wx . EXPAND , 5 ) \n"
Original    (015): ['sbThreshold', '.', 'Add', '(', 'fgSizer1', ',', '0', ',', 'wx', '.', 'EXPAND', ',', '5', ')', '\\n']
Tokenized   (026): ['<s>', 'sb', 'Th', 'reshold', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġf', 'g', 'S', 'izer', '1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['sb', 'Th', 'reshold', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġf', 'g', 'S', 'izer', '1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sbThreshold', 'Ġ.', 'ĠAdd', 'Ġ(', 'ĠfgSizer1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġwx', 'Ġ.', 'ĠEXPAND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "bsValueThresh . Add ( sbThreshold , 1 , 0 , 5 ) \n"
Original    (013): ['bsValueThresh', '.', 'Add', '(', 'sbThreshold', ',', '1', ',', '0', ',', '5', ')', '\\n']
Tokenized   (022): ['<s>', 'bs', 'Value', 'Th', 'resh', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġs', 'b', 'Th', 'reshold', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['bs', 'Value', 'Th', 'resh', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġs', 'b', 'Th', 'reshold', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['bsValueThresh', 'Ġ.', 'ĠAdd', 'Ġ(', 'ĠsbThreshold', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "cbGapTimeChoices = [ u"second" , u"minute" , u"hour" , u"day" ] \n"
Original    (012): ['cbGapTimeChoices', '=', '[', 'u"second"', ',', 'u"minute"', ',', 'u"hour"', ',', 'u"day"', ']', '\\n']
Tokenized   (032): ['<s>', 'cb', 'G', 'ap', 'Time', 'Cho', 'ices', 'Ġ=', 'Ġ[', 'Ġu', '"', 'second', '"', 'Ġ,', 'Ġu', '"', 'minute', '"', 'Ġ,', 'Ġu', '"', 'hour', '"', 'Ġ,', 'Ġu', '"', 'day', '"', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['cb', 'G', 'ap', 'Time', 'Cho', 'ices', 'Ġ=', 'Ġ[', 'Ġu', '"', 'second', '"', 'Ġ,', 'Ġu', '"', 'minute', '"', 'Ġ,', 'Ġu', '"', 'hour', '"', 'Ġ,', 'Ġu', '"', 'day', '"', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['cbGapTimeChoices', 'Ġ=', 'Ġ[', 'Ġu"second"', 'Ġ,', 'Ġu"minute"', 'Ġ,', 'Ġu"hour"', 'Ġ,', 'Ġu"day"', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "fmt24hr = True , spinButton = self . sbBefore , oob_color = ) \n"
Original    (014): ['fmt24hr', '=', 'True', ',', 'spinButton', '=', 'self', '.', 'sbBefore', ',', 'oob_color', '=', ')', '\\n']
Tokenized   (026): ['<s>', 'f', 'mt', '24', 'hr', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġspin', 'Button', 'Ġ=', 'Ġself', 'Ġ.', 'Ġs', 'b', 'Before', 'Ġ,', 'Ġo', 'ob', '_', 'color', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['f', 'mt', '24', 'hr', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġspin', 'Button', 'Ġ=', 'Ġself', 'Ġ.', 'Ġs', 'b', 'Before', 'Ġ,', 'Ġo', 'ob', '_', 'color', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['fmt24hr', 'Ġ=', 'ĠTrue', 'Ġ,', 'ĠspinButton', 'Ġ=', 'Ġself', 'Ġ.', 'ĠsbBefore', 'Ġ,', 'Ġoob_color', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "bsButtons . Add ( self . btnOK , 1 , wx . ALL | wx . EXPAND , 5 ) \n"
Original    (021): ['bsButtons', '.', 'Add', '(', 'self', '.', 'btnOK', ',', '1', ',', 'wx', '.', 'ALL', '|', 'wx', '.', 'EXPAND', ',', '5', ')', '\\n']
Tokenized   (031): ['<s>', 'bs', 'But', 'tons', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġb', 'tn', 'OK', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ|', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['bs', 'But', 'tons', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'Ġb', 'tn', 'OK', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġw', 'x', 'Ġ.', 'ĠALL', 'Ġ|', 'Ġw', 'x', 'Ġ.', 'ĠEXP', 'AND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['bsButtons', 'Ġ.', 'ĠAdd', 'Ġ(', 'Ġself', 'Ġ.', 'ĠbtnOK', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġwx', 'Ġ.', 'ĠALL', 'Ġ|', 'Ġwx', 'Ġ.', 'ĠEXPAND', 'Ġ,', 'Ġ5', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "mat ( op2 . INC , ( elem_node [ op2 . i [ 0 ] ] , \n"
Original    (018): ['mat', '(', 'op2', '.', 'INC', ',', '(', 'elem_node', '[', 'op2', '.', 'i', '[', '0', ']', ']', ',', '\\n']
Tokenized   (026): ['<s>', 'mat', 'Ġ(', 'Ġop', '2', 'Ġ.', 'ĠINC', 'Ġ,', 'Ġ(', 'Ġele', 'm', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['mat', 'Ġ(', 'Ġop', '2', 'Ġ.', 'ĠINC', 'Ġ,', 'Ġ(', 'Ġele', 'm', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (018): ['mat', 'Ġ(', 'Ġop2', 'Ġ.', 'ĠINC', 'Ġ,', 'Ġ(', 'Ġelem_node', 'Ġ[', 'Ġop2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "elem_node [ op2 . i [ 1 ] ] ) ) , \n"
Original    (013): ['elem_node', '[', 'op2', '.', 'i', '[', '1', ']', ']', ')', ')', ',', '\\n']
Tokenized   (020): ['<s>', 'e', 'lem', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['e', 'lem', '_', 'node', 'Ġ[', 'Ġop', '2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['elem_node', 'Ġ[', 'Ġop2', 'Ġ.', 'Ġi', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "partition_size = NUM_ELE / 2 , \n"
Original    (007): ['partition_size', '=', 'NUM_ELE', '/', '2', ',', '\\n']
Tokenized   (016): ['<s>', 'part', 'ition', '_', 'size', 'Ġ=', 'ĠNUM', '_', 'E', 'LE', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['part', 'ition', '_', 'size', 'Ġ=', 'ĠNUM', '_', 'E', 'LE', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['partition_size', 'Ġ=', 'ĠNUM_ELE', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "statusBarAx . barh ( [ 0 ] , [ 100.0 * expNumber / len ( data . getPaths ( ) ) ] , \n"
Original    (024): ['statusBarAx', '.', 'barh', '(', '[', '0', ']', ',', '[', '100.0', '*', 'expNumber', '/', 'len', '(', 'data', '.', 'getPaths', '(', ')', ')', ']', ',', '\\n']
Tokenized   (035): ['<s>', 'status', 'Bar', 'Ax', 'Ġ.', 'Ġbar', 'h', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ100', '.', '0', 'Ġ*', 'Ġexp', 'Number', 'Ġ/', 'Ġlen', 'Ġ(', 'Ġdata', 'Ġ.', 'Ġget', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['status', 'Bar', 'Ax', 'Ġ.', 'Ġbar', 'h', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ100', '.', '0', 'Ġ*', 'Ġexp', 'Number', 'Ġ/', 'Ġlen', 'Ġ(', 'Ġdata', 'Ġ.', 'Ġget', 'Path', 's', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (024): ['statusBarAx', 'Ġ.', 'Ġbarh', 'Ġ(', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ100.0', 'Ġ*', 'ĠexpNumber', 'Ġ/', 'Ġlen', 'Ġ(', 'Ġdata', 'Ġ.', 'ĠgetPaths', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "fluxes , errors , photFlags = photometry . multirad ( image , x , y , \n"
Original    (017): ['fluxes', ',', 'errors', ',', 'photFlags', '=', 'photometry', '.', 'multirad', '(', 'image', ',', 'x', ',', 'y', ',', '\\n']
Tokenized   (026): ['<s>', 'f', 'lux', 'es', 'Ġ,', 'Ġerrors', 'Ġ,', 'Ġphot', 'Flags', 'Ġ=', 'Ġphot', 'ometry', 'Ġ.', 'Ġmult', 'ir', 'ad', 'Ġ(', 'Ġimage', 'Ġ,', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['f', 'lux', 'es', 'Ġ,', 'Ġerrors', 'Ġ,', 'Ġphot', 'Flags', 'Ġ=', 'Ġphot', 'ometry', 'Ġ.', 'Ġmult', 'ir', 'ad', 'Ġ(', 'Ġimage', 'Ġ,', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['fluxes', 'Ġ,', 'Ġerrors', 'Ġ,', 'ĠphotFlags', 'Ġ=', 'Ġphotometry', 'Ġ.', 'Ġmultirad', 'Ġ(', 'Ġimage', 'Ġ,', 'Ġx', 'Ġ,', 'Ġy', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "meanComparisonStars , meanComparisonStarErrors = data . calcMeanComparison_multirad ( ccdGain = data . ccdGain ) \n"
Original    (015): ['meanComparisonStars', ',', 'meanComparisonStarErrors', '=', 'data', '.', 'calcMeanComparison_multirad', '(', 'ccdGain', '=', 'data', '.', 'ccdGain', ')', '\\n']
Tokenized   (040): ['<s>', 'mean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġmean', 'Compar', 'ison', 'Star', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcalc', 'Me', 'an', 'Compar', 'ison', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġc', 'cd', 'G', 'ain', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġc', 'cd', 'G', 'ain', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['mean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġmean', 'Compar', 'ison', 'Star', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcalc', 'Me', 'an', 'Compar', 'ison', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġc', 'cd', 'G', 'ain', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġc', 'cd', 'G', 'ain', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['meanComparisonStars', 'Ġ,', 'ĠmeanComparisonStarErrors', 'Ġ=', 'Ġdata', 'Ġ.', 'ĠcalcMeanComparison_multirad', 'Ġ(', 'ĠccdGain', 'Ġ=', 'Ġdata', 'Ġ.', 'ĠccdGain', 'Ġ)', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "lightCurves , lightCurveErrors = data . computeLightCurve_multirad ( meanComparisonStars , \n"
Original    (011): ['lightCurves', ',', 'lightCurveErrors', '=', 'data', '.', 'computeLightCurve_multirad', '(', 'meanComparisonStars', ',', '\\n']
Tokenized   (030): ['<s>', 'light', 'Cur', 'ves', 'Ġ,', 'Ġlight', 'Cur', 've', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcompute', 'Light', 'Cur', 've', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġmean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['light', 'Cur', 'ves', 'Ġ,', 'Ġlight', 'Cur', 've', 'Er', 'rors', 'Ġ=', 'Ġdata', 'Ġ.', 'Ġcompute', 'Light', 'Cur', 've', '_', 'mult', 'ir', 'ad', 'Ġ(', 'Ġmean', 'Compar', 'ison', 'Stars', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['lightCurves', 'Ġ,', 'ĠlightCurveErrors', 'Ġ=', 'Ġdata', 'Ġ.', 'ĠcomputeLightCurve_multirad', 'Ġ(', 'ĠmeanComparisonStars', 'Ġ,', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "json_data = self . _send_request ( , url , params = params ) \n"
Original    (014): ['json_data', '=', 'self', '.', '_send_request', '(', ',', 'url', ',', 'params', '=', 'params', ')', '\\n']
Tokenized   (022): ['<s>', 'json', '_', 'data', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'send', '_', 'request', 'Ġ(', 'Ġ,', 'Ġurl', 'Ġ,', 'Ġparams', 'Ġ=', 'Ġparams', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['json', '_', 'data', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'send', '_', 'request', 'Ġ(', 'Ġ,', 'Ġurl', 'Ġ,', 'Ġparams', 'Ġ=', 'Ġparams', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['json_data', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_send_request', 'Ġ(', 'Ġ,', 'Ġurl', 'Ġ,', 'Ġparams', 'Ġ=', 'Ġparams', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "mkdir ( env . hosts_data . log_path ( ) ) \n"
Original    (011): ['mkdir', '(', 'env', '.', 'hosts_data', '.', 'log_path', '(', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'mk', 'dir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġlog', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mk', 'dir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġlog', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['mkdir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġlog_path', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "StringIO ( env . hosts_data . celery_supervisor_config ( ) ) , \n"
Original    (012): ['StringIO', '(', 'env', '.', 'hosts_data', '.', 'celery_supervisor_config', '(', ')', ')', ',', '\\n']
Tokenized   (024): ['<s>', 'String', 'IO', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['String', 'IO', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['StringIO', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġcelery_supervisor_config', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "env . hosts_data . celery_supervisor_config_path ( ) , \n"
Original    (009): ['env', '.', 'hosts_data', '.', 'celery_supervisor_config_path', '(', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'env', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['env', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['env', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġcelery_supervisor_config_path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "rmdir ( env . hosts_data . celery_supervisor_config_path ( ) , sudo_access = True ) \n"
Original    (015): ['rmdir', '(', 'env', '.', 'hosts_data', '.', 'celery_supervisor_config_path', '(', ')', ',', 'sudo_access', '=', 'True', ')', '\\n']
Tokenized   (032): ['<s>', 'r', 'md', 'ir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġsudo', '_', 'access', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['r', 'md', 'ir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġcel', 'ery', '_', 'super', 'visor', '_', 'config', '_', 'path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġsudo', '_', 'access', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['rmdir', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġcelery_supervisor_config_path', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġsudo_access', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "sudo ( . format ( env . hosts_data . application_name ( ) ) ) \n"
Original    (015): ['sudo', '(', '.', 'format', '(', 'env', '.', 'hosts_data', '.', 'application_name', '(', ')', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'sudo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġapplication', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['sudo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts', '_', 'data', 'Ġ.', 'Ġapplication', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sudo', 'Ġ(', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġhosts_data', 'Ġ.', 'Ġapplication_name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "collection_response = SharedCollectionResponse ( json . loads ( self . send ( ) . content ) ) \n"
Original    (018): ['collection_response', '=', 'SharedCollectionResponse', '(', 'json', '.', 'loads', '(', 'self', '.', 'send', '(', ')', '.', 'content', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'collection', '_', 'response', 'Ġ=', 'ĠShared', 'Collection', 'Response', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsend', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcontent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['collection', '_', 'response', 'Ġ=', 'ĠShared', 'Collection', 'Response', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsend', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcontent', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['collection_response', 'Ġ=', 'ĠSharedCollectionResponse', 'Ġ(', 'Ġjson', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġself', 'Ġ.', 'Ġsend', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcontent', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "libraries = [ "sodium" ] , \n"
Original    (007): ['libraries', '=', '[', '"sodium"', ']', ',', '\\n']
Tokenized   (014): ['<s>', 'l', 'ibraries', 'Ġ=', 'Ġ[', 'Ġ"', 's', 'odium', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['l', 'ibraries', 'Ġ=', 'Ġ[', 'Ġ"', 's', 'odium', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['libraries', 'Ġ=', 'Ġ[', 'Ġ"sodium"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "number = 2 , type = 12 , cpp_type = 9 , label = 2 , \n"
Original    (017): ['number', '=', '2', ',', 'type', '=', '12', ',', 'cpp_type', '=', '9', ',', 'label', '=', '2', ',', '\\n']
Tokenized   (023): ['<s>', 'number', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġ12', 'Ġ,', 'Ġc', 'pp', '_', 'type', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġlabel', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['number', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġ12', 'Ġ,', 'Ġc', 'pp', '_', 'type', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġlabel', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['number', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġtype', 'Ġ=', 'Ġ12', 'Ġ,', 'Ġcpp_type', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġlabel', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "has_default_value = False , default_value = _b ( "" ) , \n"
Original    (012): ['has_default_value', '=', 'False', ',', 'default_value', '=', '_b', '(', '""', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'has', '_', 'default', '_', 'value', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ=', 'Ġ_', 'b', 'Ġ(', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['has', '_', 'default', '_', 'value', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ=', 'Ġ_', 'b', 'Ġ(', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['has_default_value', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġdefault_value', 'Ġ=', 'Ġ_b', 'Ġ(', 'Ġ""', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "PeerSeeds = _reflection . GeneratedProtocolMessageType ( , ( _message . Message , ) , dict ( \n"
Original    (017): ['PeerSeeds', '=', '_reflection', '.', 'GeneratedProtocolMessageType', '(', ',', '(', '_message', '.', 'Message', ',', ')', ',', 'dict', '(', '\\n']
Tokenized   (031): ['<s>', 'Pe', 'er', 'S', 'eeds', 'Ġ=', 'Ġ_', 'ref', 'lection', 'Ġ.', 'ĠGener', 'ated', 'Prot', 'ocol', 'Message', 'Type', 'Ġ(', 'Ġ,', 'Ġ(', 'Ġ_', 'message', 'Ġ.', 'ĠMessage', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġdict', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['Pe', 'er', 'S', 'eeds', 'Ġ=', 'Ġ_', 'ref', 'lection', 'Ġ.', 'ĠGener', 'ated', 'Prot', 'ocol', 'Message', 'Type', 'Ġ(', 'Ġ,', 'Ġ(', 'Ġ_', 'message', 'Ġ.', 'ĠMessage', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġdict', 'Ġ(', 'Ġ\\', 'n']
Detokenized (017): ['PeerSeeds', 'Ġ=', 'Ġ_reflection', 'Ġ.', 'ĠGeneratedProtocolMessageType', 'Ġ(', 'Ġ,', 'Ġ(', 'Ġ_message', 'Ġ.', 'ĠMessage', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġdict', 'Ġ(', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "__module__ = \n"
Original    (003): ['__module__', '=', '\\n']
Tokenized   (008): ['<s>', '__', 'module', '__', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['__', 'module', '__', 'Ġ=', 'Ġ\\', 'n']
Detokenized (003): ['__module__', 'Ġ=', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "tstream = BytearrayStream ( istream . read ( self . length ) ) \n"
Original    (014): ['tstream', '=', 'BytearrayStream', '(', 'istream', '.', 'read', '(', 'self', '.', 'length', ')', ')', '\\n']
Tokenized   (024): ['<s>', 't', 'stream', 'Ġ=', 'ĠBy', 't', 'ear', 'ray', 'Stream', 'Ġ(', 'Ġis', 't', 'ream', 'Ġ.', 'Ġread', 'Ġ(', 'Ġself', 'Ġ.', 'Ġlength', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['t', 'stream', 'Ġ=', 'ĠBy', 't', 'ear', 'ray', 'Stream', 'Ġ(', 'Ġis', 't', 'ream', 'Ġ.', 'Ġread', 'Ġ(', 'Ġself', 'Ġ.', 'Ġlength', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['tstream', 'Ġ=', 'ĠBytearrayStream', 'Ġ(', 'Ġistream', 'Ġ.', 'Ġread', 'Ġ(', 'Ġself', 'Ġ.', 'Ġlength', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "opts , args = parser . parse_args ( sys . argv [ 1 : ] ) \n"
Original    (017): ['opts', ',', 'args', '=', 'parser', '.', 'parse_args', '(', 'sys', '.', 'argv', '[', '1', ':', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'op', 'ts', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġparser', 'Ġ.', 'Ġparse', '_', 'args', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['op', 'ts', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġparser', 'Ġ.', 'Ġparse', '_', 'args', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['opts', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġparser', 'Ġ.', 'Ġparse_args', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : ""{0}" . format ( uid ) ) \n"
Original    (008): ['"{0}"', '.', 'format', '(', 'uid', ')', ')', '\\n']
Tokenized   (015): ['<s>', '"', '{', '0', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġu', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['"', '{', '0', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġu', 'id', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['"{0}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġuid', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : ""located." . format ( path ) \n"
Original    (007): ['"located."', '.', 'format', '(', 'path', ')', '\\n']
Tokenized   (013): ['<s>', '"', 'l', 'ocated', '."', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['"', 'l', 'ocated', '."', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['"located."', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpath', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "discover_versions . DiscoverVersionsResponsePayload , ** kwargs ) \n"
Original    (008): ['discover_versions', '.', 'DiscoverVersionsResponsePayload', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (020): ['<s>', 'd', 'iscover', '_', 'versions', 'Ġ.', 'ĠDiscover', 'Versions', 'Response', 'Pay', 'load', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['d', 'iscover', '_', 'versions', 'Ġ.', 'ĠDiscover', 'Versions', 'Response', 'Pay', 'load', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['discover_versions', 'Ġ.', 'ĠDiscoverVersionsResponsePayload', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "sqltypes . Base . metadata . create_all ( self . engine ) \n"
Original    (013): ['sqltypes', '.', 'Base', '.', 'metadata', '.', 'create_all', '(', 'self', '.', 'engine', ')', '\\n']
Tokenized   (019): ['<s>', 'sql', 'types', 'Ġ.', 'ĠBase', 'Ġ.', 'Ġmetadata', 'Ġ.', 'Ġcreate', '_', 'all', 'Ġ(', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['sql', 'types', 'Ġ.', 'ĠBase', 'Ġ.', 'Ġmetadata', 'Ġ.', 'Ġcreate', '_', 'all', 'Ġ(', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['sqltypes', 'Ġ.', 'ĠBase', 'Ġ.', 'Ġmetadata', 'Ġ.', 'Ġcreate_all', 'Ġ(', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "enums . OpaqueDataType . NONE , \n"
Original    (007): ['enums', '.', 'OpaqueDataType', '.', 'NONE', ',', '\\n']
Tokenized   (015): ['<s>', 'en', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['en', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['enums', 'Ġ.', 'ĠOpaqueDataType', 'Ġ.', 'ĠNONE', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "binascii . hexlify ( self . bytes_a ) , enums . OpaqueDataType . NONE ) \n"
Original    (016): ['binascii', '.', 'hexlify', '(', 'self', '.', 'bytes_a', ')', ',', 'enums', '.', 'OpaqueDataType', '.', 'NONE', ')', '\\n']
Tokenized   (031): ['<s>', 'bin', 'as', 'ci', 'i', 'Ġ.', 'Ġhex', 'l', 'ify', 'Ġ(', 'Ġself', 'Ġ.', 'Ġbytes', '_', 'a', 'Ġ)', 'Ġ,', 'Ġen', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['bin', 'as', 'ci', 'i', 'Ġ.', 'Ġhex', 'l', 'ify', 'Ġ(', 'Ġself', 'Ġ.', 'Ġbytes', '_', 'a', 'Ġ)', 'Ġ,', 'Ġen', 'ums', 'Ġ.', 'ĠOp', 'aque', 'Data', 'Type', 'Ġ.', 'ĠN', 'ONE', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['binascii', 'Ġ.', 'Ġhexlify', 'Ġ(', 'Ġself', 'Ġ.', 'Ġbytes_a', 'Ġ)', 'Ġ,', 'Ġenums', 'Ġ.', 'ĠOpaqueDataType', 'Ġ.', 'ĠNONE', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "Session = sessionmaker ( bind = self . engine ) \n"
Original    (011): ['Session', '=', 'sessionmaker', '(', 'bind', '=', 'self', '.', 'engine', ')', '\\n']
Tokenized   (015): ['<s>', 'Session', 'Ġ=', 'Ġsession', 'maker', 'Ġ(', 'Ġbind', 'Ġ=', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Session', 'Ġ=', 'Ġsession', 'maker', 'Ġ(', 'Ġbind', 'Ġ=', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['Session', 'Ġ=', 'Ġsessionmaker', 'Ġ(', 'Ġbind', 'Ġ=', 'Ġself', 'Ġ.', 'Ġengine', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "get_obj = session . query ( OpaqueObject ) . filter ( \n"
Original    (012): ['get_obj', '=', 'session', '.', 'query', '(', 'OpaqueObject', ')', '.', 'filter', '(', '\\n']
Tokenized   (019): ['<s>', 'get', '_', 'obj', 'Ġ=', 'Ġsession', 'Ġ.', 'Ġquery', 'Ġ(', 'ĠOp', 'aque', 'Object', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['get', '_', 'obj', 'Ġ=', 'Ġsession', 'Ġ.', 'Ġquery', 'Ġ(', 'ĠOp', 'aque', 'Object', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġ\\', 'n']
Detokenized (012): ['get_obj', 'Ġ=', 'Ġsession', 'Ġ.', 'Ġquery', 'Ġ(', 'ĠOpaqueObject', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ManagedObject . unique_identifier == obj . unique_identifier \n"
Original    (008): ['ManagedObject', '.', 'unique_identifier', '==', 'obj', '.', 'unique_identifier', '\\n']
Tokenized   (019): ['<s>', 'Man', 'aged', 'Object', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ==', 'Ġobj', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['Man', 'aged', 'Object', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ==', 'Ġobj', 'Ġ.', 'Ġunique', '_', 'ident', 'ifier', 'Ġ\\', 'n']
Detokenized (008): ['ManagedObject', 'Ġ.', 'Ġunique_identifier', 'Ġ==', 'Ġobj', 'Ġ.', 'Ġunique_identifier', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "0 ) ) \n"
Original    (004): ['0', ')', ')', '\\n']
Tokenized   (007): ['<s>', '0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (004): ['0', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "expected_mo_names . append ( sqltypes . ManagedObjectName ( expected_names [ 1 ] , \n"
Original    (014): ['expected_mo_names', '.', 'append', '(', 'sqltypes', '.', 'ManagedObjectName', '(', 'expected_names', '[', '1', ']', ',', '\\n']
Tokenized   (027): ['<s>', 'expected', '_', 'mo', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġsql', 'types', 'Ġ.', 'ĠMan', 'aged', 'Object', 'Name', 'Ġ(', 'Ġexpected', '_', 'names', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['expected', '_', 'mo', '_', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġsql', 'types', 'Ġ.', 'ĠMan', 'aged', 'Object', 'Name', 'Ġ(', 'Ġexpected', '_', 'names', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['expected_mo_names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġsqltypes', 'Ġ.', 'ĠManagedObjectName', 'Ġ(', 'Ġexpected_names', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "expected_names = [ first_name , added_name ] \n"
Original    (008): ['expected_names', '=', '[', 'first_name', ',', 'added_name', ']', '\\n']
Tokenized   (017): ['<s>', 'expected', '_', 'names', 'Ġ=', 'Ġ[', 'Ġfirst', '_', 'name', 'Ġ,', 'Ġadded', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['expected', '_', 'names', 'Ġ=', 'Ġ[', 'Ġfirst', '_', 'name', 'Ġ,', 'Ġadded', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['expected_names', 'Ġ=', 'Ġ[', 'Ġfirst_name', 'Ġ,', 'Ġadded_name', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "] } , \n"
Original    (004): [']', '}', ',', '\\n']
Tokenized   (007): ['<s>', ']', 'Ġ}', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (005): [']', 'Ġ}', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): [']', 'Ġ}', 'Ġ,', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "types . MethodType ( _lib_dir_option , None , MSVCCompiler ) ) \n"
Original    (012): ['types', '.', 'MethodType', '(', '_lib_dir_option', ',', 'None', ',', 'MSVCCompiler', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'types', 'Ġ.', 'ĠMethod', 'Type', 'Ġ(', 'Ġ_', 'lib', '_', 'dir', '_', 'option', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠMS', 'V', 'CC', 'omp', 'iler', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['types', 'Ġ.', 'ĠMethod', 'Type', 'Ġ(', 'Ġ_', 'lib', '_', 'dir', '_', 'option', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠMS', 'V', 'CC', 'omp', 'iler', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['types', 'Ġ.', 'ĠMethodType', 'Ġ(', 'Ġ_lib_dir_option', 'Ġ,', 'ĠNone', 'Ġ,', 'ĠMSVCCompiler', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "setup ( ** kwds ) \n"
Original    (006): ['setup', '(', '**', 'kwds', ')', '\\n']
Tokenized   (011): ['<s>', 'setup', 'Ġ(', 'Ġ**', 'Ġk', 'w', 'ds', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['setup', 'Ġ(', 'Ġ**', 'Ġk', 'w', 'ds', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['setup', 'Ġ(', 'Ġ**', 'Ġkwds', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "intersphinx_mapping = { : None } \n"
Original    (007): ['intersphinx_mapping', '=', '{', ':', 'None', '}', '\\n']
Tokenized   (015): ['<s>', 'inters', 'ph', 'inx', '_', 'm', 'apping', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['inters', 'ph', 'inx', '_', 'm', 'apping', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['intersphinx_mapping', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "new_w = int ( width * wrat ) \n"
Original    (009): ['new_w', '=', 'int', '(', 'width', '*', 'wrat', ')', '\\n']
Tokenized   (015): ['<s>', 'new', '_', 'w', 'Ġ=', 'Ġint', 'Ġ(', 'Ġwidth', 'Ġ*', 'Ġwr', 'at', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['new', '_', 'w', 'Ġ=', 'Ġint', 'Ġ(', 'Ġwidth', 'Ġ*', 'Ġwr', 'at', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['new_w', 'Ġ=', 'Ġint', 'Ġ(', 'Ġwidth', 'Ġ*', 'Ġwrat', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "im . getbbox ( ) , Image . BICUBIC ) \n"
Original    (011): ['im', '.', 'getbbox', '(', ')', ',', 'Image', '.', 'BICUBIC', ')', '\\n']
Tokenized   (019): ['<s>', 'im', 'Ġ.', 'Ġget', 'b', 'box', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠImage', 'Ġ.', 'ĠB', 'IC', 'UB', 'IC', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['im', 'Ġ.', 'Ġget', 'b', 'box', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠImage', 'Ġ.', 'ĠB', 'IC', 'UB', 'IC', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['im', 'Ġ.', 'Ġgetbbox', 'Ġ(', 'Ġ)', 'Ġ,', 'ĠImage', 'Ġ.', 'ĠBICUBIC', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "resize_image ( os . path . abspath ( os . path . join ( , dest + ) ) ) \n"
Original    (021): ['resize_image', '(', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'join', '(', ',', 'dest', '+', ')', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'res', 'ize', '_', 'image', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ,', 'Ġdest', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['res', 'ize', '_', 'image', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ,', 'Ġdest', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['resize_image', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ,', 'Ġdest', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "f_x = Float ( 0.0 , iotype = "out" ) \n"
Original    (011): ['f_x', '=', 'Float', '(', '0.0', ',', 'iotype', '=', '"out"', ')', '\\n']
Tokenized   (021): ['<s>', 'f', '_', 'x', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ"', 'out', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['f', '_', 'x', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ"', 'out', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['f_x', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0.0', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ"out"', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "doe_c = [ 0.1 , 0.2 , 0.3 , 0.5 , 0.7 , 0.8 , 0.9 ] + doe_e \n"
Original    (020): ['doe_c', '=', '[', '0.1', ',', '0.2', ',', '0.3', ',', '0.5', ',', '0.7', ',', '0.8', ',', '0.9', ']', '+', 'doe_e', '\\n']
Tokenized   (043): ['<s>', 'd', 'oe', '_', 'c', 'Ġ=', 'Ġ[', 'Ġ0', '.', '1', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '3', 'Ġ,', 'Ġ0', '.', '5', 'Ġ,', 'Ġ0', '.', '7', 'Ġ,', 'Ġ0', '.', '8', 'Ġ,', 'Ġ0', '.', '9', 'Ġ]', 'Ġ+', 'Ġdo', 'e', '_', 'e', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['d', 'oe', '_', 'c', 'Ġ=', 'Ġ[', 'Ġ0', '.', '1', 'Ġ,', 'Ġ0', '.', '2', 'Ġ,', 'Ġ0', '.', '3', 'Ġ,', 'Ġ0', '.', '5', 'Ġ,', 'Ġ0', '.', '7', 'Ġ,', 'Ġ0', '.', '8', 'Ġ,', 'Ġ0', '.', '9', 'Ġ]', 'Ġ+', 'Ġdo', 'e', '_', 'e', 'Ġ\\', 'n']
Detokenized (020): ['doe_c', 'Ġ=', 'Ġ[', 'Ġ0.1', 'Ġ,', 'Ġ0.2', 'Ġ,', 'Ġ0.3', 'Ġ,', 'Ġ0.5', 'Ġ,', 'Ġ0.7', 'Ġ,', 'Ġ0.8', 'Ġ,', 'Ġ0.9', 'Ġ]', 'Ġ+', 'Ġdoe_e', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "responses = ( , ) , nfi = self . nfi ) ) \n"
Original    (014): ['responses', '=', '(', ',', ')', ',', 'nfi', '=', 'self', '.', 'nfi', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'respons', 'es', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġn', 'fi', 'Ġ=', 'Ġself', 'Ġ.', 'Ġn', 'fi', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['respons', 'es', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġn', 'fi', 'Ġ=', 'Ġself', 'Ġ.', 'Ġn', 'fi', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['responses', 'Ġ=', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġnfi', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnfi', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "sigma_cok = np . array ( [ d . sigma for d in sim_cok . mm_checker . case_outputs . meta_model . f_x ] ) \n"
Original    (025): ['sigma_cok', '=', 'np', '.', 'array', '(', '[', 'd', '.', 'sigma', 'for', 'd', 'in', 'sim_cok', '.', 'mm_checker', '.', 'case_outputs', '.', 'meta_model', '.', 'f_x', ']', ')', '\\n']
Tokenized   (046): ['<s>', 's', 'igma', '_', 'c', 'ok', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġs', 'igma', 'Ġfor', 'Ġd', 'Ġin', 'Ġsim', '_', 'c', 'ok', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmeta', '_', 'model', 'Ġ.', 'Ġf', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (044): ['s', 'igma', '_', 'c', 'ok', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġs', 'igma', 'Ġfor', 'Ġd', 'Ġin', 'Ġsim', '_', 'c', 'ok', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmeta', '_', 'model', 'Ġ.', 'Ġf', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['sigma_cok', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġsigma', 'Ġfor', 'Ġd', 'Ġin', 'Ġsim_cok', 'Ġ.', 'Ġmm_checker', 'Ġ.', 'Ġcase_outputs', 'Ġ.', 'Ġmeta_model', 'Ġ.', 'Ġf_x', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 44
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "actual = sim_k . mm_checker . case_outputs . model . f_x \n"
Original    (012): ['actual', '=', 'sim_k', '.', 'mm_checker', '.', 'case_outputs', '.', 'model', '.', 'f_x', '\\n']
Tokenized   (025): ['<s>', 'actual', 'Ġ=', 'Ġsim', '_', 'k', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġf', '_', 'x', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['actual', 'Ġ=', 'Ġsim', '_', 'k', 'Ġ.', 'Ġmm', '_', 'check', 'er', 'Ġ.', 'Ġcase', '_', 'output', 's', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġf', '_', 'x', 'Ġ\\', 'n']
Detokenized (012): ['actual', 'Ġ=', 'Ġsim_k', 'Ġ.', 'Ġmm_checker', 'Ġ.', 'Ġcase_outputs', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġf_x', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "predicted_cok - 2 * sigma_cok , facecolor = , alpha = 0.2 ) \n"
Original    (014): ['predicted_cok', '-', '2', '*', 'sigma_cok', ',', 'facecolor', '=', ',', 'alpha', '=', '0.2', ')', '\\n']
Tokenized   (028): ['<s>', 'pred', 'icted', '_', 'c', 'ok', 'Ġ-', 'Ġ2', 'Ġ*', 'Ġs', 'igma', '_', 'c', 'ok', 'Ġ,', 'Ġface', 'color', 'Ġ=', 'Ġ,', 'Ġalpha', 'Ġ=', 'Ġ0', '.', '2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['pred', 'icted', '_', 'c', 'ok', 'Ġ-', 'Ġ2', 'Ġ*', 'Ġs', 'igma', '_', 'c', 'ok', 'Ġ,', 'Ġface', 'color', 'Ġ=', 'Ġ,', 'Ġalpha', 'Ġ=', 'Ġ0', '.', '2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['predicted_cok', 'Ġ-', 'Ġ2', 'Ġ*', 'Ġsigma_cok', 'Ġ,', 'Ġfacecolor', 'Ġ=', 'Ġ,', 'Ġalpha', 'Ġ=', 'Ġ0.2', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "newsetupfile = os . path . join ( os . path . dirname ( setupfile ) , \n"
Original    (018): ['newsetupfile', '=', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'dirname', '(', 'setupfile', ')', ',', '\\n']
Tokenized   (025): ['<s>', 'new', 'setup', 'file', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġsetup', 'file', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', 'setup', 'file', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġsetup', 'file', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (018): ['newsetupfile', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġsetupfile', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "srcdir = os . path . abspath ( os . path . expanduser ( srcdir ) ) . replace ( , ) \n"
Original    (023): ['srcdir', '=', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'expanduser', '(', 'srcdir', ')', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (030): ['<s>', 'src', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġsrc', 'dir', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['src', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġsrc', 'dir', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['srcdir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpanduser', 'Ġ(', 'Ġsrcdir', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "cmd . extend ( [ , destdir ] ) \n"
Original    (010): ['cmd', '.', 'extend', '(', '[', ',', 'destdir', ']', ')', '\\n']
Tokenized   (014): ['<s>', 'cmd', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġdest', 'dir', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['cmd', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġdest', 'dir', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['cmd', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġdestdir', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "list ( newfiles ) ) \n"
Original    (006): ['list', '(', 'newfiles', ')', ')', '\\n']
Tokenized   (010): ['<s>', 'list', 'Ġ(', 'Ġnew', 'files', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['list', 'Ġ(', 'Ġnew', 'files', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['list', 'Ġ(', 'Ġnewfiles', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "destdir = os . path . abspath ( os . path . expanduser ( options . destdir ) ) \n"
Original    (020): ['destdir', '=', 'os', '.', 'path', '.', 'abspath', '(', 'os', '.', 'path', '.', 'expanduser', '(', 'options', '.', 'destdir', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'dest', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġdest', 'dir', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['dest', 'dir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpand', 'user', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġdest', 'dir', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['destdir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġexpanduser', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġdestdir', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "all_names . extend ( [ prefix + name \n"
Original    (009): ['all_names', '.', 'extend', '(', '[', 'prefix', '+', 'name', '\\n']
Tokenized   (014): ['<s>', 'all', '_', 'names', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġname', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['all', '_', 'names', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġname', 'Ġ\\', 'n']
Detokenized (009): ['all_names', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġname', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "lnames = [ prefix + rec for rec in driver [ ] ] \n"
Original    (014): ['lnames', '=', '[', 'prefix', '+', 'rec', 'for', 'rec', 'in', 'driver', '[', ']', ']', '\\n']
Tokenized   (018): ['<s>', 'l', 'names', 'Ġ=', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġrec', 'Ġfor', 'Ġrec', 'Ġin', 'Ġdriver', 'Ġ[', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['l', 'names', 'Ġ=', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġrec', 'Ġfor', 'Ġrec', 'Ġin', 'Ġdriver', 'Ġ[', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['lnames', 'Ġ=', 'Ġ[', 'Ġprefix', 'Ġ+', 'Ġrec', 'Ġfor', 'Ġrec', 'Ġin', 'Ġdriver', 'Ġ[', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "driver_grp = self . _inp [ ] [ driver_name ] \n"
Original    (011): ['driver_grp', '=', 'self', '.', '_inp', '[', ']', '[', 'driver_name', ']', '\\n']
Tokenized   (021): ['<s>', 'driver', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['driver', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['driver_grp', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_inp', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver_name', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "iteration_grp = self . _inp [ ] [ driver_name ] [ iteration_case_name ] \n"
Original    (014): ['iteration_grp', '=', 'self', '.', '_inp', '[', ']', '[', 'driver_name', ']', '[', 'iteration_case_name', ']', '\\n']
Tokenized   (029): ['<s>', 'iter', 'ation', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ[', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['iter', 'ation', '_', 'gr', 'p', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver', '_', 'name', 'Ġ]', 'Ġ[', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['iteration_grp', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_inp', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġdriver_name', 'Ġ]', 'Ġ[', 'Ġiteration_case_name', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "info = self . read_iteration_case_from_hdf5 ( self . _inp , driver_name , iteration_case_name ) yield info \n"
Original    (017): ['info', '=', 'self', '.', 'read_iteration_case_from_hdf5', '(', 'self', '.', '_inp', ',', 'driver_name', ',', 'iteration_case_name', ')', 'yield', 'info', '\\n']
Tokenized   (039): ['<s>', 'info', 'Ġ=', 'Ġself', 'Ġ.', 'Ġread', '_', 'iter', 'ation', '_', 'case', '_', 'from', '_', 'h', 'df', '5', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ,', 'Ġdriver', '_', 'name', 'Ġ,', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ)', 'Ġyield', 'Ġinfo', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['info', 'Ġ=', 'Ġself', 'Ġ.', 'Ġread', '_', 'iter', 'ation', '_', 'case', '_', 'from', '_', 'h', 'df', '5', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'in', 'p', 'Ġ,', 'Ġdriver', '_', 'name', 'Ġ,', 'Ġiteration', '_', 'case', '_', 'name', 'Ġ)', 'Ġyield', 'Ġinfo', 'Ġ\\', 'n']
Detokenized (017): ['info', 'Ġ=', 'Ġself', 'Ġ.', 'Ġread_iteration_case_from_hdf5', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_inp', 'Ġ,', 'Ġdriver_name', 'Ġ,', 'Ġiteration_case_name', 'Ġ)', 'Ġyield', 'Ġinfo', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "sleep_time = Float ( 0.0 , iotype = , desc = ) \n"
Original    (013): ['sleep_time', '=', 'Float', '(', '0.0', ',', 'iotype', '=', ',', 'desc', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'sleep', '_', 'time', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġdesc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['sleep', '_', 'time', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', '0', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġdesc', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['sleep_time', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0.0', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġdesc', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "accuracy = Float ( 1.0e-6 , iotype = , \n"
Original    (010): ['accuracy', '=', 'Float', '(', '1.0e-6', ',', 'iotype', '=', ',', '\\n']
Tokenized   (020): ['<s>', 'acc', 'uracy', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ1', '.', '0', 'e', '-', '6', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['acc', 'uracy', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ1', '.', '0', 'e', '-', '6', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['accuracy', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ1.0e-6', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "iprint = Enum ( 0 , [ 0 , 1 , 2 , 3 ] , iotype = , \n"
Original    (020): ['iprint', '=', 'Enum', '(', '0', ',', '[', '0', ',', '1', ',', '2', ',', '3', ']', ',', 'iotype', '=', ',', '\\n']
Tokenized   (026): ['<s>', 'ip', 'rint', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['ip', 'rint', 'Ġ=', 'ĠEn', 'um', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['iprint', 'Ġ=', 'ĠEnum', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "output_filename = Str ( , iotype = , \n"
Original    (009): ['output_filename', '=', 'Str', '(', ',', 'iotype', '=', ',', '\\n']
Tokenized   (015): ['<s>', 'output', '_', 'filename', 'Ġ=', 'ĠStr', 'Ġ(', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['output', '_', 'filename', 'Ġ=', 'ĠStr', 'Ġ(', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['output_filename', 'Ġ=', 'ĠStr', 'Ġ(', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "la = max ( m , 1 ) \n"
Original    (009): ['la', '=', 'max', '(', 'm', ',', '1', ')', '\\n']
Tokenized   (012): ['<s>', 'la', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġm', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['la', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġm', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['la', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġm', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "gg = zeros ( [ la ] , ) \n"
Original    (010): ['gg', '=', 'zeros', '(', '[', 'la', ']', ',', ')', '\\n']
Tokenized   (014): ['<s>', 'gg', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['gg', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['gg', 'Ġ=', 'Ġzeros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "dg = zeros ( [ la , n + 1 ] , ) \n"
Original    (014): ['dg', '=', 'zeros', '(', '[', 'la', ',', 'n', '+', '1', ']', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'd', 'g', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ,', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['d', 'g', 'Ġ=', 'Ġz', 'eros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ,', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['dg', 'Ġ=', 'Ġzeros', 'Ġ(', 'Ġ[', 'Ġla', 'Ġ,', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ]', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "mineq = m - meq + 2 * ( n + 1 ) \n"
Original    (014): ['mineq', '=', 'm', '-', 'meq', '+', '2', '*', '(', 'n', '+', '1', ')', '\\n']
Tokenized   (019): ['<s>', 'mine', 'q', 'Ġ=', 'Ġm', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mine', 'q', 'Ġ=', 'Ġm', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['mineq', 'Ġ=', 'Ġm', 'Ġ-', 'Ġmeq', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "lsq = ( n + 1 ) * ( ( n + 1 ) + 1 ) + meq * ( ( n + 1 ) + 1 ) + mineq * ( ( n + 1 ) + 1 ) \n"
Original    (042): ['lsq', '=', '(', 'n', '+', '1', ')', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'meq', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '+', 'mineq', '*', '(', '(', 'n', '+', '1', ')', '+', '1', ')', '\\n']
Tokenized   (048): ['<s>', 'ls', 'q', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġme', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['ls', 'q', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġme', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (042): ['lsq', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmeq', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmineq', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 42, 768)
# Extracted words:  42
Sentence         : "lsi = ( ( n + 1 ) - meq + 1 ) * ( mineq + 2 ) + 2 * mineq \n"
Original    (024): ['lsi', '=', '(', '(', 'n', '+', '1', ')', '-', 'meq', '+', '1', ')', '*', '(', 'mineq', '+', '2', ')', '+', '2', '*', 'mineq', '\\n']
Tokenized   (031): ['<s>', 'ls', 'i', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġmine', 'q', 'Ġ+', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmine', 'q', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['ls', 'i', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġmine', 'q', 'Ġ+', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmine', 'q', 'Ġ\\', 'n']
Detokenized (024): ['lsi', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġmeq', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġmineq', 'Ġ+', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmineq', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "lsei = ( ( n + 1 ) + mineq ) * ( ( n + 1 ) - meq ) + 2 * meq + ( n + 1 ) \n"
Original    (032): ['lsei', '=', '(', '(', 'n', '+', '1', ')', '+', 'mineq', ')', '*', '(', '(', 'n', '+', '1', ')', '-', 'meq', ')', '+', '2', '*', 'meq', '+', '(', 'n', '+', '1', ')', '\\n']
Tokenized   (039): ['<s>', 'l', 'sei', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġme', 'q', 'Ġ+', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['l', 'sei', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmine', 'q', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġme', 'q', 'Ġ+', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (032): ['lsei', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġmineq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġmeq', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġmeq', 'Ġ+', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "slsqpb = ( n + 1 ) * ( n / 2 ) + 2 * m + 3 * n + 3 * ( n + 1 ) + 1 \n"
Original    (032): ['slsqpb', '=', '(', 'n', '+', '1', ')', '*', '(', 'n', '/', '2', ')', '+', '2', '*', 'm', '+', '3', '*', 'n', '+', '3', '*', '(', 'n', '+', '1', ')', '+', '1', '\\n']
Tokenized   (037): ['<s>', 'sl', 'sq', 'pb', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ/', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġm', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġn', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['sl', 'sq', 'pb', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ/', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġm', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġn', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (032): ['slsqpb', 'Ġ=', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ/', 'Ġ2', 'Ġ)', 'Ġ+', 'Ġ2', 'Ġ*', 'Ġm', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġn', 'Ġ+', 'Ġ3', 'Ġ*', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "lw = lsq + lsi + lsei + slsqpb + n + m \n"
Original    (014): ['lw', '=', 'lsq', '+', 'lsi', '+', 'lsei', '+', 'slsqpb', '+', 'n', '+', 'm', '\\n']
Tokenized   (023): ['<s>', 'l', 'w', 'Ġ=', 'Ġl', 'sq', 'Ġ+', 'Ġl', 'si', 'Ġ+', 'Ġl', 'sei', 'Ġ+', 'Ġsl', 'sq', 'pb', 'Ġ+', 'Ġn', 'Ġ+', 'Ġm', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['l', 'w', 'Ġ=', 'Ġl', 'sq', 'Ġ+', 'Ġl', 'si', 'Ġ+', 'Ġl', 'sei', 'Ġ+', 'Ġsl', 'sq', 'pb', 'Ġ+', 'Ġn', 'Ġ+', 'Ġm', 'Ġ\\', 'n']
Detokenized (014): ['lw', 'Ġ=', 'Ġlsq', 'Ġ+', 'Ġlsi', 'Ġ+', 'Ġlsei', 'Ġ+', 'Ġslsqpb', 'Ġ+', 'Ġn', 'Ġ+', 'Ġm', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "ljw = max ( mineq , ( n + 1 ) - meq ) \n"
Original    (015): ['ljw', '=', 'max', '(', 'mineq', ',', '(', 'n', '+', '1', ')', '-', 'meq', ')', '\\n']
Tokenized   (022): ['<s>', 'l', 'j', 'w', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġmine', 'q', 'Ġ,', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['l', 'j', 'w', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġmine', 'q', 'Ġ,', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġme', 'q', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['ljw', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġmineq', 'Ġ,', 'Ġ(', 'Ġn', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ-', 'Ġmeq', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "_iodict = { : , : } \n"
Original    (008): ['_iodict', '=', '{', ':', ',', ':', '}', '\\n']
Tokenized   (013): ['<s>', '_', 'iod', 'ict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['_', 'iod', 'ict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['_iodict', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "state [ ] = { } \n"
Original    (007): ['state', '[', ']', '=', '{', '}', '\\n']
Tokenized   (010): ['<s>', 'state', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['state', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\', 'n']
Detokenized (007): ['state', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ{', 'Ġ}', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "key = ( addr_type , addr , proxy . _authkey ) \n"
Original    (012): ['key', '=', '(', 'addr_type', ',', 'addr', ',', 'proxy', '.', '_authkey', ')', '\\n']
Tokenized   (019): ['<s>', 'key', 'Ġ=', 'Ġ(', 'Ġaddr', '_', 'type', 'Ġ,', 'Ġaddr', 'Ġ,', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['key', 'Ġ=', 'Ġ(', 'Ġaddr', '_', 'type', 'Ġ,', 'Ġaddr', 'Ġ,', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['key', 'Ġ=', 'Ġ(', 'Ġaddr_type', 'Ġ,', 'Ġaddr', 'Ġ,', 'Ġproxy', 'Ġ.', 'Ġ_authkey', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "address = ( ip_addr , 0 ) \n"
Original    (008): ['address', '=', '(', 'ip_addr', ',', '0', ')', '\\n']
Tokenized   (013): ['<s>', 'address', 'Ġ=', 'Ġ(', 'Ġip', '_', 'addr', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['address', 'Ġ=', 'Ġ(', 'Ġip', '_', 'addr', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['address', 'Ġ=', 'Ġ(', 'Ġip_addr', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "access = addr if addr_type == else addr_type \n"
Original    (009): ['access', '=', 'addr', 'if', 'addr_type', '==', 'else', 'addr_type', '\\n']
Tokenized   (016): ['<s>', 'access', 'Ġ=', 'Ġaddr', 'Ġif', 'Ġaddr', '_', 'type', 'Ġ==', 'Ġelse', 'Ġaddr', '_', 'type', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['access', 'Ġ=', 'Ġaddr', 'Ġif', 'Ġaddr', '_', 'type', 'Ġ==', 'Ġelse', 'Ġaddr', '_', 'type', 'Ġ\\', 'n']
Detokenized (009): ['access', 'Ġ=', 'Ġaddr', 'Ġif', 'Ġaddr_type', 'Ġ==', 'Ġelse', 'Ġaddr_type', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "manager = ObjectManager ( self , address , authkey = proxy . _authkey , \n"
Original    (015): ['manager', '=', 'ObjectManager', '(', 'self', ',', 'address', ',', 'authkey', '=', 'proxy', '.', '_authkey', ',', '\\n']
Tokenized   (022): ['<s>', 'manager', 'Ġ=', 'ĠObject', 'Manager', 'Ġ(', 'Ġself', 'Ġ,', 'Ġaddress', 'Ġ,', 'Ġauth', 'key', 'Ġ=', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['manager', 'Ġ=', 'ĠObject', 'Manager', 'Ġ(', 'Ġself', 'Ġ,', 'Ġaddress', 'Ġ,', 'Ġauth', 'key', 'Ġ=', 'Ġproxy', 'Ġ.', 'Ġ_', 'auth', 'key', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['manager', 'Ġ=', 'ĠObjectManager', 'Ġ(', 'Ġself', 'Ġ,', 'Ġaddress', 'Ġ,', 'Ġauthkey', 'Ġ=', 'Ġproxy', 'Ġ.', 'Ġ_authkey', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "match_dict = self . _alltraits ( ** metadata ) \n"
Original    (010): ['match_dict', '=', 'self', '.', '_alltraits', '(', '**', 'metadata', ')', '\\n']
Tokenized   (018): ['<s>', 'match', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'all', 'tra', 'its', 'Ġ(', 'Ġ**', 'Ġmetadata', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['match', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'all', 'tra', 'its', 'Ġ(', 'Ġ**', 'Ġmetadata', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['match_dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_alltraits', 'Ġ(', 'Ġ**', 'Ġmetadata', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "childname , _ , restofpath = traitpath . partition ( ) \n"
Original    (012): ['childname', ',', '_', ',', 'restofpath', '=', 'traitpath', '.', 'partition', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'child', 'name', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġrest', 'of', 'path', 'Ġ=', 'Ġtrait', 'path', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['child', 'name', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġrest', 'of', 'path', 'Ġ=', 'Ġtrait', 'path', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['childname', 'Ġ,', 'Ġ_', 'Ġ,', 'Ġrestofpath', 'Ġ=', 'Ġtraitpath', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mdict . setdefault ( , t . __class__ . __name__ ) \n"
Original    (012): ['mdict', '.', 'setdefault', '(', ',', 't', '.', '__class__', '.', '__name__', ')', '\\n']
Tokenized   (021): ['<s>', 'md', 'ict', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġt', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['md', 'ict', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġt', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['mdict', 'Ġ.', 'Ġsetdefault', 'Ġ(', 'Ġ,', 'Ġt', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "expr = compile ( assign , assign , mode = ) \n"
Original    (012): ['expr', '=', 'compile', '(', 'assign', ',', 'assign', ',', 'mode', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'expr', 'Ġ=', 'Ġcompile', 'Ġ(', 'Ġassign', 'Ġ,', 'Ġassign', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['expr', 'Ġ=', 'Ġcompile', 'Ġ(', 'Ġassign', 'Ġ,', 'Ġassign', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['expr', 'Ġ=', 'Ġcompile', 'Ġ(', 'Ġassign', 'Ġ,', 'Ġassign', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "tstamp = % ( now . year , now . month , now . day , now . hour , now . minute ) \n"
Original    (025): ['tstamp', '=', '%', '(', 'now', '.', 'year', ',', 'now', '.', 'month', ',', 'now', '.', 'day', ',', 'now', '.', 'hour', ',', 'now', '.', 'minute', ')', '\\n']
Tokenized   (030): ['<s>', 't', 'st', 'amp', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġnow', 'Ġ.', 'Ġyear', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġmonth', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġday', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġhour', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġminute', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['t', 'st', 'amp', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġnow', 'Ġ.', 'Ġyear', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġmonth', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġday', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġhour', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġminute', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['tstamp', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġnow', 'Ġ.', 'Ġyear', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġmonth', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġday', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġhour', 'Ġ,', 'Ġnow', 'Ġ.', 'Ġminute', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "entry_pts = [ ( self , name , _get_entry_group ( self ) ) ] \n"
Original    (015): ['entry_pts', '=', '[', '(', 'self', ',', 'name', ',', '_get_entry_group', '(', 'self', ')', ')', ']', '\\n']
Tokenized   (026): ['<s>', 'entry', '_', 'pt', 's', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġself', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ_', 'get', '_', 'entry', '_', 'group', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['entry', '_', 'pt', 's', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġself', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ_', 'get', '_', 'entry', '_', 'group', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['entry_pts', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġself', 'Ġ,', 'Ġname', 'Ġ,', 'Ġ_get_entry_group', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "root_start = root_start + 1 if root_start >= 0 else 0 \n"
Original    (012): ['root_start', '=', 'root_start', '+', '1', 'if', 'root_start', '>=', '0', 'else', '0', '\\n']
Tokenized   (021): ['<s>', 'root', '_', 'start', 'Ġ=', 'Ġroot', '_', 'start', 'Ġ+', 'Ġ1', 'Ġif', 'Ġroot', '_', 'start', 'Ġ>=', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['root', '_', 'start', 'Ġ=', 'Ġroot', '_', 'start', 'Ġ+', 'Ġ1', 'Ġif', 'Ġroot', '_', 'start', 'Ġ>=', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n']
Detokenized (012): ['root_start', 'Ġ=', 'Ġroot_start', 'Ġ+', 'Ġ1', 'Ġif', 'Ġroot_start', 'Ġ>=', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "root_pathname += \n"
Original    (003): ['root_pathname', '+=', '\\n']
Tokenized   (009): ['<s>', 'root', '_', 'path', 'name', 'Ġ+=', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['root', '_', 'path', 'name', 'Ġ+=', 'Ġ\\', 'n']
Detokenized (003): ['root_pathname', 'Ġ+=', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "Container . _bases ( type ( obj ) , names ) \n"
Original    (012): ['Container', '.', '_bases', '(', 'type', '(', 'obj', ')', ',', 'names', ')', '\\n']
Tokenized   (017): ['<s>', 'Container', 'Ġ.', 'Ġ_', 'b', 'ases', 'Ġ(', 'Ġtype', 'Ġ(', 'Ġobj', 'Ġ)', 'Ġ,', 'Ġnames', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['Container', 'Ġ.', 'Ġ_', 'b', 'ases', 'Ġ(', 'Ġtype', 'Ġ(', 'Ġobj', 'Ġ)', 'Ġ,', 'Ġnames', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['Container', 'Ġ.', 'Ġ_bases', 'Ġ(', 'Ġtype', 'Ġ(', 'Ġobj', 'Ġ)', 'Ġ,', 'Ġnames', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "names . append ( % ( cls . __module__ , cls . __name__ ) ) \n"
Original    (016): ['names', '.', 'append', '(', '%', '(', 'cls', '.', '__module__', ',', 'cls', '.', '__name__', ')', ')', '\\n']
Tokenized   (025): ['<s>', 'names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'module', '__', 'Ġ,', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'module', '__', 'Ġ,', 'Ġcl', 's', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['names', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġcls', 'Ġ.', 'Ġ__module__', 'Ġ,', 'Ġcls', 'Ġ.', 'Ġ__name__', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "_get_entry_group . group_map = [ \n"
Original    (006): ['_get_entry_group', '.', 'group_map', '=', '[', '\\n']
Tokenized   (016): ['<s>', '_', 'get', '_', 'entry', '_', 'group', 'Ġ.', 'Ġgroup', '_', 'map', 'Ġ=', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['_', 'get', '_', 'entry', '_', 'group', 'Ġ.', 'Ġgroup', '_', 'map', 'Ġ=', 'Ġ[', 'Ġ\\', 'n']
Detokenized (006): ['_get_entry_group', 'Ġ.', 'Ġgroup_map', 'Ġ=', 'Ġ[', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "pprint . pprint ( dict ( [ ( n , str ( v ) ) \n"
Original    (016): ['pprint', '.', 'pprint', '(', 'dict', '(', '[', '(', 'n', ',', 'str', '(', 'v', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'pp', 'rint', 'Ġ.', 'Ġp', 'print', 'Ġ(', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġn', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['pp', 'rint', 'Ġ.', 'Ġp', 'print', 'Ġ(', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġn', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['pprint', 'Ġ.', 'Ġpprint', 'Ġ(', 'Ġdict', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġn', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "** metadata ) ] ) , \n"
Original    (007): ['**', 'metadata', ')', ']', ')', ',', '\\n']
Tokenized   (010): ['<s>', '**', 'Ġmetadata', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['**', 'Ġmetadata', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['**', 'Ġmetadata', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "io_attr [ ] = \n"
Original    (005): ['io_attr', '[', ']', '=', '\\n']
Tokenized   (010): ['<s>', 'io', '_', 'attr', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['io', '_', 'attr', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ\\', 'n']
Detokenized (005): ['io_attr', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "_redirect_streams ( ofile . fileno ( ) ) \n"
Original    (009): ['_redirect_streams', '(', 'ofile', '.', 'fileno', '(', ')', ')', '\\n']
Tokenized   (019): ['<s>', '_', 'red', 'irect', '_', 'stream', 's', 'Ġ(', 'Ġof', 'ile', 'Ġ.', 'Ġfil', 'eno', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['_', 'red', 'irect', '_', 'stream', 's', 'Ġ(', 'Ġof', 'ile', 'Ġ.', 'Ġfil', 'eno', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['_redirect_streams', 'Ġ(', 'Ġofile', 'Ġ.', 'Ġfileno', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "leftover = arr_size % num_divisions \n"
Original    (006): ['leftover', '=', 'arr_size', '%', 'num_divisions', '\\n']
Tokenized   (015): ['<s>', 'left', 'over', 'Ġ=', 'Ġarr', '_', 'size', 'Ġ%', 'Ġnum', '_', 'div', 'isions', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['left', 'over', 'Ġ=', 'Ġarr', '_', 'size', 'Ġ%', 'Ġnum', '_', 'div', 'isions', 'Ġ\\', 'n']
Detokenized (006): ['leftover', 'Ġ=', 'Ġarr_size', 'Ġ%', 'Ġnum_divisions', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "sizes [ : leftover ] += 1 \n"
Original    (008): ['sizes', '[', ':', 'leftover', ']', '+=', '1', '\\n']
Tokenized   (012): ['<s>', 's', 'izes', 'Ġ[', 'Ġ:', 'Ġleftover', 'Ġ]', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['s', 'izes', 'Ġ[', 'Ġ:', 'Ġleftover', 'Ġ]', 'Ġ+=', 'Ġ1', 'Ġ\\', 'n']
Detokenized (008): ['sizes', 'Ġ[', 'Ġ:', 'Ġleftover', 'Ġ]', 'Ġ+=', 'Ġ1', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "offsets [ 1 : ] = numpy . cumsum ( sizes ) [ : - 1 ] \n"
Original    (018): ['offsets', '[', '1', ':', ']', '=', 'numpy', '.', 'cumsum', '(', 'sizes', ')', '[', ':', '-', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'offs', 'ets', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġc', 'ums', 'um', 'Ġ(', 'Ġsizes', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['offs', 'ets', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġc', 'ums', 'um', 'Ġ(', 'Ġsizes', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['offsets', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġcumsum', 'Ġ(', 'Ġsizes', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "z1 = Float ( 0. , iotype = ) \n"
Original    (010): ['z1', '=', 'Float', '(', '0.', ',', 'iotype', '=', ')', '\\n']
Tokenized   (016): ['<s>', 'z', '1', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['z', '1', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0', '.', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['z1', 'Ġ=', 'ĠFloat', 'Ġ(', 'Ġ0.', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "z_store = Array ( [ 0. , 0. ] , iotype = ) \n"
Original    (014): ['z_store', '=', 'Array', '(', '[', '0.', ',', '0.', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (022): ['<s>', 'z', '_', 'store', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ,', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['z', '_', 'store', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', 'Ġ,', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['z_store', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0.', 'Ġ,', 'Ġ0.', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "ssa_F = Array ( [ 0.0 ] , iotype = ) \n"
Original    (012): ['ssa_F', '=', 'Array', '(', '[', '0.0', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'ss', 'a', '_', 'F', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['ss', 'a', '_', 'F', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['ssa_F', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ0.0', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "ssa_dG = Array ( [ [ 0.0 , 0.0 ] , [ 0.0 , 0.0 ] ] , iotype = ) \n"
Original    (022): ['ssa_dG', '=', 'Array', '(', '[', '[', '0.0', ',', '0.0', ']', ',', '[', '0.0', ',', '0.0', ']', ']', ',', 'iotype', '=', ')', '\\n']
Tokenized   (038): ['<s>', 'ss', 'a', '_', 'd', 'G', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['ss', 'a', '_', 'd', 'G', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ0', '.', '0', 'Ġ,', 'Ġ0', '.', '0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['ssa_dG', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0.0', 'Ġ,', 'Ġ0.0', 'Ġ]', 'Ġ,', 'Ġ[', 'Ġ0.0', 'Ġ,', 'Ġ0.0', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "arr_out = Array ( [ 1. , 2. , 3. ] , iotype = , units = ) \n"
Original    (019): ['arr_out', '=', 'Array', '(', '[', '1.', ',', '2.', ',', '3.', ']', ',', 'iotype', '=', ',', 'units', '=', ')', '\\n']
Tokenized   (028): ['<s>', 'arr', '_', 'out', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ1', '.', 'Ġ,', 'Ġ2', '.', 'Ġ,', 'Ġ3', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['arr', '_', 'out', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ1', '.', 'Ġ,', 'Ġ2', '.', 'Ġ,', 'Ġ3', '.', 'Ġ]', 'Ġ,', 'Ġi', 'otype', 'Ġ=', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['arr_out', 'Ġ=', 'ĠArray', 'Ġ(', 'Ġ[', 'Ġ1.', 'Ġ,', 'Ġ2.', 'Ġ,', 'Ġ3.', 'Ġ]', 'Ġ,', 'Ġiotype', 'Ġ=', 'Ġ,', 'Ġunits', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "arg [ ] = np . array ( [ 3.1 ] ) \n"
Original    (013): ['arg', '[', ']', '=', 'np', '.', 'array', '(', '[', '3.1', ']', ')', '\\n']
Tokenized   (018): ['<s>', 'arg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ3', '.', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['arg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ3', '.', '1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['arg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ3.1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "jacs [ ] = np . array ( [ [ 100.0 , 101 , 102 , 103 ] , \n"
Original    (020): ['jacs', '[', ']', '=', 'np', '.', 'array', '(', '[', '[', '100.0', ',', '101', ',', '102', ',', '103', ']', ',', '\\n']
Tokenized   (026): ['<s>', 'j', 'acs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ100', '.', '0', 'Ġ,', 'Ġ101', 'Ġ,', 'Ġ102', 'Ġ,', 'Ġ103', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['j', 'acs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ100', '.', '0', 'Ġ,', 'Ġ101', 'Ġ,', 'Ġ102', 'Ġ,', 'Ġ103', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['jacs', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ100.0', 'Ġ,', 'Ġ101', 'Ġ,', 'Ġ102', 'Ġ,', 'Ġ103', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "assert_rel_error ( self , J [ 3 ] [ 0 ] , 3.0 , 1e-5 ) \n"
Original    (017): ['assert_rel_error', '(', 'self', ',', 'J', '[', '3', ']', '[', '0', ']', ',', '3.0', ',', '1e-5', ')', '\\n']
Tokenized   (029): ['<s>', 'assert', '_', 'rel', '_', 'error', 'Ġ(', 'Ġself', 'Ġ,', 'ĠJ', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ3', '.', '0', 'Ġ,', 'Ġ1', 'e', '-', '5', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['assert', '_', 'rel', '_', 'error', 'Ġ(', 'Ġself', 'Ġ,', 'ĠJ', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ3', '.', '0', 'Ġ,', 'Ġ1', 'e', '-', '5', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['assert_rel_error', 'Ġ(', 'Ġself', 'Ġ,', 'ĠJ', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġ3.0', 'Ġ,', 'Ġ1e-5', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "newval = _getformat ( val ) % val \n"
Original    (009): ['newval', '=', '_getformat', '(', 'val', ')', '%', 'val', '\\n']
Tokenized   (015): ['<s>', 'new', 'val', 'Ġ=', 'Ġ_', 'get', 'format', 'Ġ(', 'Ġval', 'Ġ)', 'Ġ%', 'Ġval', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['new', 'val', 'Ġ=', 'Ġ_', 'get', 'format', 'Ġ(', 'Ġval', 'Ġ)', 'Ġ%', 'Ġval', 'Ġ\\', 'n']
Detokenized (009): ['newval', 'Ġ=', 'Ġ_getformat', 'Ġ(', 'Ġval', 'Ġ)', 'Ġ%', 'Ġval', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "newline = re . sub ( self . reg , sub . replace_array , line ) \n"
Original    (017): ['newline', '=', 're', '.', 'sub', '(', 'self', '.', 'reg', ',', 'sub', '.', 'replace_array', ',', 'line', ')', '\\n']
Tokenized   (023): ['<s>', 'new', 'line', 'Ġ=', 'Ġre', 'Ġ.', 'Ġsub', 'Ġ(', 'Ġself', 'Ġ.', 'Ġreg', 'Ġ,', 'Ġsub', 'Ġ.', 'Ġreplace', '_', 'array', 'Ġ,', 'Ġline', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['new', 'line', 'Ġ=', 'Ġre', 'Ġ.', 'Ġsub', 'Ġ(', 'Ġself', 'Ġ.', 'Ġreg', 'Ġ,', 'Ġsub', 'Ġ.', 'Ġreplace', '_', 'array', 'Ġ,', 'Ġline', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['newline', 'Ġ=', 'Ġre', 'Ġ.', 'Ġsub', 'Ġ(', 'Ġself', 'Ġ.', 'Ġreg', 'Ġ,', 'Ġsub', 'Ġ.', 'Ġreplace_array', 'Ġ,', 'Ġline', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "fields = self . _parse_line ( ) . parseString ( line . replace ( key , "KeyField" ) ) \n"
Original    (020): ['fields', '=', 'self', '.', '_parse_line', '(', ')', '.', 'parseString', '(', 'line', '.', 'replace', '(', 'key', ',', '"KeyField"', ')', ')', '\\n']
Tokenized   (030): ['<s>', 'fields', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'parse', '_', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġparse', 'String', 'Ġ(', 'Ġline', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġkey', 'Ġ,', 'Ġ"', 'Key', 'Field', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['fields', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'parse', '_', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġparse', 'String', 'Ġ(', 'Ġline', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġkey', 'Ġ,', 'Ġ"', 'Key', 'Field', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['fields', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_parse_line', 'Ġ(', 'Ġ)', 'Ġ.', 'ĠparseString', 'Ġ(', 'Ġline', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġkey', 'Ġ,', 'Ġ"KeyField"', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "j2 = self . current_row + rowend + 1 \n"
Original    (010): ['j2', '=', 'self', '.', 'current_row', '+', 'rowend', '+', '1', '\\n']
Tokenized   (017): ['<s>', 'j', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcurrent', '_', 'row', 'Ġ+', 'Ġrow', 'end', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['j', '2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcurrent', '_', 'row', 'Ġ+', 'Ġrow', 'end', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (010): ['j2', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcurrent_row', 'Ġ+', 'Ġrowend', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ee = CaselessLiteral ( ) | CaselessLiteral ( ) \n"
Original    (010): ['ee', '=', 'CaselessLiteral', '(', ')', '|', 'CaselessLiteral', '(', ')', '\\n']
Tokenized   (021): ['<s>', 'ee', 'Ġ=', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ|', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['ee', 'Ġ=', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ|', 'ĠCas', 'eless', 'L', 'it', 'eral', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['ee', 'Ġ=', 'ĠCaselessLiteral', 'Ġ(', 'Ġ)', 'Ġ|', 'ĠCaselessLiteral', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "num_int = ToInteger ( Combine ( Optional ( sign ) + digits ) ) \n"
Original    (015): ['num_int', '=', 'ToInteger', '(', 'Combine', '(', 'Optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'num', '_', 'int', 'Ġ=', 'ĠTo', 'Integer', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['num', '_', 'int', 'Ġ=', 'ĠTo', 'Integer', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['num_int', 'Ġ=', 'ĠToInteger', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "num_float = ToFloat ( Combine ( Optional ( sign ) + \n"
Original    (012): ['num_float', '=', 'ToFloat', '(', 'Combine', '(', 'Optional', '(', 'sign', ')', '+', '\\n']
Tokenized   (018): ['<s>', 'num', '_', 'float', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['num', '_', 'float', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (012): ['num_float', 'Ġ=', 'ĠToFloat', 'Ġ(', 'ĠCombine', 'Ġ(', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Optional ( ee + Optional ( sign ) + digits ) \n"
Original    (012): ['Optional', '(', 'ee', '+', 'Optional', '(', 'sign', ')', '+', 'digits', ')', '\\n']
Tokenized   (016): ['<s>', 'Optional', 'Ġ(', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['Optional', 'Ġ(', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['Optional', 'Ġ(', 'Ġee', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "mixed_exp = ToFloat ( Combine ( digits + ee + Optional ( sign ) + digits ) ) \n"
Original    (019): ['mixed_exp', '=', 'ToFloat', '(', 'Combine', '(', 'digits', '+', 'ee', '+', 'Optional', '(', 'sign', ')', '+', 'digits', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'm', 'ixed', '_', 'exp', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'Ġdigits', 'Ġ+', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['m', 'ixed', '_', 'exp', 'Ġ=', 'ĠTo', 'Float', 'Ġ(', 'ĠCombine', 'Ġ(', 'Ġdigits', 'Ġ+', 'Ġe', 'e', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['mixed_exp', 'Ġ=', 'ĠToFloat', 'Ġ(', 'ĠCombine', 'Ġ(', 'Ġdigits', 'Ġ+', 'Ġee', 'Ġ+', 'ĠOptional', 'Ġ(', 'Ġsign', 'Ġ)', 'Ġ+', 'Ġdigits', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "string_text ) ) ) \n"
Original    (005): ['string_text', ')', ')', ')', '\\n']
Tokenized   (010): ['<s>', 'string', '_', 'text', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['string', '_', 'text', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['string_text', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "J [ , ] = - 1.0 \n"
Original    (008): ['J', '[', ',', ']', '=', '-', '1.0', '\\n']
Tokenized   (013): ['<s>', 'J', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ1', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['J', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ1', '.', '0', 'Ġ\\', 'n']
Detokenized (008): ['J', 'Ġ[', 'Ġ,', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ1.0', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "top [ ] = - 7.0 \n"
Original    (007): ['top', '[', ']', '=', '-', '7.0', '\\n']
Tokenized   (012): ['<s>', 'top', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ7', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['top', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ7', '.', '0', 'Ġ\\', 'n']
Detokenized (007): ['top', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ-', 'Ġ7.0', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "lhs , op , rhs = _parse_constraint ( expr ) \n"
Original    (011): ['lhs', ',', 'op', ',', 'rhs', '=', '_parse_constraint', '(', 'expr', ')', '\\n']
Tokenized   (021): ['<s>', 'l', 'hs', 'Ġ,', 'Ġop', 'Ġ,', 'Ġrh', 's', 'Ġ=', 'Ġ_', 'parse', '_', 'con', 'str', 'aint', 'Ġ(', 'Ġexpr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['l', 'hs', 'Ġ,', 'Ġop', 'Ġ,', 'Ġrh', 's', 'Ġ=', 'Ġ_', 'parse', '_', 'con', 'str', 'aint', 'Ġ(', 'Ġexpr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['lhs', 'Ġ,', 'Ġop', 'Ġ,', 'Ġrhs', 'Ġ=', 'Ġ_parse_constraint', 'Ġ(', 'Ġexpr', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "first , second = ( rhs , lhs ) if op . startswith ( ) else ( lhs , rhs ) \n"
Original    (022): ['first', ',', 'second', '=', '(', 'rhs', ',', 'lhs', ')', 'if', 'op', '.', 'startswith', '(', ')', 'else', '(', 'lhs', ',', 'rhs', ')', '\\n']
Tokenized   (031): ['<s>', 'first', 'Ġ,', 'Ġsecond', 'Ġ=', 'Ġ(', 'Ġrh', 's', 'Ġ,', 'Ġl', 'hs', 'Ġ)', 'Ġif', 'Ġop', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġelse', 'Ġ(', 'Ġl', 'hs', 'Ġ,', 'Ġrh', 's', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['first', 'Ġ,', 'Ġsecond', 'Ġ=', 'Ġ(', 'Ġrh', 's', 'Ġ,', 'Ġl', 'hs', 'Ġ)', 'Ġif', 'Ġop', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġelse', 'Ġ(', 'Ġl', 'hs', 'Ġ,', 'Ġrh', 's', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['first', 'Ġ,', 'Ġsecond', 'Ġ=', 'Ġ(', 'Ġrhs', 'Ġ,', 'Ġlhs', 'Ġ)', 'Ġif', 'Ġop', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġ)', 'Ġelse', 'Ġ(', 'Ġlhs', 'Ġ,', 'Ġrhs', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "input_graph . add_edges_from ( ( ( start , p ) for p in plist [ 1 : ] ) , \n"
Original    (021): ['input_graph', '.', 'add_edges_from', '(', '(', '(', 'start', ',', 'p', ')', 'for', 'p', 'in', 'plist', '[', '1', ':', ']', ')', ',', '\\n']
Tokenized   (032): ['<s>', 'input', '_', 'graph', 'Ġ.', 'Ġadd', '_', 'ed', 'ges', '_', 'from', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġstart', 'Ġ,', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpl', 'ist', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['input', '_', 'graph', 'Ġ.', 'Ġadd', '_', 'ed', 'ges', '_', 'from', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġstart', 'Ġ,', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpl', 'ist', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (021): ['input_graph', 'Ġ.', 'Ġadd_edges_from', 'Ġ(', 'Ġ(', 'Ġ(', 'Ġstart', 'Ġ,', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġplist', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "src_idxs = { src : None } \n"
Original    (008): ['src_idxs', '=', '{', 'src', ':', 'None', '}', '\\n']
Tokenized   (014): ['<s>', 'src', '_', 'id', 'xs', 'Ġ=', 'Ġ{', 'Ġsrc', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['src', '_', 'id', 'xs', 'Ġ=', 'Ġ{', 'Ġsrc', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\', 'n']
Detokenized (008): ['src_idxs', 'Ġ=', 'Ġ{', 'Ġsrc', 'Ġ:', 'ĠNone', 'Ġ}', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "units = [ params_dict [ n ] . get ( ) for n in connected_inputs ] \n"
Original    (017): ['units', '=', '[', 'params_dict', '[', 'n', ']', '.', 'get', '(', ')', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Tokenized   (025): ['<s>', 'units', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['units', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['units', 'Ġ=', 'Ġ[', 'Ġparams_dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected_inputs', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "vals = [ params_dict [ n ] [ ] for n in connected_inputs ] \n"
Original    (015): ['vals', '=', '[', 'params_dict', '[', 'n', ']', '[', ']', 'for', 'n', 'in', 'connected_inputs', ']', '\\n']
Tokenized   (023): ['<s>', 'vals', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['vals', 'Ġ=', 'Ġ[', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected', '_', 'input', 's', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['vals', 'Ġ=', 'Ġ[', 'Ġparams_dict', 'Ġ[', 'Ġn', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġfor', 'Ġn', 'Ġin', 'Ġconnected_inputs', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tname , t = connected_inputs [ i ] , u \n"
Original    (011): ['tname', ',', 't', '=', 'connected_inputs', '[', 'i', ']', ',', 'u', '\\n']
Tokenized   (018): ['<s>', 't', 'name', 'Ġ,', 'Ġt', 'Ġ=', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġu', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['t', 'name', 'Ġ,', 'Ġt', 'Ġ=', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġu', 'Ġ\\', 'n']
Detokenized (011): ['tname', 'Ġ,', 'Ġt', 'Ġ=', 'Ġconnected_inputs', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġu', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "correct_src = params_dict [ connected_inputs [ 0 ] ] [ ] \n"
Original    (012): ['correct_src', '=', 'params_dict', '[', 'connected_inputs', '[', '0', ']', ']', '[', ']', '\\n']
Tokenized   (022): ['<s>', 'correct', '_', 'src', 'Ġ=', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['correct', '_', 'src', 'Ġ=', 'Ġparams', '_', 'dict', 'Ġ[', 'Ġconnected', '_', 'input', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['correct_src', 'Ġ=', 'Ġparams_dict', 'Ġ[', 'Ġconnected_inputs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "sorted ( [ ( v , k ) for k , v in forms . items ( ) ] ) ) ) \n"
Original    (023): ['sorted', '(', '[', '(', 'v', ',', 'k', ')', 'for', 'k', ',', 'v', 'in', 'forms', '.', 'items', '(', ')', ']', ')', ')', ')', '\\n']
Tokenized   (027): ['<s>', 's', 'orted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġv', 'Ġ,', 'Ġk', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġforms', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['s', 'orted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġv', 'Ġ,', 'Ġk', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġforms', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['sorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġv', 'Ġ,', 'Ġk', 'Ġ)', 'Ġfor', 'Ġk', 'Ġ,', 'Ġv', 'Ġin', 'Ġforms', 'Ġ.', 'Ġitems', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "full_order = { s . pathname : i for i , s in \n"
Original    (014): ['full_order', '=', '{', 's', '.', 'pathname', ':', 'i', 'for', 'i', ',', 's', 'in', '\\n']
Tokenized   (020): ['<s>', 'full', '_', 'order', 'Ġ=', 'Ġ{', 'Ġs', 'Ġ.', 'Ġpath', 'name', 'Ġ:', 'Ġi', 'Ġfor', 'Ġi', 'Ġ,', 'Ġs', 'Ġin', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['full', '_', 'order', 'Ġ=', 'Ġ{', 'Ġs', 'Ġ.', 'Ġpath', 'name', 'Ġ:', 'Ġi', 'Ġfor', 'Ġi', 'Ġ,', 'Ġs', 'Ġin', 'Ġ\\', 'n']
Detokenized (014): ['full_order', 'Ġ=', 'Ġ{', 'Ġs', 'Ġ.', 'Ġpathname', 'Ġ:', 'Ġi', 'Ġfor', 'Ġi', 'Ġ,', 'Ġs', 'Ġin', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "enumerate ( self . root . subsystems ( recurse = True ) ) } \n"
Original    (015): ['enumerate', '(', 'self', '.', 'root', '.', 'subsystems', '(', 'recurse', '=', 'True', ')', ')', '}', '\\n']
Tokenized   (022): ['<s>', 'en', 'umer', 'ate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġsubsystem', 's', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['en', 'umer', 'ate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġsubsystem', 's', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\', 'n']
Detokenized (015): ['enumerate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġsubsystems', 'Ġ(', 'Ġrecurse', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ}', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "ssys = srcs [ 0 ] . rsplit ( , 1 ) [ 0 ] \n"
Original    (016): ['ssys', '=', 'srcs', '[', '0', ']', '.', 'rsplit', '(', ',', '1', ')', '[', '0', ']', '\\n']
Tokenized   (022): ['<s>', 'ss', 'ys', 'Ġ=', 'Ġsrc', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['ss', 'ys', 'Ġ=', 'Ġsrc', 's', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['ssys', 'Ġ=', 'Ġsrcs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġrsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "params_dict , unknowns_dict = self . root . _setup_variables ( ) \n"
Original    (012): ['params_dict', ',', 'unknowns_dict', '=', 'self', '.', 'root', '.', '_setup_variables', '(', ')', '\\n']
Tokenized   (024): ['<s>', 'params', '_', 'dict', 'Ġ,', 'Ġunknown', 's', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'setup', '_', 'vari', 'ables', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['params', '_', 'dict', 'Ġ,', 'Ġunknown', 's', '_', 'dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'setup', '_', 'vari', 'ables', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['params_dict', 'Ġ,', 'Ġunknowns_dict', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_setup_variables', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "is not Component . setup_distrib ) ) : \n"
Original    (009): ['is', 'not', 'Component', '.', 'setup_distrib', ')', ')', ':', '\\n']
Tokenized   (015): ['<s>', 'is', 'Ġnot', 'ĠComponent', 'Ġ.', 'Ġsetup', '_', 'dist', 'rib', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['is', 'Ġnot', 'ĠComponent', 'Ġ.', 'Ġsetup', '_', 'dist', 'rib', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (009): ['is', 'Ġnot', 'ĠComponent', 'Ġ.', 'Ġsetup_distrib', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "alloc_derivs = not self . root . fd_options [ ] \n"
Original    (011): ['alloc_derivs', '=', 'not', 'self', '.', 'root', '.', 'fd_options', '[', ']', '\\n']
Tokenized   (021): ['<s>', 'alloc', '_', 'der', 'iv', 's', 'Ġ=', 'Ġnot', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġf', 'd', '_', 'options', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['alloc', '_', 'der', 'iv', 's', 'Ġ=', 'Ġnot', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġf', 'd', '_', 'options', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['alloc_derivs', 'Ġ=', 'Ġnot', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġfd_options', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dangling_params = sorted ( set ( [ \n"
Original    (008): ['dangling_params', '=', 'sorted', '(', 'set', '(', '[', '\\n']
Tokenized   (014): ['<s>', 'd', 'angling', '_', 'params', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġset', 'Ġ(', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['d', 'angling', '_', 'params', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġset', 'Ġ(', 'Ġ[', 'Ġ\\', 'n']
Detokenized (008): ['dangling_params', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġset', 'Ġ(', 'Ġ[', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "nocomps = sorted ( [ c . pathname for c in self . root . components ( recurse = True , \n"
Original    (022): ['nocomps', '=', 'sorted', '(', '[', 'c', '.', 'pathname', 'for', 'c', 'in', 'self', '.', 'root', '.', 'components', '(', 'recurse', '=', 'True', ',', '\\n']
Tokenized   (029): ['<s>', 'n', 'ocom', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġfor', 'Ġc', 'Ġin', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġcomponents', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['n', 'ocom', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġfor', 'Ġc', 'Ġin', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġcomponents', 'Ġ(', 'Ġrec', 'urse', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\', 'n']
Detokenized (022): ['nocomps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpathname', 'Ġfor', 'Ġc', 'Ġin', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġcomponents', 'Ġ(', 'Ġrecurse', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "local = True ) \n"
Original    (005): ['local', '=', 'True', ')', '\\n']
Tokenized   (008): ['<s>', 'local', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['local', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['local', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "recorders . extend ( grp . ln_solver . recorders ) \n"
Original    (011): ['recorders', '.', 'extend', '(', 'grp', '.', 'ln_solver', '.', 'recorders', ')', '\\n']
Tokenized   (021): ['<s>', 'rec', 'orders', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ.', 'Ġrecord', 'ers', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['rec', 'orders', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ.', 'Ġrecord', 'ers', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['recorders', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgrp', 'Ġ.', 'Ġln_solver', 'Ġ.', 'Ġrecorders', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "conn_comps . update ( [ s . rsplit ( , 1 ) [ 0 ] \n"
Original    (016): ['conn_comps', '.', 'update', '(', '[', 's', '.', 'rsplit', '(', ',', '1', ')', '[', '0', ']', '\\n']
Tokenized   (023): ['<s>', 'conn', '_', 'com', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ[', 'Ġs', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['conn', '_', 'com', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ[', 'Ġs', 'Ġ.', 'Ġr', 'split', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['conn_comps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġ[', 'Ġs', 'Ġ.', 'Ġrsplit', 'Ġ(', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "noconn_comps = sorted ( [ c . pathname \n"
Original    (009): ['noconn_comps', '=', 'sorted', '(', '[', 'c', '.', 'pathname', '\\n']
Tokenized   (018): ['<s>', 'n', 'ocon', 'n', '_', 'com', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['n', 'ocon', 'n', '_', 'com', 'ps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpath', 'name', 'Ġ\\', 'n']
Detokenized (009): ['noconn_comps', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġc', 'Ġ.', 'Ġpathname', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "strong = [ s for s in nx . strongly_connected_components ( graph ) \n"
Original    (014): ['strong', '=', '[', 's', 'for', 's', 'in', 'nx', '.', 'strongly_connected_components', '(', 'graph', ')', '\\n']
Tokenized   (023): ['<s>', 'strong', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġn', 'x', 'Ġ.', 'Ġstrongly', '_', 'connected', '_', 'comp', 'onents', 'Ġ(', 'Ġgraph', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['strong', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġn', 'x', 'Ġ.', 'Ġstrongly', '_', 'connected', '_', 'comp', 'onents', 'Ġ(', 'Ġgraph', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['strong', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġnx', 'Ġ.', 'Ġstrongly_connected_components', 'Ġ(', 'Ġgraph', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "subs = [ s for s in grp . _subsystems ] \n"
Original    (012): ['subs', '=', '[', 's', 'for', 's', 'in', 'grp', '.', '_subsystems', ']', '\\n']
Tokenized   (020): ['<s>', 'sub', 's', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġgr', 'p', 'Ġ.', 'Ġ_', 'sub', 'system', 's', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['sub', 's', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġgr', 'p', 'Ġ.', 'Ġ_', 'sub', 'system', 's', 'Ġ]', 'Ġ\\', 'n']
Detokenized (012): ['subs', 'Ġ=', 'Ġ[', 'Ġs', 'Ġfor', 'Ġs', 'Ġin', 'Ġgrp', 'Ġ.', 'Ġ_subsystems', 'Ġ]', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "tups = sorted ( [ ( subs . index ( s ) , s ) for s in relstrong [ - 1 ] ] ) \n"
Original    (026): ['tups', '=', 'sorted', '(', '[', '(', 'subs', '.', 'index', '(', 's', ')', ',', 's', ')', 'for', 's', 'in', 'relstrong', '[', '-', '1', ']', ']', ')', '\\n']
Tokenized   (031): ['<s>', 't', 'ups', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġsubs', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġs', 'Ġ)', 'Ġfor', 'Ġs', 'Ġin', 'Ġrel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['t', 'ups', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġsubs', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġs', 'Ġ)', 'Ġfor', 'Ġs', 'Ġin', 'Ġrel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['tups', 'Ġ=', 'Ġsorted', 'Ġ(', 'Ġ[', 'Ġ(', 'Ġsubs', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġs', 'Ġ)', 'Ġfor', 'Ġs', 'Ġin', 'Ġrelstrong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "relstrong [ - 1 ] = [ t [ 1 ] for t in tups ] \n"
Original    (017): ['relstrong', '[', '-', '1', ']', '=', '[', 't', '[', '1', ']', 'for', 't', 'in', 'tups', ']', '\\n']
Tokenized   (022): ['<s>', 'rel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġfor', 'Ġt', 'Ġin', 'Ġt', 'ups', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['rel', 'strong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġfor', 'Ġt', 'Ġin', 'Ġt', 'ups', 'Ġ]', 'Ġ\\', 'n']
Detokenized (017): ['relstrong', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ=', 'Ġ[', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġfor', 'Ġt', 'Ġin', 'Ġtups', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "nearest_child ( grp . pathname , n ) for n in out_of_order [ name ] \n"
Original    (016): ['nearest_child', '(', 'grp', '.', 'pathname', ',', 'n', ')', 'for', 'n', 'in', 'out_of_order', '[', 'name', ']', '\\n']
Tokenized   (028): ['<s>', 'ne', 'arest', '_', 'child', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġpath', 'name', 'Ġ,', 'Ġn', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġout', '_', 'of', '_', 'order', 'Ġ[', 'Ġname', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['ne', 'arest', '_', 'child', 'Ġ(', 'Ġgr', 'p', 'Ġ.', 'Ġpath', 'name', 'Ġ,', 'Ġn', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġout', '_', 'of', '_', 'order', 'Ġ[', 'Ġname', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['nearest_child', 'Ġ(', 'Ġgrp', 'Ġ.', 'Ġpathname', 'Ġ,', 'Ġn', 'Ġ)', 'Ġfor', 'Ġn', 'Ġin', 'Ġout_of_order', 'Ġ[', 'Ġname', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "pbos = [ var for var in vec if vec . metadata ( var ) . get ( ) ] \n"
Original    (021): ['pbos', '=', '[', 'var', 'for', 'var', 'in', 'vec', 'if', 'vec', '.', 'metadata', '(', 'var', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (025): ['<s>', 'p', 'bos', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġvec', 'Ġif', 'Ġvec', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġvar', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['p', 'bos', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġvec', 'Ġif', 'Ġvec', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġvar', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['pbos', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġvec', 'Ġif', 'Ġvec', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġvar', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "iteritems ( self . root . _params_dict ) ) : \n"
Original    (011): ['iteritems', '(', 'self', '.', 'root', '.', '_params_dict', ')', ')', ':', '\\n']
Tokenized   (018): ['<s>', 'iter', 'items', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['iter', 'items', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (011): ['iteritems', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_params_dict', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "dv_scale = None , cn_scale = None , sparsity = None ) : \n"
Original    (014): ['dv_scale', '=', 'None', ',', 'cn_scale', '=', 'None', ',', 'sparsity', '=', 'None', ')', ':', '\\n']
Tokenized   (024): ['<s>', 'd', 'v', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġc', 'n', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġsp', 'arsity', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['d', 'v', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġc', 'n', '_', 'scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġsp', 'arsity', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (014): ['dv_scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġcn_scale', 'Ġ=', 'ĠNone', 'Ġ,', 'Ġsparsity', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "fd_unknowns = [ var for var in unknown_list if var not in indep_list ] \n"
Original    (015): ['fd_unknowns', '=', '[', 'var', 'for', 'var', 'in', 'unknown_list', 'if', 'var', 'not', 'in', 'indep_list', ']', '\\n']
Tokenized   (026): ['<s>', 'fd', '_', 'unknown', 's', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġvar', 'Ġnot', 'Ġin', 'Ġind', 'ep', '_', 'list', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['fd', '_', 'unknown', 's', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġvar', 'Ġnot', 'Ġin', 'Ġind', 'ep', '_', 'list', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['fd_unknowns', 'Ġ=', 'Ġ[', 'Ġvar', 'Ġfor', 'Ġvar', 'Ġin', 'Ġunknown_list', 'Ġif', 'Ġvar', 'Ġnot', 'Ġin', 'Ġindep_list', 'Ġ]', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "usize += len ( idx ) \n"
Original    (007): ['usize', '+=', 'len', '(', 'idx', ')', '\\n']
Tokenized   (012): ['<s>', 'us', 'ize', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġid', 'x', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['us', 'ize', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġid', 'x', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['usize', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġidx', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "fwd = mode == \n"
Original    (005): ['fwd', '=', 'mode', '==', '\\n']
Tokenized   (009): ['<s>', 'f', 'wd', 'Ġ=', 'Ġmode', 'Ġ==', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['f', 'wd', 'Ġ=', 'Ġmode', 'Ġ==', 'Ġ\\', 'n']
Detokenized (005): ['fwd', 'Ġ=', 'Ġmode', 'Ġ==', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "poi_indices , qoi_indices = self . _poi_indices , self . _qoi_indices \n"
Original    (012): ['poi_indices', ',', 'qoi_indices', '=', 'self', '.', '_poi_indices', ',', 'self', '.', '_qoi_indices', '\\n']
Tokenized   (033): ['<s>', 'po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġq', 'oi', '_', 'ind', 'ices', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'q', 'oi', '_', 'ind', 'ices', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġq', 'oi', '_', 'ind', 'ices', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'po', 'i', '_', 'ind', 'ices', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'q', 'oi', '_', 'ind', 'ices', 'Ġ\\', 'n']
Detokenized (012): ['poi_indices', 'Ġ,', 'Ġqoi_indices', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_poi_indices', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_qoi_indices', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "in_scale , un_scale = cn_scale , dv_scale \n"
Original    (008): ['in_scale', ',', 'un_scale', '=', 'cn_scale', ',', 'dv_scale', '\\n']
Tokenized   (021): ['<s>', 'in', '_', 'scale', 'Ġ,', 'Ġun', '_', 'scale', 'Ġ=', 'Ġc', 'n', '_', 'scale', 'Ġ,', 'Ġd', 'v', '_', 'scale', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['in', '_', 'scale', 'Ġ,', 'Ġun', '_', 'scale', 'Ġ=', 'Ġc', 'n', '_', 'scale', 'Ġ,', 'Ġd', 'v', '_', 'scale', 'Ġ\\', 'n']
Detokenized (008): ['in_scale', 'Ġ,', 'Ġun_scale', 'Ġ=', 'Ġcn_scale', 'Ġ,', 'Ġdv_scale', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "duvec = self . root . dumat [ vkey ] \n"
Original    (011): ['duvec', '=', 'self', '.', 'root', '.', 'dumat', '[', 'vkey', ']', '\\n']
Tokenized   (017): ['<s>', 'du', 'vec', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġd', 'umat', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['du', 'vec', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġd', 'umat', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['duvec', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġdumat', 'Ġ[', 'Ġvkey', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "rhs [ vkey ] [ : ] = 0.0 \n"
Original    (010): ['rhs', '[', 'vkey', ']', '[', ':', ']', '=', '0.0', '\\n']
Tokenized   (017): ['<s>', 'r', 'hs', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġ0', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['r', 'hs', 'Ġ[', 'Ġv', 'key', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġ0', '.', '0', 'Ġ\\', 'n']
Detokenized (010): ['rhs', 'Ġ[', 'Ġvkey', 'Ġ]', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġ0.0', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "isinstance ( self . root . ln_solver , LinearGaussSeidel ) ) : \n"
Original    (013): ['isinstance', '(', 'self', '.', 'root', '.', 'ln_solver', ',', 'LinearGaussSeidel', ')', ')', ':', '\\n']
Tokenized   (025): ['<s>', 'is', 'instance', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ,', 'ĠLinear', 'Ga', 'uss', 'Se', 'idel', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['is', 'instance', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġl', 'n', '_', 's', 'olver', 'Ġ,', 'ĠLinear', 'Ga', 'uss', 'Se', 'idel', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (013): ['isinstance', 'Ġ(', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġln_solver', 'Ġ,', 'ĠLinearGaussSeidel', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "unkn_list = [ item for item in dunknowns if not dunknowns . metadata ( item ) . get ( ) ] \n"
Original    (022): ['unkn_list', '=', '[', 'item', 'for', 'item', 'in', 'dunknowns', 'if', 'not', 'dunknowns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (032): ['<s>', 'unk', 'n', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġd', 'unknown', 's', 'Ġif', 'Ġnot', 'Ġd', 'unknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['unk', 'n', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġd', 'unknown', 's', 'Ġif', 'Ġnot', 'Ġd', 'unknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (022): ['unkn_list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġdunknowns', 'Ġif', 'Ġnot', 'Ġdunknowns', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "p_size = np . size ( dinputs [ p_name ] ) \n"
Original    (012): ['p_size', '=', 'np', '.', 'size', '(', 'dinputs', '[', 'p_name', ']', ')', '\\n']
Tokenized   (021): ['<s>', 'p', '_', 'size', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġsize', 'Ġ(', 'Ġd', 'input', 's', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['p', '_', 'size', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġsize', 'Ġ(', 'Ġd', 'input', 's', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['p_size', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġsize', 'Ġ(', 'Ġdinputs', 'Ġ[', 'Ġp_name', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "dresids . _dat [ u_name ] . val [ idx ] = 1.0 \n"
Original    (014): ['dresids', '.', '_dat', '[', 'u_name', ']', '.', 'val', '[', 'idx', ']', '=', '1.0', '\\n']
Tokenized   (025): ['<s>', 'd', 'res', 'ids', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġu', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ[', 'Ġid', 'x', 'Ġ]', 'Ġ=', 'Ġ1', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['d', 'res', 'ids', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġu', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ[', 'Ġid', 'x', 'Ġ]', 'Ġ=', 'Ġ1', '.', '0', 'Ġ\\', 'n']
Detokenized (014): ['dresids', 'Ġ.', 'Ġ_dat', 'Ġ[', 'Ġu_name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ[', 'Ġidx', 'Ġ]', 'Ġ=', 'Ġ1.0', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "dunknowns , dresids , ) \n"
Original    (006): ['dunknowns', ',', 'dresids', ',', ')', '\\n']
Tokenized   (013): ['<s>', 'd', 'unknown', 's', 'Ġ,', 'Ġd', 'res', 'ids', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['d', 'unknown', 's', 'Ġ,', 'Ġd', 'res', 'ids', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['dunknowns', 'Ġ,', 'Ġdresids', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "jac_rev [ ( u_name , p_name ) ] [ idx , : ] = dinputs . _dat [ p_name ] . val \n"
Original    (023): ['jac_rev', '[', '(', 'u_name', ',', 'p_name', ')', ']', '[', 'idx', ',', ':', ']', '=', 'dinputs', '.', '_dat', '[', 'p_name', ']', '.', 'val', '\\n']
Tokenized   (038): ['<s>', 'jac', '_', 'rev', 'Ġ[', 'Ġ(', 'Ġu', '_', 'name', 'Ġ,', 'Ġp', '_', 'name', 'Ġ)', 'Ġ]', 'Ġ[', 'Ġid', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġd', 'input', 's', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['jac', '_', 'rev', 'Ġ[', 'Ġ(', 'Ġu', '_', 'name', 'Ġ,', 'Ġp', '_', 'name', 'Ġ)', 'Ġ]', 'Ġ[', 'Ġid', 'x', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġd', 'input', 's', 'Ġ.', 'Ġ_', 'dat', 'Ġ[', 'Ġp', '_', 'name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ\\', 'n']
Detokenized (023): ['jac_rev', 'Ġ[', 'Ġ(', 'Ġu_name', 'Ġ,', 'Ġp_name', 'Ġ)', 'Ġ]', 'Ġ[', 'Ġidx', 'Ġ,', 'Ġ:', 'Ġ]', 'Ġ=', 'Ġdinputs', 'Ġ.', 'Ġ_dat', 'Ġ[', 'Ġp_name', 'Ġ]', 'Ġ.', 'Ġval', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "c_name = cname , jac_fd2 = jac_fd2 , fd_desc = fd_desc , \n"
Original    (013): ['c_name', '=', 'cname', ',', 'jac_fd2', '=', 'jac_fd2', ',', 'fd_desc', '=', 'fd_desc', ',', '\\n']
Tokenized   (033): ['<s>', 'c', '_', 'name', 'Ġ=', 'Ġc', 'name', 'Ġ,', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ=', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ,', 'Ġf', 'd', '_', 'desc', 'Ġ=', 'Ġf', 'd', '_', 'desc', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['c', '_', 'name', 'Ġ=', 'Ġc', 'name', 'Ġ,', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ=', 'Ġj', 'ac', '_', 'fd', '2', 'Ġ,', 'Ġf', 'd', '_', 'desc', 'Ġ=', 'Ġf', 'd', '_', 'desc', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['c_name', 'Ġ=', 'Ġcname', 'Ġ,', 'Ġjac_fd2', 'Ġ=', 'Ġjac_fd2', 'Ġ,', 'Ġfd_desc', 'Ġ=', 'Ġfd_desc', 'Ġ,', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "param_srcs = [ root . connections [ p ] for p in abs_indep_list if not root . _params_dict [ p ] . get ( ) ] \n"
Original    (027): ['param_srcs', '=', '[', 'root', '.', 'connections', '[', 'p', ']', 'for', 'p', 'in', 'abs_indep_list', 'if', 'not', 'root', '.', '_params_dict', '[', 'p', ']', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (041): ['<s>', 'param', '_', 'src', 's', 'Ġ=', 'Ġ[', 'Ġroot', 'Ġ.', 'Ġconnections', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġabs', '_', 'ind', 'ep', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (039): ['param', '_', 'src', 's', 'Ġ=', 'Ġ[', 'Ġroot', 'Ġ.', 'Ġconnections', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġabs', '_', 'ind', 'ep', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġ_', 'params', '_', 'dict', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (027): ['param_srcs', 'Ġ=', 'Ġ[', 'Ġroot', 'Ġ.', 'Ġconnections', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġabs_indep_list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġ_params_dict', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 39
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "to_prom_name [ p ] for p , idxs in param_srcs \n"
Original    (011): ['to_prom_name', '[', 'p', ']', 'for', 'p', ',', 'idxs', 'in', 'param_srcs', '\\n']
Tokenized   (022): ['<s>', 'to', '_', 'prom', '_', 'name', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġ,', 'Ġid', 'xs', 'Ġin', 'Ġparam', '_', 'src', 's', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['to', '_', 'prom', '_', 'name', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġ,', 'Ġid', 'xs', 'Ġin', 'Ġparam', '_', 'src', 's', 'Ġ\\', 'n']
Detokenized (011): ['to_prom_name', 'Ġ[', 'Ġp', 'Ġ]', 'Ġfor', 'Ġp', 'Ġ,', 'Ġidxs', 'Ġin', 'Ġparam_srcs', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "unknown_list = [ item for item in unknown_list if not root . unknowns . metadata ( item ) . get ( ) ] \n"
Original    (024): ['unknown_list', '=', '[', 'item', 'for', 'item', 'in', 'unknown_list', 'if', 'not', 'root', '.', 'unknowns', '.', 'metadata', '(', 'item', ')', '.', 'get', '(', ')', ']', '\\n']
Tokenized   (032): ['<s>', 'unknown', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġunknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['unknown', '_', 'list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġunknown', '_', 'list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġunknown', 's', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (024): ['unknown_list', 'Ġ=', 'Ġ[', 'Ġitem', 'Ġfor', 'Ġitem', 'Ġin', 'Ġunknown_list', 'Ġif', 'Ġnot', 'Ġroot', 'Ġ.', 'Ġunknowns', 'Ġ.', 'Ġmetadata', 'Ġ(', 'Ġitem', 'Ġ)', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "_assemble_deriv_data ( indep_list , unknown_list , data , \n"
Original    (009): ['_assemble_deriv_data', '(', 'indep_list', ',', 'unknown_list', ',', 'data', ',', '\\n']
Tokenized   (024): ['<s>', '_', 'as', 'semble', '_', 'der', 'iv', '_', 'data', 'Ġ(', 'Ġind', 'ep', '_', 'list', 'Ġ,', 'Ġunknown', '_', 'list', 'Ġ,', 'Ġdata', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['_', 'as', 'semble', '_', 'der', 'iv', '_', 'data', 'Ġ(', 'Ġind', 'ep', '_', 'list', 'Ġ,', 'Ġunknown', '_', 'list', 'Ġ,', 'Ġdata', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['_assemble_deriv_data', 'Ġ(', 'Ġindep_list', 'Ġ,', 'Ġunknown_list', 'Ġ,', 'Ġdata', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "_both_names ( tmeta , to_prom_name ) ) \n"
Original    (008): ['_both_names', '(', 'tmeta', ',', 'to_prom_name', ')', ')', '\\n']
Tokenized   (019): ['<s>', '_', 'both', '_', 'names', 'Ġ(', 'Ġt', 'meta', 'Ġ,', 'Ġto', '_', 'prom', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['_', 'both', '_', 'names', 'Ġ(', 'Ġt', 'meta', 'Ġ,', 'Ġto', '_', 'prom', '_', 'name', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['_both_names', 'Ġ(', 'Ġtmeta', 'Ġ,', 'Ġto_prom_name', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "abs_unames = self . root . _sysdata . to_abs_uname \n"
Original    (010): ['abs_unames', '=', 'self', '.', 'root', '.', '_sysdata', '.', 'to_abs_uname', '\\n']
Tokenized   (023): ['<s>', 'abs', '_', 'un', 'ames', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'sys', 'data', 'Ġ.', 'Ġto', '_', 'abs', '_', 'un', 'ame', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['abs', '_', 'un', 'ames', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_', 'sys', 'data', 'Ġ.', 'Ġto', '_', 'abs', '_', 'un', 'ame', 'Ġ\\', 'n']
Detokenized (010): ['abs_unames', 'Ġ=', 'Ġself', 'Ġ.', 'Ġroot', 'Ġ.', 'Ġ_sysdata', 'Ġ.', 'Ġto_abs_uname', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "out_str = tmp1 . format ( _pad_name ( ) , _pad_name ( ) , \n"
Original    (015): ['out_str', '=', 'tmp1', '.', 'format', '(', '_pad_name', '(', ')', ',', '_pad_name', '(', ')', ',', '\\n']
Tokenized   (027): ['<s>', 'out', '_', 'str', 'Ġ=', 'Ġtmp', '1', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['out', '_', 'str', 'Ġ=', 'Ġtmp', '1', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ_', 'pad', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['out_str', 'Ġ=', 'Ġtmp1', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġ_pad_name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ_pad_name', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "magfor , magrev , magfd , abs1 , abs2 , \n"
Original    (011): ['magfor', ',', 'magrev', ',', 'magfd', ',', 'abs1', ',', 'abs2', ',', '\\n']
Tokenized   (019): ['<s>', 'mag', 'for', 'Ġ,', 'Ġmag', 'rev', 'Ġ,', 'Ġmag', 'fd', 'Ġ,', 'Ġabs', '1', 'Ġ,', 'Ġabs', '2', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mag', 'for', 'Ġ,', 'Ġmag', 'rev', 'Ġ,', 'Ġmag', 'fd', 'Ġ,', 'Ġabs', '1', 'Ġ,', 'Ġabs', '2', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['magfor', 'Ġ,', 'Ġmagrev', 'Ġ,', 'Ġmagfd', 'Ġ,', 'Ġabs1', 'Ġ,', 'Ġabs2', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "rel1 , rel2 ) ) \n"
Original    (006): ['rel1', ',', 'rel2', ')', ')', '\\n']
Tokenized   (011): ['<s>', 'rel', '1', 'Ġ,', 'Ġrel', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['rel', '1', 'Ġ,', 'Ġrel', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['rel1', 'Ġ,', 'Ġrel2', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "_pad_name ( , 12 , quotes = False ) \n"
Original    (010): ['_pad_name', '(', ',', '12', ',', 'quotes', '=', 'False', ')', '\\n']
Tokenized   (016): ['<s>', '_', 'pad', '_', 'name', 'Ġ(', 'Ġ,', 'Ġ12', 'Ġ,', 'Ġquotes', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['_', 'pad', '_', 'name', 'Ġ(', 'Ġ,', 'Ġ12', 'Ġ,', 'Ġquotes', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['_pad_name', 'Ġ(', 'Ġ,', 'Ġ12', 'Ġ,', 'Ġquotes', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "magfd , magfd2 , abs4 , rel4 ) ) \n"
Original    (010): ['magfd', ',', 'magfd2', ',', 'abs4', ',', 'rel4', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'mag', 'fd', 'Ġ,', 'Ġmag', 'fd', '2', 'Ġ,', 'Ġabs', '4', 'Ġ,', 'Ġrel', '4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['mag', 'fd', 'Ġ,', 'Ġmag', 'fd', '2', 'Ġ,', 'Ġabs', '4', 'Ġ,', 'Ġrel', '4', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['magfd', 'Ġ,', 'Ġmagfd2', 'Ġ,', 'Ġabs4', 'Ġ,', 'Ġrel4', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "out_stream . write ( str ( Jsub_fd2 ) ) \n"
Original    (010): ['out_stream', '.', 'write', '(', 'str', '(', 'Jsub_fd2', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'out', '_', 'stream', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠJ', 'sub', '_', 'fd', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['out', '_', 'stream', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠJ', 'sub', '_', 'fd', '2', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['out_stream', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠJsub_fd2', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sqlite_dict_args . setdefault ( , ) \n"
Original    (007): ['sqlite_dict_args', '.', 'setdefault', '(', ',', ')', '\\n']
Tokenized   (016): ['<s>', 'sql', 'ite', '_', 'dict', '_', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['sql', 'ite', '_', 'dict', '_', 'args', 'Ġ.', 'Ġset', 'default', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['sqlite_dict_args', 'Ġ.', 'Ġsetdefault', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ll_1 = ll_0 + n_samples - k - 1 \n"
Original    (010): ['ll_1', '=', 'll_0', '+', 'n_samples', '-', 'k', '-', '1', '\\n']
Tokenized   (020): ['<s>', 'll', '_', '1', 'Ġ=', 'Ġll', '_', '0', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġk', 'Ġ-', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['ll', '_', '1', 'Ġ=', 'Ġll', '_', '0', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġk', 'Ġ-', 'Ġ1', 'Ġ\\', 'n']
Detokenized (010): ['ll_1', 'Ġ=', 'Ġll_0', 'Ġ+', 'Ġn_samples', 'Ġ-', 'Ġk', 'Ġ-', 'Ġ1', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "D = self . D [ lvl ] \n"
Original    (009): ['D', '=', 'self', '.', 'D', '[', 'lvl', ']', '\\n']
Tokenized   (012): ['<s>', 'D', 'Ġ=', 'Ġself', 'Ġ.', 'ĠD', 'Ġ[', 'Ġlvl', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['D', 'Ġ=', 'Ġself', 'Ġ.', 'ĠD', 'Ġ[', 'Ġlvl', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['D', 'Ġ=', 'Ġself', 'Ġ.', 'ĠD', 'Ġ[', 'Ġlvl', 'Ġ]', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "initial_range = INITIAL_RANGE_DEFAULT , tol = TOLERANCE_DEFAULT ) : \n"
Original    (010): ['initial_range', '=', 'INITIAL_RANGE_DEFAULT', ',', 'tol', '=', 'TOLERANCE_DEFAULT', ')', ':', '\\n']
Tokenized   (030): ['<s>', 'initial', '_', 'range', 'Ġ=', 'ĠIN', 'IT', 'IAL', '_', 'R', 'ANGE', '_', 'DE', 'FAULT', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'ĠT', 'OL', 'ER', 'ANCE', '_', 'DE', 'FAULT', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['initial', '_', 'range', 'Ġ=', 'ĠIN', 'IT', 'IAL', '_', 'R', 'ANGE', '_', 'DE', 'FAULT', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'ĠT', 'OL', 'ER', 'ANCE', '_', 'DE', 'FAULT', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (010): ['initial_range', 'Ġ=', 'ĠINITIAL_RANGE_DEFAULT', 'Ġ,', 'Ġtol', 'Ġ=', 'ĠTOLERANCE_DEFAULT', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "y_best = y [ nlevel - 1 ] \n"
Original    (009): ['y_best', '=', 'y', '[', 'nlevel', '-', '1', ']', '\\n']
Tokenized   (015): ['<s>', 'y', '_', 'best', 'Ġ=', 'Ġy', 'Ġ[', 'Ġn', 'level', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['y', '_', 'best', 'Ġ=', 'Ġy', 'Ġ[', 'Ġn', 'level', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['y_best', 'Ġ=', 'Ġy', 'Ġ[', 'Ġnlevel', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "+ str ( theta ) ) \n"
Original    (007): ['+', 'str', '(', 'theta', ')', ')', '\\n']
Tokenized   (011): ['<s>', '+', 'Ġstr', 'Ġ(', 'Ġthe', 'ta', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['+', 'Ġstr', 'Ġ(', 'Ġthe', 'ta', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['+', 'Ġstr', 'Ġ(', 'Ġtheta', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "Yt = solve_triangular ( C , y , lower = True ) \n"
Original    (013): ['Yt', '=', 'solve_triangular', '(', 'C', ',', 'y', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (020): ['<s>', 'Y', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġy', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['Y', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġy', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['Yt', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġy', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "err2 = np . dot ( err . T , err ) [ 0 , 0 ] \n"
Original    (018): ['err2', '=', 'np', '.', 'dot', '(', 'err', '.', 'T', ',', 'err', ')', '[', '0', ',', '0', ']', '\\n']
Tokenized   (022): ['<s>', 'err', '2', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠT', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['err', '2', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠT', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['err2', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġerr', 'Ġ.', 'ĠT', 'Ġ,', 'Ġerr', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "sigma2 = err2 / ( n_samples - p - q ) \n"
Original    (012): ['sigma2', '=', 'err2', '/', '(', 'n_samples', '-', 'p', '-', 'q', ')', '\\n']
Tokenized   (021): ['<s>', 's', 'igma', '2', 'Ġ=', 'Ġerr', '2', 'Ġ/', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['s', 'igma', '2', 'Ġ=', 'Ġerr', '2', 'Ġ/', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['sigma2', 'Ġ=', 'Ġerr2', 'Ġ/', 'Ġ(', 'Ġn_samples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "detR = ( ( np . diag ( C ) ) ** ( 2. / n_samples ) ) . prod ( ) \n"
Original    (023): ['detR', '=', '(', '(', 'np', '.', 'diag', '(', 'C', ')', ')', '**', '(', '2.', '/', 'n_samples', ')', ')', '.', 'prod', '(', ')', '\\n']
Tokenized   (032): ['<s>', 'det', 'R', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdi', 'ag', 'Ġ(', 'ĠC', 'Ġ)', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ2', '.', 'Ġ/', 'Ġn', '_', 's', 'amples', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġprod', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['det', 'R', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdi', 'ag', 'Ġ(', 'ĠC', 'Ġ)', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ2', '.', 'Ġ/', 'Ġn', '_', 's', 'amples', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġprod', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['detR', 'Ġ=', 'Ġ(', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdiag', 'Ġ(', 'ĠC', 'Ġ)', 'Ġ)', 'Ġ**', 'Ġ(', 'Ġ2.', 'Ġ/', 'Ġn_samples', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġprod', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "rlf_value = ( n_samples - p - q ) * np . log10 ( sigma2 ) + n_samples * np . log10 ( detR ) \n"
Original    (026): ['rlf_value', '=', '(', 'n_samples', '-', 'p', '-', 'q', ')', '*', 'np', '.', 'log10', '(', 'sigma2', ')', '+', 'n_samples', '*', 'np', '.', 'log10', '(', 'detR', ')', '\\n']
Tokenized   (043): ['<s>', 'r', 'lf', '_', 'value', 'Ġ=', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġs', 'igma', '2', 'Ġ)', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġdet', 'R', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['r', 'lf', '_', 'value', 'Ġ=', 'Ġ(', 'Ġn', '_', 's', 'amples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġs', 'igma', '2', 'Ġ)', 'Ġ+', 'Ġn', '_', 's', 'amples', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġdet', 'R', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['rlf_value', 'Ġ=', 'Ġ(', 'Ġn_samples', 'Ġ-', 'Ġp', 'Ġ-', 'Ġq', 'Ġ)', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog10', 'Ġ(', 'Ġsigma2', 'Ġ)', 'Ġ+', 'Ġn_samples', 'Ġ*', 'Ġnp', 'Ġ.', 'Ġlog10', 'Ġ(', 'ĠdetR', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "log10t [ i ] - np . log10 ( thetaL [ 0 ] [ i ] ) } ) \n"
Original    (020): ['log10t', '[', 'i', ']', '-', 'np', '.', 'log10', '(', 'thetaL', '[', '0', ']', '[', 'i', ']', ')', '}', ')', '\\n']
Tokenized   (028): ['<s>', 'log', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'L', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['log', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'L', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['log10t', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġlog10', 'Ġ(', 'ĠthetaL', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "np . log10 ( thetaU [ 0 ] [ i ] ) - log10t [ i ] } ) \n"
Original    (020): ['np', '.', 'log10', '(', 'thetaU', '[', '0', ']', '[', 'i', ']', ')', '-', 'log10t', '[', 'i', ']', '}', ')', '\\n']
Tokenized   (028): ['<s>', 'np', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'U', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġlog', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['np', 'Ġ.', 'Ġlog', '10', 'Ġ(', 'Ġthe', 'ta', 'U', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġlog', '10', 't', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['np', 'Ġ.', 'Ġlog10', 'Ġ(', 'ĠthetaU', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ-', 'Ġlog10t', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "sol = minimize ( rlf_transform , x0 , method = , \n"
Original    (012): ['sol', '=', 'minimize', '(', 'rlf_transform', ',', 'x0', ',', 'method', '=', ',', '\\n']
Tokenized   (019): ['<s>', 'sol', 'Ġ=', 'Ġminimize', 'Ġ(', 'Ġr', 'lf', '_', 'transform', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġmethod', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['sol', 'Ġ=', 'Ġminimize', 'Ġ(', 'Ġr', 'lf', '_', 'transform', 'Ġ,', 'Ġx', '0', 'Ġ,', 'Ġmethod', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['sol', 'Ġ=', 'Ġminimize', 'Ġ(', 'Ġrlf_transform', 'Ġ,', 'Ġx0', 'Ġ,', 'Ġmethod', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "optimal_theta = 10. ** log10_optimal_x \n"
Original    (006): ['optimal_theta', '=', '10.', '**', 'log10_optimal_x', '\\n']
Tokenized   (020): ['<s>', 'opt', 'imal', '_', 'the', 'ta', 'Ġ=', 'Ġ10', '.', 'Ġ**', 'Ġlog', '10', '_', 'opt', 'imal', '_', 'x', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['opt', 'imal', '_', 'the', 'ta', 'Ġ=', 'Ġ10', '.', 'Ġ**', 'Ġlog', '10', '_', 'opt', 'imal', '_', 'x', 'Ġ\\', 'n']
Detokenized (006): ['optimal_theta', 'Ġ=', 'Ġ10.', 'Ġ**', 'Ġlog10_optimal_x', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "r_t = solve_triangular ( C , r_ . T , lower = True ) \n"
Original    (015): ['r_t', '=', 'solve_triangular', '(', 'C', ',', 'r_', '.', 'T', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'r', '_', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġr', '_', 'Ġ.', 'ĠT', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['r', '_', 't', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġr', '_', 'Ġ.', 'ĠT', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['r_t', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġr_', 'Ġ.', 'ĠT', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "dx = l1_cross_distances ( X , Y = self . X [ i ] ) \n"
Original    (016): ['dx', '=', 'l1_cross_distances', '(', 'X', ',', 'Y', '=', 'self', '.', 'X', '[', 'i', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'dx', 'Ġ=', 'Ġl', '1', '_', 'cross', '_', 'dist', 'ances', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'ĠX', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['dx', 'Ġ=', 'Ġl', '1', '_', 'cross', '_', 'dist', 'ances', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'ĠX', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['dx', 'Ġ=', 'Ġl1_cross_distances', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'ĠX', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "r_ = self . corr ( self . theta [ i ] , dx ) . reshape ( n_eval , self . n_samples [ i ] ) \n"
Original    (028): ['r_', '=', 'self', '.', 'corr', '(', 'self', '.', 'theta', '[', 'i', ']', ',', 'dx', ')', '.', 'reshape', '(', 'n_eval', ',', 'self', '.', 'n_samples', '[', 'i', ']', ')', '\\n']
Tokenized   (040): ['<s>', 'r', '_', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcor', 'r', 'Ġ(', 'Ġself', 'Ġ.', 'Ġthe', 'ta', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġdx', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġn', '_', 'eval', 'Ġ,', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['r', '_', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcor', 'r', 'Ġ(', 'Ġself', 'Ġ.', 'Ġthe', 'ta', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġdx', 'Ġ)', 'Ġ.', 'Ġresh', 'ape', 'Ġ(', 'Ġn', '_', 'eval', 'Ġ,', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (028): ['r_', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcorr', 'Ġ(', 'Ġself', 'Ġ.', 'Ġtheta', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġdx', 'Ġ)', 'Ġ.', 'Ġreshape', 'Ġ(', 'Ġn_eval', 'Ġ,', 'Ġself', 'Ġ.', 'Ġn_samples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "yt = solve_triangular ( C , self . y [ i ] , lower = True ) \n"
Original    (018): ['yt', '=', 'solve_triangular', '(', 'C', ',', 'self', '.', 'y', '[', 'i', ']', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', 'yt', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġself', 'Ġ.', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['yt', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġself', 'Ġ.', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['yt', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠC', 'Ġ,', 'Ġself', 'Ġ.', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "mu [ : , i ] = ( np . dot ( f . T , beta ) + np . dot ( r_t . T , yt - np . dot ( Ft , beta ) ) ) . ravel ( ) \n"
Original    (044): ['mu', '[', ':', ',', 'i', ']', '=', '(', 'np', '.', 'dot', '(', 'f', '.', 'T', ',', 'beta', ')', '+', 'np', '.', 'dot', '(', 'r_t', '.', 'T', ',', 'yt', '-', 'np', '.', 'dot', '(', 'Ft', ',', 'beta', ')', ')', ')', '.', 'ravel', '(', ')', '\\n']
Tokenized   (051): ['<s>', 'mu', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġf', 'Ġ.', 'ĠT', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ+', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġr', '_', 't', 'Ġ.', 'ĠT', 'Ġ,', 'Ġy', 't', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġra', 'vel', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (049): ['mu', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġf', 'Ġ.', 'ĠT', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ+', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġr', '_', 't', 'Ġ.', 'ĠT', 'Ġ,', 'Ġy', 't', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġra', 'vel', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (044): ['mu', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġf', 'Ġ.', 'ĠT', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ+', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'Ġr_t', 'Ġ.', 'ĠT', 'Ġ,', 'Ġyt', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ,', 'Ġbeta', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ.', 'Ġravel', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 49
===================================================================
Hidden states:  (13, 44, 768)
# Extracted words:  44
Sentence         : "u_ = solve_triangular ( G . T , f - np . dot ( Ft . T , r_t ) , lower = True ) \n"
Original    (026): ['u_', '=', 'solve_triangular', '(', 'G', '.', 'T', ',', 'f', '-', 'np', '.', 'dot', '(', 'Ft', '.', 'T', ',', 'r_t', ')', ',', 'lower', '=', 'True', ')', '\\n']
Tokenized   (035): ['<s>', 'u', '_', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠG', 'Ġ.', 'ĠT', 'Ġ,', 'Ġf', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ.', 'ĠT', 'Ġ,', 'Ġr', '_', 't', 'Ġ)', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['u', '_', 'Ġ=', 'Ġsolve', '_', 'tri', 'angular', 'Ġ(', 'ĠG', 'Ġ.', 'ĠT', 'Ġ,', 'Ġf', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ.', 'ĠT', 'Ġ,', 'Ġr', '_', 't', 'Ġ)', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['u_', 'Ġ=', 'Ġsolve_triangular', 'Ġ(', 'ĠG', 'Ġ.', 'ĠT', 'Ġ,', 'Ġf', 'Ġ-', 'Ġnp', 'Ġ.', 'Ġdot', 'Ġ(', 'ĠFt', 'Ġ.', 'ĠT', 'Ġ,', 'Ġr_t', 'Ġ)', 'Ġ,', 'Ġlower', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "sigma2_rho = ( sigma2_rho * g ) . sum ( axis = 1 ) \n"
Original    (015): ['sigma2_rho', '=', '(', 'sigma2_rho', '*', 'g', ')', '.', 'sum', '(', 'axis', '=', '1', ')', '\\n']
Tokenized   (028): ['<s>', 's', 'igma', '2', '_', 'r', 'ho', 'Ġ=', 'Ġ(', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'Ġg', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['s', 'igma', '2', '_', 'r', 'ho', 'Ġ=', 'Ġ(', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'Ġg', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['sigma2_rho', 'Ġ=', 'Ġ(', 'Ġsigma2_rho', 'Ġ*', 'Ġg', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "MSE [ : , i ] = sigma2_rho * MSE [ : , i - 1 ] + Q_ / ( 2 * ( self . n_samples [ i ] - self . p [ i ] - self . q [ i ] ) ) * ( 1 - ( r_t ** 2 ) . sum ( axis = 0 ) ) + self . sigma2 [ i ] * ( u_ ** 2 ) . sum ( axis = 0 ) \n"
Original    (084): ['MSE', '[', ':', ',', 'i', ']', '=', 'sigma2_rho', '*', 'MSE', '[', ':', ',', 'i', '-', '1', ']', '+', 'Q_', '/', '(', '2', '*', '(', 'self', '.', 'n_samples', '[', 'i', ']', '-', 'self', '.', 'p', '[', 'i', ']', '-', 'self', '.', 'q', '[', 'i', ']', ')', ')', '*', '(', '1', '-', '(', 'r_t', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', ')', '+', 'self', '.', 'sigma2', '[', 'i', ']', '*', '(', 'u_', '**', '2', ')', '.', 'sum', '(', 'axis', '=', '0', ')', '\\n']
Tokenized   (103): ['<s>', 'M', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'ĠM', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ+', 'ĠQ', '_', 'Ġ/', 'Ġ(', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġp', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġq', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġ(', 'Ġr', '_', 't', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġs', 'igma', '2', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ*', 'Ġ(', 'Ġu', '_', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (101): ['M', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġs', 'igma', '2', '_', 'r', 'ho', 'Ġ*', 'ĠM', 'SE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ+', 'ĠQ', '_', 'Ġ/', 'Ġ(', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', '_', 's', 'amples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġp', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġq', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġ(', 'Ġr', '_', 't', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġs', 'igma', '2', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ*', 'Ġ(', 'Ġu', '_', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (084): ['MSE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ]', 'Ġ=', 'Ġsigma2_rho', 'Ġ*', 'ĠMSE', 'Ġ[', 'Ġ:', 'Ġ,', 'Ġi', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ+', 'ĠQ_', 'Ġ/', 'Ġ(', 'Ġ2', 'Ġ*', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn_samples', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġp', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ-', 'Ġself', 'Ġ.', 'Ġq', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', 'Ġ-', 'Ġ(', 'Ġr_t', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġself', 'Ġ.', 'Ġsigma2', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ*', 'Ġ(', 'Ġu_', 'Ġ**', 'Ġ2', 'Ġ)', 'Ġ.', 'Ġsum', 'Ġ(', 'Ġaxis', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 101
===================================================================
Hidden states:  (13, 84, 768)
# Extracted words:  84
Sentence         : "n_features = np . zeros ( nlevel , dtype = int ) \n"
Original    (013): ['n_features', '=', 'np', '.', 'zeros', '(', 'nlevel', ',', 'dtype', '=', 'int', ')', '\\n']
Tokenized   (021): ['<s>', 'n', '_', 'features', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġn', 'level', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġint', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['n', '_', 'features', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġz', 'eros', 'Ġ(', 'Ġn', 'level', 'Ġ,', 'Ġd', 'type', 'Ġ=', 'Ġint', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['n_features', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġzeros', 'Ġ(', 'Ġnlevel', 'Ġ,', 'Ġdtype', 'Ġ=', 'Ġint', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "n_samples_y [ i ] = y [ i ] . shape [ 0 ] \n"
Original    (015): ['n_samples_y', '[', 'i', ']', '=', 'y', '[', 'i', ']', '.', 'shape', '[', '0', ']', '\\n']
Tokenized   (023): ['<s>', 'n', '_', 's', 'amples', '_', 'y', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['n', '_', 's', 'amples', '_', 'y', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['n_samples_y', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ=', 'Ġy', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ.', 'Ġshape', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "Y_pred , MSE = self . model . predict ( [ new_x ] ) \n"
Original    (015): ['Y_pred', ',', 'MSE', '=', 'self', '.', 'model', '.', 'predict', '(', '[', 'new_x', ']', ')', '\\n']
Tokenized   (023): ['<s>', 'Y', '_', 'pred', 'Ġ,', 'ĠM', 'SE', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ[', 'Ġnew', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['Y', '_', 'pred', 'Ġ,', 'ĠM', 'SE', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ[', 'Ġnew', '_', 'x', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['Y_pred', 'Ġ,', 'ĠMSE', 'Ġ=', 'Ġself', 'Ġ.', 'Ġmodel', 'Ġ.', 'Ġpredict', 'Ġ(', 'Ġ[', 'Ġnew_x', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "X , Y = self . _fit_adapter ( X , Y ) \n"
Original    (013): ['X', ',', 'Y', '=', 'self', '.', '_fit_adapter', '(', 'X', ',', 'Y', ')', '\\n']
Tokenized   (020): ['<s>', 'X', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'fit', '_', 'ad', 'apter', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['X', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'fit', '_', 'ad', 'apter', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['X', 'Ġ,', 'ĠY', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_fit_adapter', 'Ġ(', 'ĠX', 'Ġ,', 'ĠY', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "Y = [ np . array ( y ) for y in reversed ( Y ) ] \n"
Original    (018): ['Y', '=', '[', 'np', '.', 'array', '(', 'y', ')', 'for', 'y', 'in', 'reversed', '(', 'Y', ')', ']', '\\n']
Tokenized   (021): ['<s>', 'Y', 'Ġ=', 'Ġ[', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġy', 'Ġ)', 'Ġfor', 'Ġy', 'Ġin', 'Ġreversed', 'Ġ(', 'ĠY', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Y', 'Ġ=', 'Ġ[', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġy', 'Ġ)', 'Ġfor', 'Ġy', 'Ġin', 'Ġreversed', 'Ġ(', 'ĠY', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (018): ['Y', 'Ġ=', 'Ġ[', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġy', 'Ġ)', 'Ġfor', 'Ġy', 'Ġin', 'Ġreversed', 'Ġ(', 'ĠY', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "newdata = np . array ( parsed [ : ] ) \n"
Original    (012): ['newdata', '=', 'np', '.', 'array', '(', 'parsed', '[', ':', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'new', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġparsed', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['new', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġparsed', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['newdata', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġparsed', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "icc . DB_USER ) , shell = True ) \n"
Original    (010): ['icc', '.', 'DB_USER', ')', ',', 'shell', '=', 'True', ')', '\\n']
Tokenized   (015): ['<s>', 'icc', 'Ġ.', 'ĠDB', '_', 'USER', 'Ġ)', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['icc', 'Ġ.', 'ĠDB', '_', 'USER', 'Ġ)', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['icc', 'Ġ.', 'ĠDB_USER', 'Ġ)', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "instance_db_name , shell = True ) \n"
Original    (007): ['instance_db_name', ',', 'shell', '=', 'True', ')', '\\n']
Tokenized   (014): ['<s>', 'instance', '_', 'db', '_', 'name', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['instance', '_', 'db', '_', 'name', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['instance_db_name', 'Ġ,', 'Ġshell', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "customslide = CustomSlide . objects . create ( title = , text = default_projector = Projector . objects . get ( pk = 1 ) \n"
Original    (026): ['customslide', '=', 'CustomSlide', '.', 'objects', '.', 'create', '(', 'title', '=', ',', 'text', '=', 'default_projector', '=', 'Projector', '.', 'objects', '.', 'get', '(', 'pk', '=', '1', ')', '\\n']
Tokenized   (038): ['<s>', 'custom', 'sl', 'ide', 'Ġ=', 'ĠCustom', 'Sl', 'ide', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġtitle', 'Ġ=', 'Ġ,', 'Ġtext', 'Ġ=', 'Ġdefault', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['custom', 'sl', 'ide', 'Ġ=', 'ĠCustom', 'Sl', 'ide', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġtitle', 'Ġ=', 'Ġ,', 'Ġtext', 'Ġ=', 'Ġdefault', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['customslide', 'Ġ=', 'ĠCustomSlide', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġcreate', 'Ġ(', 'Ġtitle', 'Ġ=', 'Ġ,', 'Ġtext', 'Ġ=', 'Ġdefault_projector', 'Ġ=', 'ĠProjector', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "default_projector = Projector . objects . get ( pk = 1 ) \n"
Original    (013): ['default_projector', '=', 'Projector', '.', 'objects', '.', 'get', '(', 'pk', '=', '1', ')', '\\n']
Tokenized   (021): ['<s>', 'default', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['default', '_', 'project', 'or', 'Ġ=', 'ĠProject', 'or', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġp', 'k', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['default_projector', 'Ġ=', 'ĠProjector', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġpk', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "reverse ( , args = [ ] ) ) \n"
Original    (010): ['reverse', '(', ',', 'args', '=', '[', ']', ')', ')', '\\n']
Tokenized   (013): ['<s>', 'reverse', 'Ġ(', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['reverse', 'Ġ(', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['reverse', 'Ġ(', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "yield ConfigVariable ( \n"
Original    (004): ['yield', 'ConfigVariable', '(', '\\n']
Tokenized   (009): ['<s>', 'y', 'ield', 'ĠConfig', 'Variable', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['y', 'ield', 'ĠConfig', 'Variable', 'Ġ(', 'Ġ\\', 'n']
Detokenized (004): ['yield', 'ĠConfigVariable', 'Ġ(', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "{ : , : } , { : , : } ) \n"
Original    (013): ['{', ':', ',', ':', '}', ',', '{', ':', ',', ':', '}', ')', '\\n']
Tokenized   (016): ['<s>', '{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ,', 'Ġ{', 'Ġ:', 'Ġ,', 'Ġ:', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "validators = ( validator_for_testing , ) ) \n"
Original    (008): ['validators', '=', '(', 'validator_for_testing', ',', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'valid', 'ators', 'Ġ=', 'Ġ(', 'Ġvalid', 'ator', '_', 'for', '_', 'testing', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['valid', 'ators', 'Ġ=', 'Ġ(', 'Ġvalid', 'ator', '_', 'for', '_', 'testing', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['validators', 'Ġ=', 'Ġ(', 'Ġvalidator_for_testing', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "generate_username . return_value = \n"
Original    (005): ['generate_username', '.', 'return_value', '=', '\\n']
Tokenized   (013): ['<s>', 'gener', 'ate', '_', 'username', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['gener', 'ate', '_', 'username', 'Ġ.', 'Ġreturn', '_', 'value', 'Ġ=', 'Ġ\\', 'n']
Detokenized (005): ['generate_username', 'Ġ.', 'Ġreturn_value', 'Ġ=', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "serializer = UserFullSerializer ( context = { : view } ) \n"
Original    (012): ['serializer', '=', 'UserFullSerializer', '(', 'context', '=', '{', ':', 'view', '}', ')', '\\n']
Tokenized   (019): ['<s>', 'serial', 'izer', 'Ġ=', 'ĠUser', 'Full', 'Serial', 'izer', 'Ġ(', 'Ġcontext', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġview', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['serial', 'izer', 'Ġ=', 'ĠUser', 'Full', 'Serial', 'izer', 'Ġ(', 'Ġcontext', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġview', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['serializer', 'Ġ=', 'ĠUserFullSerializer', 'Ġ(', 'Ġcontext', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġview', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "#domain... #localhost... \n"
Original    (003): ['#domain...', '#localhost...', '\\n']
Tokenized   (010): ['<s>', '#', 'domain', '...', 'Ġ#', 'localhost', '...', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['#', 'domain', '...', 'Ġ#', 'localhost', '...', 'Ġ\\', 'n']
Detokenized (003): ['#domain...', 'Ġ#localhost...', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "USERNAME_REGEX = re . compile ( , re . I ) \n"
Original    (012): ['USERNAME_REGEX', '=', 're', '.', 'compile', '(', ',', 're', '.', 'I', ')', '\\n']
Tokenized   (019): ['<s>', 'USER', 'NAME', '_', 'REG', 'EX', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġ,', 'Ġre', 'Ġ.', 'ĠI', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['USER', 'NAME', '_', 'REG', 'EX', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġ,', 'Ġre', 'Ġ.', 'ĠI', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['USERNAME_REGEX', 'Ġ=', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġ,', 'Ġre', 'Ġ.', 'ĠI', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "RouteDistinguisher . TYPE_IP_LOC , None , \n"
Original    (007): ['RouteDistinguisher', '.', 'TYPE_IP_LOC', ',', 'None', ',', '\\n']
Tokenized   (017): ['<s>', 'Route', 'Dist', 'ingu', 'isher', 'Ġ.', 'ĠTYPE', '_', 'IP', '_', 'LOC', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['Route', 'Dist', 'ingu', 'isher', 'Ġ.', 'ĠTYPE', '_', 'IP', '_', 'LOC', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['RouteDistinguisher', 'Ġ.', 'ĠTYPE_IP_LOC', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "10000 + label ) \n"
Original    (005): ['10000', '+', 'label', ')', '\\n']
Tokenized   (008): ['<s>', '10000', 'Ġ+', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['10000', 'Ġ+', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['10000', 'Ġ+', 'Ġlabel', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "nh = Inet ( 1 , socket . inet_pton ( socket . AF_INET , \n"
Original    (015): ['nh', '=', 'Inet', '(', '1', ',', 'socket', '.', 'inet_pton', '(', 'socket', '.', 'AF_INET', ',', '\\n']
Tokenized   (026): ['<s>', 'n', 'h', 'Ġ=', 'ĠIn', 'et', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġsocket', 'Ġ.', 'Ġin', 'et', '_', 'pton', 'Ġ(', 'Ġsocket', 'Ġ.', 'ĠAF', '_', 'IN', 'ET', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['n', 'h', 'Ġ=', 'ĠIn', 'et', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġsocket', 'Ġ.', 'Ġin', 'et', '_', 'pton', 'Ġ(', 'Ġsocket', 'Ġ.', 'ĠAF', '_', 'IN', 'ET', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['nh', 'Ġ=', 'ĠInet', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġsocket', 'Ġ.', 'Ġinet_pton', 'Ġ(', 'Ġsocket', 'Ġ.', 'ĠAF_INET', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "route . attributes . add ( ECommunities ( self . readvertiseToRTs ) ) \n"
Original    (014): ['route', '.', 'attributes', '.', 'add', '(', 'ECommunities', '(', 'self', '.', 'readvertiseToRTs', ')', ')', '\\n']
Tokenized   (024): ['<s>', 'route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġadd', 'Ġ(', 'ĠE', 'Commun', 'ities', 'Ġ(', 'Ġself', 'Ġ.', 'Ġread', 'vert', 'ise', 'To', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġadd', 'Ġ(', 'ĠE', 'Commun', 'ities', 'Ġ(', 'Ġself', 'Ġ.', 'Ġread', 'vert', 'ise', 'To', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġadd', 'Ġ(', 'ĠECommunities', 'Ġ(', 'Ġself', 'Ġ.', 'ĠreadvertiseToRTs', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "nlri . prefix , label ) \n"
Original    (007): ['nlri', '.', 'prefix', ',', 'label', ')', '\\n']
Tokenized   (011): ['<s>', 'nl', 'ri', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['nl', 'ri', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġlabel', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['nlri', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġlabel', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "set ( self . importRTs ) ) ) > 0 ) \n"
Original    (012): ['set', '(', 'self', '.', 'importRTs', ')', ')', ')', '>', '0', ')', '\\n']
Tokenized   (017): ['<s>', 'set', 'Ġ(', 'Ġself', 'Ġ.', 'Ġimport', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['set', 'Ġ(', 'Ġself', 'Ġ.', 'Ġimport', 'RT', 's', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['set', 'Ġ(', 'Ġself', 'Ġ.', 'ĠimportRTs', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "newRoute . nlri . labelStack [ 0 ] . labelValue , newRoute . nlri , encaps ) \n"
Original    (018): ['newRoute', '.', 'nlri', '.', 'labelStack', '[', '0', ']', '.', 'labelValue', ',', 'newRoute', '.', 'nlri', ',', 'encaps', ')', '\\n']
Tokenized   (029): ['<s>', 'new', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġnew', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ,', 'Ġencaps', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['new', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġnew', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ,', 'Ġencaps', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['newRoute', 'Ġ.', 'Ġnlri', 'Ġ.', 'ĠlabelStack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'ĠlabelValue', 'Ġ,', 'ĠnewRoute', 'Ġ.', 'Ġnlri', 'Ġ,', 'Ġencaps', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "prefix , oldRoute . attributes . get ( NextHop . ID ) . next_hop , \n"
Original    (016): ['prefix', ',', 'oldRoute', '.', 'attributes', '.', 'get', '(', 'NextHop', '.', 'ID', ')', '.', 'next_hop', ',', '\\n']
Tokenized   (023): ['<s>', 'prefix', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġget', 'Ġ(', 'ĠNext', 'Hop', 'Ġ.', 'ĠID', 'Ġ)', 'Ġ.', 'Ġnext', '_', 'hop', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['prefix', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġget', 'Ġ(', 'ĠNext', 'Hop', 'Ġ.', 'ĠID', 'Ġ)', 'Ġ.', 'Ġnext', '_', 'hop', 'Ġ,', 'Ġ\\', 'n']
Detokenized (016): ['prefix', 'Ġ,', 'ĠoldRoute', 'Ġ.', 'Ġattributes', 'Ġ.', 'Ġget', 'Ġ(', 'ĠNextHop', 'Ġ.', 'ĠID', 'Ġ)', 'Ġ.', 'Ġnext_hop', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "oldRoute . nlri . labelStack [ 0 ] . labelValue , oldRoute . nlri ) \n"
Original    (016): ['oldRoute', '.', 'nlri', '.', 'labelStack', '[', '0', ']', '.', 'labelValue', ',', 'oldRoute', '.', 'nlri', ')', '\\n']
Tokenized   (027): ['<s>', 'old', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['old', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ.', 'Ġlabel', 'Stack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlabel', 'Value', 'Ġ,', 'Ġold', 'Route', 'Ġ.', 'Ġn', 'l', 'ri', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['oldRoute', 'Ġ.', 'Ġnlri', 'Ġ.', 'ĠlabelStack', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'ĠlabelValue', 'Ġ,', 'ĠoldRoute', 'Ġ.', 'Ġnlri', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : ""readvertised" : ( LGMap . VALUE , [ repr ( prefix ) for prefix in \n"
Original    (016): ['"readvertised"', ':', '(', 'LGMap', '.', 'VALUE', ',', '[', 'repr', '(', 'prefix', ')', 'for', 'prefix', 'in', '\\n']
Tokenized   (025): ['<s>', '"', 'read', 'vert', 'ised', '"', 'Ġ:', 'Ġ(', 'ĠLG', 'Map', 'Ġ.', 'ĠVAL', 'UE', 'Ġ,', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġprefix', 'Ġ)', 'Ġfor', 'Ġprefix', 'Ġin', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['"', 'read', 'vert', 'ised', '"', 'Ġ:', 'Ġ(', 'ĠLG', 'Map', 'Ġ.', 'ĠVAL', 'UE', 'Ġ,', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġprefix', 'Ġ)', 'Ġfor', 'Ġprefix', 'Ġin', 'Ġ\\', 'n']
Detokenized (016): ['"readvertised"', 'Ġ:', 'Ġ(', 'ĠLGMap', 'Ġ.', 'ĠVALUE', 'Ġ,', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġprefix', 'Ġ)', 'Ġfor', 'Ġprefix', 'Ġin', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "REACTORNAME = DEFAULT_REACTORS . get ( platform . system ( ) , ) \n"
Original    (014): ['REACTORNAME', '=', 'DEFAULT_REACTORS', '.', 'get', '(', 'platform', '.', 'system', '(', ')', ',', ')', '\\n']
Tokenized   (025): ['<s>', 'RE', 'ACT', 'OR', 'NAME', 'Ġ=', 'ĠDE', 'FAULT', '_', 'RE', 'ACT', 'ORS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġplatform', 'Ġ.', 'Ġsystem', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['RE', 'ACT', 'OR', 'NAME', 'Ġ=', 'ĠDE', 'FAULT', '_', 'RE', 'ACT', 'ORS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġplatform', 'Ġ.', 'Ġsystem', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['REACTORNAME', 'Ġ=', 'ĠDEFAULT_REACTORS', 'Ġ.', 'Ġget', 'Ġ(', 'Ġplatform', 'Ġ.', 'Ġsystem', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "set_reactor = lambda : reactor \n"
Original    (006): ['set_reactor', '=', 'lambda', ':', 'reactor', '\\n']
Tokenized   (012): ['<s>', 'set', '_', 're', 'actor', 'Ġ=', 'Ġlambda', 'Ġ:', 'Ġreactor', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['set', '_', 're', 'actor', 'Ġ=', 'Ġlambda', 'Ġ:', 'Ġreactor', 'Ġ\\', 'n']
Detokenized (006): ['set_reactor', 'Ġ=', 'Ġlambda', 'Ġ:', 'Ġreactor', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "SIGNALS = dict ( ( k , v ) for v , k in signal . __dict__ . iteritems ( ) if v . startswith ( ) and not v . startswith ( ) ) \n"
Original    (036): ['SIGNALS', '=', 'dict', '(', '(', 'k', ',', 'v', ')', 'for', 'v', ',', 'k', 'in', 'signal', '.', '__dict__', '.', 'iteritems', '(', ')', 'if', 'v', '.', 'startswith', '(', ')', 'and', 'not', 'v', '.', 'startswith', '(', ')', ')', '\\n']
Tokenized   (047): ['<s>', 'SIGN', 'ALS', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġk', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġv', 'Ġ,', 'Ġk', 'Ġin', 'Ġsignal', 'Ġ.', 'Ġ__', 'dict', '__', 'Ġ.', 'Ġiter', 'items', 'Ġ(', 'Ġ)', 'Ġif', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġand', 'Ġnot', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (045): ['SIGN', 'ALS', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġk', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġv', 'Ġ,', 'Ġk', 'Ġin', 'Ġsignal', 'Ġ.', 'Ġ__', 'dict', '__', 'Ġ.', 'Ġiter', 'items', 'Ġ(', 'Ġ)', 'Ġif', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġand', 'Ġnot', 'Ġv', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (036): ['SIGNALS', 'Ġ=', 'Ġdict', 'Ġ(', 'Ġ(', 'Ġk', 'Ġ,', 'Ġv', 'Ġ)', 'Ġfor', 'Ġv', 'Ġ,', 'Ġk', 'Ġin', 'Ġsignal', 'Ġ.', 'Ġ__dict__', 'Ġ.', 'Ġiteritems', 'Ġ(', 'Ġ)', 'Ġif', 'Ġv', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġ)', 'Ġand', 'Ġnot', 'Ġv', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 45
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "pargs = ( self . name , self . label , self . reactor ) \n"
Original    (016): ['pargs', '=', '(', 'self', '.', 'name', ',', 'self', '.', 'label', ',', 'self', '.', 'reactor', ')', '\\n']
Tokenized   (020): ['<s>', 'p', 'args', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġself', 'Ġ.', 'Ġreactor', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['p', 'args', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġself', 'Ġ.', 'Ġreactor', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['pargs', 'Ġ=', 'Ġ(', 'Ġself', 'Ġ.', 'Ġname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġlabel', 'Ġ,', 'Ġself', 'Ġ.', 'Ġreactor', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "* pargs , ** pkwargs \n"
Original    (006): ['*', 'pargs', ',', '**', 'pkwargs', '\\n']
Tokenized   (012): ['<s>', '*', 'Ġp', 'args', 'Ġ,', 'Ġ**', 'Ġp', 'kw', 'args', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['*', 'Ġp', 'args', 'Ġ,', 'Ġ**', 'Ġp', 'kw', 'args', 'Ġ\\', 'n']
Detokenized (006): ['*', 'Ġpargs', 'Ġ,', 'Ġ**', 'Ġpkwargs', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "logdir = env . pop ( , os . path . join ( os . path . sep , ) ) \n"
Original    (022): ['logdir', '=', 'env', '.', 'pop', '(', ',', 'os', '.', 'path', '.', 'join', '(', 'os', '.', 'path', '.', 'sep', ',', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'log', 'dir', 'Ġ=', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['log', 'dir', 'Ġ=', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['logdir', 'Ġ=', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsep', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "masksignals = bool ( env . pop ( , True ) ) \n"
Original    (013): ['masksignals', '=', 'bool', '(', 'env', '.', 'pop', '(', ',', 'True', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'mas', 'ks', 'ign', 'als', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['mas', 'ks', 'ign', 'als', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['masksignals', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "usetty = bool ( env . pop ( , ) ) \n"
Original    (012): ['usetty', '=', 'bool', '(', 'env', '.', 'pop', '(', ',', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'us', 'et', 'ty', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['us', 'et', 'ty', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['usetty', 'Ġ=', 'Ġbool', 'Ġ(', 'Ġenv', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "maxfd = resource . getrlimit ( resource . RLIMIT_NOFILE ) [ 1 ] \n"
Original    (014): ['maxfd', '=', 'resource', '.', 'getrlimit', '(', 'resource', '.', 'RLIMIT_NOFILE', ')', '[', '1', ']', '\\n']
Tokenized   (025): ['<s>', 'max', 'fd', 'Ġ=', 'Ġresource', 'Ġ.', 'Ġget', 'r', 'limit', 'Ġ(', 'Ġresource', 'Ġ.', 'ĠRL', 'IM', 'IT', '_', 'NO', 'FILE', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['max', 'fd', 'Ġ=', 'Ġresource', 'Ġ.', 'Ġget', 'r', 'limit', 'Ġ(', 'Ġresource', 'Ġ.', 'ĠRL', 'IM', 'IT', '_', 'NO', 'FILE', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['maxfd', 'Ġ=', 'Ġresource', 'Ġ.', 'Ġgetrlimit', 'Ġ(', 'Ġresource', 'Ġ.', 'ĠRLIMIT_NOFILE', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "hasattr ( os , "devnull" ) and os . devnull or "/dev/null" , \n"
Original    (014): ['hasattr', '(', 'os', ',', '"devnull"', ')', 'and', 'os', '.', 'devnull', 'or', '"/dev/null"', ',', '\\n']
Tokenized   (026): ['<s>', 'has', 'attr', 'Ġ(', 'Ġos', 'Ġ,', 'Ġ"', 'dev', 'null', '"', 'Ġ)', 'Ġand', 'Ġos', 'Ġ.', 'Ġdev', 'null', 'Ġor', 'Ġ"/', 'dev', '/', 'null', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['has', 'attr', 'Ġ(', 'Ġos', 'Ġ,', 'Ġ"', 'dev', 'null', '"', 'Ġ)', 'Ġand', 'Ġos', 'Ġ.', 'Ġdev', 'null', 'Ġor', 'Ġ"/', 'dev', '/', 'null', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['hasattr', 'Ġ(', 'Ġos', 'Ġ,', 'Ġ"devnull"', 'Ġ)', 'Ġand', 'Ġos', 'Ġ.', 'Ġdevnull', 'Ġor', 'Ġ"/dev/null"', 'Ġ,', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "droned . logging . logToDir ( \n"
Original    (007): ['droned', '.', 'logging', '.', 'logToDir', '(', '\\n']
Tokenized   (014): ['<s>', 'd', 'ron', 'ed', 'Ġ.', 'Ġlogging', 'Ġ.', 'Ġlog', 'To', 'Dir', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['d', 'ron', 'ed', 'Ġ.', 'Ġlogging', 'Ġ.', 'Ġlog', 'To', 'Dir', 'Ġ(', 'Ġ\\', 'n']
Detokenized (007): ['droned', 'Ġ.', 'Ġlogging', 'Ġ.', 'ĠlogToDir', 'Ġ(', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "conversation . say ( contextSummary , useHTML = False ) \n"
Original    (011): ['conversation', '.', 'say', '(', 'contextSummary', ',', 'useHTML', '=', 'False', ')', '\\n']
Tokenized   (018): ['<s>', 'con', 'vers', 'ation', 'Ġ.', 'Ġsay', 'Ġ(', 'Ġcontext', 'Summary', 'Ġ,', 'Ġuse', 'HTML', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['con', 'vers', 'ation', 'Ġ.', 'Ġsay', 'Ġ(', 'Ġcontext', 'Summary', 'Ġ,', 'Ġuse', 'HTML', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['conversation', 'Ġ.', 'Ġsay', 'Ġ(', 'ĠcontextSummary', 'Ġ,', 'ĠuseHTML', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "moduleProvides ( IDroneDService ) #requirement \n"
Original    (006): ['moduleProvides', '(', 'IDroneDService', ')', '#requirement', '\\n']
Tokenized   (017): ['<s>', 'module', 'Prov', 'ides', 'Ġ(', 'ĠID', 'rone', 'DS', 'erv', 'ice', 'Ġ)', 'Ġ#', 'requ', 'irement', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['module', 'Prov', 'ides', 'Ġ(', 'ĠID', 'rone', 'DS', 'erv', 'ice', 'Ġ)', 'Ġ#', 'requ', 'irement', 'Ġ\\', 'n']
Detokenized (006): ['moduleProvides', 'Ġ(', 'ĠIDroneDService', 'Ġ)', 'Ġ#requirement', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "hour = property ( lambda foo : 3600 ) \n"
Original    (010): ['hour', '=', 'property', '(', 'lambda', 'foo', ':', '3600', ')', '\\n']
Tokenized   (014): ['<s>', 'hour', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġfoo', 'Ġ:', 'Ġ36', '00', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['hour', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġfoo', 'Ġ:', 'Ġ36', '00', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['hour', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġfoo', 'Ġ:', 'Ġ3600', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "watchDict = property ( lambda s : SERVICECONFIG . wrapped . get ( , { } ) ) \n"
Original    (019): ['watchDict', '=', 'property', '(', 'lambda', 's', ':', 'SERVICECONFIG', '.', 'wrapped', '.', 'get', '(', ',', '{', '}', ')', ')', '\\n']
Tokenized   (028): ['<s>', 'watch', 'D', 'ict', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġs', 'Ġ:', 'ĠSERV', 'IC', 'EC', 'ON', 'FIG', 'Ġ.', 'Ġwrapped', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['watch', 'D', 'ict', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġs', 'Ġ:', 'ĠSERV', 'IC', 'EC', 'ON', 'FIG', 'Ġ.', 'Ġwrapped', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['watchDict', 'Ġ=', 'Ġproperty', 'Ġ(', 'Ġlambda', 'Ġs', 'Ġ:', 'ĠSERVICECONFIG', 'Ġ.', 'Ġwrapped', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "model = gm . throat_surface_area . cylinder ) \n"
Original    (009): ['model', '=', 'gm', '.', 'throat_surface_area', '.', 'cylinder', ')', '\\n']
Tokenized   (017): ['<s>', 'model', 'Ġ=', 'Ġg', 'm', 'Ġ.', 'Ġthroat', '_', 'surface', '_', 'area', 'Ġ.', 'Ġcylinder', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['model', 'Ġ=', 'Ġg', 'm', 'Ġ.', 'Ġthroat', '_', 'surface', '_', 'area', 'Ġ.', 'Ġcylinder', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['model', 'Ġ=', 'Ġgm', 'Ġ.', 'Ġthroat_surface_area', 'Ġ.', 'Ġcylinder', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "pores = network . find_connected_pores ( throats , flatten = False ) \n"
Original    (013): ['pores', '=', 'network', '.', 'find_connected_pores', '(', 'throats', ',', 'flatten', '=', 'False', ')', '\\n']
Tokenized   (023): ['<s>', 'p', 'ores', 'Ġ=', 'Ġnetwork', 'Ġ.', 'Ġfind', '_', 'connected', '_', 'p', 'ores', 'Ġ(', 'Ġthroats', 'Ġ,', 'Ġflatt', 'en', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['p', 'ores', 'Ġ=', 'Ġnetwork', 'Ġ.', 'Ġfind', '_', 'connected', '_', 'p', 'ores', 'Ġ(', 'Ġthroats', 'Ġ,', 'Ġflatt', 'en', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['pores', 'Ġ=', 'Ġnetwork', 'Ġ.', 'Ġfind_connected_pores', 'Ġ(', 'Ġthroats', 'Ġ,', 'Ġflatten', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "C0 = network [ ] [ pores , 0 ] \n"
Original    (011): ['C0', '=', 'network', '[', ']', '[', 'pores', ',', '0', ']', '\\n']
Tokenized   (015): ['<s>', 'C', '0', 'Ġ=', 'Ġnetwork', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġpores', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['C', '0', 'Ġ=', 'Ġnetwork', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġpores', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['C0', 'Ġ=', 'Ġnetwork', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġpores', 'Ġ,', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "P = phase [ pore_P ] / 100000 \n"
Original    (009): ['P', '=', 'phase', '[', 'pore_P', ']', '/', '100000', '\\n']
Tokenized   (016): ['<s>', 'P', 'Ġ=', 'Ġphase', 'Ġ[', 'Ġp', 'ore', '_', 'P', 'Ġ]', 'Ġ/', 'Ġ100', '000', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['P', 'Ġ=', 'Ġphase', 'Ġ[', 'Ġp', 'ore', '_', 'P', 'Ġ]', 'Ġ/', 'Ġ100', '000', 'Ġ\\', 'n']
Detokenized (009): ['P', 'Ġ=', 'Ġphase', 'Ġ[', 'Ġpore_P', 'Ġ]', 'Ġ/', 'Ġ100000', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "a1 = - 1 / b \n"
Original    (007): ['a1', '=', '-', '1', '/', 'b', '\\n']
Tokenized   (011): ['<s>', 'a', '1', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ/', 'Ġb', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['a', '1', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ/', 'Ġb', 'Ġ\\', 'n']
Detokenized (007): ['a1', 'Ġ=', 'Ġ-', 'Ġ1', 'Ġ/', 'Ġb', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "a2 = ( R * T + b * P ) / ( a * b ) \n"
Original    (018): ['a2', '=', '(', 'R', '*', 'T', '+', 'b', '*', 'P', ')', '/', '(', 'a', '*', 'b', ')', '\\n']
Tokenized   (022): ['<s>', 'a', '2', 'Ġ=', 'Ġ(', 'ĠR', 'Ġ*', 'ĠT', 'Ġ+', 'Ġb', 'Ġ*', 'ĠP', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['a', '2', 'Ġ=', 'Ġ(', 'ĠR', 'Ġ*', 'ĠT', 'Ġ+', 'Ġb', 'Ġ*', 'ĠP', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['a2', 'Ġ=', 'Ġ(', 'ĠR', 'Ġ*', 'ĠT', 'Ġ+', 'Ġb', 'Ġ*', 'ĠP', 'Ġ)', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "a3 = - P / ( a * b ) \n"
Original    (011): ['a3', '=', '-', 'P', '/', '(', 'a', '*', 'b', ')', '\\n']
Tokenized   (015): ['<s>', 'a', '3', 'Ġ=', 'Ġ-', 'ĠP', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['a', '3', 'Ġ=', 'Ġ-', 'ĠP', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['a3', 'Ġ=', 'Ġ-', 'ĠP', 'Ġ/', 'Ġ(', 'Ġa', 'Ġ*', 'Ġb', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "coeffs = sp . vstack ( ( a0 , a1 , a2 , a3 ) ) . T \n"
Original    (019): ['coeffs', '=', 'sp', '.', 'vstack', '(', '(', 'a0', ',', 'a1', ',', 'a2', ',', 'a3', ')', ')', '.', 'T', '\\n']
Tokenized   (029): ['<s>', 'co', 'eff', 's', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġv', 'stack', 'Ġ(', 'Ġ(', 'Ġa', '0', 'Ġ,', 'Ġa', '1', 'Ġ,', 'Ġa', '2', 'Ġ,', 'Ġa', '3', 'Ġ)', 'Ġ)', 'Ġ.', 'ĠT', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['co', 'eff', 's', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġv', 'stack', 'Ġ(', 'Ġ(', 'Ġa', '0', 'Ġ,', 'Ġa', '1', 'Ġ,', 'Ġa', '2', 'Ġ,', 'Ġa', '3', 'Ġ)', 'Ġ)', 'Ġ.', 'ĠT', 'Ġ\\', 'n']
Detokenized (019): ['coeffs', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġvstack', 'Ġ(', 'Ġ(', 'Ġa0', 'Ġ,', 'Ġa1', 'Ġ,', 'Ġa2', 'Ġ,', 'Ġa3', 'Ġ)', 'Ġ)', 'Ġ.', 'ĠT', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "density = sp . array ( [ sp . roots ( C ) for C in coeffs ] ) \n"
Original    (020): ['density', '=', 'sp', '.', 'array', '(', '[', 'sp', '.', 'roots', '(', 'C', ')', 'for', 'C', 'in', 'coeffs', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'density', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġsp', 'Ġ.', 'Ġroots', 'Ġ(', 'ĠC', 'Ġ)', 'Ġfor', 'ĠC', 'Ġin', 'Ġco', 'eff', 's', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['density', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġsp', 'Ġ.', 'Ġroots', 'Ġ(', 'ĠC', 'Ġ)', 'Ġfor', 'ĠC', 'Ġin', 'Ġco', 'eff', 's', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['density', 'Ġ=', 'Ġsp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġsp', 'Ġ.', 'Ġroots', 'Ġ(', 'ĠC', 'Ġ)', 'Ġfor', 'ĠC', 'Ġin', 'Ġcoeffs', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "comp2 = OpenPNM . Phases . GenericPhase ( network = self . net ) \n"
Original    (015): ['comp2', '=', 'OpenPNM', '.', 'Phases', '.', 'GenericPhase', '(', 'network', '=', 'self', '.', 'net', ')', '\\n']
Tokenized   (023): ['<s>', 'comp', '2', 'Ġ=', 'ĠOpen', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['comp', '2', 'Ġ=', 'ĠOpen', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['comp2', 'Ġ=', 'ĠOpenPNM', 'Ġ.', 'ĠPhases', 'Ġ.', 'ĠGenericPhase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "OpenPNM . Phases . GenericPhase ( network = self . net , \n"
Original    (013): ['OpenPNM', '.', 'Phases', '.', 'GenericPhase', '(', 'network', '=', 'self', '.', 'net', ',', '\\n']
Tokenized   (020): ['<s>', 'Open', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['Open', 'PN', 'M', 'Ġ.', 'ĠPh', 'ases', 'Ġ.', 'ĠGeneric', 'Phase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['OpenPNM', 'Ġ.', 'ĠPhases', 'Ġ.', 'ĠGenericPhase', 'Ġ(', 'Ġnetwork', 'Ġ=', 'Ġself', 'Ġ.', 'Ġnet', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "components = [ comp1 , comp2 ] ) \n"
Original    (009): ['components', '=', '[', 'comp1', ',', 'comp2', ']', ')', '\\n']
Tokenized   (015): ['<s>', 'comp', 'onents', 'Ġ=', 'Ġ[', 'Ġcomp', '1', 'Ġ,', 'Ġcomp', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['comp', 'onents', 'Ġ=', 'Ġ[', 'Ġcomp', '1', 'Ġ,', 'Ġcomp', '2', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['components', 'Ġ=', 'Ġ[', 'Ġcomp1', 'Ġ,', 'Ġcomp2', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "phase . set_component ( comp2 , mode = ) \n"
Original    (010): ['phase', '.', 'set_component', '(', 'comp2', ',', 'mode', '=', ')', '\\n']
Tokenized   (016): ['<s>', 'phase', 'Ġ.', 'Ġset', '_', 'component', 'Ġ(', 'Ġcomp', '2', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['phase', 'Ġ.', 'Ġset', '_', 'component', 'Ġ(', 'Ġcomp', '2', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['phase', 'Ġ.', 'Ġset_component', 'Ġ(', 'Ġcomp2', 'Ġ,', 'Ġmode', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "best_seq = fd [ x ] . sequence \n"
Original    (009): ['best_seq', '=', 'fd', '[', 'x', ']', '.', 'sequence', '\\n']
Tokenized   (015): ['<s>', 'best', '_', 'seq', 'Ġ=', 'Ġf', 'd', 'Ġ[', 'Ġx', 'Ġ]', 'Ġ.', 'Ġsequence', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['best', '_', 'seq', 'Ġ=', 'Ġf', 'd', 'Ġ[', 'Ġx', 'Ġ]', 'Ġ.', 'Ġsequence', 'Ġ\\', 'n']
Detokenized (009): ['best_seq', 'Ġ=', 'Ġfd', 'Ġ[', 'Ġx', 'Ġ]', 'Ġ.', 'Ġsequence', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "best_id , best_seq , best_qual = rep_info [ pb_id ] \n"
Original    (011): ['best_id', ',', 'best_seq', ',', 'best_qual', '=', 'rep_info', '[', 'pb_id', ']', '\\n']
Tokenized   (025): ['<s>', 'best', '_', 'id', 'Ġ,', 'Ġbest', '_', 'seq', 'Ġ,', 'Ġbest', '_', 'qual', 'Ġ=', 'Ġrep', '_', 'info', 'Ġ[', 'Ġp', 'b', '_', 'id', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['best', '_', 'id', 'Ġ,', 'Ġbest', '_', 'seq', 'Ġ,', 'Ġbest', '_', 'qual', 'Ġ=', 'Ġrep', '_', 'info', 'Ġ[', 'Ġp', 'b', '_', 'id', 'Ġ]', 'Ġ\\', 'n']
Detokenized (011): ['best_id', 'Ġ,', 'Ġbest_seq', 'Ġ,', 'Ġbest_qual', 'Ġ=', 'Ġrep_info', 'Ġ[', 'Ġpb_id', 'Ġ]', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_id_ = "{0}|{1}|{2}" . format ( pb_id , coords [ best_id ] , best_id ) \n"
Original    (016): ['_id_', '=', '"{0}|{1}|{2}"', '.', 'format', '(', 'pb_id', ',', 'coords', '[', 'best_id', ']', ',', 'best_id', ')', '\\n']
Tokenized   (039): ['<s>', '_', 'id', '_', 'Ġ=', 'Ġ"{', '0', '}', '|', '{', '1', '}', '|', '{', '2', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'b', '_', 'id', 'Ġ,', 'Ġco', 'ords', 'Ġ[', 'Ġbest', '_', 'id', 'Ġ]', 'Ġ,', 'Ġbest', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['_', 'id', '_', 'Ġ=', 'Ġ"{', '0', '}', '|', '{', '1', '}', '|', '{', '2', '}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'b', '_', 'id', 'Ġ,', 'Ġco', 'ords', 'Ġ[', 'Ġbest', '_', 'id', 'Ġ]', 'Ġ,', 'Ġbest', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['_id_', 'Ġ=', 'Ġ"{0}|{1}|{2}"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpb_id', 'Ġ,', 'Ġcoords', 'Ġ[', 'Ġbest_id', 'Ġ]', 'Ġ,', 'Ġbest_id', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "iter = BioReaders . GMAPSAMReader ( gmap_sam_filename , True , query_len_dict = transfrag_len_dict ) \n"
Original    (015): ['iter', '=', 'BioReaders', '.', 'GMAPSAMReader', '(', 'gmap_sam_filename', ',', 'True', ',', 'query_len_dict', '=', 'transfrag_len_dict', ')', '\\n']
Tokenized   (038): ['<s>', 'iter', 'Ġ=', 'ĠBio', 'Read', 'ers', 'Ġ.', 'ĠGM', 'APS', 'AM', 'Reader', 'Ġ(', 'Ġg', 'map', '_', 'sam', '_', 'filename', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġquery', '_', 'len', '_', 'dict', 'Ġ=', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['iter', 'Ġ=', 'ĠBio', 'Read', 'ers', 'Ġ.', 'ĠGM', 'APS', 'AM', 'Reader', 'Ġ(', 'Ġg', 'map', '_', 'sam', '_', 'filename', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġquery', '_', 'len', '_', 'dict', 'Ġ=', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['iter', 'Ġ=', 'ĠBioReaders', 'Ġ.', 'ĠGMAPSAMReader', 'Ġ(', 'Ġgmap_sam_filename', 'Ġ,', 'ĠTrue', 'Ġ,', 'Ġquery_len_dict', 'Ġ=', 'Ġtransfrag_len_dict', 'Ġ)', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "TmpRec = namedtuple ( , [ , , , , , , ] ) \n"
Original    (015): ['TmpRec', '=', 'namedtuple', '(', ',', '[', ',', ',', ',', ',', ',', ',', ']', ')', '\\n']
Tokenized   (022): ['<s>', 'T', 'mp', 'Rec', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['T', 'mp', 'Rec', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['TmpRec', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "compressed_records_pointer_dict = defaultdict ( lambda : [ ] ) \n"
Original    (010): ['compressed_records_pointer_dict', '=', 'defaultdict', '(', 'lambda', ':', '[', ']', ')', '\\n']
Tokenized   (022): ['<s>', 'comp', 'ressed', '_', 'rec', 'ords', '_', 'pointer', '_', 'dict', 'Ġ=', 'Ġdefault', 'dict', 'Ġ(', 'Ġlambda', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['comp', 'ressed', '_', 'rec', 'ords', '_', 'pointer', '_', 'dict', 'Ġ=', 'Ġdefault', 'dict', 'Ġ(', 'Ġlambda', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['compressed_records_pointer_dict', 'Ġ=', 'Ġdefaultdict', 'Ġ(', 'Ġlambda', 'Ġ:', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "check_ids_unique ( fa_or_fq_filename , is_fq = is_fq ) \n"
Original    (009): ['check_ids_unique', '(', 'fa_or_fq_filename', ',', 'is_fq', '=', 'is_fq', ')', '\\n']
Tokenized   (029): ['<s>', 'check', '_', 'ids', '_', 'unique', 'Ġ(', 'Ġfa', '_', 'or', '_', 'f', 'q', '_', 'filename', 'Ġ,', 'Ġis', '_', 'f', 'q', 'Ġ=', 'Ġis', '_', 'f', 'q', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['check', '_', 'ids', '_', 'unique', 'Ġ(', 'Ġfa', '_', 'or', '_', 'f', 'q', '_', 'filename', 'Ġ,', 'Ġis', '_', 'f', 'q', 'Ġ=', 'Ġis', '_', 'f', 'q', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['check_ids_unique', 'Ġ(', 'Ġfa_or_fq_filename', 'Ġ,', 'Ġis_fq', 'Ġ=', 'Ġis_fq', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "fusion_candidates = find_fusion_candidates ( sam_filename , bs . transfrag_len_dict , min_locus_coverage \n"
Original    (012): ['fusion_candidates', '=', 'find_fusion_candidates', '(', 'sam_filename', ',', 'bs', '.', 'transfrag_len_dict', ',', 'min_locus_coverage', '\\n']
Tokenized   (040): ['<s>', 'f', 'usion', '_', 'cand', 'idates', 'Ġ=', 'Ġfind', '_', 'f', 'usion', '_', 'cand', 'idates', 'Ġ(', 'Ġsam', '_', 'filename', 'Ġ,', 'Ġb', 's', 'Ġ.', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['f', 'usion', '_', 'cand', 'idates', 'Ġ=', 'Ġfind', '_', 'f', 'usion', '_', 'cand', 'idates', 'Ġ(', 'Ġsam', '_', 'filename', 'Ġ,', 'Ġb', 's', 'Ġ.', 'Ġtrans', 'fr', 'ag', '_', 'len', '_', 'dict', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ\\', 'n']
Detokenized (012): ['fusion_candidates', 'Ġ=', 'Ġfind_fusion_candidates', 'Ġ(', 'Ġsam_filename', 'Ġ,', 'Ġbs', 'Ġ.', 'Ġtransfrag_len_dict', 'Ġ,', 'Ġmin_locus_coverage', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "pbid1 , groups1 = line . strip ( ) . split ( ) \n"
Original    (014): ['pbid1', ',', 'groups1', '=', 'line', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (020): ['<s>', 'p', 'bid', '1', 'Ġ,', 'Ġgroups', '1', 'Ġ=', 'Ġline', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['p', 'bid', '1', 'Ġ,', 'Ġgroups', '1', 'Ġ=', 'Ġline', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['pbid1', 'Ġ,', 'Ġgroups1', 'Ġ=', 'Ġline', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pbid2 , groups2 = f . readline ( ) . strip ( ) . split ( ) \n"
Original    (018): ['pbid2', ',', 'groups2', '=', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (025): ['<s>', 'p', 'bid', '2', 'Ġ,', 'Ġgroups', '2', 'Ġ=', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['p', 'bid', '2', 'Ġ,', 'Ġgroups', '2', 'Ġ=', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['pbid2', 'Ġ,', 'Ġgroups2', 'Ġ=', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "f_group . write ( "{0}\\t{1}\\n" . format ( pbid1 [ : pbid1 . rfind ( ) ] , "," . join ( group ) ) ) \n"
Original    (027): ['f_group', '.', 'write', '(', '"{0}\\\\t{1}\\\\n"', '.', 'format', '(', 'pbid1', '[', ':', 'pbid1', '.', 'rfind', '(', ')', ']', ',', '","', '.', 'join', '(', 'group', ')', ')', ')', '\\n']
Tokenized   (048): ['<s>', 'f', '_', 'group', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"{', '0', '}', '\\\\', 't', '{', '1', '}', '\\\\', 'n', '"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ"', ',"', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (046): ['f', '_', 'group', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"{', '0', '}', '\\\\', 't', '{', '1', '}', '\\\\', 'n', '"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ"', ',"', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['f_group', 'Ġ.', 'Ġwrite', 'Ġ(', 'Ġ"{0}\\\\t{1}\\\\n"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġpbid1', 'Ġ[', 'Ġ:', 'Ġpbid1', 'Ġ.', 'Ġrfind', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ","', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 46
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "group_info [ pbid1 [ : pbid1 . rfind ( ) ] ] = list ( group ) \n"
Original    (018): ['group_info', '[', 'pbid1', '[', ':', 'pbid1', '.', 'rfind', '(', ')', ']', ']', '=', 'list', '(', 'group', ')', '\\n']
Tokenized   (028): ['<s>', 'group', '_', 'info', 'Ġ[', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ]', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['group', '_', 'info', 'Ġ[', 'Ġp', 'bid', '1', 'Ġ[', 'Ġ:', 'Ġp', 'bid', '1', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ]', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['group_info', 'Ġ[', 'Ġpbid1', 'Ġ[', 'Ġ:', 'Ġpbid1', 'Ġ.', 'Ġrfind', 'Ġ(', 'Ġ)', 'Ġ]', 'Ġ]', 'Ġ=', 'Ġlist', 'Ġ(', 'Ġgroup', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "d1 . update ( d [ ] ) \n"
Original    (009): ['d1', '.', 'update', '(', 'd', '[', ']', ')', '\\n']
Tokenized   (013): ['<s>', 'd', '1', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġd', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['d', '1', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġd', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['d1', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġd', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "fusion_main ( args . input , args . sam , args . prefix , \n"
Original    (015): ['fusion_main', '(', 'args', '.', 'input', ',', 'args', '.', 'sam', ',', 'args', '.', 'prefix', ',', '\\n']
Tokenized   (021): ['<s>', 'f', 'usion', '_', 'main', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġinput', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġsam', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['f', 'usion', '_', 'main', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġinput', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġsam', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['fusion_main', 'Ġ(', 'Ġargs', 'Ġ.', 'Ġinput', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġsam', 'Ġ,', 'Ġargs', 'Ġ.', 'Ġprefix', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "is_fq = args . fq , allow_extra_5_exons = args . allow_extra_5exon , \n"
Original    (013): ['is_fq', '=', 'args', '.', 'fq', ',', 'allow_extra_5_exons', '=', 'args', '.', 'allow_extra_5exon', ',', '\\n']
Tokenized   (033): ['<s>', 'is', '_', 'f', 'q', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġf', 'q', 'Ġ,', 'Ġallow', '_', 'extra', '_', '5', '_', 'ex', 'ons', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġallow', '_', 'extra', '_', '5', 'ex', 'on', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['is', '_', 'f', 'q', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġf', 'q', 'Ġ,', 'Ġallow', '_', 'extra', '_', '5', '_', 'ex', 'ons', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġallow', '_', 'extra', '_', '5', 'ex', 'on', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['is_fq', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġfq', 'Ġ,', 'Ġallow_extra_5_exons', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġallow_extra_5exon', 'Ġ,', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "skip_5_exon_alt = False , prefix_dict_pickle_filename = args . prefix_dict_pickle_filename , min_locus_coverage = args . min_locus_coverage , min_locus_coverage_bp = args . min_locus_coverage_bp min_total_coverage = args . min_total_coverage , \n"
Original    (028): ['skip_5_exon_alt', '=', 'False', ',', 'prefix_dict_pickle_filename', '=', 'args', '.', 'prefix_dict_pickle_filename', ',', 'min_locus_coverage', '=', 'args', '.', 'min_locus_coverage', ',', 'min_locus_coverage_bp', '=', 'args', '.', 'min_locus_coverage_bp', 'min_total_coverage', '=', 'args', '.', 'min_total_coverage', ',', '\\n']
Tokenized   (090): ['<s>', 'skip', '_', '5', '_', 'ex', 'on', '_', 'alt', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (088): ['skip', '_', '5', '_', 'ex', 'on', '_', 'alt', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġprefix', '_', 'dict', '_', 'pick', 'le', '_', 'filename', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', 'Ġ,', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'l', 'ocus', '_', 'co', 'verage', '_', 'bp', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin', '_', 'total', '_', 'co', 'verage', 'Ġ,', 'Ġ\\', 'n']
Detokenized (028): ['skip_5_exon_alt', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġprefix_dict_pickle_filename', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġprefix_dict_pickle_filename', 'Ġ,', 'Ġmin_locus_coverage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin_locus_coverage', 'Ġ,', 'Ġmin_locus_coverage_bp', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin_locus_coverage_bp', 'Ġmin_total_coverage', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġmin_total_coverage', 'Ġ,', 'Ġ\\n']
Counter: 88
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "raw = self . f . readline ( ) . strip ( ) . split ( ) \n"
Original    (018): ['raw', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (022): ['<s>', 'raw', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['raw', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['raw', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "iden = float ( raw [ 3 ] ) \n"
Original    (010): ['iden', '=', 'float', '(', 'raw', '[', '3', ']', ')', '\\n']
Tokenized   (013): ['<s>', 'iden', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġraw', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['iden', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġraw', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['iden', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġraw', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "_qStart , qAln = self . f . readline ( ) . strip ( ) . split ( ) \n"
Original    (020): ['_qStart', ',', 'qAln', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '\\n']
Tokenized   (028): ['<s>', '_', 'q', 'Start', 'Ġ,', 'Ġq', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['_', 'q', 'Start', 'Ġ,', 'Ġq', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['_qStart', 'Ġ,', 'ĠqAln', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "_sStart , sAln = self . f . readline ( ) . strip ( ) . split ( ) [ : 2 ] \n"
Original    (024): ['_sStart', ',', 'sAln', '=', 'self', '.', 'f', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '.', 'split', '(', ')', '[', ':', '2', ']', '\\n']
Tokenized   (032): ['<s>', '_', 's', 'Start', 'Ġ,', 'Ġs', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['_', 's', 'Start', 'Ġ,', 'Ġs', 'Al', 'n', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (024): ['_sStart', 'Ġ,', 'ĠsAln', 'Ġ=', 'Ġself', 'Ġ.', 'Ġf', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "missed_q = missed_q * 1. / r . qLength , \n"
Original    (011): ['missed_q', '=', 'missed_q', '*', '1.', '/', 'r', '.', 'qLength', ',', '\\n']
Tokenized   (021): ['<s>', 'miss', 'ed', '_', 'q', 'Ġ=', 'Ġmissed', '_', 'q', 'Ġ*', 'Ġ1', '.', 'Ġ/', 'Ġr', 'Ġ.', 'Ġq', 'Length', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['miss', 'ed', '_', 'q', 'Ġ=', 'Ġmissed', '_', 'q', 'Ġ*', 'Ġ1', '.', 'Ġ/', 'Ġr', 'Ġ.', 'Ġq', 'Length', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['missed_q', 'Ġ=', 'Ġmissed_q', 'Ġ*', 'Ġ1.', 'Ġ/', 'Ġr', 'Ġ.', 'ĠqLength', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "ece_penalty , ece_min_len ) : \n"
Original    (006): ['ece_penalty', ',', 'ece_min_len', ')', ':', '\\n']
Tokenized   (018): ['<s>', 'e', 'ce', '_', 'pen', 'alty', 'Ġ,', 'Ġe', 'ce', '_', 'min', '_', 'len', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['e', 'ce', '_', 'pen', 'alty', 'Ġ,', 'Ġe', 'ce', '_', 'min', '_', 'len', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['ece_penalty', 'Ġ,', 'Ġece_min_len', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "heading = % ( current_indent , , self . heading ) \n"
Original    (012): ['heading', '=', '%', '(', 'current_indent', ',', ',', 'self', '.', 'heading', ')', '\\n']
Tokenized   (018): ['<s>', 'heading', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġcurrent', '_', 'ind', 'ent', 'Ġ,', 'Ġ,', 'Ġself', 'Ġ.', 'Ġheading', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['heading', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġcurrent', '_', 'ind', 'ent', 'Ġ,', 'Ġ,', 'Ġself', 'Ġ.', 'Ġheading', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['heading', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġcurrent_indent', 'Ġ,', 'Ġ,', 'Ġself', 'Ġ.', 'Ġheading', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "section = self . _Section ( self , self . _current_section , heading ) \n"
Original    (015): ['section', '=', 'self', '.', '_Section', '(', 'self', ',', 'self', '.', '_current_section', ',', 'heading', ')', '\\n']
Tokenized   (022): ['<s>', 'section', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'Section', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'section', 'Ġ,', 'Ġheading', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['section', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'Section', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'section', 'Ġ,', 'Ġheading', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['section', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_Section', 'Ġ(', 'Ġself', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_current_section', 'Ġ,', 'Ġheading', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "invocations = [ get_invocation ( action ) ] \n"
Original    (009): ['invocations', '=', '[', 'get_invocation', '(', 'action', ')', ']', '\\n']
Tokenized   (016): ['<s>', 'inv', 'ocations', 'Ġ=', 'Ġ[', 'Ġget', '_', 'inv', 'ocation', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['inv', 'ocations', 'Ġ=', 'Ġ[', 'Ġget', '_', 'inv', 'ocation', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['invocations', 'Ġ=', 'Ġ[', 'Ġget_invocation', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "action_usage = format ( optionals + positionals , groups ) \n"
Original    (011): ['action_usage', '=', 'format', '(', 'optionals', '+', 'positionals', ',', 'groups', ')', '\\n']
Tokenized   (018): ['<s>', 'action', '_', 'usage', 'Ġ=', 'Ġformat', 'Ġ(', 'Ġoption', 'als', 'Ġ+', 'Ġposition', 'als', 'Ġ,', 'Ġgroups', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['action', '_', 'usage', 'Ġ=', 'Ġformat', 'Ġ(', 'Ġoption', 'als', 'Ġ+', 'Ġposition', 'als', 'Ġ,', 'Ġgroups', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['action_usage', 'Ġ=', 'Ġformat', 'Ġ(', 'Ġoptionals', 'Ġ+', 'Ġpositionals', 'Ġ,', 'Ġgroups', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "text_width = self . _width - self . _current_indent \n"
Original    (010): ['text_width', '=', 'self', '.', '_width', '-', 'self', '.', '_current_indent', '\\n']
Tokenized   (020): ['<s>', 'text', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['text', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n']
Detokenized (010): ['text_width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_width', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_current_indent', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "line_len += len ( part ) + 1 \n"
Original    (009): ['line_len', '+=', 'len', '(', 'part', ')', '+', '1', '\\n']
Tokenized   (014): ['<s>', 'line', '_', 'len', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġpart', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['line', '_', 'len', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġpart', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (009): ['line_len', 'Ġ+=', 'Ġlen', 'Ġ(', 'Ġpart', 'Ġ)', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "part = % ( option_string , args_string ) \n"
Original    (009): ['part', '=', '%', '(', 'option_string', ',', 'args_string', ')', '\\n']
Tokenized   (016): ['<s>', 'part', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġoption', '_', 'string', 'Ġ,', 'Ġargs', '_', 'string', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['part', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġoption', '_', 'string', 'Ġ,', 'Ġargs', '_', 'string', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['part', 'Ġ=', 'Ġ%', 'Ġ(', 'Ġoption_string', 'Ġ,', 'Ġargs_string', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "indent = * self . _current_indent \n"
Original    (007): ['indent', '=', '*', 'self', '.', '_current_indent', '\\n']
Tokenized   (015): ['<s>', 'ind', 'ent', 'Ġ=', 'Ġ*', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['ind', 'ent', 'Ġ=', 'Ġ*', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ\\', 'n']
Detokenized (007): ['indent', 'Ġ=', 'Ġ*', 'Ġself', 'Ġ.', 'Ġ_current_indent', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "help_width = self . _width - help_position \n"
Original    (008): ['help_width', '=', 'self', '.', '_width', '-', 'help_position', '\\n']
Tokenized   (016): ['<s>', 'help', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġhelp', '_', 'position', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['help', '_', 'width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'width', 'Ġ-', 'Ġhelp', '_', 'position', 'Ġ\\', 'n']
Detokenized (008): ['help_width', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_width', 'Ġ-', 'Ġhelp_position', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "action_width = help_position - self . _current_indent - 2 \n"
Original    (010): ['action_width', '=', 'help_position', '-', 'self', '.', '_current_indent', '-', '2', '\\n']
Tokenized   (021): ['<s>', 'action', '_', 'width', 'Ġ=', 'Ġhelp', '_', 'position', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ-', 'Ġ2', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['action', '_', 'width', 'Ġ=', 'Ġhelp', '_', 'position', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_', 'current', '_', 'ind', 'ent', 'Ġ-', 'Ġ2', 'Ġ\\', 'n']
Detokenized (010): ['action_width', 'Ġ=', 'Ġhelp_position', 'Ġ-', 'Ġself', 'Ġ.', 'Ġ_current_indent', 'Ġ-', 'Ġ2', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "sup . __init__ ( option_strings = [ ] , dest = name , help = help ) \n"
Original    (018): ['sup', '.', '__init__', '(', 'option_strings', '=', '[', ']', ',', 'dest', '=', 'name', ',', 'help', '=', 'help', ')', '\\n']
Tokenized   (025): ['<s>', 'sup', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġoption', '_', 'strings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġname', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġhelp', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['sup', 'Ġ.', 'Ġ__', 'init', '__', 'Ġ(', 'Ġoption', '_', 'strings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġname', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġhelp', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['sup', 'Ġ.', 'Ġ__init__', 'Ġ(', 'Ġoption_strings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġname', 'Ġ,', 'Ġhelp', 'Ġ=', 'Ġhelp', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "arg_strings = values [ 1 : ] \n"
Original    (008): ['arg_strings', '=', 'values', '[', '1', ':', ']', '\\n']
Tokenized   (013): ['<s>', 'arg', '_', 'strings', 'Ġ=', 'Ġvalues', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['arg', '_', 'strings', 'Ġ=', 'Ġvalues', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['arg_strings', 'Ġ=', 'Ġvalues', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "args_str = . join ( [ repr ( arg ) for arg in args if arg is not None ] ) \n"
Original    (022): ['args_str', '=', '.', 'join', '(', '[', 'repr', '(', 'arg', ')', 'for', 'arg', 'in', 'args', 'if', 'arg', 'is', 'not', 'None', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'args', '_', 'str', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġfor', 'Ġarg', 'Ġin', 'Ġargs', 'Ġif', 'Ġarg', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['args', '_', 'str', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġfor', 'Ġarg', 'Ġin', 'Ġargs', 'Ġif', 'Ġarg', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['args_str', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġrepr', 'Ġ(', 'Ġarg', 'Ġ)', 'Ġfor', 'Ġarg', 'Ġin', 'Ġargs', 'Ġif', 'Ġarg', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "type_func = self . _registry_get ( , action . type , action . type ) \n"
Original    (016): ['type_func', '=', 'self', '.', '_registry_get', '(', ',', 'action', '.', 'type', ',', 'action', '.', 'type', ')', '\\n']
Tokenized   (025): ['<s>', 'type', '_', 'func', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'reg', 'istry', '_', 'get', 'Ġ(', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['type', '_', 'func', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'reg', 'istry', '_', 'get', 'Ġ(', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['type_func', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_registry_get', 'Ġ(', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ,', 'Ġaction', 'Ġ.', 'Ġtype', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "conflict_string = . join ( [ option_string \n"
Original    (008): ['conflict_string', '=', '.', 'join', '(', '[', 'option_string', '\\n']
Tokenized   (016): ['<s>', 'conf', 'lict', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġoption', '_', 'string', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['conf', 'lict', '_', 'string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġoption', '_', 'string', 'Ġ\\', 'n']
Detokenized (008): ['conflict_string', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġoption_string', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "in conflicting_actions ] ) \n"
Original    (005): ['in', 'conflicting_actions', ']', ')', '\\n']
Tokenized   (010): ['<s>', 'in', 'Ġconflicting', '_', 'actions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['in', 'Ġconflicting', '_', 'actions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['in', 'Ġconflicting_actions', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "super_init ( description = description , ** kwargs ) \n"
Original    (010): ['super_init', '(', 'description', '=', 'description', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (017): ['<s>', 'super', '_', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['super', '_', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['super_init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : """"instead""" , DeprecationWarning ) \n"
Original    (005): ['"""instead"""', ',', 'DeprecationWarning', ')', '\\n']
Tokenized   (013): ['<s>', '"""', 'instead', '"""', 'Ġ,', 'ĠDep', 'rec', 'ation', 'Warning', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['"""', 'instead', '"""', 'Ġ,', 'ĠDep', 'rec', 'ation', 'Warning', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['"""instead"""', 'Ġ,', 'ĠDeprecationWarning', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "superinit ( description = description , \n"
Original    (007): ['superinit', '(', 'description', '=', 'description', ',', '\\n']
Tokenized   (011): ['<s>', 'super', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['super', 'init', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['superinit', 'Ġ(', 'Ġdescription', 'Ġ=', 'Ġdescription', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "default_prefix + , default_prefix * 2 + , \n"
Original    (009): ['default_prefix', '+', ',', 'default_prefix', '*', '2', '+', ',', '\\n']
Tokenized   (016): ['<s>', 'default', '_', 'prefix', 'Ġ+', 'Ġ,', 'Ġdefault', '_', 'prefix', 'Ġ*', 'Ġ2', 'Ġ+', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['default', '_', 'prefix', 'Ġ+', 'Ġ,', 'Ġdefault', '_', 'prefix', 'Ġ*', 'Ġ2', 'Ġ+', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['default_prefix', 'Ġ+', 'Ġ,', 'Ġdefault_prefix', 'Ġ*', 'Ġ2', 'Ġ+', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "conflicts . extend ( group_actions [ i + 1 : ] ) \n"
Original    (013): ['conflicts', '.', 'extend', '(', 'group_actions', '[', 'i', '+', '1', ':', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'conf', 'licts', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgroup', '_', 'actions', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['conf', 'licts', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgroup', '_', 'actions', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['conflicts', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġgroup_actions', 'Ġ[', 'Ġi', 'Ġ+', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "action , option_string , explicit_arg = option_tuple \n"
Original    (008): ['action', ',', 'option_string', ',', 'explicit_arg', '=', 'option_tuple', '\\n']
Tokenized   (018): ['<s>', 'action', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġexplicit', '_', 'arg', 'Ġ=', 'Ġoption', '_', 't', 'uple', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['action', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġexplicit', '_', 'arg', 'Ġ=', 'Ġoption', '_', 't', 'uple', 'Ġ\\', 'n']
Detokenized (008): ['action', 'Ġ,', 'Ġoption_string', 'Ġ,', 'Ġexplicit_arg', 'Ġ=', 'Ġoption_tuple', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "option_string = char + explicit_arg [ 0 ] \n"
Original    (009): ['option_string', '=', 'char', '+', 'explicit_arg', '[', '0', ']', '\\n']
Tokenized   (016): ['<s>', 'option', '_', 'string', 'Ġ=', 'Ġchar', 'Ġ+', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['option', '_', 'string', 'Ġ=', 'Ġchar', 'Ġ+', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (009): ['option_string', 'Ġ=', 'Ġchar', 'Ġ+', 'Ġexplicit_arg', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "new_explicit_arg = explicit_arg [ 1 : ] or None \n"
Original    (010): ['new_explicit_arg', '=', 'explicit_arg', '[', '1', ':', ']', 'or', 'None', '\\n']
Tokenized   (020): ['<s>', 'new', '_', 'expl', 'icit', '_', 'arg', 'Ġ=', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['new', '_', 'expl', 'icit', '_', 'arg', 'Ġ=', 'Ġexplicit', '_', 'arg', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n']
Detokenized (010): ['new_explicit_arg', 'Ġ=', 'Ġexplicit_arg', 'Ġ[', 'Ġ1', 'Ġ:', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "action_tuples . append ( ( action , args , option_string ) ) \n"
Original    (013): ['action_tuples', '.', 'append', '(', '(', 'action', ',', 'args', ',', 'option_string', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'action', '_', 'tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġaction', 'Ġ,', 'Ġargs', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['action', '_', 'tu', 'ples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġaction', 'Ġ,', 'Ġargs', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['action_tuples', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ(', 'Ġaction', 'Ġ,', 'Ġargs', 'Ġ,', 'Ġoption_string', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "selected_patterns = arg_strings_pattern [ start : ] \n"
Original    (008): ['selected_patterns', '=', 'arg_strings_pattern', '[', 'start', ':', ']', '\\n']
Tokenized   (018): ['<s>', 'selected', '_', 'pattern', 's', 'Ġ=', 'Ġarg', '_', 'strings', '_', 'pattern', 'Ġ[', 'Ġstart', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['selected', '_', 'pattern', 's', 'Ġ=', 'Ġarg', '_', 'strings', '_', 'pattern', 'Ġ[', 'Ġstart', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['selected_patterns', 'Ġ=', 'Ġarg_strings_pattern', 'Ġ[', 'Ġstart', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "extras . extend ( arg_strings [ stop_index : ] ) \n"
Original    (011): ['extras', '.', 'extend', '(', 'arg_strings', '[', 'stop_index', ':', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'ext', 'ras', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġarg', '_', 'strings', 'Ġ[', 'Ġstop', '_', 'index', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['ext', 'ras', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġarg', '_', 'strings', 'Ġ[', 'Ġstop', '_', 'index', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['extras', 'Ġ.', 'Ġextend', 'Ġ(', 'Ġarg_strings', 'Ġ[', 'Ġstop_index', 'Ġ:', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "OPTIONAL : _ ( ) , \n"
Original    (007): ['OPTIONAL', ':', '_', '(', ')', ',', '\\n']
Tokenized   (012): ['<s>', 'OP', 'TION', 'AL', 'Ġ:', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['OP', 'TION', 'AL', 'Ġ:', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['OPTIONAL', 'Ġ:', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "pattern = . join ( [ self . _get_nargs_pattern ( action ) \n"
Original    (013): ['pattern', '=', '.', 'join', '(', '[', 'self', '.', '_get_nargs_pattern', '(', 'action', ')', '\\n']
Tokenized   (022): ['<s>', 'pattern', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'n', 'args', '_', 'pattern', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['pattern', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 'get', '_', 'n', 'args', '_', 'pattern', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['pattern', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_get_nargs_pattern', 'Ġ(', 'Ġaction', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "short_option_prefix = option_string [ : 2 ] \n"
Original    (008): ['short_option_prefix', '=', 'option_string', '[', ':', '2', ']', '\\n']
Tokenized   (017): ['<s>', 'short', '_', 'option', '_', 'prefix', 'Ġ=', 'Ġoption', '_', 'string', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['short', '_', 'option', '_', 'prefix', 'Ġ=', 'Ġoption', '_', 'string', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['short_option_prefix', 'Ġ=', 'Ġoption_string', 'Ġ[', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "tup = action , option_string , short_explicit_arg \n"
Original    (008): ['tup', '=', 'action', ',', 'option_string', ',', 'short_explicit_arg', '\\n']
Tokenized   (019): ['<s>', 't', 'up', 'Ġ=', 'Ġaction', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġshort', '_', 'expl', 'icit', '_', 'arg', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['t', 'up', 'Ġ=', 'Ġaction', 'Ġ,', 'Ġoption', '_', 'string', 'Ġ,', 'Ġshort', '_', 'expl', 'icit', '_', 'arg', 'Ġ\\', 'n']
Detokenized (008): ['tup', 'Ġ=', 'Ġaction', 'Ġ,', 'Ġoption_string', 'Ġ,', 'Ġshort_explicit_arg', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "not action . option_strings ) : \n"
Original    (007): ['not', 'action', '.', 'option_strings', ')', ':', '\\n']
Tokenized   (012): ['<s>', 'not', 'Ġaction', 'Ġ.', 'Ġoption', '_', 'strings', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['not', 'Ġaction', 'Ġ.', 'Ġoption', '_', 'strings', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (007): ['not', 'Ġaction', 'Ġ.', 'Ġoption_strings', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "vulnerability = obj [ ] [ ] [ ] [ ] [ ] \n"
Original    (014): ['vulnerability', '=', 'obj', '[', ']', '[', ']', '[', ']', '[', ']', '[', ']', '\\n']
Tokenized   (018): ['<s>', 'v', 'ulnerability', 'Ġ=', 'Ġobj', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['v', 'ulnerability', 'Ġ=', 'Ġobj', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['vulnerability', 'Ġ=', 'Ġobj', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "apikey = common . apikey ( sessionKey , args [ 0 ] , debug ) \n"
Original    (016): ['apikey', '=', 'common', '.', 'apikey', '(', 'sessionKey', ',', 'args', '[', '0', ']', ',', 'debug', ')', '\\n']
Tokenized   (024): ['<s>', 'ap', 'ike', 'y', 'Ġ=', 'Ġcommon', 'Ġ.', 'Ġap', 'ike', 'y', 'Ġ(', 'Ġsession', 'Key', 'Ġ,', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġdebug', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['ap', 'ike', 'y', 'Ġ=', 'Ġcommon', 'Ġ.', 'Ġap', 'ike', 'y', 'Ġ(', 'Ġsession', 'Key', 'Ġ,', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġdebug', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['apikey', 'Ġ=', 'Ġcommon', 'Ġ.', 'Ġapikey', 'Ġ(', 'ĠsessionKey', 'Ġ,', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġdebug', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "device = pandevice . base . PanDevice ( args [ 0 ] , api_key = apikey ) \n"
Original    (018): ['device', '=', 'pandevice', '.', 'base', '.', 'PanDevice', '(', 'args', '[', '0', ']', ',', 'api_key', '=', 'apikey', ')', '\\n']
Tokenized   (028): ['<s>', 'device', 'Ġ=', 'Ġpand', 'ev', 'ice', 'Ġ.', 'Ġbase', 'Ġ.', 'ĠPan', 'Device', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġapi', '_', 'key', 'Ġ=', 'Ġap', 'ike', 'y', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['device', 'Ġ=', 'Ġpand', 'ev', 'ice', 'Ġ.', 'Ġbase', 'Ġ.', 'ĠPan', 'Device', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġapi', '_', 'key', 'Ġ=', 'Ġap', 'ike', 'y', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['device', 'Ġ=', 'Ġpandevice', 'Ġ.', 'Ġbase', 'Ġ.', 'ĠPanDevice', 'Ġ(', 'Ġargs', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġapi_key', 'Ġ=', 'Ġapikey', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "rebalance_backoff_ms = 2 * 1000 , \n"
Original    (007): ['rebalance_backoff_ms', '=', '2', '*', '1000', ',', '\\n']
Tokenized   (016): ['<s>', 're', 'balance', '_', 'back', 'off', '_', 'ms', 'Ġ=', 'Ġ2', 'Ġ*', 'Ġ1000', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['re', 'balance', '_', 'back', 'off', '_', 'ms', 'Ġ=', 'Ġ2', 'Ġ*', 'Ġ1000', 'Ġ,', 'Ġ\\', 'n']
Detokenized (007): ['rebalance_backoff_ms', 'Ġ=', 'Ġ2', 'Ġ*', 'Ġ1000', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "uuid = uuid4 ( ) \n"
Original    (006): ['uuid', '=', 'uuid4', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'uu', 'id', 'Ġ=', 'Ġu', 'uid', '4', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['uu', 'id', 'Ġ=', 'Ġu', 'uid', '4', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['uuid', 'Ġ=', 'Ġuuid4', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : """ . join ( traceback . format_tb ( tb ) ) ) \n"
Original    (013): ['""', '.', 'join', '(', 'traceback', '.', 'format_tb', '(', 'tb', ')', ')', ')', '\\n']
Tokenized   (021): ['<s>', '""', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġtrace', 'back', 'Ġ.', 'Ġformat', '_', 't', 'b', 'Ġ(', 'Ġt', 'b', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['""', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġtrace', 'back', 'Ġ.', 'Ġformat', '_', 't', 'b', 'Ġ(', 'Ġt', 'b', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['""', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġtraceback', 'Ġ.', 'Ġformat_tb', 'Ġ(', 'Ġtb', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "kazoo_kwargs = { : timeout / 1000 } \n"
Original    (009): ['kazoo_kwargs', '=', '{', ':', 'timeout', '/', '1000', '}', '\\n']
Tokenized   (017): ['<s>', 'k', 'az', 'oo', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġtimeout', 'Ġ/', 'Ġ1000', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['k', 'az', 'oo', '_', 'kw', 'args', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġtimeout', 'Ġ/', 'Ġ1000', 'Ġ}', 'Ġ\\', 'n']
Detokenized (009): ['kazoo_kwargs', 'Ġ=', 'Ġ{', 'Ġ:', 'Ġtimeout', 'Ġ/', 'Ġ1000', 'Ġ}', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "p_to_str = lambda p : . join ( [ str ( p . topic . name ) , str ( p . leader . id ) , str ( p . id ) ] ) \n"
Original    (036): ['p_to_str', '=', 'lambda', 'p', ':', '.', 'join', '(', '[', 'str', '(', 'p', '.', 'topic', '.', 'name', ')', ',', 'str', '(', 'p', '.', 'leader', '.', 'id', ')', ',', 'str', '(', 'p', '.', 'id', ')', ']', ')', '\\n']
Tokenized   (043): ['<s>', 'p', '_', 'to', '_', 'str', 'Ġ=', 'Ġlambda', 'Ġp', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġtopic', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġleader', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['p', '_', 'to', '_', 'str', 'Ġ=', 'Ġlambda', 'Ġp', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġtopic', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġleader', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (036): ['p_to_str', 'Ġ=', 'Ġlambda', 'Ġp', 'Ġ:', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġtopic', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġleader', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġp', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 36, 768)
# Extracted words:  36
Sentence         : "idx = participants . index ( consumer_id or self . _consumer_id ) \n"
Original    (013): ['idx', '=', 'participants', '.', 'index', '(', 'consumer_id', 'or', 'self', '.', '_consumer_id', ')', '\\n']
Tokenized   (022): ['<s>', 'id', 'x', 'Ġ=', 'Ġparticipants', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġconsumer', '_', 'id', 'Ġor', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['id', 'x', 'Ġ=', 'Ġparticipants', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġconsumer', '_', 'id', 'Ġor', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['idx', 'Ġ=', 'Ġparticipants', 'Ġ.', 'Ġindex', 'Ġ(', 'Ġconsumer_id', 'Ġor', 'Ġself', 'Ġ.', 'Ġ_consumer_id', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "parts_per_consumer = len ( all_parts ) // len ( participants ) \n"
Original    (012): ['parts_per_consumer', '=', 'len', '(', 'all_parts', ')', '//', 'len', '(', 'participants', ')', '\\n']
Tokenized   (021): ['<s>', 'parts', '_', 'per', '_', 'consumer', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ//', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['parts', '_', 'per', '_', 'consumer', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ//', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['parts_per_consumer', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall_parts', 'Ġ)', 'Ġ//', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "remainder_ppc = len ( all_parts ) % len ( participants ) \n"
Original    (012): ['remainder_ppc', '=', 'len', '(', 'all_parts', ')', '%', 'len', '(', 'participants', ')', '\\n']
Tokenized   (022): ['<s>', 'rem', 'ain', 'der', '_', 'pp', 'c', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ%', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['rem', 'ain', 'der', '_', 'pp', 'c', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall', '_', 'parts', 'Ġ)', 'Ġ%', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['remainder_ppc', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġall_parts', 'Ġ)', 'Ġ%', 'Ġlen', 'Ġ(', 'Ġparticipants', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "num_parts = parts_per_consumer + ( 0 if ( idx + 1 > remainder_ppc ) else 1 ) \n"
Original    (018): ['num_parts', '=', 'parts_per_consumer', '+', '(', '0', 'if', '(', 'idx', '+', '1', '>', 'remainder_ppc', ')', 'else', '1', ')', '\\n']
Tokenized   (031): ['<s>', 'num', '_', 'parts', 'Ġ=', 'Ġparts', '_', 'per', '_', 'consumer', 'Ġ+', 'Ġ(', 'Ġ0', 'Ġif', 'Ġ(', 'Ġid', 'x', 'Ġ+', 'Ġ1', 'Ġ>', 'Ġremainder', '_', 'pp', 'c', 'Ġ)', 'Ġelse', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['num', '_', 'parts', 'Ġ=', 'Ġparts', '_', 'per', '_', 'consumer', 'Ġ+', 'Ġ(', 'Ġ0', 'Ġif', 'Ġ(', 'Ġid', 'x', 'Ġ+', 'Ġ1', 'Ġ>', 'Ġremainder', '_', 'pp', 'c', 'Ġ)', 'Ġelse', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['num_parts', 'Ġ=', 'Ġparts_per_consumer', 'Ġ+', 'Ġ(', 'Ġ0', 'Ġif', 'Ġ(', 'Ġidx', 'Ġ+', 'Ġ1', 'Ġ>', 'Ġremainder_ppc', 'Ġ)', 'Ġelse', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "log . debug ( , [ p_to_str ( p ) for p in new_partitions ] ) \n"
Original    (017): ['log', '.', 'debug', '(', ',', '[', 'p_to_str', '(', 'p', ')', 'for', 'p', 'in', 'new_partitions', ']', ')', '\\n']
Tokenized   (027): ['<s>', 'log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġp', '_', 'to', '_', 'str', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġnew', '_', 'part', 'itions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġp', '_', 'to', '_', 'str', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġnew', '_', 'part', 'itions', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['log', 'Ġ.', 'Ġdebug', 'Ġ(', 'Ġ,', 'Ġ[', 'Ġp_to_str', 'Ġ(', 'Ġp', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġnew_partitions', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "id_ = get_string ( self . _consumer_id ) \n"
Original    (009): ['id_', '=', 'get_string', '(', 'self', '.', '_consumer_id', ')', '\\n']
Tokenized   (018): ['<s>', 'id', '_', 'Ġ=', 'Ġget', '_', 'string', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['id', '_', 'Ġ=', 'Ġget', '_', 'string', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'consumer', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['id_', 'Ġ=', 'Ġget_string', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_consumer_id', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "path = self . _topic_path , slug = partition_slug ) ) \n"
Original    (012): ['path', '=', 'self', '.', '_topic_path', ',', 'slug', '=', 'partition_slug', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'topic', '_', 'path', 'Ġ,', 'Ġslug', 'Ġ=', 'Ġpartition', '_', 'sl', 'ug', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_', 'topic', '_', 'path', 'Ġ,', 'Ġslug', 'Ġ=', 'Ġpartition', '_', 'sl', 'ug', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['path', 'Ġ=', 'Ġself', 'Ġ.', 'Ġ_topic_path', 'Ġ,', 'Ġslug', 'Ġ=', 'Ġpartition_slug', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "HZCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (016): ['HZCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (023): ['<s>', 'H', 'Z', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['H', 'Z', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['HZCharLenTable', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "ISO2022CNCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (022): ['ISO2022CNCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (031): ['<s>', 'ISO', '20', '22', 'CN', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['ISO', '20', '22', 'CN', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['ISO2022CNCharLenTable', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "ISO2022JPCharLenTable = ( 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) \n"
Original    (024): ['ISO2022JPCharLenTable', '=', '(', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ',', '0', ')', '\\n']
Tokenized   (033): ['<s>', 'ISO', '20', '22', 'JP', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['ISO', '20', '22', 'JP', 'Char', 'Len', 'Table', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (024): ['ISO2022JPCharLenTable', 'Ġ=', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "logging . basicConfig ( level = logging . INFO ) \n"
Original    (011): ['logging', '.', 'basicConfig', '(', 'level', '=', 'logging', '.', 'INFO', ')', '\\n']
Tokenized   (016): ['<s>', 'log', 'ging', 'Ġ.', 'Ġbasic', 'Config', 'Ġ(', 'Ġlevel', 'Ġ=', 'Ġlogging', 'Ġ.', 'ĠINFO', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['log', 'ging', 'Ġ.', 'Ġbasic', 'Config', 'Ġ(', 'Ġlevel', 'Ġ=', 'Ġlogging', 'Ġ.', 'ĠINFO', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['logging', 'Ġ.', 'ĠbasicConfig', 'Ġ(', 'Ġlevel', 'Ġ=', 'Ġlogging', 'Ġ.', 'ĠINFO', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "tasa . __version__ , sys . version ) ) \n"
Original    (010): ['tasa', '.', '__version__', ',', 'sys', '.', 'version', ')', ')', '\\n']
Tokenized   (016): ['<s>', 't', 'asa', 'Ġ.', 'Ġ__', 'version', '__', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['t', 'asa', 'Ġ.', 'Ġ__', 'version', '__', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['tasa', 'Ġ.', 'Ġ__version__', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "type = lambda w : w . partition ( ) [ : : 2 ] , \n"
Original    (017): ['type', '=', 'lambda', 'w', ':', 'w', '.', 'partition', '(', ')', '[', ':', ':', '2', ']', ',', '\\n']
Tokenized   (020): ['<s>', 'type', 'Ġ=', 'Ġlambda', 'Ġw', 'Ġ:', 'Ġw', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['type', 'Ġ=', 'Ġlambda', 'Ġw', 'Ġ:', 'Ġw', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (017): ['type', 'Ġ=', 'Ġlambda', 'Ġw', 'Ġ:', 'Ġw', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ:', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "worker_class_name = args . worker [ 1 ] or \n"
Original    (010): ['worker_class_name', '=', 'args', '.', 'worker', '[', '1', ']', 'or', '\\n']
Tokenized   (017): ['<s>', 'worker', '_', 'class', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġworker', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['worker', '_', 'class', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġworker', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġor', 'Ġ\\', 'n']
Detokenized (010): ['worker_class_name', 'Ġ=', 'Ġargs', 'Ġ.', 'Ġworker', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġor', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "str ( job ) [ : 50 ] ) \n"
Original    (010): ['str', '(', 'job', ')', '[', ':', '50', ']', ')', '\\n']
Tokenized   (013): ['<s>', 'str', 'Ġ(', 'Ġjob', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ50', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['str', 'Ġ(', 'Ġjob', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ50', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['str', 'Ġ(', 'Ġjob', 'Ġ)', 'Ġ[', 'Ġ:', 'Ġ50', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "processes = [ Process ( target = run , args = ( ) ) for x in range ( count ) ] \n"
Original    (023): ['processes', '=', '[', 'Process', '(', 'target', '=', 'run', ',', 'args', '=', '(', ')', ')', 'for', 'x', 'in', 'range', '(', 'count', ')', ']', '\\n']
Tokenized   (027): ['<s>', 'process', 'es', 'Ġ=', 'Ġ[', 'ĠProcess', 'Ġ(', 'Ġtarget', 'Ġ=', 'Ġrun', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġcount', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['process', 'es', 'Ġ=', 'Ġ[', 'ĠProcess', 'Ġ(', 'Ġtarget', 'Ġ=', 'Ġrun', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġcount', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (023): ['processes', 'Ġ=', 'Ġ[', 'ĠProcess', 'Ġ(', 'Ġtarget', 'Ġ=', 'Ġrun', 'Ġ,', 'Ġargs', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġrange', 'Ġ(', 'Ġcount', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "color = models . CharField ( max_length = 6 , validators = [ color_regex ] , help_text = \n"
Original    (019): ['color', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '6', ',', 'validators', '=', '[', 'color_regex', ']', ',', 'help_text', '=', '\\n']
Tokenized   (031): ['<s>', 'color', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ6', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġcolor', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['color', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ6', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġcolor', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (019): ['color', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ6', 'Ġ,', 'Ġvalidators', 'Ġ=', 'Ġ[', 'Ġcolor_regex', 'Ġ]', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "first_name = models . CharField ( max_length = 64 ) \n"
Original    (011): ['first_name', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '64', ')', '\\n']
Tokenized   (019): ['<s>', 'first', '_', 'name', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['first', '_', 'name', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['first_name', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "role = models . CharField ( max_length = 17 , choices = ROLE_CHOICES ) \n"
Original    (015): ['role', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '17', ',', 'choices', '=', 'ROLE_CHOICES', ')', '\\n']
Tokenized   (025): ['<s>', 'role', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ17', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠRO', 'LE', '_', 'CHO', 'ICES', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['role', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ17', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠRO', 'LE', '_', 'CHO', 'ICES', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['role', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ17', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠROLE_CHOICES', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "phone_work = models . CharField ( max_length = 15 , validators = [ phone_regex ] , blank = True ) \n"
Original    (021): ['phone_work', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '15', ',', 'validators', '=', '[', 'phone_regex', ']', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (033): ['<s>', 'phone', '_', 'work', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġphone', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['phone', '_', 'work', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġvalid', 'ators', 'Ġ=', 'Ġ[', 'Ġphone', '_', 're', 'gex', 'Ġ]', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['phone_work', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġvalidators', 'Ġ=', 'Ġ[', 'Ġphone_regex', 'Ġ]', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "job_title = models . CharField ( max_length = 128 , blank = True ) \n"
Original    (015): ['job_title', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '128', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (023): ['<s>', 'job', '_', 'title', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['job', '_', 'title', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['job_title', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "category = models . CharField ( max_length = 21 , choices = CATEGORY_CHOICES , help_text = description = models . CharField ( max_length = 256 , blank = True , help_text = reference = models . URLField ( blank = True , help_text = ) \n"
Original    (046): ['category', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '21', ',', 'choices', '=', 'CATEGORY_CHOICES', ',', 'help_text', '=', 'description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '256', ',', 'blank', '=', 'True', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (068): ['<s>', 'category', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ21', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (066): ['category', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ21', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (046): ['category', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ21', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠCATEGORY_CHOICES', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 66
===================================================================
Hidden states:  (13, 46, 768)
# Extracted words:  46
Sentence         : "acronym = models . CharField ( max_length = 20 , unique = True , help_text = category = models . CharField ( max_length = 9 , choices = CATEGORY_CHOICES , help_text = jurisdiction = models . CharField ( max_length = 64 , help_text = description = models . TextField ( blank = True , help_text = reference = models . URLField ( blank = True , help_text = ) \n"
Original    (070): ['acronym', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '20', ',', 'unique', '=', 'True', ',', 'help_text', '=', 'category', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '9', ',', 'choices', '=', 'CATEGORY_CHOICES', ',', 'help_text', '=', 'jurisdiction', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '64', ',', 'help_text', '=', 'description', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', 'reference', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (102): ['<s>', 'ac', 'ron', 'ym', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ20', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġcategory', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġjurisdiction', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (100): ['ac', 'ron', 'ym', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ20', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġcategory', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠC', 'ATE', 'G', 'ORY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġjurisdiction', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ64', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (070): ['acronym', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ20', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġcategory', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠCATEGORY_CHOICES', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġjurisdiction', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ64', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġreference', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 100
===================================================================
Hidden states:  (13, 70, 768)
# Extracted words:  70
Sentence         : "description = models . CharField ( max_length = 256 , blank = True , help_text = \n"
Original    (017): ['description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '256', ',', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (025): ['<s>', 'description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (017): ['description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ256', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "business_criticality = models . CharField ( max_length = 9 , choices = BUSINESS_CRITICALITY_CHOICES , blank platform = models . CharField ( max_length = 11 , choices = PLATFORM_CHOICES , blank = True , null = True ) \n"
Original    (038): ['business_criticality', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '9', ',', 'choices', '=', 'BUSINESS_CRITICALITY_CHOICES', ',', 'blank', 'platform', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '11', ',', 'choices', '=', 'PLATFORM_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (064): ['<s>', 'business', '_', 'critical', 'ity', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠBUS', 'INESS', '_', 'CR', 'IT', 'ICAL', 'ITY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġplatform', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ11', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠPL', 'AT', 'FORM', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (062): ['business', '_', 'critical', 'ity', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠBUS', 'INESS', '_', 'CR', 'IT', 'ICAL', 'ITY', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġplatform', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ11', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠPL', 'AT', 'FORM', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (038): ['business_criticality', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ9', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠBUSINESS_CRITICALITY_CHOICES', 'Ġ,', 'Ġblank', 'Ġplatform', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ11', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠPLATFORM_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 62
===================================================================
Hidden states:  (13, 38, 768)
# Extracted words:  38
Sentence         : "lifecycle = models . CharField ( max_length = 8 , choices = LIFECYCLE_CHOICES , blank = True , null = True ) \n"
Original    (023): ['lifecycle', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '8', ',', 'choices', '=', 'LIFECYCLE_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (037): ['<s>', 'lif', 'ecycle', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠL', 'IF', 'EC', 'Y', 'CLE', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['lif', 'ecycle', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠL', 'IF', 'EC', 'Y', 'CLE', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['lifecycle', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ8', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠLIFECYCLE_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "user_records = models . PositiveIntegerField ( blank = True , null = True , help_text = revenue = models . DecimalField ( max_digits = 15 , decimal_places = 2 , blank = True , null = True , help_text = external_audience = models . BooleanField ( default = False , help_text = internet_accessible = models . BooleanField ( default = False , help_text = requestable = models . NullBooleanField ( default = True , help_text = _ ( \n"
Original    (079): ['user_records', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'revenue', '=', 'models', '.', 'DecimalField', '(', 'max_digits', '=', '15', ',', 'decimal_places', '=', '2', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'external_audience', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', 'internet_accessible', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', 'requestable', '=', 'models', '.', 'NullBooleanField', '(', 'default', '=', 'True', ',', 'help_text', '=', '_', '(', '\\n']
Tokenized   (115): ['<s>', 'user', '_', 'rec', 'ords', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrevenue', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDec', 'imal', 'Field', 'Ġ(', 'Ġmax', '_', 'dig', 'its', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġdecimal', '_', 'places', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġexternal', '_', 'aud', 'ience', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġinternet', '_', 'accessible', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrequest', 'able', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠNull', 'Boo', 'lean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (113): ['user', '_', 'rec', 'ords', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrevenue', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDec', 'imal', 'Field', 'Ġ(', 'Ġmax', '_', 'dig', 'its', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġdecimal', '_', 'places', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġexternal', '_', 'aud', 'ience', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġinternet', '_', 'accessible', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġrequest', 'able', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠNull', 'Boo', 'lean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ\\', 'n']
Detokenized (079): ['user_records', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġrevenue', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDecimalField', 'Ġ(', 'Ġmax_digits', 'Ġ=', 'Ġ15', 'Ġ,', 'Ġdecimal_places', 'Ġ=', 'Ġ2', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġexternal_audience', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġinternet_accessible', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġrequestable', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠNullBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ\\n']
Counter: 113
===================================================================
Hidden states:  (13, 79, 768)
# Extracted words:  79
Sentence         : "override_dcl = models . IntegerField ( choices = DATA_CLASSIFICATION_CHOICES , blank = True , null = True , help_text override_reason = models . TextField ( blank = True , help_text = \n"
Original    (032): ['override_dcl', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'DATA_CLASSIFICATION_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', 'override_reason', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (054): ['<s>', 'over', 'ride', '_', 'd', 'cl', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠDATA', '_', 'CLASS', 'IFIC', 'ATION', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġoverride', '_', 'reason', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (052): ['over', 'ride', '_', 'd', 'cl', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠDATA', '_', 'CLASS', 'IFIC', 'ATION', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġoverride', '_', 'reason', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (032): ['override_dcl', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠIntegerField', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠDATA_CLASSIFICATION_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġoverride_reason', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 52
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "threadfix = models . ForeignKey ( ThreadFix , blank = True , null = True , help_text = threadfix_team_id = models . PositiveIntegerField ( blank = True , null = True , help_text = threadfix_application_id = models . PositiveIntegerField ( blank = True , null = True , help_text = \n"
Original    (051): ['threadfix', '=', 'models', '.', 'ForeignKey', '(', 'ThreadFix', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'threadfix_team_id', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'threadfix_application_id', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (077): ['<s>', 'thread', 'fix', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠThread', 'Fix', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'team', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'application', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (075): ['thread', 'fix', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠThread', 'Fix', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'team', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġthread', 'fix', '_', 'application', '_', 'id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (051): ['threadfix', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'ĠThreadFix', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġthreadfix_team_id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġthreadfix_application_id', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 75
===================================================================
Hidden states:  (13, 51, 768)
# Extracted words:  51
Sentence         : "asvs_level = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = asvs_level_percent_achieved = models . PositiveIntegerField ( blank = True , null = True , help_text = asvs_doc_url = models . URLField ( blank = True , help_text = ) \n"
Original    (050): ['asvs_level', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'ASVS_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'asvs_level_percent_achieved', '=', 'models', '.', 'PositiveIntegerField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'asvs_doc_url', '=', 'models', '.', 'URLField', '(', 'blank', '=', 'True', ',', 'help_text', '=', ')', '\\n']
Tokenized   (083): ['<s>', 'as', 'vs', '_', 'level', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'level', '_', 'percent', '_', 'ach', 'ieved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'doc', '_', 'url', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (081): ['as', 'vs', '_', 'level', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'level', '_', 'percent', '_', 'ach', 'ieved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositive', 'Integer', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġas', 'vs', '_', 'doc', '_', 'url', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (050): ['asvs_level', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠIntegerField', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠASVS_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġasvs_level_percent_achieved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠPositiveIntegerField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġasvs_doc_url', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 81
===================================================================
Hidden states:  (13, 50, 768)
# Extracted words:  50
Sentence         : "asvs_level_target = models . IntegerField ( choices = ASVS_CHOICES , blank = True , null = True , help_text = \n"
Original    (021): ['asvs_level_target', '=', 'models', '.', 'IntegerField', '(', 'choices', '=', 'ASVS_CHOICES', ',', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (036): ['<s>', 'as', 'vs', '_', 'level', '_', 'target', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['as', 'vs', '_', 'level', '_', 'target', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠInteger', 'Field', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠAS', 'VS', '_', 'CHO', 'ICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (021): ['asvs_level_target', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠIntegerField', 'Ġ(', 'Ġchoices', 'Ġ=', 'ĠASVS_CHOICES', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "organization = models . ForeignKey ( Organization , help_text = people = models . ManyToManyField ( Person , through = , blank = True ) \n"
Original    (026): ['organization', '=', 'models', '.', 'ForeignKey', '(', 'Organization', ',', 'help_text', '=', 'people', '=', 'models', '.', 'ManyToManyField', '(', 'Person', ',', 'through', '=', ',', 'blank', '=', 'True', ')', '\\n']
Tokenized   (036): ['<s>', 'organ', 'ization', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠOrganization', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġpeople', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġthrough', 'Ġ=', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['organ', 'ization', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠOrganization', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġpeople', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġthrough', 'Ġ=', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['organization', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'ĠOrganization', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġpeople', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠManyToManyField', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġthrough', 'Ġ=', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "delta = self . created_date - timezone . now ( ) \n"
Original    (012): ['delta', '=', 'self', '.', 'created_date', '-', 'timezone', '.', 'now', '(', ')', '\\n']
Tokenized   (019): ['<s>', 'd', 'elta', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcreated', '_', 'date', 'Ġ-', 'Ġtime', 'zone', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['d', 'elta', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcreated', '_', 'date', 'Ġ-', 'Ġtime', 'zone', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['delta', 'Ġ=', 'Ġself', 'Ġ.', 'Ġcreated_date', 'Ġ-', 'Ġtimezone', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "person = models . ForeignKey ( Person , help_text = ) \n"
Original    (012): ['person', '=', 'models', '.', 'ForeignKey', '(', 'Person', ',', 'help_text', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'person', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['person', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeign', 'Key', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['person', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠForeignKey', 'Ġ(', 'ĠPerson', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "environment_type = models . CharField ( max_length = 4 , choices = ENVIRONMENT_CHOICES , help_text = description = models . TextField ( blank = True , help_text = testing_approved = models . BooleanField ( default = False , help_text = \n"
Original    (041): ['environment_type', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '4', ',', 'choices', '=', 'ENVIRONMENT_CHOICES', ',', 'help_text', '=', 'description', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', 'testing_approved', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ',', 'help_text', '=', '\\n']
Tokenized   (066): ['<s>', 'environment', '_', 'type', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠEN', 'V', 'IR', 'ON', 'MENT', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġtesting', '_', 'approved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (064): ['environment', '_', 'type', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠEN', 'V', 'IR', 'ON', 'MENT', '_', 'CHO', 'ICES', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġtesting', '_', 'approved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (041): ['environment_type', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġchoices', 'Ġ=', 'ĠENVIRONMENT_CHOICES', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġdescription', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġtesting_approved', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 64
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "location = models . URLField ( help_text = notes = models . TextField ( blank = True , help_text = \n"
Original    (021): ['location', '=', 'models', '.', 'URLField', '(', 'help_text', '=', 'notes', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (030): ['<s>', 'location', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['location', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURL', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (021): ['location', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠURLField', 'Ġ(', 'Ġhelp_text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "role_description = models . CharField ( max_length = 128 , blank = True , help_text = notes = models . TextField ( blank = True , help_text = \n"
Original    (029): ['role_description', '=', 'models', '.', 'CharField', '(', 'max_length', '=', '128', ',', 'blank', '=', 'True', ',', 'help_text', '=', 'notes', '=', 'models', '.', 'TextField', '(', 'blank', '=', 'True', ',', 'help_text', '=', '\\n']
Tokenized   (042): ['<s>', 'role', '_', 'description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (040): ['role', '_', 'description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠChar', 'Field', 'Ġ(', 'Ġmax', '_', 'length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠText', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ\\', 'n']
Detokenized (029): ['role_description', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠCharField', 'Ġ(', 'Ġmax_length', 'Ġ=', 'Ġ128', 'Ġ,', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġnotes', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠTextField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġ\\n']
Counter: 40
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "start_date = models . DateField ( help_text = ) \n"
Original    (010): ['start_date', '=', 'models', '.', 'DateField', '(', 'help_text', '=', ')', '\\n']
Tokenized   (018): ['<s>', 'start', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['start', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Field', 'Ġ(', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['start_date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDateField', 'Ġ(', 'Ġhelp_text', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "open_date = models . DateTimeField ( blank = True , null = True , help_text = close_date = models . DateTimeField ( blank = True , null = True , help_text = duration = models . DurationField ( blank = True , null = True ) \n"
Original    (047): ['open_date', '=', 'models', '.', 'DateTimeField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'close_date', '=', 'models', '.', 'DateTimeField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ',', 'help_text', '=', 'duration', '=', 'models', '.', 'DurationField', '(', 'blank', '=', 'True', ',', 'null', '=', 'True', ')', '\\n']
Tokenized   (063): ['<s>', 'open', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġclose', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġduration', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDuration', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (061): ['open', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġclose', '_', 'date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDate', 'Time', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp', '_', 'text', 'Ġ=', 'Ġduration', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDuration', 'Field', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (047): ['open_date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDateTimeField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġclose_date', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDateTimeField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġhelp_text', 'Ġ=', 'Ġduration', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠDurationField', 'Ġ(', 'Ġblank', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġnull', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 61
===================================================================
Hidden states:  (13, 47, 768)
# Extracted words:  47
Sentence         : "metrics = managers . ActivityTypeMetrics . from_queryset ( managers . ActivityTypeQuerySet ) ( ) \n"
Original    (015): ['metrics', '=', 'managers', '.', 'ActivityTypeMetrics', '.', 'from_queryset', '(', 'managers', '.', 'ActivityTypeQuerySet', ')', '(', ')', '\\n']
Tokenized   (029): ['<s>', 'met', 'rics', 'Ġ=', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Met', 'rics', 'Ġ.', 'Ġfrom', '_', 'quer', 'ys', 'et', 'Ġ(', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Query', 'Set', 'Ġ)', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['met', 'rics', 'Ġ=', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Met', 'rics', 'Ġ.', 'Ġfrom', '_', 'quer', 'ys', 'et', 'Ġ(', 'Ġmanagers', 'Ġ.', 'ĠActivity', 'Type', 'Query', 'Set', 'Ġ)', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['metrics', 'Ġ=', 'Ġmanagers', 'Ġ.', 'ĠActivityTypeMetrics', 'Ġ.', 'Ġfrom_queryset', 'Ġ(', 'Ġmanagers', 'Ġ.', 'ĠActivityTypeQuerySet', 'Ġ)', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "token = models . UUIDField ( default = uuid . uuid4 , editable = False ) \n"
Original    (017): ['token', '=', 'models', '.', 'UUIDField', '(', 'default', '=', 'uuid', '.', 'uuid4', ',', 'editable', '=', 'False', ')', '\\n']
Tokenized   (026): ['<s>', 'token', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠU', 'UID', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'Ġu', 'uid', 'Ġ.', 'Ġu', 'uid', '4', 'Ġ,', 'Ġedit', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['token', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠU', 'UID', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'Ġu', 'uid', 'Ġ.', 'Ġu', 'uid', '4', 'Ġ,', 'Ġedit', 'able', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['token', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠUUIDField', 'Ġ(', 'Ġdefault', 'Ġ=', 'Ġuuid', 'Ġ.', 'Ġuuid4', 'Ġ,', 'Ġeditable', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "activities = models . ManyToManyField ( ActivityType , limit_choices_to = { : True } ) \n"
Original    (016): ['activities', '=', 'models', '.', 'ManyToManyField', '(', 'ActivityType', ',', 'limit_choices_to', '=', '{', ':', 'True', '}', ')', '\\n']
Tokenized   (029): ['<s>', 'activ', 'ities', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠActivity', 'Type', 'Ġ,', 'Ġlimit', '_', 'cho', 'ices', '_', 'to', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠTrue', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['activ', 'ities', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠMany', 'To', 'Many', 'Field', 'Ġ(', 'ĠActivity', 'Type', 'Ġ,', 'Ġlimit', '_', 'cho', 'ices', '_', 'to', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠTrue', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['activities', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠManyToManyField', 'Ġ(', 'ĠActivityType', 'Ġ,', 'Ġlimit_choices_to', 'Ġ=', 'Ġ{', 'Ġ:', 'ĠTrue', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "opener . addheaders = [ ( , ) ] \n"
Original    (010): ['opener', '.', 'addheaders', '=', '[', '(', ',', ')', ']', '\\n']
Tokenized   (015): ['<s>', 'op', 'ener', 'Ġ.', 'Ġadd', 'headers', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['op', 'ener', 'Ġ.', 'Ġadd', 'headers', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['opener', 'Ġ.', 'Ġaddheaders', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "False = 0 \n"
Original    (004): ['False', '=', '0', '\\n']
Tokenized   (007): ['<s>', 'False', 'Ġ=', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['False', 'Ġ=', 'Ġ0', 'Ġ\\', 'n']
Detokenized (004): ['False', 'Ġ=', 'Ġ0', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "option_pattern = chr ( 0 ) * 8 \n"
Original    (009): ['option_pattern', '=', 'chr', '(', '0', ')', '*', '8', '\\n']
Tokenized   (015): ['<s>', 'option', '_', 'pattern', 'Ġ=', 'Ġch', 'r', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ*', 'Ġ8', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['option', '_', 'pattern', 'Ġ=', 'Ġch', 'r', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ*', 'Ġ8', 'Ġ\\', 'n']
Detokenized (009): ['option_pattern', 'Ġ=', 'Ġchr', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ*', 'Ġ8', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "begin = toint ( s [ 5 : 9 ] ) \n"
Original    (012): ['begin', '=', 'toint', '(', 's', '[', '5', ':', '9', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'begin', 'Ġ=', 'Ġto', 'int', 'Ġ(', 'Ġs', 'Ġ[', 'Ġ5', 'Ġ:', 'Ġ9', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['begin', 'Ġ=', 'Ġto', 'int', 'Ġ(', 'Ġs', 'Ġ[', 'Ġ5', 'Ġ:', 'Ġ9', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['begin', 'Ġ=', 'Ġtoint', 'Ġ(', 'Ġs', 'Ġ[', 'Ġ5', 'Ġ:', 'Ġ9', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "length = len ( s ) - 9 \n"
Original    (009): ['length', '=', 'len', '(', 's', ')', '-', '9', '\\n']
Tokenized   (012): ['<s>', 'length', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ-', 'Ġ9', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['length', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ-', 'Ġ9', 'Ġ\\', 'n']
Detokenized (009): ['length', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ-', 'Ġ9', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "DivergeCommits = namedtuple ( "DivergeCommits" , [ "common_parent" , \n"
Original    (010): ['DivergeCommits', '=', 'namedtuple', '(', '"DivergeCommits"', ',', '[', '"common_parent"', ',', '\\n']
Tokenized   (029): ['<s>', 'D', 'iver', 'ge', 'Comm', 'its', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'D', 'iver', 'ge', 'Comm', 'its', '"', 'Ġ,', 'Ġ[', 'Ġ"', 'common', '_', 'parent', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['D', 'iver', 'ge', 'Comm', 'its', 'Ġ=', 'Ġnamed', 't', 'uple', 'Ġ(', 'Ġ"', 'D', 'iver', 'ge', 'Comm', 'its', '"', 'Ġ,', 'Ġ[', 'Ġ"', 'common', '_', 'parent', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['DivergeCommits', 'Ġ=', 'Ġnamedtuple', 'Ġ(', 'Ġ"DivergeCommits"', 'Ġ,', 'Ġ[', 'Ġ"common_parent"', 'Ġ,', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : ""first_commits" , "second_commits" ] ) \n"
Original    (006): ['"first_commits"', ',', '"second_commits"', ']', ')', '\\n']
Tokenized   (019): ['<s>', '"', 'first', '_', 'comm', 'its', '"', 'Ġ,', 'Ġ"', 'second', '_', 'comm', 'its', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['"', 'first', '_', 'comm', 'its', '"', 'Ġ,', 'Ġ"', 'second', '_', 'comm', 'its', '"', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['"first_commits"', 'Ġ,', 'Ġ"second_commits"', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "behind = len ( diverge_commits . second_commits ) > 0 \n"
Original    (011): ['behind', '=', 'len', '(', 'diverge_commits', '.', 'second_commits', ')', '>', '0', '\\n']
Tokenized   (021): ['<s>', 'behind', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġdiver', 'ge', '_', 'comm', 'its', 'Ġ.', 'Ġsecond', '_', 'comm', 'its', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['behind', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġdiver', 'ge', '_', 'comm', 'its', 'Ġ.', 'Ġsecond', '_', 'comm', 'its', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ\\', 'n']
Detokenized (011): ['behind', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġdiverge_commits', 'Ġ.', 'Ġsecond_commits', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "onerror = lambda function , fpath , excinfo : log . info ( \n"
Original    (014): ['onerror', '=', 'lambda', 'function', ',', 'fpath', ',', 'excinfo', ':', 'log', '.', 'info', '(', '\\n']
Tokenized   (020): ['<s>', 'oner', 'ror', 'Ġ=', 'Ġlambda', 'Ġfunction', 'Ġ,', 'Ġf', 'path', 'Ġ,', 'Ġexc', 'info', 'Ġ:', 'Ġlog', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['oner', 'ror', 'Ġ=', 'Ġlambda', 'Ġfunction', 'Ġ,', 'Ġf', 'path', 'Ġ,', 'Ġexc', 'info', 'Ġ:', 'Ġlog', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ\\', 'n']
Detokenized (014): ['onerror', 'Ġ=', 'Ġlambda', 'Ġfunction', 'Ġ,', 'Ġfpath', 'Ġ,', 'Ġexcinfo', 'Ġ:', 'Ġlog', 'Ġ.', 'Ġinfo', 'Ġ(', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "commiter = Signature ( commiter [ 0 ] , commiter [ 1 ] ) \n"
Original    (015): ['commiter', '=', 'Signature', '(', 'commiter', '[', '0', ']', ',', 'commiter', '[', '1', ']', ')', '\\n']
Tokenized   (021): ['<s>', 'comm', 'iter', 'Ġ=', 'ĠSignature', 'Ġ(', 'Ġcomm', 'iter', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġcomm', 'iter', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['comm', 'iter', 'Ġ=', 'ĠSignature', 'Ġ(', 'Ġcomm', 'iter', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġcomm', 'iter', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['commiter', 'Ġ=', 'ĠSignature', 'Ġ(', 'Ġcommiter', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġcommiter', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "len ( path_components ) == 1 and \n"
Original    (008): ['len', '(', 'path_components', ')', '==', '1', 'and', '\\n']
Tokenized   (014): ['<s>', 'len', 'Ġ(', 'Ġpath', '_', 'comp', 'onents', 'Ġ)', 'Ġ==', 'Ġ1', 'Ġand', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['len', 'Ġ(', 'Ġpath', '_', 'comp', 'onents', 'Ġ)', 'Ġ==', 'Ġ1', 'Ġand', 'Ġ\\', 'n']
Detokenized (008): ['len', 'Ġ(', 'Ġpath_components', 'Ġ)', 'Ġ==', 'Ġ1', 'Ġand', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "entry_name == path_components [ 0 ] ) \n"
Original    (008): ['entry_name', '==', 'path_components', '[', '0', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'entry', '_', 'name', 'Ġ==', 'Ġpath', '_', 'comp', 'onents', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['entry', '_', 'name', 'Ġ==', 'Ġpath', '_', 'comp', 'onents', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['entry_name', 'Ġ==', 'Ġpath_components', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "lambda entry : self . _repo [ entry . id ] ) \n"
Original    (013): ['lambda', 'entry', ':', 'self', '.', '_repo', '[', 'entry', '.', 'id', ']', ')', '\\n']
Tokenized   (018): ['<s>', 'lambda', 'Ġentry', 'Ġ:', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ[', 'Ġentry', 'Ġ.', 'Ġid', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['lambda', 'Ġentry', 'Ġ:', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ[', 'Ġentry', 'Ġ.', 'Ġid', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['lambda', 'Ġentry', 'Ġ:', 'Ġself', 'Ġ.', 'Ġ_repo', 'Ġ[', 'Ġentry', 'Ġ.', 'Ġid', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "GIT_FILEMODE_LINK : { \n"
Original    (004): ['GIT_FILEMODE_LINK', ':', '{', '\\n']
Tokenized   (014): ['<s>', 'G', 'IT', '_', 'FILE', 'MODE', '_', 'L', 'INK', 'Ġ:', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['G', 'IT', '_', 'FILE', 'MODE', '_', 'L', 'INK', 'Ġ:', 'Ġ{', 'Ġ\\', 'n']
Detokenized (004): ['GIT_FILEMODE_LINK', 'Ġ:', 'Ġ{', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "iterators = [ self . _repo . walk ( branch . target , sort ) \n"
Original    (016): ['iterators', '=', '[', 'self', '.', '_repo', '.', 'walk', '(', 'branch', '.', 'target', ',', 'sort', ')', '\\n']
Tokenized   (022): ['<s>', 'iter', 'ators', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ(', 'Ġbranch', 'Ġ.', 'Ġtarget', 'Ġ,', 'Ġsort', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['iter', 'ators', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ(', 'Ġbranch', 'Ġ.', 'Ġtarget', 'Ġ,', 'Ġsort', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['iterators', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġ_repo', 'Ġ.', 'Ġwalk', 'Ġ(', 'Ġbranch', 'Ġ.', 'Ġtarget', 'Ġ,', 'Ġsort', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "stop_iteration = [ False for branch in branches ] \n"
Original    (010): ['stop_iteration', '=', '[', 'False', 'for', 'branch', 'in', 'branches', ']', '\\n']
Tokenized   (016): ['<s>', 'stop', '_', 'iter', 'ation', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġfor', 'Ġbranch', 'Ġin', 'Ġbranches', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['stop', '_', 'iter', 'ation', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġfor', 'Ġbranch', 'Ġin', 'Ġbranches', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['stop_iteration', 'Ġ=', 'Ġ[', 'ĠFalse', 'Ġfor', 'Ġbranch', 'Ġin', 'Ġbranches', 'Ġ]', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "second_commit in first_commits ) : \n"
Original    (006): ['second_commit', 'in', 'first_commits', ')', ':', '\\n']
Tokenized   (014): ['<s>', 'second', '_', 'commit', 'Ġin', 'Ġfirst', '_', 'comm', 'its', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['second', '_', 'commit', 'Ġin', 'Ġfirst', '_', 'comm', 'its', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (006): ['second_commit', 'Ġin', 'Ġfirst_commits', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "new_commit = Commit ( 2 , 2 , "21111111111" ) \n"
Original    (011): ['new_commit', '=', 'Commit', '(', '2', ',', '2', ',', '"21111111111"', ')', '\\n']
Tokenized   (020): ['<s>', 'new', '_', 'commit', 'Ġ=', 'ĠCommit', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ"', '211', '1111', '1111', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['new', '_', 'commit', 'Ġ=', 'ĠCommit', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ"', '211', '1111', '1111', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['new_commit', 'Ġ=', 'ĠCommit', 'Ġ(', 'Ġ2', 'Ġ,', 'Ġ2', 'Ġ,', 'Ġ"21111111111"', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "mocked_repo . walk . assert_called_once_with ( "head" , GIT_SORT_TIME ) \n"
Original    (011): ['mocked_repo', '.', 'walk', '.', 'assert_called_once_with', '(', '"head"', ',', 'GIT_SORT_TIME', ')', '\\n']
Tokenized   (032): ['<s>', 'm', 'ocked', '_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ"', 'head', '"', 'Ġ,', 'ĠG', 'IT', '_', 'S', 'ORT', '_', 'TIME', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['m', 'ocked', '_', 're', 'po', 'Ġ.', 'Ġwalk', 'Ġ.', 'Ġassert', '_', 'called', '_', 'once', '_', 'with', 'Ġ(', 'Ġ"', 'head', '"', 'Ġ,', 'ĠG', 'IT', '_', 'S', 'ORT', '_', 'TIME', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['mocked_repo', 'Ġ.', 'Ġwalk', 'Ġ.', 'Ġassert_called_once_with', 'Ġ(', 'Ġ"head"', 'Ġ,', 'ĠGIT_SORT_TIME', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "to_datetime = True ) == datetime \n"
Original    (007): ['to_datetime', '=', 'True', ')', '==', 'datetime', '\\n']
Tokenized   (014): ['<s>', 'to', '_', 'dat', 'etime', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ==', 'Ġdat', 'etime', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['to', '_', 'dat', 'etime', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ==', 'Ġdat', 'etime', 'Ġ\\', 'n']
Detokenized (007): ['to_datetime', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ==', 'Ġdatetime', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "date = dt . date ( 1970 , 1 , 1 ) \n"
Original    (013): ['date', '=', 'dt', '.', 'date', '(', '1970', ',', '1', ',', '1', ')', '\\n']
Tokenized   (017): ['<s>', 'date', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdate', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['date', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdate', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['date', 'Ġ=', 'Ġdt', 'Ġ.', 'Ġdate', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "datetime = dt . datetime ( 1970 , 1 , 1 , 13 , 30 ) \n"
Original    (017): ['datetime', '=', 'dt', '.', 'datetime', '(', '1970', ',', '1', ',', '1', ',', '13', ',', '30', ')', '\\n']
Tokenized   (023): ['<s>', 'dat', 'etime', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ13', 'Ġ,', 'Ġ30', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['dat', 'etime', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ13', 'Ġ,', 'Ġ30', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['datetime', 'Ġ=', 'Ġdt', 'Ġ.', 'Ġdatetime', 'Ġ(', 'Ġ1970', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġ13', 'Ġ,', 'Ġ30', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "internationalizeDocstring = lambda x : x \n"
Original    (007): ['internationalizeDocstring', '=', 'lambda', 'x', ':', 'x', '\\n']
Tokenized   (013): ['<s>', 'international', 'ize', 'Doc', 'string', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['international', 'ize', 'Doc', 'string', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ\\', 'n']
Detokenized (007): ['internationalizeDocstring', 'Ġ=', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġx', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "conf . supybot . drivers . maxReconnectWait ( ) ) \n"
Original    (011): ['conf', '.', 'supybot', '.', 'drivers', '.', 'maxReconnectWait', '(', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'conf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġdrivers', 'Ġ.', 'Ġmax', 'Rec', 'on', 'nect', 'Wait', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['conf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġdrivers', 'Ġ.', 'Ġmax', 'Rec', 'on', 'nect', 'Wait', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['conf', 'Ġ.', 'Ġsupybot', 'Ġ.', 'Ġdrivers', 'Ġ.', 'ĠmaxReconnectWait', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "inst . conn . _sock . __class__ is socket . _closedsocket ) : \n"
Original    (014): ['inst', '.', 'conn', '.', '_sock', '.', '__class__', 'is', 'socket', '.', '_closedsocket', ')', ':', '\\n']
Tokenized   (023): ['<s>', 'inst', 'Ġ.', 'Ġconn', 'Ġ.', 'Ġ_', 's', 'ock', 'Ġ.', 'Ġ__', 'class', '__', 'Ġis', 'Ġsocket', 'Ġ.', 'Ġ_', 'closed', 'socket', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['inst', 'Ġ.', 'Ġconn', 'Ġ.', 'Ġ_', 's', 'ock', 'Ġ.', 'Ġ__', 'class', '__', 'Ġis', 'Ġsocket', 'Ġ.', 'Ġ_', 'closed', 'socket', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (014): ['inst', 'Ġ.', 'Ġconn', 'Ġ.', 'Ġ_sock', 'Ġ.', 'Ġ__class__', 'Ġis', 'Ġsocket', 'Ġ.', 'Ġ_closedsocket', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "network_config = getattr ( conf . supybot . networks , self . irc . network ) \n"
Original    (017): ['network_config', '=', 'getattr', '(', 'conf', '.', 'supybot', '.', 'networks', ',', 'self', '.', 'irc', '.', 'network', ')', '\\n']
Tokenized   (026): ['<s>', 'network', '_', 'config', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġnetworks', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġnetwork', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['network', '_', 'config', 'Ġ=', 'Ġget', 'attr', 'Ġ(', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġnetworks', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġnetwork', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['network_config', 'Ġ=', 'Ġgetattr', 'Ġ(', 'Ġconf', 'Ġ.', 'Ġsupybot', 'Ġ.', 'Ġnetworks', 'Ġ,', 'Ġself', 'Ġ.', 'Ġirc', 'Ġ.', 'Ġnetwork', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "vhost = conf . supybot . protocols . irc . vhost ( ) , \n"
Original    (015): ['vhost', '=', 'conf', '.', 'supybot', '.', 'protocols', '.', 'irc', '.', 'vhost', '(', ')', ',', '\\n']
Tokenized   (023): ['<s>', 'v', 'host', 'Ġ=', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġprotocols', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġv', 'host', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['v', 'host', 'Ġ=', 'Ġconf', 'Ġ.', 'Ġsup', 'y', 'bot', 'Ġ.', 'Ġprotocols', 'Ġ.', 'Ġ', 'irc', 'Ġ.', 'Ġv', 'host', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['vhost', 'Ġ=', 'Ġconf', 'Ġ.', 'Ġsupybot', 'Ġ.', 'Ġprotocols', 'Ġ.', 'Ġirc', 'Ġ.', 'Ġvhost', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "trusted_fingerprints = network_config . ssl . serverFingerprints ( ) , \n"
Original    (011): ['trusted_fingerprints', '=', 'network_config', '.', 'ssl', '.', 'serverFingerprints', '(', ')', ',', '\\n']
Tokenized   (024): ['<s>', 'tr', 'usted', '_', 'finger', 'prints', 'Ġ=', 'Ġnetwork', '_', 'config', 'Ġ.', 'Ġs', 'sl', 'Ġ.', 'Ġserver', 'F', 'inger', 'prints', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['tr', 'usted', '_', 'finger', 'prints', 'Ġ=', 'Ġnetwork', '_', 'config', 'Ġ.', 'Ġs', 'sl', 'Ġ.', 'Ġserver', 'F', 'inger', 'prints', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (011): ['trusted_fingerprints', 'Ġ=', 'Ġnetwork_config', 'Ġ.', 'Ġssl', 'Ġ.', 'ĠserverFingerprints', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "while tb : \n"
Original    (004): ['while', 'tb', ':', '\\n']
Tokenized   (008): ['<s>', 'while', 'Ġt', 'b', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['while', 'Ġt', 'b', 'Ġ:', 'Ġ\\', 'n']
Detokenized (004): ['while', 'Ġtb', 'Ġ:', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "frame . f_lineno ) ) \n"
Original    (006): ['frame', '.', 'f_lineno', ')', ')', '\\n']
Tokenized   (012): ['<s>', 'frame', 'Ġ.', 'Ġf', '_', 'lin', 'eno', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['frame', 'Ġ.', 'Ġf', '_', 'lin', 'eno', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['frame', 'Ġ.', 'Ġf_lineno', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "window = timedelta ( 0 , 0 , 0 , 0 , settings . SESSION_TIMEOUT ) \n"
Original    (017): ['window', '=', 'timedelta', '(', '0', ',', '0', ',', '0', ',', '0', ',', 'settings', '.', 'SESSION_TIMEOUT', ')', '\\n']
Tokenized   (025): ['<s>', 'window', 'Ġ=', 'Ġtimed', 'elta', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġsettings', 'Ġ.', 'ĠS', 'ESSION', '_', 'TIME', 'OUT', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['window', 'Ġ=', 'Ġtimed', 'elta', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġsettings', 'Ġ.', 'ĠS', 'ESSION', '_', 'TIME', 'OUT', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['window', 'Ġ=', 'Ġtimedelta', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġ0', 'Ġ,', 'Ġsettings', 'Ġ.', 'ĠSESSION_TIMEOUT', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "shared = request . POST . get ( "shared" , False ) \n"
Original    (013): ['shared', '=', 'request', '.', 'POST', '.', 'get', '(', '"shared"', ',', 'False', ')', '\\n']
Tokenized   (018): ['<s>', 'shared', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'shared', '"', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['shared', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'shared', '"', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['shared', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"shared"', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "} , p . score_functions . all ( ) . filter ( selectable_bodies = plan . legislative_body } , report_displays [ 0 ] . scorepanel_set . all ( ) . order_by ( ) ) \n"
Original    (035): ['}', ',', 'p', '.', 'score_functions', '.', 'all', '(', ')', '.', 'filter', '(', 'selectable_bodies', '=', 'plan', '.', 'legislative_body', '}', ',', 'report_displays', '[', '0', ']', '.', 'scorepanel_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', ')', '\\n']
Tokenized   (055): ['<s>', '}', 'Ġ,', 'Ġp', 'Ġ.', 'Ġscore', '_', 'fun', 'ctions', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ}', 'Ġ,', 'Ġreport', '_', 'dis', 'plays', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (053): ['}', 'Ġ,', 'Ġp', 'Ġ.', 'Ġscore', '_', 'fun', 'ctions', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ}', 'Ġ,', 'Ġreport', '_', 'dis', 'plays', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (035): ['}', 'Ġ,', 'Ġp', 'Ġ.', 'Ġscore_functions', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselectable_bodies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative_body', 'Ġ}', 'Ġ,', 'Ġreport_displays', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġscorepanel_set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 53
===================================================================
Hidden states:  (13, 35, 768)
# Extracted words:  35
Sentence         : "body_member_long_label = _ ( ) + \n"
Original    (007): ['body_member_long_label', '=', '_', '(', ')', '+', '\\n']
Tokenized   (016): ['<s>', 'body', '_', 'member', '_', 'long', '_', 'label', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['body', '_', 'member', '_', 'long', '_', 'label', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (007): ['body_member_long_label', 'Ġ=', 'Ġ_', 'Ġ(', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "body_members = _n ( , , 2 ) \n"
Original    (009): ['body_members', '=', '_n', '(', ',', ',', '2', ')', '\\n']
Tokenized   (015): ['<s>', 'body', '_', 'members', 'Ġ=', 'Ġ_', 'n', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['body', '_', 'members', 'Ġ=', 'Ġ_', 'n', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['body_members', 'Ġ=', 'Ġ_n', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "has_regions = Region . objects . all ( ) . count ( ) > 1 \n"
Original    (016): ['has_regions', '=', 'Region', '.', 'objects', '.', 'all', '(', ')', '.', 'count', '(', ')', '>', '1', '\\n']
Tokenized   (022): ['<s>', 'has', '_', 'reg', 'ions', 'Ġ=', 'ĠRegion', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ)', 'Ġ>', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['has', '_', 'reg', 'ions', 'Ġ=', 'ĠRegion', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ)', 'Ġ>', 'Ġ1', 'Ġ\\', 'n']
Detokenized (016): ['has_regions', 'Ġ=', 'ĠRegion', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ)', 'Ġ>', 'Ġ1', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "bodies = LegislativeBody . objects . all ( ) . order_by ( , ) \n"
Original    (015): ['bodies', '=', 'LegislativeBody', '.', 'objects', '.', 'all', '(', ')', '.', 'order_by', '(', ',', ')', '\\n']
Tokenized   (022): ['<s>', 'b', 'odies', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['b', 'odies', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['bodies', 'Ġ=', 'ĠLegislativeBody', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "l_bodies = [ b for b in bodies if b in [ sd . legislative_body for sd in ScoreDisplay . objects . filter \n"
Original    (024): ['l_bodies', '=', '[', 'b', 'for', 'b', 'in', 'bodies', 'if', 'b', 'in', '[', 'sd', '.', 'legislative_body', 'for', 'sd', 'in', 'ScoreDisplay', '.', 'objects', '.', 'filter', '\\n']
Tokenized   (033): ['<s>', 'l', '_', 'b', 'odies', 'Ġ=', 'Ġ[', 'Ġb', 'Ġfor', 'Ġb', 'Ġin', 'Ġbodies', 'Ġif', 'Ġb', 'Ġin', 'Ġ[', 'Ġsd', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġfor', 'Ġsd', 'Ġin', 'ĠScore', 'Display', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['l', '_', 'b', 'odies', 'Ġ=', 'Ġ[', 'Ġb', 'Ġfor', 'Ġb', 'Ġin', 'Ġbodies', 'Ġif', 'Ġb', 'Ġin', 'Ġ[', 'Ġsd', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġfor', 'Ġsd', 'Ġin', 'ĠScore', 'Display', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ\\', 'n']
Detokenized (024): ['l_bodies', 'Ġ=', 'Ġ[', 'Ġb', 'Ġfor', 'Ġb', 'Ġin', 'Ġbodies', 'Ġif', 'Ġb', 'Ġin', 'Ġ[', 'Ġsd', 'Ġ.', 'Ġlegislative_body', 'Ġfor', 'Ġsd', 'Ġin', 'ĠScoreDisplay', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "cfg [ ] = datetime . now ( ) \n"
Original    (010): ['cfg', '[', ']', '=', 'datetime', '.', 'now', '(', ')', '\\n']
Tokenized   (014): ['<s>', 'cfg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['cfg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdat', 'etime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['cfg', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġdatetime', 'Ġ.', 'Ġnow', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ll = ModestMaps . Geo . Location ( pt1 . y , pt1 . x ) \n"
Original    (017): ['ll', '=', 'ModestMaps', '.', 'Geo', '.', 'Location', '(', 'pt1', '.', 'y', ',', 'pt1', '.', 'x', ')', '\\n']
Tokenized   (023): ['<s>', 'll', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠGeo', 'Ġ.', 'ĠLocation', 'Ġ(', 'Ġpt', '1', 'Ġ.', 'Ġy', 'Ġ,', 'Ġpt', '1', 'Ġ.', 'Ġx', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['ll', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠGeo', 'Ġ.', 'ĠLocation', 'Ġ(', 'Ġpt', '1', 'Ġ.', 'Ġy', 'Ġ,', 'Ġpt', '1', 'Ġ.', 'Ġx', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['ll', 'Ġ=', 'ĠModestMaps', 'Ġ.', 'ĠGeo', 'Ġ.', 'ĠLocation', 'Ġ(', 'Ġpt1', 'Ġ.', 'Ġy', 'Ġ,', 'Ġpt1', 'Ġ.', 'Ġx', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "provider = ModestMaps . WMS . Provider ( cfg [ ] , { \n"
Original    (014): ['provider', '=', 'ModestMaps', '.', 'WMS', '.', 'Provider', '(', 'cfg', '[', ']', ',', '{', '\\n']
Tokenized   (021): ['<s>', 'prov', 'ider', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠW', 'MS', 'Ġ.', 'ĠProvider', 'Ġ(', 'Ġcf', 'g', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ{', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['prov', 'ider', 'Ġ=', 'ĠModest', 'Maps', 'Ġ.', 'ĠW', 'MS', 'Ġ.', 'ĠProvider', 'Ġ(', 'Ġcf', 'g', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ{', 'Ġ\\', 'n']
Detokenized (014): ['provider', 'Ġ=', 'ĠModestMaps', 'Ġ.', 'ĠWMS', 'Ġ.', 'ĠProvider', 'Ġ(', 'Ġcfg', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ{', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "overlayImg = Image . blend ( overlayImg , ModestMaps . mapByExtent ( provider , ll , ur , dims ) . draw ( ) , \n"
Original    (026): ['overlayImg', '=', 'Image', '.', 'blend', '(', 'overlayImg', ',', 'ModestMaps', '.', 'mapByExtent', '(', 'provider', ',', 'll', ',', 'ur', ',', 'dims', ')', '.', 'draw', '(', ')', ',', '\\n']
Tokenized   (039): ['<s>', 'over', 'lay', 'Im', 'g', 'Ġ=', 'ĠImage', 'Ġ.', 'Ġblend', 'Ġ(', 'Ġoverlay', 'Im', 'g', 'Ġ,', 'ĠModest', 'Maps', 'Ġ.', 'Ġmap', 'By', 'Ext', 'ent', 'Ġ(', 'Ġprovider', 'Ġ,', 'Ġll', 'Ġ,', 'Ġur', 'Ġ,', 'Ġdim', 's', 'Ġ)', 'Ġ.', 'Ġdraw', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['over', 'lay', 'Im', 'g', 'Ġ=', 'ĠImage', 'Ġ.', 'Ġblend', 'Ġ(', 'Ġoverlay', 'Im', 'g', 'Ġ,', 'ĠModest', 'Maps', 'Ġ.', 'Ġmap', 'By', 'Ext', 'ent', 'Ġ(', 'Ġprovider', 'Ġ,', 'Ġll', 'Ġ,', 'Ġur', 'Ġ,', 'Ġdim', 's', 'Ġ)', 'Ġ.', 'Ġdraw', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (026): ['overlayImg', 'Ġ=', 'ĠImage', 'Ġ.', 'Ġblend', 'Ġ(', 'ĠoverlayImg', 'Ġ,', 'ĠModestMaps', 'Ġ.', 'ĠmapByExtent', 'Ġ(', 'Ġprovider', 'Ġ,', 'Ġll', 'Ġ,', 'Ġur', 'Ġ,', 'Ġdims', 'Ġ)', 'Ġ.', 'Ġdraw', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "fullImg . save ( settings . WEB_TEMP + ( % sha . hexdigest ( ) ) , , quality = 100 ) \n"
Original    (023): ['fullImg', '.', 'save', '(', 'settings', '.', 'WEB_TEMP', '+', '(', '%', 'sha', '.', 'hexdigest', '(', ')', ')', ',', ',', 'quality', '=', '100', ')', '\\n']
Tokenized   (035): ['<s>', 'full', 'Im', 'g', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġsettings', 'Ġ.', 'ĠWE', 'B', '_', 'T', 'EMP', 'Ġ+', 'Ġ(', 'Ġ%', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġquality', 'Ġ=', 'Ġ100', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['full', 'Im', 'g', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġsettings', 'Ġ.', 'ĠWE', 'B', '_', 'T', 'EMP', 'Ġ+', 'Ġ(', 'Ġ%', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġquality', 'Ġ=', 'Ġ100', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['fullImg', 'Ġ.', 'Ġsave', 'Ġ(', 'Ġsettings', 'Ġ.', 'ĠWEB_TEMP', 'Ġ+', 'Ġ(', 'Ġ%', 'Ġsha', 'Ġ.', 'Ġhexdigest', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġquality', 'Ġ=', 'Ġ100', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "CreatePDF ( page , result , show_error_as_pdf = True ) \n"
Original    (011): ['CreatePDF', '(', 'page', ',', 'result', ',', 'show_error_as_pdf', '=', 'True', ')', '\\n']
Tokenized   (021): ['<s>', 'Create', 'PDF', 'Ġ(', 'Ġpage', 'Ġ,', 'Ġresult', 'Ġ,', 'Ġshow', '_', 'error', '_', 'as', '_', 'pdf', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Create', 'PDF', 'Ġ(', 'Ġpage', 'Ġ,', 'Ġresult', 'Ġ,', 'Ġshow', '_', 'error', '_', 'as', '_', 'pdf', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['CreatePDF', 'Ġ(', 'Ġpage', 'Ġ,', 'Ġresult', 'Ġ,', 'Ġshow_error_as_pdf', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "body = LegislativeBody . objects . get ( id = int ( request . POST [ ] ) ) \n"
Original    (020): ['body', '=', 'LegislativeBody', '.', 'objects', '.', 'get', '(', 'id', '=', 'int', '(', 'request', '.', 'POST', '[', ']', ')', ')', '\\n']
Tokenized   (024): ['<s>', 'body', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['body', 'Ġ=', 'ĠLegislative', 'Body', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['body', 'Ġ=', 'ĠLegislativeBody', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ[', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "PlanReport . createreport . delay ( planid , stamp , req , language = translation . get_language ( ) ) \n"
Original    (021): ['PlanReport', '.', 'createreport', '.', 'delay', '(', 'planid', ',', 'stamp', ',', 'req', ',', 'language', '=', 'translation', '.', 'get_language', '(', ')', ')', '\\n']
Tokenized   (029): ['<s>', 'Plan', 'Report', 'Ġ.', 'Ġcreate', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['Plan', 'Report', 'Ġ.', 'Ġcreate', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['PlanReport', 'Ġ.', 'Ġcreatereport', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplanid', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget_language', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "stamp = request . POST . get ( , sha . hexdigest ( ) ) \n"
Original    (016): ['stamp', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'sha', '.', 'hexdigest', '(', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'st', 'amp', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['st', 'amp', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġsh', 'a', 'Ġ.', 'Ġhex', 'dig', 'est', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['stamp', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġsha', 'Ġ.', 'Ġhexdigest', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "CalculatorReport . createcalculatorreport . delay ( planid , stamp , req , language = translation . get_language ~~ else : \n"
Original    (021): ['CalculatorReport', '.', 'createcalculatorreport', '.', 'delay', '(', 'planid', ',', 'stamp', ',', 'req', ',', 'language', '=', 'translation', '.', 'get_language', '~~', 'else', ':', '\\n']
Tokenized   (035): ['<s>', 'Cal', 'cul', 'ator', 'Report', 'Ġ.', 'Ġcreate', 'cal', 'cul', 'ator', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['Cal', 'cul', 'ator', 'Report', 'Ġ.', 'Ġcreate', 'cal', 'cul', 'ator', 'report', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplan', 'id', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget', '_', 'language', 'Ġ', '~~', 'Ġelse', 'Ġ:', 'Ġ\\', 'n']
Detokenized (021): ['CalculatorReport', 'Ġ.', 'Ġcreatecalculatorreport', 'Ġ.', 'Ġdelay', 'Ġ(', 'Ġplanid', 'Ġ,', 'Ġstamp', 'Ġ,', 'Ġreq', 'Ġ,', 'Ġlanguage', 'Ġ=', 'Ġtranslation', 'Ġ.', 'Ġget_language', 'Ġ~~', 'Ġelse', 'Ġ:', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "site_id = Site . objects . get_current ( ) . id , \n"
Original    (013): ['site_id', '=', 'Site', '.', 'objects', '.', 'get_current', '(', ')', '.', 'id', ',', '\\n']
Tokenized   (020): ['<s>', 'site', '_', 'id', 'Ġ=', 'ĠSite', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'current', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['site', '_', 'id', 'Ġ=', 'ĠSite', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', '_', 'current', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['site_id', 'Ġ=', 'ĠSite', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget_current', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġid', 'Ġ,', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "from_id = int ( request . POST . get ( , - 1 ) ) \n"
Original    (016): ['from_id', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', '-', '1', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'from', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['from', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['from_id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "to_id = int ( request . POST . get ( , None ) ) \n"
Original    (015): ['to_id', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', 'None', ')', ')', '\\n']
Tokenized   (020): ['<s>', 'to', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['to', '_', 'id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['to_id', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "from_districts = filter ( lambda d : True if d . district_id == from_id else False , all_districts to_district = filter ( lambda d : True if d . district_id == to_id else False , all_districts ) [ 0 ] \n"
Original    (041): ['from_districts', '=', 'filter', '(', 'lambda', 'd', ':', 'True', 'if', 'd', '.', 'district_id', '==', 'from_id', 'else', 'False', ',', 'all_districts', 'to_district', '=', 'filter', '(', 'lambda', 'd', ':', 'True', 'if', 'd', '.', 'district_id', '==', 'to_id', 'else', 'False', ',', 'all_districts', ')', '[', '0', ']', '\\n']
Tokenized   (067): ['<s>', 'from', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġfrom', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġto', '_', 'dist', 'rict', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġto', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (065): ['from', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġfrom', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġto', '_', 'dist', 'rict', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict', '_', 'id', 'Ġ==', 'Ġto', '_', 'id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall', '_', 'dist', 'rict', 's', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (041): ['from_districts', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict_id', 'Ġ==', 'Ġfrom_id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall_districts', 'Ġto_district', 'Ġ=', 'Ġfilter', 'Ġ(', 'Ġlambda', 'Ġd', 'Ġ:', 'ĠTrue', 'Ġif', 'Ġd', 'Ġ.', 'Ġdistrict_id', 'Ġ==', 'Ġto_id', 'Ġelse', 'ĠFalse', 'Ġ,', 'Ġall_districts', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 65
===================================================================
Hidden states:  (13, 41, 768)
# Extracted words:  41
Sentence         : "inverse = request . REQUEST [ ] == if in request . REQUEST else False \n"
Original    (016): ['inverse', '=', 'request', '.', 'REQUEST', '[', ']', '==', 'if', 'in', 'request', '.', 'REQUEST', 'else', 'False', '\\n']
Tokenized   (022): ['<s>', 'in', 'verse', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġif', 'Ġin', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġelse', 'ĠFalse', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['in', 'verse', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġif', 'Ġin', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġelse', 'ĠFalse', 'Ġ\\', 'n']
Detokenized (016): ['inverse', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġ[', 'Ġ]', 'Ġ==', 'Ġif', 'Ġin', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġelse', 'ĠFalse', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "my_context . update ( plan . compute_splits ( layer , version = version , inverse = inverse , extended last_item = layer is layers [ - 1 ] \n"
Original    (029): ['my_context', '.', 'update', '(', 'plan', '.', 'compute_splits', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', ',', 'extended', 'last_item', '=', 'layer', 'is', 'layers', '[', '-', '1', ']', '\\n']
Tokenized   (039): ['<s>', 'my', '_', 'context', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġcompute', '_', 'spl', 'its', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġ,', 'Ġextended', 'Ġlast', '_', 'item', 'Ġ=', 'Ġlayer', 'Ġis', 'Ġlayers', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['my', '_', 'context', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġcompute', '_', 'spl', 'its', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġ,', 'Ġextended', 'Ġlast', '_', 'item', 'Ġ=', 'Ġlayer', 'Ġis', 'Ġlayers', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\', 'n']
Detokenized (029): ['my_context', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġcompute_splits', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġ,', 'Ġextended', 'Ġlast_item', 'Ġ=', 'Ġlayer', 'Ġis', 'Ġlayers', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "community_info = plan . get_community_type_info ( layer , version = version , inverse = inverse if community_info is not None : \n"
Original    (022): ['community_info', '=', 'plan', '.', 'get_community_type_info', '(', 'layer', ',', 'version', '=', 'version', ',', 'inverse', '=', 'inverse', 'if', 'community_info', 'is', 'not', 'None', ':', '\\n']
Tokenized   (035): ['<s>', 'community', '_', 'info', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġget', '_', 'community', '_', 'type', '_', 'info', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġif', 'Ġcommunity', '_', 'info', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['community', '_', 'info', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġget', '_', 'community', '_', 'type', '_', 'info', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġif', 'Ġcommunity', '_', 'info', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ:', 'Ġ\\', 'n']
Detokenized (022): ['community_info', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġget_community_type_info', 'Ġ(', 'Ġlayer', 'Ġ,', 'Ġversion', 'Ġ=', 'Ġversion', 'Ġ,', 'Ġinverse', 'Ġ=', 'Ġinverse', 'Ġif', 'Ġcommunity_info', 'Ġis', 'Ġnot', 'ĠNone', 'Ġ:', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "html += report . render ( calc_context ) \n"
Original    (009): ['html', '+=', 'report', '.', 'render', '(', 'calc_context', ')', '\\n']
Tokenized   (014): ['<s>', 'html', 'Ġ+=', 'Ġreport', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġcalc', '_', 'context', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['html', 'Ġ+=', 'Ġreport', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġcalc', '_', 'context', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['html', 'Ġ+=', 'Ġreport', 'Ġ.', 'Ġrender', 'Ġ(', 'Ġcalc_context', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "geounit_ids = string . split ( request . REQUEST [ "geounits" ] , "|" ) \n"
Original    (016): ['geounit_ids', '=', 'string', '.', 'split', '(', 'request', '.', 'REQUEST', '[', '"geounits"', ']', ',', '"|"', ')', '\\n']
Tokenized   (030): ['<s>', 'ge', 'oun', 'it', '_', 'ids', 'Ġ=', 'Ġstring', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'ge', 'oun', 'its', '"', 'Ġ]', 'Ġ,', 'Ġ"', '|', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['ge', 'oun', 'it', '_', 'ids', 'Ġ=', 'Ġstring', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠRE', 'QUEST', 'Ġ[', 'Ġ"', 'ge', 'oun', 'its', '"', 'Ġ]', 'Ġ,', 'Ġ"', '|', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['geounit_ids', 'Ġ=', 'Ġstring', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠREQUEST', 'Ġ[', 'Ġ"geounits"', 'Ġ]', 'Ġ,', 'Ġ"|"', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "max_version = max ( [ d . version for d in districts ] ) \n"
Original    (015): ['max_version', '=', 'max', '(', '[', 'd', '.', 'version', 'for', 'd', 'in', 'districts', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'max', '_', 'version', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġversion', 'Ġfor', 'Ġd', 'Ġin', 'Ġdistricts', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['max', '_', 'version', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġversion', 'Ġfor', 'Ġd', 'Ġin', 'Ġdistricts', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['max_version', 'Ġ=', 'Ġmax', 'Ġ(', 'Ġ[', 'Ġd', 'Ġ.', 'Ġversion', 'Ġfor', 'Ġd', 'Ġin', 'Ġdistricts', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "can_undo = max_version > plan . min_version \n"
Original    (008): ['can_undo', '=', 'max_version', '>', 'plan', '.', 'min_version', '\\n']
Tokenized   (017): ['<s>', 'can', '_', 'undo', 'Ġ=', 'Ġmax', '_', 'version', 'Ġ>', 'Ġplan', 'Ġ.', 'Ġmin', '_', 'version', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['can', '_', 'undo', 'Ġ=', 'Ġmax', '_', 'version', 'Ġ>', 'Ġplan', 'Ġ.', 'Ġmin', '_', 'version', 'Ġ\\', 'n']
Detokenized (008): ['can_undo', 'Ġ=', 'Ġmax_version', 'Ġ>', 'Ġplan', 'Ġ.', 'Ġmin_version', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bbox = tuple ( map ( lambda x : float ( x ) , bbox . split ( ) ) ) \n"
Original    (022): ['bbox', '=', 'tuple', '(', 'map', '(', 'lambda', 'x', ':', 'float', '(', 'x', ')', ',', 'bbox', '.', 'split', '(', ')', ')', ')', '\\n']
Tokenized   (027): ['<s>', 'b', 'box', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġb', 'box', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['b', 'box', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġb', 'box', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['bbox', 'Ġ=', 'Ġtuple', 'Ġ(', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġbbox', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "wkt = wkt . replace ( , ) . replace ( , ) \n"
Original    (014): ['wkt', '=', 'wkt', '.', 'replace', '(', ',', ')', '.', 'replace', '(', ',', ')', '\\n']
Tokenized   (019): ['<s>', 'w', 'kt', 'Ġ=', 'Ġw', 'kt', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['w', 'kt', 'Ġ=', 'Ġw', 'kt', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['wkt', 'Ġ=', 'Ġwkt', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ.', 'Ġreplace', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "districts = [ d . id for d in plan . get_districts_at_version ( version , include_geom = True ) if locked = District . objects . filter ( id__in = districts ) . collect ( ) \n"
Original    (037): ['districts', '=', '[', 'd', '.', 'id', 'for', 'd', 'in', 'plan', '.', 'get_districts_at_version', '(', 'version', ',', 'include_geom', '=', 'True', ')', 'if', 'locked', '=', 'District', '.', 'objects', '.', 'filter', '(', 'id__in', '=', 'districts', ')', '.', 'collect', '(', ')', '\\n']
Tokenized   (055): ['<s>', 'dist', 'rict', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ.', 'Ġid', 'Ġfor', 'Ġd', 'Ġin', 'Ġplan', 'Ġ.', 'Ġget', '_', 'dist', 'rict', 's', '_', 'at', '_', 'version', 'Ġ(', 'Ġversion', 'Ġ,', 'Ġinclude', '_', 'ge', 'om', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġ=', 'ĠDistrict', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġid', '__', 'in', 'Ġ=', 'Ġdistricts', 'Ġ)', 'Ġ.', 'Ġcollect', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (053): ['dist', 'rict', 's', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ.', 'Ġid', 'Ġfor', 'Ġd', 'Ġin', 'Ġplan', 'Ġ.', 'Ġget', '_', 'dist', 'rict', 's', '_', 'at', '_', 'version', 'Ġ(', 'Ġversion', 'Ġ,', 'Ġinclude', '_', 'ge', 'om', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġ=', 'ĠDistrict', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġid', '__', 'in', 'Ġ=', 'Ġdistricts', 'Ġ)', 'Ġ.', 'Ġcollect', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (037): ['districts', 'Ġ=', 'Ġ[', 'Ġd', 'Ġ.', 'Ġid', 'Ġfor', 'Ġd', 'Ġin', 'Ġplan', 'Ġ.', 'Ġget_districts_at_version', 'Ġ(', 'Ġversion', 'Ġ,', 'Ġinclude_geom', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġ=', 'ĠDistrict', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġid__in', 'Ġ=', 'Ġdistricts', 'Ġ)', 'Ġ.', 'Ġcollect', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 53
===================================================================
Hidden states:  (13, 37, 768)
# Extracted words:  37
Sentence         : "locked_buffered = locked . simplify ( 100 , True ) . buffer ( 100 ) if locked else None \n"
Original    (020): ['locked_buffered', '=', 'locked', '.', 'simplify', '(', '100', ',', 'True', ')', '.', 'buffer', '(', '100', ')', 'if', 'locked', 'else', 'None', '\\n']
Tokenized   (026): ['<s>', 'locked', '_', 'buff', 'ered', 'Ġ=', 'Ġlocked', 'Ġ.', 'Ġsimplify', 'Ġ(', 'Ġ100', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġbuffer', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġelse', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['locked', '_', 'buff', 'ered', 'Ġ=', 'Ġlocked', 'Ġ.', 'Ġsimplify', 'Ġ(', 'Ġ100', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġbuffer', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġelse', 'ĠNone', 'Ġ\\', 'n']
Detokenized (020): ['locked_buffered', 'Ġ=', 'Ġlocked', 'Ġ.', 'Ġsimplify', 'Ġ(', 'Ġ100', 'Ġ,', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġbuffer', 'Ġ(', 'Ġ100', 'Ġ)', 'Ġif', 'Ġlocked', 'Ġelse', 'ĠNone', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "filtered = Geolevel . objects . get ( id = geolevel ) . geounit_set . filter ( selection ) \n"
Original    (020): ['filtered', '=', 'Geolevel', '.', 'objects', '.', 'get', '(', 'id', '=', 'geolevel', ')', '.', 'geounit_set', '.', 'filter', '(', 'selection', ')', '\\n']
Tokenized   (032): ['<s>', 'fil', 'tered', 'Ġ=', 'ĠGe', 'ole', 'vel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġge', 'ole', 'vel', 'Ġ)', 'Ġ.', 'Ġge', 'oun', 'it', '_', 'set', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselection', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['fil', 'tered', 'Ġ=', 'ĠGe', 'ole', 'vel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġge', 'ole', 'vel', 'Ġ)', 'Ġ.', 'Ġge', 'oun', 'it', '_', 'set', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselection', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['filtered', 'Ġ=', 'ĠGeolevel', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġget', 'Ġ(', 'Ġid', 'Ġ=', 'Ġgeolevel', 'Ġ)', 'Ġ.', 'Ġgeounit_set', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselection', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "pfilter = Q ( legislative_body = leg_body ) & Q ( is_valid = True ) \n"
Original    (016): ['pfilter', '=', 'Q', '(', 'legislative_body', '=', 'leg_body', ')', '&', 'Q', '(', 'is_valid', '=', 'True', ')', '\\n']
Tokenized   (026): ['<s>', 'p', 'filter', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġlegislative', '_', 'body', 'Ġ=', 'Ġleg', '_', 'body', 'Ġ)', 'Ġ&', 'ĠQ', 'Ġ(', 'Ġis', '_', 'valid', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['p', 'filter', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġlegislative', '_', 'body', 'Ġ=', 'Ġleg', '_', 'body', 'Ġ)', 'Ġ&', 'ĠQ', 'Ġ(', 'Ġis', '_', 'valid', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['pfilter', 'Ġ=', 'ĠQ', 'Ġ(', 'Ġlegislative_body', 'Ġ=', 'Ġleg_body', 'Ġ)', 'Ġ&', 'ĠQ', 'Ġ(', 'Ġis_valid', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "panels = display . scorepanel_set . all ( ) . order_by ( ) \n"
Original    (014): ['panels', '=', 'display', '.', 'scorepanel_set', '.', 'all', '(', ')', '.', 'order_by', '(', ')', '\\n']
Tokenized   (023): ['<s>', 'pan', 'els', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['pan', 'els', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġscore', 'panel', '_', 'set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['panels', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġscorepanel_set', 'Ġ.', 'Ġall', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "writer . writerow ( [ , , ] + [ p . __unicode__ ( ) for p in panels ] ) \n"
Original    (022): ['writer', '.', 'writerow', '(', '[', ',', ',', ']', '+', '[', 'p', '.', '__unicode__', '(', ')', 'for', 'p', 'in', 'panels', ']', ')', '\\n']
Tokenized   (029): ['<s>', 'writer', 'Ġ.', 'Ġwriter', 'ow', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ+', 'Ġ[', 'Ġp', 'Ġ.', 'Ġ__', 'unic', 'ode', '__', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpanels', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['writer', 'Ġ.', 'Ġwriter', 'ow', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ+', 'Ġ[', 'Ġp', 'Ġ.', 'Ġ__', 'unic', 'ode', '__', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpanels', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['writer', 'Ġ.', 'Ġwriterow', 'Ġ(', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ+', 'Ġ[', 'Ġp', 'Ġ.', 'Ġ__unicode__', 'Ġ(', 'Ġ)', 'Ġfor', 'Ġp', 'Ġin', 'Ġpanels', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "rows = int ( request . POST . get ( , 10 ) ) \n"
Original    (015): ['rows', '=', 'int', '(', 'request', '.', 'POST', '.', 'get', '(', ',', '10', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'rows', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['rows', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['rows', 'Ġ=', 'Ġint', 'Ġ(', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "sidx = request . POST . get ( , ) \n"
Original    (011): ['sidx', '=', 'request', '.', 'POST', '.', 'get', '(', ',', ')', '\\n']
Tokenized   (015): ['<s>', 'sid', 'x', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['sid', 'x', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['sidx', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "owner_filter = request . POST . get ( ) ; \n"
Original    (011): ['owner_filter', '=', 'request', '.', 'POST', '.', 'get', '(', ')', ';', '\\n']
Tokenized   (016): ['<s>', 'owner', '_', 'filter', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['owner', '_', 'filter', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ;', 'Ġ\\', 'n']
Detokenized (011): ['owner_filter', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ;', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "body_pk = int ( body_pk ) if body_pk else body_pk ; \n"
Original    (012): ['body_pk', '=', 'int', '(', 'body_pk', ')', 'if', 'body_pk', 'else', 'body_pk', ';', '\\n']
Tokenized   (027): ['<s>', 'body', '_', 'p', 'k', 'Ġ=', 'Ġint', 'Ġ(', 'Ġbody', '_', 'p', 'k', 'Ġ)', 'Ġif', 'Ġbody', '_', 'p', 'k', 'Ġelse', 'Ġbody', '_', 'p', 'k', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['body', '_', 'p', 'k', 'Ġ=', 'Ġint', 'Ġ(', 'Ġbody', '_', 'p', 'k', 'Ġ)', 'Ġif', 'Ġbody', '_', 'p', 'k', 'Ġelse', 'Ġbody', '_', 'p', 'k', 'Ġ;', 'Ġ\\', 'n']
Detokenized (012): ['body_pk', 'Ġ=', 'Ġint', 'Ġ(', 'Ġbody_pk', 'Ġ)', 'Ġif', 'Ġbody_pk', 'Ġelse', 'Ġbody_pk', 'Ġ;', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "search = request . POST . get ( , False ) ; \n"
Original    (013): ['search', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'False', ')', ';', '\\n']
Tokenized   (016): ['<s>', 'search', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['search', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ;', 'Ġ\\', 'n']
Detokenized (013): ['search', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ;', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "search_string = request . POST . get ( , ) ; \n"
Original    (012): ['search_string', '=', 'request', '.', 'POST', '.', 'get', '(', ',', ')', ';', '\\n']
Tokenized   (017): ['<s>', 'search', '_', 'string', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['search', '_', 'string', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ;', 'Ġ\\', 'n']
Detokenized (012): ['search_string', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'Ġ)', 'Ġ;', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "is_community = request . POST . get ( , False ) == ; \n"
Original    (014): ['is_community', '=', 'request', '.', 'POST', '.', 'get', '(', ',', 'False', ')', '==', ';', '\\n']
Tokenized   (019): ['<s>', 'is', '_', 'community', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ==', 'Ġ;', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['is', '_', 'community', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ==', 'Ġ;', 'Ġ\\', 'n']
Detokenized (014): ['is_community', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ,', 'ĠFalse', 'Ġ)', 'Ġ==', 'Ġ;', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "all_plans = Plan . objects . filter ( available , not_creating , search_filter , community_filter ) . order_by \n"
Original    (019): ['all_plans', '=', 'Plan', '.', 'objects', '.', 'filter', '(', 'available', ',', 'not_creating', ',', 'search_filter', ',', 'community_filter', ')', '.', 'order_by', '\\n']
Tokenized   (034): ['<s>', 'all', '_', 'pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġavailable', 'Ġ,', 'Ġnot', '_', 'creat', 'ing', 'Ġ,', 'Ġsearch', '_', 'filter', 'Ġ,', 'Ġcommunity', '_', 'filter', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['all', '_', 'pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġavailable', 'Ġ,', 'Ġnot', '_', 'creat', 'ing', 'Ġ,', 'Ġsearch', '_', 'filter', 'Ġ,', 'Ġcommunity', '_', 'filter', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ\\', 'n']
Detokenized (019): ['all_plans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġavailable', 'Ġ,', 'Ġnot_creating', 'Ġ,', 'Ġsearch_filter', 'Ġ,', 'Ġcommunity_filter', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "all_districts = ( ) \n"
Original    (005): ['all_districts', '=', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'all', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['all', '_', 'dist', 'rict', 's', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['all_districts', 'Ġ=', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "_ ( ) ) \n"
Original    (005): ['_', '(', ')', ')', '\\n']
Tokenized   (008): ['<s>', '_', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['_', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['_', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "user_functions = ScoreFunction . objects . filter ( selectable_bodies = plan . legislative_body ) . order_by for f in user_functions : \n"
Original    (022): ['user_functions', '=', 'ScoreFunction', '.', 'objects', '.', 'filter', '(', 'selectable_bodies', '=', 'plan', '.', 'legislative_body', ')', '.', 'order_by', 'for', 'f', 'in', 'user_functions', ':', '\\n']
Tokenized   (040): ['<s>', 'user', '_', 'fun', 'ctions', 'Ġ=', 'ĠScore', 'Function', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġfor', 'Ġf', 'Ġin', 'Ġuser', '_', 'fun', 'ctions', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (038): ['user', '_', 'fun', 'ctions', 'Ġ=', 'ĠScore', 'Function', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselect', 'able', '_', 'b', 'odies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġfor', 'Ġf', 'Ġin', 'Ġuser', '_', 'fun', 'ctions', 'Ġ:', 'Ġ\\', 'n']
Detokenized (022): ['user_functions', 'Ġ=', 'ĠScoreFunction', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġselectable_bodies', 'Ġ=', 'Ġplan', 'Ġ.', 'Ġlegislative_body', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġfor', 'Ġf', 'Ġin', 'Ġuser_functions', 'Ġ:', 'Ġ\\n']
Counter: 38
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : ""%s_sidebar_demo" % plan . legislative_body . name , \n"
Original    (009): ['"%s_sidebar_demo"', '%', 'plan', '.', 'legislative_body', '.', 'name', ',', '\\n']
Tokenized   (023): ['<s>', '"', '%', 's', '_', 'side', 'bar', '_', 'dem', 'o', '"', 'Ġ%', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['"', '%', 's', '_', 'side', 'bar', '_', 'dem', 'o', '"', 'Ġ%', 'Ġplan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['"%s_sidebar_demo"', 'Ġ%', 'Ġplan', 'Ġ.', 'Ġlegislative_body', 'Ġ.', 'Ġname', 'Ġ,', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "plan . legislative_body . name ) \n"
Original    (007): ['plan', '.', 'legislative_body', '.', 'name', ')', '\\n']
Tokenized   (012): ['<s>', 'plan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['plan', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['plan', 'Ġ.', 'Ġlegislative_body', 'Ġ.', 'Ġname', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "functions = map ( lambda x : int ( x ) , functions ) \n"
Original    (015): ['functions', '=', 'map', '(', 'lambda', 'x', ':', 'int', '(', 'x', ')', ',', 'functions', ')', '\\n']
Tokenized   (019): ['<s>', 'fun', 'ctions', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfunctions', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['fun', 'ctions', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfunctions', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['functions', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġint', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfunctions', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "display = display . copy_from ( display = demo , title = request . POST . get ( ) , owner = result [ ] = True \n"
Original    (028): ['display', '=', 'display', '.', 'copy_from', '(', 'display', '=', 'demo', ',', 'title', '=', 'request', '.', 'POST', '.', 'get', '(', ')', ',', 'owner', '=', 'result', '[', ']', '=', 'True', '\\n']
Tokenized   (033): ['<s>', 'display', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġcopy', '_', 'from', 'Ġ(', 'Ġdisplay', 'Ġ=', 'Ġdemo', 'Ġ,', 'Ġtitle', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġowner', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['display', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġcopy', '_', 'from', 'Ġ(', 'Ġdisplay', 'Ġ=', 'Ġdemo', 'Ġ,', 'Ġtitle', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġowner', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\', 'n']
Detokenized (028): ['display', 'Ġ=', 'Ġdisplay', 'Ġ.', 'Ġcopy_from', 'Ġ(', 'Ġdisplay', 'Ġ=', 'Ġdemo', 'Ġ,', 'Ġtitle', 'Ġ=', 'Ġrequest', 'Ġ.', 'ĠPOST', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġowner', 'Ġ=', 'Ġresult', 'Ġ[', 'Ġ]', 'Ġ=', 'ĠTrue', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 28, 768)
# Extracted words:  28
Sentence         : "version = min ( plan . version , int ( version ) ) \n"
Original    (014): ['version', '=', 'min', '(', 'plan', '.', 'version', ',', 'int', '(', 'version', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'version', 'Ġ=', 'Ġmin', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġint', 'Ġ(', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['version', 'Ġ=', 'Ġmin', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġint', 'Ġ(', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['version', 'Ġ=', 'Ġmin', 'Ġ(', 'Ġplan', 'Ġ.', 'Ġversion', 'Ġ,', 'Ġint', 'Ġ(', 'Ġversion', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "Comment . objects . filter ( object_pk = district . id , content_type = ct ) . delete ( ) \n"
Original    (021): ['Comment', '.', 'objects', '.', 'filter', '(', 'object_pk', '=', 'district', '.', 'id', ',', 'content_type', '=', 'ct', ')', '.', 'delete', '(', ')', '\\n']
Tokenized   (030): ['<s>', 'Comment', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġobject', '_', 'p', 'k', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ,', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġc', 't', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['Comment', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġobject', '_', 'p', 'k', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ,', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġc', 't', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['Comment', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġobject_pk', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ,', 'Ġcontent_type', 'Ġ=', 'Ġct', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "TaggedItem . objects . filter ( tag__in = tset , object_id = district . id ) . delete ( ) \n"
Original    (021): ['TaggedItem', '.', 'objects', '.', 'filter', '(', 'tag__in', '=', 'tset', ',', 'object_id', '=', 'district', '.', 'id', ')', '.', 'delete', '(', ')', '\\n']
Tokenized   (031): ['<s>', 'T', 'agged', 'Item', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġtag', '__', 'in', 'Ġ=', 'Ġt', 'set', 'Ġ,', 'Ġobject', '_', 'id', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): ['T', 'agged', 'Item', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġtag', '__', 'in', 'Ġ=', 'Ġt', 'set', 'Ġ,', 'Ġobject', '_', 'id', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (021): ['TaggedItem', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġtag__in', 'Ġ=', 'Ġtset', 'Ġ,', 'Ġobject_id', 'Ġ=', 'Ġdistrict', 'Ġ.', 'Ġid', 'Ġ)', 'Ġ.', 'Ġdelete', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "geolevel = plans [ 0 ] . legislative_body . get_geolevels ( ) [ 0 ] \n"
Original    (016): ['geolevel', '=', 'plans', '[', '0', ']', '.', 'legislative_body', '.', 'get_geolevels', '(', ')', '[', '0', ']', '\\n']
Tokenized   (028): ['<s>', 'ge', 'ole', 'vel', 'Ġ=', 'Ġplans', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġget', '_', 'ge', 'ole', 'vel', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['ge', 'ole', 'vel', 'Ġ=', 'Ġplans', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlegislative', '_', 'body', 'Ġ.', 'Ġget', '_', 'ge', 'ole', 'vel', 's', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (016): ['geolevel', 'Ġ=', 'Ġplans', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġlegislative_body', 'Ġ.', 'Ġget_geolevels', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "plans = Plan . objects . filter ( is_shared = True ) . order_by ( ) [ 0 : 10 ] \n"
Original    (022): ['plans', '=', 'Plan', '.', 'objects', '.', 'filter', '(', 'is_shared', '=', 'True', ')', '.', 'order_by', '(', ')', '[', '0', ':', '10', ']', '\\n']
Tokenized   (030): ['<s>', 'pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġis', '_', 'shared', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġ10', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (028): ['pl', 'ans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġis', '_', 'shared', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġ10', 'Ġ]', 'Ġ\\', 'n']
Detokenized (022): ['plans', 'Ġ=', 'ĠPlan', 'Ġ.', 'Ġobjects', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġis_shared', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ:', 'Ġ10', 'Ġ]', 'Ġ\\n']
Counter: 28
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "write_page = 0 if write_page == 1 else write_page + 1 \n"
Original    (012): ['write_page', '=', '0', 'if', 'write_page', '==', '1', 'else', 'write_page', '+', '1', '\\n']
Tokenized   (021): ['<s>', 'write', '_', 'page', 'Ġ=', 'Ġ0', 'Ġif', 'Ġwrite', '_', 'page', 'Ġ==', 'Ġ1', 'Ġelse', 'Ġwrite', '_', 'page', 'Ġ+', 'Ġ1', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['write', '_', 'page', 'Ġ=', 'Ġ0', 'Ġif', 'Ġwrite', '_', 'page', 'Ġ==', 'Ġ1', 'Ġelse', 'Ġwrite', '_', 'page', 'Ġ+', 'Ġ1', 'Ġ\\', 'n']
Detokenized (012): ['write_page', 'Ġ=', 'Ġ0', 'Ġif', 'Ġwrite_page', 'Ġ==', 'Ġ1', 'Ġelse', 'Ġwrite_page', 'Ġ+', 'Ġ1', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "init_sum = 1 if i == 0 else 0 \n"
Original    (010): ['init_sum', '=', '1', 'if', 'i', '==', '0', 'else', '0', '\\n']
Tokenized   (015): ['<s>', 'init', '_', 'sum', 'Ġ=', 'Ġ1', 'Ġif', 'Ġi', 'Ġ==', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['init', '_', 'sum', 'Ġ=', 'Ġ1', 'Ġif', 'Ġi', 'Ġ==', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\', 'n']
Detokenized (010): ['init_sum', 'Ġ=', 'Ġ1', 'Ġif', 'Ġi', 'Ġ==', 'Ġ0', 'Ġelse', 'Ġ0', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "mem_d0 . read_nonblocking ( 1 , write_addr , mesh_size - 2 ) \n"
Original    (013): ['mem_d0', '.', 'read_nonblocking', '(', '1', ',', 'write_addr', ',', 'mesh_size', '-', '2', ')', '\\n']
Tokenized   (026): ['<s>', 'mem', '_', 'd', '0', 'Ġ.', 'Ġread', '_', 'non', 'blocking', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġwrite', '_', 'addr', 'Ġ,', 'Ġmesh', '_', 'size', 'Ġ-', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['mem', '_', 'd', '0', 'Ġ.', 'Ġread', '_', 'non', 'blocking', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġwrite', '_', 'addr', 'Ġ,', 'Ġmesh', '_', 'size', 'Ġ-', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['mem_d0', 'Ġ.', 'Ġread_nonblocking', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġwrite_addr', 'Ġ,', 'Ġmesh_size', 'Ġ-', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "write_addr += mesh_size * DSIZE \n"
Original    (006): ['write_addr', '+=', 'mesh_size', '*', 'DSIZE', '\\n']
Tokenized   (014): ['<s>', 'write', '_', 'addr', 'Ġ+=', 'Ġmesh', '_', 'size', 'Ġ*', 'ĠD', 'SIZE', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['write', '_', 'addr', 'Ġ+=', 'Ġmesh', '_', 'size', 'Ġ*', 'ĠD', 'SIZE', 'Ġ\\', 'n']
Detokenized (006): ['write_addr', 'Ġ+=', 'Ġmesh_size', 'Ġ*', 'ĠDSIZE', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "sub_id_base = ( 10 if sub_id_m . group ( 1 ) . count ( "\'d" ) > 0 else \n"
Original    (020): ['sub_id_base', '=', '(', '10', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'d"', ')', '>', '0', 'else', '\\n']
Tokenized   (034): ['<s>', 'sub', '_', 'id', '_', 'base', 'Ġ=', 'Ġ(', 'Ġ10', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'd', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['sub', '_', 'id', '_', 'base', 'Ġ=', 'Ġ(', 'Ġ10', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'd', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n']
Detokenized (020): ['sub_id_base', 'Ġ=', 'Ġ(', 'Ġ10', 'Ġif', 'Ġsub_id_m', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\\'d"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "16 if sub_id_m . group ( 1 ) . count ( "\'h" ) > 0 else \n"
Original    (017): ['16', 'if', 'sub_id_m', '.', 'group', '(', '1', ')', '.', 'count', '(', '"\\\'h"', ')', '>', '0', 'else', '\\n']
Tokenized   (027): ['<s>', '16', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'h', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['16', 'Ġif', 'Ġsub', '_', 'id', '_', 'm', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\', "'", 'h', '"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\', 'n']
Detokenized (017): ['16', 'Ġif', 'Ġsub_id_m', 'Ġ.', 'Ġgroup', 'Ġ(', 'Ġ1', 'Ġ)', 'Ġ.', 'Ġcount', 'Ġ(', 'Ġ"\\\'h"', 'Ġ)', 'Ġ>', 'Ġ0', 'Ġelse', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "10 ) \n"
Original    (003): ['10', ')', '\\n']
Tokenized   (006): ['<s>', '10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (004): ['10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (003): ['10', 'Ġ)', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "optparser . add_option ( "--noreorder" , action = "store_true" , dest = "noreorder" , \n"
Original    (015): ['optparser', '.', 'add_option', '(', '"--noreorder"', ',', 'action', '=', '"store_true"', ',', 'dest', '=', '"noreorder"', ',', '\\n']
Tokenized   (034): ['<s>', 'opt', 'parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ"', '--', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ"', 'store', '_', 'true', '"', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ"', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['opt', 'parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ"', '--', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ"', 'store', '_', 'true', '"', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ"', 'n', 'ore', 'order', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (015): ['optparser', 'Ġ.', 'Ġadd_option', 'Ġ(', 'Ġ"--noreorder"', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ"store_true"', 'Ġ,', 'Ġdest', 'Ġ=', 'Ġ"noreorder"', 'Ġ,', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "truenode = replaceUndefined ( tree . truenode , termname ) \n"
Original    (011): ['truenode', '=', 'replaceUndefined', '(', 'tree', '.', 'truenode', ',', 'termname', ')', '\\n']
Tokenized   (022): ['<s>', 't', 'ru', 'en', 'ode', 'Ġ=', 'Ġreplace', 'Und', 'efined', 'Ġ(', 'Ġtree', 'Ġ.', 'Ġtru', 'en', 'ode', 'Ġ,', 'Ġterm', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['t', 'ru', 'en', 'ode', 'Ġ=', 'Ġreplace', 'Und', 'efined', 'Ġ(', 'Ġtree', 'Ġ.', 'Ġtru', 'en', 'ode', 'Ġ,', 'Ġterm', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['truenode', 'Ġ=', 'ĠreplaceUndefined', 'Ġ(', 'Ġtree', 'Ġ.', 'Ġtruenode', 'Ġ,', 'Ġtermname', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "codedir = os . path . dirname ( os . path . dirname ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) ) + \n"
Original    (033): ['codedir', '=', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'dirname', '(', 'os', '.', 'path', '.', 'abspath', '(', '__file__', ')', ')', ')', ')', '+', '\\n']
Tokenized   (043): ['<s>', 'coded', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġ\\', 'n', '</s>']
Filtered   (041): ['coded', 'ir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdir', 'name', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabs', 'path', 'Ġ(', 'Ġ__', 'file', '__', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġ\\', 'n']
Detokenized (033): ['codedir', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġdirname', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġabspath', 'Ġ(', 'Ġ__file__', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ+', 'Ġ\\n']
Counter: 41
===================================================================
Hidden states:  (13, 33, 768)
# Extracted words:  33
Sentence         : "analyzer = VerilogDataflowAnalyzer ( filelist , topmodule , \n"
Original    (009): ['analyzer', '=', 'VerilogDataflowAnalyzer', '(', 'filelist', ',', 'topmodule', ',', '\\n']
Tokenized   (021): ['<s>', 'analy', 'zer', 'Ġ=', 'ĠVer', 'il', 'og', 'Data', 'flow', 'Analy', 'zer', 'Ġ(', 'Ġfile', 'list', 'Ġ,', 'Ġtop', 'module', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['analy', 'zer', 'Ġ=', 'ĠVer', 'il', 'og', 'Data', 'flow', 'Analy', 'zer', 'Ġ(', 'Ġfile', 'list', 'Ġ,', 'Ġtop', 'module', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['analyzer', 'Ġ=', 'ĠVerilogDataflowAnalyzer', 'Ġ(', 'Ġfilelist', 'Ġ,', 'Ġtopmodule', 'Ġ,', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "constlist = optimizer . getConstlist ( ) \n"
Original    (008): ['constlist', '=', 'optimizer', '.', 'getConstlist', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'const', 'list', 'Ġ=', 'Ġoptim', 'izer', 'Ġ.', 'Ġget', 'Const', 'list', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['const', 'list', 'Ġ=', 'Ġoptim', 'izer', 'Ġ.', 'Ġget', 'Const', 'list', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['constlist', 'Ġ=', 'Ġoptimizer', 'Ġ.', 'ĠgetConstlist', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "interval = m . Parameter ( , 16 ) \n"
Original    (010): ['interval', '=', 'm', '.', 'Parameter', '(', ',', '16', ')', '\\n']
Tokenized   (015): ['<s>', 'inter', 'val', 'Ġ=', 'Ġm', 'Ġ.', 'ĠParam', 'eter', 'Ġ(', 'Ġ,', 'Ġ16', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['inter', 'val', 'Ġ=', 'Ġm', 'Ġ.', 'ĠParam', 'eter', 'Ġ(', 'Ġ,', 'Ġ16', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['interval', 'Ġ=', 'Ġm', 'Ġ.', 'ĠParameter', 'Ġ(', 'Ġ,', 'Ġ16', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "led ( led + 1 ) , \n"
Original    (008): ['led', '(', 'led', '+', '1', ')', ',', '\\n']
Tokenized   (011): ['<s>', 'led', 'Ġ(', 'Ġled', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['led', 'Ġ(', 'Ġled', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['led', 'Ġ(', 'Ġled', 'Ġ+', 'Ġ1', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "SingleStatement ( SystemTask ( , , led ) ) \n"
Original    (010): ['SingleStatement', '(', 'SystemTask', '(', ',', ',', 'led', ')', ')', '\\n']
Tokenized   (015): ['<s>', 'Single', 'Statement', 'Ġ(', 'ĠSystem', 'Task', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġled', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Single', 'Statement', 'Ġ(', 'ĠSystem', 'Task', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġled', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['SingleStatement', 'Ġ(', 'ĠSystemTask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġled', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "y = dataflow . Variable ( , valid = , ready = , point = 4 ) \n"
Original    (018): ['y', '=', 'dataflow', '.', 'Variable', '(', ',', 'valid', '=', ',', 'ready', '=', ',', 'point', '=', '4', ')', '\\n']
Tokenized   (022): ['<s>', 'y', 'Ġ=', 'Ġdata', 'flow', 'Ġ.', 'ĠVariable', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ,', 'Ġpoint', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['y', 'Ġ=', 'Ġdata', 'flow', 'Ġ.', 'ĠVariable', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ,', 'Ġpoint', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['y', 'Ġ=', 'Ġdataflow', 'Ġ.', 'ĠVariable', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ,', 'Ġpoint', 'Ġ=', 'Ġ4', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "z . output ( , valid = , ready = ) \n"
Original    (012): ['z', '.', 'output', '(', ',', 'valid', '=', ',', 'ready', '=', ')', '\\n']
Tokenized   (015): ['<s>', 'z', 'Ġ.', 'Ġoutput', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['z', 'Ġ.', 'Ġoutput', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['z', 'Ġ.', 'Ġoutput', 'Ġ(', 'Ġ,', 'Ġvalid', 'Ġ=', 'Ġ,', 'Ġready', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "xdata_orig = m . RegLike ( ports [ ] , name = , initval = 0 ) \n"
Original    (018): ['xdata_orig', '=', 'm', '.', 'RegLike', '(', 'ports', '[', ']', ',', 'name', '=', ',', 'initval', '=', '0', ')', '\\n']
Tokenized   (026): ['<s>', 'x', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['x', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['xdata_orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠRegLike', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ,', 'Ġinitval', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "zdata_orig = m . WireLike ( ports [ ] , name = ) \n"
Original    (014): ['zdata_orig', '=', 'm', '.', 'WireLike', '(', 'ports', '[', ']', ',', 'name', '=', ')', '\\n']
Tokenized   (021): ['<s>', 'z', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['z', 'data', '_', 'orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Like', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['zdata_orig', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWireLike', 'Ġ(', 'Ġports', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġname', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "params = m . connect_params ( main ) , \n"
Original    (010): ['params', '=', 'm', '.', 'connect_params', '(', 'main', ')', ',', '\\n']
Tokenized   (015): ['<s>', 'params', 'Ġ=', 'Ġm', 'Ġ.', 'Ġconnect', '_', 'params', 'Ġ(', 'Ġmain', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['params', 'Ġ=', 'Ġm', 'Ġ.', 'Ġconnect', '_', 'params', 'Ġ(', 'Ġmain', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['params', 'Ġ=', 'Ġm', 'Ġ.', 'Ġconnect_params', 'Ġ(', 'Ġmain', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "reset_stmt . append ( ydata_orig ( 0 ) ) \n"
Original    (010): ['reset_stmt', '.', 'append', '(', 'ydata_orig', '(', '0', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'reset', '_', 'st', 'mt', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġy', 'data', '_', 'orig', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['reset', '_', 'st', 'mt', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġy', 'data', '_', 'orig', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['reset_stmt', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġydata_orig', 'Ġ(', 'Ġ0', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "nclk ( clk ) , \n"
Original    (006): ['nclk', '(', 'clk', ')', ',', '\\n']
Tokenized   (012): ['<s>', 'n', 'cl', 'k', 'Ġ(', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['n', 'cl', 'k', 'Ġ(', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['nclk', 'Ġ(', 'Ġclk', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "send ( , ydata_orig , yvalid , yready , step = 1 , waitnum = 20 ) \n"
Original    (018): ['send', '(', ',', 'ydata_orig', ',', 'yvalid', ',', 'yready', ',', 'step', '=', '1', ',', 'waitnum', '=', '20', ')', '\\n']
Tokenized   (027): ['<s>', 'send', 'Ġ(', 'Ġ,', 'Ġy', 'data', '_', 'orig', 'Ġ,', 'Ġy', 'valid', 'Ġ,', 'Ġy', 'ready', 'Ġ,', 'Ġstep', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ20', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['send', 'Ġ(', 'Ġ,', 'Ġy', 'data', '_', 'orig', 'Ġ,', 'Ġy', 'valid', 'Ġ,', 'Ġy', 'ready', 'Ġ,', 'Ġstep', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ20', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['send', 'Ġ(', 'Ġ,', 'Ġydata_orig', 'Ġ,', 'Ġyvalid', 'Ġ,', 'Ġyready', 'Ġ,', 'Ġstep', 'Ġ=', 'Ġ1', 'Ġ,', 'Ġwaitnum', 'Ġ=', 'Ġ20', 'Ġ)', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "receive ( , zdata , zvalid , zready , waitnum = 50 ) \n"
Original    (014): ['receive', '(', ',', 'zdata', ',', 'zvalid', ',', 'zready', ',', 'waitnum', '=', '50', ')', '\\n']
Tokenized   (022): ['<s>', 're', 'ceive', 'Ġ(', 'Ġ,', 'Ġz', 'data', 'Ġ,', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ50', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['re', 'ceive', 'Ġ(', 'Ġ,', 'Ġz', 'data', 'Ġ,', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ,', 'Ġwait', 'num', 'Ġ=', 'Ġ50', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['receive', 'Ġ(', 'Ġ,', 'Ġzdata', 'Ġ,', 'Ġzvalid', 'Ġ,', 'Ġzready', 'Ġ,', 'Ġwaitnum', 'Ġ=', 'Ġ50', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "If ( AndList ( zvalid , zready ) ) ( \n"
Original    (011): ['If', '(', 'AndList', '(', 'zvalid', ',', 'zready', ')', ')', '(', '\\n']
Tokenized   (017): ['<s>', 'If', 'Ġ(', 'ĠAnd', 'List', 'Ġ(', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ)', 'Ġ)', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['If', 'Ġ(', 'ĠAnd', 'List', 'Ġ(', 'Ġz', 'valid', 'Ġ,', 'Ġz', 'ready', 'Ġ)', 'Ġ)', 'Ġ(', 'Ġ\\', 'n']
Detokenized (011): ['If', 'Ġ(', 'ĠAndList', 'Ġ(', 'Ġzvalid', 'Ġ,', 'Ġzready', 'Ġ)', 'Ġ)', 'Ġ(', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Systask ( , , zdata_orig ) \n"
Original    (007): ['Systask', '(', ',', ',', 'zdata_orig', ')', '\\n']
Tokenized   (015): ['<s>', 'Sy', 'st', 'ask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġz', 'data', '_', 'orig', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['Sy', 'st', 'ask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġz', 'data', '_', 'orig', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['Systask', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġzdata_orig', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "count = m . Reg ( , width = 32 , initval = 0 ) \n"
Original    (016): ['count', '=', 'm', '.', 'Reg', '(', ',', 'width', '=', '32', ',', 'initval', '=', '0', ')', '\\n']
Tokenized   (020): ['<s>', 'count', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Ġ(', 'Ġ,', 'Ġwidth', 'Ġ=', 'Ġ32', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['count', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Ġ(', 'Ġ,', 'Ġwidth', 'Ġ=', 'Ġ32', 'Ġ,', 'Ġinit', 'val', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['count', 'Ġ=', 'Ġm', 'Ġ.', 'ĠReg', 'Ġ(', 'Ġ,', 'Ġwidth', 'Ġ=', 'Ġ32', 'Ġ,', 'Ġinitval', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "fsm . add ( valid ( down ) , cond = c , delay = 4 , eager_val = True , lazy_cond = True ) \n"
Original    (026): ['fsm', '.', 'add', '(', 'valid', '(', 'down', ')', ',', 'cond', '=', 'c', ',', 'delay', '=', '4', ',', 'eager_val', '=', 'True', ',', 'lazy_cond', '=', 'True', ')', '\\n']
Tokenized   (034): ['<s>', 'f', 'sm', 'Ġ.', 'Ġadd', 'Ġ(', 'Ġvalid', 'Ġ(', 'Ġdown', 'Ġ)', 'Ġ,', 'Ġcond', 'Ġ=', 'Ġc', 'Ġ,', 'Ġdelay', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġeager', '_', 'val', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġlazy', '_', 'cond', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (032): ['f', 'sm', 'Ġ.', 'Ġadd', 'Ġ(', 'Ġvalid', 'Ġ(', 'Ġdown', 'Ġ)', 'Ġ,', 'Ġcond', 'Ġ=', 'Ġc', 'Ġ,', 'Ġdelay', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġeager', '_', 'val', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġlazy', '_', 'cond', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (026): ['fsm', 'Ġ.', 'Ġadd', 'Ġ(', 'Ġvalid', 'Ġ(', 'Ġdown', 'Ġ)', 'Ġ,', 'Ġcond', 'Ġ=', 'Ġc', 'Ġ,', 'Ġdelay', 'Ġ=', 'Ġ4', 'Ġ,', 'Ġeager_val', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġlazy_cond', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 32
===================================================================
Hidden states:  (13, 26, 768)
# Extracted words:  26
Sentence         : "uut = m . Instance ( mkLed ( ) , , \n"
Original    (012): ['uut', '=', 'm', '.', 'Instance', '(', 'mkLed', '(', ')', ',', ',', '\\n']
Tokenized   (018): ['<s>', 'u', 'ut', 'Ġ=', 'Ġm', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmk', 'Led', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['u', 'ut', 'Ġ=', 'Ġm', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmk', 'Led', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['uut', 'Ġ=', 'Ġm', 'Ġ.', 'ĠInstance', 'Ġ(', 'ĠmkLed', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ,', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "rslt = m . Wire ( , retwidth , signed = True ) \n"
Original    (014): ['rslt', '=', 'm', '.', 'Wire', '(', ',', 'retwidth', ',', 'signed', '=', 'True', ')', '\\n']
Tokenized   (019): ['<s>', 'rs', 'lt', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Ġ(', 'Ġ,', 'Ġret', 'width', 'Ġ,', 'Ġsigned', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rs', 'lt', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Ġ(', 'Ġ,', 'Ġret', 'width', 'Ġ,', 'Ġsigned', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['rslt', 'Ġ=', 'Ġm', 'Ġ.', 'ĠWire', 'Ġ(', 'Ġ,', 'Ġretwidth', 'Ġ,', 'Ġsigned', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "tmpval [ 0 ] ( rslt ) , \n"
Original    (009): ['tmpval', '[', '0', ']', '(', 'rslt', ')', ',', '\\n']
Tokenized   (014): ['<s>', 'tmp', 'val', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ(', 'Ġrs', 'lt', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['tmp', 'val', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ(', 'Ġrs', 'lt', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['tmpval', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ(', 'Ġrslt', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "vtypes . If ( rst ) ( \n"
Original    (008): ['vtypes', '.', 'If', '(', 'rst', ')', '(', '\\n']
Tokenized   (013): ['<s>', 'v', 'types', 'Ġ.', 'ĠIf', 'Ġ(', 'Ġr', 'st', 'Ġ)', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['v', 'types', 'Ġ.', 'ĠIf', 'Ġ(', 'Ġr', 'st', 'Ġ)', 'Ġ(', 'Ġ\\', 'n']
Detokenized (008): ['vtypes', 'Ġ.', 'ĠIf', 'Ġ(', 'Ġrst', 'Ġ)', 'Ġ(', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ports = [ ( , clk ) , ( , update ) , ( , a ) , ( , b ) , ( , c ) ] \n"
Original    (029): ['ports', '=', '[', '(', ',', 'clk', ')', ',', '(', ',', 'update', ')', ',', '(', ',', 'a', ')', ',', '(', ',', 'b', ')', ',', '(', ',', 'c', ')', ']', '\\n']
Tokenized   (033): ['<s>', 'ports', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġupdate', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġc', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (031): ['ports', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġcl', 'k', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġupdate', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġc', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (029): ['ports', 'Ġ=', 'Ġ[', 'Ġ(', 'Ġ,', 'Ġclk', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġupdate', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġa', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġb', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ,', 'Ġc', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 31
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "m . Instance ( mult , , ports = ports ) \n"
Original    (012): ['m', '.', 'Instance', '(', 'mult', ',', ',', 'ports', '=', 'ports', ')', '\\n']
Tokenized   (016): ['<s>', 'm', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmult', 'Ġ,', 'Ġ,', 'Ġports', 'Ġ=', 'Ġports', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['m', 'Ġ.', 'ĠInst', 'ance', 'Ġ(', 'Ġmult', 'Ġ,', 'Ġ,', 'Ġports', 'Ġ=', 'Ġports', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['m', 'Ġ.', 'ĠInstance', 'Ġ(', 'Ġmult', 'Ġ,', 'Ġ,', 'Ġports', 'Ġ=', 'Ġports', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "stdout = subprocess . PIPE ) . stdout \n"
Original    (009): ['stdout', '=', 'subprocess', '.', 'PIPE', ')', '.', 'stdout', '\\n']
Tokenized   (017): ['<s>', 'std', 'out', 'Ġ=', 'Ġsub', 'process', 'Ġ.', 'ĠP', 'IP', 'E', 'Ġ)', 'Ġ.', 'Ġstd', 'out', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['std', 'out', 'Ġ=', 'Ġsub', 'process', 'Ġ.', 'ĠP', 'IP', 'E', 'Ġ)', 'Ġ.', 'Ġstd', 'out', 'Ġ\\', 'n']
Detokenized (009): ['stdout', 'Ġ=', 'Ġsubprocess', 'Ġ.', 'ĠPIPE', 'Ġ)', 'Ġ.', 'Ġstdout', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "line = [ l for l in sout ] [ 0 ] \n"
Original    (013): ['line', '=', '[', 'l', 'for', 'l', 'in', 'sout', ']', '[', '0', ']', '\\n']
Tokenized   (017): ['<s>', 'line', 'Ġ=', 'Ġ[', 'Ġl', 'Ġfor', 'Ġl', 'Ġin', 'Ġs', 'out', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['line', 'Ġ=', 'Ġ[', 'Ġl', 'Ġfor', 'Ġl', 'Ġin', 'Ġs', 'out', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\', 'n']
Detokenized (013): ['line', 'Ġ=', 'Ġ[', 'Ġl', 'Ġfor', 'Ġl', 'Ġin', 'Ġsout', 'Ġ]', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "round ( wmean , prec ) , "+-" , round ( wstd , prec ) ) \n"
Original    (017): ['round', '(', 'wmean', ',', 'prec', ')', ',', '"+-"', ',', 'round', '(', 'wstd', ',', 'prec', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'round', 'Ġ(', 'Ġw', 'mean', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ,', 'Ġ"+', '-"', 'Ġ,', 'Ġround', 'Ġ(', 'Ġw', 'std', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['round', 'Ġ(', 'Ġw', 'mean', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ,', 'Ġ"+', '-"', 'Ġ,', 'Ġround', 'Ġ(', 'Ġw', 'std', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['round', 'Ġ(', 'Ġwmean', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ,', 'Ġ"+-"', 'Ġ,', 'Ġround', 'Ġ(', 'Ġwstd', 'Ġ,', 'Ġprec', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "size = stop - start ) \n"
Original    (007): ['size', '=', 'stop', '-', 'start', ')', '\\n']
Tokenized   (010): ['<s>', 'size', 'Ġ=', 'Ġstop', 'Ġ-', 'Ġstart', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['size', 'Ġ=', 'Ġstop', 'Ġ-', 'Ġstart', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['size', 'Ġ=', 'Ġstop', 'Ġ-', 'Ġstart', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "rndbase = numpy . random . randint ( self . nrows , size = niter ) \n"
Original    (017): ['rndbase', '=', 'numpy', '.', 'random', '.', 'randint', '(', 'self', '.', 'nrows', ',', 'size', '=', 'niter', ')', '\\n']
Tokenized   (026): ['<s>', 'r', 'nd', 'base', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', 'rows', 'Ġ,', 'Ġsize', 'Ġ=', 'Ġn', 'iter', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['r', 'nd', 'base', 'Ġ=', 'Ġn', 'umpy', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġrand', 'int', 'Ġ(', 'Ġself', 'Ġ.', 'Ġn', 'rows', 'Ġ,', 'Ġsize', 'Ġ=', 'Ġn', 'iter', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['rndbase', 'Ġ=', 'Ġnumpy', 'Ġ.', 'Ġrandom', 'Ġ.', 'Ġrandint', 'Ġ(', 'Ġself', 'Ġ.', 'Ġnrows', 'Ġ,', 'Ġsize', 'Ġ=', 'Ġniter', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "rng = [ - 1000 , - 1000 ] \n"
Original    (010): ['rng', '=', '[', '-', '1000', ',', '-', '1000', ']', '\\n']
Tokenized   (014): ['<s>', 'r', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġ1000', 'Ġ,', 'Ġ-', 'Ġ1000', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['r', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġ1000', 'Ġ,', 'Ġ-', 'Ġ1000', 'Ġ]', 'Ġ\\', 'n']
Detokenized (010): ['rng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġ1000', 'Ġ,', 'Ġ-', 'Ġ1000', 'Ġ]', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "benchtime , stones = prof . run ( \n"
Original    (009): ['benchtime', ',', 'stones', '=', 'prof', '.', 'run', '(', '\\n']
Tokenized   (013): ['<s>', 'bench', 'time', 'Ġ,', 'Ġstones', 'Ġ=', 'Ġprof', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['bench', 'time', 'Ġ,', 'Ġstones', 'Ġ=', 'Ġprof', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['benchtime', 'Ġ,', 'Ġstones', 'Ġ=', 'Ġprof', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "db . rng = [ - rng / 2 , rng / 2 ] \n"
Original    (015): ['db', '.', 'rng', '=', '[', '-', 'rng', '/', '2', ',', 'rng', '/', '2', ']', '\\n']
Tokenized   (021): ['<s>', 'db', 'Ġ.', 'Ġr', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['db', 'Ġ.', 'Ġr', 'ng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġr', 'ng', 'Ġ/', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (015): ['db', 'Ġ.', 'Ġrng', 'Ġ=', 'Ġ[', 'Ġ-', 'Ġrng', 'Ġ/', 'Ġ2', 'Ġ,', 'Ġrng', 'Ġ/', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "MB_ = 1024 * KB_ \n"
Original    (006): ['MB_', '=', '1024', '*', 'KB_', '\\n']
Tokenized   (011): ['<s>', 'MB', '_', 'Ġ=', 'Ġ1024', 'Ġ*', 'ĠKB', '_', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['MB', '_', 'Ġ=', 'Ġ1024', 'Ġ*', 'ĠKB', '_', 'Ġ\\', 'n']
Detokenized (006): ['MB_', 'Ġ=', 'Ġ1024', 'Ġ*', 'ĠKB_', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "markers = [ , , , , , , , , , ] \n"
Original    (014): ['markers', '=', '[', ',', ',', ',', ',', ',', ',', ',', ',', ',', ']', '\\n']
Tokenized   (018): ['<s>', 'mark', 'ers', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['mark', 'ers', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['markers', 'Ġ=', 'Ġ[', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ,', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "memcpyw = float ( tmp . split ( ) [ 1 ] ) \n"
Original    (014): ['memcpyw', '=', 'float', '(', 'tmp', '.', 'split', '(', ')', '[', '1', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'mem', 'c', 'py', 'w', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġtmp', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['mem', 'c', 'py', 'w', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġtmp', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['memcpyw', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġtmp', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "values [ "memcpyr" ] . append ( memcpyr ) \n"
Original    (010): ['values', '[', '"memcpyr"', ']', '.', 'append', '(', 'memcpyr', ')', '\\n']
Tokenized   (019): ['<s>', 'values', 'Ġ[', 'Ġ"', 'mem', 'cp', 'yr', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġmem', 'cp', 'yr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['values', 'Ġ[', 'Ġ"', 'mem', 'cp', 'yr', '"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġmem', 'cp', 'yr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['values', 'Ġ[', 'Ġ"memcpyr"', 'Ġ]', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġmemcpyr', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "ratio = float ( line . split ( ) [ - 1 ] ) \n"
Original    (015): ['ratio', '=', 'float', '(', 'line', '.', 'split', '(', ')', '[', '-', '1', ']', ')', '\\n']
Tokenized   (019): ['<s>', 'rat', 'io', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġline', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rat', 'io', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġline', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['ratio', 'Ġ=', 'Ġfloat', 'Ġ(', 'Ġline', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ-', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "xlim ( 0 , xmax ) \n"
Original    (007): ['xlim', '(', '0', ',', 'xmax', ')', '\\n']
Tokenized   (012): ['<s>', 'x', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġx', 'max', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['x', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġx', 'max', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['xlim', 'Ġ(', 'Ġ0', 'Ġ,', 'Ġxmax', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "ylim ( 0 , None ) \n"
Original    (007): ['ylim', '(', '0', ',', 'None', ')', '\\n']
Tokenized   (011): ['<s>', 'y', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['y', 'lim', 'Ġ(', 'Ġ0', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['ylim', 'Ġ(', 'Ġ0', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "grid ( True ) \n"
Original    (005): ['grid', '(', 'True', ')', '\\n']
Tokenized   (008): ['<s>', 'grid', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['grid', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['grid', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "legend ( [ p [ 0 ] for p in plots \n"
Original    (012): ['legend', '(', '[', 'p', '[', '0', ']', 'for', 'p', 'in', 'plots', '\\n']
Tokenized   (016): ['<s>', 'leg', 'end', 'Ġ(', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġplots', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['leg', 'end', 'Ġ(', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġplots', 'Ġ\\', 'n']
Detokenized (012): ['legend', 'Ġ(', 'Ġ[', 'Ġp', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġfor', 'Ġp', 'Ġin', 'Ġplots', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "savefig ( outfile , dpi = 64 ) \n"
Original    (009): ['savefig', '(', 'outfile', ',', 'dpi', '=', '64', ')', '\\n']
Tokenized   (015): ['<s>', 'save', 'fig', 'Ġ(', 'Ġout', 'file', 'Ġ,', 'Ġd', 'pi', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['save', 'fig', 'Ġ(', 'Ġout', 'file', 'Ġ,', 'Ġd', 'pi', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['savefig', 'Ġ(', 'Ġoutfile', 'Ġ,', 'Ġdpi', 'Ġ=', 'Ġ64', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "help = , ) \n"
Original    (005): ['help', '=', ',', ')', '\\n']
Tokenized   (008): ['<s>', 'help', 'Ġ=', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['help', 'Ġ=', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['help', 'Ġ=', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "parser . add_option ( , , action = , \n"
Original    (010): ['parser', '.', 'add_option', '(', ',', ',', 'action', '=', ',', '\\n']
Tokenized   (015): ['<s>', 'parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['parser', 'Ġ.', 'Ġadd', '_', 'option', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['parser', 'Ġ.', 'Ġadd_option', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġaction', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "show_plot ( plots , yaxis , legends , gtitle , xmax = int ( options . xmax ) if \n"
Original    (020): ['show_plot', '(', 'plots', ',', 'yaxis', ',', 'legends', ',', 'gtitle', ',', 'xmax', '=', 'int', '(', 'options', '.', 'xmax', ')', 'if', '\\n']
Tokenized   (029): ['<s>', 'show', '_', 'plot', 'Ġ(', 'Ġplots', 'Ġ,', 'Ġy', 'axis', 'Ġ,', 'Ġlegends', 'Ġ,', 'Ġg', 'title', 'Ġ,', 'Ġx', 'max', 'Ġ=', 'Ġint', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġx', 'max', 'Ġ)', 'Ġif', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['show', '_', 'plot', 'Ġ(', 'Ġplots', 'Ġ,', 'Ġy', 'axis', 'Ġ,', 'Ġlegends', 'Ġ,', 'Ġg', 'title', 'Ġ,', 'Ġx', 'max', 'Ġ=', 'Ġint', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġx', 'max', 'Ġ)', 'Ġif', 'Ġ\\', 'n']
Detokenized (020): ['show_plot', 'Ġ(', 'Ġplots', 'Ġ,', 'Ġyaxis', 'Ġ,', 'Ġlegends', 'Ġ,', 'Ġgtitle', 'Ġ,', 'Ġxmax', 'Ġ=', 'Ġint', 'Ġ(', 'Ġoptions', 'Ġ.', 'Ġxmax', 'Ġ)', 'Ġif', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "options . xmax else None ) \n"
Original    (007): ['options', '.', 'xmax', 'else', 'None', ')', '\\n']
Tokenized   (011): ['<s>', 'options', 'Ġ.', 'Ġx', 'max', 'Ġelse', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['options', 'Ġ.', 'Ġx', 'max', 'Ġelse', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['options', 'Ġ.', 'Ġxmax', 'Ġelse', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "hdfarray . attrs . object = { "a" : 32.1 , "b" : 1 , "c" : [ 1 , 2 ] } \n"
Original    (024): ['hdfarray', '.', 'attrs', '.', 'object', '=', '{', '"a"', ':', '32.1', ',', '"b"', ':', '1', ',', '"c"', ':', '[', '1', ',', '2', ']', '}', '\\n']
Tokenized   (038): ['<s>', 'h', 'df', 'array', 'Ġ.', 'Ġatt', 'rs', 'Ġ.', 'Ġobject', 'Ġ=', 'Ġ{', 'Ġ"', 'a', '"', 'Ġ:', 'Ġ32', '.', '1', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ:', 'Ġ1', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ}', 'Ġ\\', 'n', '</s>']
Filtered   (036): ['h', 'df', 'array', 'Ġ.', 'Ġatt', 'rs', 'Ġ.', 'Ġobject', 'Ġ=', 'Ġ{', 'Ġ"', 'a', '"', 'Ġ:', 'Ġ32', '.', '1', 'Ġ,', 'Ġ"', 'b', '"', 'Ġ:', 'Ġ1', 'Ġ,', 'Ġ"', 'c', '"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ}', 'Ġ\\', 'n']
Detokenized (024): ['hdfarray', 'Ġ.', 'Ġattrs', 'Ġ.', 'Ġobject', 'Ġ=', 'Ġ{', 'Ġ"a"', 'Ġ:', 'Ġ32.1', 'Ġ,', 'Ġ"b"', 'Ġ:', 'Ġ1', 'Ġ,', 'Ġ"c"', 'Ġ:', 'Ġ[', 'Ġ1', 'Ġ,', 'Ġ2', 'Ġ]', 'Ġ}', 'Ġ\\n']
Counter: 36
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "addr = hex ( id ( self ) ) \n"
Original    (010): ['addr', '=', 'hex', '(', 'id', '(', 'self', ')', ')', '\\n']
Tokenized   (013): ['<s>', 'addr', 'Ġ=', 'Ġhex', 'Ġ(', 'Ġid', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['addr', 'Ġ=', 'Ġhex', 'Ġ(', 'Ġid', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['addr', 'Ġ=', 'Ġhex', 'Ġ(', 'Ġid', 'Ġ(', 'Ġself', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "node_manager . registry . pop ( pathname , None ) \n"
Original    (011): ['node_manager', '.', 'registry', '.', 'pop', '(', 'pathname', ',', 'None', ')', '\\n']
Tokenized   (017): ['<s>', 'node', '_', 'manager', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġpath', 'name', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['node', '_', 'manager', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġpath', 'name', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['node_manager', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġpop', 'Ġ(', 'Ġpathname', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "oldpathname , self . _v_pathname ) \n"
Original    (007): ['oldpathname', ',', 'self', '.', '_v_pathname', ')', '\\n']
Tokenized   (016): ['<s>', 'old', 'path', 'name', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['old', 'path', 'name', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['oldpathname', 'Ġ,', 'Ġself', 'Ġ.', 'Ġ_v_pathname', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "recursive = False , _log = False , ** kwargs ) \n"
Original    (012): ['recursive', '=', 'False', ',', '_log', '=', 'False', ',', '**', 'kwargs', ')', '\\n']
Tokenized   (019): ['<s>', 'rec', 'ursive', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ_', 'log', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['rec', 'ursive', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ_', 'log', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['recursive', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ_log', 'Ġ=', 'ĠFalse', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "% node . _v_pathname ) \n"
Original    (006): ['%', 'node', '.', '_v_pathname', ')', '\\n']
Tokenized   (013): ['<s>', '%', 'Ġnode', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['%', 'Ġnode', 'Ġ.', 'Ġ_', 'v', '_', 'path', 'name', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['%', 'Ġnode', 'Ġ.', 'Ġ_v_pathname', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "or pathname . startswith ( mypathname + ) ) : \n"
Original    (011): ['or', 'pathname', '.', 'startswith', '(', 'mypathname', '+', ')', ')', ':', '\\n']
Tokenized   (019): ['<s>', 'or', 'Ġpath', 'name', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġmy', 'path', 'name', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['or', 'Ġpath', 'name', 'Ġ.', 'Ġstart', 'sw', 'ith', 'Ġ(', 'Ġmy', 'path', 'name', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (011): ['or', 'Ġpathname', 'Ġ.', 'Ġstartswith', 'Ġ(', 'Ġmypathname', 'Ġ+', 'Ġ)', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "newarr = self . h5file . create_array ( , , [ 1 ] ) \n"
Original    (015): ['newarr', '=', 'self', '.', 'h5file', '.', 'create_array', '(', ',', ',', '[', '1', ']', ')', '\\n']
Tokenized   (023): ['<s>', 'new', 'arr', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcreate', '_', 'array', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['new', 'arr', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcreate', '_', 'array', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['newarr', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ.', 'Ġcreate_array', 'Ġ(', 'Ġ,', 'Ġ,', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "with self . assertRaises ( tables . UndoRedoError ) : \n"
Original    (011): ['with', 'self', '.', 'assertRaises', '(', 'tables', '.', 'UndoRedoError', ')', ':', '\\n']
Tokenized   (020): ['<s>', 'with', 'Ġself', 'Ġ.', 'Ġassert', 'Ra', 'ises', 'Ġ(', 'Ġtables', 'Ġ.', 'ĠUnd', 'o', 'Red', 'o', 'Error', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['with', 'Ġself', 'Ġ.', 'Ġassert', 'Ra', 'ises', 'Ġ(', 'Ġtables', 'Ġ.', 'ĠUnd', 'o', 'Red', 'o', 'Error', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (011): ['with', 'Ġself', 'Ġ.', 'ĠassertRaises', 'Ġ(', 'Ġtables', 'Ġ.', 'ĠUndoRedoError', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : ""/othergroup1/othergroup2/othergroup3" not in self . h5file ) \n"
Original    (008): ['"/othergroup1/othergroup2/othergroup3"', 'not', 'in', 'self', '.', 'h5file', ')', '\\n']
Tokenized   (026): ['<s>', '"', '/', 'other', 'group', '1', '/', 'other', 'group', '2', '/', 'other', 'group', '3', '"', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['"', '/', 'other', 'group', '1', '/', 'other', 'group', '2', '/', 'other', 'group', '3', '"', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['"/othergroup1/othergroup2/othergroup3"', 'Ġnot', 'Ġin', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "var2 = BoolCol ( dflt = 0 , pos = 2 ) \n"
Original    (013): ['var2', '=', 'BoolCol', '(', 'dflt', '=', '0', ',', 'pos', '=', '2', ')', '\\n']
Tokenized   (020): ['<s>', 'var', '2', 'Ġ=', 'ĠB', 'ool', 'Col', 'Ġ(', 'Ġdf', 'lt', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġpos', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['var', '2', 'Ġ=', 'ĠB', 'ool', 'Col', 'Ġ(', 'Ġdf', 'lt', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġpos', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['var2', 'Ġ=', 'ĠBoolCol', 'Ġ(', 'Ġdflt', 'Ġ=', 'Ġ0', 'Ġ,', 'Ġpos', 'Ġ=', 'Ġ2', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "None , nrows ) \n"
Original    (005): ['None', ',', 'nrows', ')', '\\n']
Tokenized   (009): ['<s>', 'None', 'Ġ,', 'Ġn', 'rows', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (007): ['None', 'Ġ,', 'Ġn', 'rows', 'Ġ)', 'Ġ\\', 'n']
Detokenized (005): ['None', 'Ġ,', 'Ġnrows', 'Ġ)', 'Ġ\\n']
Counter: 7
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "populateTable ( self . h5file . root , ) \n"
Original    (010): ['populateTable', '(', 'self', '.', 'h5file', '.', 'root', ',', ')', '\\n']
Tokenized   (017): ['<s>', 'pop', 'ulate', 'Table', 'Ġ(', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġroot', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['pop', 'ulate', 'Table', 'Ġ(', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġroot', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['populateTable', 'Ġ(', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ.', 'Ġroot', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "new_node = self . h5file . copy_children ( \n"
Original    (009): ['new_node', '=', 'self', '.', 'h5file', '.', 'copy_children', '(', '\\n']
Tokenized   (018): ['<s>', 'new', '_', 'node', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcopy', '_', 'children', 'Ġ(', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['new', '_', 'node', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh', '5', 'file', 'Ġ.', 'Ġcopy', '_', 'children', 'Ġ(', 'Ġ\\', 'n']
Detokenized (009): ['new_node', 'Ġ=', 'Ġself', 'Ġ.', 'Ġh5file', 'Ġ.', 'Ġcopy_children', 'Ġ(', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : ", , recursive = 1 ) \n"
Original    (007): [',', ',', 'recursive', '=', '1', ')', '\\n']
Tokenized   (010): ['<s>', ',', 'Ġ,', 'Ġrecursive', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): [',', 'Ġ,', 'Ġrecursive', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): [',', 'Ġ,', 'Ġrecursive', 'Ġ=', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "setattr ( attrs , , 11 ) \n"
Original    (008): ['setattr', '(', 'attrs', ',', ',', '11', ')', '\\n']
Tokenized   (013): ['<s>', 'set', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ,', 'Ġ11', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['set', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ,', 'Ġ11', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['setattr', 'Ġ(', 'Ġattrs', 'Ġ,', 'Ġ,', 'Ġ11', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "delattr ( attrs , ) \n"
Original    (006): ['delattr', '(', 'attrs', ',', ')', '\\n']
Tokenized   (011): ['<s>', 'del', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['del', 'attr', 'Ġ(', 'Ġatt', 'rs', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['delattr', 'Ġ(', 'Ġattrs', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "arr . _v_attrs . foo = \n"
Original    (007): ['arr', '.', '_v_attrs', '.', 'foo', '=', '\\n']
Tokenized   (014): ['<s>', 'arr', 'Ġ.', 'Ġ_', 'v', '_', 'att', 'rs', 'Ġ.', 'Ġfoo', 'Ġ=', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['arr', 'Ġ.', 'Ġ_', 'v', '_', 'att', 'rs', 'Ġ.', 'Ġfoo', 'Ġ=', 'Ġ\\', 'n']
Detokenized (007): ['arr', 'Ġ.', 'Ġ_v_attrs', 'Ġ.', 'Ġfoo', 'Ġ=', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "assert response . header ( ) == \n"
Original    (008): ['assert', 'response', '.', 'header', '(', ')', '==', '\\n']
Tokenized   (011): ['<s>', 'assert', 'Ġresponse', 'Ġ.', 'Ġheader', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['assert', 'Ġresponse', 'Ġ.', 'Ġheader', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġ\\', 'n']
Detokenized (008): ['assert', 'Ġresponse', 'Ġ.', 'Ġheader', 'Ġ(', 'Ġ)', 'Ġ==', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "CHANGES = open ( os . path . join ( here , ) , encoding = "utf-8" ) . read ( ) \n"
Original    (023): ['CHANGES', '=', 'open', '(', 'os', '.', 'path', '.', 'join', '(', 'here', ',', ')', ',', 'encoding', '=', '"utf-8"', ')', '.', 'read', '(', ')', '\\n']
Tokenized   (032): ['<s>', 'CH', 'ANG', 'ES', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ=', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['CH', 'ANG', 'ES', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ=', 'Ġ"', 'utf', '-', '8', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (023): ['CHANGES', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġhere', 'Ġ,', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ=', 'Ġ"utf-8"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 23, 768)
# Extracted words:  23
Sentence         : "tests_require = requires + [ ] , \n"
Original    (008): ['tests_require', '=', 'requires', '+', '[', ']', ',', '\\n']
Tokenized   (013): ['<s>', 'tests', '_', 'require', 'Ġ=', 'Ġrequires', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['tests', '_', 'require', 'Ġ=', 'Ġrequires', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (008): ['tests_require', 'Ġ=', 'Ġrequires', 'Ġ+', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "user_id = Column ( Integer , primary_key = True ) \n"
Original    (011): ['user_id', '=', 'Column', '(', 'Integer', ',', 'primary_key', '=', 'True', ')', '\\n']
Tokenized   (018): ['<s>', 'user', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['user', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġprimary', '_', 'key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['user_id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġprimary_key', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "username = Column ( Unicode ( 20 ) , unique = True ) \n"
Original    (014): ['username', '=', 'Column', '(', 'Unicode', '(', '20', ')', ',', 'unique', '=', 'True', ')', '\\n']
Tokenized   (017): ['<s>', 'username', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ20', 'Ġ)', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['username', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ20', 'Ġ)', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['username', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠUnicode', 'Ġ(', 'Ġ20', 'Ġ)', 'Ġ,', 'Ġunique', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "hits = Column ( Integer , default = 0 ) \n"
Original    (011): ['hits', '=', 'Column', '(', 'Integer', ',', 'default', '=', '0', ')', '\\n']
Tokenized   (015): ['<s>', 'h', 'its', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['h', 'its', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['hits', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'Ġdefault', 'Ġ=', 'Ġ0', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "_password = Column ( , Unicode ( 60 ) ) \n"
Original    (011): ['_password', '=', 'Column', '(', ',', 'Unicode', '(', '60', ')', ')', '\\n']
Tokenized   (015): ['<s>', '_', 'password', 'Ġ=', 'ĠColumn', 'Ġ(', 'Ġ,', 'ĠUnicode', 'Ġ(', 'Ġ60', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['_', 'password', 'Ġ=', 'ĠColumn', 'Ġ(', 'Ġ,', 'ĠUnicode', 'Ġ(', 'Ġ60', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['_password', 'Ġ=', 'ĠColumn', 'Ġ(', 'Ġ,', 'ĠUnicode', 'Ġ(', 'Ġ60', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "Column ( , Integer , ForeignKey ( ) ) \n"
Original    (010): ['Column', '(', ',', 'Integer', ',', 'ForeignKey', '(', ')', ')', '\\n']
Tokenized   (014): ['<s>', 'Column', 'Ġ(', 'Ġ,', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['Column', 'Ġ(', 'Ġ,', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['Column', 'Ġ(', 'Ġ,', 'ĠInteger', 'Ġ,', 'ĠForeignKey', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "target_id = Column ( Integer , ForeignKey ( ) ) \n"
Original    (011): ['target_id', '=', 'Column', '(', 'Integer', ',', 'ForeignKey', '(', ')', ')', '\\n']
Tokenized   (017): ['<s>', 'target', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['target', '_', 'id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'ĠForeign', 'Key', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['target_id', 'Ġ=', 'ĠColumn', 'Ġ(', 'ĠInteger', 'Ġ,', 'ĠForeignKey', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "comments = relation ( , cascade = "delete" , \n"
Original    (010): ['comments', '=', 'relation', '(', ',', 'cascade', '=', '"delete"', ',', '\\n']
Tokenized   (015): ['<s>', 'comments', 'Ġ=', 'Ġrelation', 'Ġ(', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['comments', 'Ġ=', 'Ġrelation', 'Ġ(', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (010): ['comments', 'Ġ=', 'Ġrelation', 'Ġ(', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"delete"', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "author = relation ( User , cascade = "delete" , backref = ) \n"
Original    (014): ['author', '=', 'relation', '(', 'User', ',', 'cascade', '=', '"delete"', ',', 'backref', '=', ')', '\\n']
Tokenized   (020): ['<s>', 'author', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['author', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"', 'delete', '"', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['author', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġcascade', 'Ġ=', 'Ġ"delete"', 'Ġ,', 'Ġbackref', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "tags = relation ( Tag , secondary = ideas_tags , backref = ) \n"
Original    (014): ['tags', '=', 'relation', '(', 'Tag', ',', 'secondary', '=', 'ideas_tags', ',', 'backref', '=', ')', '\\n']
Tokenized   (020): ['<s>', 'tags', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠTag', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġideas', '_', 'tags', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['tags', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠTag', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġideas', '_', 'tags', 'Ġ,', 'Ġback', 'ref', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['tags', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠTag', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġideas_tags', 'Ġ,', 'Ġbackref', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "voted_users = relation ( User , secondary = voted_users , lazy = , \n"
Original    (014): ['voted_users', '=', 'relation', '(', 'User', ',', 'secondary', '=', 'voted_users', ',', 'lazy', '=', ',', '\\n']
Tokenized   (022): ['<s>', 'v', 'oted', '_', 'users', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġvoted', '_', 'users', 'Ġ,', 'Ġlazy', 'Ġ=', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['v', 'oted', '_', 'users', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġvoted', '_', 'users', 'Ġ,', 'Ġlazy', 'Ġ=', 'Ġ,', 'Ġ\\', 'n']
Detokenized (014): ['voted_users', 'Ġ=', 'Ġrelation', 'Ġ(', 'ĠUser', 'Ġ,', 'Ġsecondary', 'Ġ=', 'Ġvoted_users', 'Ġ,', 'Ġlazy', 'Ġ=', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "total_votes = column_property ( ( hits + misses ) . label ( ) ) \n"
Original    (015): ['total_votes', '=', 'column_property', '(', '(', 'hits', '+', 'misses', ')', '.', 'label', '(', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'total', '_', 'votes', 'Ġ=', 'Ġcolumn', '_', 'property', 'Ġ(', 'Ġ(', 'Ġhits', 'Ġ+', 'Ġmisses', 'Ġ)', 'Ġ.', 'Ġlabel', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['total', '_', 'votes', 'Ġ=', 'Ġcolumn', '_', 'property', 'Ġ(', 'Ġ(', 'Ġhits', 'Ġ+', 'Ġmisses', 'Ġ)', 'Ġ.', 'Ġlabel', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['total_votes', 'Ġ=', 'Ġcolumn_property', 'Ġ(', 'Ġ(', 'Ġhits', 'Ġ+', 'Ġmisses', 'Ġ)', 'Ġ.', 'Ġlabel', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "query = query . filter ( cls . target == None ) . order_by ( order_by ) \n"
Original    (018): ['query', '=', 'query', '.', 'filter', '(', 'cls', '.', 'target', '==', 'None', ')', '.', 'order_by', '(', 'order_by', ')', '\\n']
Tokenized   (026): ['<s>', 'query', 'Ġ=', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġtarget', 'Ġ==', 'ĠNone', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġorder', '_', 'by', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['query', 'Ġ=', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġcl', 's', 'Ġ.', 'Ġtarget', 'Ġ==', 'ĠNone', 'Ġ)', 'Ġ.', 'Ġorder', '_', 'by', 'Ġ(', 'Ġorder', '_', 'by', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['query', 'Ġ=', 'Ġquery', 'Ġ.', 'Ġfilter', 'Ġ(', 'Ġcls', 'Ġ.', 'Ġtarget', 'Ġ==', 'ĠNone', 'Ġ)', 'Ġ.', 'Ġorder_by', 'Ġ(', 'Ġorder_by', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "mock_get_auditlog . side_effect = lambda c : auditlog \n"
Original    (009): ['mock_get_auditlog', '.', 'side_effect', '=', 'lambda', 'c', ':', 'auditlog', '\\n']
Tokenized   (022): ['<s>', 'm', 'ock', '_', 'get', '_', 'aud', 'it', 'log', 'Ġ.', 'Ġside', '_', 'effect', 'Ġ=', 'Ġlambda', 'Ġc', 'Ġ:', 'Ġaudit', 'log', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['m', 'ock', '_', 'get', '_', 'aud', 'it', 'log', 'Ġ.', 'Ġside', '_', 'effect', 'Ġ=', 'Ġlambda', 'Ġc', 'Ġ:', 'Ġaudit', 'log', 'Ġ\\', 'n']
Detokenized (009): ['mock_get_auditlog', 'Ġ.', 'Ġside_effect', 'Ġ=', 'Ġlambda', 'Ġc', 'Ġ:', 'Ġauditlog', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "json . loads ( entry [ 2 ] . payload ) , \n"
Original    (013): ['json', '.', 'loads', '(', 'entry', '[', '2', ']', '.', 'payload', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'json', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġentry', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġpayload', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['json', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġentry', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġpayload', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (013): ['json', 'Ġ.', 'Ġloads', 'Ġ(', 'Ġentry', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġpayload', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : ": 5 \n"
Original    (003): [':', '5', '\\n']
Tokenized   (006): ['<s>', ':', 'Ġ5', 'Ġ\\', 'n', '</s>']
Filtered   (004): [':', 'Ġ5', 'Ġ\\', 'n']
Detokenized (003): [':', 'Ġ5', 'Ġ\\n']
Counter: 4
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "registry . content = DummyContentRegistry ( ) \n"
Original    (008): ['registry', '.', 'content', '=', 'DummyContentRegistry', '(', ')', '\\n']
Tokenized   (016): ['<s>', 'reg', 'istry', 'Ġ.', 'Ġcontent', 'Ġ=', 'ĠD', 'ummy', 'Content', 'Reg', 'istry', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['reg', 'istry', 'Ġ.', 'Ġcontent', 'Ġ=', 'ĠD', 'ummy', 'Content', 'Reg', 'istry', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['registry', 'Ġ.', 'Ġcontent', 'Ġ=', 'ĠDummyContentRegistry', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "ep = DummyFunction ( True ) \n"
Original    (007): ['ep', '=', 'DummyFunction', '(', 'True', ')', '\\n']
Tokenized   (012): ['<s>', 'ep', 'Ġ=', 'ĠD', 'ummy', 'Function', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['ep', 'Ġ=', 'ĠD', 'ummy', 'Function', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['ep', 'Ġ=', 'ĠDummyFunction', 'Ġ(', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "name_node . validator ( node [ ] , filename ) \n"
Original    (011): ['name_node', '.', 'validator', '(', 'node', '[', ']', ',', 'filename', ')', '\\n']
Tokenized   (017): ['<s>', 'name', '_', 'node', 'Ġ.', 'Ġvalid', 'ator', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['name', '_', 'node', 'Ġ.', 'Ġvalid', 'ator', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['name_node', 'Ġ.', 'Ġvalidator', 'Ġ(', 'Ġnode', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġfilename', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "schema [ ] . missing = colander . null \n"
Original    (010): ['schema', '[', ']', '.', 'missing', '=', 'colander', '.', 'null', '\\n']
Tokenized   (015): ['<s>', 'sche', 'ma', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmissing', 'Ġ=', 'Ġcol', 'ander', 'Ġ.', 'Ġnull', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['sche', 'ma', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmissing', 'Ġ=', 'Ġcol', 'ander', 'Ġ.', 'Ġnull', 'Ġ\\', 'n']
Detokenized (010): ['schema', 'Ġ[', 'Ġ]', 'Ġ.', 'Ġmissing', 'Ġ=', 'Ġcolander', 'Ġ.', 'Ġnull', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "title = appstruct [ ] or None \n"
Original    (008): ['title', '=', 'appstruct', '[', ']', 'or', 'None', '\\n']
Tokenized   (012): ['<s>', 'title', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['title', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\', 'n']
Detokenized (008): ['title', 'Ġ=', 'Ġappstruct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠNone', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mimetype = appstruct [ ] or USE_MAGIC \n"
Original    (008): ['mimetype', '=', 'appstruct', '[', ']', 'or', 'USE_MAGIC', '\\n']
Tokenized   (018): ['<s>', 'm', 'im', 'ety', 'pe', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠUSE', '_', 'MAG', 'IC', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['m', 'im', 'ety', 'pe', 'Ġ=', 'Ġapp', 'struct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠUSE', '_', 'MAG', 'IC', 'Ġ\\', 'n']
Detokenized (008): ['mimetype', 'Ġ=', 'Ġappstruct', 'Ġ[', 'Ġ]', 'Ġor', 'ĠUSE_MAGIC', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "filedata = tempstore . get ( uid , { } ) \n"
Original    (012): ['filedata', '=', 'tempstore', '.', 'get', '(', 'uid', ',', '{', '}', ')', '\\n']
Tokenized   (019): ['<s>', 'f', 'iled', 'ata', 'Ġ=', 'Ġtemp', 'store', 'Ġ.', 'Ġget', 'Ġ(', 'Ġu', 'id', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['f', 'iled', 'ata', 'Ġ=', 'Ġtemp', 'store', 'Ġ.', 'Ġget', 'Ġ(', 'Ġu', 'id', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['filedata', 'Ġ=', 'Ġtempstore', 'Ġ.', 'Ġget', 'Ġ(', 'Ġuid', 'Ġ,', 'Ġ{', 'Ġ}', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "resource1 . __acl__ = [ ( None , , None ) , ( None , 1 , None ) ] \n"
Original    (021): ['resource1', '.', '__acl__', '=', '[', '(', 'None', ',', ',', 'None', ')', ',', '(', 'None', ',', '1', ',', 'None', ')', ']', '\\n']
Tokenized   (027): ['<s>', 'resource', '1', 'Ġ.', 'Ġ__', 'acl', '__', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['resource', '1', 'Ġ.', 'Ġ__', 'acl', '__', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['resource1', 'Ġ.', 'Ġ__acl__', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "new_acl = [ ( None , , None ) , ( None , 1 , None ) ] , \n"
Original    (020): ['new_acl', '=', '[', '(', 'None', ',', ',', 'None', ')', ',', '(', 'None', ',', '1', ',', 'None', ')', ']', ',', '\\n']
Tokenized   (025): ['<s>', 'new', '_', 'acl', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['new', '_', 'acl', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (020): ['new_acl', 'Ġ=', 'Ġ[', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ,', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'ĠNone', 'Ġ)', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "request . registry . notify ( LoggedIn ( login , user , context , request ) ) \n"
Original    (018): ['request', '.', 'registry', '.', 'notify', '(', 'LoggedIn', '(', 'login', ',', 'user', ',', 'context', ',', 'request', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'request', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġnotify', 'Ġ(', 'ĠLogged', 'In', 'Ġ(', 'Ġlogin', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġcontext', 'Ġ,', 'Ġrequest', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['request', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġnotify', 'Ġ(', 'ĠLogged', 'In', 'Ġ(', 'Ġlogin', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġcontext', 'Ġ,', 'Ġrequest', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['request', 'Ġ.', 'Ġregistry', 'Ġ.', 'Ġnotify', 'Ġ(', 'ĠLoggedIn', 'Ġ(', 'Ġlogin', 'Ġ,', 'Ġuser', 'Ġ,', 'Ġcontext', 'Ġ,', 'Ġrequest', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "dirname , filename = os . path . split ( context . path ) \n"
Original    (015): ['dirname', ',', 'filename', '=', 'os', '.', 'path', '.', 'split', '(', 'context', '.', 'path', ')', '\\n']
Tokenized   (019): ['<s>', 'dir', 'name', 'Ġ,', 'Ġfilename', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['dir', 'name', 'Ġ,', 'Ġfilename', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['dirname', 'Ġ,', 'Ġfilename', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġcontext', 'Ġ.', 'Ġpath', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "response . content_type = mt or \n"
Original    (007): ['response', '.', 'content_type', '=', 'mt', 'or', '\\n']
Tokenized   (012): ['<s>', 'response', 'Ġ.', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġmt', 'Ġor', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['response', 'Ġ.', 'Ġcontent', '_', 'type', 'Ġ=', 'Ġmt', 'Ġor', 'Ġ\\', 'n']
Detokenized (007): ['response', 'Ġ.', 'Ġcontent_type', 'Ġ=', 'Ġmt', 'Ġor', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "getattr ( SkipCase ( ) , ) ) \n"
Original    (009): ['getattr', '(', 'SkipCase', '(', ')', ',', ')', ')', '\\n']
Tokenized   (014): ['<s>', 'get', 'attr', 'Ġ(', 'ĠSkip', 'Case', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['get', 'attr', 'Ġ(', 'ĠSkip', 'Case', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['getattr', 'Ġ(', 'ĠSkipCase', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "iterator . __class__ . __name__ ) ) \n"
Original    (008): ['iterator', '.', '__class__', '.', '__name__', ')', ')', '\\n']
Tokenized   (015): ['<s>', 'iterator', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['iterator', 'Ġ.', 'Ġ__', 'class', '__', 'Ġ.', 'Ġ__', 'name', '__', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['iterator', 'Ġ.', 'Ġ__class__', 'Ġ.', 'Ġ__name__', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "parts = super ( newbytes , self ) . splitlines ( keepends ) \n"
Original    (014): ['parts', '=', 'super', '(', 'newbytes', ',', 'self', ')', '.', 'splitlines', '(', 'keepends', ')', '\\n']
Tokenized   (020): ['<s>', 'parts', 'Ġ=', 'Ġsuper', 'Ġ(', 'Ġnew', 'bytes', 'Ġ,', 'Ġself', 'Ġ)', 'Ġ.', 'Ġsplit', 'lines', 'Ġ(', 'Ġkeep', 'ends', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['parts', 'Ġ=', 'Ġsuper', 'Ġ(', 'Ġnew', 'bytes', 'Ġ,', 'Ġself', 'Ġ)', 'Ġ.', 'Ġsplit', 'lines', 'Ġ(', 'Ġkeep', 'ends', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['parts', 'Ġ=', 'Ġsuper', 'Ġ(', 'Ġnewbytes', 'Ġ,', 'Ġself', 'Ġ)', 'Ġ.', 'Ġsplitlines', 'Ġ(', 'Ġkeepends', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "pos = self . rfind ( sub , * args ) \n"
Original    (012): ['pos', '=', 'self', '.', 'rfind', '(', 'sub', ',', '*', 'args', ')', '\\n']
Tokenized   (016): ['<s>', 'pos', 'Ġ=', 'Ġself', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġsub', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['pos', 'Ġ=', 'Ġself', 'Ġ.', 'Ġr', 'find', 'Ġ(', 'Ġsub', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['pos', 'Ġ=', 'Ġself', 'Ġ.', 'Ġrfind', 'Ġ(', 'Ġsub', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "replaced_builtins = . split ( ) \n"
Original    (007): ['replaced_builtins', '=', '.', 'split', '(', ')', '\\n']
Tokenized   (014): ['<s>', 're', 'placed', '_', 'built', 'ins', 'Ġ=', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['re', 'placed', '_', 'built', 'ins', 'Ġ=', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['replaced_builtins', 'Ġ=', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "expression = . join ( [ "name=\'{0}\'" . format ( name ) for name in replaced_builtins ] ) \n"
Original    (019): ['expression', '=', '.', 'join', '(', '[', '"name=\\\'{0}\\\'"', '.', 'format', '(', 'name', ')', 'for', 'name', 'in', 'replaced_builtins', ']', ')', '\\n']
Tokenized   (032): ['<s>', 'expression', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ"', 'name', '=', "\\'", '{', '0', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ)', 'Ġfor', 'Ġname', 'Ġin', 'Ġreplaced', '_', 'built', 'ins', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (030): ['expression', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ"', 'name', '=', "\\'", '{', '0', '}\\', '\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ)', 'Ġfor', 'Ġname', 'Ġin', 'Ġreplaced', '_', 'built', 'ins', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['expression', 'Ġ=', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ"name=\\\'{0}\\\'"', 'Ġ.', 'Ġformat', 'Ġ(', 'Ġname', 'Ġ)', 'Ġfor', 'Ġname', 'Ġin', 'Ġreplaced_builtins', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 30
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "touch_import_top ( , name . value , node ) \n"
Original    (010): ['touch_import_top', '(', ',', 'name', '.', 'value', ',', 'node', ')', '\\n']
Tokenized   (017): ['<s>', 'touch', '_', 'import', '_', 'top', 'Ġ(', 'Ġ,', 'Ġname', 'Ġ.', 'Ġvalue', 'Ġ,', 'Ġnode', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['touch', '_', 'import', '_', 'top', 'Ġ(', 'Ġ,', 'Ġname', 'Ġ.', 'Ġvalue', 'Ġ,', 'Ġnode', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['touch_import_top', 'Ġ(', 'Ġ,', 'Ġname', 'Ġ.', 'Ġvalue', 'Ġ,', 'Ġnode', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "retcode = main ( [ self . textfilename ] ) \n"
Original    (011): ['retcode', '=', 'main', '(', '[', 'self', '.', 'textfilename', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'ret', 'code', 'Ġ=', 'Ġmain', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġtext', 'filename', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['ret', 'code', 'Ġ=', 'Ġmain', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġtext', 'filename', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (011): ['retcode', 'Ġ=', 'Ġmain', 'Ġ(', 'Ġ[', 'Ġself', 'Ġ.', 'Ġtextfilename', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "v = self . visit ( node . values [ i ] ) \n"
Original    (014): ['v', '=', 'self', '.', 'visit', '(', 'node', '.', 'values', '[', 'i', ']', ')', '\\n']
Tokenized   (017): ['<s>', 'v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġvalues', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġvalues', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['v', 'Ġ=', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġvalues', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "props . update ( self . _class_props [ p ] ) \n"
Original    (012): ['props', '.', 'update', '(', 'self', '.', '_class_props', '[', 'p', ']', ')', '\\n']
Tokenized   (020): ['<s>', 'pro', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'class', '_', 'pro', 'ps', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['pro', 'ps', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_', 'class', '_', 'pro', 'ps', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['props', 'Ġ.', 'Ġupdate', 'Ġ(', 'Ġself', 'Ġ.', 'Ġ_class_props', 'Ġ[', 'Ġp', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "kwargs_init = [ % ( x . split ( ) [ 0 ] , x . split ( ) [ 0 ] ) for x in kwargs ] \n"
Original    (029): ['kwargs_init', '=', '[', '%', '(', 'x', '.', 'split', '(', ')', '[', '0', ']', ',', 'x', '.', 'split', '(', ')', '[', '0', ']', ')', 'for', 'x', 'in', 'kwargs', ']', '\\n']
Tokenized   (037): ['<s>', 'kw', 'args', '_', 'init', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġk', 'w', 'args', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['kw', 'args', '_', 'init', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġk', 'w', 'args', 'Ġ]', 'Ġ\\', 'n']
Detokenized (029): ['kwargs_init', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġ(', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġx', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġfor', 'Ġx', 'Ġin', 'Ġkwargs', 'Ġ]', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 29, 768)
# Extracted words:  29
Sentence         : "else : nargs = node . args . args \n"
Original    (010): ['else', ':', 'nargs', '=', 'node', '.', 'args', '.', 'args', '\\n']
Tokenized   (014): ['<s>', 'else', 'Ġ:', 'Ġn', 'args', 'Ġ=', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['else', 'Ġ:', 'Ġn', 'args', 'Ġ=', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ\\', 'n']
Detokenized (010): ['else', 'Ġ:', 'Ġnargs', 'Ġ=', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "kwargs . append ( % ( a , default_value ) ) \n"
Original    (012): ['kwargs', '.', 'append', '(', '%', '(', 'a', ',', 'default_value', ')', ')', '\\n']
Tokenized   (018): ['<s>', 'kw', 'args', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġa', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['kw', 'args', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġa', 'Ġ,', 'Ġdefault', '_', 'value', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['kwargs', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġ%', 'Ġ(', 'Ġa', 'Ġ,', 'Ġdefault_value', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "offset = len ( node . args . args ) - len ( node . args . defaults ) \n"
Original    (020): ['offset', '=', 'len', '(', 'node', '.', 'args', '.', 'args', ')', '-', 'len', '(', 'node', '.', 'args', '.', 'defaults', ')', '\\n']
Tokenized   (023): ['<s>', 'offset', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġdefaults', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['offset', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġdefaults', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['offset', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġargs', 'Ġ)', 'Ġ-', 'Ġlen', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġargs', 'Ġ.', 'Ġdefaults', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "varargs = [ % n for n in range ( 16 ) ] \n"
Original    (014): ['varargs', '=', '[', '%', 'n', 'for', 'n', 'in', 'range', '(', '16', ')', ']', '\\n']
Tokenized   (018): ['<s>', 'var', 'args', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġn', 'Ġfor', 'Ġn', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ16', 'Ġ)', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['var', 'args', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġn', 'Ġfor', 'Ġn', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ16', 'Ġ)', 'Ġ]', 'Ġ\\', 'n']
Detokenized (014): ['varargs', 'Ġ=', 'Ġ[', 'Ġ%', 'Ġn', 'Ġfor', 'Ġn', 'Ġin', 'Ġrange', 'Ġ(', 'Ġ16', 'Ġ)', 'Ġ]', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "buffer += % self . indent ( ) \n"
Original    (009): ['buffer', '+=', '%', 'self', '.', 'indent', '(', ')', '\\n']
Tokenized   (012): ['<s>', 'buffer', 'Ġ+=', 'Ġ%', 'Ġself', 'Ġ.', 'Ġindent', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['buffer', 'Ġ+=', 'Ġ%', 'Ġself', 'Ġ.', 'Ġindent', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['buffer', 'Ġ+=', 'Ġ%', 'Ġself', 'Ġ.', 'Ġindent', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "arg_name = args = None \n"
Original    (006): ['arg_name', '=', 'args', '=', 'None', '\\n']
Tokenized   (011): ['<s>', 'arg', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['arg', '_', 'name', 'Ġ=', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ\\', 'n']
Detokenized (006): ['arg_name', 'Ġ=', 'Ġargs', 'Ġ=', 'ĠNone', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "comp . append ( self . visit ( node . comparators [ i ] ) ) \n"
Original    (017): ['comp', '.', 'append', '(', 'self', '.', 'visit', '(', 'node', '.', 'comparators', '[', 'i', ']', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'comp', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġcompar', 'ators', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['comp', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġcompar', 'ators', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['comp', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġself', 'Ġ.', 'Ġvisit', 'Ġ(', 'Ġnode', 'Ġ.', 'Ġcomparators', 'Ġ[', 'Ġi', 'Ġ]', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "testtime = time ( ) - starttime \n"
Original    (008): ['testtime', '=', 'time', '(', ')', '-', 'starttime', '\\n']
Tokenized   (013): ['<s>', 'test', 'time', 'Ġ=', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġstart', 'time', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['test', 'time', 'Ġ=', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġstart', 'time', 'Ġ\\', 'n']
Detokenized (008): ['testtime', 'Ġ=', 'Ġtime', 'Ġ(', 'Ġ)', 'Ġ-', 'Ġstarttime', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "primes_per_sec = len ( seq ) * ( 1.0 / testtime ) \n"
Original    (013): ['primes_per_sec', '=', 'len', '(', 'seq', ')', '*', '(', '1.0', '/', 'testtime', ')', '\\n']
Tokenized   (024): ['<s>', 'pr', 'imes', '_', 'per', '_', 'sec', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġseq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġtest', 'time', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['pr', 'imes', '_', 'per', '_', 'sec', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġseq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1', '.', '0', 'Ġ/', 'Ġtest', 'time', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['primes_per_sec', 'Ġ=', 'Ġlen', 'Ġ(', 'Ġseq', 'Ġ)', 'Ġ*', 'Ġ(', 'Ġ1.0', 'Ġ/', 'Ġtesttime', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "b = range ( 1 , 10 ) \n"
Original    (009): ['b', '=', 'range', '(', '1', ',', '10', ')', '\\n']
Tokenized   (012): ['<s>', 'b', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (010): ['b', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['b', 'Ġ=', 'Ġrange', 'Ġ(', 'Ġ1', 'Ġ,', 'Ġ10', 'Ġ)', 'Ġ\\n']
Counter: 10
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "w1 = threading . start_webworker ( worker , ( seq , , ) ) \n"
Original    (015): ['w1', '=', 'threading', '.', 'start_webworker', '(', 'worker', ',', '(', 'seq', ',', ',', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'w', '1', 'Ġ=', 'Ġthread', 'ing', 'Ġ.', 'Ġstart', '_', 'web', 'worker', 'Ġ(', 'Ġworker', 'Ġ,', 'Ġ(', 'Ġseq', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['w', '1', 'Ġ=', 'Ġthread', 'ing', 'Ġ.', 'Ġstart', '_', 'web', 'worker', 'Ġ(', 'Ġworker', 'Ġ,', 'Ġ(', 'Ġseq', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['w1', 'Ġ=', 'Ġthreading', 'Ġ.', 'Ġstart_webworker', 'Ġ(', 'Ġworker', 'Ġ,', 'Ġ(', 'Ġseq', 'Ġ,', 'Ġ,', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "TestError ( in seq ) \n"
Original    (006): ['TestError', '(', 'in', 'seq', ')', '\\n']
Tokenized   (010): ['<s>', 'Test', 'Error', 'Ġ(', 'Ġin', 'Ġseq', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['Test', 'Error', 'Ġ(', 'Ġin', 'Ġseq', 'Ġ)', 'Ġ\\', 'n']
Detokenized (006): ['TestError', 'Ġ(', 'Ġin', 'Ġseq', 'Ġ)', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "del self . face_groups [ : ] \n"
Original    (008): ['del', 'self', '.', 'face_groups', '[', ':', ']', '\\n']
Tokenized   (013): ['<s>', 'del', 'Ġself', 'Ġ.', 'Ġface', '_', 'groups', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['del', 'Ġself', 'Ġ.', 'Ġface', '_', 'groups', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\', 'n']
Detokenized (008): ['del', 'Ġself', 'Ġ.', 'Ġface_groups', 'Ġ[', 'Ġ:', 'Ġ]', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "mtllib_path = os . path . join ( model_path , data [ 0 ] ) \n"
Original    (016): ['mtllib_path', '=', 'os', '.', 'path', '.', 'join', '(', 'model_path', ',', 'data', '[', '0', ']', ')', '\\n']
Tokenized   (025): ['<s>', 'mt', 'll', 'ib', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġmodel', '_', 'path', 'Ġ,', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['mt', 'll', 'ib', '_', 'path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġmodel', '_', 'path', 'Ġ,', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['mtllib_path', 'Ġ=', 'Ġos', 'Ġ.', 'Ġpath', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġmodel_path', 'Ġ,', 'Ġdata', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "vertex = ( float ( x ) , float ( y ) , float ( z ) ) \n"
Original    (019): ['vertex', '=', '(', 'float', '(', 'x', ')', ',', 'float', '(', 'y', ')', ',', 'float', '(', 'z', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'ver', 'tex', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġz', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['ver', 'tex', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġz', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['vertex', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġx', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġy', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġz', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "tex_coord = ( float ( s ) , float ( t ) ) \n"
Original    (014): ['tex_coord', '=', '(', 'float', '(', 's', ')', ',', 'float', '(', 't', ')', ')', '\\n']
Tokenized   (019): ['<s>', 'tex', '_', 'coord', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġt', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['tex', '_', 'coord', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġt', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['tex_coord', 'Ġ=', 'Ġ(', 'Ġfloat', 'Ġ(', 'Ġs', 'Ġ)', 'Ġ,', 'Ġfloat', 'Ġ(', 'Ġt', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "indices = ( int ( vi ) - 1 , int ( ti ) - 1 , int ( ni ) - 1 ) \n"
Original    (025): ['indices', '=', '(', 'int', '(', 'vi', ')', '-', '1', ',', 'int', '(', 'ti', ')', '-', '1', ',', 'int', '(', 'ni', ')', '-', '1', ')', '\\n']
Tokenized   (029): ['<s>', 'ind', 'ices', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġvi', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġti', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġni', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['ind', 'ices', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġvi', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġti', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġni', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['indices', 'Ġ=', 'Ġ(', 'Ġint', 'Ġ(', 'Ġvi', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġti', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ,', 'Ġint', 'Ġ(', 'Ġni', 'Ġ)', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "glBindTexture ( GL_TEXTURE_2D , material . texture_id ) \n"
Original    (009): ['glBindTexture', '(', 'GL_TEXTURE_2D', ',', 'material', '.', 'texture_id', ')', '\\n']
Tokenized   (021): ['<s>', 'gl', 'Bind', 'Texture', 'Ġ(', 'ĠGL', '_', 'TEXTURE', '_', '2', 'D', 'Ġ,', 'Ġmaterial', 'Ġ.', 'Ġtexture', '_', 'id', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['gl', 'Bind', 'Texture', 'Ġ(', 'ĠGL', '_', 'TEXTURE', '_', '2', 'D', 'Ġ,', 'Ġmaterial', 'Ġ.', 'Ġtexture', '_', 'id', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['glBindTexture', 'Ġ(', 'ĠGL_TEXTURE_2D', 'Ġ,', 'Ġmaterial', 'Ġ.', 'Ġtexture_id', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "glPixelStorei ( GL_UNPACK_ALIGNMENT , 1 ) \n"
Original    (007): ['glPixelStorei', '(', 'GL_UNPACK_ALIGNMENT', ',', '1', ')', '\\n']
Tokenized   (021): ['<s>', 'gl', 'Pixel', 'Store', 'i', 'Ġ(', 'ĠGL', '_', 'UN', 'P', 'ACK', '_', 'AL', 'IGN', 'MENT', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['gl', 'Pixel', 'Store', 'i', 'Ġ(', 'ĠGL', '_', 'UN', 'P', 'ACK', '_', 'AL', 'IGN', 'MENT', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['glPixelStorei', 'Ġ(', 'ĠGL_UNPACK_ALIGNMENT', 'Ġ,', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "glNormal3fv ( normals [ ni ] ) \n"
Original    (008): ['glNormal3fv', '(', 'normals', '[', 'ni', ']', ')', '\\n']
Tokenized   (016): ['<s>', 'gl', 'Normal', '3', 'f', 'v', 'Ġ(', 'Ġnorm', 'als', 'Ġ[', 'Ġni', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['gl', 'Normal', '3', 'f', 'v', 'Ġ(', 'Ġnorm', 'als', 'Ġ[', 'Ġni', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['glNormal3fv', 'Ġ(', 'Ġnormals', 'Ġ[', 'Ġni', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "picture = pygame . image . load ( picture_file ) . convert ( ) \n"
Original    (015): ['picture', '=', 'pygame', '.', 'image', '.', 'load', '(', 'picture_file', ')', '.', 'convert', '(', ')', '\\n']
Tokenized   (021): ['<s>', 'picture', 'Ġ=', 'Ġpy', 'game', 'Ġ.', 'Ġimage', 'Ġ.', 'Ġload', 'Ġ(', 'Ġpicture', '_', 'file', 'Ġ)', 'Ġ.', 'Ġconvert', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['picture', 'Ġ=', 'Ġpy', 'game', 'Ġ.', 'Ġimage', 'Ġ.', 'Ġload', 'Ġ(', 'Ġpicture', '_', 'file', 'Ġ)', 'Ġ.', 'Ġconvert', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['picture', 'Ġ=', 'Ġpygame', 'Ġ.', 'Ġimage', 'Ġ.', 'Ġload', 'Ġ(', 'Ġpicture_file', 'Ġ)', 'Ġ.', 'Ġconvert', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "screen . blit ( picture , ( - picture_pos . x , picture_pos . y ) ) \n"
Original    (018): ['screen', '.', 'blit', '(', 'picture', ',', '(', '-', 'picture_pos', '.', 'x', ',', 'picture_pos', '.', 'y', ')', ')', '\\n']
Tokenized   (026): ['<s>', 'screen', 'Ġ.', 'Ġbl', 'it', 'Ġ(', 'Ġpicture', 'Ġ,', 'Ġ(', 'Ġ-', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġx', 'Ġ,', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġy', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['screen', 'Ġ.', 'Ġbl', 'it', 'Ġ(', 'Ġpicture', 'Ġ,', 'Ġ(', 'Ġ-', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġx', 'Ġ,', 'Ġpicture', '_', 'pos', 'Ġ.', 'Ġy', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['screen', 'Ġ.', 'Ġblit', 'Ġ(', 'Ġpicture', 'Ġ,', 'Ġ(', 'Ġ-', 'Ġpicture_pos', 'Ġ.', 'Ġx', 'Ġ,', 'Ġpicture_pos', 'Ġ.', 'Ġy', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "time_passed_seconds = time_passed / 1000.0 \n"
Original    (006): ['time_passed_seconds', '=', 'time_passed', '/', '1000.0', '\\n']
Tokenized   (019): ['<s>', 'time', '_', 'pass', 'ed', '_', 'seconds', 'Ġ=', 'Ġtime', '_', 'pass', 'ed', 'Ġ/', 'Ġ1000', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['time', '_', 'pass', 'ed', '_', 'seconds', 'Ġ=', 'Ġtime', '_', 'pass', 'ed', 'Ġ/', 'Ġ1000', '.', '0', 'Ġ\\', 'n']
Detokenized (006): ['time_passed_seconds', 'Ġ=', 'Ġtime_passed', 'Ġ/', 'Ġ1000.0', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "picture_pos += scroll_direction * scroll_speed * time_passed_seconds \n"
Original    (008): ['picture_pos', '+=', 'scroll_direction', '*', 'scroll_speed', '*', 'time_passed_seconds', '\\n']
Tokenized   (022): ['<s>', 'picture', '_', 'pos', 'Ġ+=', 'Ġscroll', '_', 'direction', 'Ġ*', 'Ġscroll', '_', 'speed', 'Ġ*', 'Ġtime', '_', 'pass', 'ed', '_', 'seconds', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['picture', '_', 'pos', 'Ġ+=', 'Ġscroll', '_', 'direction', 'Ġ*', 'Ġscroll', '_', 'speed', 'Ġ*', 'Ġtime', '_', 'pass', 'ed', '_', 'seconds', 'Ġ\\', 'n']
Detokenized (008): ['picture_pos', 'Ġ+=', 'Ġscroll_direction', 'Ġ*', 'Ġscroll_speed', 'Ġ*', 'Ġtime_passed_seconds', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "VERSION = open ( "version.txt" ) . readline ( ) . strip ( ) \n"
Original    (015): ['VERSION', '=', 'open', '(', '"version.txt"', ')', '.', 'readline', '(', ')', '.', 'strip', '(', ')', '\\n']
Tokenized   (023): ['<s>', 'VERSION', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'version', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['VERSION', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'version', '.', 'txt', '"', 'Ġ)', 'Ġ.', 'Ġread', 'line', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['VERSION', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"version.txt"', 'Ġ)', 'Ġ.', 'Ġreadline', 'Ġ(', 'Ġ)', 'Ġ.', 'Ġstrip', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "DOWNLOAD_URL = DOWNLOAD_BASEURL + "dubbo-client-%s-py2.7.egg" % VERSION \n"
Original    (008): ['DOWNLOAD_URL', '=', 'DOWNLOAD_BASEURL', '+', '"dubbo-client-%s-py2.7.egg"', '%', 'VERSION', '\\n']
Tokenized   (036): ['<s>', 'DOWN', 'LOAD', '_', 'URL', 'Ġ=', 'ĠDOWN', 'LOAD', '_', 'B', 'ASE', 'URL', 'Ġ+', 'Ġ"', 'd', 'ub', 'bo', '-', 'client', '-', '%', 's', '-', 'py', '2', '.', '7', '.', 'egg', '"', 'Ġ%', 'ĠVERS', 'ION', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['DOWN', 'LOAD', '_', 'URL', 'Ġ=', 'ĠDOWN', 'LOAD', '_', 'B', 'ASE', 'URL', 'Ġ+', 'Ġ"', 'd', 'ub', 'bo', '-', 'client', '-', '%', 's', '-', 'py', '2', '.', '7', '.', 'egg', '"', 'Ġ%', 'ĠVERS', 'ION', 'Ġ\\', 'n']
Detokenized (008): ['DOWNLOAD_URL', 'Ġ=', 'ĠDOWNLOAD_BASEURL', 'Ġ+', 'Ġ"dubbo-client-%s-py2.7.egg"', 'Ġ%', 'ĠVERSION', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "long_description = open ( "README.md" ) . read ( ) , \n"
Original    (012): ['long_description', '=', 'open', '(', '"README.md"', ')', '.', 'read', '(', ')', ',', '\\n']
Tokenized   (022): ['<s>', 'long', '_', 'description', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'READ', 'ME', '.', 'md', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['long', '_', 'description', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"', 'READ', 'ME', '.', 'md', '"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['long_description', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġ"README.md"', 'Ġ)', 'Ġ.', 'Ġread', 'Ġ(', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "install_requires = [ "kazoo>=2.0" , "python-jsonrpc>=0.7.3" ] , \n"
Original    (009): ['install_requires', '=', '[', '"kazoo>=2.0"', ',', '"python-jsonrpc>=0.7.3"', ']', ',', '\\n']
Tokenized   (036): ['<s>', 'install', '_', 'requires', 'Ġ=', 'Ġ[', 'Ġ"', 'k', 'az', 'oo', '>', '=', '2', '.', '0', '"', 'Ġ,', 'Ġ"', 'python', '-', 'json', 'r', 'pc', '>', '=', '0', '.', '7', '.', '3', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (034): ['install', '_', 'requires', 'Ġ=', 'Ġ[', 'Ġ"', 'k', 'az', 'oo', '>', '=', '2', '.', '0', '"', 'Ġ,', 'Ġ"', 'python', '-', 'json', 'r', 'pc', '>', '=', '0', '.', '7', '.', '3', '"', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (009): ['install_requires', 'Ġ=', 'Ġ[', 'Ġ"kazoo>=2.0"', 'Ġ,', 'Ġ"python-jsonrpc>=0.7.3"', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 34
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "field = models . BooleanField ( default = False ) , \n"
Original    (012): ['field', '=', 'models', '.', 'BooleanField', '(', 'default', '=', 'False', ')', ',', '\\n']
Tokenized   (016): ['<s>', 'field', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['field', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBoolean', 'Field', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['field', 'Ġ=', 'Ġmodels', 'Ġ.', 'ĠBooleanField', 'Ġ(', 'Ġdefault', 'Ġ=', 'ĠFalse', 'Ġ)', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "args = [ in_path , user_out_path ] , env = [ "PATH=" + os . environ . get ( "PATH" , "" ) use_sandbox = True , use_nobody = True ) \n"
Original    (032): ['args', '=', '[', 'in_path', ',', 'user_out_path', ']', ',', 'env', '=', '[', '"PATH="', '+', 'os', '.', 'environ', '.', 'get', '(', '"PATH"', ',', '""', ')', 'use_sandbox', '=', 'True', ',', 'use_nobody', '=', 'True', ')', '\\n']
Tokenized   (052): ['<s>', 'args', 'Ġ=', 'Ġ[', 'Ġin', '_', 'path', 'Ġ,', 'Ġuser', '_', 'out', '_', 'path', 'Ġ]', 'Ġ,', 'Ġenv', 'Ġ=', 'Ġ[', 'Ġ"', 'PATH', '="', 'Ġ+', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'PATH', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġuse', '_', 'sand', 'box', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġuse', '_', 'nob', 'ody', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (050): ['args', 'Ġ=', 'Ġ[', 'Ġin', '_', 'path', 'Ġ,', 'Ġuser', '_', 'out', '_', 'path', 'Ġ]', 'Ġ,', 'Ġenv', 'Ġ=', 'Ġ[', 'Ġ"', 'PATH', '="', 'Ġ+', 'Ġos', 'Ġ.', 'Ġen', 'viron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"', 'PATH', '"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġuse', '_', 'sand', 'box', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġuse', '_', 'nob', 'ody', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (032): ['args', 'Ġ=', 'Ġ[', 'Ġin_path', 'Ġ,', 'Ġuser_out_path', 'Ġ]', 'Ġ,', 'Ġenv', 'Ġ=', 'Ġ[', 'Ġ"PATH="', 'Ġ+', 'Ġos', 'Ġ.', 'Ġenviron', 'Ġ.', 'Ġget', 'Ġ(', 'Ġ"PATH"', 'Ġ,', 'Ġ""', 'Ġ)', 'Ġuse_sandbox', 'Ġ=', 'ĠTrue', 'Ġ,', 'Ġuse_nobody', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 50
===================================================================
Hidden states:  (13, 32, 768)
# Extracted words:  32
Sentence         : "print_skip = 5 , * args , ** kwargs ) : \n"
Original    (012): ['print_skip', '=', '5', ',', '*', 'args', ',', '**', 'kwargs', ')', ':', '\\n']
Tokenized   (019): ['<s>', 'print', '_', 'skip', 'Ġ=', 'Ġ5', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (017): ['print', '_', 'skip', 'Ġ=', 'Ġ5', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġk', 'w', 'args', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (012): ['print_skip', 'Ġ=', 'Ġ5', 'Ġ,', 'Ġ*', 'Ġargs', 'Ġ,', 'Ġ**', 'Ġkwargs', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 17
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "error = np . max ( np . abs ( new_v - v ) ) \n"
Original    (016): ['error', '=', 'np', '.', 'max', '(', 'np', '.', 'abs', '(', 'new_v', '-', 'v', ')', ')', '\\n']
Tokenized   (021): ['<s>', 'error', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġabs', 'Ġ(', 'Ġnew', '_', 'v', 'Ġ-', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['error', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġabs', 'Ġ(', 'Ġnew', '_', 'v', 'Ġ-', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (016): ['error', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġmax', 'Ġ(', 'Ġnp', 'Ġ.', 'Ġabs', 'Ġ(', 'Ġnew_v', 'Ġ-', 'Ġv', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "ac = ( a_0 - c ) / 2.0 \n"
Original    (010): ['ac', '=', '(', 'a_0', '-', 'c', ')', '/', '2.0', '\\n']
Tokenized   (017): ['<s>', 'ac', 'Ġ=', 'Ġ(', 'Ġa', '_', '0', 'Ġ-', 'Ġc', 'Ġ)', 'Ġ/', 'Ġ2', '.', '0', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['ac', 'Ġ=', 'Ġ(', 'Ġa', '_', '0', 'Ġ-', 'Ġc', 'Ġ)', 'Ġ/', 'Ġ2', '.', '0', 'Ġ\\', 'n']
Detokenized (010): ['ac', 'Ġ=', 'Ġ(', 'Ġa_0', 'Ġ-', 'Ġc', 'Ġ)', 'Ġ/', 'Ġ2.0', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "R = - R \n"
Original    (005): ['R', '=', '-', 'R', '\\n']
Tokenized   (008): ['<s>', 'R', 'Ġ=', 'Ġ-', 'ĠR', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['R', 'Ġ=', 'Ġ-', 'ĠR', 'Ġ\\', 'n']
Detokenized (005): ['R', 'Ġ=', 'Ġ-', 'ĠR', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "B = np . array ( [ [ 0. ] , \n"
Original    (012): ['B', '=', 'np', '.', 'array', '(', '[', '[', '0.', ']', ',', '\\n']
Tokenized   (016): ['<s>', 'B', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (014): ['B', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0', '.', 'Ġ]', 'Ġ,', 'Ġ\\', 'n']
Detokenized (012): ['B', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġarray', 'Ġ(', 'Ġ[', 'Ġ[', 'Ġ0.', 'Ġ]', 'Ġ,', 'Ġ\\n']
Counter: 14
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "Fr , Kr , Pr = self . Fr , self . Kr , self . Pr \n"
Original    (018): ['Fr', ',', 'Kr', ',', 'Pr', '=', 'self', '.', 'Fr', ',', 'self', '.', 'Kr', ',', 'self', '.', 'Pr', '\\n']
Tokenized   (021): ['<s>', 'Fr', 'Ġ,', 'ĠKr', 'Ġ,', 'ĠPr', 'Ġ=', 'Ġself', 'Ġ.', 'ĠFr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠKr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠPr', 'Ġ\\', 'n', '</s>']
Filtered   (019): ['Fr', 'Ġ,', 'ĠKr', 'Ġ,', 'ĠPr', 'Ġ=', 'Ġself', 'Ġ.', 'ĠFr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠKr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠPr', 'Ġ\\', 'n']
Detokenized (018): ['Fr', 'Ġ,', 'ĠKr', 'Ġ,', 'ĠPr', 'Ġ=', 'Ġself', 'Ġ.', 'ĠFr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠKr', 'Ġ,', 'Ġself', 'Ġ.', 'ĠPr', 'Ġ\\n']
Counter: 19
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "Fs , Ks , Ps = rblq . robust_rule_simple ( P_init = Pr , tol = 1e-12 ) \n"
Original    (019): ['Fs', ',', 'Ks', ',', 'Ps', '=', 'rblq', '.', 'robust_rule_simple', '(', 'P_init', '=', 'Pr', ',', 'tol', '=', '1e-12', ')', '\\n']
Tokenized   (035): ['<s>', 'Fs', 'Ġ,', 'ĠK', 's', 'Ġ,', 'ĠPs', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġrobust', '_', 'rule', '_', 'simple', 'Ġ(', 'ĠP', '_', 'init', 'Ġ=', 'ĠPr', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'Ġ1', 'e', '-', '12', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['Fs', 'Ġ,', 'ĠK', 's', 'Ġ,', 'ĠPs', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġrobust', '_', 'rule', '_', 'simple', 'Ġ(', 'ĠP', '_', 'init', 'Ġ=', 'ĠPr', 'Ġ,', 'Ġto', 'l', 'Ġ=', 'Ġ1', 'e', '-', '12', 'Ġ)', 'Ġ\\', 'n']
Detokenized (019): ['Fs', 'Ġ,', 'ĠKs', 'Ġ,', 'ĠPs', 'Ġ=', 'Ġrblq', 'Ġ.', 'Ġrobust_rule_simple', 'Ġ(', 'ĠP_init', 'Ġ=', 'ĠPr', 'Ġ,', 'Ġtol', 'Ġ=', 'Ġ1e-12', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 19, 768)
# Extracted words:  19
Sentence         : "Kf , Pf , df , Of , of = rblq . evaluate_F ( Fr ) \n"
Original    (017): ['Kf', ',', 'Pf', ',', 'df', ',', 'Of', ',', 'of', '=', 'rblq', '.', 'evaluate_F', '(', 'Fr', ')', '\\n']
Tokenized   (025): ['<s>', 'K', 'f', 'Ġ,', 'ĠPf', 'Ġ,', 'Ġdf', 'Ġ,', 'ĠOf', 'Ġ,', 'Ġof', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġevaluate', '_', 'F', 'Ġ(', 'ĠFr', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (023): ['K', 'f', 'Ġ,', 'ĠPf', 'Ġ,', 'Ġdf', 'Ġ,', 'ĠOf', 'Ġ,', 'Ġof', 'Ġ=', 'Ġr', 'bl', 'q', 'Ġ.', 'Ġevaluate', '_', 'F', 'Ġ(', 'ĠFr', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['Kf', 'Ġ,', 'ĠPf', 'Ġ,', 'Ġdf', 'Ġ,', 'ĠOf', 'Ġ,', 'Ġof', 'Ġ=', 'Ġrblq', 'Ġ.', 'Ġevaluate_F', 'Ġ(', 'ĠFr', 'Ġ)', 'Ġ\\n']
Counter: 23
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "group = h5f . createGroup ( "/" , ) \n"
Original    (010): ['group', '=', 'h5f', '.', 'createGroup', '(', '"/"', ',', ')', '\\n']
Tokenized   (017): ['<s>', 'group', 'Ġ=', 'Ġh', '5', 'f', 'Ġ.', 'Ġcreate', 'Group', 'Ġ(', 'Ġ"/', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['group', 'Ġ=', 'Ġh', '5', 'f', 'Ġ.', 'Ġcreate', 'Group', 'Ġ(', 'Ġ"/', '"', 'Ġ,', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['group', 'Ġ=', 'Ġh5f', 'Ġ.', 'ĠcreateGroup', 'Ġ(', 'Ġ"/"', 'Ġ,', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "global ctr \n"
Original    (003): ['global', 'ctr', '\\n']
Tokenized   (007): ['<s>', 'global', 'Ġc', 'tr', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['global', 'Ġc', 'tr', 'Ġ\\', 'n']
Detokenized (003): ['global', 'Ġctr', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 3, 768)
# Extracted words:  3
Sentence         : "listOfInputPaths . append ( rootdir + "/Raw/Yahoo/US/NYSE/" ) \n"
Original    (009): ['listOfInputPaths', '.', 'append', '(', 'rootdir', '+', '"/Raw/Yahoo/US/NYSE/"', ')', '\\n']
Tokenized   (026): ['<s>', 'list', 'Of', 'Input', 'Path', 's', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġroot', 'dir', 'Ġ+', 'Ġ"/', 'Raw', '/', 'Y', 'ahoo', '/', 'US', '/', 'NYSE', '/"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['list', 'Of', 'Input', 'Path', 's', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġroot', 'dir', 'Ġ+', 'Ġ"/', 'Raw', '/', 'Y', 'ahoo', '/', 'US', '/', 'NYSE', '/"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['listOfInputPaths', 'Ġ.', 'Ġappend', 'Ġ(', 'Ġrootdir', 'Ġ+', 'Ġ"/Raw/Yahoo/US/NYSE/"', 'Ġ)', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "filtered_names = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ 0 ] ) , filtered_names ) \n"
Original    (025): ['filtered_names', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'str', '(', 'fileExtensionToRemove', ')', ')', '[', '0', ']', ')', ',', 'filtered_names', ')', '\\n']
Tokenized   (037): ['<s>', 'fil', 'tered', '_', 'names', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġfiltered', '_', 'names', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['fil', 'tered', '_', 'names', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġfiltered', '_', 'names', 'Ġ)', 'Ġ\\', 'n']
Detokenized (025): ['filtered_names', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠfileExtensionToRemove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġfiltered_names', 'Ġ)', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 25, 768)
# Extracted words:  25
Sentence         : "stock_data = np . loadtxt ( path + stock + ".csv" , np . float , None , "," , None , 1 , use_cols ) \n"
Original    (027): ['stock_data', '=', 'np', '.', 'loadtxt', '(', 'path', '+', 'stock', '+', '".csv"', ',', 'np', '.', 'float', ',', 'None', ',', '","', ',', 'None', ',', '1', ',', 'use_cols', ')', '\\n']
Tokenized   (039): ['<s>', 'stock', '_', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġload', 'txt', 'Ġ(', 'Ġpath', 'Ġ+', 'Ġstock', 'Ġ+', 'Ġ".', 'csv', '"', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ"', ',"', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġuse', '_', 'col', 's', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (037): ['stock', '_', 'data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġload', 'txt', 'Ġ(', 'Ġpath', 'Ġ+', 'Ġstock', 'Ġ+', 'Ġ".', 'csv', '"', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ"', ',"', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġuse', '_', 'col', 's', 'Ġ)', 'Ġ\\', 'n']
Detokenized (027): ['stock_data', 'Ġ=', 'Ġnp', 'Ġ.', 'Ġloadtxt', 'Ġ(', 'Ġpath', 'Ġ+', 'Ġstock', 'Ġ+', 'Ġ".csv"', 'Ġ,', 'Ġnp', 'Ġ.', 'Ġfloat', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ","', 'Ġ,', 'ĠNone', 'Ġ,', 'Ġ1', 'Ġ,', 'Ġuse_cols', 'Ġ)', 'Ġ\\n']
Counter: 37
===================================================================
Hidden states:  (13, 27, 768)
# Extracted words:  27
Sentence         : "pkl . dump ( stock_data , f , - 1 ) \n"
Original    (012): ['pkl', '.', 'dump', '(', 'stock_data', ',', 'f', ',', '-', '1', ')', '\\n']
Tokenized   (018): ['<s>', 'p', 'kl', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġstock', '_', 'data', 'Ġ,', 'Ġf', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (016): ['p', 'kl', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġstock', '_', 'data', 'Ġ,', 'Ġf', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['pkl', 'Ġ.', 'Ġdump', 'Ġ(', 'Ġstock_data', 'Ġ,', 'Ġf', 'Ġ,', 'Ġ-', 'Ġ1', 'Ġ)', 'Ġ\\n']
Counter: 16
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "startday = dt . datetime ( t [ 2 ] , t [ 0 ] , t [ 1 ] ) \n"
Original    (022): ['startday', '=', 'dt', '.', 'datetime', '(', 't', '[', '2', ']', ',', 't', '[', '0', ']', ',', 't', '[', '1', ']', ')', '\\n']
Tokenized   (028): ['<s>', 'start', 'day', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġt', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (026): ['start', 'day', 'Ġ=', 'Ġd', 't', 'Ġ.', 'Ġdat', 'etime', 'Ġ(', 'Ġt', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (022): ['startday', 'Ġ=', 'Ġdt', 'Ġ.', 'Ġdatetime', 'Ġ(', 'Ġt', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ,', 'Ġt', 'Ġ[', 'Ġ1', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 26
===================================================================
Hidden states:  (13, 22, 768)
# Extracted words:  22
Sentence         : "t = map ( int , sys . argv [ 2 ] . split ( ) ) \n"
Original    (018): ['t', '=', 'map', '(', 'int', ',', 'sys', '.', 'argv', '[', '2', ']', '.', 'split', '(', ')', ')', '\\n']
Tokenized   (022): ['<s>', 't', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġint', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['t', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġint', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['t', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġint', 'Ġ,', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ.', 'Ġsplit', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "historic = dataobj . get_data ( timestamps , symbols , "close" ) \n"
Original    (013): ['historic', '=', 'dataobj', '.', 'get_data', '(', 'timestamps', ',', 'symbols', ',', '"close"', ')', '\\n']
Tokenized   (023): ['<s>', 'historic', 'Ġ=', 'Ġdata', 'obj', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġtim', 'est', 'amps', 'Ġ,', 'Ġsymbols', 'Ġ,', 'Ġ"', 'close', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['historic', 'Ġ=', 'Ġdata', 'obj', 'Ġ.', 'Ġget', '_', 'data', 'Ġ(', 'Ġtim', 'est', 'amps', 'Ġ,', 'Ġsymbols', 'Ġ,', 'Ġ"', 'close', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (013): ['historic', 'Ġ=', 'Ġdataobj', 'Ġ.', 'Ġget_data', 'Ġ(', 'Ġtimestamps', 'Ġ,', 'Ġsymbols', 'Ġ,', 'Ġ"close"', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 13, 768)
# Extracted words:  13
Sentence         : "alloc = alloc . append ( DataMatrix ( index = [ historic . index [ date ] ] , data = [ alloc_val ] , columns = [ symbols ~~ alloc [ ] = 1 - alloc [ symbols [ 0 ] ] \n"
Original    (044): ['alloc', '=', 'alloc', '.', 'append', '(', 'DataMatrix', '(', 'index', '=', '[', 'historic', '.', 'index', '[', 'date', ']', ']', ',', 'data', '=', '[', 'alloc_val', ']', ',', 'columns', '=', '[', 'symbols', '~~', 'alloc', '[', ']', '=', '1', '-', 'alloc', '[', 'symbols', '[', '0', ']', ']', '\\n']
Tokenized   (051): ['<s>', 'alloc', 'Ġ=', 'Ġalloc', 'Ġ.', 'Ġappend', 'Ġ(', 'ĠData', 'Matrix', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġ[', 'Ġhistoric', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġdate', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġalloc', '_', 'val', 'Ġ]', 'Ġ,', 'Ġcolumns', 'Ġ=', 'Ġ[', 'Ġsymbols', 'Ġ', '~~', 'Ġalloc', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġalloc', 'Ġ[', 'Ġsymbols', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (049): ['alloc', 'Ġ=', 'Ġalloc', 'Ġ.', 'Ġappend', 'Ġ(', 'ĠData', 'Matrix', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġ[', 'Ġhistoric', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġdate', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġalloc', '_', 'val', 'Ġ]', 'Ġ,', 'Ġcolumns', 'Ġ=', 'Ġ[', 'Ġsymbols', 'Ġ', '~~', 'Ġalloc', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġalloc', 'Ġ[', 'Ġsymbols', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\', 'n']
Detokenized (044): ['alloc', 'Ġ=', 'Ġalloc', 'Ġ.', 'Ġappend', 'Ġ(', 'ĠDataMatrix', 'Ġ(', 'Ġindex', 'Ġ=', 'Ġ[', 'Ġhistoric', 'Ġ.', 'Ġindex', 'Ġ[', 'Ġdate', 'Ġ]', 'Ġ]', 'Ġ,', 'Ġdata', 'Ġ=', 'Ġ[', 'Ġalloc_val', 'Ġ]', 'Ġ,', 'Ġcolumns', 'Ġ=', 'Ġ[', 'Ġsymbols', 'Ġ~~', 'Ġalloc', 'Ġ[', 'Ġ]', 'Ġ=', 'Ġ1', 'Ġ-', 'Ġalloc', 'Ġ[', 'Ġsymbols', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ]', 'Ġ\\n']
Counter: 49
===================================================================
Hidden states:  (13, 44, 768)
# Extracted words:  44
Sentence         : "output = open ( sys . argv [ 3 ] , "wb" ) \n"
Original    (014): ['output', '=', 'open', '(', 'sys', '.', 'argv', '[', '3', ']', ',', '"wb"', ')', '\\n']
Tokenized   (020): ['<s>', 'output', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ"', 'wb', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['output', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġarg', 'v', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ"', 'wb', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['output', 'Ġ=', 'Ġopen', 'Ġ(', 'Ġsys', 'Ġ.', 'Ġargv', 'Ġ[', 'Ġ3', 'Ġ]', 'Ġ,', 'Ġ"wb"', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "stocksAtThisPath = map ( lambda x : ( x . partition ( str ( fileExtensionToRemove ) ) [ 0 ] ) , stocksAtThisPath \n"
Original    (024): ['stocksAtThisPath', '=', 'map', '(', 'lambda', 'x', ':', '(', 'x', '.', 'partition', '(', 'str', '(', 'fileExtensionToRemove', ')', ')', '[', '0', ']', ')', ',', 'stocksAtThisPath', '\\n']
Tokenized   (037): ['<s>', 'stocks', 'At', 'This', 'Path', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġstocks', 'At', 'This', 'Path', 'Ġ\\', 'n', '</s>']
Filtered   (035): ['stocks', 'At', 'This', 'Path', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'Ġfile', 'Ext', 'ension', 'To', 'Remove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'Ġstocks', 'At', 'This', 'Path', 'Ġ\\', 'n']
Detokenized (024): ['stocksAtThisPath', 'Ġ=', 'Ġmap', 'Ġ(', 'Ġlambda', 'Ġx', 'Ġ:', 'Ġ(', 'Ġx', 'Ġ.', 'Ġpartition', 'Ġ(', 'Ġstr', 'Ġ(', 'ĠfileExtensionToRemove', 'Ġ)', 'Ġ)', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ)', 'Ġ,', 'ĠstocksAtThisPath', 'Ġ\\n']
Counter: 35
===================================================================
Hidden states:  (13, 24, 768)
# Extracted words:  24
Sentence         : "@ memoize_default ( None , evaluator_is_first_arg = True ) \n"
Original    (010): ['@', 'memoize_default', '(', 'None', ',', 'evaluator_is_first_arg', '=', 'True', ')', '\\n']
Tokenized   (024): ['<s>', '@', 'Ġmemo', 'ize', '_', 'default', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġeval', 'u', 'ator', '_', 'is', '_', 'first', '_', 'arg', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['@', 'Ġmemo', 'ize', '_', 'default', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġeval', 'u', 'ator', '_', 'is', '_', 'first', '_', 'arg', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\', 'n']
Detokenized (010): ['@', 'Ġmemoize_default', 'Ġ(', 'ĠNone', 'Ġ,', 'Ġevaluator_is_first_arg', 'Ġ=', 'ĠTrue', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "param_str = _search_param_in_docstr ( func . raw_doc , str ( param . get_name ( ) ) ) \n"
Original    (018): ['param_str', '=', '_search_param_in_docstr', '(', 'func', '.', 'raw_doc', ',', 'str', '(', 'param', '.', 'get_name', '(', ')', ')', ')', '\\n']
Tokenized   (035): ['<s>', 'param', '_', 'str', 'Ġ=', 'Ġ_', 'search', '_', 'param', '_', 'in', '_', 'doc', 'str', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġraw', '_', 'doc', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġparam', 'Ġ.', 'Ġget', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (033): ['param', '_', 'str', 'Ġ=', 'Ġ_', 'search', '_', 'param', '_', 'in', '_', 'doc', 'str', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġraw', '_', 'doc', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġparam', 'Ġ.', 'Ġget', '_', 'name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (018): ['param_str', 'Ġ=', 'Ġ_search_param_in_docstr', 'Ġ(', 'Ġfunc', 'Ġ.', 'Ġraw_doc', 'Ġ,', 'Ġstr', 'Ġ(', 'Ġparam', 'Ġ.', 'Ġget_name', 'Ġ(', 'Ġ)', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 33
===================================================================
Hidden states:  (13, 18, 768)
# Extracted words:  18
Sentence         : "patterns = [ re . compile ( p % re . escape ( param_str ) ) \n"
Original    (017): ['patterns', '=', '[', 're', '.', 'compile', '(', 'p', '%', 're', '.', 'escape', '(', 'param_str', ')', ')', '\\n']
Tokenized   (023): ['<s>', 'pattern', 's', 'Ġ=', 'Ġ[', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġp', 'Ġ%', 'Ġre', 'Ġ.', 'Ġescape', 'Ġ(', 'Ġparam', '_', 'str', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (021): ['pattern', 's', 'Ġ=', 'Ġ[', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġp', 'Ġ%', 'Ġre', 'Ġ.', 'Ġescape', 'Ġ(', 'Ġparam', '_', 'str', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (017): ['patterns', 'Ġ=', 'Ġ[', 'Ġre', 'Ġ.', 'Ġcompile', 'Ġ(', 'Ġp', 'Ġ%', 'Ġre', 'Ġ.', 'Ġescape', 'Ġ(', 'Ġparam_str', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 21
===================================================================
Hidden states:  (13, 17, 768)
# Extracted words:  17
Sentence         : "it = ( evaluator . execute ( d ) for d in definitions ) \n"
Original    (015): ['it', '=', '(', 'evaluator', '.', 'execute', '(', 'd', ')', 'for', 'd', 'in', 'definitions', ')', '\\n']
Tokenized   (020): ['<s>', 'it', 'Ġ=', 'Ġ(', 'Ġeval', 'u', 'ator', 'Ġ.', 'Ġexecute', 'Ġ(', 'Ġd', 'Ġ)', 'Ġfor', 'Ġd', 'Ġin', 'Ġdefinitions', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['it', 'Ġ=', 'Ġ(', 'Ġeval', 'u', 'ator', 'Ġ.', 'Ġexecute', 'Ġ(', 'Ġd', 'Ġ)', 'Ġfor', 'Ġd', 'Ġin', 'Ġdefinitions', 'Ġ)', 'Ġ\\', 'n']
Detokenized (015): ['it', 'Ġ=', 'Ġ(', 'Ġevaluator', 'Ġ.', 'Ġexecute', 'Ġ(', 'Ġd', 'Ġ)', 'Ġfor', 'Ġd', 'Ġin', 'Ġdefinitions', 'Ġ)', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 15, 768)
# Extracted words:  15
Sentence         : "tok = parsed . module . subscopes [ 0 ] . statements [ 0 ] . _token_list [ 2 ] \n"
Original    (021): ['tok', '=', 'parsed', '.', 'module', '.', 'subscopes', '[', '0', ']', '.', 'statements', '[', '0', ']', '.', '_token_list', '[', '2', ']', '\\n']
Tokenized   (029): ['<s>', 't', 'ok', 'Ġ=', 'Ġparsed', 'Ġ.', 'Ġmodule', 'Ġ.', 'Ġsubsc', 'opes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġstatements', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġ_', 'token', '_', 'list', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (027): ['t', 'ok', 'Ġ=', 'Ġparsed', 'Ġ.', 'Ġmodule', 'Ġ.', 'Ġsubsc', 'opes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġstatements', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġ_', 'token', '_', 'list', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['tok', 'Ġ=', 'Ġparsed', 'Ġ.', 'Ġmodule', 'Ġ.', 'Ġsubscopes', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġstatements', 'Ġ[', 'Ġ0', 'Ġ]', 'Ġ.', 'Ġ_token_list', 'Ġ[', 'Ġ2', 'Ġ]', 'Ġ\\n']
Counter: 27
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "__slots__ = ( "graphVariable" , \n"
Original    (006): ['__slots__', '=', '(', '"graphVariable"', ',', '\\n']
Tokenized   (015): ['<s>', '__', 'sl', 'ots', '__', 'Ġ=', 'Ġ(', 'Ġ"', 'graph', 'Variable', '"', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['__', 'sl', 'ots', '__', 'Ġ=', 'Ġ(', 'Ġ"', 'graph', 'Variable', '"', 'Ġ,', 'Ġ\\', 'n']
Detokenized (006): ['__slots__', 'Ġ=', 'Ġ(', 'Ġ"graphVariable"', 'Ġ,', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 6, 768)
# Extracted words:  6
Sentence         : "( None , \n"
Original    (004): ['(', 'None', ',', '\\n']
Tokenized   (007): ['<s>', '(', 'ĠNone', 'Ġ,', 'Ġ\\', 'n', '</s>']
Filtered   (005): ['(', 'ĠNone', 'Ġ,', 'Ġ\\', 'n']
Detokenized (004): ['(', 'ĠNone', 'Ġ,', 'Ġ\\n']
Counter: 5
===================================================================
Hidden states:  (13, 4, 768)
# Extracted words:  4
Sentence         : "def __init__ ( self , patterns = [ ] , prolog = None ) : \n"
Original    (016): ['def', '__init__', '(', 'self', ',', 'patterns', '=', '[', ']', ',', 'prolog', '=', 'None', ')', ':', '\\n']
Tokenized   (022): ['<s>', 'def', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġpatterns', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġpro', 'log', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['def', 'Ġ__', 'init', '__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġpatterns', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġpro', 'log', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (016): ['def', 'Ġ__init__', 'Ġ(', 'Ġself', 'Ġ,', 'Ġpatterns', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ,', 'Ġprolog', 'Ġ=', 'ĠNone', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 16, 768)
# Extracted words:  16
Sentence         : "return term . n3 ( ) \n"
Original    (007): ['return', 'term', '.', 'n3', '(', ')', '\\n']
Tokenized   (011): ['<s>', 'return', 'Ġterm', 'Ġ.', 'Ġn', '3', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (009): ['return', 'Ġterm', 'Ġ.', 'Ġn', '3', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): ['return', 'Ġterm', 'Ġ.', 'Ġn3', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 9
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : ". join ( [ + . join ( [ \n"
Original    (010): ['.', 'join', '(', '[', '+', '.', 'join', '(', '[', '\\n']
Tokenized   (013): ['<s>', '.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ+', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ+', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ\\', 'n']
Detokenized (010): ['.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ+', 'Ġ.', 'Ġjoin', 'Ġ(', 'Ġ[', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "[ ( "a" , "?b" , 24 ) , ( "?r" , "?c" , 12345 ) , ( v1 , "?c" , 3333 ) , ( u1 , "?c" , 9999 ) ] ) \n"
Original    (035): ['[', '(', '"a"', ',', '"?b"', ',', '24', ')', ',', '(', '"?r"', ',', '"?c"', ',', '12345', ')', ',', '(', 'v1', ',', '"?c"', ',', '3333', ')', ',', '(', 'u1', ',', '"?c"', ',', '9999', ')', ']', ')', '\\n']
Tokenized   (060): ['<s>', '[', 'Ġ(', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', '?', 'b', '"', 'Ġ,', 'Ġ24', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ"', '?', 'r', '"', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ123', '45', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġv', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ3', '333', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġu', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ9', '999', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (058): ['[', 'Ġ(', 'Ġ"', 'a', '"', 'Ġ,', 'Ġ"', '?', 'b', '"', 'Ġ,', 'Ġ24', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ"', '?', 'r', '"', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ123', '45', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġv', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ3', '333', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġu', '1', 'Ġ,', 'Ġ"', '?', 'c', '"', 'Ġ,', 'Ġ9', '999', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (035): ['[', 'Ġ(', 'Ġ"a"', 'Ġ,', 'Ġ"?b"', 'Ġ,', 'Ġ24', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġ"?r"', 'Ġ,', 'Ġ"?c"', 'Ġ,', 'Ġ12345', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġv1', 'Ġ,', 'Ġ"?c"', 'Ġ,', 'Ġ3333', 'Ġ)', 'Ġ,', 'Ġ(', 'Ġu1', 'Ġ,', 'Ġ"?c"', 'Ġ,', 'Ġ9999', 'Ġ)', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 58
===================================================================
Hidden states:  (13, 35, 768)
# Extracted words:  35
Sentence         : "unittest . TextTestRunner ( verbosity = 3 ) . run ( suite ) \n"
Original    (014): ['unittest', '.', 'TextTestRunner', '(', 'verbosity', '=', '3', ')', '.', 'run', '(', 'suite', ')', '\\n']
Tokenized   (022): ['<s>', 'un', 'itt', 'est', 'Ġ.', 'ĠText', 'Test', 'Runner', 'Ġ(', 'Ġverb', 'osity', 'Ġ=', 'Ġ3', 'Ġ)', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġsuite', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['un', 'itt', 'est', 'Ġ.', 'ĠText', 'Test', 'Runner', 'Ġ(', 'Ġverb', 'osity', 'Ġ=', 'Ġ3', 'Ġ)', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġsuite', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['unittest', 'Ġ.', 'ĠTextTestRunner', 'Ġ(', 'Ġverbosity', 'Ġ=', 'Ġ3', 'Ġ)', 'Ġ.', 'Ġrun', 'Ġ(', 'Ġsuite', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : ") . parse ( "http://www.w3.org/People/Berners-Lee/card.rdf" ) \n"
Original    (007): [')', '.', 'parse', '(', '"http://www.w3.org/People/Berners-Lee/card.rdf"', ')', '\\n']
Tokenized   (031): ['<s>', ')', 'Ġ.', 'Ġparse', 'Ġ(', 'Ġ"', 'http', '://', 'www', '.', 'w', '3', '.', 'org', '/', 'People', '/', 'Bern', 'ers', '-', 'Lee', '/', 'card', '.', 'rd', 'f', '"', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (029): [')', 'Ġ.', 'Ġparse', 'Ġ(', 'Ġ"', 'http', '://', 'www', '.', 'w', '3', '.', 'org', '/', 'People', '/', 'Bern', 'ers', '-', 'Lee', '/', 'card', '.', 'rd', 'f', '"', 'Ġ)', 'Ġ\\', 'n']
Detokenized (007): [')', 'Ġ.', 'Ġparse', 'Ġ(', 'Ġ"http://www.w3.org/People/Berners-Lee/card.rdf"', 'Ġ)', 'Ġ\\n']
Counter: 29
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "graph . get_context ( URIRef ( ) \n"
Original    (008): ['graph', '.', 'get_context', '(', 'URIRef', '(', ')', '\\n']
Tokenized   (015): ['<s>', 'graph', 'Ġ.', 'Ġget', '_', 'context', 'Ġ(', 'ĠUR', 'IR', 'ef', 'Ġ(', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (013): ['graph', 'Ġ.', 'Ġget', '_', 'context', 'Ġ(', 'ĠUR', 'IR', 'ef', 'Ġ(', 'Ġ)', 'Ġ\\', 'n']
Detokenized (008): ['graph', 'Ġ.', 'Ġget_context', 'Ġ(', 'ĠURIRef', 'Ġ(', 'Ġ)', 'Ġ\\n']
Counter: 13
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "bob . set ( FOAF . name , Literal ( "Bob" ) ) \n"
Original    (014): ['bob', '.', 'set', '(', 'FOAF', '.', 'name', ',', 'Literal', '(', '"Bob"', ')', ')', '\\n']
Tokenized   (022): ['<s>', 'b', 'ob', 'Ġ.', 'Ġset', 'Ġ(', 'ĠFO', 'AF', 'Ġ.', 'Ġname', 'Ġ,', 'ĠLit', 'eral', 'Ġ(', 'Ġ"', 'Bob', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (020): ['b', 'ob', 'Ġ.', 'Ġset', 'Ġ(', 'ĠFO', 'AF', 'Ġ.', 'Ġname', 'Ġ,', 'ĠLit', 'eral', 'Ġ(', 'Ġ"', 'Bob', '"', 'Ġ)', 'Ġ)', 'Ġ\\', 'n']
Detokenized (014): ['bob', 'Ġ.', 'Ġset', 'Ġ(', 'ĠFOAF', 'Ġ.', 'Ġname', 'Ġ,', 'ĠLiteral', 'Ġ(', 'Ġ"Bob"', 'Ġ)', 'Ġ)', 'Ġ\\n']
Counter: 20
===================================================================
Hidden states:  (13, 14, 768)
# Extracted words:  14
Sentence         : "print g . serialize ( format = ) \n"
Original    (009): ['print', 'g', '.', 'serialize', '(', 'format', '=', ')', '\\n']
Tokenized   (013): ['<s>', 'print', 'Ġg', 'Ġ.', 'Ġserial', 'ize', 'Ġ(', 'Ġformat', 'Ġ=', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['print', 'Ġg', 'Ġ.', 'Ġserial', 'ize', 'Ġ(', 'Ġformat', 'Ġ=', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['print', 'Ġg', 'Ġ.', 'Ġserialize', 'Ġ(', 'Ġformat', 'Ġ=', 'Ġ)', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Sentence         : "context = self . uriref ( ) or self . nodeid ( ) or self . sink . identifier \n"
Original    (020): ['context', '=', 'self', '.', 'uriref', '(', ')', 'or', 'self', '.', 'nodeid', '(', ')', 'or', 'self', '.', 'sink', '.', 'identifier', '\\n']
Tokenized   (026): ['<s>', 'context', 'Ġ=', 'Ġself', 'Ġ.', 'Ġur', 'ire', 'f', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġnode', 'id', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġsink', 'Ġ.', 'Ġidentifier', 'Ġ\\', 'n', '</s>']
Filtered   (024): ['context', 'Ġ=', 'Ġself', 'Ġ.', 'Ġur', 'ire', 'f', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġnode', 'id', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġsink', 'Ġ.', 'Ġidentifier', 'Ġ\\', 'n']
Detokenized (020): ['context', 'Ġ=', 'Ġself', 'Ġ.', 'Ġuriref', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġnodeid', 'Ġ(', 'Ġ)', 'Ġor', 'Ġself', 'Ġ.', 'Ġsink', 'Ġ.', 'Ġidentifier', 'Ġ\\n']
Counter: 24
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "from rdflib . query import Result , ResultSerializer , ResultParser \n"
Original    (011): ['from', 'rdflib', '.', 'query', 'import', 'Result', ',', 'ResultSerializer', ',', 'ResultParser', '\\n']
Tokenized   (020): ['<s>', 'from', 'Ġr', 'd', 'fl', 'ib', 'Ġ.', 'Ġquery', 'Ġimport', 'ĠResult', 'Ġ,', 'ĠResult', 'Serial', 'izer', 'Ġ,', 'ĠResult', 'Parser', 'Ġ\\', 'n', '</s>']
Filtered   (018): ['from', 'Ġr', 'd', 'fl', 'ib', 'Ġ.', 'Ġquery', 'Ġimport', 'ĠResult', 'Ġ,', 'ĠResult', 'Serial', 'izer', 'Ġ,', 'ĠResult', 'Parser', 'Ġ\\', 'n']
Detokenized (011): ['from', 'Ġrdflib', 'Ġ.', 'Ġquery', 'Ġimport', 'ĠResult', 'Ġ,', 'ĠResultSerializer', 'Ġ,', 'ĠResultParser', 'Ġ\\n']
Counter: 18
===================================================================
Hidden states:  (13, 11, 768)
# Extracted words:  11
Sentence         : "class CSVResultParser ( ResultParser ) : \n"
Original    (007): ['class', 'CSVResultParser', '(', 'ResultParser', ')', ':', '\\n']
Tokenized   (013): ['<s>', 'class', 'ĠCSV', 'Result', 'Parser', 'Ġ(', 'ĠResult', 'Parser', 'Ġ)', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['class', 'ĠCSV', 'Result', 'Parser', 'Ġ(', 'ĠResult', 'Parser', 'Ġ)', 'Ġ:', 'Ġ\\', 'n']
Detokenized (007): ['class', 'ĠCSVResultParser', 'Ġ(', 'ĠResultParser', 'Ġ)', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "r . bindings = [ ] \n"
Original    (007): ['r', '.', 'bindings', '=', '[', ']', '\\n']
Tokenized   (010): ['<s>', 'r', 'Ġ.', 'Ġbindings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (008): ['r', 'Ġ.', 'Ġbindings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\', 'n']
Detokenized (007): ['r', 'Ġ.', 'Ġbindings', 'Ġ=', 'Ġ[', 'Ġ]', 'Ġ\\n']
Counter: 8
===================================================================
Hidden states:  (13, 7, 768)
# Extracted words:  7
Sentence         : "if result . type != "SELECT" : \n"
Original    (008): ['if', 'result', '.', 'type', '!=', '"SELECT"', ':', '\\n']
Tokenized   (013): ['<s>', 'if', 'Ġresult', 'Ġ.', 'Ġtype', 'Ġ!=', 'Ġ"', 'SELECT', '"', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['if', 'Ġresult', 'Ġ.', 'Ġtype', 'Ġ!=', 'Ġ"', 'SELECT', '"', 'Ġ:', 'Ġ\\', 'n']
Detokenized (008): ['if', 'Ġresult', 'Ġ.', 'Ġtype', 'Ġ!=', 'Ġ"SELECT"', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 8, 768)
# Extracted words:  8
Sentence         : "stream = codecs . getwriter ( encoding ) ( stream ) \n"
Original    (012): ['stream', '=', 'codecs', '.', 'getwriter', '(', 'encoding', ')', '(', 'stream', ')', '\\n']
Tokenized   (017): ['<s>', 'stream', 'Ġ=', 'Ġcodec', 's', 'Ġ.', 'Ġget', 'writer', 'Ġ(', 'Ġencoding', 'Ġ)', 'Ġ(', 'Ġstream', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['stream', 'Ġ=', 'Ġcodec', 's', 'Ġ.', 'Ġget', 'writer', 'Ġ(', 'Ġencoding', 'Ġ)', 'Ġ(', 'Ġstream', 'Ġ)', 'Ġ\\', 'n']
Detokenized (012): ['stream', 'Ġ=', 'Ġcodecs', 'Ġ.', 'Ġgetwriter', 'Ġ(', 'Ġencoding', 'Ġ)', 'Ġ(', 'Ġstream', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 12, 768)
# Extracted words:  12
Sentence         : "vs = [ self . serializeTerm ( v , encoding ) for v in self . result . vars ] \n"
Original    (021): ['vs', '=', '[', 'self', '.', 'serializeTerm', '(', 'v', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'vars', ']', '\\n']
Tokenized   (027): ['<s>', 'vs', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġserial', 'ize', 'Term', 'Ġ(', 'Ġv', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ\\', 'n', '</s>']
Filtered   (025): ['vs', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'Ġserial', 'ize', 'Term', 'Ġ(', 'Ġv', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ\\', 'n']
Detokenized (021): ['vs', 'Ġ=', 'Ġ[', 'Ġself', 'Ġ.', 'ĠserializeTerm', 'Ġ(', 'Ġv', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġvars', 'Ġ]', 'Ġ\\n']
Counter: 25
===================================================================
Hidden states:  (13, 21, 768)
# Extracted words:  21
Sentence         : "for row in self . result . bindings : \n"
Original    (010): ['for', 'row', 'in', 'self', '.', 'result', '.', 'bindings', ':', '\\n']
Tokenized   (013): ['<s>', 'for', 'Ġrow', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġbindings', 'Ġ:', 'Ġ\\', 'n', '</s>']
Filtered   (011): ['for', 'Ġrow', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġbindings', 'Ġ:', 'Ġ\\', 'n']
Detokenized (010): ['for', 'Ġrow', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġbindings', 'Ġ:', 'Ġ\\n']
Counter: 11
===================================================================
Hidden states:  (13, 10, 768)
# Extracted words:  10
Sentence         : "row . get ( v ) , encoding ) for v in self . result . vars ] ) \n"
Original    (020): ['row', '.', 'get', '(', 'v', ')', ',', 'encoding', ')', 'for', 'v', 'in', 'self', '.', 'result', '.', 'vars', ']', ')', '\\n']
Tokenized   (024): ['<s>', 'row', 'Ġ.', 'Ġget', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (022): ['row', 'Ġ.', 'Ġget', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġv', 'ars', 'Ġ]', 'Ġ)', 'Ġ\\', 'n']
Detokenized (020): ['row', 'Ġ.', 'Ġget', 'Ġ(', 'Ġv', 'Ġ)', 'Ġ,', 'Ġencoding', 'Ġ)', 'Ġfor', 'Ġv', 'Ġin', 'Ġself', 'Ġ.', 'Ġresult', 'Ġ.', 'Ġvars', 'Ġ]', 'Ġ)', 'Ġ\\n']
Counter: 22
===================================================================
Hidden states:  (13, 20, 768)
# Extracted words:  20
Sentence         : "try : import nose \n"
Original    (005): ['try', ':', 'import', 'nose', '\\n']
Tokenized   (008): ['<s>', 'try', 'Ġ:', 'Ġimport', 'Ġnose', 'Ġ\\', 'n', '</s>']
Filtered   (006): ['try', 'Ġ:', 'Ġimport', 'Ġnose', 'Ġ\\', 'n']
Detokenized (005): ['try', 'Ġ:', 'Ġimport', 'Ġnose', 'Ġ\\n']
Counter: 6
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "~~~ argv += DEFAULT_DIRS \n"
Original    (005): ['~~~', 'argv', '+=', 'DEFAULT_DIRS', '\\n']
Tokenized   (014): ['<s>', '~~', '~', 'Ġarg', 'v', 'Ġ+=', 'ĠDE', 'FAULT', '_', 'DIR', 'S', 'Ġ\\', 'n', '</s>']
Filtered   (012): ['~~', '~', 'Ġarg', 'v', 'Ġ+=', 'ĠDE', 'FAULT', '_', 'DIR', 'S', 'Ġ\\', 'n']
Detokenized (005): ['~~~', 'Ġargv', 'Ġ+=', 'ĠDEFAULT_DIRS', 'Ġ\\n']
Counter: 12
===================================================================
Hidden states:  (13, 5, 768)
# Extracted words:  5
Sentence         : "nose . run_exit ( argv = finalArgs ) \n"
Original    (009): ['nose', '.', 'run_exit', '(', 'argv', '=', 'finalArgs', ')', '\\n']
Tokenized   (017): ['<s>', 'n', 'ose', 'Ġ.', 'Ġrun', '_', 'exit', 'Ġ(', 'Ġarg', 'v', 'Ġ=', 'Ġfinal', 'Args', 'Ġ)', 'Ġ\\', 'n', '</s>']
Filtered   (015): ['n', 'ose', 'Ġ.', 'Ġrun', '_', 'exit', 'Ġ(', 'Ġarg', 'v', 'Ġ=', 'Ġfinal', 'Args', 'Ġ)', 'Ġ\\', 'n']
Detokenized (009): ['nose', 'Ġ.', 'Ġrun_exit', 'Ġ(', 'Ġargv', 'Ġ=', 'ĠfinalArgs', 'Ġ)', 'Ġ\\n']
Counter: 15
===================================================================
Hidden states:  (13, 9, 768)
# Extracted words:  9
Loading json activations from bert_temp_activations.json...
1547 13.0
Loading json activations from codebert_temp_activations.json...
1547 13.0
Loading json activations from graphcodebert_temp_activations.json...
1547 13.0
Loading json activations from bert_temp_activations.json...
1547 13.0
Loading json activations from codebert_temp_activations.json...
1547 13.0
Loading json activations from graphcodebert_temp_activations.json...
1547 13.0
Number of tokens:  20509
length of source dictionary:  3730
length of target dictionary:  41
20509
Total instances: 20509
['matcher', 'u_', '"core_tasks"', 'line_len', 'Point2PointService', 'yield', 'fields_by_name', '"{0}|{1}|{2}"', 'v', 'richtext', 'meq', '"c"', '"raw"', '"can"', 'IDroneDService', '"grid.png"', 'replaceUndefined', 'Quantity', 'nout', 'entry_pts']
Number of samples:  20509
Stats: Labels with their frequencies in the final set
NAME 6901
DOT 1726
COMMA 1673
LPAR 1645
EQUAL 1600
RPAR 1593
NEWLINE 1195
NUMBER 715
LSQB 659
RSQB 623
KEYWORD 551
NL 352
STRING 349
COLON 270
PLUS 150
STAR 101
MINUS 94
LBRACE 65
RBRACE 61
SLASH 39
EQEQUAL 34
PERCENT 26
DOUBLESTAR 21
PLUSEQUAL 16
GREATER 9
COMMENT 7
SEMI 6
GREATEREQUAL 4
DEDENT 4
VBAR 3
NOTEQUAL 2
MINEQUAL 2
AMPER 2
TILDE 2
ERRORTOKEN 2
INDENT 2
LESS 1
SLASHEQUAL 1
LEFTSHIFT 1
DOUBLESLASH 1
AT 1
Number of tokens:  20509
length of source dictionary:  3730
length of target dictionary:  41
20509
Total instances: 20509
['matcher', 'u_', '"core_tasks"', 'line_len', 'Point2PointService', 'yield', 'fields_by_name', '"{0}|{1}|{2}"', 'v', 'richtext', 'meq', '"c"', '"raw"', '"can"', 'IDroneDService', '"grid.png"', 'replaceUndefined', 'Quantity', 'nout', 'entry_pts']
Number of samples:  20509
Stats: Labels with their frequencies in the final set
NAME 6901
DOT 1726
COMMA 1673
LPAR 1645
EQUAL 1600
RPAR 1593
NEWLINE 1195
NUMBER 715
LSQB 659
RSQB 623
KEYWORD 551
NL 352
STRING 349
COLON 270
PLUS 150
STAR 101
MINUS 94
LBRACE 65
RBRACE 61
SLASH 39
EQEQUAL 34
PERCENT 26
DOUBLESTAR 21
PLUSEQUAL 16
GREATER 9
COMMENT 7
SEMI 6
GREATEREQUAL 4
DEDENT 4
VBAR 3
NOTEQUAL 2
MINEQUAL 2
AMPER 2
TILDE 2
ERRORTOKEN 2
INDENT 2
LESS 1
SLASHEQUAL 1
LEFTSHIFT 1
DOUBLESLASH 1
AT 1
Number of tokens:  20509
length of source dictionary:  3730
length of target dictionary:  41
20509
Total instances: 20509
['matcher', 'u_', '"core_tasks"', 'line_len', 'Point2PointService', 'yield', 'fields_by_name', '"{0}|{1}|{2}"', 'v', 'richtext', 'meq', '"c"', '"raw"', '"can"', 'IDroneDService', '"grid.png"', 'replaceUndefined', 'Quantity', 'nout', 'entry_pts']
Number of samples:  20509
Stats: Labels with their frequencies in the final set
NAME 6901
DOT 1726
COMMA 1673
LPAR 1645
EQUAL 1600
RPAR 1593
NEWLINE 1195
NUMBER 715
LSQB 659
RSQB 623
KEYWORD 551
NL 352
STRING 349
COLON 270
PLUS 150
STAR 101
MINUS 94
LBRACE 65
RBRACE 61
SLASH 39
EQEQUAL 34
PERCENT 26
DOUBLESTAR 21
PLUSEQUAL 16
GREATER 9
COMMENT 7
SEMI 6
GREATEREQUAL 4
DEDENT 4
VBAR 3
NOTEQUAL 2
MINEQUAL 2
AMPER 2
TILDE 2
ERRORTOKEN 2
INDENT 2
LESS 1
SLASHEQUAL 1
LEFTSHIFT 1
DOUBLESLASH 1
AT 1
distribution:
{0: 6901, 1: 1726, 2: 1673, 3: 1645, 4: 1600, 5: 1593, 6: 1195, 7: 715, 8: 659, 9: 623, 10: 551, 11: 352, 12: 349, 13: 270, 14: 150, 15: 101, 16: 94, 17: 65, 18: 61, 19: 39, 20: 34, 21: 26, 22: 21, 23: 16, 24: 9, 25: 7, 26: 6, 27: 4, 28: 4, 29: 3, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1}
Training classification probe
Creating model...
Number of training instances: 16082
Number of classes: 16
Epoch: [1/10], Loss: 0.0148
Epoch: [2/10], Loss: 0.0146
Epoch: [3/10], Loss: 0.0133
Epoch: [4/10], Loss: 0.0146
Epoch: [5/10], Loss: 0.0137
Epoch: [6/10], Loss: 0.0157
Epoch: [7/10], Loss: 0.0138
Epoch: [8/10], Loss: 0.0117
Epoch: [9/10], Loss: 0.0164
Epoch: [10/10], Loss: 0.0144
Score (accuracy) of the probe: 0.98
Score (accuracy) of the probe: 0.98
Score on the test set: {'__OVERALL__': 0.9781148967918428, 'NAME': 0.9985601151907847, 'DOT': 1.0, 'COMMA': 1.0, 'LPAR': 1.0, 'EQUAL': 1.0, 'RPAR': 0.9941176470588236, 'NEWLINE': 1.0, 'NUMBER': 0.9847328244274809, 'LSQB': 1.0, 'RSQB': 0.9634146341463414, 'KEYWORD': 0.95, 'NL': 0.0, 'STRING': 0.7346938775510204, 'COLON': 1.0, 'PLUS': 1.0, 'STAR': 0.875, 'MINUS': nan, 'LBRACE': nan, 'RBRACE': nan, 'SLASH': nan, 'EQEQUAL': nan, 'PERCENT': nan, 'DOUBLESTAR': nan, 'PLUSEQUAL': nan, 'GREATER': nan, 'COMMENT': nan, 'SEMI': nan, 'GREATEREQUAL': nan, 'DEDENT': nan, 'VBAR': nan, 'NOTEQUAL': nan, 'MINEQUAL': nan, 'AMPER': nan, 'TILDE': nan, 'ERRORTOKEN': nan, 'INDENT': nan, 'LESS': nan, 'SLASHEQUAL': nan, 'LEFTSHIFT': nan, 'DOUBLESLASH': nan, 'AT': nan}
Score (accuracy) of the probe: 0.98
Score on the training set: {'__OVERALL__': 0.9750031090660366, 'NAME': 0.9996371552975326, 'DOT': 0.9992647058823529, 'COMMA': 1.0, 'LPAR': 1.0, 'EQUAL': 1.0, 'RPAR': 0.9976057462090981, 'NEWLINE': 1.0, 'NUMBER': 1.0, 'LSQB': 1.0, 'RSQB': 0.988909426987061, 'KEYWORD': 0.9919137466307277, 'NL': 0.006756756756756757, 'STRING': 0.71, 'COLON': 1.0, 'PLUS': 1.0, 'STAR': 0.9354838709677419, 'MINUS': nan, 'LBRACE': nan, 'RBRACE': nan, 'SLASH': nan, 'EQEQUAL': nan, 'PERCENT': nan, 'DOUBLESTAR': nan, 'PLUSEQUAL': nan, 'GREATER': nan, 'COMMENT': nan, 'SEMI': nan, 'GREATEREQUAL': nan, 'DEDENT': nan, 'VBAR': nan, 'NOTEQUAL': nan, 'MINEQUAL': nan, 'AMPER': nan, 'TILDE': nan, 'ERRORTOKEN': nan, 'INDENT': nan, 'LESS': nan, 'SLASHEQUAL': nan, 'LEFTSHIFT': nan, 'DOUBLESLASH': nan, 'AT': nan}
