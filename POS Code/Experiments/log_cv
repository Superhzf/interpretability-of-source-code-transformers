Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations.json...
32002 13.0
Number of tokens:  325100
length of source dictionary:  17255
length of target dictionary:  47
325100
Total instances: 325100
['nextitem', 'None', 'root_pathname', 'isAncestorOf', '"jsonschema.validators.validates"', 'pod', 'appmod', '"source"', 'p_dropout', 'get_eq_constraints', 'config_dict', '200.0', 'conversation', '__gadgetMenuDefinition', 'new', 'sort_keys', 'obj_info', '"min_event_date"', 'default_metavar', 'final_features']
Number of samples:  325100
Stats: Labels with their frequencies in the final set
NAME 104243
NEWLINE 28415
DOT 27737
LPAR 24899
RPAR 23914
KEYWORD 21043
COMMA 18332
EQUAL 15063
COLON 10649
DEDENT 8365
INDENT 7255
LSQB 7221
RSQB 7056
NUMBER 6667
STRING 3985
NL 3586
PLUS 928
LBRACE 870
EQEQUAL 827
MINUS 701
RBRACE 673
STAR 606
PERCENT 459
DOUBLESTAR 242
PLUSEQUAL 204
GREATER 187
SLASH 177
NOTEQUAL 176
AT 165
LESS 90
COMMENT 72
GREATEREQUAL 55
LESSEQUAL 40
VBAR 39
LEFTSHIFT 32
SEMI 22
MINEQUAL 21
AMPER 20
DOUBLESLASH 19
STAREQUAL 16
TILDE 10
ELLIPSIS 6
VBAREQUAL 5
RIGHTSHIFT 3
SLASHEQUAL 2
ERRORTOKEN 2
AMPEREQUAL 1
pretrained_BERT distribution:
{0: 104243, 1: 28415, 2: 27737, 3: 24899, 4: 23914, 5: 21043, 6: 18332, 7: 15063, 8: 10649, 9: 8365, 10: 7255, 11: 7221, 12: 7056, 13: 6667, 14: 3985, 15: 3586, 16: 928, 17: 870, 18: 827, 19: 701, 20: 673, 21: 606, 22: 459, 23: 242, 24: 204, 25: 187, 26: 177, 27: 176, 28: 165, 29: 90, 30: 72, 31: 55, 32: 40, 33: 39, 34: 32, 35: 22, 36: 21, 37: 20, 38: 19, 39: 16, 40: 10, 41: 6, 42: 5, 43: 3, 44: 2, 45: 2, 46: 1}
pretrained_BERT distribution after trauncating:
{0: 0.3206677720322012, 1: 0.0874089842223938, 2: 0.08532335018041658, 3: 0.07659321830559153, 4: 0.07356320424755676, 5: 0.06473155921139655, 6: 0.05639209919989172, 7: 0.04633614391490121, 8: 0.03275798954722054, 9: 0.025732048320264794, 10: 0.022317514711718004, 11: 0.022212925393978733, 12: 0.021705359587302856, 13: 0.020508734746109432, 14: 0.012258483270323396, 15: 0.011031096865089008, 16: 0.002854673143001283, 17: 0.0026762560715637026, 18: 0.0025439813461875654, 19: 0.0021563856392714433, 20: 0.002070253259956749, 21: 0.0018641507808823032, 22: 0.0014119557894801604, 23: 0.0007444298497912828, 24: 0.0006275359064356268, 25: 0.0005752412475659912, 26: 0.0005444796835250292, 27: 0.0005414035271209329, 28: 0.0005075658066758746, 29: 0.0002768540763686589, 30: 0.0002214832610949271, 31: 0.00016918860222529155, 32: 0.0001230462561638484, 33: 0.00011997009975975218, 34: 9.843700493107872e-05, 35: 6.767544089011662e-05, 36: 6.45992844860204e-05, 37: 6.15231280819242e-05, 38: 5.8446971677827984e-05, 39: 4.921850246553936e-05, 40: 3.07615640409621e-05}
Training classification probe
Creating model...
Number of training instances: 263314
Number of classes: 41
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0093
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0090
Epoch: [5/10], Loss: 0.0092
Epoch: [6/10], Loss: 0.0090
Epoch: [7/10], Loss: 0.0091
Epoch: [8/10], Loss: 0.0093
Epoch: [9/10], Loss: 0.0091
Epoch: [10/10], Loss: 0.0092
Score (accuracy) of the probe: 0.98
l1=0.001,l2=0.001
Absolute average value of parameters: 0.00075168465
Number of parameters that are not zero: [9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984]
Accuracy on the validation set: {'__OVERALL__': 0.9804839701961856, 'NAME': 0.9991438356164384, 'NEWLINE': 1.0, 'DOT': 1.0, 'LPAR': 1.0, 'RPAR': 1.0, 'KEYWORD': 0.9926276987888363, 'COMMA': 1.0, 'EQUAL': 0.9978586723768736, 'COLON': 1.0, 'DEDENT': 0.9421052631578948, 'INDENT': 0.9430656934306569, 'LSQB': 1.0, 'RSQB': 1.0, 'NUMBER': 0.975328947368421, 'STRING': 0.9460227272727273, 'NL': 0.056074766355140186, 'PLUS': 1.0, 'LBRACE': 1.0, 'EQEQUAL': 1.0, 'MINUS': 0.9875, 'RBRACE': 1.0, 'STAR': 1.0, 'PERCENT': 0.9090909090909091, 'DOUBLESTAR': 0.0, 'PLUSEQUAL': 0.0, 'GREATER': 0.0, 'SLASH': 0.9285714285714286, 'NOTEQUAL': 0.0, 'AT': 0.0, 'LESS': 0.0, 'COMMENT': 0.0, 'GREATEREQUAL': 0.0, 'LESSEQUAL': 0.0, 'VBAR': 0.0, 'LEFTSHIFT': 0.0, 'SEMI': 0.0, 'MINEQUAL': 0.0, 'AMPER': 0.0, 'DOUBLESLASH': 0.0, 'STAREQUAL': nan, 'TILDE': nan}
Training classification probe
Creating model...
Number of training instances: 263314
Number of classes: 41
Epoch: [1/10], Loss: 0.0237
Epoch: [2/10], Loss: 0.0223
Epoch: [3/10], Loss: 0.0222
Epoch: [4/10], Loss: 0.0222
Epoch: [5/10], Loss: 0.0222
Epoch: [6/10], Loss: 0.0222
Epoch: [7/10], Loss: 0.0221
Epoch: [8/10], Loss: 0.0222
Epoch: [9/10], Loss: 0.0222
Epoch: [10/10], Loss: 0.0222
Score (accuracy) of the probe: 0.95
l1=0.01,l2=0.001
Absolute average value of parameters: 0.000252058
Number of parameters that are not zero: [9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984]
Accuracy on the validation set: {'__OVERALL__': 0.9488345068015586, 'NAME': 0.9991438356164384, 'NEWLINE': 1.0, 'DOT': 1.0, 'LPAR': 1.0, 'RPAR': 1.0, 'KEYWORD': 0.9373354397051079, 'COMMA': 1.0, 'EQUAL': 1.0, 'COLON': 0.9989550679205852, 'DEDENT': 0.8263157894736842, 'INDENT': 0.6875912408759124, 'LSQB': 1.0, 'RSQB': 1.0, 'NUMBER': 0.8865131578947368, 'STRING': 0.5909090909090909, 'NL': 0.0, 'PLUS': 1.0, 'LBRACE': 0.0, 'EQEQUAL': 0.0, 'MINUS': 0.0, 'RBRACE': 0.7068965517241379, 'STAR': 0.0, 'PERCENT': 0.0, 'DOUBLESTAR': 0.0, 'PLUSEQUAL': 0.0, 'GREATER': 0.0, 'SLASH': 0.0, 'NOTEQUAL': 0.0, 'AT': 0.0, 'LESS': 0.0, 'COMMENT': 0.0, 'GREATEREQUAL': 0.0, 'LESSEQUAL': 0.0, 'VBAR': 0.0, 'LEFTSHIFT': 0.0, 'SEMI': 0.0, 'MINEQUAL': 0.0, 'AMPER': 0.0, 'DOUBLESLASH': 0.0, 'STAREQUAL': nan, 'TILDE': nan}
Training classification probe
Creating model...
Number of training instances: 263314
Number of classes: 41
Epoch: [1/10], Loss: 0.1207
Epoch: [2/10], Loss: 0.1111
Epoch: [3/10], Loss: 0.1109
Epoch: [4/10], Loss: 0.1109
Epoch: [5/10], Loss: 0.1109
Epoch: [6/10], Loss: 0.1109
Epoch: [7/10], Loss: 0.1109
Epoch: [8/10], Loss: 0.1109
Epoch: [9/10], Loss: 0.1109
Epoch: [10/10], Loss: 0.1109
Score (accuracy) of the probe: 0.76
l1=0.1,l2=0.001
Absolute average value of parameters: 0.00014360237
Number of parameters that are not zero: [9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984]
Accuracy on the validation set: {'__OVERALL__': 0.7648506391414314, 'NAME': 0.9998929794520548, 'NEWLINE': 1.0, 'DOT': 1.0, 'LPAR': 1.0, 'RPAR': 0.994838104176443, 'KEYWORD': 0.0, 'COMMA': 0.9894212818917237, 'EQUAL': 0.9992862241256245, 'COLON': 0.0, 'DEDENT': 0.0, 'INDENT': 0.0, 'LSQB': 0.0, 'RSQB': 0.9540889526542324, 'NUMBER': 0.0, 'STRING': 0.0, 'NL': 0.0, 'PLUS': 0.0, 'LBRACE': 0.0, 'EQEQUAL': 0.0, 'MINUS': 0.0, 'RBRACE': 0.0, 'STAR': 0.0, 'PERCENT': 0.0, 'DOUBLESTAR': 0.0, 'PLUSEQUAL': 0.0, 'GREATER': 0.0, 'SLASH': 0.0, 'NOTEQUAL': 0.0, 'AT': 0.0, 'LESS': 0.0, 'COMMENT': 0.0, 'GREATEREQUAL': 0.0, 'LESSEQUAL': 0.0, 'VBAR': 0.0, 'LEFTSHIFT': 0.0, 'SEMI': 0.0, 'MINEQUAL': 0.0, 'AMPER': 0.0, 'DOUBLESLASH': 0.0, 'STAREQUAL': nan, 'TILDE': nan}
Training classification probe
Creating model...
Number of training instances: 263314
Number of classes: 41
Epoch: [1/10], Loss: 0.8193
Epoch: [2/10], Loss: 0.7541
Epoch: [3/10], Loss: 0.7523
Epoch: [4/10], Loss: 0.7515
Epoch: [5/10], Loss: 0.7515
Epoch: [6/10], Loss: 0.7513
Epoch: [7/10], Loss: 0.7510
Epoch: [8/10], Loss: 0.7514
Epoch: [9/10], Loss: 0.7511
Epoch: [10/10], Loss: 0.7512
Score (accuracy) of the probe: 0.32
l1=1,l2=0.001
Absolute average value of parameters: 0.0001119433
Number of parameters that are not zero: [9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984]
Accuracy on the validation set: {'__OVERALL__': 0.31936564358466063, 'NAME': 1.0, 'NEWLINE': 0.0, 'DOT': 0.0, 'LPAR': 0.0, 'RPAR': 0.0, 'KEYWORD': 0.0, 'COMMA': 0.0, 'EQUAL': 0.0, 'COLON': 0.0, 'DEDENT': 0.0, 'INDENT': 0.0, 'LSQB': 0.0, 'RSQB': 0.0, 'NUMBER': 0.0, 'STRING': 0.0, 'NL': 0.0, 'PLUS': 0.0, 'LBRACE': 0.0, 'EQEQUAL': 0.0, 'MINUS': 0.0, 'RBRACE': 0.0, 'STAR': 0.0, 'PERCENT': 0.0, 'DOUBLESTAR': 0.0, 'PLUSEQUAL': 0.0, 'GREATER': 0.0, 'SLASH': 0.0, 'NOTEQUAL': 0.0, 'AT': 0.0, 'LESS': 0.0, 'COMMENT': 0.0, 'GREATEREQUAL': 0.0, 'LESSEQUAL': 0.0, 'VBAR': 0.0, 'LEFTSHIFT': 0.0, 'SEMI': 0.0, 'MINEQUAL': 0.0, 'AMPER': 0.0, 'DOUBLESLASH': 0.0, 'STAREQUAL': nan, 'TILDE': nan}
Training classification probe
Creating model...
Number of training instances: 263314
Number of classes: 41
Epoch: [1/10], Loss: 7.9070
Epoch: [2/10], Loss: 7.1891
Epoch: [3/10], Loss: 7.1222
Epoch: [4/10], Loss: 7.0870
Epoch: [5/10], Loss: 7.0636
Epoch: [6/10], Loss: 7.0484
Epoch: [7/10], Loss: 7.0358
Epoch: [8/10], Loss: 7.0233
Epoch: [9/10], Loss: 7.0134
Epoch: [10/10], Loss: 7.0088
Score (accuracy) of the probe: 0.32
l1=10,l2=0.001
Absolute average value of parameters: 0.00010904289
Number of parameters that are not zero: [9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984
 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984 9984]
Accuracy on the validation set: {'__OVERALL__': 0.31936564358466063, 'NAME': 1.0, 'NEWLINE': 0.0, 'DOT': 0.0, 'LPAR': 0.0, 'RPAR': 0.0, 'KEYWORD': 0.0, 'COMMA': 0.0, 'EQUAL': 0.0, 'COLON': 0.0, 'DEDENT': 0.0, 'INDENT': 0.0, 'LSQB': 0.0, 'RSQB': 0.0, 'NUMBER': 0.0, 'STRING': 0.0, 'NL': 0.0, 'PLUS': 0.0, 'LBRACE': 0.0, 'EQEQUAL': 0.0, 'MINUS': 0.0, 'RBRACE': 0.0, 'STAR': 0.0, 'PERCENT': 0.0, 'DOUBLESTAR': 0.0, 'PLUSEQUAL': 0.0, 'GREATER': 0.0, 'SLASH': 0.0, 'NOTEQUAL': 0.0, 'AT': 0.0, 'LESS': 0.0, 'COMMENT': 0.0, 'GREATEREQUAL': 0.0, 'LESSEQUAL': 0.0, 'VBAR': 0.0, 'LEFTSHIFT': 0.0, 'SEMI': 0.0, 'MINEQUAL': 0.0, 'AMPER': 0.0, 'DOUBLESLASH': 0.0, 'STAREQUAL': nan, 'TILDE': nan}
----------------------------------------------------------------
