Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
1289 13.0
Number of tokens:  1042
length of source dictionary:  1042
length of target dictionary:  34
1042
Total instances: 1042
['types', 'GetUID', 'to_timezoned_naive_datetime', 'pooltype', 'idList', 'MINUTE_MICROS', '20000', 'login', 'rval', '"m_LengthScale"', 'PUBLIC_SHMKEY', '"sysmail"', 'link', 'endswith', 'get_context_data', 'st', 'readline', '40', 'hpOneView', 'context']
Number of samples:  1042
Stats: Labels with their frequencies in the final set
NAME 876
STRING 72
NUMBER 36
KEYWORD 25
COMMENT 4
NL 1
LPAR 1
DOT 1
RPAR 1
COLON 1
EQUAL 1
COMMA 1
INDENT 1
DEDENT 1
LSQB 1
RSQB 1
AT 1
STAR 1
EQEQUAL 1
MINUS 1
PLUS 1
PERCENT 1
GREATER 1
NOTEQUAL 1
PLUSEQUAL 1
GREATEREQUAL 1
LESS 1
MINEQUAL 1
LBRACE 1
RBRACE 1
LESSEQUAL 1
DOUBLESTAR 1
SLASH 1
SEMI 1
pretrained_BERT distribution:
{0: 876, 1: 72, 2: 36, 3: 25, 4: 4, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1}
pretrained_BERT distribution after trauncating:
{0: 0.8681863230921705, 1: 0.07135777998017839, 2: 0.035678889990089196, 3: 0.024777006937561942}
{0: 876, 1: 72, 2: 36, 3: 25}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
494 13.0
Number of tokens:  482
length of source dictionary:  482
length of target dictionary:  33
482
Total instances: 482
['0.9801', 'n_tokens', 't', '0.', 'mask_name', 'ElemwiseSumLayer', 'BufferStructure', 'init_scale', 'pytest', 'targets_name', 'get', 'te_cost', '0.6', 'dbeta_tmp', 'True', 'epsilon', 'np', 'cropping', 'modelbase', '_']
Number of samples:  482
Stats: Labels with their frequencies in the final set
NAME 400
NUMBER 27
KEYWORD 22
STRING 4
COMMA 1
NEWLINE 1
DOT 1
LPAR 1
RPAR 1
EQUAL 1
COLON 1
DEDENT 1
INDENT 1
LBRACE 1
RBRACE 1
LSQB 1
RSQB 1
MINUS 1
SLASH 1
AT 1
EQEQUAL 1
GREATER 1
STAREQUAL 1
LESS 1
DOUBLESTAR 1
STAR 1
PLUS 1
COMMENT 1
GREATEREQUAL 1
PLUSEQUAL 1
LESSEQUAL 1
PERCENT 1
AMPER 1
pretrained_BERT distribution:
{0: 400, 1: 27, 2: 22, 3: 4, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1}
pretrained_BERT distribution after trauncating:
{0: 0.8830022075055187, 1: 0.059602649006622516, 2: 0.04856512141280353, 3: 0.008830022075055188}
{0: 400, 1: 27, 2: 22, 3: 4}
{'NAME': 0, 'NUMBER': 1, 'KEYWORD': 2, 'STRING': 3}
The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 835, 1: 72, 2: 25, 3: 14})
The distribution of classes in testing:
Counter({0: 400, 2: 27, 3: 12, 1: 4})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The shape of the training set: (851, 9984)
The shape of the validation set: (95, 9984)
The shape of the testing set: (443, 9984)
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0182
Epoch: [2/10], Loss: 0.0075
Epoch: [3/10], Loss: 0.0053
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0183
Epoch: [2/10], Loss: 0.0077
Epoch: [3/10], Loss: 0.0052
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0017
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0179
Epoch: [2/10], Loss: 0.0076
Epoch: [3/10], Loss: 0.0054
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0018
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0189
Epoch: [2/10], Loss: 0.0085
Epoch: [3/10], Loss: 0.0062
Epoch: [4/10], Loss: 0.0043
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.97
The best l1=0, the best l2=0 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8442437923250564, 'NAME': 0.835, 'STRING': 1.0, 'NUMBER': 0.9629629629629629, 'KEYWORD': 0.8333333333333334}
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0076
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0063
Epoch: [10/10], Loss: 0.0060
Score (accuracy) of the probe: 0.81
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0076
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0063
Epoch: [10/10], Loss: 0.0060
Score (accuracy) of the probe: 0.76
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0063
Epoch: [10/10], Loss: 0.0060
Score (accuracy) of the probe: 0.82
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0083
Epoch: [7/10], Loss: 0.0079
Epoch: [8/10], Loss: 0.0075
Epoch: [9/10], Loss: 0.0072
Epoch: [10/10], Loss: 0.0069
Score (accuracy) of the probe: 0.83
The best l1=0, the best l2=0.1 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.67
{'__OVERALL__': 0.6704288939051919, 'NAME': 0.6525, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.4166666666666667}
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0107
Epoch: [3/10], Loss: 0.0097
Epoch: [4/10], Loss: 0.0090
Epoch: [5/10], Loss: 0.0084
Epoch: [6/10], Loss: 0.0078
Epoch: [7/10], Loss: 0.0074
Epoch: [8/10], Loss: 0.0069
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0062
Score (accuracy) of the probe: 0.69
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.66
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0069
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.79
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0134
Epoch: [2/10], Loss: 0.0114
Epoch: [3/10], Loss: 0.0104
Epoch: [4/10], Loss: 0.0097
Epoch: [5/10], Loss: 0.0091
Epoch: [6/10], Loss: 0.0086
Epoch: [7/10], Loss: 0.0082
Epoch: [8/10], Loss: 0.0078
Epoch: [9/10], Loss: 0.0074
Epoch: [10/10], Loss: 0.0071
Score (accuracy) of the probe: 0.82
The best l1=0, the best l2=0.1 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.65
{'__OVERALL__': 0.6478555304740407, 'NAME': 0.63, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.3333333333333333}
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0065
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0058
Score (accuracy) of the probe: 0.67
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.80
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0078
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0069
Epoch: [9/10], Loss: 0.0066
Epoch: [10/10], Loss: 0.0062
Score (accuracy) of the probe: 0.76
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0135
Epoch: [2/10], Loss: 0.0114
Epoch: [3/10], Loss: 0.0105
Epoch: [4/10], Loss: 0.0098
Epoch: [5/10], Loss: 0.0092
Epoch: [6/10], Loss: 0.0087
Epoch: [7/10], Loss: 0.0083
Epoch: [8/10], Loss: 0.0079
Epoch: [9/10], Loss: 0.0076
Epoch: [10/10], Loss: 0.0073
Score (accuracy) of the probe: 0.78
The best l1=0, the best l2=0.001 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.65
{'__OVERALL__': 0.6501128668171557, 'NAME': 0.64, 'STRING': 1.0, 'NUMBER': 0.9259259259259259, 'KEYWORD': 0.25}
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.74
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0065
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0058
Score (accuracy) of the probe: 0.78
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.77
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0110
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0083
Epoch: [7/10], Loss: 0.0078
Epoch: [8/10], Loss: 0.0075
Epoch: [9/10], Loss: 0.0071
Epoch: [10/10], Loss: 0.0068
Score (accuracy) of the probe: 0.81
The best l1=0, the best l2=0.1 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.69
{'__OVERALL__': 0.6884875846501128, 'NAME': 0.675, 'STRING': 1.0, 'NUMBER': 0.8148148148148148, 'KEYWORD': 0.75}
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.84
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0126
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0086
Epoch: [5/10], Loss: 0.0080
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0065
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0058
Score (accuracy) of the probe: 0.85
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0128
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0063
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.82
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0134
Epoch: [2/10], Loss: 0.0113
Epoch: [3/10], Loss: 0.0103
Epoch: [4/10], Loss: 0.0095
Epoch: [5/10], Loss: 0.0089
Epoch: [6/10], Loss: 0.0084
Epoch: [7/10], Loss: 0.0080
Epoch: [8/10], Loss: 0.0076
Epoch: [9/10], Loss: 0.0072
Epoch: [10/10], Loss: 0.0069
Score (accuracy) of the probe: 0.77
The best l1=0, the best l2=0.001 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.67
{'__OVERALL__': 0.6704288939051919, 'NAME': 0.6475, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.5833333333333334}
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 0.79
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0073
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0064
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0057
Score (accuracy) of the probe: 0.80
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0086
Epoch: [5/10], Loss: 0.0080
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0065
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0058
Score (accuracy) of the probe: 0.78
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0133
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0093
Epoch: [5/10], Loss: 0.0087
Epoch: [6/10], Loss: 0.0082
Epoch: [7/10], Loss: 0.0077
Epoch: [8/10], Loss: 0.0074
Epoch: [9/10], Loss: 0.0070
Epoch: [10/10], Loss: 0.0067
Score (accuracy) of the probe: 0.81
The best l1=0, the best l2=0.1 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.66
{'__OVERALL__': 0.6636568848758465, 'NAME': 0.6525, 'STRING': 1.0, 'NUMBER': 0.7777777777777778, 'KEYWORD': 0.6666666666666666}
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 0.87
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0098
Epoch: [3/10], Loss: 0.0088
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0068
Epoch: [8/10], Loss: 0.0064
Epoch: [9/10], Loss: 0.0060
Epoch: [10/10], Loss: 0.0057
Score (accuracy) of the probe: 0.83
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0109
Epoch: [3/10], Loss: 0.0099
Epoch: [4/10], Loss: 0.0092
Epoch: [5/10], Loss: 0.0086
Epoch: [6/10], Loss: 0.0081
Epoch: [7/10], Loss: 0.0076
Epoch: [8/10], Loss: 0.0073
Epoch: [9/10], Loss: 0.0069
Epoch: [10/10], Loss: 0.0067
Score (accuracy) of the probe: 0.85
The best l1=0, the best l2=0.001 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.70
{'__OVERALL__': 0.6975169300225733, 'NAME': 0.695, 'STRING': 1.0, 'NUMBER': 0.7407407407407407, 'KEYWORD': 0.5833333333333334}
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0060
Epoch: [10/10], Loss: 0.0057
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0126
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0073
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0065
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0058
Score (accuracy) of the probe: 0.84
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0073
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0065
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0058
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0131
Epoch: [2/10], Loss: 0.0109
Epoch: [3/10], Loss: 0.0098
Epoch: [4/10], Loss: 0.0091
Epoch: [5/10], Loss: 0.0085
Epoch: [6/10], Loss: 0.0080
Epoch: [7/10], Loss: 0.0076
Epoch: [8/10], Loss: 0.0072
Epoch: [9/10], Loss: 0.0069
Epoch: [10/10], Loss: 0.0066
Score (accuracy) of the probe: 0.87
The best l1=0, the best l2=0 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.67
{'__OVERALL__': 0.6749435665914221, 'NAME': 0.675, 'STRING': 1.0, 'NUMBER': 0.6666666666666666, 'KEYWORD': 0.5833333333333334}
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0119
Epoch: [2/10], Loss: 0.0098
Epoch: [3/10], Loss: 0.0088
Epoch: [4/10], Loss: 0.0080
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0119
Epoch: [2/10], Loss: 0.0097
Epoch: [3/10], Loss: 0.0086
Epoch: [4/10], Loss: 0.0079
Epoch: [5/10], Loss: 0.0073
Epoch: [6/10], Loss: 0.0068
Epoch: [7/10], Loss: 0.0063
Epoch: [8/10], Loss: 0.0059
Epoch: [9/10], Loss: 0.0056
Epoch: [10/10], Loss: 0.0052
Score (accuracy) of the probe: 0.91
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0098
Epoch: [3/10], Loss: 0.0088
Epoch: [4/10], Loss: 0.0080
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0068
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0056
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 0.92
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0107
Epoch: [3/10], Loss: 0.0097
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0078
Epoch: [7/10], Loss: 0.0074
Epoch: [8/10], Loss: 0.0070
Epoch: [9/10], Loss: 0.0067
Epoch: [10/10], Loss: 0.0064
Score (accuracy) of the probe: 0.91
The best l1=0, the best l2=0.01 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.71
{'__OVERALL__': 0.7133182844243793, 'NAME': 0.72, 'STRING': 1.0, 'NUMBER': 0.6296296296296297, 'KEYWORD': 0.5833333333333334}
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0073
Epoch: [6/10], Loss: 0.0068
Epoch: [7/10], Loss: 0.0062
Epoch: [8/10], Loss: 0.0058
Epoch: [9/10], Loss: 0.0054
Epoch: [10/10], Loss: 0.0051
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0097
Epoch: [3/10], Loss: 0.0087
Epoch: [4/10], Loss: 0.0079
Epoch: [5/10], Loss: 0.0072
Epoch: [6/10], Loss: 0.0066
Epoch: [7/10], Loss: 0.0061
Epoch: [8/10], Loss: 0.0057
Epoch: [9/10], Loss: 0.0053
Epoch: [10/10], Loss: 0.0050
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 0.87
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0136
Epoch: [2/10], Loss: 0.0110
Epoch: [3/10], Loss: 0.0098
Epoch: [4/10], Loss: 0.0090
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0062
Score (accuracy) of the probe: 0.89
The best l1=0, the best l2=0.001 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.72
{'__OVERALL__': 0.7200902934537246, 'NAME': 0.71, 'STRING': 1.0, 'NUMBER': 0.8148148148148148, 'KEYWORD': 0.75}
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0098
Epoch: [3/10], Loss: 0.0087
Epoch: [4/10], Loss: 0.0079
Epoch: [5/10], Loss: 0.0073
Epoch: [6/10], Loss: 0.0067
Epoch: [7/10], Loss: 0.0063
Epoch: [8/10], Loss: 0.0059
Epoch: [9/10], Loss: 0.0055
Epoch: [10/10], Loss: 0.0052
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 0.85
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0056
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0135
Epoch: [2/10], Loss: 0.0112
Epoch: [3/10], Loss: 0.0100
Epoch: [4/10], Loss: 0.0092
Epoch: [5/10], Loss: 0.0086
Epoch: [6/10], Loss: 0.0080
Epoch: [7/10], Loss: 0.0076
Epoch: [8/10], Loss: 0.0072
Epoch: [9/10], Loss: 0.0068
Epoch: [10/10], Loss: 0.0065
Score (accuracy) of the probe: 0.93
The best l1=0, the best l2=0.1 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.69
{'__OVERALL__': 0.6884875846501128, 'NAME': 0.7, 'STRING': 1.0, 'NUMBER': 0.48148148148148145, 'KEYWORD': 0.6666666666666666}
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.86
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0128
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 0.86
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 0.91
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0137
Epoch: [2/10], Loss: 0.0113
Epoch: [3/10], Loss: 0.0102
Epoch: [4/10], Loss: 0.0093
Epoch: [5/10], Loss: 0.0087
Epoch: [6/10], Loss: 0.0082
Epoch: [7/10], Loss: 0.0077
Epoch: [8/10], Loss: 0.0073
Epoch: [9/10], Loss: 0.0070
Epoch: [10/10], Loss: 0.0067
Score (accuracy) of the probe: 0.84
The best l1=0, the best l2=0.01 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.72
{'__OVERALL__': 0.7178329571106095, 'NAME': 0.7225, 'STRING': 1.0, 'NUMBER': 0.5555555555555556, 'KEYWORD': 0.8333333333333334}
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.81
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.86
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.84
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0135
Epoch: [2/10], Loss: 0.0112
Epoch: [3/10], Loss: 0.0102
Epoch: [4/10], Loss: 0.0095
Epoch: [5/10], Loss: 0.0089
Epoch: [6/10], Loss: 0.0085
Epoch: [7/10], Loss: 0.0081
Epoch: [8/10], Loss: 0.0077
Epoch: [9/10], Loss: 0.0075
Epoch: [10/10], Loss: 0.0072
Score (accuracy) of the probe: 0.80
The best l1=0, the best l2=0.001 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.66
{'__OVERALL__': 0.6613995485327314, 'NAME': 0.6525, 'STRING': 1.0, 'NUMBER': 0.7407407407407407, 'KEYWORD': 0.6666666666666666}
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT top neurons
array([2055, 2058, 6155, 8204, 4108, 6158,   13, 8208,   12, 4121, 8218,
       4123, 4124,   31,   50, 4147, 4148, 2104, 4154, 2107,   62, 2116,
         73, 6218, 8265,   76, 4171, 4176, 2131,   84, 4180,   86, 8282,
         94, 6240, 2144, 4193, 2150, 6252,  112,  113,  117, 2167, 8320,
       2182, 4231,  139, 4237, 6287, 8347, 6300, 4256, 6305,  162,  160,
       2209, 4261, 8357,  165,  177,  182, 2237,  195, 8389, 2250, 8404,
        212,  213, 2260, 2262, 4314,  229,  230, 4327,  232, 2280, 8424,
       6376,  236, 2286, 2293, 8442, 8451,  262, 4360, 6413, 6414,  271,
       4368,  275, 6421, 4375,  281, 6428, 2334, 6434, 8493,  307,  308,
       6458, 6459, 4417, 4418, 4419,  332,  333,  336,  337, 4433, 6480,
       6484, 8547,  357, 8549, 8567,  380, 4477,  386, 6534,  395, 2448,
       4501,  405, 6550, 2470,  425, 4528, 8624, 4530,  436,  444, 8636,
       4541, 4547, 2501, 4550,  455, 2507, 2516,  475, 2523, 4574, 8673,
       2531, 2534, 8678,  490, 2541,  499, 4606, 2568,  521, 4619, 4623,
       6672,  529,  531, 8727,  537, 2588, 8733,  541,  540, 4636, 4637,
       8739,  548, 6699, 6701, 4653, 4657, 2612,  565, 2615, 2619,  579,
        580,  586, 2637,  595,  596,  597, 8790, 2647,  599,  598, 2661,
       2664,  617, 4718, 6772, 8828, 8839, 8841, 4751, 4755,  669, 4773,
       6821,  680, 2728,  690, 2740, 2742, 4796,  708,  709, 6854, 4818,
       6868, 8917,  726,  731,  736,  737, 4842, 8939, 4845, 6894,  752,
       4851, 6906, 6912, 2821, 8965, 2823, 2824, 8968, 6923, 8975, 2838,
       6940, 4892, 8990,  799, 4898,  808,  812, 6957, 4915,  819, 4919,
       4920, 4923, 4928, 9024, 2882, 6980, 6989, 4945, 2897, 2903, 9053,
       9054, 2911, 2912, 7013, 2917, 4967, 7020, 2935, 7034, 2941,  895,
        911, 7058, 2967, 7073, 9125, 9129, 2987, 2994, 7100, 3005, 3006,
       7105,  963, 5061,  971, 7121, 9172,  981,  980, 9175, 5082, 7131,
        995, 9187, 3048, 1000, 9197, 7155, 1011, 1020, 9219, 5125, 9225,
       5130, 7180, 5136, 1043, 7191, 5143, 7195, 5148, 3101, 9254, 3117,
       7213, 1071, 5165, 9265, 1073, 1075, 1076, 3121, 7223, 1083, 3133,
       5187, 7248, 3153, 7259, 7268, 9317, 1125, 3174, 5239, 9340, 5245,
       1154, 7302, 7305, 1165, 3215, 7326, 1183, 1193, 7337, 7340, 9388,
       1197, 1204, 3253, 5311, 5313, 3267, 5318, 9415, 7367, 3278, 3284,
       7381, 1239, 7386, 9441, 1265, 3327, 7429, 5381, 1287, 9480, 1289,
       5384, 7432, 5391, 7440, 3345, 5396, 1302, 3351, 1304, 1303, 3356,
       5404, 5421, 3379, 1339, 3387, 3392, 5444, 1348, 3405, 5460, 1368,
       1370, 1375, 1376, 3427, 5477, 3429, 7533, 7540, 1401, 1403, 1406,
       9602, 3458, 5519, 5523, 1437, 9631, 3488, 7589, 1448, 7603, 7611,
       1469, 1477, 1485, 7631, 1494, 5591, 7641, 9690, 1504, 7653, 7656,
       1518, 5614, 1525, 5626, 3586, 9733, 1542, 3597, 5660, 1566, 5667,
       1574, 3627, 1581, 7726, 9775, 1585, 3637, 3643, 3647, 5696, 9796,
       7757, 1616, 3679, 7779, 7781, 1648, 9859, 3719, 5775, 5780, 3732,
       3735, 3737, 3744, 1702, 9896, 9909, 3773, 7873, 1731, 5829, 3782,
       1742, 3791, 1748, 7905, 9955, 1765, 3822, 5879, 1783, 3838, 5893,
       5896, 3855, 5904, 7959, 7964, 7965, 3869, 7971, 3880, 1839, 3889,
       1841, 1844, 7992, 5954, 8004, 3911, 3915, 1869, 1872, 1893, 3950,
       8060, 6013, 8070, 1933, 8079, 3984, 3983, 3987, 6039, 6044, 6048,
       4005, 1965, 1968, 8114, 8123, 8133, 4043, 4046, 8142, 8150, 6102,
       8154, 8166, 2023, 8186])
pretrained_BERT top neurons per class
{'NAME': array([7959, 7191, 4477, 4550, 8727,  726, 4147, 2280, 8320, 2588, 7302,
       7631, 4501, 1204, 8424, 6300, 1437, 5318, 8060, 4619, 7611, 4121,
       7905,   31,   73, 4375, 5313, 4915, 6672, 2882, 2507, 7386, 2286,
       1518, 3987, 2055, 6413, 1302, 4623, 8442, 5523, 9775, 7429, 2935,
       6854, 8917, 4528, 8733,  307, 3379, 5187, 3117, 4360, 1043, 5421,
       6699, 8204, 6459, 4606, 4256, 3586, 3405, 5136,  541, 4108, 5061,
       1494, 4043, 1075,  737, 8673, 6414,  182, 4327,  529,  895,  499,
       4755, 6305, 7058,  444, 5245, 9053, 1154, 3735,  380, 3889, 6252,
       3356, 4368, 9197, 5829, 7073, 1841, 5780, 5879, 7121, 3048, 1339,
       8208, 7020, 2619, 5148, 1239, 4928, 5082, 2116, 6458, 7971, 3782,
       6240, 5143, 9602,  336, 6155, 1401, 1542, 7965, 1083, 6158, 2824,
       3637, 1844, 7195, 2516, 1742, 3392, 2647, 4314, 8123,  229, 9955,
       1375, 2107, 9175, 8636, 9054, 5460, 9225,  540,   86, 8828, 4945,
       2821,  357]), 'STRING': array([7191, 2144,  799, 1437, 7653,  236, 7305, 5404,  333, 6940, 3822,
       1742, 8549, 3267, 8841, 2838, 1869,  752, 4368,  405, 1839, 5381,
       4945,  230, 3791,  669,  808, 1165,  436,  819, 9317, 2541, 1376,
       2664, 8965,  586,  475,  162, 9172, 8567, 2882, 5591, 5187, 2237,
        444, 5477,  113, 2286, 1933, 2167, 1239, 9480, 2058, 4636, 3735,
       6428,   84,  617, 7440, 5519, 6868,  490, 2740, 1075, 5136, 8347,
        537,  981, 1783,  596, 4261,  337, 8624, 9631, 2994,  595, 1193,
       4845, 5396, 4842, 3253, 1125, 4574, 5130, 7268, 8357, 1731, 2531,
       3153, 7873, 1076, 7223, 7105, 4773, 5125, 8150,  597, 9733,  531,
       1702, 9254, 2967, 5893, 1504, 9415,  548, 3356, 2912, 2935, 6957,
       1265, 2055, 1765, 3327, 4046, 9024,  680, 7013, 4231, 2250, 9265,
       5696, 2131,   76, 1469, 7337, 1304,  963, 8404, 7965,  579, 9340,
       8079, 3597, 8790, 7340, 1071, 3737, 9441, 6434, 8166, 1368, 4657,
       4193,  565, 3174, 7779, 3392, 9388, 3627,  177, 2728, 6376, 3732,
       4123, 7540, 7726]), 'NUMBER': array([2116, 2661,  232, 1125, 1204, 8739, 3889, 8636, 7155, 1731, 9219,
        599,   13, 3458, 6989, 2448, 3950, 2742, 4180,  281, 1376, 2897,
        598, 8204, 2150, 2917,  709, 5696, 5904, 7248, 3101, 2144, 3647,
       1289, 4433, 5444, 6980, 2334, 7213, 7781, 4417, 3379, 4619, 1183,
       6701,  580, 4550, 9129, 4919, 1154, 1748, 1525, 9197, 6044, 5660,
       4653, 4419,  386, 1370,  195, 5384, 9909, 8939, 2286, 1075, 6480,
       1073,  812, 7964,  995, 3284,  308, 7191, 1477, 6484, 6550, 4418,
       5311,  726, 3133, 3869, 1485, 4637, 5082,  971, 7340, 4547, 1348,
       3429, 8727, 7180, 5954, 4898, 4818, 4920, 2182, 9733,  117, 6013,
       8186,  212, 6240, 2911,  980, 3984, 3838, 6428, 8975,  332, 1403,
       8493, 6218, 8218, 4718,  911, 4657, 5829, 4851, 4256, 4967, 8133,
       3880,  521, 7992, 9317, 2293, 4530, 7641,   12, 4154,  799, 8004,
       7381, 1000, 3427, 7034, 1197, 2104, 7259, 7100, 4796, 2501, 3488,
       6048, 6894, 9796, 6912,  165, 2903, 3351, 7326, 7533, 4892, 1566,
       8282, 4176, 3006, 2023, 5318]), 'KEYWORD': array([ 521, 1469,  262, 4541, 2612, 6821, 3278,  669,   73, 5460, 9254,
       7757, 4419, 6923, 2661, 2637, 1494, 6772,  160, 1289,  455, 6459,
       1076, 1844, 8673,  307, 3405,  425,  395,  799, 8265, 4124, 9896,
       3121,   94, 3855, 1368, 7656,  112, 4171,  680, 2523, 3773, 4945,
       9859, 8968, 3679, 1437, 5667, 7589, 9125, 3005, 2941,   62,  405,
        275, 3215, 9733,  736, 1287, 7603, 7367, 1448, 1648, 8839,  213,
       5391, 4842, 3387, 1011, 6102, 7432, 1020,  271, 8451, 9187, 5239,
       5591, 3744, 6300, 6434, 2534, 5626,  139, 3643, 6305, 6421, 3983,
       9690, 2260, 3719, 6480, 4148, 6906, 4237, 4751, 4923, 2237, 2615,
        162, 1303, 6287, 2647,  490, 2262, 8154, 4920, 3915, 7073, 1581,
       1872, 8990, 2903, 5896,  731, 3345, 4360, 3379, 8678, 1043, 6039,
       1616, 5614,   50, 1574, 8142, 8547, 1968, 5165, 6534, 2209, 1893,
       7131, 2470, 8727, 4005, 2838, 1585, 1965, 8389, 8114, 3911, 5775,
       1406,  690, 8070, 2987,  708, 2568, 2823, 3356, 4314])}
The shape of selected features (851, 521)
The shape of the training set: (851, 521)
The shape of the validation set: (95, 521)
The shape of the testing set: (443, 521)
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0114
Epoch: [2/10], Loss: 0.0094
Epoch: [3/10], Loss: 0.0080
Epoch: [4/10], Loss: 0.0070
Epoch: [5/10], Loss: 0.0061
Epoch: [6/10], Loss: 0.0054
Epoch: [7/10], Loss: 0.0048
Epoch: [8/10], Loss: 0.0043
Epoch: [9/10], Loss: 0.0040
Epoch: [10/10], Loss: 0.0036
Score (accuracy) of the probe: 0.92
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0085
Epoch: [4/10], Loss: 0.0073
Epoch: [5/10], Loss: 0.0064
Epoch: [6/10], Loss: 0.0057
Epoch: [7/10], Loss: 0.0051
Epoch: [8/10], Loss: 0.0046
Epoch: [9/10], Loss: 0.0042
Epoch: [10/10], Loss: 0.0038
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0118
Epoch: [2/10], Loss: 0.0097
Epoch: [3/10], Loss: 0.0083
Epoch: [4/10], Loss: 0.0072
Epoch: [5/10], Loss: 0.0063
Epoch: [6/10], Loss: 0.0056
Epoch: [7/10], Loss: 0.0051
Epoch: [8/10], Loss: 0.0046
Epoch: [9/10], Loss: 0.0042
Epoch: [10/10], Loss: 0.0038
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0129
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0079
Epoch: [5/10], Loss: 0.0071
Epoch: [6/10], Loss: 0.0064
Epoch: [7/10], Loss: 0.0059
Epoch: [8/10], Loss: 0.0054
Epoch: [9/10], Loss: 0.0051
Epoch: [10/10], Loss: 0.0048
Score (accuracy) of the probe: 0.94
The best l1=0, the best l2=0.1 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.76
{'__OVERALL__': 0.7629796839729119, 'NAME': 0.7675, 'STRING': 1.0, 'NUMBER': 0.6666666666666666, 'KEYWORD': 0.75}
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.90
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0113
Epoch: [3/10], Loss: 0.0105
Epoch: [4/10], Loss: 0.0097
Epoch: [5/10], Loss: 0.0091
Epoch: [6/10], Loss: 0.0086
Epoch: [7/10], Loss: 0.0081
Epoch: [8/10], Loss: 0.0076
Epoch: [9/10], Loss: 0.0072
Epoch: [10/10], Loss: 0.0069
Score (accuracy) of the probe: 0.79
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0110
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0083
Epoch: [7/10], Loss: 0.0078
Epoch: [8/10], Loss: 0.0074
Epoch: [9/10], Loss: 0.0070
Epoch: [10/10], Loss: 0.0067
Score (accuracy) of the probe: 0.84
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0119
Epoch: [2/10], Loss: 0.0109
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0082
Epoch: [7/10], Loss: 0.0078
Epoch: [8/10], Loss: 0.0074
Epoch: [9/10], Loss: 0.0070
Epoch: [10/10], Loss: 0.0067
Score (accuracy) of the probe: 0.82
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0103
Epoch: [4/10], Loss: 0.0097
Epoch: [5/10], Loss: 0.0091
Epoch: [6/10], Loss: 0.0086
Epoch: [7/10], Loss: 0.0082
Epoch: [8/10], Loss: 0.0078
Epoch: [9/10], Loss: 0.0075
Epoch: [10/10], Loss: 0.0072
Score (accuracy) of the probe: 0.91
The best l1=0, the best l2=0.1 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.68
{'__OVERALL__': 0.6817155756207675, 'NAME': 0.7025, 'STRING': 1.0, 'NUMBER': 0.4074074074074074, 'KEYWORD': 0.5}
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 2055 [('filters', 1.0), ('f', 0.9933481163001449), ('seconds', 0.8723980058228384), ('uss', 0.8361487998026631), ('META', 0.8324758144351372)]
Top words for pretrained_BERT neuron indx 2058 [('error', 1.0), ('exceptions', 0.9379259355661107), ('Exception', 0.8750324017646214), ('host', 0.8638581000820981), ('""', 0.8593052545126721)]
Top words for pretrained_BERT neuron indx 6155 [('9', 1.0), ('17', 0.9532847432032694), ('14', 0.9262421124743384), ('16', 0.830780056678453), ('component', 0.7341342089789414)]
Top words for pretrained_BERT neuron indx 8204 [('end', 1.0), ('16', 0.9677555980695298), ('60', 0.9608949443583407), ('40', 0.9565970931459002), ('task', 0.9154181829608014)]
Top words for pretrained_BERT neuron indx 4108 [('Board', 1.0), ('direct', 0.9971459590100529), ('REQUEST', 0.941373065968001), ('render', 0.8890278498503502), ('i', 0.8749723555879919)]
Top words for pretrained_BERT neuron indx 6158 [('force', 1.0), ('15', 0.9225419035062995), ('oslo', 0.8542707954078853), ('Off', 0.7997665099787771), ('enclosure', 0.7820939770286068)]
Top words for pretrained_BERT neuron indx 13 [('field', 1.0), ('item', 0.9090791803642527), ('year', 0.8452370078830994), ('blocking', 0.7474586019005676), ('1000', 0.7404204037470309)]
Top words for pretrained_BERT neuron indx 8208 [('400', 1.0), ('128', 0.994609037355857), ('600', 0.7895559441404815), ('800', 0.7292517048860022), ('""', 0.7198806416957857)]
Top words for pretrained_BERT neuron indx 12 [('unicode', 1.0), ('con', 0.736249130351723), ('sanetime', 0.7294703536784485), ('probe', 0.7285455058557627), ('uss', 0.6986887082006876)]
Top words for pretrained_BERT neuron indx 4121 [('bare', 1.0), ('send', 0.9534017888024978), ('log', 0.9241213944081087), ('dt', 0.8577945580140485), ('List', 0.8119193366040673)]
Top words for pretrained_BERT neuron indx 8218 [('15', 1.0), ('ignore', 0.9420127149273776), ('key', 0.9035137927538642), ('text', 0.8999385533671641), ('"gbk"', 0.8635050468910576)]
Top words for pretrained_BERT neuron indx 4123 [('sorted', 1.0), ('state', 0.9390438006934727), ('E', 0.8603964684168434), ('wait', 0.7907130920857072), ('stanza', 0.7864316948175226)]
Top words for pretrained_BERT neuron indx 4124 [('sorted', 1.0), ('View', 0.9717685532028685), ('""', 0.8167815209530883), ('Plugin', 0.7618461819623226), ('boot', 0.7554914545471325)]
Top words for pretrained_BERT neuron indx 31 [('Node', 1.0), ('objects', 0.9830036380247986), ('loads', 0.9735048580400586), ('token', 0.9060497653013085), ('ndt', 0.8914818612582961)]
Top words for pretrained_BERT neuron indx 50 [('ms', 1.0), ('unicode', 0.8252890579617104), ('GET', 0.8231672958506975), ('GetBoard', 0.7158428130322283), ('token', 0.7125183857015321)]
Top words for pretrained_BERT neuron indx 4147 [('loads', 1.0), ('"Host"', 0.7141178357437681), ('"r"', 0.6762442591358181), ('"Name"', 0.6567256661434353), ('""', 0.6563790590950223)]
Top words for pretrained_BERT neuron indx 4148 [('with', 1.0), ('as', 0.8287827685234936), ('from', 0.7747328247696001), ('broadcast', 0.6545181384356362), ('features', 0.6424513442545561)]
Top words for pretrained_BERT neuron indx 2104 [('component', 1.0), ('Component', 0.9807526630584156), ('bind', 0.8615122855450402), ('task', 0.807253160361323), ('modes', 0.7682955019893014)]
Top words for pretrained_BERT neuron indx 4154 [('st', 1.0), ('time', 0.9689715654146491), ('horizon', 0.9428654444642633), ('Library', 0.8688564387395024), ('field', 0.8548144237416788)]
Top words for pretrained_BERT neuron indx 2107 [('part', 1.0), ('parts', 0.9674502029782983), ('routes', 0.9034184698525681), ('main', 0.7944781525348666), ('con', 0.7799204055580551)]
Top words for pretrained_BERT neuron indx 62 [('int', 1.0), ('1000', 0.7717818495458364), ('send', 0.7382122690066996), ('required', 0.6759689381701741), ('META', 0.654235544002398)]
Top words for pretrained_BERT neuron indx 2116 [('match', 1.0), ('id', 0.9285359309816346), ('clone', 0.9283309123227522), ('state', 0.9173651446563728), ('timezone', 0.9145537997937221)]
Top words for pretrained_BERT neuron indx 73 [('future', 1.0), ('utc', 0.9763772129200454), ('match', 0.9576060045634153), ('Unauthorized', 0.8488757985701004), ('False', 0.8037632185200992)]
Top words for pretrained_BERT neuron indx 6218 [('upper', 1.0), ('link', 0.8622959276894627), ('continue', 0.8238536972353455), ('host', 0.8087259617258531), ('alt', 0.7927101810913665)]
Top words for pretrained_BERT neuron indx 8265 [('part', 1.0), ('oslo', 0.9836595859255386), ('hasattr', 0.949054773840038), ('put', 0.8927380595527022), ('sht', 0.8322820177569953)]
Top words for pretrained_BERT neuron indx 76 [('baseline', 1.0), ('save', 0.9828362900073725), ('Register', 0.94511820898088), ('unicode', 0.944967211145637), ('patch', 0.9365435163048826)]
Top words for pretrained_BERT neuron indx 4171 [('REQUEST', 1.0), ('identity', 0.9370031608398589), ('Exception', 0.8713751637321487), ('type', 0.8629888114112725), ('logging', 0.8030721320838414)]
Top words for pretrained_BERT neuron indx 4176 [('time', 1.0), ('Log', 0.9029837521422444), ('MAXSIGLINES', 0.8215394166124027), ('profile', 0.8208008451073718), ('8000', 0.8202384460252633)]
Top words for pretrained_BERT neuron indx 2131 [('1000', 1.0), ('feature', 0.7481324599569097), ('unicode', 0.6717449191181363), ('us', 0.627073705969063), ('if', 0.6142449036846297)]
Top words for pretrained_BERT neuron indx 84 [('partition', 1.0), ('Distance', 0.9566385385687999), ('resource', 0.9292673385720317), ('logging', 0.9223967482455567), ('common', 0.9062019392295734)]
Top words for pretrained_BERT neuron indx 4180 [('template', 1.0), ('target', 0.8421085723412364), ('task', 0.7998042288466739), ('conn', 0.7980119897971286), ('k', 0.7932594631948651)]
Top words for pretrained_BERT neuron indx 86 [('token', 1.0), ('Tab', 0.9950214932363474), ('save', 0.9188722544696701), ('local', 0.8738344224162394), ('uss', 0.8729328994463331)]
Top words for pretrained_BERT neuron indx 8282 [('other', 1.0), ('authorization', 0.948756550684768), ('blocking', 0.8533953403961803), ('ref', 0.814186851942075), ('bind', 0.8008098891258909)]
Top words for pretrained_BERT neuron indx 94 [('affinity', 1.0), ('identity', 0.9725634004224342), ('authentication', 0.8380002382022914), ('key', 0.791495817874774), ('session', 0.7030089253794803)]
Top words for pretrained_BERT neuron indx 6240 [('tz', 1.0), ('features', 0.8173230899122854), ('models', 0.7927382263260941), ('oslo', 0.7600997198834962), ('core', 0.7338438104824246)]
Top words for pretrained_BERT neuron indx 2144 [('Log', 1.0), ('body', 0.933601791541185), ('common', 0.8526974600615969), ('line', 0.84366630741154), ('reactor', 0.8333143894648358)]
Top words for pretrained_BERT neuron indx 4193 [('second', 1.0), ('long', 0.919456229202189), ('repr', 0.8545019900220466), ('\\\'"\\\'', 0.8269307746737937), ('utc_datetime', 0.7662677280604989)]
Top words for pretrained_BERT neuron indx 2150 [('authorization', 1.0), ('LoadUser', 0.8056654531775186), ('script', 0.7972446581985251), ('resource', 0.7480006454064952), ('unicode', 0.7459299852795211)]
Top words for pretrained_BERT neuron indx 6252 [('authentication', 1.0), ('k', 0.9221165040488506), ('"oslo"', 0.9033448749128654), ('"Name"', 0.8820375326445318), ('exceptions', 0.8612034725828)]
Top words for pretrained_BERT neuron indx 112 [('False', 1.0), ('save', 0.9937954535906388), ('exit', 0.9442725821818085), ('horizon', 0.8481496020841511), ('arg', 0.8437291493405262)]
Top words for pretrained_BERT neuron indx 113 [('Library', 1.0), ('patch', 0.7650990875539418), ('boot', 0.7590988992313222), ('contents', 0.7515253902526968), ('k', 0.6621519304216819)]
Top words for pretrained_BERT neuron indx 117 [('minute', 1.0), ('join', 0.9019744157695692), ('target', 0.8563563232960155), ('component', 0.8518928079141367), ('server', 0.8388007077256812)]
Top words for pretrained_BERT neuron indx 2167 [('child', 1.0), ('send', 0.9306836394391359), ('prange', 0.8390965406776391), ('force', 0.8352002250224426), ('ref', 0.8331527039750952)]
Top words for pretrained_BERT neuron indx 8320 [('30', 1.0), ('20', 0.9077507744618599), ('40', 0.9042046224322228), ('60', 0.8782799044961853), ('600', 0.8227897154672261)]
Top words for pretrained_BERT neuron indx 2182 [('settings', 1.0), ('oslo', 0.8812420450462195), ('horizon', 0.8097124724299819), ('unicode', 0.8043519302639527), ('child', 0.762893353559324)]
Top words for pretrained_BERT neuron indx 4231 [('parser', 1.0), ('seconds', 0.9510821138399111), ('val', 0.9397214631050324), ('text', 0.8767667702838228), ('uuid', 0.8399501863798254)]
Top words for pretrained_BERT neuron indx 139 [('utc', 1.0), ('utcnow', 0.8794712329199594), ('reactor', 0.8181120847135982), ('endswith', 0.7415183798077446), ('disable_manage_boot', 0.7349212964604881)]
Top words for pretrained_BERT neuron indx 4237 [('close', 1.0), ('Billboard', 0.9748133400377804), ('slug', 0.9277852221301116), ('Simple', 0.8846947664542082), ('re', 0.858969531005803)]
Top words for pretrained_BERT neuron indx 6287 [('Unauthorized', 1.0), ('patch', 0.999181014635374), ('long', 0.9243079867940582), ('port', 0.8261407775045871), ('servers', 0.7886410406805405)]
Top words for pretrained_BERT neuron indx 8347 [('end', 1.0), ('"purpose"', 0.9447429742553132), ('"view"', 0.9385672053498504), ('seconds', 0.7894710074985809), ('class', 0.7121154181886008)]
Top words for pretrained_BERT neuron indx 6300 [('logging', 1.0), ('wait', 0.7142618752054821), ('resource', 0.713713477633967), ('user', 0.6835013924866169), ('stat', 0.6109537796170625)]
Top words for pretrained_BERT neuron indx 4256 [('80', 1.0), ('60', 0.9445245059282458), ('32', 0.8974342532317707), ('40', 0.8668737540531727), ('20', 0.7481020941905038)]
Top words for pretrained_BERT neuron indx 6305 [('False', 1.0), ('profile', 0.6357449379361516), ('Post', 0.5989780548003085), ('Profile', 0.5893086927173953), ('error', 0.5233644153528803)]
Top words for pretrained_BERT neuron indx 162 [('contextlib', 1.0), ('split', 0.8333941719768054), ('uss', 0.8223767719190627), ('context', 0.7613642523239282), ('boot', 0.7446433451523841)]
Top words for pretrained_BERT neuron indx 160 [('META', 1.0), ('count', 0.7797562794148591), ('View', 0.6997169123739447), ('GetMirror', 0.6729883874107143), ('baseline', 0.6503523926180995)]
Top words for pretrained_BERT neuron indx 2209 [('horizon', 1.0), ('host', 0.9886865948638018), ('utc', 0.9551793497455446), ('builtins', 0.887265234757409), ('presence', 0.8583949906601963)]
Top words for pretrained_BERT neuron indx 4261 [('calendar', 1.0), ('affinity', 0.870150808867467), ('log', 0.8350367972554515), ('break', 0.8173634912917168), ('logging', 0.8103787186786845)]
Top words for pretrained_BERT neuron indx 8357 [('if', 1.0), ('META', 0.9214870871968129), ('1800', 0.7066530678243613), ('400', 0.6901527916192977), ('14', 0.6651867544519667)]
Top words for pretrained_BERT neuron indx 165 [('close', 1.0), ('REQUEST', 0.9888218523132358), ('iq', 0.9281104774895929), ('hpov', 0.870578976312656), ('refresh', 0.837401203355967)]
Top words for pretrained_BERT neuron indx 177 [('replace', 1.0), ('ignore', 0.8565413409271593), ('authorized', 0.7549337981487524), ('Session', 0.752799145795599), ('reactor', 0.6816351609765164)]
Top words for pretrained_BERT neuron indx 182 [('import', 1.0), ('clone', 0.9950917825228563), ('32', 0.9606751953969687), ('domain', 0.8445765250530725), ('message', 0.8136810059630146)]
Top words for pretrained_BERT neuron indx 2237 [('enabled', 1.0), ('Node', 0.898814841699704), ('other', 0.8515890852962995), ('sts', 0.7959014023276405), ('None', 0.7892253894689821)]
Top words for pretrained_BERT neuron indx 195 [('add', 1.0), ('reactor', 0.8317328899680987), ('material', 0.8083987524906315), ('error', 0.8006356469566076), ('mtime', 0.7337451124259456)]
Top words for pretrained_BERT neuron indx 8389 [('other', 1.0), ('from_', 0.9850095217445777), ('authorization', 0.8849090811712137), ('__long__', 0.860018887646), ('board', 0.8239878140180034)]
Top words for pretrained_BERT neuron indx 2250 [('partition', 1.0), ('scope', 0.989821593174559), ('close', 0.9689833472671797), ('created', 0.9012286156289779), ('main', 0.8965594372971809)]
Top words for pretrained_BERT neuron indx 8404 [('route', 1.0), ('line', 0.9633179457750058), ('REQUEST', 0.8870896838718711), ('strip', 0.8858346106517996), ('Simple', 0.870572922970508)]
Top words for pretrained_BERT neuron indx 212 [('stat', 1.0), ('component', 0.8907250842802013), ('List', 0.782715289484503), ('ranges', 0.7361422240109057), ('defval', 0.708160451923158)]
Top words for pretrained_BERT neuron indx 213 [('exit', 1.0), ('line', 0.9943089498374184), ('val', 0.9498200278011298), ('write', 0.9442242303011763), ('close', 0.9352945237360282)]
Top words for pretrained_BERT neuron indx 2260 [('strip', 1.0), ('child', 0.9989987576319316), ('route', 0.9570573319155903), ('host', 0.914197060335286), ('feature', 0.8615721490779855)]
Top words for pretrained_BERT neuron indx 2262 [('count', 1.0), ('seek', 0.9891025765965301), ('close', 0.9707754005167959), ('while', 0.8536856995201181), ('closing', 0.8324036913990402)]
Top words for pretrained_BERT neuron indx 4314 [('Tab', 1.0), ('Profile', 0.7762297507790323), ('import', 0.7651216185999334), ('as', 0.6843238698584165), ('PY2', 0.6047368904556961)]
Top words for pretrained_BERT neuron indx 229 [('core', 1.0), ('Register', 0.9873527073704352), ('hour', 0.9840505385194409), ('reactor', 0.8991340072740575), ('strip', 0.8141094636884266)]
Top words for pretrained_BERT neuron indx 230 [('calendar', 1.0), ('v', 0.985249358357714), ('register', 0.8225069420098561), ('digest', 0.8191654587635807), ('patch', 0.8080653455208908)]
Top words for pretrained_BERT neuron indx 4327 [('store', 1.0), ('Unauthorized', 0.9998857688286305), ('1800', 0.933303088496501), ('oslo', 0.9304403306768827), ('3700', 0.8928328680073043)]
Top words for pretrained_BERT neuron indx 232 [('settings', 1.0), ('authorized', 0.8978632039109679), ('send', 0.8172387790461202), ('store', 0.7310029425027953), ('render', 0.7309611637532988)]
Top words for pretrained_BERT neuron indx 2280 [('REQUEST', 1.0), ('int', 0.9993000746737052), ('probe', 0.9730612663253483), ('push', 0.9511593586253402), ('read', 0.9218520030563941)]
Top words for pretrained_BERT neuron indx 8424 [('600', 1.0), ('authorization', 0.849935851772957), ('import', 0.8476276393639742), ('3700', 0.8459670899305076), ('format', 0.8384054654913754)]
Top words for pretrained_BERT neuron indx 6376 [('Unauthorized', 1.0), ('fileno', 0.9403755202561993), ('8000', 0.9356057995383422), ('affinity', 0.9316562343106178), ('datetime', 0.9179818515624768)]
Top words for pretrained_BERT neuron indx 236 [('parts', 1.0), ('hour', 0.8135300759299744), ('List', 0.7791496494133852), ('direct', 0.755844827017133), ('type', 0.7532047668172034)]
Top words for pretrained_BERT neuron indx 2286 [('Component', 1.0), ('24', 0.9661204210487164), ('count', 0.9298818012913154), ('List', 0.9236079008527429), ('Board', 0.9183971927847046)]
Top words for pretrained_BERT neuron indx 2293 [('replace', 1.0), ('feature', 0.7767717038805119), ('stat', 0.6974026249112001), ('activity', 0.6968140441260193), ('break', 0.6958610148087347)]
Top words for pretrained_BERT neuron indx 8442 [('add', 1.0), ('return', 0.9534167485026874), ('future', 0.9284471891654683), ('session', 0.8984446323907932), ('argparse', 0.8924260972715102)]
Top words for pretrained_BERT neuron indx 8451 [('80', 1.0), ('if', 0.8947181953794062), ('20', 0.7957854977897645), ('hasattr', 0.7691835918049604), ('30', 0.7679776642586446)]
Top words for pretrained_BERT neuron indx 262 [('identity', 1.0), ('stanza', 0.9694626746440145), ('zone', 0.8555129974119958), ('ping', 0.8487875353683252), ('Distance', 0.7877083682619527)]
Top words for pretrained_BERT neuron indx 4360 [('con', 1.0), ('pop', 0.9604719113262591), ('re', 0.7551073841973486), ('1000', 0.7397553062448706), ('400', 0.7344899716351749)]
Top words for pretrained_BERT neuron indx 6413 [('write', 1.0), ('identity', 0.9454527055733071), ('reactor', 0.920990925587104), ('bind', 0.9154655614725538), ('id', 0.9099071353879518)]
Top words for pretrained_BERT neuron indx 6414 [('Off', 1.0), ('def', 0.8927795618700316), ('find', 0.8603563315650262), ('3700', 0.7628505037347549), ('20000', 0.7506448769568287)]
Top words for pretrained_BERT neuron indx 271 [('bind', 1.0), ('Session', 0.845794715132436), ('field', 0.8393272312598159), ('Register', 0.8357937022596377), ('digest', 0.811016505169726)]
Top words for pretrained_BERT neuron indx 4368 [('pop', 1.0), ('ignore', 0.8947157548438386), ('types', 0.8295492177794435), ('log', 0.7982694647107184), ('400', 0.7927589014950034)]
Top words for pretrained_BERT neuron indx 275 [('egroup', 1.0), ('False', 0.9850087322826252), ('key', 0.952648552741768), ('utc', 0.8701480346190383), ('required', 0.8482427121310114)]
Top words for pretrained_BERT neuron indx 6421 [('other', 1.0), ('read', 0.8627949446374306), ('unicode', 0.7864616647254635), ('loads', 0.7227686286599165), ('fcs', 0.6353281279826221)]
Top words for pretrained_BERT neuron indx 4375 [('token', 1.0), ('86400', 0.9217300637831378), ('3600', 0.887196770549467), ('item', 0.8801394471972873), ('80', 0.8785005247950227)]
Top words for pretrained_BERT neuron indx 281 [('bare', 1.0), ('send', 0.9849965592304389), ('int', 0.7725718569225526), ('sts', 0.7481479261914921), ('View', 0.7054354369641141)]
Top words for pretrained_BERT neuron indx 6428 [('View', 1.0), ('if', 0.9488813188042668), ('url', 0.8761714049330238), ('Plugin', 0.846333860079992), ('None', 0.7691955834038209)]
Top words for pretrained_BERT neuron indx 2334 [('boot', 1.0), ('Util', 0.8049157199507626), ('task', 0.7693430304734042), ('message', 0.7605880696226266), ('proxy', 0.7124161434620091)]
Top words for pretrained_BERT neuron indx 6434 [('route', 1.0), ('modes', 0.9770205984214393), ('routes', 0.8896362884575785), ('List', 0.8710151627000711), ('created', 0.8640079758435907)]
Top words for pretrained_BERT neuron indx 8493 [('if', 1.0), ('hasattr', 0.9073133378359213), ('method', 0.8990178384341436), ('iteritems', 0.8113044646464125), ('identity', 0.8098850208361407)]
Top words for pretrained_BERT neuron indx 307 [('close', 1.0), ('loads', 0.8321363124703902), ('partition', 0.7256524268343756), ('Profile', 0.7237465043611263), ('roster', 0.6913081337516109)]
Top words for pretrained_BERT neuron indx 308 [('".."', 1.0), ('to', 0.9867403510237927), ('with', 0.8343859976152751), ('""', 0.7803293137970155), ('"../../%s"', 0.7395643377567517)]
Top words for pretrained_BERT neuron indx 6458 [('st', 1.0), ('end', 0.969357111121799), ('horizon', 0.9178084864009127), ('time', 0.911018836508141), ('field', 0.8816537296492403)]
Top words for pretrained_BERT neuron indx 6459 [('sorted', 1.0), ('with', 0.9708883808412826), ('long', 0.8845108591227738), ('profile', 0.8662582574552009), ('wait', 0.8183737820763541)]
Top words for pretrained_BERT neuron indx 4417 [('direct', 1.0), ('field', 0.7444427092215705), ('if', 0.6949340860155301), ('register', 0.6613935585546168), ('i', 0.6593047440993374)]
Top words for pretrained_BERT neuron indx 4418 [('startswith', 1.0), ('stanza', 0.9615774239134226), ('settings', 0.8892940109313626), ('wait', 0.8591608925943474), ('upper', 0.8249978389880355)]
Top words for pretrained_BERT neuron indx 4419 [('local', 1.0), ('id', 0.9164497805934984), ('target', 0.8687493700181093), ('v', 0.8145574938077701), ('int', 0.7979017493316106)]
Top words for pretrained_BERT neuron indx 332 [('dt', 1.0), ('sans', 0.9699787926203086), ('sts', 0.8933410400396552), ('server', 0.8573003516756813), ('val', 0.8010835402763293)]
Top words for pretrained_BERT neuron indx 333 [('24', 1.0), ('Unauthorized', 0.9929125996027518), ('enclosure', 0.9823657006343189), ('main', 0.9481312240469908), ('horizon', 0.926897504222984)]
Top words for pretrained_BERT neuron indx 336 [('hour', 1.0), ('objects', 0.9624441571770519), ('domain', 0.940203382412957), ('enclosure', 0.9165541547557586), ('exceptions', 0.8999456374606074)]
Top words for pretrained_BERT neuron indx 337 [('iq', 1.0), ('choices', 0.8106203289183914), ('def', 0.7627988651159265), ('context', 0.7146388463842295), ('calendar', 0.6792648833657967)]
Top words for pretrained_BERT neuron indx 4433 [('types', 1.0), ('objects', 0.9881554688504909), ('sans', 0.9466161176025114), ('attr', 0.9143042392095501), ('Off', 0.836482576535185)]
Top words for pretrained_BERT neuron indx 6480 [('MAXSIGLINES', 1.0), ('""', 0.9993997044979811), ('remove_server_hardware_type', 0.9627540021727732), ('time', 0.9617787785997657), ('strftime', 0.9093855650487658)]
Top words for pretrained_BERT neuron indx 6484 [('".."', 1.0), ('""', 0.9820569991742524), ('9', 0.9358414453001355), ('"Port"', 0.8646335389596325), ('"Attach"', 0.8151160578007368)]
Top words for pretrained_BERT neuron indx 8547 [('title', 1.0), ('post', 0.9922732541369105), ('policy', 0.9816380045339379), ('host', 0.9209563417548678), ('exit', 0.9192184236797861)]
Top words for pretrained_BERT neuron indx 357 [('boot', 1.0), ('contents', 0.8722259392479665), ('Stretch', 0.765687294585199), ('link', 0.7546432060596474), ('title', 0.7071524798099849)]
Top words for pretrained_BERT neuron indx 8549 [('patch', 1.0), ('alt', 0.9937708078260229), ('repr', 0.8080929177965893), ('replace', 0.7420604111047574), ('ping', 0.7265290353588331)]
Top words for pretrained_BERT neuron indx 8567 [('local', 1.0), ('"oslo"', 0.9390671054925988), ('oslo', 0.8570076365625764), ('minutes', 0.8539747402740269), ('materials', 0.8168605530091614)]
Top words for pretrained_BERT neuron indx 380 [('slug', 1.0), ('read', 0.9379298898745327), ('unicode', 0.8844404526064044), ('alt', 0.8496898799281704), ('minutes', 0.8483337497199653)]
Top words for pretrained_BERT neuron indx 4477 [('300', 1.0), ('17', 0.9594403079729918), ('30', 0.8837788868508527), ('reactor', 0.8226069028955755), ('32', 0.7933300477661818)]
Top words for pretrained_BERT neuron indx 386 [('unicode', 1.0), ('import', 0.8595854508269707), ('format', 0.8557086449040496), ('alt', 0.7539834226257983), ('val', 0.7355191671056307)]
Top words for pretrained_BERT neuron indx 6534 [('"purpose"', 1.0), ('"r"', 0.9561115591738898), ('"gbk"', 0.8381329473010982), ('"oslo"', 0.8334175970655353), ('"Path"', 0.771104211392251)]
Top words for pretrained_BERT neuron indx 395 [('enclosuregroup', 1.0), ('enclosure', 0.9095937976476569), ('child', 0.8496187324522099), ('unpack', 0.840229133435105), ('cfg', 0.8142299737997791)]
Top words for pretrained_BERT neuron indx 2448 [('blocking', 1.0), ('pass', 0.922087338128273), ('other', 0.8118046379026964), ('Distance', 0.7859853171564901), ('read', 0.7810665735303396)]
Top words for pretrained_BERT neuron indx 4501 [('boot', 1.0), ('bare', 0.9947867547695471), ('ping', 0.9208827425384907), ('9', 0.8888840422965382), ('required', 0.8607162465712571)]
Top words for pretrained_BERT neuron indx 405 [('server', 1.0), ('request', 0.8922643956044766), ('REQUEST', 0.754652035194559), ('purpose', 0.6616764337182777), ('requests', 0.6283640855087277)]
Top words for pretrained_BERT neuron indx 6550 [('uss', 1.0), ('end', 0.9730477040854663), ('info', 0.9345562172103644), ('us', 0.9015647770167081), ('OldestInFront', 0.8813815967121574)]
Top words for pretrained_BERT neuron indx 2470 [('core', 1.0), ('bare', 0.9304892609988867), ('mesh', 0.8099838885276237), ('resource', 0.7531080759369915), ('continue', 0.7526640577718391)]
Top words for pretrained_BERT neuron indx 425 [('Simple', 1.0), ('ref', 0.8083021875855447), ('core', 0.7613784803122269), ('class', 0.6795437856848484), ('calendar', 0.6318527371918637)]
Top words for pretrained_BERT neuron indx 4528 [('re', 1.0), ('List', 0.8149916298786333), ('modes', 0.8043592764907591), ('push', 0.7896214397452513), ('roster', 0.7328154109797093)]
Top words for pretrained_BERT neuron indx 8624 [('""', 1.0), ('sans', 0.8794238695825912), ('milliseconds', 0.7480501703414743), ('millis', 0.7461597403430369), ('Billboard', 0.7217262026116895)]
Top words for pretrained_BERT neuron indx 4530 [('30', 1.0), ('Mesh', 0.9791540706751344), ('choices', 0.9686879101590736), ('if', 0.9626190606708941), ('replace', 0.899583882182671)]
Top words for pretrained_BERT neuron indx 436 [('strip', 1.0), ('unicode', 0.9360872560136101), ('exceptions', 0.9226627450708221), ('Exception', 0.8051339946056008), ('purpose', 0.7815094775032381)]
Top words for pretrained_BERT neuron indx 444 [('bare', 1.0), ('Tab', 0.9762327099869343), ('blocking', 0.943505392244576), ('objects', 0.918114126746726), ('None', 0.7956732062332389)]
Top words for pretrained_BERT neuron indx 8636 [('message', 1.0), ('route', 0.9537246802996083), ('connection', 0.9038214805716509), ('partition', 0.8817377727365093), ('1000', 0.8776470639875876)]
Top words for pretrained_BERT neuron indx 4541 [('Node', 1.0), ('None', 0.8274757974813033), ('v', 0.7137315120499345), ('Off', 0.6771850805816206), ('encode', 0.6664903220316426)]
Top words for pretrained_BERT neuron indx 4547 [('clone', 1.0), ('""', 0.9591946217064702), ('render', 0.8512080896387892), ('i', 0.7571543897892845), ('parser', 0.7466515949459737)]
Top words for pretrained_BERT neuron indx 2501 [('post', 1.0), ('id', 0.8537231036668503), ('closing', 0.7882053046705368), ('add', 0.7781941219472679), ('purpose', 0.768337597192626)]
Top words for pretrained_BERT neuron indx 4550 [('80', 1.0), ('40', 0.9616211133162204), ('20', 0.868495590702905), ('400', 0.8493788299881772), ('60', 0.8398177693603973)]
Top words for pretrained_BERT neuron indx 455 [('error', 1.0), ('dt', 0.6768642880763206), ('write', 0.6735597205583833), ('oslo', 0.6674143279191868), ('choices', 0.6604580927833926)]
Top words for pretrained_BERT neuron indx 2507 [('400', 1.0), ('board', 0.9525091830716711), ('Log', 0.9106779351548021), ('Post', 0.8959612397412359), ('refresh', 0.8819992276509843)]
Top words for pretrained_BERT neuron indx 2516 [('400', 1.0), ('key', 0.9331593222797533), ('1000', 0.9208499212196473), ('target', 0.9207297399202293), ('wait', 0.892292624494576)]
Top words for pretrained_BERT neuron indx 475 [('entity', 1.0), ('state', 0.9796884263909211), ('View', 0.9109330890193758), ('enclosure', 0.8165024374243072), ('save', 0.7848998767630324)]
Top words for pretrained_BERT neuron indx 2523 [('128', 1.0), ('32', 0.9687936216052035), ('minute', 0.9407137105355091), ('uss', 0.9098067994278931), ('hour', 0.8875344983850822)]
Top words for pretrained_BERT neuron indx 4574 [('add', 1.0), ('other', 0.8048152731899719), ('credential', 0.662493618182073), ('save', 0.6603218844468419), ('policy', 0.6340030702783742)]
Top words for pretrained_BERT neuron indx 8673 [('blocking', 1.0), ('presence', 0.8996854737414685), ('__long__', 0.8606693446878722), ('ignore', 0.810712233366215), ('ARTICLE_TITLE_LEN', 0.7317339803179298)]
Top words for pretrained_BERT neuron indx 2531 [('save', 1.0), ('boot', 0.8770747213726318), ('login', 0.8051129184623009), ('def', 0.791293257610629), ('join', 0.7892845423358027)]
Top words for pretrained_BERT neuron indx 2534 [('title', 1.0), ('v', 0.9982617382453308), ('message', 0.7465338440610656), ('direct', 0.728744273713713), ('state', 0.7266893904648737)]
Top words for pretrained_BERT neuron indx 8678 [('enclosure', 1.0), ('1000', 0.9651847851841858), ('i', 0.9271749084685927), ('to', 0.8964313666815688), ('types', 0.8927427230861633)]
Top words for pretrained_BERT neuron indx 490 [('exit', 1.0), ('break', 0.748798730106392), ('material', 0.7377781110763345), ('st', 0.7336064020996242), ('read', 0.678190953770261)]
Top words for pretrained_BERT neuron indx 2541 [('title', 1.0), ('unicode', 0.9712720557789146), ('upper', 0.9150213044465518), ('egs', 0.7924695905182969), ('end', 0.7909139429477162)]
Top words for pretrained_BERT neuron indx 499 [('slug', 1.0), ('print', 0.9551848709975809), ('NoPerm', 0.9114676009799244), ('False', 0.8960153523540123), ('ref', 0.8822864085339944)]
Top words for pretrained_BERT neuron indx 4606 [('9', 1.0), ('14', 0.9469126643885571), ('con', 0.8723846768934187), ('contents', 0.8488653861949733), ('Authorization', 0.8448535829753376)]
Top words for pretrained_BERT neuron indx 2568 [('contents', 1.0), ('Distance', 0.8533269100881188), ('sans', 0.7347105575195657), ('""', 0.705368909082292), ('probe', 0.688537932673399)]
Top words for pretrained_BERT neuron indx 521 [('class', 1.0), ('save', 0.922109573892824), ('us', 0.9217373733152617), ('profile', 0.9103293495727132), ('BlendProbes', 0.8685046238433449)]
Top words for pretrained_BERT neuron indx 4619 [('14', 1.0), ('Off', 0.960728650911685), ('Exception', 0.8992989044927087), ('16', 0.8547845451450401), ('400', 0.8416314298364023)]
Top words for pretrained_BERT neuron indx 4623 [('key', 1.0), ('as', 0.990240067559306), ('break', 0.7248089891608711), ('Tab', 0.7042802834969452), ('Plugin', 0.6959474698677761)]
Top words for pretrained_BERT neuron indx 6672 [('128', 1.0), ('pop', 0.9955545024252015), ('400', 0.9646595636785467), ('600', 0.9025210899117996), ('types', 0.8835827104060057)]
Top words for pretrained_BERT neuron indx 529 [('utcnow', 1.0), ('unicode', 0.9217645342986175), ('utc', 0.9201433223680072), ('On', 0.883086731431279), ('with', 0.8511411775250651)]
Top words for pretrained_BERT neuron indx 531 [('count', 1.0), ('stanza', 0.9053153066057913), ('re', 0.8720464355829114), ('pop', 0.8541463410016386), ('Billboard', 0.8132222205524526)]
Top words for pretrained_BERT neuron indx 8727 [('replace', 1.0), ('alt', 0.9395229919386449), ('session', 0.8489737058328578), ('80', 0.8413911077570042), ('20', 0.7538766562835945)]
Top words for pretrained_BERT neuron indx 537 [('upper', 1.0), ('strip', 0.9284448147883462), ('month', 0.8828018034425357), ('year', 0.8216155430708864), ('boot', 0.8082251100849809)]
Top words for pretrained_BERT neuron indx 2588 [('sorted', 1.0), ('View', 0.8482510357943354), ('v', 0.7223301077545736), ('port', 0.6746936565837365), ('resource', 0.6720421429456113)]
Top words for pretrained_BERT neuron indx 8733 [('log', 1.0), ('Log', 0.7705195343093956), ('400', 0.7642139317566541), ('zone', 0.7306946224289068), ('800', 0.6317189566356283)]
Top words for pretrained_BERT neuron indx 541 [('32', 1.0), ('17', 0.874831401334601), ('1024', 0.8434937710082133), ('utc', 0.8295087479619917), ('128', 0.8292196960861821)]
Top words for pretrained_BERT neuron indx 540 [('Board', 1.0), ('created', 0.9736386554369424), ('enabled', 0.9160554876073689), ('part', 0.9150592108787411), ('False', 0.9022732006065773)]
Top words for pretrained_BERT neuron indx 4636 [('View', 1.0), ('host', 0.9763944459986517), ('fcs', 0.9269460002895848), ('requests', 0.9255506206746541), ('error', 0.9196914414576731)]
Top words for pretrained_BERT neuron indx 4637 [('session', 1.0), ('action', 0.8793163950596489), ('sans', 0.8521666460372087), ('32', 0.8307721435963398), ('other', 0.7448539604518404)]
Top words for pretrained_BERT neuron indx 8739 [('pop', 1.0), ('entity', 0.9430421851561346), ('template', 0.9109472233029504), ('routes', 0.8971478701447853), ('us', 0.8771990723884463)]
Top words for pretrained_BERT neuron indx 548 [('add', 1.0), ('Distance', 0.8515176503093445), ('host', 0.8490264418927266), ('root', 0.7855057455529789), ('start', 0.7111888666341765)]
Top words for pretrained_BERT neuron indx 6699 [('open', 1.0), ('core', 0.9232564825240596), ('group', 0.8391776174773425), ('write', 0.7944911448662282), ('patch', 0.7944699477900558)]
Top words for pretrained_BERT neuron indx 6701 [('readfp', 1.0), ('repr', 0.9696170896093294), ('read', 0.9431953573649353), ('alt', 0.8663422988733039), ('dest', 0.8407895658203617)]
Top words for pretrained_BERT neuron indx 4653 [('state', 1.0), ('E', 0.9348607751202127), ('digest', 0.8331168261450499), ('calendar', 0.8176986284356585), ('required', 0.8083633100129132)]
Top words for pretrained_BERT neuron indx 4657 [('Authorization', 1.0), ('end', 0.9092544136419815), ('required', 0.8941423615458158), ('authorization', 0.8671060886877549), ('24', 0.8303812566576758)]
Top words for pretrained_BERT neuron indx 2612 [('as', 1.0), ('with', 0.986124523395788), ('from', 0.9282798240910204), ('".."', 0.8717667046279615), ('to', 0.8258761667211725)]
Top words for pretrained_BERT neuron indx 565 [('import', 1.0), ('target', 0.8574847180965758), ('uuid', 0.6573795930524066), ('filter', 0.6137147207665581), ('basepath', 0.5855363624267407)]
Top words for pretrained_BERT neuron indx 2615 [('link', 1.0), ('Session', 0.8624621159196797), ('created', 0.8516005466922189), ('root', 0.826420505673053), ('E', 0.7135387971506226)]
Top words for pretrained_BERT neuron indx 2619 [('field', 1.0), ('part', 0.9896328470951983), ('sorted', 0.9626532253364593), ('ping', 0.9176688916653801), ('LoadUser', 0.9168903679043978)]
Top words for pretrained_BERT neuron indx 579 [('exceptions', 1.0), ('contents', 0.9633971163558829), ('sorted', 0.9271788042740828), ('clone', 0.8919620218281434), ('script', 0.8480588280799524)]
Top words for pretrained_BERT neuron indx 580 [('month', 1.0), ('template', 0.9798105450161714), ('stanza', 0.9441730821244383), ('id', 0.8968126563361457), ('end', 0.8511414586842183)]
Top words for pretrained_BERT neuron indx 586 [('replace', 1.0), ('settings', 0.8975507639319831), ('exceptions', 0.8651883498818035), ('unicode', 0.8233218528302724), ('iq', 0.8132084482420002)]
Top words for pretrained_BERT neuron indx 2637 [('main', 1.0), ('types', 0.9557100004133526), ('v', 0.9397891468617023), ('board', 0.8964813438448654), ('128', 0.8942042032843432)]
Top words for pretrained_BERT neuron indx 595 [('feature', 1.0), ('1000', 0.9374835203770537), ('break', 0.835428562894481), ('features', 0.8238892734134243), ('alt', 0.7411521419389925)]
Top words for pretrained_BERT neuron indx 596 [('800', 1.0), ('stanza', 0.9485991480073748), ('alt', 0.7752509866458743), ('wait', 0.7704726615281344), ('clone', 0.733758073343799)]
Top words for pretrained_BERT neuron indx 597 [('loads', 1.0), ('400', 0.7504546578578934), ('policy', 0.7323584030676091), ('utc', 0.7088442502780685), ('link', 0.6700181613987122)]
Top words for pretrained_BERT neuron indx 8790 [('ignore', 1.0), ('write', 0.9528559448839234), ('False', 0.8967322620154994), ('body', 0.8944612146772186), ('hour', 0.8499098278019411)]
Top words for pretrained_BERT neuron indx 2647 [('1800', 1.0), ('View', 0.7659804034397482), ('800', 0.7345202706252495), ('k', 0.677745967457044), ('8000', 0.6538849056065865)]
Top words for pretrained_BERT neuron indx 599 [('1000', 1.0), ('objects', 0.9333793941168708), ('View', 0.890806502806513), ('break', 0.8777325210645002), ('sans', 0.8746107751408555)]
Top words for pretrained_BERT neuron indx 598 [('Unauthorized', 1.0), ('domain', 0.8972164900808483), ('minute', 0.8894476555032348), ('unicode', 0.8599103365119515), ('bare', 0.8558229916373906)]
Top words for pretrained_BERT neuron indx 2661 [('contents', 1.0), ('arg', 0.7109199508163212), ('closing', 0.681452966309991), ('boot', 0.6748180817664837), ('link', 0.6699609077857631)]
Top words for pretrained_BERT neuron indx 2664 [('put', 1.0), ('target', 0.7240896181951096), ('ranges', 0.6554865488558024), ('us', 0.652796557571332), ('upper', 0.6366910553484106)]
Top words for pretrained_BERT neuron indx 617 [('resource', 1.0), ('Node', 0.9713219660585424), ('query', 0.926995046370354), ('val', 0.880715164757916), ('context', 0.8350653967575167)]
Top words for pretrained_BERT neuron indx 4718 [('Session', 1.0), ('slug', 0.846460347255012), ('stanza', 0.8440956145700934), ('affinity', 0.7984114346489724), ('utc', 0.7328811366728547)]
Top words for pretrained_BERT neuron indx 6772 [('""', 1.0), ('find', 0.9440125533324709), ('request', 0.8982615549863542), ('bool', 0.8552991018988317), ('pid', 0.8417941758544407)]
Top words for pretrained_BERT neuron indx 8828 [('9', 1.0), ('1000', 0.9924956499393953), ('600', 0.9340694741171977), ('14', 0.8979540607483457), ('close', 0.8338907030658658)]
Top words for pretrained_BERT neuron indx 8839 [('close', 1.0), ('24', 0.8521701890731642), ('postinfo', 0.7911982103509309), ('blocking', 0.7152008961218063), ('val', 0.6888527849807742)]
Top words for pretrained_BERT neuron indx 8841 [('contents', 1.0), ('Authorization', 0.9657745215359168), ('models', 0.8820778459412492), ('authorization', 0.8659631208597939), ('i', 0.8635207032451646)]
Top words for pretrained_BERT neuron indx 4751 [('patch', 1.0), ('long', 0.978331728899521), ('Unauthorized', 0.9521693254085305), ('authentication', 0.9200402284762453), ('local', 0.9072375902730477)]
Top words for pretrained_BERT neuron indx 4755 [('E', 1.0), ('15', 0.9544986020145847), ('80', 0.9215102530506099), ('Unauthorized', 0.9106750885008263), ('24', 0.9057738201827482)]
Top words for pretrained_BERT neuron indx 669 [('Board', 1.0), ('board', 0.9802112484554407), ('boardname', 0.9607358418477064), ('print', 0.8771902618341131), ('patch', 0.8623578672322809)]
Top words for pretrained_BERT neuron indx 4773 [('False', 1.0), ('wait', 0.8930436387620568), ('child', 0.8750174454949818), ('group', 0.8460187451803732), ('reactor', 0.8279579956473131)]
Top words for pretrained_BERT neuron indx 6821 [('if', 1.0), ('META', 0.8364138360994636), ('60', 0.7139693668671517), ('400', 0.6892424116457189), ('description', 0.6773621633066376)]
Top words for pretrained_BERT neuron indx 680 [('1800', 1.0), ('routes', 0.7872399675028295), ('id', 0.7655237293929267), ('sans', 0.7629517094882129), ('probe', 0.7544134244976367)]
Top words for pretrained_BERT neuron indx 2728 [('host', 1.0), ('port', 0.9499903185543038), ('connection', 0.8905041601375355), ('field', 0.850204044497681), ('"Resource"', 0.7895133097264248)]
Top words for pretrained_BERT neuron indx 690 [('if', 1.0), ('Mesh', 0.9536254614069292), ('mesh', 0.9536254614069292), ('action', 0.9210094465244125), ('authorization', 0.9168126540226126)]
Top words for pretrained_BERT neuron indx 2740 [('open', 1.0), ('link', 0.998521955607184), ('core', 0.92071450225468), ('utc', 0.8446753788144804), ('dict', 0.8170353988383081)]
Top words for pretrained_BERT neuron indx 2742 [('root', 1.0), ('description', 0.9383683561220107), ('route', 0.877848238673668), ('sorted', 0.8260225130811681), ('Tab', 0.8155976779116982)]
Top words for pretrained_BERT neuron indx 4796 [('1000', 1.0), ('connection', 0.9828867291319915), ('View', 0.9342024408168161), ('description', 0.8696387321837676), ('False', 0.7753428069868068)]
Top words for pretrained_BERT neuron indx 708 [('StringIO', 1.0), ('List', 0.9734390466114741), ('models', 0.9548785012142205), ('blocking', 0.8766628686543889), ('def', 0.8693788302305634)]
Top words for pretrained_BERT neuron indx 709 [('authorized', 1.0), ('authentication', 0.9658578263469996), ('Unauthorized', 0.9604227096935616), ('match', 0.9039536837422516), ('direct', 0.8823692928075134)]
Top words for pretrained_BERT neuron indx 6854 [('20', 1.0), ('60', 0.9647065244351218), ('40', 0.9529356663192206), ('600', 0.9312851722741832), ('1800', 0.9107618226208767)]
Top words for pretrained_BERT neuron indx 4818 [('main', 1.0), ('script', 0.8211816826236782), ('task', 0.7768919401180182), ('Distance', 0.7762112099142595), ('with', 0.7446035410017912)]
Top words for pretrained_BERT neuron indx 6868 [('route', 1.0), ('iq', 0.7925760636305252), ('sorted', 0.719412304353955), ('filter', 0.7117903409710505), ('long', 0.7083335635021422)]
Top words for pretrained_BERT neuron indx 8917 [('us', 1.0), ('stanza', 0.955075848840958), ('choices', 0.9317197633993876), ('int', 0.9246181287629698), ('86400', 0.9154468382029186)]
Top words for pretrained_BERT neuron indx 726 [('close', 1.0), ('count', 0.8791521873617467), ('Exception', 0.7834592030859813), ('def', 0.7362281642699198), ('reactor', 0.7083748666802511)]
Top words for pretrained_BERT neuron indx 731 [('servers', 1.0), ('feature', 0.9908713982528404), ('List', 0.9260538265862631), ('script', 0.8598964548386752), ('choices', 0.851441905837084)]
Top words for pretrained_BERT neuron indx 736 [('alt', 1.0), ('calendar', 0.9856673540306606), ('proxy', 0.9448489694239757), ('Mesh', 0.9419689537058682), ('mesh', 0.9419689537058682)]
Top words for pretrained_BERT neuron indx 737 [('horizon', 1.0), ('con', 0.8385640941347453), ('proxy', 0.828903300735732), ('800', 0.8067250813214047), ('hour', 0.7926743201953609)]
Top words for pretrained_BERT neuron indx 4842 [('eg', 1.0), ('description', 0.998352671389238), ('i', 0.9746046270643741), ('contents', 0.8852721443766441), ('Off', 0.8815981857562633)]
Top words for pretrained_BERT neuron indx 8939 [('features', 1.0), ('import', 0.7278481499362893), ('argv', 0.6927164561153549), ('TabGroup', 0.6815779577222268), ('seek', 0.6673365710733785)]
Top words for pretrained_BERT neuron indx 4845 [('broadcast', 1.0), ('while', 0.942400477413195), ('domain', 0.8805327770780617), ('post', 0.7570403238194102), ('unicode', 0.7240252586814862)]
Top words for pretrained_BERT neuron indx 6894 [('List', 1.0), ('GetBoard', 0.9807703377489184), ('Mesh', 0.8598507730306361), ('__repr__', 0.8565025946331487), ('24', 0.8471171220645379)]
Top words for pretrained_BERT neuron indx 752 [('slug', 1.0), ('re', 0.9930972467413378), ('exceptions', 0.8605749862642058), ('EffectiveId', 0.8011582084189749), ('direct', 0.7738850881001212)]
Top words for pretrained_BERT neuron indx 4851 [('blocking', 1.0), ('seconds', 0.9028316777421403), ('stat', 0.8635238156388654), ('affinity', 0.8483429637037246), ('16', 0.813569608138552)]
Top words for pretrained_BERT neuron indx 6906 [('Stretch', 1.0), ('Session', 0.9145735744113326), ('authJID', 0.8030965479850641), ('fileno', 0.784695509493727), ('material', 0.7587314657873531)]
Top words for pretrained_BERT neuron indx 6912 [('domain', 1.0), ('600', 0.9952355748112014), ('strip', 0.8794161345966955), ('broadcast', 0.8678156389982727), ('split', 0.825958383783089)]
Top words for pretrained_BERT neuron indx 2821 [('1000', 1.0), ('resource', 0.9344141877052475), ('fcs', 0.8714388540592706), ('60', 0.8487281374668127), ('20000', 0.8354959485165585)]
Top words for pretrained_BERT neuron indx 8965 [('utc', 1.0), ('tz', 0.8524944813344579), ('VerticalBillboard', 0.790321764856191), ('HorizontalBillboard', 0.7603354474645903), ('9', 0.7304238857110718)]
Top words for pretrained_BERT neuron indx 2823 [('f', 1.0), ('uss', 0.9791190512921155), ('created', 0.9300544331974421), ('filters', 0.9211110440264146), ('open', 0.845954903746631)]
Top words for pretrained_BERT neuron indx 2824 [('pop', 1.0), ('con', 0.9116613992961348), ('128', 0.9046961386343396), ('re', 0.8219688002335634), ('60', 0.8042205568481453)]
Top words for pretrained_BERT neuron indx 8968 [('pop', 1.0), ('80', 0.9422441397759144), ('400', 0.8908083879351821), ('"oslo"', 0.8724465914584806), ('600', 0.8723871932584267)]
Top words for pretrained_BERT neuron indx 6923 [('17', 1.0), ('14', 0.9099269281960366), ('9', 0.9074518509945446), ('16', 0.7815800133623025), ('20', 0.753663848658772)]
Top words for pretrained_BERT neuron indx 8975 [('con', 1.0), ('80', 0.9400059901173475), ('field', 0.9041425629419273), ('60', 0.8829382069304431), ('exceptions', 0.7991960077915485)]
Top words for pretrained_BERT neuron indx 2838 [('k', 1.0), ('print', 0.966084997270434), ('clone', 0.9441724867634029), ('open', 0.8853713938233622), ('ref', 0.8317202831695633)]
Top words for pretrained_BERT neuron indx 6940 [('us', 1.0), ('to', 0.9433083564715377), ('loads', 0.7819259022538826), ('host', 0.740910836300361), ('common', 0.7386931068941944)]
Top words for pretrained_BERT neuron indx 4892 [('View', 1.0), ('sorted', 0.8639696682468831), ('if', 0.8626339367334765), ('boot', 0.8378191096923842), ('url', 0.8227593067792948)]
Top words for pretrained_BERT neuron indx 8990 [('materials', 1.0), ('long', 0.783060481799405), ('pop', 0.7341694441890084), ('unicode', 0.7334342290234886), ('Distance', 0.7278098770585006)]
Top words for pretrained_BERT neuron indx 799 [('Component', 1.0), ('local', 0.9394075863860848), ('objects', 0.9275429218769466), ('Node', 0.897473900934766), ('i', 0.8815525949015337)]
Top words for pretrained_BERT neuron indx 4898 [('objects', 1.0), ('link', 0.9816501163692785), ('probe', 0.956900698215671), ('features', 0.9377753297129557), ('body', 0.9212659425911559)]
Top words for pretrained_BERT neuron indx 808 [('upper', 1.0), ('body', 0.7874886988137666), ('if', 0.7591699770297311), ('materials', 0.7367499141575002), ('second', 0.7216870926709957)]
Top words for pretrained_BERT neuron indx 812 [('bool', 1.0), ('user', 0.9219141506538829), ('post', 0.8918856009936014), ('part', 0.8487313327649941), ('mesh', 0.835712372065399)]
Top words for pretrained_BERT neuron indx 6957 [('description', 1.0), ('calendar', 0.9755028347322346), ('url', 0.9359986014501664), ('Digest', 0.8684406889283242), ('stat', 0.8550939625217442)]
Top words for pretrained_BERT neuron indx 4915 [('loads', 1.0), ('""', 0.7784796910043695), ('"Host"', 0.7626331810856247), ('"r"', 0.7440556799770639), ('"Name"', 0.7430655973845987)]
Top words for pretrained_BERT neuron indx 819 [('choices', 1.0), ('title', 0.9903697050980806), ('strip', 0.9110749746589415), ('logging', 0.8076000347658422), ('log', 0.7873185747956196)]
Top words for pretrained_BERT neuron indx 4919 [('future', 1.0), ('minutes', 0.9146059304520727), ('firstitem', 0.856686769026262), ('purpose', 0.8555136504283911), ('token', 0.8500562717127825)]
Top words for pretrained_BERT neuron indx 4920 [('Simple', 1.0), ('Register', 0.7791606160811833), ('sans', 0.7676600376217236), ('year', 0.7015523101295673), ('child', 0.6692025036025778)]
Top words for pretrained_BERT neuron indx 4923 [('sorted', 1.0), ('with', 0.9549997881958846), ('profile', 0.9128681617013985), ('long', 0.7340299963710539), ('identity', 0.7096402989927194)]
Top words for pretrained_BERT neuron indx 4928 [('find', 1.0), ('close', 0.9701159970239596), ('View', 0.8108380497660098), ('seek', 0.7410335187645802), ('zone', 0.7263335725994584)]
Top words for pretrained_BERT neuron indx 9024 [('count', 1.0), ('def', 0.9969328680906467), ('slug', 0.9932692609954968), ('vCard', 0.871638460433481), ('enclosure', 0.8602784731349407)]
Top words for pretrained_BERT neuron indx 2882 [('settings', 1.0), ('stanza', 0.9963812520611758), ('startswith', 0.9693306150797287), ('help', 0.9627133077942758), ('wait', 0.9564712452554268)]
Top words for pretrained_BERT neuron indx 6980 [('time', 1.0), ('action', 0.8506124929459432), ('sanetime', 0.8348309486736004), ('minutes', 0.8215912337064881), ('class', 0.7892803962955932)]
Top words for pretrained_BERT neuron indx 6989 [('".."', 1.0), ('postinfo', 0.9220114308526531), ('to', 0.8232598794704665), ('Simple', 0.7961988706346306), ('9', 0.7654214787942787)]
Top words for pretrained_BERT neuron indx 4945 [('port', 1.0), ('choices', 0.8616098849034998), ('iq', 0.7455353904762199), ('replace', 0.7169584171839167), ('core', 0.6592963997234474)]
Top words for pretrained_BERT neuron indx 2897 [('bind', 1.0), ('ping', 0.9402849107813365), ('Off', 0.8738402402919252), ('sans', 0.8281362786708646), ('upper', 0.7491216853243405)]
Top words for pretrained_BERT neuron indx 2903 [('host', 1.0), ('On', 0.9313405183213765), ('pop', 0.9151730092051096), ('types', 0.8086678643790104), ('type', 0.7989187152413183)]
Top words for pretrained_BERT neuron indx 9053 [('E', 1.0), ('k', 0.9709519939725144), ('def', 0.9311997394231117), ('with', 0.8995965664388812), ('con', 0.8365270891390105)]
Top words for pretrained_BERT neuron indx 9054 [('re', 1.0), ('f', 0.945222113011205), ('server', 0.8258477186805061), ('created', 0.739544778680295), ('end', 0.6306994777643175)]
Top words for pretrained_BERT neuron indx 2911 [('settings', 1.0), ('seconds', 0.8761245728245051), ('us', 0.8627158920700017), ('tastypie', 0.782539782633828), ('CONF', 0.7387786740173046)]
Top words for pretrained_BERT neuron indx 2912 [('Log', 1.0), ('return', 0.9031489803309712), ('line', 0.896382616603161), ('open', 0.8484673752758233), ('key', 0.8182925701148047)]
Top words for pretrained_BERT neuron indx 7013 [('patch', 1.0), ('alt', 0.879681834764419), ('replace', 0.8333696530613665), ('add', 0.79864221283125), ('route', 0.7799363011245273)]
Top words for pretrained_BERT neuron indx 2917 [('ref', 1.0), ('Billboard', 0.9958096744845197), ('def', 0.9715004865757056), ('Log', 0.903427094036525), ('re', 0.861677598160509)]
Top words for pretrained_BERT neuron indx 4967 [('9', 1.0), ('field', 0.9990081916381214), ('materials', 0.9730515569692141), ('material', 0.9525989504505393), ('E', 0.9426762665386104)]
Top words for pretrained_BERT neuron indx 7020 [('k', 1.0), ('mins', 0.8955332069871951), ('authentication', 0.844894385659493), ('"view"', 0.8231093968972589), ('"Name"', 0.8168803941260402)]
Top words for pretrained_BERT neuron indx 2935 [('ref', 1.0), ('force', 0.9237098859762548), ('blocking', 0.8588238273060995), ('parts', 0.7809108908357215), ('Log', 0.7175383458901005)]
Top words for pretrained_BERT neuron indx 7034 [('"purpose"', 1.0), ('to', 0.8740032985010451), ('Tab', 0.7998955664151802), ('logging', 0.7592849844196933), ('choices', 0.7184139351748123)]
Top words for pretrained_BERT neuron indx 2941 [('reactor', 1.0), ('300', 0.9744757022779446), ('30', 0.8728981896845545), ('400', 0.8025758554138466), ('continue', 0.791159910558121)]
Top words for pretrained_BERT neuron indx 895 [('other', 1.0), ('required', 0.8096312404347129), ('part', 0.7318627264120339), ('1024', 0.7259131469984933), ('with', 0.6981609087588162)]
Top words for pretrained_BERT neuron indx 911 [('body', 1.0), ('reactor', 0.9874034753368888), ('patch', 0.9294312229963154), ('format', 0.8799844541893816), ('broadcast', 0.8424902479798018)]
Top words for pretrained_BERT neuron indx 7058 [('post', 1.0), ('server', 0.8255450995961986), ('servers', 0.8168764741835655), ('iq', 0.7097705927409715), ('route', 0.7078641547185158)]
Top words for pretrained_BERT neuron indx 2967 [('context', 1.0), ('field', 0.8628741476193988), ('split', 0.7619852162088646), ('pop', 0.7481966460350638), ('enclosure', 0.7345205490550524)]
Top words for pretrained_BERT neuron indx 7073 [('False', 1.0), ('profile', 0.6075654641885074), ('Post', 0.5870952236747353), ('Unauthorized', 0.5252963147187288), ('Simple', 0.5061173530784103)]
Top words for pretrained_BERT neuron indx 9125 [('META', 1.0), ('if', 0.922365242972411), ('400', 0.8435460410415712), ('with', 0.8053562607030222), ('14', 0.7324594624060244)]
Top words for pretrained_BERT neuron indx 9129 [('enclosure', 1.0), ('META', 0.8552821666369069), ('token', 0.8231404951286918), ('Post', 0.6701883528788806), ('routes', 0.6648709465259542)]
Top words for pretrained_BERT neuron indx 2987 [('split', 1.0), ('host', 0.9807320871090418), ('query', 0.9440926231499968), ('port', 0.9248088831682469), ('Exception', 0.9197956521599865)]
Top words for pretrained_BERT neuron indx 2994 [('30', 1.0), ('if', 0.9193871581385921), ('context', 0.8181678979456317), ('roster', 0.8133833697675406), ('Mesh', 0.7968804773050128)]
Top words for pretrained_BERT neuron indx 7100 [('connection', 1.0), ('View', 0.9841571942635065), ('1000', 0.9820910334475228), ('description', 0.9466756669793142), ('False', 0.9170484781169551)]
Top words for pretrained_BERT neuron indx 3005 [('other', 1.0), ('Node', 0.9942738029187748), ('None', 0.8434357468215545), ('enabled', 0.8038243290005034), ('v', 0.7504785692119912)]
Top words for pretrained_BERT neuron indx 3006 [('utc', 1.0), ('year', 0.970439204405385), ('cfg', 0.883882018619397), ('bare', 0.8803662237397197), ('token', 0.8587141564749076)]
Top words for pretrained_BERT neuron indx 7105 [('oslo', 1.0), ('with', 0.7911076304283546), ('ignore', 0.7790841253481927), ('600', 0.768835225104443), ('baseline', 0.7370531897816184)]
Top words for pretrained_BERT neuron indx 963 [('error', 1.0), ('match', 0.9970813537902151), ('sts', 0.8983817370604602), ('max', 0.8862474688433044), ('MAXBOARD', 0.8805253886989516)]
Top words for pretrained_BERT neuron indx 5061 [('bind', 1.0), ('direct', 0.9490830527147424), ('objects', 0.9234006618094267), ('filters', 0.9198169314130586), ('strip', 0.9192678943231752)]
Top words for pretrained_BERT neuron indx 971 [('400', 1.0), ('hour', 0.9064872991727716), ('v', 0.8571373950490694), ('repr', 0.8199938592824385), ('Post', 0.7986519082112127)]
Top words for pretrained_BERT neuron indx 7121 [('millis', 1.0), ('closing', 0.9634527994841642), ('core', 0.9500216210960488), ('400', 0.8774523952080486), ('choices', 0.8670868707493437)]
Top words for pretrained_BERT neuron indx 9172 [('Distance', 1.0), ('Simple', 0.9913347649970291), ('REQUEST', 0.9486699552705633), ('""', 0.932429746432654), ('route', 0.9206657236185299)]
Top words for pretrained_BERT neuron indx 981 [('line', 1.0), ('purpose', 0.9791896649442093), ('replace', 0.9632094876628797), ('st', 0.9563617586415947), ('val', 0.9032261918800517)]
Top words for pretrained_BERT neuron indx 980 [('stat', 1.0), ('ranges', 0.9214993946344203), ('break', 0.9190424908010375), ('write', 0.9129757614767693), ('component', 0.8502385101572112)]
Top words for pretrained_BERT neuron indx 9175 [('upper', 1.0), ('REQUEST', 0.9797204721215089), ('15', 0.9643580314527535), ('to', 0.8733204811786338), ('core', 0.7516562863523278)]
Top words for pretrained_BERT neuron indx 5082 [('Tab', 1.0), ('import', 0.938740829787761), ('parts', 0.8319909032142639), ('32', 0.7697210047476686), ('entity', 0.7661724621335647)]
Top words for pretrained_BERT neuron indx 7131 [('error', 1.0), ('600', 0.8682859788240979), ('tz', 0.8073944632396345), ('to', 0.7876099184754367), ('created', 0.7589085808488089)]
Top words for pretrained_BERT neuron indx 995 [('if', 1.0), ('scope', 0.9215193681913103), ('state', 0.8843294770015806), ('from', 0.8721008531082046), ('while', 0.856613520047422)]
Top words for pretrained_BERT neuron indx 9187 [('enclosure', 1.0), ('1024', 0.9789761777325368), ('Board', 0.9379777231048108), ('other', 0.8783251078462008), ('Tab', 0.8723579456609926)]
Top words for pretrained_BERT neuron indx 3048 [('False', 1.0), ('REQUEST', 0.9956832832989556), ('type', 0.8335152920411659), ('uri', 0.8004122146993659), ('probe', 0.7749667638529081)]
Top words for pretrained_BERT neuron indx 1000 [('contents', 1.0), ('zone', 0.9828626529527854), ('settings', 0.9011733142933838), ('mesh', 0.8621199060360567), ('authorized', 0.8443008887563217)]
Top words for pretrained_BERT neuron indx 9197 [('17', 1.0), ('1800', 0.9662944144842528), ('requests', 0.9591765999548995), ('repr', 0.909601916794758), ('save', 0.9042856588333863)]
Top words for pretrained_BERT neuron indx 7155 [('route', 1.0), ('ignore', 0.9760076268969726), ('created', 0.8893813731071333), ('REQUEST', 0.852037220551804), ('minutes', 0.8215770320700173)]
Top words for pretrained_BERT neuron indx 1011 [('Component', 1.0), ('presence', 0.8949851331957569), ('component', 0.8608805467496048), ('main', 0.8523507757782327), ('unicode', 0.8069771485178447)]
Top words for pretrained_BERT neuron indx 1020 [('sts', 1.0), ('profile', 0.986790453704272), ('Profile', 0.93945274121737), ('ms', 0.8451039092247035), ('800', 0.8402901814790594)]
Top words for pretrained_BERT neuron indx 9219 [('if', 1.0), ('while', 0.8681530809882416), ('arg', 0.7371427687164088), ('hasattr', 0.7230092404610226), ('seek', 0.7026397968165862)]
Top words for pretrained_BERT neuron indx 5125 [('models', 1.0), ('15', 0.811867477146786), ('9', 0.7650398603587104), ('1000', 0.7424242043444929), ('oslo', 0.7422564166894682)]
Top words for pretrained_BERT neuron indx 9225 [('bool', 1.0), ('128', 0.8715388109676728), ('32', 0.8551120988010533), ('17', 0.8004137871059273), ('16', 0.7757500958683198)]
Top words for pretrained_BERT neuron indx 5130 [('register', 1.0), ('year', 0.9873602871524759), ('Register', 0.942985284841745), ('time', 0.8979111538689756), ('pop', 0.8714872421292568)]
Top words for pretrained_BERT neuron indx 7180 [('E', 1.0), ('Board', 0.8158187627555742), ('calendar', 0.7477356584759028), ('800', 0.6024782659841601), ('timedelta', 0.585317991340696)]
Top words for pretrained_BERT neuron indx 5136 [('types', 1.0), ('pop', 0.9081336322391563), ('Exception', 0.8913405679446691), ('400', 0.8616003941956653), ('log', 0.8583534655398037)]
Top words for pretrained_BERT neuron indx 1043 [('class', 1.0), ('routes', 0.963497707582242), ('con', 0.8838125276013522), ('egroup', 0.8530959603664656), ('user', 0.8400914718847609)]
Top words for pretrained_BERT neuron indx 7191 [('session', 1.0), ('alt', 0.9938691655885088), ('replace', 0.9863204544405687), ('Session', 0.9369603692186002), ('ref', 0.9256651647033013)]
Top words for pretrained_BERT neuron indx 5143 [('token', 1.0), ('item', 0.9786552032924352), ('3600', 0.9619692967277885), ('Register', 0.8900539090853964), ('encode', 0.8837868455092456)]
Top words for pretrained_BERT neuron indx 7195 [('bare', 1.0), ('Off', 0.9472982658474155), ('_closed', 0.8585719853711877), ('choices', 0.8412121295439314), ('recv_close', 0.787979569005139)]
Top words for pretrained_BERT neuron indx 5148 [('80', 1.0), ('60', 0.9268470674176581), ('local', 0.8758738380666777), ('error', 0.8128938152674696), ('40', 0.7699805690960209)]
Top words for pretrained_BERT neuron indx 3101 [('sans', 1.0), ('session', 0.9609820712697513), ('refresh', 0.8264395553833336), ('32', 0.7933416114470644), ('utcnow', 0.786886214798243)]
Top words for pretrained_BERT neuron indx 9254 [('identity', 1.0), ('f', 0.8753449838268877), ('error', 0.8658168295343716), ('make_boot_settings_dict', 0.8216323794335783), ('board', 0.8156809981232671)]
Top words for pretrained_BERT neuron indx 3117 [('calendar', 1.0), ('state', 0.9489106355587712), ('digest', 0.8198092423742456), ('k', 0.7426670069844808), ('child', 0.7078874246296883)]
Top words for pretrained_BERT neuron indx 7213 [('match', 1.0), ('alt', 0.9208274282178448), ('stat', 0.7709181552361447), ('k', 0.6937500239427388), ('partition', 0.6623203678918113)]
Top words for pretrained_BERT neuron indx 1071 [('REQUEST', 1.0), ('requests', 0.9712679485744792), ('required', 0.945440358081743), ('request', 0.8562976633602336), ('route', 0.8417449743074193)]
Top words for pretrained_BERT neuron indx 5165 [('millis', 1.0), ('topid', 0.8488238617475468), ('str', 0.8462847865121539), ('Plugin', 0.7710438943477355), ('elem', 0.7629730119918972)]
Top words for pretrained_BERT neuron indx 9265 [('authorization', 1.0), ('Distance', 0.9918628635498364), ('msgbox', 0.9823991760514801), ('seek', 0.9523217298468423), ('affinity', 0.9180216865556605)]
Top words for pretrained_BERT neuron indx 1073 [('identity', 1.0), ('replace', 0.8940099659244526), ('error', 0.8475207241775755), ('domain', 0.8023791969505273), ('split', 0.7975872667007181)]
Top words for pretrained_BERT neuron indx 1075 [('loads', 1.0), ('close', 0.868006488327786), ('k', 0.7368122076495747), ('push', 0.693422450759868), ('find', 0.6692658061876596)]
Top words for pretrained_BERT neuron indx 1076 [('".."', 1.0), ('to', 0.9925258721576068), ('as', 0.8349396712205293), ('with', 0.8265402212874843), ('from', 0.7570611643495766)]
Top words for pretrained_BERT neuron indx 3121 [('core', 1.0), ('required', 0.9537680789168275), ('Authorization', 0.7786646993720769), ('Distance', 0.72640568701896), ('count', 0.7230862510666782)]
Top words for pretrained_BERT neuron indx 7223 [('force', 1.0), ('enclosure', 0.9544083607328353), ('tz', 0.848644985293065), ('action', 0.8023578003607569), ('blocking', 0.6744419897184203)]
Top words for pretrained_BERT neuron indx 1083 [('session', 1.0), ('routes', 0.955480677506111), ('Session', 0.8834065121160067), ('types', 0.7983528120001656), ('direct', 0.7612538518669356)]
Top words for pretrained_BERT neuron indx 3133 [('builtins', 1.0), ('add', 0.9437592776796109), ('enabled', 0.9311115418919118), ('View', 0.8977614881791998), ('def', 0.8805812983675934)]
Top words for pretrained_BERT neuron indx 5187 [('local', 1.0), ('id', 0.8546177806583398), ('field', 0.7949487375280334), ('modes', 0.7838402648956251), ('target', 0.7705946245139338)]
Top words for pretrained_BERT neuron indx 7248 [('""', 1.0), ('title', 0.9183005569855738), ('MAXSIGLINES', 0.8287518600201124), ('datastore_owner_uuid', 0.7314934956503669), ('second', 0.7239198895676837)]
Top words for pretrained_BERT neuron indx 3153 [('sans', 1.0), ('session', 0.7620590332766435), ('Session', 0.7528026236359391), ('Library', 0.7374627609225801), ('sts', 0.7192429154395199)]
Top words for pretrained_BERT neuron indx 7259 [('__title__', 1.0), ('enclosure', 0.964148608807411), ('baseline', 0.9630588215614746), ('Tab', 0.9099074420709632), ('token', 0.893587154278489)]
Top words for pretrained_BERT neuron indx 7268 [('script', 1.0), ('core', 0.945962040920204), ('local', 0.9181960775262825), ('action', 0.898723707947694), ('purpose', 0.8795601515831324)]
Top words for pretrained_BERT neuron indx 9317 [('patch', 1.0), ('alt', 0.9117966083980037), ('repr', 0.7824694938726451), ('On', 0.7015591439993729), ('split', 0.6910031094039873)]
Top words for pretrained_BERT neuron indx 1125 [('boot', 1.0), ('contents', 0.8327085838592141), ('part', 0.821841162906614), ('v', 0.7748545465161357), ('body', 0.7229307546107853)]
Top words for pretrained_BERT neuron indx 3174 [('second', 1.0), ('seconds', 0.9736655282356372), ('count', 0.8896775125684969), ('Distance', 0.7985897389901838), ('state', 0.7737604256520566)]
Top words for pretrained_BERT neuron indx 5239 [('Authorization', 1.0), ('Board', 0.9695941588327167), ('title', 0.8641604361278216), ('text', 0.8442424476367502), ('parts', 0.828166291547648)]
Top words for pretrained_BERT neuron indx 9340 [('"happy_birthday"', 1.0), ('unicode', 0.986617564360964), ('core', 0.8480327332585655), ('choices', 0.8169210994303556), ('"view"', 0.8062082341284426)]
Top words for pretrained_BERT neuron indx 5245 [('300', 1.0), ('30', 0.9844615894196906), ('17', 0.8376771321640951), ('32', 0.7800037869368222), ('400', 0.7422766610154975)]
Top words for pretrained_BERT neuron indx 1154 [('dict', 1.0), ('import', 0.9414035776685248), ('16', 0.9408605232977236), ('connection', 0.9104879201998387), ('14', 0.8439190647563704)]
Top words for pretrained_BERT neuron indx 7302 [('"purpose"', 1.0), ('"r"', 0.9584210353421322), ('info', 0.8025921551380507), ('"gbk"', 0.766984649267961), ('600', 0.7643306062972861)]
Top words for pretrained_BERT neuron indx 7305 [('contents', 1.0), ('with', 0.9238085366407878), ('LoadUser', 0.8479871895987297), ('write', 0.8006210879774266), ('user', 0.7772833876484019)]
Top words for pretrained_BERT neuron indx 1165 [('while', 1.0), ('utc', 0.9570875693613752), ('dateutil', 0.9290198415725696), ('send', 0.9231577936064016), ('Simple', 0.9226764713361523)]
Top words for pretrained_BERT neuron indx 3215 [('minutes', 1.0), ('Unauthorized', 0.9984610507405262), ('authentication', 0.9284778526682832), ('patch', 0.9058930694294086), ('blocking', 0.8501084812544918)]
Top words for pretrained_BERT neuron indx 7326 [('"oslo"', 1.0), ('"Port"', 0.9476677066049374), ('"list"', 0.8922683751004449), ('"Name"', 0.8859303088219254), ('exceptions', 0.8855823630828584)]
Top words for pretrained_BERT neuron indx 1183 [('local', 1.0), ('month', 0.8321834259527935), ('exceptions', 0.8021211999794059), ('action', 0.7849332297598098), ('Post', 0.7838082032901827)]
Top words for pretrained_BERT neuron indx 1193 [('class', 1.0), ('Simple', 0.8579971179483934), ('sorted', 0.7657939314256594), ('Node', 0.7273245727877715), ('text', 0.7185831033699215)]
Top words for pretrained_BERT neuron indx 7337 [('as', 1.0), ('Node', 0.6919758878416283), ('created', 0.687166099619452), ('continue', 0.6855055763099537), ('long', 0.6639464495045907)]
Top words for pretrained_BERT neuron indx 7340 [('end', 1.0), ('ping', 0.8824903134953481), ('uss', 0.8823014355169474), ('int', 0.7699753140359491), ('port', 0.743512124526088)]
Top words for pretrained_BERT neuron indx 9388 [('start', 1.0), ('baseline', 0.8727243971820711), ('80', 0.7804132604896987), ('"\\\\n"', 0.7761848182042433), ('".."', 0.7747794298286096)]
Top words for pretrained_BERT neuron indx 1197 [('open', 1.0), ('14', 0.968705316953187), ('20', 0.9638647584518245), ('128', 0.947741776002502), ('17', 0.8885376560753745)]
Top words for pretrained_BERT neuron indx 1204 [('exceptions', 1.0), ('core', 0.9498693057078563), ('strip', 0.9287177880908097), ('Exception', 0.8634362919891266), ('unicode', 0.8528261940752531)]
Top words for pretrained_BERT neuron indx 3253 [('domain', 1.0), ('from', 0.9939339079898218), ('types', 0.9913823113843155), ('settings', 0.9188750660679235), ('None', 0.8789041995794377)]
Top words for pretrained_BERT neuron indx 5311 [('iq', 1.0), ('ms', 0.9934134904002321), ('hpov', 0.9176510080648289), ('enum', 0.9113393758793518), ('sts', 0.9068786676822033)]
Top words for pretrained_BERT neuron indx 5313 [('key', 1.0), ('associatedLIGs', 0.9803251759133819), ('continue', 0.9004492871927304), ('pass', 0.845713208418858), ('operand', 0.8455020665918572)]
Top words for pretrained_BERT neuron indx 3267 [('clone', 1.0), ('match', 0.9941938867517756), ('part', 0.9472465695160678), ('Exception', 0.9289407615409558), ('Board', 0.9269304323078333)]
Top words for pretrained_BERT neuron indx 5318 [('scope', 1.0), ('domain', 0.9529554291800321), ('body', 0.9389326338737504), ('parser', 0.9379856686154684), ('board', 0.9304319836396641)]
Top words for pretrained_BERT neuron indx 9415 [('component', 1.0), ('oslo', 0.6830425169800283), ('Component', 0.6670829386975903), ('exceptions', 0.6563528620655553), ('i', 0.5957631233979905)]
Top words for pretrained_BERT neuron indx 7367 [('main', 1.0), ('group', 0.9447109795590941), ('Mesh', 0.8936510677514957), ('models', 0.8776061121059038), ('future', 0.8685406987300173)]
Top words for pretrained_BERT neuron indx 3278 [('main', 1.0), ('sans', 0.9473121598287197), ('loads', 0.9408327557001119), ('reactor', 0.9320552728342856), ('ping', 0.9112532350878344)]
Top words for pretrained_BERT neuron indx 3284 [('wait', 1.0), ('future', 0.9965112373638885), ('elem', 0.9927769887874555), ('List', 0.9766683277366235), ('key', 0.9594092092039177)]
Top words for pretrained_BERT neuron indx 7381 [('future', 1.0), ('stanza', 0.9003178408087518), ('us', 0.8681145214099577), ('int', 0.8487501313086696), ('log', 0.7441781743686321)]
Top words for pretrained_BERT neuron indx 1239 [('stat', 1.0), ('import', 0.6177890105426337), ('user', 0.6081956490652143), ('split', 0.5900376152550065), ('break', 0.5525382939875694)]
Top words for pretrained_BERT neuron indx 7386 [('parts', 1.0), ('purpose', 0.9895362464612191), ('time', 0.8154319513484499), ('32', 0.8116596030245149), ('error', 0.804909678980488)]
Top words for pretrained_BERT neuron indx 9441 [('Node', 1.0), ('17', 0.9087717634843874), ('presence', 0.9030964639244088), ('method', 0.8520988036914797), ('weakref', 0.8274411177154064)]
Top words for pretrained_BERT neuron indx 1265 [('common', 1.0), ('objects', 0.9198861865007344), ('hour', 0.8599283227449661), ('v', 0.8440906171074014), ('preload', 0.8415874081271159)]
Top words for pretrained_BERT neuron indx 3327 [('Session', 1.0), ('Distance', 0.9891843431259996), ('direct', 0.8214727529315637), ('Billboard', 0.7895448613844996), ('proxy', 0.7373691213094454)]
Top words for pretrained_BERT neuron indx 7429 [('core', 1.0), ('tz', 0.943392040733818), ('features', 0.933120500595934), ('models', 0.8989829447232015), ('year', 0.8744788646393609)]
Top words for pretrained_BERT neuron indx 5381 [('Node', 1.0), ('from', 0.9611336282825934), ('REQUEST', 0.9461254719440105), ('authorization', 0.9053189219781431), ('authentication', 0.8832356139182537)]
Top words for pretrained_BERT neuron indx 1287 [('filters', 1.0), ('f', 0.8398400723551879), ('seconds', 0.8035792018158299), ('enabled', 0.7983312330331794), ('Digest', 0.7917975353328252)]
Top words for pretrained_BERT neuron indx 9480 [('save', 1.0), ('hpov', 0.888140046667956), ('read', 0.8542655966510352), ('debug', 0.7555553797516984), ('"!@#$%"', 0.7511679225702139)]
Top words for pretrained_BERT neuron indx 1289 [('other', 1.0), ('profile', 0.9074373396690565), ('us', 0.9042301159676515), ('Profile', 0.8124435417915453), ('models', 0.7624511050745655)]
Top words for pretrained_BERT neuron indx 5384 [('group', 1.0), ('type', 0.9703601234182687), ('Register', 0.8751148194753848), ('connection', 0.8675155279969353), ('exit', 0.8563223337672974)]
Top words for pretrained_BERT neuron indx 7432 [('pop', 1.0), ('"oslo"', 0.9090711312104564), ('40', 0.8837637755322058), ('con', 0.877603045720808), ('profile', 0.8564040967130745)]
Top words for pretrained_BERT neuron indx 5391 [('key', 1.0), ('as', 0.9419365390522458), ('context', 0.8827777004352307), ('break', 0.8811547775273234), ('us', 0.8589578248810179)]
Top words for pretrained_BERT neuron indx 7440 [('400', 1.0), ('128', 0.9736705480450127), ('600', 0.9045049626467513), ('pop', 0.8358212059710834), ('""', 0.7851280261579696)]
Top words for pretrained_BERT neuron indx 3345 [('9', 1.0), ('pass', 0.9391977725938746), ('enclosure', 0.8784369027014824), ('strip', 0.874470975995184), ('day', 0.8405081495974114)]
Top words for pretrained_BERT neuron indx 5396 [('REQUEST', 1.0), ('log', 0.9411885165883318), ('v', 0.9297742893257771), ('field', 0.9256285634782517), ('minutes', 0.8794184910949521)]
Top words for pretrained_BERT neuron indx 1302 [('k', 1.0), ('domain', 0.9840045177154148), ('clone', 0.933316427804261), ('ref', 0.8277381571537162), ('print', 0.8267814355133054)]
Top words for pretrained_BERT neuron indx 3351 [('second', 1.0), ('Session', 0.9637482996042769), ('session', 0.8573746655912958), ('minute', 0.8285533336593223), ('created', 0.8006666670594245)]
Top words for pretrained_BERT neuron indx 1304 [('probe', 1.0), ('resource', 0.9107968943434175), ('servers', 0.8131946612621574), ('int', 0.7769664824522869), ('loads', 0.7678992980551753)]
Top words for pretrained_BERT neuron indx 1303 [('seek', 1.0), ('server', 0.7684142538771799), ('logging', 0.7128273191193013), ('find', 0.689267220859052), ('user', 0.688313354290617)]
Top words for pretrained_BERT neuron indx 3356 [('sorted', 1.0), ('View', 0.973632521990314), ('""', 0.7606593605629973), ('port', 0.7368012671663013), ('identity', 0.7251661103983373)]
Top words for pretrained_BERT neuron indx 5404 [('requests', 1.0), ('loads', 0.9642519488515623), ('objects', 0.9293221932329382), ('host', 0.9175440842624502), ('View', 0.8924232709809478)]
Top words for pretrained_BERT neuron indx 5421 [('digest', 1.0), ('calendar', 0.9342507212681427), ('Digest', 0.8258405640275234), ('30', 0.8194684323243834), ('24', 0.786497064417521)]
Top words for pretrained_BERT neuron indx 3379 [('loads', 1.0), ('""', 0.6584053700506745), ('main', 0.6580721981422847), ('stat', 0.6433147183325884), ('"Host"', 0.621171736738377)]
Top words for pretrained_BERT neuron indx 1339 [('con', 1.0), ('datetime', 0.9274497134963604), ('part', 0.8802961805474687), ('routes', 0.8078372727679988), ('bind', 0.7821215183963846)]
Top words for pretrained_BERT neuron indx 3387 [('with', 1.0), ('sorted', 0.8784989098715614), ('start', 0.8534600643284991), ('end', 0.837055737557456), ('max', 0.8186067811013703)]
Top words for pretrained_BERT neuron indx 3392 [('print', 1.0), ('find', 0.9964502935284674), ('body', 0.8345015278528738), ('close', 0.8279207484894741), ('View', 0.8110949964959763)]
Top words for pretrained_BERT neuron indx 5444 [('action', 1.0), ('choices', 0.9395395828515989), ('SaneTime', 0.8538484420972094), ('9', 0.8471522996093355), ('sanetime', 0.8260781104197767)]
Top words for pretrained_BERT neuron indx 1348 [('id', 1.0), ('template', 0.842778865459998), ('powerRequest', 0.8206643286150326), ('timezone', 0.7424838293320545), ('month', 0.7348888454262534)]
Top words for pretrained_BERT neuron indx 3405 [('main', 1.0), ('types', 0.953849248002322), ('v', 0.8559267167948272), ('board', 0.8039082542861223), ('host', 0.764111504062597)]
Top words for pretrained_BERT neuron indx 5460 [('as', 1.0), ('with', 0.9562663072302161), ('while', 0.8191672529940452), ('return', 0.7969441127845132), ('import', 0.7836790110789223)]
Top words for pretrained_BERT neuron indx 1368 [('calendar', 1.0), ('connection', 0.9877030384036171), ('future', 0.963247991209488), ('Component', 0.9250942278269687), ('component', 0.8794078425955413)]
Top words for pretrained_BERT neuron indx 1370 [('bind', 1.0), ('minute', 0.9443335031271167), ('Stretch', 0.8296210828254941), ('put', 0.8112457485270741), ('blocking', 0.7723893231850977)]
Top words for pretrained_BERT neuron indx 1375 [('settings', 1.0), ('repr', 0.9598692202870578), ('operand', 0.8997312102895523), ('tastypie', 0.8733217014189518), ('prange', 0.835544240936575)]
Top words for pretrained_BERT neuron indx 1376 [('Log', 1.0), ('line', 0.8338608063628987), ('start', 0.8135424174856584), ('uss', 0.7877883943542865), ('xmlns', 0.7830974757380799)]
Top words for pretrained_BERT neuron indx 3427 [('400', 1.0), ('40', 0.7657911346931336), ('alt', 0.7590425278262874), ('60', 0.7556850315225284), ('proxy', 0.7499695984779379)]
Top words for pretrained_BERT neuron indx 5477 [('patch', 1.0), ('add', 0.9492799335171763), ('route', 0.9010499891659876), ('replace', 0.8657949011335939), ('send', 0.8573290348968585)]
Top words for pretrained_BERT neuron indx 3429 [('contents', 1.0), ('objects', 0.9824092161469907), ('arg', 0.9210566740773386), ('link', 0.8620730453084452), ('routes', 0.8283238315312459)]
Top words for pretrained_BERT neuron indx 7533 [('state', 1.0), ('materials', 0.9202151970599436), ('slug', 0.8645920190334959), ('uri', 0.8444173099353476), ('url', 0.8353447811395981)]
Top words for pretrained_BERT neuron indx 7540 [('find', 1.0), ('send', 0.9044621454576944), ('add', 0.8750071396722569), ('REQUEST', 0.8388563880259866), ('request', 0.8000520965762739)]
Top words for pretrained_BERT neuron indx 1401 [('common', 1.0), ('info', 0.7045288246147345), ('600', 0.6071830406421143), ('logging', 0.5709271891479), ('800', 0.5692457403430096)]
Top words for pretrained_BERT neuron indx 1403 [('add', 1.0), ('local', 0.859177937658174), ('List', 0.8247847080821984), ('ignore', 0.8112507534491656), ('def', 0.8093561893102545)]
Top words for pretrained_BERT neuron indx 1406 [('import', 1.0), ('endswith', 0.933899493290961), ('realpath', 0.9067190570226245), ('year', 0.8713566811076124), ('while', 0.8621280821289647)]
Top words for pretrained_BERT neuron indx 9602 [('20', 1.0), ('Distance', 0.8978765348347181), ('60', 0.8304808576753689), ('40', 0.7921823613482734), ('type', 0.7735911380677829)]
Top words for pretrained_BERT neuron indx 3458 [('import', 1.0), ('as', 0.8614705827658165), ('Library', 0.846223726745311), ('Plugin', 0.8003358278839755), ('Session', 0.7710490439991091)]
Top words for pretrained_BERT neuron indx 5519 [('patch', 1.0), ('Unauthorized', 0.8752964019345667), ('long', 0.8517491312077613), ('format', 0.8027134907441639), ('port', 0.7858748370777846)]
Top words for pretrained_BERT neuron indx 5523 [('calendar', 1.0), ('80', 0.9056777637111117), ('E', 0.8875900690899818), ('17', 0.8464949823328781), ('24', 0.8379563527187045)]
Top words for pretrained_BERT neuron indx 1437 [('core', 1.0), ('main', 0.767777467441797), ('"Resource"', 0.7244874902807201), ('entity', 0.6933482743801629), ('resource', 0.6834955736202684)]
Top words for pretrained_BERT neuron indx 9631 [('bind', 1.0), ('key', 0.8742953733549206), ('9', 0.8447853904984828), ('Util', 0.8397489185220375), ('exceptions', 0.7960802076113208)]
Top words for pretrained_BERT neuron indx 3488 [('80', 1.0), ('32', 0.8057951841936039), ('40', 0.8044115563949151), ('60', 0.789935320762386), ('20', 0.7275136413404155)]
Top words for pretrained_BERT neuron indx 7589 [('if', 1.0), ('META', 0.9879546847860783), ('400', 0.7837149677057309), ('E', 0.7459654143389295), ('60', 0.7035375528416616)]
Top words for pretrained_BERT neuron indx 1448 [('1800', 1.0), ('routes', 0.7683108479037545), ('link', 0.7262334674769495), ('unicode', 0.6214166518632886), ('rval', 0.6048720447193472)]
Top words for pretrained_BERT neuron indx 7603 [('Billboard', 1.0), ('choices', 0.9818162904129445), ('128', 0.8815813236578882), ('as', 0.8796828552378035), ('filters', 0.7935738829256308)]
Top words for pretrained_BERT neuron indx 7611 [('tzinfo', 1.0), ('add', 0.9909717414022543), ('day', 0.9555116079131925), ('save', 0.9346898275711767), ('"oslo"', 0.9160757240292939)]
Top words for pretrained_BERT neuron indx 1469 [('enabled', 1.0), ('description', 0.9864959100380271), ('sts', 0.9435994877255903), ('board', 0.8716856990211415), ('META', 0.83777534070953)]
Top words for pretrained_BERT neuron indx 1477 [('authentication', 1.0), ('match', 0.7591159307611589), ('direct', 0.7530029202023173), ('description', 0.7368420694312822), ('9', 0.7350531958832137)]
Top words for pretrained_BERT neuron indx 1485 [('uss', 1.0), ('join', 0.8884965486191797), ('message', 0.8360949342626741), ('connection', 0.8020157421793813), ('20', 0.768719073501816)]
Top words for pretrained_BERT neuron indx 7631 [('1000', 1.0), ('blocking', 0.8477279441739963), ('us', 0.8184095387950331), ('1800', 0.6507545138156862), ('E', 0.6231954959820452)]
Top words for pretrained_BERT neuron indx 1494 [('count', 1.0), ('close', 0.9892597441177561), ('wait', 0.7055529422413698), ('def', 0.6961106341879593), ('seek', 0.6684185287132078)]
Top words for pretrained_BERT neuron indx 5591 [('On', 1.0), ('to', 0.8413632573272015), ('"Host"', 0.757558580611187), ('return', 0.729724440055223), ('stanza', 0.7260410694069338)]
Top words for pretrained_BERT neuron indx 7641 [('core', 1.0), ('IsBM', 0.947622925690562), ('message', 0.9088200324680027), ('routes', 0.8954995665023568), ('requests', 0.8639381067578942)]
Top words for pretrained_BERT neuron indx 9690 [('E', 1.0), ('purpose', 0.9842477947669446), ('authentication', 0.9158996243817175), ('Tab', 0.8467992768721021), ('oslo', 0.7841966802366663)]
Top words for pretrained_BERT neuron indx 1504 [('alt', 1.0), ('future', 0.8193834898421417), ('context', 0.7809369327321802), ('proxy', 0.7285562586790325), ('authorization', 0.7192472565980598)]
Top words for pretrained_BERT neuron indx 7653 [('day', 1.0), ('month', 0.9992357345543277), ('contents', 0.9058333781212945), ('wait', 0.8524582830017768), ('as', 0.8472019433705718)]
Top words for pretrained_BERT neuron indx 7656 [('600', 1.0), ('import', 0.9093356163814654), ('400', 0.8990125593681153), ('read', 0.8606397220869906), ('to', 0.8194743162663832)]
Top words for pretrained_BERT neuron indx 1518 [('component', 1.0), ('Component', 0.9861276795183552), ('replace', 0.8200734818977674), ('count', 0.8017548033993246), ('Exception', 0.7927481243004325)]
Top words for pretrained_BERT neuron indx 5614 [('close', 1.0), ('count', 0.9101332311661618), ('st', 0.9085196103153774), ('link', 0.9004199313535194), ('task', 0.8660540192365382)]
Top words for pretrained_BERT neuron indx 1525 [('replace', 1.0), ('force', 0.9336576610955614), ('token', 0.9183215576869014), ('domain', 0.8840782424191597), ('activity', 0.87504644638573)]
Top words for pretrained_BERT neuron indx 5626 [('log', 1.0), ('Log', 0.9142244672606433), ('i', 0.897979620158258), ('help', 0.8806625037598165), ('iq', 0.858041948303253)]
Top words for pretrained_BERT neuron indx 3586 [('zone', 1.0), ('main', 0.8707656530856268), ('state', 0.7492660297966389), ('context', 0.7349020647740053), ('24', 0.7052020001848304)]
Top words for pretrained_BERT neuron indx 9733 [('tz', 1.0), ('post', 0.9001774745037863), ('localize', 0.8232176156106916), ('long', 0.8010475878674762), ('9', 0.8009066186198104)]
Top words for pretrained_BERT neuron indx 1542 [('format', 1.0), ('ignore', 0.9090026160252256), ('authentication', 0.9075975152261511), ('20000', 0.8661134539270405), ('800', 0.8447859028865161)]
Top words for pretrained_BERT neuron indx 3597 [('alt', 1.0), ('direct', 0.9821046727305313), ('main', 0.9768829503756965), ('clone', 0.9016673743616932), ('calendar', 0.8960021094942866)]
Top words for pretrained_BERT neuron indx 5660 [('if', 1.0), ('View', 0.9995875375937565), ('url', 0.9259873574367188), ('sorted', 0.8559823118131754), ('Plugin', 0.8532554265437047)]
Top words for pretrained_BERT neuron indx 1566 [('message', 1.0), ('future', 0.8688278401123617), ('boot', 0.8106908656519567), ('Util', 0.8009300964082254), ('partition', 0.7800455945462337)]
Top words for pretrained_BERT neuron indx 5667 [('save', 1.0), ('link', 0.9653928751485586), ('On', 0.8963984338650123), ('description', 0.8619191633801248), ('Distance', 0.8501731509718358)]
Top words for pretrained_BERT neuron indx 1574 [('exceptions', 1.0), ('uss', 0.8510606059544438), ('bare', 0.8315210473445848), ('300', 0.8155407231253484), ('False', 0.7574429379235703)]
Top words for pretrained_BERT neuron indx 3627 [('patch', 1.0), ('open', 0.9020496341737273), ('bare', 0.8219670587900909), ('Node', 0.7828581163006689), ('token', 0.7386480899618633)]
Top words for pretrained_BERT neuron indx 1581 [('calendar', 1.0), ('k', 0.9221497834113481), ('state', 0.8975201499512934), ('v', 0.7811965416295525), ('20', 0.7782097950098754)]
Top words for pretrained_BERT neuron indx 7726 [('probe', 1.0), ('calendar', 0.917667346961032), ('minutes', 0.8651410471629899), ('partition', 0.8596894139619534), ('ranges', 0.8569867719225007)]
Top words for pretrained_BERT neuron indx 9775 [('9', 1.0), ('32', 0.807771466429445), ('1024', 0.7773622915713762), ('128', 0.69882496953092), ('40', 0.6863787371145867)]
Top words for pretrained_BERT neuron indx 1585 [('core', 1.0), ('enabled', 0.8989598357792644), ('count', 0.8946281097037941), ('required', 0.8903139255395649), ('Authorization', 0.8281094193307358)]
Top words for pretrained_BERT neuron indx 3637 [('read', 1.0), ('method', 0.9076310505232166), ('print', 0.8363511174654854), ('""', 0.818299863946339), ('v', 0.7930780384647779)]
Top words for pretrained_BERT neuron indx 3643 [('if', 1.0), ('part', 0.9931541570790744), ('main', 0.9929730512009668), ('year', 0.8646668676842355), ('routes', 0.863296422941689)]
Top words for pretrained_BERT neuron indx 3647 [('error', 1.0), ('Exception', 0.8398405680475447), ('17', 0.7744542397318843), ('host', 0.7456771667303028), ('other', 0.7403628413552373)]
Top words for pretrained_BERT neuron indx 5696 [('close', 1.0), ('View', 0.9822191687438605), ('find', 0.9545155947627709), ('seek', 0.8534893467155406), ('Board', 0.7828496784382777)]
Top words for pretrained_BERT neuron indx 9796 [('if', 1.0), ('unicode', 0.9665338446972865), ('f', 0.9593146924728445), ('strftime', 0.9405180295792291), ('as', 0.8064385721137258)]
Top words for pretrained_BERT neuron indx 7757 [('postinfo', 1.0), ('presence', 0.9774581595313747), ('closing', 0.8390617856551267), ('UserInfo', 0.814526480642101), ('enclosure', 0.7984839550047435)]
Top words for pretrained_BERT neuron indx 1616 [('other', 1.0), ('minute', 0.9621927146549921), ('month', 0.9562079884528139), ('None', 0.9547217103827969), ('iq', 0.898819753086121)]
Top words for pretrained_BERT neuron indx 3679 [('settings', 1.0), ('ret', 0.9706188570671851), ('us', 0.9017455376001497), ('dict', 0.8762821319472066), ('error', 0.854185077883678)]
Top words for pretrained_BERT neuron indx 7779 [('host', 1.0), ('title', 0.9700043339632687), ('k', 0.9216598244079778), ('Post', 0.9112328223010097), ('policy', 0.8559988888225509)]
Top words for pretrained_BERT neuron indx 7781 [('patch', 1.0), ('alt', 0.9154549614691465), ('replace', 0.7568794773333445), ('ping', 0.7146939260630673), ('post', 0.7137116746548768)]
Top words for pretrained_BERT neuron indx 1648 [('start', 1.0), ('sorted', 0.8885206316956454), ('Authorization', 0.8783003780296467), ('connection', 0.8544803209417318), ('iq', 0.8403647607472416)]
Top words for pretrained_BERT neuron indx 9859 [('bool', 1.0), ('affinity', 0.8929658936387541), ('naive_dt', 0.8535060655687193), ('readline', 0.8441099714612768), ('Profile', 0.8236400504848792)]
Top words for pretrained_BERT neuron indx 3719 [('day', 1.0), ('month', 0.9414672632559876), ('filter', 0.915712993070884), ('broadcast', 0.8988446262946771), ('alt', 0.8060588541766444)]
Top words for pretrained_BERT neuron indx 5775 [('class', 1.0), ('parts', 0.8165868414040821), ('Profile', 0.730416153285505), ('closing', 0.7233293837907246), ('baseline', 0.6039163474499949)]
Top words for pretrained_BERT neuron indx 5780 [('minutes', 1.0), ('seconds', 0.9111562911451673), ('line', 0.8502732798505078), ('contents', 0.8215284608028289), ('boardname', 0.7906218609216098)]
Top words for pretrained_BERT neuron indx 3732 [('month', 1.0), ('group', 0.987560757260647), ('us', 0.7508173232224025), ('domain', 0.7443638192345825), ('types', 0.7401894839538801)]
Top words for pretrained_BERT neuron indx 3735 [('context', 1.0), ('40', 0.8706647813264923), ('field', 0.8634604575240766), ('con', 0.8492630503508837), ('pop', 0.8453357600152493)]
Top words for pretrained_BERT neuron indx 3737 [('sts', 1.0), ('break', 0.9845699613583917), ('session', 0.8254543125191126), ('pass', 0.8197197044082414), ('local', 0.8193349367239271)]
Top words for pretrained_BERT neuron indx 3744 [('purpose', 1.0), ('key', 0.8310357788674256), ('match', 0.7839647412668246), ('part', 0.7675498805713127), ('features', 0.6583635919369385)]
Top words for pretrained_BERT neuron indx 1702 [('strip', 1.0), ('format', 0.9200596207010473), ('render', 0.9122659645373272), ('user', 0.9097393032261304), ('partition', 0.908543801974521)]
Top words for pretrained_BERT neuron indx 9896 [('link', 1.0), ('end', 0.9589596551586266), ('val', 0.9434010708672786), ('routes', 0.8993904536916143), ('1800', 0.8245237480780904)]
Top words for pretrained_BERT neuron indx 9909 [('400', 1.0), ('parts', 0.7900624926402493), ('__copyright__', 0.7762643889864917), ('created', 0.7743237332709902), ('child', 0.6825037537424197)]
Top words for pretrained_BERT neuron indx 3773 [('Node', 1.0), ('enabled', 0.8202941940069892), ('other', 0.7655933270332328), ('reactor', 0.7381500640771493), ('v', 0.7057760697819334)]
Top words for pretrained_BERT neuron indx 7873 [('oslo', 1.0), ('baseline', 0.7671562664554414), ('Tab', 0.651611609644297), ('put', 0.6455225069494385), ('presence', 0.6417214457611279)]
Top words for pretrained_BERT neuron indx 1731 [('match', 1.0), ('clone', 0.9328369870508249), ('material', 0.8708359723230126), ('MAXBOARD', 0.8159257801757342), ('error', 0.8087387092246144)]
Top words for pretrained_BERT neuron indx 5829 [('20', 1.0), ('help', 0.9910065063940761), ('300', 0.9221690887041138), ('uss', 0.9070334372035085), ('bind', 0.8597641773560789)]
Top words for pretrained_BERT neuron indx 3782 [('60', 1.0), ('40', 0.9576022244013199), ('body', 0.9289838985801919), ('80', 0.8971348682112205), ('17', 0.8501779892943003)]
Top words for pretrained_BERT neuron indx 1742 [('ping', 1.0), ('force', 0.871111756587552), ('exceptions', 0.8597579744667962), ('break', 0.8557686604621221), ('loads', 0.8465760717819815)]
Top words for pretrained_BERT neuron indx 3791 [('1000', 1.0), ('closing', 0.9562499854332424), ('blocking', 0.9156319770935742), ('if', 0.8541512437925679), ('parts', 0.8530289594501947)]
Top words for pretrained_BERT neuron indx 1748 [('wait', 1.0), ('target', 0.9586978921667451), ('1000', 0.9228586788522277), ('future', 0.9023547364648433), ('key', 0.8685755325582958)]
Top words for pretrained_BERT neuron indx 7905 [('blocking', 1.0), ('__long__', 0.8501171934555605), ('vwwn', 0.8433910582611464), ('vsn', 0.8128669737263851), ('egs', 0.7971895605170143)]
Top words for pretrained_BERT neuron indx 9955 [('enclosure', 1.0), ('15', 0.9010245608943508), ('20000', 0.8987198021045046), ('1800', 0.8674385852546386), ('Tab', 0.8079670177207082)]
Top words for pretrained_BERT neuron indx 1765 [('1000', 1.0), ('Simple', 0.923090929251244), ('strip', 0.8851571156307595), ('80', 0.8767697211234775), ('reactor', 0.8699729654543392)]
Top words for pretrained_BERT neuron indx 3822 [('count', 1.0), ('Board', 0.9909148605178968), ('List', 0.9848449154067468), ('Component', 0.9685973729980664), ('component', 0.9412483288109018)]
Top words for pretrained_BERT neuron indx 5879 [('replace', 1.0), ('local', 0.9903059014150812), ('sanetime', 0.8661896545726162), ('80', 0.8417457098444013), ('open', 0.8081154124248142)]
Top words for pretrained_BERT neuron indx 1783 [('board', 1.0), ('GET', 0.96616197694267), ('tz', 0.9501248421572253), ('Stretch', 0.9213775908046984), ('ntime', 0.913646488905587)]
Top words for pretrained_BERT neuron indx 3838 [('seconds', 1.0), ('authorization', 0.8609926023329348), ('contents', 0.8162952047327002), ('9', 0.8106891691618612), ('exceptions', 0.7674596787853271)]
Top words for pretrained_BERT neuron indx 5893 [('models', 1.0), ('tz', 0.6764381682526603), ('month', 0.6455163278522918), ('oslo', 0.6286905709407866), ('year', 0.6265965024295173)]
Top words for pretrained_BERT neuron indx 5896 [('pop', 1.0), ('con', 0.9612983742390607), ('re', 0.8129370985419296), ('authorization', 0.8027657899738454), ('1000', 0.7895502456590927)]
Top words for pretrained_BERT neuron indx 3855 [('break', 1.0), ('GET', 0.7686848977855001), ('send', 0.6826877782145372), ('key', 0.6654747432344048), ('"list"', 0.6175153848539129)]
Top words for pretrained_BERT neuron indx 5904 [('types', 1.0), ('400', 0.9506019943761824), ('exceptions', 0.8963274118167399), ('log', 0.8505510655115116), ('pop', 0.8301191394679591)]
Top words for pretrained_BERT neuron indx 7959 [('replace', 1.0), ('alt', 0.9564676837175796), ('session', 0.8883895506127237), ('ref', 0.8474534713857435), ('80', 0.8364986711323232)]
Top words for pretrained_BERT neuron indx 7964 [('if', 1.0), ('View', 0.8883169541633685), ('boot', 0.7360215373900552), ('128', 0.6971234638065704), ('url', 0.6901800217460591)]
Top words for pretrained_BERT neuron indx 7965 [('Log', 1.0), ('log', 0.9636408693304345), ('""', 0.79462340987969), ('zone', 0.7252172888032706), ('Session', 0.7175003774656585)]
Top words for pretrained_BERT neuron indx 3869 [('session', 1.0), ('Profile', 0.9888173769690123), ('32', 0.9586928217426147), ('sans', 0.9422501444941024), ('modes', 0.9399801631766278)]
Top words for pretrained_BERT neuron indx 7971 [('pop', 1.0), ('Tab', 0.9212880115444043), ('iq', 0.9168298051031093), ('us', 0.8357299933338179), ('core', 0.8242293909027495)]
Top words for pretrained_BERT neuron indx 3880 [('upper', 1.0), ('server', 0.983275176763059), ('presence', 0.9140155783304401), ('to', 0.8322045668992325), ('stanza', 0.8182766011165916)]
Top words for pretrained_BERT neuron indx 1839 [('requests', 1.0), ('route', 0.9684597323436543), ('REQUEST', 0.9588051062703445), ('k', 0.9407365312991601), ('request', 0.8813323872062595)]
Top words for pretrained_BERT neuron indx 3889 [('required', 1.0), ('Authorization', 0.8735755733379994), ('core', 0.871305468709557), ('msgbox', 0.8054977130536046), ('24', 0.7733225520555456)]
Top words for pretrained_BERT neuron indx 1841 [('split', 1.0), ('slug', 0.9902699482713337), ('domain', 0.971622506347134), ('error', 0.9696655209471281), ('force', 0.9382813065009117)]
Top words for pretrained_BERT neuron indx 1844 [('to', 1.0), ('".."', 0.9715949540094723), ('as', 0.9084014050141024), ('from', 0.865238261331083), ('On', 0.8625204619814633)]
Top words for pretrained_BERT neuron indx 7992 [('while', 1.0), ('E', 0.712490419041005), ('Billboard', 0.7073695392147821), ('sans', 0.648674991800829), ('common', 0.6418672945742643)]
Top words for pretrained_BERT neuron indx 5954 [('stanza', 1.0), ('required', 0.9374888927386864), ('help', 0.8938042768947648), ('startswith', 0.8813639086819124), ('settings', 0.8338910763511818)]
Top words for pretrained_BERT neuron indx 8004 [('minutes', 1.0), ('connection', 0.9501873924832342), ('Billboard', 0.9191845782258229), ('iq', 0.9119229052952228), ('contents', 0.7929003462242636)]
Top words for pretrained_BERT neuron indx 3911 [('link', 1.0), ('dt', 0.8470382184505065), ('if', 0.8130898148813128), ('part', 0.7459080167586182), ('Stretch', 0.7124748104698647)]
Top words for pretrained_BERT neuron indx 3915 [('On', 1.0), ('save', 0.8931654101611959), ('second', 0.866864368332481), ('with', 0.8055559237367336), ('800', 0.8032612054778848)]
Top words for pretrained_BERT neuron indx 1869 [('main', 1.0), ('other', 0.9713248903813457), ('types', 0.96709870467094), ('day', 0.9008705014076446), ('v', 0.8705361137706058)]
Top words for pretrained_BERT neuron indx 1872 [('enclosure', 1.0), ('domain', 0.838688122712286), ('exceptions', 0.814301131367613), ('Node', 0.7284285241416053), ('enclosuregroup', 0.7272798351582921)]
Top words for pretrained_BERT neuron indx 1893 [('contents', 1.0), ('boot', 0.9222618835593032), ('v', 0.7502550548249388), ('Tab', 0.6985495424977463), ('Board', 0.6825826864045427)]
Top words for pretrained_BERT neuron indx 3950 [('Session', 1.0), ('slug', 0.9693616489535689), ('utc', 0.8936024808319669), ('affinity', 0.85584699494549), ('17', 0.8432198519689578)]
Top words for pretrained_BERT neuron indx 8060 [('9', 1.0), ('1800', 0.9668130148098415), ('14', 0.8727258889892765), ('800', 0.8686300887808226), ('1000', 0.8427756297649197)]
Top words for pretrained_BERT neuron indx 6013 [('300', 1.0), ('continue', 0.9613135767875955), ('30', 0.921982723917802), ('time', 0.9034587258803364), ('return', 0.8738513749553005)]
Top words for pretrained_BERT neuron indx 8070 [('"purpose"', 1.0), ('"r"', 0.8907777649280362), ('stat', 0.8667170267177209), ('info', 0.8451381160877312), ('600', 0.7762100949152709)]
Top words for pretrained_BERT neuron indx 1933 [('send', 1.0), ('task', 0.8486124369352788), ('Exception', 0.8181290464273894), ('other', 0.8127856124276553), ('end', 0.7917030181360373)]
Top words for pretrained_BERT neuron indx 8079 [('minutes', 1.0), ('baseline', 0.9521276796298627), ('mins', 0.9503594252045484), ('class', 0.9383301282485434), ('profile', 0.9225260881240751)]
Top words for pretrained_BERT neuron indx 3984 [('read', 1.0), ('closing', 0.7985625651587708), ('blocking', 0.7934527464425063), ('pass', 0.750949914987277), ('Distance', 0.7484183602106281)]
Top words for pretrained_BERT neuron indx 3983 [('Unauthorized', 1.0), ('patch', 0.9332281042730939), ('long', 0.8751526715021737), ('xmlns', 0.8355964580211496), ('local', 0.8340492207228966)]
Top words for pretrained_BERT neuron indx 3987 [('16', 1.0), ('17', 0.9775362132723617), ('15', 0.9424039153560013), ('32', 0.9420108933545291), ('14', 0.9201269124438569)]
Top words for pretrained_BERT neuron indx 6039 [('Board', 1.0), ('pop', 0.9677015425989149), ('Mesh', 0.8670248179201414), ('context', 0.8495915142077536), ('40', 0.8463890811077047)]
Top words for pretrained_BERT neuron indx 6044 [('dt', 1.0), ('direct', 0.9549925542107628), ('close', 0.9248807662872852), ('start', 0.8913620266128699), ('Distance', 0.8698889499664441)]
Top words for pretrained_BERT neuron indx 6048 [('purpose', 1.0), ('with', 0.5538955524992238), ('main', 0.5378706888404963), ('Unauthorized', 0.5240037703501015), ('script', 0.5142253576147982)]
Top words for pretrained_BERT neuron indx 4005 [('False', 1.0), ('choices', 0.910334610493852), ('other', 0.8511158213145039), ('group', 0.8116767794671227), ('requests', 0.809318628790687)]
Top words for pretrained_BERT neuron indx 1965 [('open', 1.0), ('state', 0.9043972435288626), ('break', 0.8628447075383927), ('128', 0.8134522936327556), ('Exception', 0.7808129532713878)]
Top words for pretrained_BERT neuron indx 1968 [('86400', 1.0), ('24', 0.9930550496160901), ('loads', 0.9020489463143381), ('read', 0.8562174006337823), ('find', 0.8469138044571243)]
Top words for pretrained_BERT neuron indx 8114 [('start', 1.0), ('exit', 0.9551238888430648), ('probe', 0.858789864642899), ('push', 0.7936890021383243), ('9', 0.7872427008500609)]
Top words for pretrained_BERT neuron indx 8123 [('query', 1.0), ('".."', 0.9608521924533304), ('15', 0.9382318285763979), ('slug', 0.9131854774139021), ('""', 0.8995913889567306)]
Top words for pretrained_BERT neuron indx 8133 [('32', 1.0), ('20', 0.991220590080596), ('force', 0.9692495525981516), ('800', 0.9685115660171875), ('1800', 0.9226470219174902)]
Top words for pretrained_BERT neuron indx 4043 [('Tab', 1.0), ('Log', 0.9900462157027563), ('tz', 0.8264029913601667), ('mins', 0.7747046101903112), ('class', 0.7716362480136405)]
Top words for pretrained_BERT neuron indx 4046 [('loads', 1.0), ('split', 0.9996263925279559), ('main', 0.9727711316207922), ('ping', 0.8966759873055166), ('sans', 0.895187224126793)]
Top words for pretrained_BERT neuron indx 8142 [('features', 1.0), ('common', 0.8118641372967019), ('alt', 0.8045779421792283), ('ranges', 0.7993925760834135), ('tout', 0.7689531224827751)]
Top words for pretrained_BERT neuron indx 8150 [('9', 1.0), ('Log', 0.6999525217016208), ('600', 0.682327476604385), ('v', 0.6611110922492437), ('log', 0.6326141511775494)]
Top words for pretrained_BERT neuron indx 6102 [('close', 1.0), ('blocking', 0.9377662253037996), ('push', 0.8473453191111133), ('while', 0.8377943460047855), ('seek', 0.7557716087043687)]
Top words for pretrained_BERT neuron indx 8154 [('Tab', 1.0), ('features', 0.923728536117749), ('error', 0.9139142027876589), ('while', 0.910893424126197), ('purpose', 0.8916437851785478)]
Top words for pretrained_BERT neuron indx 8166 [('authentication', 1.0), ('E', 0.8937858247551455), ('authorization', 0.8787538649776381), ('type', 0.7825776510464053), ('common', 0.7702882131689853)]
Top words for pretrained_BERT neuron indx 2023 [('store', 1.0), ('import', 0.8770645788207884), ('material', 0.7894222793479613), ('300', 0.7832615918135685), ('1800', 0.7274987717738006)]
Top words for pretrained_BERT neuron indx 8186 [('us', 1.0), ('uss', 0.8496819118926551), ('dict', 0.816446797381974), ('def', 0.8093002914746069), ('scope', 0.7968695906201505)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0140
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0085
Epoch: [4/10], Loss: 0.0070
Epoch: [5/10], Loss: 0.0064
Epoch: [6/10], Loss: 0.0049
Epoch: [7/10], Loss: 0.0047
Epoch: [8/10], Loss: 0.0036
Epoch: [9/10], Loss: 0.0034
Epoch: [10/10], Loss: 0.0028
Score (accuracy) of the probe: 0.27
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0139
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0085
Epoch: [4/10], Loss: 0.0070
Epoch: [5/10], Loss: 0.0062
Epoch: [6/10], Loss: 0.0051
Epoch: [7/10], Loss: 0.0051
Epoch: [8/10], Loss: 0.0040
Epoch: [9/10], Loss: 0.0039
Epoch: [10/10], Loss: 0.0030
Score (accuracy) of the probe: 0.25
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0140
Epoch: [2/10], Loss: 0.0108
Epoch: [3/10], Loss: 0.0083
Epoch: [4/10], Loss: 0.0069
Epoch: [5/10], Loss: 0.0065
Epoch: [6/10], Loss: 0.0051
Epoch: [7/10], Loss: 0.0050
Epoch: [8/10], Loss: 0.0039
Epoch: [9/10], Loss: 0.0037
Epoch: [10/10], Loss: 0.0031
Score (accuracy) of the probe: 0.29
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0151
Epoch: [2/10], Loss: 0.0119
Epoch: [3/10], Loss: 0.0102
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0064
Epoch: [7/10], Loss: 0.0058
Epoch: [8/10], Loss: 0.0051
Epoch: [9/10], Loss: 0.0048
Epoch: [10/10], Loss: 0.0045
Score (accuracy) of the probe: 0.27
The best l1=0, the best l2=0.01 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.27
{'__OVERALL__': 0.2708803611738149, 'NAME': 0.2653061224489796, 'STRING': 0.2809917355371901, 'NUMBER': 0.18584070796460178, 'KEYWORD': 0.35135135135135137}
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.27
pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.5733634311512414
----------------------------------------------------------------
