Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
7656 13.0
Number of tokens:  72951
length of source dictionary:  5099
length of target dictionary:  42
72951
Total instances: 72951
['future', 'is_py2', 'one', '_geo_indices', 'createVPNPayload', '"not-specified"', 'tls', 'BLESS_BOARD', 'ping_client', 'get_profile_compliance_preview', 'remote_branch', 'lat__gt', 'API_VERSION_MINIMUM', 'Test_root_added', 'STEAL_AFTER_SEEN', '3700', 'post_event_url', 'pipeline_draw_graph', 'SaneTime', 'get_serializer_class']
Number of samples:  72951
Stats: Labels with their frequencies in the final set
NAME 23204
NEWLINE 6586
DOT 5889
LPAR 5444
RPAR 5263
KEYWORD 5018
COMMA 4364
EQUAL 3897
COLON 2622
DEDENT 1878
INDENT 1593
NUMBER 1356
LSQB 1291
RSQB 1267
NL 1069
STRING 550
LBRACE 293
EQEQUAL 226
RBRACE 211
PLUS 200
PERCENT 109
STAR 94
MINUS 83
AT 61
DOUBLESTAR 60
GREATER 59
PLUSEQUAL 52
NOTEQUAL 44
LEFTSHIFT 31
LESS 29
LESSEQUAL 18
COMMENT 15
GREATEREQUAL 15
SEMI 13
VBAR 12
SLASH 11
TILDE 7
ELLIPSIS 6
AMPER 5
MINEQUAL 3
ERRORTOKEN 2
RIGHTSHIFT 1
pretrained_BERT distribution after trauncating:
{0: 0.7701805629314923, 3: 0.16655602761550717, 2: 0.045007966011683484, 1: 0.01825544344131705}
{0: 23204, 3: 5018, 2: 1356, 1: 550}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
5985 13.0
Number of tokens:  64699
length of source dictionary:  3727
length of target dictionary:  42
64699
Total instances: 64699
['0.97', 'y_x', '_build_R', 'pstats', '_', 'dgamma', 'addr', 'pad_y', '0.09990891117239205', '"nodrug"', 'small_tmp', 'writeable_objects', '"memcpyr"', '"elsize"', 'crop0', 'UserWarning', 'term1', 'height_js', 'inner', 'pore_Tc']
Number of samples:  64699
Stats: Labels with their frequencies in the final set
NAME 20893
NEWLINE 5444
DOT 5083
COMMA 4481
RPAR 4279
LPAR 4277
KEYWORD 3639
EQUAL 3459
NUMBER 2218
COLON 1972
LSQB 1939
RSQB 1927
DEDENT 1387
INDENT 1203
NL 540
STRING 324
MINUS 262
PLUS 248
STAR 236
EQEQUAL 141
LBRACE 128
RBRACE 126
SLASH 122
PERCENT 69
DOUBLESTAR 55
PLUSEQUAL 50
GREATER 47
NOTEQUAL 32
COMMENT 22
LESS 20
STAREQUAL 16
GREATEREQUAL 16
AT 10
MINEQUAL 7
SEMI 7
VBAR 6
LESSEQUAL 5
AMPER 3
SLASHEQUAL 2
DOUBLESLASH 2
TILDE 1
LEFTSHIFT 1
pretrained_BERT distribution after trauncating:
{0: 0.7716997857723277, 3: 0.134409396468937, 2: 0.08192361675408141, 1: 0.011967201004653911}
{0: 20893, 3: 3639, 2: 2218, 1: 324}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 13506, 3: 1019, 1: 491, 2: 136})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({2: 2039, 0: 1882, 3: 68, 1: 37})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (13636, 9984)
The shape of the validation set: (1516, 9984)
The shape of the testing set: (4026, 9984)
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0100
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0010
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0103
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0011
Epoch: [4/10], Loss: 0.0007
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0099
Epoch: [2/10], Loss: 0.0043
Epoch: [3/10], Loss: 0.0013
Epoch: [4/10], Loss: 0.0009
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0004
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0112
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0029
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 0.93

The best l1=0, the best l2=0 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.8238946845504223, 'NAME': 0.6248671625929861, 'STRING': 1.0, 'NUMBER': 0.9990191270230505, 'KEYWORD': 0.9852941176470589}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1176,KW_NAME:0
NAME_KW:84,KW_KW:67
NAME_STRING:335,KW_other:1
NAME_NUMBER:287
NAME_STRING_list:['m', 'm', 'm', 'm', 'm', 'a', 'T', 'T', 'T', 'T', 'T', 'T', 'p', 'T', 'T', 'p', 't', 'p', 'p', 'p', 'p', 'p', 'a', 'a', 'a', 'T', 'a', 'i', 'i', 'i', 'i', 'i', 't', 't', 'i', 'i', 'i', 'i', 'm', 'm', 'm', 'm', 'm', 't', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 't', 'm', 'm', 'x', 'x', 'i', 'a', 'a', 'm', 'm', 'm', 'i', 'i', 'i', 'i', 'x', 't', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'x', 'i', 'I', 'I', 'T', 'I', 'P', 'p', 'I', 'p', 'I', 'P', 'I', 'E', 'T', 'p', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'p', 'P', 't', 'T', 'P', 'I', 'P', 't', 't', 't', 'P', 'P', 'I', 'p', 'p', 'p', 'P', 'I', 'I', 'I', 'I', 'I', 'i', 'i', 'i', 'T', 'T', 'p', 'p', 'T', 'T', 'X', 'T', 'T', 'i', 'p', 'p', 't', 't', 't', 't', 'i', 'i', 'i', 'u', 'i', 'i', 'i', 'i', 'i', 'v', 'i', 'i', 'i', 'i', 'm', 'm', 'm', 't', 'i', 't', 't', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'p', 'p', 'p', 'm', 'm', 'm', 'd', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'T', 'T', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'i', 'i', 'i', 'i', 'i', 'T', 'T', 'T', 'i', 'i', 'i', 'i', 'i', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'j1', 'i', 'i', 'j1', 'i', 'i', 'T', 'T', 'P', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'p', 'p', 'i', 'i', 'i', 't', 'T', 'R', 'A', 'R', 'A']
NAME_NUMBER_list:['a', 'x', 'X', 'h', 'W', 'U', 'W', 'U', 'W', 'U', 'h0', 'T', 'h0', 's', 'T', 't', 't0', 't0', 'h', 'x', 'y', 'y', 'y', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'f', 'i', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'j', 'k', 'v', 'xx', 'd', 'g', 'i', 'z', 'z', 'x', 'x', 'f1', 'f1', 'q', 'q', 'K', 'I', 'K', 'q', 'q', 'Q', 'P', 'p', 'q', 'Q', 'K', 'N', 'I', 'K', 'K', 'q', 'q', 'Q', 'p', 'U', 'T0', 'T0', 't0', 't0', 't0', 'T0', 'T0', 't0', 't0', 't0', 'T0', 'T0', 't0', 't0', 't0', 'T0', 't0', 't0', 'T0', 't0', 't0', 'T', 'x', 'p', 'P', 'p0', 'p0', 'p0', 'Q', 'D', 'D', 'K', 'D', 'D', 'N', 'c', 'C', 'k', 'K', 'x', 'I', 'n', 'N', 'n', 'n', 'D', 't', 'D', 't', 't', 'K', 'N', 'p0', 'q0', 'x', 'k', 'K', 'k', 'n', 'p0', 'D', 'D', 'N', 'D', 'D', 'N', 'K', 'D', 'D', 'K', 'U', 'D', 'D', 'K', 'x', 'n', 'n', 'k', 'K', 'n', 'k', 'n', 'D', 't', 't', 't', 'X', 'N', 'K', 'K', 'Q', 'N', 'q', 'X', 'I', 'N', 'q', 'Q', 'q', 'n', 'K', 'pq', 'x', 'x', 'u', 'j', 't', 'p', 'g', 'T', 'g', 'T', 'T', 'T', 'T', 'X', 'X', 'x', 'x', 't', 't', 't', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'u', 'v', 'u', 'u', 'f', 'k', 'k', 'k', 'v', 'n', 'n', 's', 'p', 'd', 'n', 'v', 'n', 'n', 's', 'u', 'p', 'p', 'p', 'p', 'J', 'J', 'J', 'J', 'x', 'x', 'X', 'k', 'k', 'k', 'X', 'X', 'q', 'G', 'T', 'T', 'p', 'p', 'q', 'G', 'i', 'i', 'f0', 'X', 'T', 'G', 'X', 'T', 'g', 'G', 'X', 'i', 'i', 'i', 'X', 'X', 'X', 'X', 'x', 'X', 'i', 'T', 'P', 'a3', 'a0', 'a0', 'T', 'f', 'p', 'i', 'i', 'g', 'n', 'T', 'Q', 'Q']
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0053
Epoch: [3/10], Loss: 0.0038
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0053
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0054
Epoch: [3/10], Loss: 0.0038
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0101
Epoch: [2/10], Loss: 0.0065
Epoch: [3/10], Loss: 0.0052
Epoch: [4/10], Loss: 0.0045
Epoch: [5/10], Loss: 0.0040
Epoch: [6/10], Loss: 0.0037
Epoch: [7/10], Loss: 0.0034
Epoch: [8/10], Loss: 0.0032
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.86
{'__OVERALL__': 0.8611525086934922, 'NAME': 0.7460148777895855, 'STRING': 1.0, 'NUMBER': 0.9931338891613536, 'KEYWORD': 0.014705882352941176}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1404,KW_NAME:67
NAME_KW:170,KW_KW:1
NAME_STRING:257,KW_other:0
NAME_NUMBER:51
NAME_STRING_list:['a', 'a', 'a', 'a', 'T', 'T', 't', 'a', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'd', 'i', 'a', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'D', 'D', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 's', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'A', 'A', 'A']
NAME_NUMBER_list:['t0', 't0', 'xx', 'xx', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'T0', 'T0', 'T0', 't0', 't0', 't0', 'T0', 'T0', 'T0', 't0', 't0', 't0', 'T0', 'T0', 'T0', 't0', 't0', 't0', 'T0', 't0', 't0', 'T0', 't0', 't0', 'p0', 'p0', 'p0', 'p0', 'p0', 'q0', 'p0', 'q0', 'f0', 'f0', 'a3', 'a0', 'a0', 'a3']
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0094
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0040
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0102
Epoch: [2/10], Loss: 0.0067
Epoch: [3/10], Loss: 0.0054
Epoch: [4/10], Loss: 0.0047
Epoch: [5/10], Loss: 0.0042
Epoch: [6/10], Loss: 0.0038
Epoch: [7/10], Loss: 0.0036
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0030
Score (accuracy) of the probe: 0.96

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8370591157476404, 'NAME': 0.6859723698193412, 'STRING': 1.0, 'NUMBER': 0.9970573810691515, 'KEYWORD': 0.1323529411764706}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1291,KW_NAME:59
NAME_KW:55,KW_KW:9
NAME_STRING:468,KW_other:0
NAME_NUMBER:68
NAME_STRING_list:['a', 'a', 'a', 'a', 'T', 'b1', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 't', 'T', 'T', 'T', 'T', 't', 't', 'p', 'p', 'b1', 'p', 'p', 'p', 'd', 'd', 'T', 'a', 'a', 'b', 'a', 'T', 'T', 'a', 'T', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 't', 't', 't', 'i', 'i', 'i', 'i', 'm', 'm', 'm', 't', 'm', 'y', 'y', 'y', 'f', 'i', 'd', 'd', 'i', 'a', 'a', 'f', 'f', 'j', 'i', 'i', 'i', 'i', 'd', 'd', 'f', 't', 't', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'f', 'i', 'i', 'i', 'f', 'd', 'iw', 'ih', 'd', 'd', 'i', 'i', 'f', 'I', 'I', 'T', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'T', 'T', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'T', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'F', 'T', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'T', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'p', 'p', 'D', 'P', 'D', 'D', 'I', 's', 't', 's', 't', 's', 't', 'T', 's', 't', 'B', 'B', 'I', 'B', 's', 's', 't', 's', 't', 'T', 's', 't', 's', 't', 's', 't', 'T', 's', 't', 'I', 'I', 'I', 'I', 'I', 'F', 'F', 'I', 'I', 'i', 'i', 'i', 'i', 'j', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'i', 't', 's', 't', 's', 't', 't', 't', 't', 't', 'i', 'i', 'i', 't', 's', 't', 'i', 'i', 'i', 'i', 'i', 'i', 's', 'i', 'i', 'i', 'i', 't', 't', 'i', 's', 't', 't', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'i', 'i', 'J', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 's', 's', 's', 'd', 'D', 'D', 'D', 'D', 'i', 'i', 'i', 'D', 'i', 'T', 'T', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'T', 'T', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'i', 'T', 'i', 'i', 'i', 'i', 'T', 'T', 'T', 'T', 'i', 'T', 'i', 'i', 'i', 'i', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'T', 'a', 'T', 'a', 'b', 'P', 'a', 'b', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'd', 't', 'T', 'T', 'A', 'A', 'A', 't', 't', 't', 't', 't', 't', 't', 't']
NAME_NUMBER_list:['h0', 'h0', 'h0', 't0', 't0', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'f1', 'f1', 'T0', 'T0', 'T0', 't0', 't0', 't0', 't3', 'T0', 'T0', 'T0', 't0', 't0', 't0', 'T0', 'T0', 'T0', 't0', 't0', 't3', 't0', 't3', 'T0', 't0', 't0', 't3', 't3', 'T0', 't0', 't0', 'p0', 'p0', 'p0', 'p0', 'p0', 'q0', 'p0', 'q0', 'f', 't', 'J', 'f0', 'f0', 'j1', 'j1', 'j1', 'j1', 'j1', 'j1', 'a3', 'a0', 'a0', 'a2', 'a3', 'g1']
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0097
Epoch: [2/10], Loss: 0.0061
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0035
Epoch: [5/10], Loss: 0.0029
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0060
Epoch: [3/10], Loss: 0.0044
Epoch: [4/10], Loss: 0.0035
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0097
Epoch: [2/10], Loss: 0.0062
Epoch: [3/10], Loss: 0.0046
Epoch: [4/10], Loss: 0.0037
Epoch: [5/10], Loss: 0.0031
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0017
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0106
Epoch: [2/10], Loss: 0.0071
Epoch: [3/10], Loss: 0.0058
Epoch: [4/10], Loss: 0.0050
Epoch: [5/10], Loss: 0.0045
Epoch: [6/10], Loss: 0.0041
Epoch: [7/10], Loss: 0.0038
Epoch: [8/10], Loss: 0.0035
Epoch: [9/10], Loss: 0.0033
Epoch: [10/10], Loss: 0.0031
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.66
{'__OVERALL__': 0.6629408842523596, 'NAME': 0.3193411264612115, 'STRING': 1.0, 'NUMBER': 0.9941147621383031, 'KEYWORD': 0.058823529411764705}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:601,KW_NAME:61
NAME_KW:121,KW_KW:4
NAME_STRING:437,KW_other:3
NAME_NUMBER:723
NAME_STRING_list:['m', 'm', 'm', 'm', 'm', 'a', 'a', 'a', 'a', 'W', 'W', 'T', 'T', 'W', 'W', 'T', 'U', 'W', 'T', 'W', 'T', 'W', 'T', 'W', 'T', 'W', 'T', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'd', 's', 'a', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'j', 'i', 'i', 'y', 'i', 'i', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'y', 'y', 'y', 'd', 'X', 'X', 'X', 'X', 'X', 'd', 'i', 'd', 'd', 'i', 'd', 'a', 'a', 'f', 'f', 'm', 'i', 'i', 'i', 'i', 'x', 'Y', 'x', 'd', 'd', 'x', 'Y', 'Y', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'd', 'ih', 'iw', 'ih', 'i', 'i', 's', 's', 's', 'I', 'I', 'I', 'I', 'P', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'D', 'P', 'D', 'D', 'I', 's', 't', 'T', 'I', 's', 't', 't', 'T', 't', 't', 'T', 't', 'I', 'I', 'I', 'I', 'I', 'F', 'F', 'I', 'I', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'i', 'i', 'j', 'j', 'j', 'j', 'j', 'j', 'i', 'i', 's', 'i', 's', 't', 't', 'i', 'i', 'i', 's', 'i', 'i', 'i', 'i', 'i', 'i', 'v', 'v', 'u', 's', 'i', 'i', 's', 's', 's', 'i', 'i', 's', 'm', 's', 's', 's', 'm', 'i', 'c', 's', 't', 't', 's', 'J', 'J', 'J', 'p', 'i', 'i', 'J', 'i', 'i', 'i', 'J', 'i', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'i', 'J', 'i', 'J', 'i', 'c', 'p', 'p', 's', 's', 's', 'm', 'm', 'm', 'm', 'd', 'd', 'D', 'D', 'D', 'D', 'D', 'i', 'y', 'i', 'i', 'D', 'D', 'y', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'i', 'T', 'i', 'i', 'i', 'i', 'T', 'T', 'T', 'i', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'y', 'i', 'y', 'i', 'i', 'y', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'V', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'p', 'p', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'd', 't', 'v', 'A', 'A', 'A', 't', 't', 't', 't']
NAME_NUMBER_list:['x', 'x', 'T', 'W1', 'b1', 'X', 'T', 'X', 'b', 'T', 'T', 'T', 'T', 'c', 'X', 'T', 'T', 'X', 'T', 'T', 'X', 'b', 'T', 'T', 'X', 'X', 'T', 'X', 'b', 'T', 'X', 'x', 'p', 'x', 'h0', 'h0', 't', 'T', 'T', 'x', 't', 'h0', 'b1', 'd', 'T', 'x', 'x', 'b', 'T', 'b', 'T', 'b', 'j', 'x', 'j', 'x', 'j', 'j', 'j', 'x', 'x', 'x', 'x', 't', 'x', 't', 't', 'x', 'f', 't', 't0', 't', 't0', 'f', 'y', 'y', 'x', 'x', 'x', 'x', 'y', 'x', 'x', 'y', 'x', 'y', 'x', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'f', 'f', 'l', 'x', 'x', 'x', 'x', 'm', 'm', 'j', 'j', 'v', 'x', 'x', 'x', 'Y', 'Y', 'xx', 'Y', 'xx', 'Y', 'Y', 'x', 'X', 'X', 'X', 'Y', 'Y', 'Y', 'Y', 'x', 'x', 'd', 'x', 'x', 'x', 'x', 'x', 'x', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y1', 'x', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'x', 'Y1', 'Y', 'Y', 'Y', 'Y', 'Y', 'x', 'x', 'Y', 'Y', 'f', 'f', 't', 'p', 'p', 't', 'f', 'f', 'x', 'x', 'f', 'f', 'x', 'x', 'x', 'x', 'R', 'f', 'x', 'x', 'x', 'x', 'x', 'x', 'z', 'z', 'x', 'x', 'x', 'd', 'd', 'd', 'd', 'x', 'y', 'x', 'y', 'X', 'f', 'X', 'f1', 'f2', 'f1', 'X', 'X', 'f2', 'f1', 'f1', 'x', 'x', 'q', 'q', 'q', 'F', 'F', 'T', 'F', 'F', 'Y', 'X', 'C', 'F', 'P', 'X', 'p', 'p', 'Y', 'K', 'N', 'T', 'Y', 'X', 'P', 'R', 'x', 'X', 'p', 'p', 'q', 'T', 'T0', 'T0', 'T0', 't0', 't3', 't0', 't0', 'T', 'T0', 'T0', 'T0', 't0', 't0', 't0', 'T', 'T', 'T0', 'T0', 'T0', 't0', 't0', 't0', 'T', 'T', 'T0', 't0', 't0', 't3', 'T', 'T0', 't0', 't0', 'T', 'x', 'X', 'D', 'x', 'D', 'X', 'X', 'p', 'P', 'p0', 'p', 'p0', 'B', 'P', 'p0', 'p0', 'F', 'p', 'Q', 'B', 'D', 'D', 'D', 'y', 'Y', 'x', 'X', 'n', 'N', 'y', 'x', 'D', 'D', 't', 'p0', 'y', 'P', 'B', 'q0', 'q1', 'x', 'Q', 'B', 'y', 'x', 'p0', 'q0', 'U', 'D', 'D', 'y', 'P', 'B', 'x', 'Q', 'B', 'B', 'D', 't', 'N', 'Y', 'Y', 'X', 'P', 'Q', 'C', 'Y', 'X', 'N', 'C', 'R', 'P', 'Q', 'N', 'p', 'q', 'Y', 'X', 'p', 'N', 'p', 'q', 'P', 'Q', 'p', 'f', 'f', 'f', 'x', 'x', 'x', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'T', 'X', 'X', 'X', 'T', 'X', 'X', 'T', 'X', 'X', 'p', 'p', 'T', 'p', 'p', 'X', 'p', 'p', 'X', 'X', 'p', 'X', 'X', 'X', 'X', 'T', 'X', 'T', 'T', 'T', 'Y', 'T', 'X', 'X', 'T', 'T', 'Y', 'X', 'Y', 'X', 'x', 'x', 'y', 'x', 'y', 'p', 'p', 'p', 't', 'n', 't', 'n', 'n', 'n', 'n', 'u', 't', 'v', 'v', 'v', 'v', 'u', 'f', 'f', 'f', 'v', 'v', 'v', 'v', 'v', 'n', 'p', 'd', 'd', 'c', 'c', 'c', 't', 't', 'v', 'v', 'v', 'n', 'x', 'x', 'J', 'J', 'j', 'u', 'u', 'p', 'p', 'J', 'p', 'j', 'J', 'p', 'J', 'p', 'J', 'J', 'J', 'p', 'p', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'c', 'p', 'm', 'x', 'y', 'x', 'y', 'x', 'x', 'x', 'x', 'x', 'd', 'd', 'd', 'd', 'X', 'Y', 'Y', 'X', 'X', 'X', 'D', 'X', 'D', 'Y', 'Y', 'X', 'Y', 'X', 'Y', 'D', 'R', 'R', 'X', 'y', 'X', 'y', 'X', 'X', 'y', 'y', 'F', 'p', 'y', 'X', 'F', 'X', 'F', 'X', 'F', 'p', 'p', 'X', 'y', 'y', 'F', 'C', 'y', 'Q', 'T', 'T', 'p', 'p', 'C', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'f0', 'X', 'X', 'Y', 'X', 'F', 'F', 'C', 'y', 'T', 'f', 'T', 'T', 'F', 'X', 'X', 'Y', 'X', 'f0', 'C', 'T', 'T', 'T', 'p', 'X', 'y', 'X', 'X', 'X', 'X', 'y', 'y', 'y', 'X', 'y', 'X', 'X', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'X', 'X', 'Y', 'Y', 'X', 'x', 'x', 'X', 'Y', 'y', 'y', 'Y', 'X', 'Y', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j1', 'j2', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j1', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'V', 'V', 'T', 'P', 'R', 'T', 'a2', 'T', 'P', 'a3', 'b', 'a0', 'a0', 'a2', 'T', 'f', 'j', 'j', 'f', 'f', 'f', 'p', 'n', 'd', 'T', 'v', 'T', 'v', 'v', 'v', 'R', 'R', 'Q', 'Q', 'x', 'x', 't', 't', 'x', 'x']
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0055
Epoch: [3/10], Loss: 0.0040
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0042
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0042
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0099
Epoch: [2/10], Loss: 0.0068
Epoch: [3/10], Loss: 0.0055
Epoch: [4/10], Loss: 0.0048
Epoch: [5/10], Loss: 0.0043
Epoch: [6/10], Loss: 0.0039
Epoch: [7/10], Loss: 0.0036
Epoch: [8/10], Loss: 0.0034
Epoch: [9/10], Loss: 0.0032
Epoch: [10/10], Loss: 0.0030
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.69
{'__OVERALL__': 0.6947342275211128, 'NAME': 0.35600425079702447, 'STRING': 1.0, 'NUMBER': 0.9931338891613536, 'KEYWORD': 0.9558823529411765}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:670,KW_NAME:3
NAME_KW:118,KW_KW:65
NAME_STRING:444,KW_other:0
NAME_NUMBER:650
NAME_STRING_list:['m', 'm', 'a', 'a', 'a', 'a', 'x', 'x', 'W', 'T', 'X', 'W', 'T', 'T', 'X', 'W', 'p', 'p', 'p', 'p', 'p', 'p', 's', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'x', 'i', 'x', 'x', 'i', 'i', 'i', 'i', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'y', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'x', 'x', 'i', 'd', 'i', 'd', 'a', 'a', 'w', 'c', 'x', 'i', 'x', 'i', 'x', 'i', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'Y', 'Y', 'x', 'x', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'x', 'i', 'i', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'iw', 'ih', 'i', 'i', 's', 's', 's', 'I', 'x', 'I', 'I', 'O', 'I', 'X', 'P', 'I', 'I', 'I', 'I', 'X', 'Iw', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'Iw', 'Iw', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'p', 'C', 'x', 'X', 'I', 'C', 'Iw', 's', 't', 'Iw', 'I', 'C', 'Iw', 's', 'Iw', 't', 't', 'Iw', 't', 'T', 't', 'C', 'x', 'I', 'I', 'I', 'I', 'I', 'E', 'I', 'I', 'x', 'x', 'x', 'j', 'j', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'X', 'i', 't', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'v', 's', 'i', 'i', 's', 's', 's', 's', 'i', 'i', 'm', 'm', 's', 's', 's', 's', 's', 'c', 'c', 'c', 'i', 'c', 's', 'x', 's', 'J', 'J', 'J', 'i', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'c', 'c', 's', 's', 'm', 'm', 'm', 'm', 'x', 'x', 'd', 'X', 'X', 'k', 'i', 'i', 'i', 'X', 'i', 'C', 'C', 'C', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'C', 'T', 'i', 'i', 'i', 'X', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'x', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'a', 'a', 'a', 'C', 'l', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'A', 'A', 'C', 'A', 'x', 't', 't', 'x', 'x']
NAME_NUMBER_list:['m', 'm', 'T', 'W1', 'b1', 'W2', 'X', 'W', 'b', 'T', 'X', 'W', 'b', 'T', 'T', 'h', 'c', 'X', 'W', 'T', 'T', 'X', 'W', 'T', 'T', 'T', 'X', 'b', 'T', 'T', 'h', 'X', 'h', 'W', 'T', 'T', 'X', 'W', 'b', 'T', 'T', 'T', 'b', 'x', 'x', 'h0', 'h0', 'T', 'p', 'T', 'T', 'x', 'h0', 'b1', 'W2', 'd', 'T', 'x', 'x', 'b', 'b', 'b', 'T', 'T', 'b', 'T', 'b', 'j', 'x', 'j', 'j', 'j', 'j', 'j', 'j', 'x', 't', 'x', 't', 'x', 't', 't', 'm', 't', 't0', 't0', 'm', 'm', 'm', 'h', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'y', 'x', 'x', 'd', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'l', 'x', 'l', 'x', 'f', 'l', 'd', 'e', 'k', 'm', 'm', 'm', 'j', 'w', 'j', 'v', 'Y', 'Y', 'xx', 'xx', 'X', 'X', 'X', 'x', 'd', 'x', 'x', 'Y', 'Y', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y1', 'Y', 'Y', 'Y', 'Y', 'Y', 't', 't', 'f', 'x', 'x', 'z', 'x', 'd', 'x', 'y', 'x', 'X', 'X', 'f', 'X', 'f1', 'q', 'f1', 'X', 'f2', 'f1', 'f1', 'Q', 'x', 'q', 'q', 'q', 'q', 'F', 'F', 'T', 'Y', 'X', 'N', 'F', 'P', 'Q', 'N', 'O', 'q', 'p', 'p', 'Y', 'q', 'K', 'N', 'T', 'Y', 'X', 'N', 'P', 'Q', 'N', 'E', 'x', 'T', 'q', 'p', 'p', 'q', 'T', 'T0', 'T0', 'T0', 't0', 't0', 't0', 't3', 't3', 'T', 'T', 'T0', 'T0', 'T0', 't0', 't0', 't0', 'T', 'T', 'T0', 'T0', 'T0', 't0', 't0', 't3', 't0', 'T', 'T', 'T0', 't0', 't0', 't3', 't3', 'T0', 't0', 't0', 'T', 'x', 'X', 'B', 'x', 'B', 'D', 'X', 'X', 'p', 'P', 'B', 'p0', 'B', 'p0', 'B', 'p0', 'p0', 'p', 'B', 'D', 'P', 'B', 'Q', 'B', 'N', 'k', 'y', 'Y', 'B', 'D', 'x', 'B', 'D', 'c', 'n', 'N', 'n', 'n', 'D', 'D', 'N', 'p0', 'y', 'B', 'q0', 'x', 'B', 'y', 'x', 'n', 'p0', 'q0', 'n', 'N', 'N', 'y', 'P', 'B', 'B', 'x', 'B', 'B', 'n', 'n', 'k', 'n', 'n', 'D', 'c', 'X', 'Y', 'Q', 'X', 'P', 'Q', 'C', 'Y', 'X', 'N', 'C', 'P', 'Q', 'N', 'F', 'p', 'q', 'Y', 'X', 'p', 'q', 'N', 'p', 'q', 'P', 'Q', 'p', 'q', 'n', 'f', 'n', 'n', 'n', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'T', 'X', 'X', 'X', 'T', 'X', 'X', 'T', 'X', 'X', 'T', 'T', 'p', 'p', 'X', 'X', 'X', 'X', 'T', 'X', 'T', 'T', 'T', 'T', 'T', 'T', 'X', 'x', 'x', 'y', 'p', 't', 't', 't', 't', 'n', 'n', 't', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'u', 'u', 't', 't', 'u', 'v', 'v', 'v', 'v', 'v', 'v', 'u', 'n', 'u', 'v', 'v', 'v', 'v', 'n', 'n', 'm', 'd', 'n', 'n', 't', 't', 'c', 'v', 'v', 'v', 'n', 'n', 'n', 'x', 'J', 'J', 'j', 'j', 'u', 'p', 'J', 'j', 'p', 'j', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'p', 'm', 'x', 'y', 'x', 'x', 'x', 'd', 'd', 'd', 'X', 'Y', 'Y', 'X', 'X', 'X', 'D', 'k', 'k', 'D', 'Y', 'X', 'Y', 'k', 'X', 'D', 'D', 'R', 'X', 'y', 'X', 'y', 'X', 'X', 'y', 'y', 'D', 'D', 'D', 'X', 'X', 'q', 'q', 'F', 'p', 'q', 'q', 'X', 'X', 'y', 'y', 'F', 'q', 'C', 'y', 'Q', 'T', 'T', 'G', 'x', 'x', 'X', 'X', 'f', 'X', 'f0', 'X', 'Y', 'F', 'F', 'C', 'T', 'C', 'T', 'F', 'X', 'Y', 'f0', 'T', 'T', 'T', 'T', 'X', 'X', 'X', 'X', 'y', 'X', 'y', 'X', 'y', 'X', 'X', 'Y', 'X', 'X', 'Y', 'X', 'X', 'X', 'Y', 'x', 'y', 'X', 'Y', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j1', 'j2', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'V', 'V', 'T', 'T', 'T', 'T', 'b', 'a2', 'T', 'b', 'P', 'a0', 'a0', 'a2', 'T', 'l', 'j', 'j', 'p', 'p', 'n', 'd', 'd', 'T', 'v', 'T', 'v', 'R', 'R', 'B', 'Q', 'B', 'Q', 'B', 'x', 'f', 't', 't']
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0065
Epoch: [3/10], Loss: 0.0052
Epoch: [4/10], Loss: 0.0046
Epoch: [5/10], Loss: 0.0041
Epoch: [6/10], Loss: 0.0038
Epoch: [7/10], Loss: 0.0035
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.96

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.79
{'__OVERALL__': 0.7868852459016393, 'NAME': 0.5637619553666312, 'STRING': 1.0, 'NUMBER': 0.9818538499264345, 'KEYWORD': 1.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1061,KW_NAME:0
NAME_KW:26,KW_KW:68
NAME_STRING:385,KW_other:0
NAME_NUMBER:410
NAME_STRING_list:['m', 'm', 'm', 'm', 'm', 'a', 'a', 'a', 'x', 'x', 'T', 'W', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 's', 's', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'x', 'x', 'x', 'i', 'd', 'a', 'a', 'c', 'i', 'i', 'i', 'i', 'd', 'd', 't', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'x', 'x', 'i', 'i', 's', 's', 's', 'I', 'C', 'I', 'I', 'C', 'C', 'p', 'P', 'p', 'I', 'p', 'I', 'P', 'I', 'E', 'p', 'T', 'Iw', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'Iw', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'p', 'P', 'p', 'P', 'P', 'I', 'p', 'p', 'P', 'c', 'C', 'c', 'I', 'C', 'N', 'P', 'I', 'C', 'P', 'x', 'C', 'P', 'C', 'I', 'I', 'P', 'I', 'I', 'I', 'E', 'I', 'x', 'j', 'i', 'i', 'j', 'j', 'j', 'j', 'j', 'j', 'u', 's', 'p', 'p', 'p', 'g', 'i', 'p', 'p', 'p', 'p', 'n', 'u', 'i', 'u', 'i', 'i', 'i', 'i', 'u', 's', 'i', 'i', 's', 's', 's', 's', 'i', 'i', 's', 'm', 'm', 's', 's', 's', 's', 'm', 'i', 's', 't', 't', 'n', 'x', 's', 'J', 'p', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'i', 'c', 'c', 'm', 'm', 'm', 'm', 'd', 'i', 'i', 'i', 'X', 'X', 'X', 'i', 'p', 'C', 'C', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'C', 'i', 'i', 'T', 'i', 'i', 'i', 'T', 'i', 'i', 'i', 'i', 'T', 'g', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'a', 'P', 'a', 'a', 'C', 'l', 'l', 'i', 'i', 'i', 'i', 'i', 'i', 'j', 'i', 'i', 'i', 'p', 'p', 'a', 'i', 'i', 'i', 'i', 'T', 'A', 'A', 'C', 'A', 'C', 't', 't', 't', 't', 't', 't', 'x']
NAME_NUMBER_list:['T', 'W1', 'b1', 'W2', 'X', 'T', 'b', 'T', 'h', 'T', 'W', 'T', 'b', 'T', 'T', 'W', 'T', 'b', 'T', 'T', 'W', 'b', 'h', 'X', 'h', 'T', 'W', 'T', 'b', 'T', 'T', 'T', 'b', 'x', 'h0', 'h0', 't', 'T', 'x', 'h0', 'b1', 'x', 'b', 'b', 'T', 'T', 'b', 'T', 'b', 'j', 'x', 'j', 'j', 'x', 'x', 't', 't', 'm', 't0', 't0', 'y', 'x', 'y', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'l', 'x', 'l', 'x', 'l', 'x', 'i', 'k', 'e', 'e', 'k', 'm', 'm', 'm', 'j', 'j', 'v', 'x', 'x', 'Y', 'xx', 'X', 'Y', 'Y', 'x', 'Y', 'x', 'Y1', 'Y1', 'Y1', 'Y', 't', 'x', 'x', 'x', 'x', 'x', 'x', 'z', 'x', 'x', 'x', 'y', 'y', 'f1', 'f1', 'f1', 'f1', 'q', 'q', 'q', 'q', 'C', 'X', 'I', 'P', 'Q', 'q', 'K', 'N', 'C', 'X', 'I', 'p', 'q', 'T0', 'T0', 'T0', 't0', 't0', 't0', 't3', 't3', 'T0', 'I', 'T0', 'T0', 't0', 't0', 't0', 'T0', 'T0', 'T0', 't0', 't0', 't3', 't0', 't3', 'T0', 't0', 't0', 't3', 't3', 'T0', 't0', 't0', 'x', 'B', 'X', 'B', 'p0', 'B', 'p0', 'B', 'p0', 'p0', 'Q', 'B', 'N', 'k', 'B', 'c', 'n', 'N', 'n', 'n', 't', 'p0', 'q0', 'x', 'B', 'k', 'x', 'n', 'p0', 'q0', 'n', 'N', 'N', 'B', 'x', 'B', 'B', 'n', 'n', 'k', 'n', 'n', 'c', 'Q', 'Y', 'X', 'N', 'P', 'Q', 'N', 'p', 'q', 'X', 'p', 'p', 'Q', 'p', 'q', 'n', 'j', 'j', 'j', 'j', 't', 'T', 'X', 'X', 'X', 'T', 'T', 'g', 'T', 'p', 'p', 'T', 'T', 'T', 'T', 'T', 'X', 'x', 'y', 'x', 'y', 't', 't', 't', 'n', 'n', 'n', 'n', 'n', 'i', 'v', 'v', 'v', 'v', 'u', 'v', 'v', 'v', 'n', 'n', 'c', 'n', 't', 'c', 'v', 'v', 'v', 'n', 'n', 'J', 'J', 'j', 'j', 'J', 'J', 'J', 'j', 'J', 'p', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'x', 'y', 'x', 'y', 'x', 'x', 'x', 'X', 'X', 'X', 'D', 'k', 'X', 'X', 'Y', 'k', 'X', 'X', 'y', 'X', 'y', 'X', 'y', 'y', 'q', 'p', 'X', 'y', 'C', 'y', 'p', 'C', 'G', 'x', 'x', 'X', 'X', 'f0', 'X', 'C', 'C', 'X', 'X', 'X', 'f0', 'C', 'y', 'X', 'X', 'X', 'y', 'Y', 'x', 'X', 'Y', 'j', 'j', 'j', 'j', 'j1', 'j2', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'L', 'V', 'L', 'T', 'a2', 'b', 'b', 'a3', 'b', 'a0', 'a0', 'a2', 'a3', 'T', 'j', 'p', 'g1', 'n', 'v', 'B', 'h5f', 'h5f', 'h5f', 'h5f', 'x', 'x', 'x']
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0054
Epoch: [3/10], Loss: 0.0039
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0021
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0054
Epoch: [3/10], Loss: 0.0039
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0055
Epoch: [3/10], Loss: 0.0040
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0066
Epoch: [3/10], Loss: 0.0053
Epoch: [4/10], Loss: 0.0046
Epoch: [5/10], Loss: 0.0042
Epoch: [6/10], Loss: 0.0038
Epoch: [7/10], Loss: 0.0035
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.71
{'__OVERALL__': 0.706408345752608, 'NAME': 0.4059511158342189, 'STRING': 1.0, 'NUMBER': 0.9686120647376165, 'KEYWORD': 1.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:764,KW_NAME:0
NAME_KW:41,KW_KW:68
NAME_STRING:618,KW_other:0
NAME_NUMBER:459
NAME_STRING_list:['m', 'm', 'm', 'm', 'm', 'a', 'a', 'a', 'x', 'x', 'h', 'T', 'T', 'T', 'h', 'c', 'h', 'T', 'p', 't', 'T', 'p', 'x', 'p', 'p', 'p', 'p', 'p', 'p', 's', 'T', 's', 'x', 'x', 'a', 'a', 'a', 'T', 'a', 'a', 'i', 'i', 'i', 'i', 'j', 'i', 'j', 'j', 'j', 'j', 'x', 'i', 'i', 'i', 'i', 'm', 'h', 'm', 'h', 'm', 'm', 'h', 'x', 'x', 'x', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'l', 'x', 'x', 'x', 'x', 'i', 'i', 'a', 'e', 'k', 'k', 'k', 'k', 'k', 'm', 'm', 'j', 'k', 'c', 'x', 'i', 'x', 'i', 'x', 'i', 'i', 'x', 'x', 'x', 'x', 't', 't', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'S', 'i', 'i', 'S', 'S', 'S', 'S', 's', 's', 's', 'I', 'F', 'I', 'I', 'I', 'S', 'P', 'S', 'X', 'p', 'P', 'p', 'K', 'I', 'N', 'p', 'T', 'I', 'I', 'P', 'S', 'S', 'I', 'E', 'S', 'X', 'p', 'p', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'T', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'p', 'P', 'P', 'P', 'I', 'p', 'p', 'P', 'N', 'c', 'C', 'x', 'X', 'I', 'N', 'n', 'n', 's', 's', 's', 'N', 'P', 'K', 'x', 'n', 'n', 'I', 'N', 'K', 'P', 'n', 'n', 'n', 'k', 'n', 's', 's', 's', 's', 's', 's', 's', 'x', 'C', 'S', 'X', 'P', 'C', 'N', 'C', 'S', 'P', 'N', 'I', 'p', 'I', 'p', 'N', 'p', 'P', 'p', 'n', 'I', 'I', 'I', 'I', 'E', 'I', 'E', 's', 's', 's', 's', 's', 's', 'x', 'x', 'j', 'j', 'j', 'j', 'i', 'i', 'j', 'j', 'i', 'i', 'u', 's', 's', 'j', 'j', 'X', 'X', 'X', 'T', 'p', 'p', 'T', 'p', 'p', 'X', 'h', 'h', 'T', 'h', 'T', 'X', 'X', 'T', 'X', 'X', 'i', 'p', 'p', 'p', 'p', 'p', 'p', 's', 's', 's', 'n', 'n', 'n', 'n', 'n', 'n', 'i', 'i', 'i', 'i', 'i', 'i', 'v', 'i', 'i', 'i', 'n', 'v', 'k', 'v', 'k', 'v', 'k', 's', 'i', 's', 's', 's', 's', 's', 's', 's', 's', 'i', 'i', 's', 's', 's', 'n', 'm', 'm', 's', 's', 's', 's', 's', 's', 's', 'm', 't', 's', 'i', 's', 's', 's', 's', 's', 's', 's', 's', 's', 't', 't', 'n', 's', 'x', 'x', 's', 's', 's', 'J', 'j', 'j', 'J', 'J', 'J', 'u', 'p', 'p', 'j', 'p', 'j', 'J', 'p', 'J', 'J', 'J', 'J', 'p', 'p', 'p', 'i', 'i', 'J', 'J', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'J', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'p', 'p', 's', 's', 's', 's', 's', 's', 'm', 'm', 'm', 'm', 'x', 'X', 'X', 'k', 'X', 'k', 'X', 'i', 'i', 'i', 'X', 'X', 'X', 'p', 'i', 'p', 'C', 'p', 'p', 'C', 'x', 'x', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'C', 'T', 'T', 'T', 'i', 'i', 'i', 'i', 'i', 'i', 'g', 'i', 'i', 'i', 'i', 'T', 'T', 'T', 'T', 'i', 'T', 'i', 'i', 'i', 'i', 'T', 'i', 'i', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'x', 'X', 'j', 'j', 'j', 'j', 'j', 'i', 'i', 'i', 'i', 'L', 'P', 'T', 'P', 'a', 'C', 'C', 'l', 'i', 'i', 'i', 'i', 'i', 'i', 'j', 'j', 'i', 'i', 'i', 'p', 'p', 'p', 'i', 'i', 'i', 'i', 'T', 'T', 'A', 'C', 'A', 'C', 'x', 'x', 't', 't', 't', 't', 't', 't', 'x', 'x']
NAME_NUMBER_list:['T', 'b1', 'W2', 'X', 'X', 'X', 'h', 'X', 'X', 'X', 'X', 'h', 'X', 'X', 'x', 'h0', 'h0', 'h0', 'b1', 'X', 'X', 'd', 'd', 'b', 'T', 'j', 'x', 'k', 'x', 'x', 'x', 'x', 'x', 't', 'f', 't0', 't0', 'f', 'f', 'f', 'x', 'x', 'y', 'x', 'x', 'y', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'l', 'f', 'd', 'd', 'k', 'k2e', 'k', 'f', 'k', 'k', 'k', 'k', 'k2e', 'k', 'm', 'j', 'v', 'w', 'Y', 'Y', 'xx', 'Y', 'Y', 'k', 'X', 'Y', 'x', 'd', 'd', 'd', 'x', 'g', 'g', 'g', 'Y', 'Y', 'x', 'Y1', 'x', 'Y1', 'Y', 'f', 'x', 'f', 'f', 'x', 'x', 'z', 'x', 'x', 'd', 'x', 'X', 'f', 'X', 'f1', 'f2', 'f2', 'f1', 'f2', 'f1', 'x', 'Q', 'x', 'q', 'q', 'q', 'q', 'x', 'F', 'F', 'K', 'F', 'Y', 'X', 'N', 'K', 'F', 'K', 'Q', 'N', 'O', 'Q', 'R', 'q', 'q', 'Y', 'X', 'N', 'K', 'Q', 'N', 'E', 'K', 'U', 'x', 'R', 'K', 'E', 'q', 'K', 'T0', 'T0', 'T0', 't0', 't3', 'O', 't0', 't0', 't3', 't3', 'O', 'T0', 'T0', 'T0', 't0', 'O', 'O', 't0', 'O', 't0', 'O', 'O', 'O', 'F', 'T0', 'T0', 'T0', 't0', 'O', 't0', 't0', 'T0', 't0', 't0', 'T0', 't0', 'O', 'O', 't0', 'x', 'X', 'D', 'X', 'X', 'p0', 'B', 'p0', 'B', 'p0', 'p0', 'B', 'Q', 'B', 'D', 'D', 'K', 'D', 'D', 'k', 'K', 'k', 'y', 'D', 'x', 'B', 'D', 'c', 'n', 'y', 'x', 't', 'K', 'p0', 'B', 'q0', 'x', 'B', 'k', 'k', 'y', 'O', 'p0', 'q0', 'D', 'D', 'N', 'D', 'D', 'K', 'D', 'K', 'U', 'D', 'D', 'y', 'x', 'B', 'B', 'E', 'k', 'K', 'k', 'c', 'Q', 'Y', 'X', 'R', 'K', 'K', 'Q', 'q', 'Y', 'X', 'q', 'q', 'Q', 'q', 'K', 'F', 'F', 'f', 'f', 'x', 'n', 'n', 'n', 't', 'T', 'X', 'X', 'X', 'g', 'g', 'g', 'X', 'X', 'X', 'X', 'T', 'y', 'x', 'x', 'y', 't', 't', 't', 'n', 'n', 'n', 'n', 'u', 'u', 'u', 'v', 'v', 'v', 'u', 'u', 'f', 'k', 'k', 'k', 'v', 'n', 'd', 'n', 'v', 'n', 'n', 'J', 'u', 'J', 'u', 'u', 'J', 'x', 'y', 'x', 'x', 'x', 'x', 'd', 'd', 'X', 'Y', 'X', 'X', 'k', 'k', 'D', 'X', 'k', 'k', 'D', 'D', 'R', 'X', 'y', 'X', 'X', 'X', 'F', 'q', 'q', 'F', 'q', 'X', 'y', 'F', 'F', 'C', 'y', 'G', 'G', 'G', 'X', 'X', 'X', 'f0', 'X', 'X', 'F', 'F', 'C', 'f', 'C', 'G', 'F', 'g', 'X', 'X', 'f0', 'C', 'G', 'g', 'G', 'G', 'g', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'Y', 'X', 'X', 'x', 'X', 'j', 'j', 'j1', 'j2', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'L', 'V', 'a2', 'a3', 'a0', 'a0', 'a2', 'a3', 'f', 'f', 'l', 'f', 'f', 'g1', 'g1', 'g', 'n', 'v', 'R', 'R', 'Q', 'R', 'B', 'Q', 'R', 'B', 'h5f', 'h5f', 'h5f', 'h5f', 'h5f', 'f']
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0050
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0051
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0085
Epoch: [2/10], Loss: 0.0053
Epoch: [3/10], Loss: 0.0038
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0094
Epoch: [2/10], Loss: 0.0063
Epoch: [3/10], Loss: 0.0051
Epoch: [4/10], Loss: 0.0044
Epoch: [5/10], Loss: 0.0040
Epoch: [6/10], Loss: 0.0037
Epoch: [7/10], Loss: 0.0034
Epoch: [8/10], Loss: 0.0032
Epoch: [9/10], Loss: 0.0030
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.76
{'__OVERALL__': 0.7573273720814705, 'NAME': 0.5010626992561105, 'STRING': 1.0, 'NUMBER': 0.9813634134379597, 'KEYWORD': 1.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:943,KW_NAME:0
NAME_KW:9,KW_KW:68
NAME_STRING:659,KW_other:0
NAME_NUMBER:271
NAME_STRING_list:['m', 'm', 'a', 'a', 'a', 'a', 'x', 'x', 'T', 'X', 'h', 'c', 'X', 'c', 'X', 'h', 'X', 'X', 'X', 'h', 'X', 'h', 'X', 'X', 'h', 'x', 'p', 'p', 'x', 'p', 'p', 'p', 'p', 'p', 'p', 'X', 'X', 's', 's', 'x', 'x', 'a', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'i', 'x', 'i', 'j', 'x', 'x', 'x', 'x', 'i', 'i', 'i', 'i', 'm', 'm', 'm', 'm', 'h', 'm', 'h', 'm', 'h', 'm', 'm', 'm', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'l', 'x', 'x', 'x', 'x', 'i', 'd', 'i', 'd', 'a', 'a', 'e', 'e', 'j', 'v', 'c', 'x', 'i', 'x', 'i', 'x', 'i', 'i', 'x', 'x', 'X', 'X', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 't', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'x', 'i', 'i', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'd', 'd', 'x', 'x', 'X', 'i', 'i', 'S', 'X', 'S', 'X', 'X', 'x', 'S', 'x', 'S', 's', 'I', 'x', 'x', 'C', 'I', 'I', 'X', 'I', 'S', 'P', 'S', 'X', 'Q', 'p', 'P', 'p', 'I', 'p', 'I', 'E', 'X', 'I', 'P', 'E', 'C', 'S', 'x', 'x', 'S', 'I', 'E', 'S', 'X', 'Q', 'p', 'E', 'p', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'x', 'X', 'X', 'p', 'P', 'I', 'P', 'C', 'N', 'c', 'c', 'c', 'x', 'x', 'X', 'I', 'x', 'c', 's', 's', 's', 's', 't', 'C', 'K', 'N', 'P', 'x', 'x', 'O', 'n', 'I', 'E', 'C', 'K', 'C', 'C', 'P', 'x', 'E', 'c', 'c', 's', 's', 's', 's', 's', 's', 'x', 'x', 'C', 'X', 'P', 'C', 'X', 'C', 'S', 'P', 'I', 'E', 'p', 'X', 'I', 'p', 'p', 'P', 'Q', 'p', 'I', 'E', 'I', 'I', 'I', 'E', 'I', 'E', 's', 's', 's', 'x', 'x', 'j', 'j', 'i', 'i', 'i', 'i', 'u', 'u', 's', 's', 'j', 'T', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'p', 'p', 'p', 'g', 'X', 'X', 'X', 'X', 'X', 'X', 'h', 'X', 'X', 'X', 'X', 'i', 'x', 'x', 'x', 'p', 'p', 'p', 'p', 'p', 'p', 'n', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 's', 'i', 's', 's', 'i', 'i', 's', 's', 'm', 'm', 's', 'i', 's', 's', 's', 's', 's', 's', 's', 'x', 'x', 's', 'J', 'j', 'J', 'J', 'J', 'u', 'p', 'j', 'p', 'J', 'p', 'J', 'J', 'J', 'i', 'i', 'i', 'i', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'J', 'i', 'J', 'i', 'J', 'J', 'J', 'p', 's', 'm', 'm', 'x', 'x', 'x', 'x', 'x', 'x', 'd', 'X', 'X', 'X', 'X', 'X', 'X', 'i', 'i', 'i', 'X', 'D', 'X', 'X', 'p', 'i', 'C', 'C', 'p', 'C', 'p', 'C', 'C', 'x', 'x', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'C', 'C', 'i', 'i', 'i', 'X', 'X', 'X', 'i', 'i', 'i', 'g', 'i', 'T', 'i', 'i', 'i', 'i', 'T', 'i', 'T', 'G', 'i', 'i', 'i', 'i', 'g', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'X', 'X', 'X', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'X', 'X', 'j', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'T', 'a', 'P', 'a', 'C', 'C', 'l', 'i', 'i', 'i', 'i', 'i', 'i', 'j', 'i', 'i', 'i', 'p', 'p', 'p', 'a', 'i', 'i', 'i', 'i', 'i', 'A', 'A', 'C', 'A', 'C', 'x', 'x', 'x', 'x']
NAME_NUMBER_list:['m', 'm', 'b1', 'h', 'h', 'h0', 'h0', 'h0', 'b1', 'd', 'd', 'b', 'k', 't', 'm', 't0', 't0', 'm', 'm', 'f', 'x', 'X', 'X', 'X', 'l', 'd', 'k', 'k2e', 'k', 'k', 'k', 'k', 'k', 'k', 'm', 'm', 'm', 'j', 'k', 'k', 'd', 'd', 'd', 'g', 'g', 'g', 'z', 'z', 'd', 'f1', 'f2', 'f2', 'f1', 'f2', 'f1', 'q', 'q', 'q', 'q', 'K', 'N', 'F', 'K', 'N', 'q', 'q', 'F', 'K', 'N', 'N', 'K', 'N', 'U', 'K', 'q', 'q', 'U', 'T0', 'T0', 't0', 't0', 't3', 'T0', 'T0', 't0', 'T0', 'T0', 't0', 'T0', 't0', 'T0', 'B', 'D', 'p0', 'B', 'p0', 'B', 'P', 'p0', 'p0', 'p', 'B', 'B', 'Q', 'D', 'D', 'K', 'k', 'K', 'D', 'B', 'D', 'c', 'n', 'N', 'n', 'n', 'D', 't', 'D', 'p0', 'q0', 'k', 'K', 'k', 'n', 'p0', 'D', 'D', 'N', 'D', 'D', 'N', 'D', 'D', 'K', 'U', 'D', 'D', 'K', 'B', 'n', 'n', 'k', 'K', 'n', 'k', 'n', 'D', 'c', 'N', 'N', 'K', 'K', 'Q', 'N', 'q', 'q', 'N', 'q', 'n', 'k', 'pq', 'x', 'n', 'n', 't', 'g', 'g', 'X', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'v', 'n', 'f', 'k', 'k', 'k', 'n', 'n', 'p', 'd', 'n', 'n', 'n', 'n', 'J', 'u', 'u', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'm', 'm', 'y', 'd', 'X', 'X', 'k', 'k', 'D', 'X', 'k', 'D', 'D', 'D', 'R', 'X', 'X', 'X', 'q', 'G', 'G', 'X', 'f0', 'C', 'f0', 'C', 'g', 'X', 'X', 'j1', 'j2', 'j2', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'L', 'V', 'L', 'b', 'b', 'a2', 'b', 'b', 'a3', 'a0', 'a0', 'a2', 'a3', 'l', 'g1', 'g', 'n', 'v', 'LQ', 'Q', 'B', 'B', 'h5f', 'h5f', 'h5f']
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0047
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0047
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0060
Epoch: [3/10], Loss: 0.0048
Epoch: [4/10], Loss: 0.0042
Epoch: [5/10], Loss: 0.0038
Epoch: [6/10], Loss: 0.0035
Epoch: [7/10], Loss: 0.0033
Epoch: [8/10], Loss: 0.0031
Epoch: [9/10], Loss: 0.0029
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.73
{'__OVERALL__': 0.7337307501241928, 'NAME': 0.5276301806588736, 'STRING': 1.0, 'NUMBER': 0.9112309955860716, 'KEYWORD': 0.9705882352941176}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:993,KW_NAME:0
NAME_KW:18,KW_KW:66
NAME_STRING:654,KW_other:2
NAME_NUMBER:217
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'a', 'x', 'x', 'X', 'h', 'c', 'W', 'U', 'b', 'h', 'c', 'h', 'W', 'U', 'h', 'W', 'U', 'p', 'p', 'p', 'p', 'p', 'X', 's', 'x', 'e', 'e', 'a', 'a', 'a', 'a', 'b', 'i', 'i', 'i', 'i', 'j', 'i', 'j', 'j', 'j', 'j', 't', 't', 'i', 'i', 'i', 'i', 'm', 'm', 'm', 'f', 'f', 'm', 'm', 'f', 'h', 'm', 'm', 'h', 'm', 'm', 'h', 'm', 'f', 'f', 'm', 'm', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'f', 'f', 'l', 'x', 'x', 'x', 'x', 'i', 'i', 'd', 'a', 'a', 'e', 'f', 'f', 'k', 'k', 'k', 'e', 'j', 'j', 'v', 'w', 'i', 'x', 'i', 'i', 'i', 'x', 'x', 'd', 'd', 'x', 'x', 'x', 'g', 'g', 'x', 'x', 'f', 't', 't', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'f', 'i', 'i', 'i', 'x', 'x', 'x', 'x', 'f', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'd', 'd', 'f', 'i', 'X', 'x', 'S', 'Q', 'S', 'I', 'x', 'C', 'I', 'K', 'I', 'F', 'X', 'I', 'C', 'S', 'P', 'Q', 'X', 'p', 'P', 'p', 'K', 'I', 'N', 'p', 'I', 'E', 'X', 'I', 'P', 'Q', 'E', 'C', 'S', 'x', 'S', 'I', 'E', 'X', 'p', 'E', 'p', 'U', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'F', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'O', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'F', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'x', 'X', 'p', 'P', 'I', 'p', 'p', 'P', 'C', 'K', 'Iw', 'C', 'N', 'c', 'C', 'c', 'c', 'D', 'x', 'x', 'I', 'c', 'C', 'n', 'c', 'n', 's', 't', 'C', 'K', 'N', 'P', 'k', 'x', 'n', 'O', 'n', 'I', 'E', 'C', 'N', 'K', 'C', 'K', 'D', 'C', 'K', 'P', 'E', 'n', 'c', 'c', 'n', 'n', 'k', 'n', 's', 'c', 'c', 'x', 'C', 'P', 'C', 'N', 'C', 'S', 'P', 'N', 'I', 'E', 'p', 'X', 'I', 'p', 'p', 'P', 'Q', 'p', 'n', 'I', 'F', 'E', 'I', 'I', 'E', 'E', 'F', 'I', 'E', 'I', 'E', 'Uw', 'x', 'x', 'x', 'j', 'j', 'j', 'j', 'i', 'i', 'j', 'j', 'i', 'i', 'u', 'u', 's', 's', 'j', 'j', 'T', 'X', 'X', 'X', 'p', 'p', 'p', 'g', 'h', 'X', 'X', 'X', 'i', 'x', 'x', 'p', 'p', 'p', 'p', 'p', 'p', 'n', 'n', 'n', 'n', 'n', 'i', 'i', 'i', 'i', 'u', 'i', 'v', 'i', 'i', 'v', 'i', 'v', 'u', 'n', 'f', 'k', 's', 'i', 'i', 'i', 'i', 's', 'm', 'm', 's', 's', 'p', 'm', 't', 'i', 'c', 's', 's', 's', 's', 's', 's', 'n', 's', 'x', 'x', 'J', 'J', 'j', 'j', 'J', 'J', 'u', 'p', 'p', 'J', 'j', 'p', 'j', 'J', 'p', 'J', 'J', 'p', 'p', 'p', 'J', 'i', 'i', 'J', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'i', 'J', 'p', 'p', 'p', 'p', 'p', 's', 'm', 'm', 'm', 'x', 'x', 'x', 'f', 'x', 'f', 'd', 'X', 'X', 'D', 'X', 'i', 'i', 'i', 'X', 'D', 'p', 'i', 'p', 'p', 'C', 'F', 'C', 'p', 'C', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'C', 'F', 'C', 'f', 'C', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'f', 'g', 'i', 'C', 'i', 'i', 'i', 'i', 'G', 'g', 'i', 'G', 'i', 'i', 'i', 'i', 'g', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'x', 'x', 'X', 'X', 'j', 'j', 'j', 'j', 'j', 'j', 'i', 'j', 'i', 'i', 'i', 'i', 'i', 'i', 'L', 'L', 'P', 'T', 'P', 'T', 'P', 'a', 'P', 'C', 'C', 'f', 'l', 'i', 'i', 'i', 'i', 'i', 'i', 'j', 'i', 'f', 'i', 'i', 'p', 'p', 'a', 'i', 'i', 'i', 'i', 'g', 'i', 'v', 'c', 'c', 'A', 'C', 'Q', 'A', 'C', 'A', 'C', 'x', 'f', 'f', 'x']
NAME_NUMBER_list:['W1', 'b1', 'h0', 'h0', 'h0', 'b1', 'X', 'd', 'd', 'b', 'x', 'x', 'x', 'f', 't0', 't0', 'f', 'f', 'x', 'x', 'x', 'X', 'X', 'X', 'd', 'k', 'k2e', 'k', 'k', 'k', 'k', 'm', 'k', 'k', 'd', 'Y1', 'f', 'x', 'z', 'd', 'd', 'x', 'x', 'f', 'f1', 'f2', 'f1', 'f2', 'f1', 'q', 'q', 'q', 'F', 'N', 'F', 'K', 'N', 'O', 'q', 'Q', 'q', 'Q', 'F', 'q', 'N', 'K', 'N', 'U', 'q', 'Q', 'q', 'T0', 'T0', 't0', 'T0', 'T0', 'F', 'T0', 'T0', 'T0', 't0', 'T0', 'D', 'p0', 'p0', 'B', 'P', 'p0', 'F', 'B', 'D', 'Q', 'D', 'k', 'K', 'D', 'n', 'N', 'D', 'D', 'p0', 'x', 'k', 'K', 'p0', 'N', 'D', 'U', 'D', 'k', 'K', 'D', 'Q', 'X', 'K', 'K', 'Q', 'F', 'q', 'q', 'N', 'q', 'q', 'K', 'F', 'pq', 'g', 'p', 'X', 'X', 'n', 'n', 'n', 'n', 'v', 'f', 'k', 'k', 'k', 'n', 'n', 'p', 'd', 'n', 'n', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'm', 'd', 'D', 'k', 'D', 'k', 'D', 'X', 'X', 'X', 'X', 'q', 'X', 'F', 'F', 'q', 'q', 'G', 'G', 'x', 'f', 'f0', 'F', 'F', 'g', 'X', 'X', 'X', 'j1', 'j2', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j1', 'j2', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'V', 'b', 'b', 'a2', 'a3', 'a0', 'a0', 'a2', 'a3', 'f', 'f', 'g1', 'g1', 'n', 'd', 'Q', 'B', 'Q', 'h5f', 'h5f', 'f']
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0047
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0014
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0047
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0046
Epoch: [4/10], Loss: 0.0040
Epoch: [5/10], Loss: 0.0036
Epoch: [6/10], Loss: 0.0034
Epoch: [7/10], Loss: 0.0032
Epoch: [8/10], Loss: 0.0030
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.89
{'__OVERALL__': 0.8859910581222057, 'NAME': 0.798087141339001, 'STRING': 1.0, 'NUMBER': 0.9641981363413438, 'KEYWORD': 0.9117647058823529}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1502,KW_NAME:6
NAME_KW:17,KW_KW:62
NAME_STRING:223,KW_other:0
NAME_NUMBER:140
NAME_STRING_list:['m', 'a', 'X', 'h', 'U', 'X', 'h', 'U', 'X', 'h', 'U', 's', 'a', 'a', 'a', 'i', 'j', 'i', 'j', 'j', 'i', 'i', 'm', 'm', 'm', 'm', 'm', 'm', 'h', 'm', 'm', 'm', 'f', 'd', 'a', 'a', 'j', 'f', 'i', 'i', 'i', 'i', 'i', 'x', 'R', 'f', 'F', 'S', 'P', 'p', 'P', 'p', 'F', 'p', 'I', 'P', 'S', 'E', 'p', 'E', 'p', 'I', 'I', 'p', 'P', 'P', 'N', 'I', 'n', 'n', 'O', 'I', 'E', 'N', 'N', 'P', 'E', 'n', 'n', 'n', 'n', 'c', 'C', 'N', 'S', 'P', 'N', 'p', 'p', 'P', 'p', 'F', 'I', 'E', 'I', 'E', 'f', 'j', 'j', 'j', 'j', 'p', 'p', 'X', 'x', 'p', 'p', 'n', 'n', 'n', 'n', 'n', 'i', 'i', 'i', 'i', 'u', 'f', 'i', 'i', 's', 'J', 'j', 'J', 'J', 'J', 'j', 'J', 'J', 'J', 'J', 'p', 'p', 'i', 'J', 'J', 'i', 'J', 'i', 'J', 'J', 'J', 'J', 'i', 'J', 'J', 'J', 'J', 'J', 'J', 'p', 'p', 'm', 'm', 'x', 'f', 'X', 'X', 'F', 'X', 'F', 'i', 'F', 'p', 'F', 'p', 'p', 'i', 'i', 'i', 'i', 'f', 'i', 'i', 'i', 'f', 'i', 'i', 'g', 'i', 'i', 'i', 'i', 'g', 'i', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'y', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'i', 'P', 'P', 'a', 'C', 'i', 'p', 'Q', 'R', 'A', 'A', 'f']
NAME_NUMBER_list:['b1', 'h0', 'h0', 'd', 'x', 'm', 't0', 't0', 'm', 'm', 'f', 'X', 'X', 'X', 'X', 'f', 'k', 'k', 'k', 'd', 'g', 'Y1', 'Y1', 'f', 'f', 'f', 'd', 'x', 'f1', 'f2', 'f1', 'f2', 'f1', 'f2', 'f1', 'q', 'q', 'q', 'K', 'F', 'Q', 'q', 'Q', 'N', 'K', 'Q', 'T0', 'T0', 'T0', 'x', 'p0', 'p0', 'p0', 'Q', 'k', 'K', 'x', 'n', 'N', 't', 'p0', 'q0', 'x', 'k', 'K', 'p0', 'x', 'k', 'K', 'X', 'K', 'Q', 'N', 'Q', 'pq', 'x', 'X', 'g', 'x', 'p', 'n', 'n', 'n', 'n', 'k', 'k', 'k', 'v', 'n', 'p', 'n', 'n', 'x', 'm', 'x', 'd', 'k', 'k', 'k', 'X', 'X', 'X', 'G', 'f', 'f0', 'X', 'F', 'X', 'f0', 'X', 'X', 'X', 'X', 'X', 'X', 'j1', 'j1', 'j1', 'j2', 'j1', 'j1', 'j2', 'j1', 'j2', 'j1', 'j2', 'j1', 'b', 'a3', 'a0', 'a0', 'a3', 'f', 'f', 'g1', 'g', 'n', 'Q', 'h5f', 'f']
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0045
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0024
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0016
Epoch: [7/10], Loss: 0.0013
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0045
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0024
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0016
Epoch: [7/10], Loss: 0.0014
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0032
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0039
Epoch: [5/10], Loss: 0.0036
Epoch: [6/10], Loss: 0.0033
Epoch: [7/10], Loss: 0.0031
Epoch: [8/10], Loss: 0.0029
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0026
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.85
{'__OVERALL__': 0.8522106308991555, 'NAME': 0.6971307120085016, 'STRING': 0.972972972972973, 'NUMBER': 0.9926434526728789, 'KEYWORD': 0.8676470588235294}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1312,KW_NAME:8
NAME_KW:80,KW_KW:59
NAME_STRING:189,KW_other:1
NAME_NUMBER:301
NAME_STRING_list:['a', 'a', 'a', 'X', 'h', 'X', 'X', 'h', 'W', 'h', 't', 'T', 'p', 'p', 'p', 's', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'm', 'm', 'h', 'm', 'm', 'x', 'x', 'a', 'a', 'i', 'i', 'x', 'R', 'S', 'I', 'C', 'I', 'C', 'F', 'R', 'S', 'P', 'p', 'F', 'p', 'I', 'P', 'R', 'S', 'I', 'C', 'E', 'p', 'E', 'p', 'I', 'I', 'p', 'N', 'I', 'n', 'n', 'K', 'O', 'I', 'E', 'n', 'n', 'n', 'n', 's', 's', 'N', 'S', 'N', 'I', 'p', 'P', 'p', 'n', 'I', 'E', 'I', 'E', 'I', 'E', 'f', 'j', 'p', 'X', 'i', 'x', 'p', 'n', 'i', 'i', 'u', 'i', 'i', 'm', 'm', 't', 'i', 's', 'J', 'i', 'i', 'i', 'i', 'i', 'J', 'J', 'J', 'J', 'p', 'm', 'm', 'x', 'x', 'X', 'i', 'X', 'F', 'i', 'C', 'F', 'C', 'i', 'i', 'X', 'C', 'f', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'x', 'i', 'P', 'a', 'C', 'f', 'l', 'i', 'i', 'i', 'i', 'R', 'A', 'R', 'A', 'f', 'f']
NAME_NUMBER_list:['x', 'b1', 'W', 'X', 'W', 'h0', 'h0', 'b1', 'd', 'k', 'm', 't0', 't0', 'h', 'm', 'h', 'm', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'f', 'x', 'x', 'k', 'e', 'k', 'k', 'k', 'j', 'k', 'v', 'k', 'x', 'd', 'd', 'd', 'g', 'g', 'Y1', 'x', 'Y1', 't', 't', 'i', 'f', 'f', 'x', 'x', 'x', 'f', 'x', 'x', 'x', 'z', 'x', 'd', 'x', 'f1', 'f2', 'f1', 'f2', 'f1', 'f2', 'q', 'q', 'x', 'F', 'K', 'C', 'X', 'I', 'C', 'F', 'K', 'Q', 'q', 'Q', 'p', 'P', 'q', 'Q', 'K', 'N', 'q', 'X', 'I', 'K', 'Q', 'E', 'C', 'q', 'Q', 'q', 'T0', 't0', 'T0', 'I', 'T0', 'I', 'T0', 't0', 'T0', 'x', 'X', 'D', 'p', 'P', 'p0', 'p0', 'p0', 'p', 'P', 'Q', 'D', 'D', 'C', 'K', 'D', 'D', 'C', 'c', 'k', 'K', 'D', 'x', 'x', 'n', 'N', 'D', 't', 'D', 'p0', 'P', 'q0', 'x', 'Q', 'k', 'K', 'k', 'D', 'D', 'N', 'D', 'D', 'N', 'K', 'D', 'D', 'K', 'D', 'D', 'K', 'P', 'B', 'x', 'Q', 'k', 'K', 'D', 'C', 'X', 'C', 'R', 'K', 'K', 'P', 'Q', 'p', 'q', 'X', 'q', 'N', 'p', 'q', 'Q', 'q', 'K', 'pq', 'x', 'x', 'x', 't', 'p', 'g', 'p', 'g', 'p', 'T', 'T', 'x', 'p', 'p', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'i', 'i', 'n', 'f', 'v', 'k', 'k', 'v', 'k', 'k', 'v', 'k', 'k', 'i', 'i', 'n', 'n', 's', 'p', 'd', 'n', 'v', 'n', 'n', 'p', 'p', 'p', 'p', 'p', 'p', 'm', 'd', 'd', 'k', 'k', 'k', 'k', 'k', 'D', 'X', 'X', 'X', 'X', 'C', 'Q', 'i', 'i', 'f0', 'F', 'C', 'i', 'i', 'g', 'X', 'X', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'x', 'X', 'X', 'j1', 'j1', 'j1', 'j1', 'j2', 'j1', 'j2', 'j1', 'V', 'L', 'P', 'a3', 'a0', 'a0', 'a2', 'a3', 'C', 'f', 'i', 'i', 'i', 'f', 'p', 'i', 'g1', 'n', 'c', 'Q', 'Q', 'h5f', 'h5f']
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0051
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0050
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0060
Epoch: [3/10], Loss: 0.0047
Epoch: [4/10], Loss: 0.0041
Epoch: [5/10], Loss: 0.0037
Epoch: [6/10], Loss: 0.0034
Epoch: [7/10], Loss: 0.0031
Epoch: [8/10], Loss: 0.0029
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0026
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.86
{'__OVERALL__': 0.8559364133134625, 'NAME': 0.7130712008501594, 'STRING': 1.0, 'NUMBER': 0.9872486512996567, 'KEYWORD': 0.7941176470588235}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1342,KW_NAME:13
NAME_KW:78,KW_KW:54
NAME_STRING:233,KW_other:1
NAME_NUMBER:229
NAME_STRING_list:['m', 'a', 'a', 'a', 'X', 'h', 'X', 'h', 'X', 'X', 'h', 'p', 'x', 'a', 'a', 'i', 'x', 'x', 't', 'i', 'm', 'm', 'm', 'm', 'm', 'm', 'h', 'm', 'm', 'm', 'x', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'x', 'x', 'a', 'f', 'k', 'k', 'x', 'x', 'x', 'x', 'x', 'x', 'i', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'd', 'x', 'x', 'C', 'I', 'C', 'R', 'S', 'P', 'p', 'C', 'R', 'x', 'I', 'C', 'E', 'p', 'I', 'x', 'p', 'P', 'C', 'C', 'C', 'x', 'C', 'n', 'c', 'x', 'C', 'C', 'C', 'x', 'c', 'c', 'C', 'x', 'x', 'N', 'C', 'S', 'N', 'P', 'Q', 'p', 'f', 'x', 'x', 'X', 'T', 'p', 'X', 'X', 'X', 'X', 'x', 'p', 'n', 'n', 'n', 'i', 'i', 'v', 'v', 'i', 'u', 'i', 'v', 's', 'i', 's', 's', 'c', 'c', 't', 'c', 'c', 'i', 'i', 'i', 'c', 'c', 'm', 'x', 'x', 'x', 'x', 'X', 'X', 'D', 'X', 'i', 'X', 'X', 'i', 'C', 'q', 'q', 'i', 'i', 'X', 'X', 'C', 'C', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'x', 'x', 'X', 'i', 'V', 'a', 'b', 'C', 'C', 'i', 'i', 'i', 'i', 'c', 'R', 'A', 'R', 'A', 'f', 'f']
NAME_NUMBER_list:['x', 'b1', 'x', 'h0', 'b1', 'd', 'x', 'x', 'k', 'm', 'm', 'h', 'm', 'x', 'x', 'f', 'k', 'k', 'k', 'k', 'k', 'm', 'm', 'k', 'c', 'k', 'd', 'd', 'd', 'g', 'g', 'Y1', 't', 't', 'f', 'x', 'x', 'x', 'x', 'd', 'f1', 'f2', 'f1', 'X', 'f2', 'f1', 'f2', 'q', 'q', 'q', 'C', 'X', 'I', 'C', 'F', 'K', 'q', 'q', 'Q', 'p', 'P', 'q', 'Q', 'K', 'N', 'C', 'X', 'I', 'K', 'Q', 'q', 'q', 'Q', 'p', 'q', 'T0', 'I', 'T0', 'T0', 'I', 'T0', 'T0', 'I', 'T0', 'T0', 'T0', 'D', 'X', 'p0', 'p0', 'p0', 'p', 'p', 'P', 'Q', 'D', 'D', 'D', 'D', 'c', 'k', 'K', 'D', 'x', 'n', 'N', 'D', 't', 'D', 'p0', 'P', 'q0', 'Q', 'k', 'K', 'k', 'D', 'D', 'N', 'D', 'D', 'N', 'K', 'D', 'D', 'U', 'D', 'D', 'P', 'Q', 'k', 'K', 'D', 'C', 'C', 'X', 'R', 'K', 'K', 'P', 'Q', 'p', 'q', 'X', 'p', 'q', 'N', 'p', 'q', 'K', 'pq', 'x', 't', 'X', 'g', 'T', 'g', 'T', 'T', 'T', 'i', 'p', 'p', 't', 'n', 'n', 'n', 'i', 'f', 'k', 'k', 'k', 'k', 'k', 'k', 'i', 'n', 'n', 'm', 'm', 'p', 'd', 'n', 'i', 'n', 'n', 'p', 'p', 'p', 'm', 'm', 'd', 'd', 'X', 'k', 'D', 'k', 'X', 'X', 'q', 'C', 'Q', 'C', 'G', 'f0', 'C', 'i', 'X', 'C', 'i', 'i', 'X', 'X', 'X', 'X', 'j1', 'j1', 'a3', 'a0', 'a0', 'a3', 'i', 'i', 'i', 'p', 'n', 'Q', 'h5f', 'h5f']
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0052
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0051
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0052
Epoch: [3/10], Loss: 0.0038
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0021
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0062
Epoch: [3/10], Loss: 0.0050
Epoch: [4/10], Loss: 0.0043
Epoch: [5/10], Loss: 0.0039
Epoch: [6/10], Loss: 0.0035
Epoch: [7/10], Loss: 0.0033
Epoch: [8/10], Loss: 0.0031
Epoch: [9/10], Loss: 0.0029
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.8176850471932439, 'NAME': 0.655154091392136, 'STRING': 1.0, 'NUMBER': 0.9637076998528691, 'KEYWORD': 0.8382352941176471}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1233,KW_NAME:8
NAME_KW:128,KW_KW:57
NAME_STRING:241,KW_other:3
NAME_NUMBER:280
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'a', 'x', 'X', 'h', 'U', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'a', 'a', 'i', 'x', 'i', 'i', 'm', 'm', 'f', 'm', 'm', 'm', 'f', 'm', 'm', 'f', 'm', 'm', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'a', 'f', 'f', 'k', 'm', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'f', 'i', 'i', 'i', 'x', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'C', 'F', 'C', 'I', 'C', 'C', 'C', 'X', 'C', 'C', 'E', 'X', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'x', 'C', 'C', 'C', 'x', 'C', 'c', 'c', 'x', 'C', 'C', 'C', 'x', 'c', 'C', 'C', 'C', 'C', 'X', 'f', 's', 's', 's', 'x', 'x', 'X', 'p', 'X', 'X', 'X', 'X', 'X', 'n', 'i', 'i', 'i', 'u', 'f', 'i', 'v', 's', 'i', 's', 'c', 'c', 't', 'c', 'c', 's', 'u', 'i', 'i', 'i', 'i', 'i', 'c', 'c', 'p', 'm', 'x', 'x', 'x', 'x', 'x', 'X', 'X', 'i', 'C', 'C', 'C', 'i', 'i', 'X', 'X', 'C', 'C', 'C', 'f', 'C', 'C', 'X', 'i', 'i', 'i', 'i', 'i', 'q', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'i', 'a', 'a', 'C', 'C', 'l', 'i', 'i', 'j', 'i', 'i', 'i', 'c', 'c', 'C', 'R', 'A', 'C', 'A', 'C', 'x', 'f', 'x']
NAME_NUMBER_list:['x', 'T', 'b1', 'h', 'W', 'W', 'x', 'h0', 't', 'd', 'd', 'x', 'x', 'b', 'x', 'i', 't', 'i', 'm', 'f', 'm', 'h', 'm', 'h', 'f', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'f', 'x', 'x', 'i', 'k', 'e', 'e', 'k', 'm', 'm', 'j', 'c', 'i', 'i', 'k', 'X', 'd', 'd', 'd', 't', 't', 'f', 'f', 'x', 'f', 'f', 'f', 'x', 'x', 'x', 'x', 'x', 'd', 'x', 'f', 'f1', 'f2', 'q', 'f2', 'f1', 'X', 'f2', 'f1', 'f2', 'x', 'q', 'q', 'Q', 's', 'q', 's', 'q', 'x', 'F', 'F', 'F', 'C', 'K', 'O', 'q', 'q', 'Q', 'p', 'q', 'N', 'K', 'x', 'U', 'q', 'q', 'Q', 'O', 'O', 'T0', 'T', 'O', 'T0', 'T', 'D', 'X', 'X', 'p0', 'B', 'p0', 'P', 'p0', 'p', 'p', 'P', 'Q', 'c', 'k', 'K', 'x', 'n', 'N', 'D', 't', 'p0', 'q0', 'k', 'k', 'U', 'D', 'k', 'K', 'x', 'X', 'K', 'N', 'p', 'N', 'p', 'q', 'P', 'Q', 'E', 'pq', 'pq', 'x', 'u', 'j', 't', 'X', 'X', 'p', 'T', 'X', 'p', 'X', 'T', 'i', 'x', 'p', 'p', 'p', 't', 'n', 'n', 'n', 'n', 'n', 'n', 'i', 'i', 'v', 'i', 'f', 'i', 'i', 'n', 'n', 's', 's', 'm', 'p', 'd', 'n', 'i', 'n', 'n', 'p', 'p', 'p', 'p', 'i', 'i', 'p', 'p', 'x', 'x', 'X', 'k', 'D', 'X', 'k', 'D', 'R', 'X', 'X', 'D', 'X', 'q', 'Q', 'Q', 'C', 'C', 'i', 'i', 'i', 'f0', 'X', 'F', 'C', 'i', 'F', 'X', 'C', 'X', 'X', 'i', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'X', 'X', 'j1', 'j1', 'i', 'j1', 'j1', 'i', 'j1', 'T', 'b', 'b', 'a3', 'b', 'a0', 'a0', 'T', 'f', 'i', 'i', 'i', 'i', 'p', 'i', 'i', 'i', 'i', 'n', 'R', 'Q', 'Q', 'R', 'h5f', 'f']
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0055
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0043
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0043
Epoch: [4/10], Loss: 0.0035
Epoch: [5/10], Loss: 0.0029
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0097
Epoch: [2/10], Loss: 0.0067
Epoch: [3/10], Loss: 0.0054
Epoch: [4/10], Loss: 0.0047
Epoch: [5/10], Loss: 0.0042
Epoch: [6/10], Loss: 0.0038
Epoch: [7/10], Loss: 0.0036
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.81
{'__OVERALL__': 0.8144560357675111, 'NAME': 0.6535600425079703, 'STRING': 1.0, 'NUMBER': 0.9583128984796468, 'KEYWORD': 0.8529411764705882}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1230,KW_NAME:3
NAME_KW:111,KW_KW:58
NAME_STRING:278,KW_other:7
NAME_NUMBER:263
NAME_STRING_list:['m', 'm', 'a', 'a', 'a', 'X', 'h', 'c', 'U', 'X', 'X', 'X', 'X', 'X', 'a', 'a', 'a', 'a', 'i', 'i', 'j', 'x', 'j', 'j', 'j', 'x', 'x', 'i', 'i', 'i', 'm', 'm', 'm', 'm', 'm', 'h', 'm', 'm', 'm', 'm', 'x', 'x', 'x', 'x', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'a', 'f', 'f', 'k', 'k', 'm', 'r', 'j', 'c', 'i', 'x', 'X', 'x', 'x', 'x', 'x', 'x', 'i', 'i', 'i', 'i', 'x', 'x', 'i', 'f', 'x', 'x', 'x', 'z', 'x', 'x', 'i', 'x', 'x', 'C', 'F', 'I', 'I', 'F', 'X', 'I', 'E', 'X', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'x', 'B', 'C', 'C', 'c', 'x', 'B', 'C', 'x', 'n', 'c', 'n', 'x', 'B', 'x', 'B', 'x', 'B', 'c', 'c', 'C', 'c', 'x', 'x', 'C', 'X', 's', 'x', 'x', 'u', 'X', 'X', 'X', 'X', 'n', 'i', 'i', 'i', 'v', 'i', 'i', 's', 'v', 's', 'i', 'c', 'c', 'c', 'c', 's', 'j', 'J', 'u', 'J', 'j', 'u', 'J', 'J', 'J', 'J', 'J', 'J', 'i', 'i', 'i', 'i', 'i', 'i', 'J', 'i', 'i', 'i', 'J', 'c', 'c', 'm', 'x', 'x', 'x', 'X', 'X', 'i', 'i', 'p', 'C', 'C', 'i', 'i', 'i', 'X', 'C', 'C', 'C', 'C', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'X', 'X', 'X', 'x', 'j', 'j', 'j', 'j', 'V', 'a', 'a', 'i', 'i', 'i', 'j', 'i', 'i', 'i', 'f', 'i', 'C', 'R', 'A', 'A', 'x', 'x']
NAME_NUMBER_list:['x', 'W', 'W', 'h', 'b', 'h', 'c', 'h', 'W', 'U', 'h', 'W', 'U', 'x', 'h0', 'h0', 'h0', 'b1', 'd', 'd', 'b', 'b', 'b', 'j', 'k', 'o', 't', 'm', 'h', 'm', 'h', 'm', 'X', 'x', 'x', 'x', 'i', 'k', 'e', 'k', 'k', 'e', 'k', 'j', 'k', 'c', 'k', 'X', 'X', 'Y', 'd', 'x', 'x', 'g', 'Y1', 'Y1', 'Y1', 'f', 'x', 'd', 'R', 'y', 'f', 'f1', 'q', 'f1', 'X', 'f1', 'f2', 'q', 'q', 'q', 'q', 'Q', 's', 'q', 's', 'q', 'X', 'q', 'K', 'N', 'E', 'X', 'E', 'U', 'U', 'E', 'O', 'T0', 'T', 'O', 'T0', 'T', 'O', 'T0', 'T', 'B', 'D', 'X', 'p0', 'B', 'p0', 'B', 'P', 'p0', 'p0', 'B', 'K', 'D', 'D', 'N', 'c', 'k', 'K', 'D', 'x', 'n', 'N', 'c', 't', 'N', 'p0', 'B', 'q0', 'k', 'K', 'k', 'k', 'p0', 'n', 'E', 'C', 'N', 'K', 'K', 'U', 'D', 'D', 'K', 'P', 'E', 'k', 'K', 'k', 'C', 'X', 'Y', 'X', 'N', 'K', 'K', 'N', 'p', 'Y', 'N', 'P', 'Q', 'E', 'n', 'K', 'E', 'E', 'E', 'pq', 'x', 'j', 'X', 'T', 'p', 'p', 'T', 'T', 'X', 'x', 'y', 'p', 'p', 't', 'n', 'n', 'n', 'f', 'v', 'k', 'k', 'k', 'i', 'n', 's', 's', 'p', 'd', 'n', 'c', 'n', 'n', 'J', 'i', 'i', 'i', 'J', 'd', 'X', 'k', 'D', 'k', 'k', 'D', 'X', 'k', 'D', 'k', 'D', 'R', 'X', 'y', 'X', 'D', 'F', 'q', 'C', 'C', 'G', 'i', 'f0', 'C', 'C', 'X', 'i', 'i', 'X', 'X', 'j', 'j', 'j1', 'j1', 'j2', 'i', 'j1', 'j2', 'j2', 'j1', 'j2', 'j1', 'b', 'b', 'a0', 'a0', 'T', 'C', 'i', 'j', 'p', 'i', 'i', 'n', 'c', 'c', 'Q', 'R', 'h5f', 'h5f']
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.47

pretrained_BERT top neurons
array([   4, 8199, 8200,   11, 2067, 6170, 6172, 8222,   40, 6184,   43,
       8236, 4148, 8265, 4171, 2124, 8268, 4179,   84, 6240, 4194,  118,
        127, 2177, 8332, 6286, 8334, 8347,  159,  172,  179,  183,  196,
        199,  201,  204, 2270,  225,  227, 8442, 4350,  262, 4360,  268,
        269, 8466,  282, 6437, 8488,  302,  308, 8501, 6459,  319, 6475,
       8523,  333, 6489, 6500,  357, 8571, 8572, 6524, 8600, 8610, 6563,
        419,  425,  426, 6570,  429, 6578, 6580,  436, 6594, 6595, 4559,
       6616,  473,  478, 2531, 6647, 6654,  515, 8709, 6664, 8713,  521,
        534,  538, 2588,  540, 4650, 2612, 8767, 4679, 6729,  596, 4692,
       8793, 4704, 4712, 4713, 4714, 6765,  628,  641, 8834, 4737,  642,
        645,  646, 4739, 8838, 8841, 8845, 4749,  656, 2705, 2706,  658,
        663,  672, 8869, 8895, 8915, 6870,  734,  737, 4834, 8931,  752,
       8952,  765, 8968, 8969, 4872, 6930, 2835, 8981, 6940,  808, 6952,
       9004, 4916, 6967, 4923, 2875, 2882, 2887, 9033, 4939, 9036, 9041,
       9043, 6996, 4953, 7008, 9057, 7015, 9064, 9082, 4989, 2945,  898,
       9091, 9090, 7049, 7054, 5007, 9104, 9113, 2976,  940, 5052,  958,
       5059, 9172,  980, 3038,  998, 5094, 3058, 9203, 5123, 5125, 1039,
       9234, 5139, 7191, 3098, 7195, 7205, 1076, 3125, 7223, 7231, 5188,
       7243, 1101, 1105, 9300, 7257, 3168, 9312, 9314, 5239, 9340, 9352,
       7317, 9377, 5294, 1204, 5313, 7367, 7379, 3299, 3302, 7399, 7408,
       9468, 9472, 9474, 9477, 7431, 7432, 1299, 9495, 7450, 5417, 7468,
       9517, 3380, 9533, 5438, 3393, 7497, 1356, 7500, 7507, 7519, 5472,
       3428, 5482, 7537, 9588, 9590, 1401, 1403, 7554, 1413, 9609, 7564,
       5517, 7568, 1431, 7579, 1440, 1451, 9658, 7611, 1469, 9665, 7619,
       7636, 5591, 7642, 5601, 9697, 5606, 1511, 5608, 7662, 7667, 7668,
       5631, 3587, 1543, 7698, 7706, 7708, 3615, 5669, 9771, 9772, 7733,
       5691, 9799, 3655, 7764, 5720, 7776, 9832, 5737, 9835, 9859, 7817,
       9869, 3726, 5781, 7832, 9881, 3744, 5795, 5802, 7862, 3771, 5826,
       5827, 3791, 1766, 7929, 3833, 7945, 1802, 5905, 5907, 7965, 7973,
       5928, 5931, 1844, 1853, 7999, 3913, 3971, 8070, 6030, 6032, 1937,
       6046, 6050, 6058, 6075, 6081, 8147, 2009, 4067, 8163, 8167])
pretrained_BERT top neurons per class
{'NAME': array([5472, 4704, 2531, 5591, 6459, 3299, 6081, 9609, 3791, 7191, 9004,
       2612, 6030, 9881, 6967,  765,  596,  302, 7667, 4148,  538, 8713,
          4, 7432, 8147, 5720, 2976, 3771, 1076,  308, 1299, 3380, 8793,
       6170, 6240, 8200,  672, 9533, 2124, 8968, 7929, 7431, 9495, 9859,
       4679, 9517, 7008, 4923, 1403, 7999, 7668,  808, 8869, 5139, 6489,
       7317, 7564, 9036,  268, 7636,  333, 7817,  656, 3168, 7379,  426,
       6075,  940, 9771, 7832, 9468, 2706, 3971, 6870, 4350, 4067, 7642,
       8442,  734, 6475, 9588, 6952,   43,  641, 4834, 5052, 3744, 9477,
        183, 7367, 7698, 8915, 4194, 7054, 9772, 7399,  628, 7733, 8265,
        429, 4989, 7965, 5691, 5438, 9377,  998, 4692, 2705, 8841,  645,
       1802, 4916,  898, 7195, 8501, 7776, 6050, 1937, 8332, 8834, 8070,
       1431, 8767, 2009, 2945, 6058, 8268, 4737, 1356, 9234, 6594, 6996,
       7519,  958, 4360, 5931,  478, 6172, 5795, 6563, 1440,  319, 7408]), 'STRING': array([4704, 9477, 9772, 9036, 3299, 9881, 7776, 5472,   40, 9517, 7008,
       4559, 6075, 7929, 5438,  998, 6030, 5691,  641, 5591, 6940, 3791,
       7431, 7698,  646, 8952, 9004, 7862, 7579, 2067, 8163, 5631,  672,
       5601, 6729, 9609,  282,  308, 6240,  473, 2612, 7049, 1299,  658,
       3302, 1440, 7668, 4939, 8915,  765, 7817,  268, 7708,  596, 7667,
       5606, 9590,  808, 8332, 7636, 2531, 8147, 5125, 6967, 8793, 9312,
       3380,  645, 7764, 9352, 3428, 2835, 7497,  199, 8571, 6654, 2177,
       3587, 9033, 4067,  737, 1844, 4953, 7662, 8347, 8199, 9468, 6930,
        269, 5669, 9697, 1451, 8610, 1802, 2588, 5608, 9203,  538, 6172,
       3393,   11, 2124, 8709,  429,  752, 1937, 5795, 3913, 7432,  540,
       9041, 9104, 1356, 5737, 5294, 7945, 8222, 8931, 5781, 9300, 6952,
       1469,  172,  958, 5188, 7468, 1511, 4679, 6765, 4350, 9658,  642,
       1101, 8268, 2976, 5826, 7015, 8981, 9172, 6647]), 'NUMBER': array([3299,  308, 4559, 4704, 9772, 4067, 9881, 3744,  538, 6489, 3168,
        808, 8793, 8572, 5905, 6030, 7317, 3791,  641, 9004, 8869,  159,
       7008, 2124, 8845, 6967, 7611, 7668, 3302, 2531, 6570, 9832, 8915,
        201, 3380,  425,  672, 6578, 9517, 8713, 7564, 7568, 2882, 7432,
       9609, 9340, 5691, 7965, 3771, 6729, 8167, 2705, 2875, 7973, 9036,
        429, 5931, 4194, 4679, 1076, 7205, 5591, 8147,   84, 1766,  898,
        534, 5802, 6286, 8952, 3098, 1356, 1413, 5123, 8265,  596,  262,
       5472, 6170, 6664, 9658,  646, 7667, 7468,  419, 1299, 9799, 8334,
       6563, 3615, 5601, 9468, 8969, 8600, 9314, 9043,  183, 7945,  521,
       3125, 7519, 1401,  179, 1543, 1440, 9057, 4179, 5482, 9113, 4872,
       5094, 5781, 6765,  172, 9352, 4834,  127, 7507, 1105, 7662, 6996,
       6595, 9064, 7191, 4739,  333, 7497, 9835,  737,  357,   40,  225,
       5239, 3833, 7450, 8523,  196, 5007, 6032, 8199,  980]), 'KEYWORD': array([4704, 5472, 8793, 7999, 8767, 7008, 3299, 5591, 3791, 8147, 9832,
        940, 4939, 6967, 6580, 8523, 7431, 7776,   43, 9609, 5239,    4,
       4739, 7379, 8600, 5139, 2976, 6081, 7432, 6046, 9517, 9772,  538,
       3058, 6184, 7832, 7817, 9468, 7054, 3038, 6489, 9033, 1039, 4067,
       7500, 5313, 6459, 2887, 7507, 9472, 8488, 6729, 5928, 6930, 6475,
       2270, 4171, 9234, 4559, 5601, 5907,  596, 3168,  204, 7708, 2531,
       1204, 9004, 6952, 9590, 8838, 4714, 7698, 2705, 5417, 7929, 5827,
       5631, 7223,  159, 7619, 3726, 9881, 5059, 5691, 8236,  201,  179,
        515, 4712, 4713, 8268, 9091,  227, 9082,  672, 1853,  436, 8222,
        268, 4650, 7733, 3833,  425, 3655, 6524, 9340, 6595, 7706, 9665,
       9314, 8572,  734, 6500, 4749, 7519, 6437,  225, 6563, 8895,  663,
        628, 7231, 8200, 9869, 8466, 7537, 5517, 6616, 9090,  118, 7257,
       4179, 7554, 7243, 7468, 9477, 9474])}
The shape of selected features (13636, 340)
The shape of the training set: (13636, 340)
The shape of the validation set: (1516, 340)
The shape of the testing set: (4026, 340)
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0043
Epoch: [3/10], Loss: 0.0030
Epoch: [4/10], Loss: 0.0023
Epoch: [5/10], Loss: 0.0018
Epoch: [6/10], Loss: 0.0015
Epoch: [7/10], Loss: 0.0013
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0044
Epoch: [3/10], Loss: 0.0030
Epoch: [4/10], Loss: 0.0023
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0016
Epoch: [7/10], Loss: 0.0014
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0032
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0092
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0039
Epoch: [5/10], Loss: 0.0036
Epoch: [6/10], Loss: 0.0033
Epoch: [7/10], Loss: 0.0031
Epoch: [8/10], Loss: 0.0030
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.96

The best l1=0, the best l2=0.1 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.71
{'__OVERALL__': 0.7056631892697467, 'NAME': 0.6413390010626993, 'STRING': 0.972972972972973, 'NUMBER': 0.7523295733202551, 'KEYWORD': 0.9411764705882353}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1207,KW_NAME:4
NAME_KW:181,KW_KW:64
NAME_STRING:340,KW_other:0
NAME_NUMBER:154
NAME_STRING_list:['a', 'a', 'a', 'a', 'x', 'X', 'h', 'U', 'h', 'U', 'h', 'U', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 'p', 's', 's', 'a', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'm', 'h', 'm', 'm', 'X', 'f', 'x', 'x', 'x', 'x', 'i', 'a', 'a', 'f', 'e', 'w', 'i', 'i', 'i', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'S', 'i', 'S', 'S', 'Q', 'x', 'F', 'C', 'C', 'C', 'q', 'Q', 'p', 'P', 'Q', 'p', 'I', 'E', 'C', 'C', 'E', 'q', 'q', 'Q', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'x', 'X', 'B', 'p', 'P', 'B', 'C', 'x', 'X', 'C', 'P', 'I', 'E', 'C', 'C', 'P', 'B', 'B', 'x', 'P', 'Q', 'I', 'I', 'I', 'E', 'I', 'E', 'Bw', 'x', 'x', 'i', 'i', 'i', 'i', 's', 'T', 'p', 'h', 'h', 'X', 'p', 'i', 'u', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'u', 'u', 'f', 'k', 'k', 'k', 'k', 'i', 'i', 'i', 's', 'm', 'm', 's', 's', 's', 's', 'x', 'x', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'p', 'p', 'm', 'm', 'm', 'i', 'i', 'i', 'p', 'p', 'q', 'q', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'C', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'G', 'q', 'i', 'q', 'i', 'q', 'i', 'q', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'i', 'j2', 'j1', 'j1', 'i', 'P', 'T', 'P', 'T', 'a', 'a', 'b', 'a', 'b', 'a0', 'a3', 'i', 'i', 'i', 'i', 'f', 'i', 'i', 'p', 'a', 'i', 'i', 'i', 'i', 'v', 'A', 'A', 'A', 'B', 'x', 't', 't', 'x']
NAME_NUMBER_list:['h', 'h0', 'd', 'b', 'b', 'h', 'h', 'y', 'l', 'k', 'k', 'k', 'k', 'xx', 'd', 'd', 'd', 'Y', 'd', 'q', 'Q', 'q', 'q', 'P', 'Q', 'p', 'q', 'P', 'Q', 'E', 'x', 'p', 'p', 'q', 't0', 't0', 't0', 't0', 't0', 't0', 't0', 'P', 'p', 'p0', 'P', 'p0', 'p', 'p', 'B', 'B', 'Q', 'B', 'D', 'D', 'K', 'D', 'D', 'k', 'K', 'y', 'Y', 'B', 'D', 'B', 'y', 'D', 'D', 'Q', 'k', 'K', 'k', 'D', 'D', 'N', 'D', 'D', 'N', 'D', 'D', 'D', 'D', 'K', 'Q', 'B', 'k', 'D', 'P', 'S', 'K', 'K', 'P', 'Q', 'p', 'q', 'p', 'q', 'p', 'q', 'p', 'q', 'pq', 'u', 'p', 'p', 'g', 'p', 'x', 'n', 'v', 'v', 'v', 'v', 'v', 'v', 'k', 'v', 'v', 'k', 'v', 'p', 'p', 'v', 'p', 'p', 'p', 'p', 'p', 'd', 'k', 'k', 'k', 'y', 'q', 'y', 'G', 'q', 'q', 'j2', 'j1', 'j2', 'j2', 'V', 'b', 'P', 'a3', 'P', 'a0', 'a2', 'p', 'p', 'g', 'LQ', 'Q', 'Q']
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.47
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0043
Epoch: [4/10], Loss: 0.0035
Epoch: [5/10], Loss: 0.0029
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0085
Epoch: [2/10], Loss: 0.0055
Epoch: [3/10], Loss: 0.0042
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0029
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0060
Epoch: [3/10], Loss: 0.0046
Epoch: [4/10], Loss: 0.0038
Epoch: [5/10], Loss: 0.0032
Epoch: [6/10], Loss: 0.0028
Epoch: [7/10], Loss: 0.0025
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0067
Epoch: [3/10], Loss: 0.0055
Epoch: [4/10], Loss: 0.0048
Epoch: [5/10], Loss: 0.0043
Epoch: [6/10], Loss: 0.0040
Epoch: [7/10], Loss: 0.0037
Epoch: [8/10], Loss: 0.0035
Epoch: [9/10], Loss: 0.0032
Epoch: [10/10], Loss: 0.0031
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.1 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.51
{'__OVERALL__': 0.5062096373571784, 'NAME': 0.5621679064824655, 'STRING': 0.918918918918919, 'NUMBER': 0.4374693477194703, 'KEYWORD': 0.7941176470588235}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1058,KW_NAME:14
NAME_KW:200,KW_KW:54
NAME_STRING:399,KW_other:0
NAME_NUMBER:225
NAME_STRING_list:['a', 'a', 'a', 'a', 'x', 'X', 'h', 'U', 'X', 'W', 'c', 'c', 'U', 'b', 'X', 'X', 'X', 'X', 'b', 'X', 'X', 'p', 'p', 'W1', 'p', 'p', 'p', 'W2', 'p', 'p', 'X', 'X', 's', 'x', 'a', 'a', 'a', 'a', 'i', 'i', 'i', 'x', 'i', 'i', 'm', 'h', 'x', 'x', 'y', 'x', 'y', 'y', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'l', 'x', 'x', 'x', 'x', 'a', 'a', 'w', 'i', 'x', 'x', 'i', 'x', 'x', 'X', 'x', 'x', 'Y', 'x', 'x', 'x', 'x', 'i', 'i', 'i', 'i', 'i', 'i', 'x', 'i', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'z', 'x', 'x', 'x', 'x', 'ih', 'S', 'i', 'i', 'X', 'I', 'x', 'x', 'F', 'C', 'I', 'C', 'C', 'C', 'S', 'X', 'Q', 'P', 'q', 'p', 'I', 'C', 'x', 'S', 'I', 'C', 'S', 'X', 'Q', 'q', 'p', 'C', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'x', 'X', 'B', 'X', 'p', 'B', 'P', 'B', 'B', 'C', 'C', 'C', 'c', 'c', 'Y', 'B', 'x', 'X', 'B', 'c', 'c', 's', 's', 's', 'C', 'P', 'x', 'I', 'E', 'C', 'C', 'C', 'P', 'B', 'B', 'B', 'B', 'c', 'c', 's', 'c', 'c', 'x', 'X', 'C', 'C', 'X', 'P', 'Q', 'I', 'I', 'I', 'E', 's', 'x', 'x', 'x', 'i', 'i', 'i', 'i', 's', 'T', 'X', 'p', 'g', 'X', 'X', 'h', 'X', 'X', 'X', 'X', 'x', 'p', 'p', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'u', 'u', 'i', 's', 's', 's', 'c', 'c', 's', 's', 's', 's', 's', 'x', 'x', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'c', 'p', 'p', 'x', 'x', 'x', 'X', 'X', 'X', 'i', 'i', 'i', 'y', 'C', 'C', 'C', 'C', 'q', 'q', 'i', 'i', 'i', 'i', 'i', 'X', 'C', 'C', 'T', 'C', 'C', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'T', 'T', 'i', 'G', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'X', 'x', 'x', 'i', 'j1', 'i', 'i', 'T', 'a', 'a', 'b', 'a', 'b', 'a0', 'a0', 'C', 'f', 'i', 'i', 'i', 'i', 'i', 'a', 'i', 'i', 'i', 'i', 'c', 'A', 'A', 'A', 'B', 'x', 'x']
NAME_NUMBER_list:['T', 'W', 'b', 'h', 'X', 'h', 'W', 'W', 'W', 'W', 'h', 'W', 'W', 'p', 'd', 'd', 's', 'b', 'b', 'k', 'm', 'h', 'x', 'l', 'k', 'k', 'k', 'v', 'xx', 'd', 'd', 'd', 'x', 'Y1', 't', 'x', 'd', 'S', 'S', 'S', 'x', 'S', 'Q', 'q', 'q', 'q', 'Q', 's', 'q', 's', 'q', 'Y', 'X', 'R', 'S', 'P', 'Q', 'p', 'p', 'Q', 'K', 'q', 'X', 'P', 'Q', 'S', 'x', 'p', 'q', 'P', 'B', 'p0', 'P', 'p', 'p', 'B', 'D', 'D', 'K', 'D', 'D', 'y', 'y', 'D', 'x', 'y', 'x', 's', 'D', 'D', 'Q', 'k', 'q1', 'D', 'D', 'K', 'D', 'D', 'D', 'D', 'x', 'Q', 'n', 'k', 's', 's', 'X', 'R', 'S', 'K', 'P', 'Q', 'p', 'p', 'q', 'p', 'q', 'p', 'q', 'k', 'pq', 's', 's', 's', 's', 's', 't', 'X', 'p', 'p', 'h', 'y', 'x', 'x', 'p', 'p', 'p', 's', 't', 's', 't', 'n', 'u', 'v', 'v', 'v', 'n', 'v', 'k', 'k', 'v', 'v', 'k', 'k', 'v', 'v', 'k', 'k', 'v', 's', 's', 'v', 'v', 's', 'n', 'm', 'm', 's', 'p', 'm', 'p', 's', 's', 's', 'v', 'v', 's', 'u', 'p', 'p', 'p', 'p', 'u', 'p', 'p', 'p', 's', 'x', 'X', 'q', 'q', 'y', 'Q', 'Q', 'G', 'p', 'q', 'p', 'T', 'T', 'q', 'q', 'q', 'q', 'X', 'X', 'j1', 'j2', 'j1', 'j1', 'j2', 'j1', 'j2', 'j1', 'L', 'b', 'a3', 'P', 'a3', 'p', 'p', 'g', 'v', 'v', 'Q']
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 4 [('genie', 1.0), ('locals', 0.9741528747135267), ('entry', 0.9678435504799228), ('tornado', 0.9234733291412645), ('Mesh', 0.9192834698092651)]
Top words for pretrained_BERT neuron indx 8199 [('ur', 1.0), ('117', 0.8372153424218519), ('69', 0.8073895791956891), ('identical', 0.7968562937356669), ('ID', 0.7822508572181905)]
Top words for pretrained_BERT neuron indx 8200 [('75', 1.0), ('33', 0.9953339889923178), ('1970', 0.9356236551156872), ('window', 0.8984197679183682), ('80', 0.881875923576941)]
Top words for pretrained_BERT neuron indx 11 [('tenant', 1.0), ('nh', 0.9629773713982432), ('bus', 0.956237511050425), ('CREATING', 0.9440037807241514), ('quota', 0.9433848384531471)]
Top words for pretrained_BERT neuron indx 2067 [('REFERENCES', 1.0), ('RELATIONS', 0.9646138606351125), ('25', 0.8063256742024467), ('User', 0.7878016112874006), ('success', 0.7682449581251247)]
Top words for pretrained_BERT neuron indx 6170 [('detect', 1.0), ('ip', 0.9981619257982699), ('critical', 0.9870509682673472), ('geventclient', 0.9694510762630647), ('moderate', 0.946045011172491)]
Top words for pretrained_BERT neuron indx 6172 [('imports', 1.0), ('loads', 0.9725251821637205), ('Bytes', 0.9064486618184959), ('intersects', 0.8927155881795794), ('manager', 0.8384136223362976)]
Top words for pretrained_BERT neuron indx 8222 [('span', 1.0), ('Output', 0.997077930776905), ('ref', 0.9803646171144687), ('region', 0.9633358581294003), ('set_up', 0.9493534874244538)]
Top words for pretrained_BERT neuron indx 40 [('Int', 1.0), ('Asset', 0.9907582356174528), ('asset', 0.9647122760451564), ('socket', 0.9097881242821482), ('vol', 0.9080814013948583)]
Top words for pretrained_BERT neuron indx 6184 [('discovery', 1.0), ('reservations', 0.9487025524280375), ('terms', 0.9200556227540588), ('management', 0.9154599634839226), ('last', 0.9076189862474888)]
Top words for pretrained_BERT neuron indx 43 [('decimal', 1.0), ('afi', 0.8960777054676461), ('AFI', 0.8892298663943853), ('patch', 0.8500807032198956), ('selection', 0.8348617891099713)]
Top words for pretrained_BERT neuron indx 8236 [('bk', 1.0), ('by', 0.8040876520141591), ('On', 0.7258312535344777), ('ON', 0.7258312535344777), ('each', 0.7024754748972409)]
Top words for pretrained_BERT neuron indx 4148 [('with', 1.0), ('and', 0.9893247005012202), ('is', 0.968348274416457), ('in', 0.9356868258143566), ('as', 0.852632882407507)]
Top words for pretrained_BERT neuron indx 8265 [('oslo', 1.0), ('south', 0.9577277957694375), ('pattern', 0.9313287706414084), ('plural', 0.8979361360243301), ('465', 0.8867172111890369)]
Top words for pretrained_BERT neuron indx 4171 [('chunks', 1.0), ('Manager', 0.9922243162315485), ('Address', 0.7623960975269368), ('FILES', 0.7539669909348592), ('Basic', 0.7487106273568156)]
Top words for pretrained_BERT neuron indx 2124 [('alt', 1.0), ('advance', 0.9930889214305912), ('select', 0.9895843366500282), ('visit', 0.9475161594340604), ('Integer', 0.9179423031468805)]
Top words for pretrained_BERT neuron indx 8268 [('one', 1.0), ('instanceId', 0.9968044894056458), ('CREATING', 0.9423907606934284), ('REFERENCES', 0.9392191334616184), ('utc', 0.9325014418290751)]
Top words for pretrained_BERT neuron indx 4179 [('CANCEL', 1.0), ('scheme', 0.981960863512019), ('zope', 0.8444267976786034), ('initial', 0.7783388745645009), ('secret', 0.7773968618278864)]
Top words for pretrained_BERT neuron indx 84 [('Reg', 1.0), ('Else', 0.8246786516787025), ('doc', 0.7642617210227103), ('relay', 0.7589228291903491), ('single', 0.7556505695558736)]
Top words for pretrained_BERT neuron indx 6240 [('95', 1.0), ('31', 0.9432868069718745), ('decimal', 0.9347812348818824), ('tls', 0.9042190383220738), ('bson', 0.8820856603321471)]
Top words for pretrained_BERT neuron indx 4194 [('upstream', 1.0), ('contents', 0.9196495728675216), ('42', 0.8595540203963676), ('23', 0.8284309873804231), ('Distance', 0.7456486881277168)]
Top words for pretrained_BERT neuron indx 118 [('day', 1.0), ('messages', 0.9123712601696897), ('reason', 0.8644790980730467), ('lb', 0.828107609064741), ('changed', 0.8093945812260122)]
Top words for pretrained_BERT neuron indx 127 [('unicode', 1.0), ('apache', 0.7839912240538219), ('http', 0.7661978146275599), ('HorizontalBillboard', 0.6704742835679675), ('flags', 0.666359038549871)]
Top words for pretrained_BERT neuron indx 2177 [('flags', 1.0), ('sites', 0.912500553019304), ('SpatialReference', 0.8940383262963226), ('Reg', 0.8886727702911902), ('choice', 0.8778933725747923)]
Top words for pretrained_BERT neuron indx 8332 [('tries', 1.0), ('intersects', 0.9633272430719912), ('forwards', 0.8656993019285882), ('999999', 0.8479510372306823), ('compute', 0.843553911608762)]
Top words for pretrained_BERT neuron indx 6286 [('ORIGIN', 1.0), ('origin', 0.9375439230934067), ('Origin', 0.9216199335042834), ('1970', 0.9021706387584439), ('MINIMUM', 0.873923899977184)]
Top words for pretrained_BERT neuron indx 8334 [('down', 1.0), ('props', 0.9248171143152527), ('__hash__', 0.8859834638912994), ('Video', 0.8836983271956603), ('NodeBuilder', 0.8365975491353785)]
Top words for pretrained_BERT neuron indx 8347 [('"shared"', 1.0), ('"-I"', 0.8837366426937906), ('"warning"', 0.8825195864530871), ('"secret"', 0.8474610017455702), ('"x"', 0.8310520559292905)]
Top words for pretrained_BERT neuron indx 159 [('187', 1.0), ('boot', 0.9628123814539742), ('75', 0.9562802094620051), ('119', 0.9060050447671979), ('512', 0.8457867626944235)]
Top words for pretrained_BERT neuron indx 172 [('protocols', 1.0), ('enclosure', 0.9614477039407892), ('package', 0.9442921607240531), ('sock', 0.8244374654167406), ('chunk', 0.8212176946491159)]
Top words for pretrained_BERT neuron indx 179 [('secure', 1.0), ('imports', 0.9553626094008447), ('moderate', 0.9187250948174135), ('750', 0.8719178541178068), ('Prefix', 0.8168913310482443)]
Top words for pretrained_BERT neuron indx 183 [('reverse', 1.0), ('discovery', 0.9309110642646541), ('Update', 0.8899821743232981), ('Dummy', 0.8868382350466454), ('regions', 0.8364135656617235)]
Top words for pretrained_BERT neuron indx 196 [('exception', 1.0), ('strict', 0.9716949790909429), ('upgrade', 0.907541334752286), ('auditor', 0.8962943147049809), ('password', 0.8638126622944718)]
Top words for pretrained_BERT neuron indx 199 [('worker', 1.0), ('presence', 0.9593392612403965), ('Presence', 0.9397711947290939), ('69', 0.8991768560904424), ('warn', 0.8310038659469998)]
Top words for pretrained_BERT neuron indx 201 [('confirm', 1.0), ('symmetric', 0.9597285911024663), ('cover', 0.9563357731961057), ('flat', 0.9533612583624842), ('typeof', 0.9507858723900575)]
Top words for pretrained_BERT neuron indx 204 [('quota', 1.0), ('Lock', 0.954161014057787), ('number', 0.9333753031966933), ('roster', 0.8898085641323827), ('lock', 0.8671951719010802)]
Top words for pretrained_BERT neuron indx 2270 [('bus', 1.0), ('zone', 0.9536025154470711), ('horizon', 0.9506061295437345), ('Recording', 0.9278084564332308), ('Stream', 0.924590490140708)]
Top words for pretrained_BERT neuron indx 225 [('MULTILINE', 1.0), ('jtype', 0.9413895757718741), ('trello', 0.8609852579603845), ('intersects', 0.8395544904834551), ('62', 0.7990675251701411)]
Top words for pretrained_BERT neuron indx 227 [('ELEMENT', 1.0), ('buttons', 0.9494600140465579), ('WAY', 0.876570360177892), ('broker', 0.8538928382368469), ('mail', 0.8486671620801679)]
Top words for pretrained_BERT neuron indx 8442 [('Prefix', 1.0), ('omit', 0.932591787988164), ('IFile', 0.9204034590373671), ('walk', 0.9203730877835206), ('five', 0.9036135809092484)]
Top words for pretrained_BERT neuron indx 4350 [('TRANSITIVE', 1.0), ('unquote', 0.947613434211109), ('RELATIONS', 0.8876174231793452), ('"key"', 0.8514252453286104), ('single', 0.8228122914030364)]
Top words for pretrained_BERT neuron indx 262 [('select', 1.0), ('reflection', 0.9511019708652132), ('signed', 0.8939978355594392), ('brightness', 0.8664602314488009), ('abstract', 0.8557553330187698)]
Top words for pretrained_BERT neuron indx 4360 [('choice', 1.0), ('direct', 0.8635335332152916), ('window', 0.8548513972936836), ('imports', 0.8430305513254358), ('200', 0.8338866382671996)]
Top words for pretrained_BERT neuron indx 268 [('twisted', 1.0), ('ax', 0.997966509468365), ('else', 0.9600751253765222), ('Else', 0.920361175759377), ('backwards', 0.8980773438488079)]
Top words for pretrained_BERT neuron indx 269 [('no', 1.0), ('dom', 0.9750247195595797), ('composite', 0.9288448781492661), ('space', 0.9187360414169342), ('texture', 0.9149708312534913)]
Top words for pretrained_BERT neuron indx 8466 [('ax', 1.0), ('each', 0.9843622415055625), ('plural', 0.9134653279716123), ('realm', 0.9055760127282984), ('audit', 0.8959898852700405)]
Top words for pretrained_BERT neuron indx 282 [('depth', 1.0), ('enclosure', 0.8917966917426429), ('filtered', 0.8279031219855968), ('Repository', 0.8213332802490259), ('ping', 0.796133923109245)]
Top words for pretrained_BERT neuron indx 6437 [('omit', 1.0), ('deferred', 0.9990406684577249), ('Subject', 0.8586526474482252), ('Region', 0.8139712810576263), ('agency', 0.7948890514317192)]
Top words for pretrained_BERT neuron indx 8488 [('Presence', 1.0), ('management', 0.8726798831429412), ('south', 0.8384869398844255), ('receiver', 0.838361664362087), ('redistricting', 0.8279195267608889)]
Top words for pretrained_BERT neuron indx 302 [('resolve', 1.0), ('bodies', 0.9401348226664272), ('Int', 0.9372190693112015), ('def', 0.9351414518511032), ('chunks', 0.7910132297429854)]
Top words for pretrained_BERT neuron indx 308 [('and', 1.0), ('to', 0.867833621017307), ('in', 0.867726722143447), ('".."', 0.8665045777521424), ('with', 0.7247832718323066)]
Top words for pretrained_BERT neuron indx 8501 [('VALUE', 1.0), ('127', 0.8380773662936597), ('If', 0.8063086865330756), ('5001', 0.7274500008774342), ('MultiPolygon', 0.6872748065257702)]
Top words for pretrained_BERT neuron indx 6459 [('with', 1.0), ('sr', 0.8415315156311381), ('WITHDRAW', 0.789518398114357), ('".js"', 0.7594899312810645), ('do', 0.7590895737376383)]
Top words for pretrained_BERT neuron indx 319 [('runm', 1.0), ('Simulator', 0.9845336619726923), ('negotiate', 0.9844003500786166), ('detect', 0.9443834720589996), ('five', 0.941097006525664)]
Top words for pretrained_BERT neuron indx 6475 [('INCOMPLETE', 1.0), ('ROLE', 0.9948198695978718), ('polygon', 0.9799250903102019), ('CACHES', 0.9635618645521642), ('"0.14.0"', 0.9533511907043788)]
Top words for pretrained_BERT neuron indx 8523 [('Clock', 1.0), ('BlendProbes', 0.9765083713194771), ('33', 0.9458470037735173), ('25', 0.943853745835892), ('HTTP_PORT', 0.9411869254146754)]
Top words for pretrained_BERT neuron indx 333 [('ah', 1.0), ('Parent', 0.8692099808225767), ('sr', 0.8161292931718174), ('tornado', 0.8143535503363432), ('accounts', 0.8055199251749228)]
Top words for pretrained_BERT neuron indx 6489 [('BBOX', 1.0), ('IGP', 0.9982631452825668), ('IDLEN', 0.9605331279655454), ('Stretch', 0.9579587976521075), ('LAT', 0.9576628509033633)]
Top words for pretrained_BERT neuron indx 6500 [('Column', 1.0), ('affinity', 0.8318393458635635), ('resolve', 0.8224244661446715), ('WAY', 0.7703421973149832), ('management', 0.7658597126683453)]
Top words for pretrained_BERT neuron indx 357 [('PROVISION', 1.0), ('tenant', 0.9542532050800744), ('provision', 0.9191556385947558), ('boot', 0.858089273814443), ('contents', 0.8097768508721965)]
Top words for pretrained_BERT neuron indx 8571 [('75', 1.0), ('topology', 0.980384295648466), ('"y"', 0.9705588574916664), ('187', 0.9421257216338447), ('"file"', 0.9394470147524919)]
Top words for pretrained_BERT neuron indx 8572 [('scheme', 1.0), ('for', 0.8592540687456749), ('with', 0.85723009791201), ('agency', 0.8545227918470324), ('"sequence"', 0.8536472334761454)]
Top words for pretrained_BERT neuron indx 6524 [('42', 1.0), ('69', 0.8180619721402976), ('23', 0.8100795516549988), ('800', 0.7924652684318959), ('36', 0.791933526121841)]
Top words for pretrained_BERT neuron indx 8600 [('28', 1.0), ('implementation', 0.990861122008479), ('2014', 0.9870692313889703), ('204', 0.9311778653471259), ('class', 0.9093020019497922)]
Top words for pretrained_BERT neuron indx 8610 [('answer', 1.0), ('LoadUser', 0.9277071848319437), ('responses', 0.7921646504176844), ('unicode', 0.740633426107309), ('part', 0.7359470876029057)]
Top words for pretrained_BERT neuron indx 6563 [('except', 1.0), ('if', 0.9372716964120181), ('bagpipe', 0.8653428258248128), ('If', 0.7644344190603705), ('with', 0.7641113754097595)]
Top words for pretrained_BERT neuron indx 419 [('jtype', 1.0), ('ping', 0.80343705454112), ('StringType', 0.7785142804286421), ('long', 0.756525890198997), ('INCOMPLETE', 0.7395052948488768)]
Top words for pretrained_BERT neuron indx 425 [('Simple', 1.0), ('simple', 0.8798897637993812), ('identical', 0.7248395795650958), ('MAXIMUM', 0.7030058491391444), ('Lock', 0.6872191212837742)]
Top words for pretrained_BERT neuron indx 426 [('digest', 1.0), ('Digest', 0.9613208051393528), ('loop', 0.7843112676502043), ('height', 0.7804139554514342), ('behind', 0.7661236362022884)]
Top words for pretrained_BERT neuron indx 6570 [('capacity', 1.0), ('answer', 0.9593641791599588), ('width', 0.9457829618149973), ('pattern', 0.9205913970747573), ('composite', 0.9046503677662936)]
Top words for pretrained_BERT neuron indx 429 [('exception', 1.0), ('blend', 0.9180190848687019), ('Filter', 0.9172760905285132), ('sock', 0.8902538353113565), ('resource', 0.8435003651707077)]
Top words for pretrained_BERT neuron indx 6578 [('activate', 1.0), ('advance', 0.9296504984630125), ('ur', 0.866012983671102), ('begin', 0.8527894093670209), ('groups', 0.8345680109611824)]
Top words for pretrained_BERT neuron indx 6580 [('relay', 1.0), ('form', 0.9377664224230011), ('selection', 0.8443329986313988), ('Provider', 0.8346721727670532), ('utcnow', 0.7793841357622044)]
Top words for pretrained_BERT neuron indx 436 [('Output', 1.0), ('props', 0.967858072647165), ('unicode', 0.9248240747867722), ('ORIGIN', 0.8524770680683001), ('record', 0.8351924872401515)]
Top words for pretrained_BERT neuron indx 6594 [('75', 1.0), ('ignore', 0.9823815592771502), ('quota', 0.8977098913965317), ('Instance', 0.8770667727171505), ('tell', 0.8581284412522088)]
Top words for pretrained_BERT neuron indx 6595 [('operator', 1.0), ('bk', 0.980417080458714), ('template', 0.9144668665521062), ('seek', 0.9099234164544193), ('pk', 0.8950076025273076)]
Top words for pretrained_BERT neuron indx 4559 [('ah', 1.0), ('closing', 0.9898972730198805), ('Failure', 0.9549874448863093), ('dr', 0.9012777923600334), ('record', 0.8488093506923838)]
Top words for pretrained_BERT neuron indx 6616 [('passed', 1.0), ('cb', 0.9139050195299339), ('Unauthorized', 0.8796948026683302), ('intersects', 0.8794781149538216), ('decoded', 0.8498339937501314)]
Top words for pretrained_BERT neuron indx 473 [('missing', 1.0), ('Allow', 0.9570473437655289), ('asset', 0.9458495184218898), ('space', 0.9278207200896225), ('backwards', 0.9113397501846698)]
Top words for pretrained_BERT neuron indx 478 [('forwards', 1.0), ('pisa', 0.9936601175958482), ('height', 0.9700687396772741), ('partial', 0.9485681955787156), ('audit', 0.891599829619357)]
Top words for pretrained_BERT neuron indx 2531 [('WAY', 1.0), ('Geo', 0.8277857059137587), ('Projector', 0.7810927404823227), ('"label"', 0.7630007545225027), ('simplify', 0.75414238671282)]
Top words for pretrained_BERT neuron indx 6647 [('within', 1.0), ('Criteria', 0.6374154894510115), ('sanetime', 0.6371349480339263), ('chunks', 0.6314188006195305), ('90.0', 0.6260561845921678)]
Top words for pretrained_BERT neuron indx 6654 [('omit', 1.0), ('unquote', 0.8816043384212027), ('"first_commits"', 0.8641067695562521), ('ts', 0.7993704112119584), ('"x"', 0.7862083340011864)]
Top words for pretrained_BERT neuron indx 515 [('clone', 1.0), ('revision', 0.9877989251131543), ('topology', 0.9439790771918982), ('python', 0.9438461324216361), ('ALPHABET', 0.8869328878487014)]
Top words for pretrained_BERT neuron indx 8709 [('81.4471435546875', 1.0), ('74.616338', 0.9310541993409623), ('"--version"', 0.8645688350745692), ('23.61432859499169', 0.816873354432727), ('33', 0.8107445657671736)]
Top words for pretrained_BERT neuron indx 6664 [('window', 1.0), ('1970', 0.9066668356894491), ('62', 0.8997335417672816), ('75', 0.8312204454904618), ('File', 0.8042507168524166)]
Top words for pretrained_BERT neuron indx 8713 [('in', 1.0), ('openwatch', 0.9283006004055956), ('WAY', 0.8899832098882792), ('1800', 0.8841954646311337), ('setupDatabase', 0.8475114283019025)]
Top words for pretrained_BERT neuron indx 521 [('rest', 1.0), ('clean', 0.697182711236046), ('reflection', 0.6465609256850895), ('bus', 0.6367472574659165), ('dictionary', 0.6318054305778289)]
Top words for pretrained_BERT neuron indx 534 [('tenant', 1.0), ('processes', 0.9753540913347645), ('reference', 0.9525623877739766), ('aspect', 0.9237231017861309), ('edit', 0.8917763996469169)]
Top words for pretrained_BERT neuron indx 538 [('minutes', 1.0), ('targets', 0.9729973686334764), ('def', 0.9632968399607558), ('Subject', 0.8787259210738282), ('PORT', 0.8546998341686667)]
Top words for pretrained_BERT neuron indx 2588 [('View', 1.0), ('69', 0.9918721145234044), ('lat', 0.9678461611976945), ('topology', 0.9122547179879028), ('42', 0.8687550021881364)]
Top words for pretrained_BERT neuron indx 540 [('OK', 1.0), ('choice', 0.9913551379429083), ('sha', 0.9548797747606115), ('TAG', 0.9135649724746077), ('Tag', 0.9013837011826632)]
Top words for pretrained_BERT neuron indx 4650 [('baseline', 1.0), ('forwards', 0.9193458134035946), ('resolve', 0.8994966738726592), ('advance', 0.8961605382089173), ('spawn', 0.8882710641835709)]
Top words for pretrained_BERT neuron indx 2612 [('and', 1.0), ('in', 0.9248110907160317), ('is', 0.9078516486382139), ('with', 0.8005722119590688), ('as', 0.8000503080771721)]
Top words for pretrained_BERT neuron indx 8767 [('Else', 1.0), ('is', 0.8178607393924123), ('If', 0.8127052036231951), ('for', 0.7165972096789494), ('74.616338', 0.6740056796726646)]
Top words for pretrained_BERT neuron indx 4679 [('WAYS', 1.0), ('cipher', 0.8937264908105234), ('worker', 0.8767233453844506), ('Site', 0.8753136802247494), ('PROVISION', 0.8702399363931009)]
Top words for pretrained_BERT neuron indx 6729 [('fragment', 1.0), ('criterion', 0.9820494365735064), ('pattern', 0.9718965702073195), ('ur', 0.9501406896835506), ('2.1', 0.9422853036265831)]
Top words for pretrained_BERT neuron indx 596 [('submit', 1.0), ('signed', 0.857590088762827), ('800', 0.8534953502885662), ('ns', 0.814805084420327), ('secret', 0.7993442776572333)]
Top words for pretrained_BERT neuron indx 4692 [('62', 1.0), ('FSM', 0.9207570790124554), ('frame', 0.8865153009755238), ('sdi', 0.871646278408648), ('gf', 0.8613807578895218)]
Top words for pretrained_BERT neuron indx 8793 [('ay', 1.0), ('ax', 0.7578768570782722), ('communities', 0.7568724323424824), ('construct', 0.7520932125752775), ('BBOX', 0.7428286258220828)]
Top words for pretrained_BERT neuron indx 4704 [('300', 1.0), ('69', 0.9377285482313947), ('1800', 0.9338789039515457), ('milliseconds', 0.9152723082592018), ('95', 0.9129744415244763)]
Top words for pretrained_BERT neuron indx 4712 [('python', 1.0), ('WITHDRAW', 0.9783317978642699), ('startTime', 0.9023102485283842), ('SAFI', 0.8692438973151551), ('safi', 0.8591370473460321)]
Top words for pretrained_BERT neuron indx 4713 [('1800', 1.0), ('300', 0.991015655321734), ('unlink', 0.9713713791949872), ('setLevel', 0.9475718341137804), ('WAYNODES', 0.9257703535554489)]
Top words for pretrained_BERT neuron indx 4714 [('2014', 1.0), ('fifteen', 0.9250761444079502), ('oslo', 0.9095259337277434), ('Wire', 0.8742600660800404), ('1970', 0.8109146182110148)]
Top words for pretrained_BERT neuron indx 6765 [('qdict', 1.0), ('"http://"', 0.682727374309148), ('blend', 0.6810229350142678), ('Cat', 0.6237653465086687), ('tell', 0.6135296710385115)]
Top words for pretrained_BERT neuron indx 628 [('CANCEL', 1.0), ('cancel', 0.960529097062075), ('reservation', 0.9143322104532363), ('REQUEST', 0.8612492037165037), ('probe', 0.8061991389451973)]
Top words for pretrained_BERT neuron indx 641 [('flat', 1.0), ('direct', 0.8159929011870916), ('genie', 0.7778990757828457), ('demo', 0.7676436761646953), ('Card', 0.7606033291405424)]
Top words for pretrained_BERT neuron indx 8834 [('WAYS', 1.0), ('"multiple"', 0.9887768518589303), ('libraries', 0.9642601109261997), ('Off', 0.9578774350595505), ('REFERENCES', 0.9444253889041326)]
Top words for pretrained_BERT neuron indx 4737 [('abstract', 1.0), ('Card', 0.8188434627053289), ('other', 0.8044432305199105), ('ns', 0.7936835689352427), ('nsi2', 0.756813378064267)]
Top words for pretrained_BERT neuron indx 642 [('Wire', 1.0), ('intersects', 0.8347691300191407), ('class', 0.7584801402037008), ('Command', 0.7407923173936951), ('WAY', 0.7118890664347177)]
Top words for pretrained_BERT neuron indx 645 [('socket', 1.0), ('profile', 0.941545667419804), ('ur', 0.8289815754672579), ('href', 0.8184458694019364), ('_property', 0.8075001499433052)]
Top words for pretrained_BERT neuron indx 646 [('strategy', 1.0), ('BOUNDS', 0.9283976018618464), ('unicode', 0.9056822552400263), ('Stream', 0.7929165497706288), ('ORIGIN', 0.7853457438505793)]
Top words for pretrained_BERT neuron indx 4739 [('vol', 1.0), ('space', 0.890703701313829), ('old', 0.7832161646083258), ('ref', 0.7805851667315848), ('application', 0.7631905787157127)]
Top words for pretrained_BERT neuron indx 8838 [('"0"', 1.0), ('"r"', 0.9467652215199722), ('75', 0.9301044810381974), ('42', 0.8665511499372749), ('"100"', 0.836677444952002)]
Top words for pretrained_BERT neuron indx 8841 [('o2', 1.0), ('ax', 0.8793073663610356), ('pb', 0.7981164409657256), ('Authorization', 0.7902890472077262), ('owner', 0.7779752489788717)]
Top words for pretrained_BERT neuron indx 8845 [('Action', 1.0), ('Clock', 0.9413525711351646), ('"1.2.3"', 0.8277642569669448), ('21', 0.797999879956641), ('"0.0.0.0/0"', 0.7969361595691713)]
Top words for pretrained_BERT neuron indx 4749 [('unicode', 1.0), ('sans', 0.8857432334126747), ('buttons', 0.7900506160455162), ('commands', 0.7657620922375002), ('deploy', 0.7553544002763322)]
Top words for pretrained_BERT neuron indx 656 [('cb', 1.0), ('Register', 0.8718616043749688), ('valid', 0.7781027435531744), ('validators', 0.7769679236580769), ('restart', 0.7704897943821666)]
Top words for pretrained_BERT neuron indx 2705 [('ts', 1.0), ('bk', 0.9474359282259259), ('Iq', 0.8746956793966105), ('nh', 0.8594709353765967), ('ep', 0.8064328974353578)]
Top words for pretrained_BERT neuron indx 2706 [('WAY', 1.0), ('vol', 0.9965904868323697), ('ep', 0.9420916962761067), ('WAYS', 0.9272600883052426), ('oid', 0.9200688378891437)]
Top words for pretrained_BERT neuron indx 658 [('secret', 1.0), ('ignore', 0.706635440054367), ('push', 0.7065280749838969), ('sa', 0.7010308480493886), ('null', 0.6660494135200856)]
Top words for pretrained_BERT neuron indx 663 [('blank', 1.0), ('sid', 0.9490992822784223), ('secret', 0.8581742107760059), ('principal', 0.829064245298571), ('doc', 0.8157148769980179)]
Top words for pretrained_BERT neuron indx 672 [('Column', 1.0), ('space', 0.7806373225420592), ('cover', 0.7567172878452265), ('ADVERTISE', 0.7395457036783806), ('horizon', 0.7303808793182603)]
Top words for pretrained_BERT neuron indx 8869 [('from', 1.0), ('deploy', 0.9629085258416127), ('except', 0.9577892002612127), ('score', 0.921519463059688), ('try', 0.9049066089672853)]
Top words for pretrained_BERT neuron indx 8895 [('five', 1.0), ('2.1', 0.5392226715747674), ('aspect', 0.5383506598605322), ('0.04', 0.5316885248039024), ('fifteen', 0.5305442105859602)]
Top words for pretrained_BERT neuron indx 8915 [('five', 1.0), ('Provider', 0.9373184437457038), ('oslo', 0.9011270421993884), ('import', 0.8199700689918898), ('edited', 0.8182352889953802)]
Top words for pretrained_BERT neuron indx 6870 [('fail', 1.0), ('while', 0.924638527124924), ('requires', 0.8795990775203599), ('inc', 0.8664866224907695), ('tornado', 0.8243934896533506)]
Top words for pretrained_BERT neuron indx 734 [('reference', 1.0), ('Authenticated', 0.999913748215915), ('Migration', 0.9565679638846529), ('entries', 0.9506694863480676), ('horizon', 0.8925199931635509)]
Top words for pretrained_BERT neuron indx 737 [('quality', 1.0), ('horizon', 0.7434804310547906), ('commands', 0.7174760407467444), ('span', 0.7033456008595333), ('Prefix', 0.669596781335287)]
Top words for pretrained_BERT neuron indx 4834 [('exists', 1.0), ('23', 0.9343864805671582), ('DISCONNECTED', 0.9318487128140404), ('Stretch', 0.9136603608280665), ('TAGS', 0.9009926074116884)]
Top words for pretrained_BERT neuron indx 8931 [('intersects', 1.0), ('exabgp', 0.9483295458175314), ('button', 0.8971817126906944), ('89.999999999999992', 0.8832517568694095), ('forwards', 0.8786522758388735)]
Top words for pretrained_BERT neuron indx 752 [('twisted', 1.0), ('MANIFEST', 0.8048264948243201), ('hyper', 0.8009208499970263), ('slug', 0.7932480038970279), ('quote', 0.7292932581574286)]
Top words for pretrained_BERT neuron indx 8952 [('IntType', 1.0), ('materials', 0.9956305137607617), ('Card', 0.959898864443215), ('site', 0.8794560053336808), ('do', 0.865627305006082)]
Top words for pretrained_BERT neuron indx 765 [('lb', 1.0), ('Geo', 0.9627356466223846), ('encoding', 0.8327923227400418), ('File', 0.8022557503823464), ('python', 0.7580089025414154)]
Top words for pretrained_BERT neuron indx 8968 [('33', 1.0), ('62', 0.9011983997203464), ('window', 0.9009785877980675), ('75', 0.888174251834394), ('80', 0.8306231154417348)]
Top words for pretrained_BERT neuron indx 8969 [('"oslo"', 1.0), ('functional', 0.8844063800043791), ('SSLContext', 0.8393122799925892), ('location__exact', 0.8232736284650791), ('inc', 0.8218079598470686)]
Top words for pretrained_BERT neuron indx 4872 [('RESERVE', 1.0), ('Distance', 0.8208361039857809), ('Card', 0.8145967491790768), ('upgrade', 0.8092651954105468), ('10000', 0.7987874157091108)]
Top words for pretrained_BERT neuron indx 6930 [('each', 1.0), ('plural', 0.9227354073011901), ('ax', 0.8830573964301685), ('synchronized', 0.848064803930663), ('Simple', 0.8338384014592437)]
Top words for pretrained_BERT neuron indx 2835 [('RELATIONS', 1.0), ('LOG', 0.8717242004885744), ('Log', 0.870086943524456), ('ur', 0.850587267594395), ('25', 0.8432882362979004)]
Top words for pretrained_BERT neuron indx 8981 [('or', 1.0), ('False', 0.9945271297928686), ('Job', 0.9453902362603495), ('strict', 0.8846193962507165), ('28', 0.8275482331882973)]
Top words for pretrained_BERT neuron indx 6940 [('intersects', 1.0), ('75', 0.9463729410960415), ('"y"', 0.9210489171510853), ('flat', 0.9128300295319275), ('venue', 0.9016159392491834)]
Top words for pretrained_BERT neuron indx 808 [('asset', 1.0), ('Asset', 0.9810862413275229), ('last', 0.9298370444310133), ('decorators', 0.9234107176102022), ('materials', 0.908324755370326)]
Top words for pretrained_BERT neuron indx 6952 [('terms', 1.0), ('discovery', 0.9929980117445786), ('Presence', 0.9874183936745734), ('last', 0.9705772968973968), ('selection', 0.9016470153049428)]
Top words for pretrained_BERT neuron indx 9004 [('bk', 1.0), ('by', 0.9405457518043167), ('On', 0.7358972400092328), ('ON', 0.7358972400092328), ('libraries', 0.7311013005033492)]
Top words for pretrained_BERT neuron indx 4916 [('with', 1.0), ('is', 0.892299388257154), ('and', 0.8377364732797592), ('as', 0.8184866239717282), ('in', 0.8066037448998119)]
Top words for pretrained_BERT neuron indx 6967 [('five', 1.0), ('42', 0.927143696491439), ('1800', 0.87167965176439), ('75', 0.818357667588736), ('fifteen', 0.7227673751025762)]
Top words for pretrained_BERT neuron indx 4923 [('with', 1.0), ('Basic', 0.9713394657559835), ('randomize', 0.9003417157212582), ('part', 0.8929892047967328), ('ajax', 0.8925845682796807)]
Top words for pretrained_BERT neuron indx 2875 [('initial', 1.0), ('Basic', 0.9148517647871377), ('responses', 0.8626968279535602), ('original', 0.8184687652956265), ('part', 0.8184114942415325)]
Top words for pretrained_BERT neuron indx 2882 [('sublime', 1.0), ('available', 0.8421695415847026), ('CANCEL', 0.8137598572008494), ('stanza', 0.8039041232669785), ('wait', 0.7960316052004567)]
Top words for pretrained_BERT neuron indx 2887 [('agency', 1.0), ('exception', 0.9611627863254113), ('old', 0.8852488857825963), ('translation', 0.8058573249577444), ('CRITICAL', 0.7902892413060731)]
Top words for pretrained_BERT neuron indx 9033 [('465', 1.0), ('15597', 0.967873830656997), ('1025', 0.9545609420022181), ('south', 0.927839218283271), ('bare', 0.9255914692500818)]
Top words for pretrained_BERT neuron indx 4939 [('NODES', 1.0), ('On', 0.9639180765487658), ('ON', 0.9639180765487658), ('MEMBERS', 0.8123136519629156), ('CACHES', 0.8064855966293861)]
Top words for pretrained_BERT neuron indx 9036 [('available', 1.0), ('CREATING', 0.9267415358849819), ('one', 0.8297348648499517), ('intersects', 0.8206529792740618), ('instanceId', 0.8016591501518873)]
Top words for pretrained_BERT neuron indx 9041 [('providers', 1.0), ('services', 0.9852917989543077), ('quota', 0.9463587193552268), ('CREATING', 0.8799912322450376), ('resources', 0.8776964686792392)]
Top words for pretrained_BERT neuron indx 9043 [('TERMINATE', 1.0), ('GEOSGeometry', 0.8776647796286513), ('buttons', 0.8575003870310786), ('for', 0.8300799002068255), ('WAYNODES', 0.8051495063068999)]
Top words for pretrained_BERT neuron indx 6996 [('ip', 1.0), ('checkout_branch', 0.8396120573217369), ('except', 0.7511940442250107), ('GEOSGeometry', 0.7475896715173387), ('with', 0.7196255133461162)]
Top words for pretrained_BERT neuron indx 4953 [('READY', 1.0), ('ready', 0.9902799473344668), ('IDLEN', 0.9051591495821434), ('LAT', 0.8736315577594223), ('created', 0.8536986731012681)]
Top words for pretrained_BERT neuron indx 7008 [('"KILLED"', 1.0), ('oslo', 0.9965087539321563), ('bson', 0.974736789295125), ('95', 0.9303350739266707), ('"SUCCEEDED"', 0.9185185340815739)]
Top words for pretrained_BERT neuron indx 9057 [('unicode', 1.0), ('omit', 0.9347018129547738), ('Always', 0.891296867708878), ('huffman', 0.8798839612906035), ('password', 0.8584108325589631)]
Top words for pretrained_BERT neuron indx 7015 [('functional', 1.0), ('Assign', 0.9038167213731851), ('closing', 0.8968834267213145), ('META', 0.8883917219967363), ('future', 0.887118102490383)]
Top words for pretrained_BERT neuron indx 9064 [('microseconds', 1.0), ('Else', 0.9786298906778539), ('isalnum', 0.8713784522159042), ('OperationMock', 0.8253165729591557), ('CommandMock', 0.8090210596904498)]
Top words for pretrained_BERT neuron indx 9082 [('300', 1.0), ('80', 0.9631479262063559), ('1970', 0.9165007223673814), ('42', 0.8969087424736492), ('800', 0.8685009852467945)]
Top words for pretrained_BERT neuron indx 4989 [('"0800305c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 1.0), ('"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.9871775696905783), ('for', 0.938869706947185), ('with', 0.910973197265894), ('lon__gt', 0.8929402048371512)]
Top words for pretrained_BERT neuron indx 2945 [('flags', 1.0), ('sites', 0.9030205886378723), ('choice', 0.9001911312070914), ('credential', 0.8783504464317464), ('forwards', 0.8616871430217323)]
Top words for pretrained_BERT neuron indx 898 [('stamp', 1.0), ('region', 0.9067427260230686), ('Region', 0.9046953866748086), ('blend', 0.8700718511298986), ('tell', 0.8690775402887645)]
Top words for pretrained_BERT neuron indx 9091 [('cb', 1.0), ('2.1', 0.7963138668061226), ('while', 0.7879138176763799), ('OK', 0.7856807943718395), ('if', 0.7150142449957043)]
Top words for pretrained_BERT neuron indx 9090 [('"SUCCEEDED"', 1.0), ('SON', 0.8389165418425398), ('ll', 0.8162645761941998), ('"warning"', 0.8000853417128312), ('cm', 0.7891754416671076)]
Top words for pretrained_BERT neuron indx 7049 [('frame', 1.0), ('by', 0.9839263904409941), ('flat', 0.9651989670718931), ('created', 0.8614530427157958), ('within', 0.8563475484821987)]
Top words for pretrained_BERT neuron indx 7054 [('1970', 1.0), ('tv', 0.9464963444171395), ('yield', 0.9224124607270477), ('ORIGIN', 0.8909190764691528), ('prop', 0.8909091729966968)]
Top words for pretrained_BERT neuron indx 5007 [('class', 1.0), ('95', 0.8260419862008784), ('topology', 0.7808304511548492), ('inc', 0.7729664747492873), ('Delay', 0.7682037642568353)]
Top words for pretrained_BERT neuron indx 9104 [('tell', 1.0), ('PROVISION', 0.8780344359194012), ('RESERVE', 0.8193486814102288), ('District', 0.7898681442361061), ('TERMINATE', 0.717316948455799)]
Top words for pretrained_BERT neuron indx 9113 [('TERMINATE', 1.0), ('187', 0.9880918296989487), ('RELEASE', 0.955178031775375), ('agency', 0.7650571825478066), ('terminate', 0.7555391410131453)]
Top words for pretrained_BERT neuron indx 2976 [('purpose', 1.0), ('CONNECTED', 0.7665430764766683), ('DISCONNECTED', 0.7632609879728818), ('bodies', 0.7252918322755404), ('frame', 0.7044333451093572)]
Top words for pretrained_BERT neuron indx 940 [('proxy', 1.0), ('each', 0.9352192670372464), ('length', 0.9300193399887182), ('Switch', 0.8907509276012939), ('render', 0.8859667060226625)]
Top words for pretrained_BERT neuron indx 5052 [('other', 1.0), ('1970', 0.9546039930799654), ('is', 0.9417952738252788), ('sr', 0.9350097190323716), ('FSM', 0.9201029277357675)]
Top words for pretrained_BERT neuron indx 958 [('inc', 1.0), ('quality', 0.9524843868389691), ('patch', 0.9271451260094654), ('authorization', 0.9194215967544804), ('Off', 0.9043993133159964)]
Top words for pretrained_BERT neuron indx 5059 [('seek', 1.0), ('pk', 0.9123488994448613), ('template', 0.8946173449831357), ('302', 0.845745174214016), ('operator', 0.8344173331760436)]
Top words for pretrained_BERT neuron indx 9172 [('broker', 1.0), ('intersects', 0.9013991118269608), ('CustomSlide', 0.8949342119678719), ('composite', 0.8604576531228855), ('Distance', 0.8572448957486365)]
Top words for pretrained_BERT neuron indx 980 [('repeat', 1.0), ('stat', 0.9647456026295124), ('wait', 0.9583214012737336), ('break', 0.8786234273633344), ('ranges', 0.8438763908357328)]
Top words for pretrained_BERT neuron indx 3038 [('bus', 1.0), ('Stream', 0.9147926060334339), ('district', 0.8943634211134779), ('Entity', 0.8505584831138865), ('Post', 0.8307172873426374)]
Top words for pretrained_BERT neuron indx 998 [('Proto', 1.0), ('length', 0.9124551404244597), ('year', 0.889284345579294), ('deploy', 0.887834113913292), ('v2', 0.8728250961651141)]
Top words for pretrained_BERT neuron indx 5094 [('no', 1.0), ('Asset', 0.9646618930211508), ('success', 0.963101243990285), ('asset', 0.9530365510984402), ('security', 0.9359942033298161)]
Top words for pretrained_BERT neuron indx 3058 [('bk', 1.0), ('OK', 0.8431299160807864), ('el', 0.7214564894373021), ('sid', 0.7208740240140425), ('LOGGING', 0.7153491359495006)]
Top words for pretrained_BERT neuron indx 9203 [('single', 1.0), ('95', 0.9938203664038286), ('TERMINATE', 0.964323914528807), ('VALUE', 0.9499725220670647), ('Frame', 0.9484004186823064)]
Top words for pretrained_BERT neuron indx 5123 [('Distance', 1.0), ('decimal', 0.8156430660898706), ('80', 0.7648100466236039), ('ROLE', 0.7395587602824649), ('topology', 0.7247437894142958)]
Top words for pretrained_BERT neuron indx 5125 [('services', 1.0), ('tls', 0.9873667720846911), ('requires', 0.9041963311319998), ('Geo', 0.902829920128328), ('providers', 0.8734049587063701)]
Top words for pretrained_BERT neuron indx 1039 [('broker', 1.0), ('el', 0.9386024152265283), ('Clock', 0.926895782860073), ('clock', 0.9209224327415299), ('Int', 0.9091856676586073)]
Top words for pretrained_BERT neuron indx 9234 [('purpose', 1.0), ('realm', 0.8950962386710135), ('audit', 0.8803465972515171), ('Module', 0.855574035728814), ('upstream', 0.8255286153549956)]
Top words for pretrained_BERT neuron indx 5139 [('management', 1.0), ('ur', 0.9885867611673897), ('cm', 0.9587341596598256), ('calculators', 0.9433666139814776), ('negotiate', 0.942752405765764)]
Top words for pretrained_BERT neuron indx 7191 [('communities', 1.0), ('RELEASE', 0.9188041510471655), ('Event', 0.8535971962044518), ('rest', 0.8185595464611432), ('restart', 0.7737664869594426)]
Top words for pretrained_BERT neuron indx 3098 [('PRIORITY', 1.0), ('LOG', 0.9352169400438486), ('try', 0.9283239207767375), ('services', 0.8514893080305104), ('INCOMPLETE', 0.8467945112914588)]
Top words for pretrained_BERT neuron indx 7195 [('bare', 1.0), ('ip', 0.9778508853677251), ('sr', 0.8761161123588194), ('"action"', 0.8680048472802891), ('False', 0.866348128189451)]
Top words for pretrained_BERT neuron indx 7205 [('deferred', 1.0), ('Region', 0.9472603037347643), ('sets', 0.8632279774403515), ('Subject', 0.8394797043678965), ('omit', 0.8334177254015865)]
Top words for pretrained_BERT neuron indx 1076 [('and', 1.0), ('in', 0.8906884490921863), ('".."', 0.8685345141037353), ('to', 0.8322022686215242), ('is', 0.7514481175687243)]
Top words for pretrained_BERT neuron indx 3125 [('dependencies', 1.0), ('TEMPLATES', 0.9762366246880264), ('do', 0.9524820685396926), ('MAXSIGLINES', 0.8854079889192417), ('presets', 0.8796030695828192)]
Top words for pretrained_BERT neuron indx 7223 [('"KILLED"', 1.0), ('"multiple"', 0.895544612338622), ('sel', 0.8645732544853205), ('"SUCCEEDED"', 0.8513387270218817), ('"include"', 0.8389845063098582)]
Top words for pretrained_BERT neuron indx 7231 [('3785', 1.0), ('fifteen', 0.9910389407028617), ('750', 0.985078689384525), ('81.4471435546875', 0.9791361477938744), ('74.616338', 0.9426071449534605)]
Top words for pretrained_BERT neuron indx 5188 [('http', 1.0), ('within', 0.9046460769271553), ('permission', 0.8983112953336954), ('300', 0.8441430411731452), ('LongType', 0.8374340093401303)]
Top words for pretrained_BERT neuron indx 7243 [('polygon', 1.0), ('WAY', 0.9716732399726011), ('walker', 0.9337026734380451), ('ROLE', 0.9149753098984648), ('RELATION', 0.9092600175693514)]
Top words for pretrained_BERT neuron indx 1101 [('subscribers', 1.0), ('sr', 0.9760520922014662), ('transfer', 0.9521668807123297), ('ah', 0.9073732265611227), ('Migration', 0.8753374111828228)]
Top words for pretrained_BERT neuron indx 1105 [('Command', 1.0), ('command', 0.9555160658111549), ('iq', 0.7702910964934181), ('Iq', 0.7314147900334549), ('chunks', 0.7121075048684277)]
Top words for pretrained_BERT neuron indx 9300 [('archive', 1.0), ('functional', 0.9680165695774267), ('MINIMUM', 0.9268309604735055), ('BaseWorker', 0.9125499750461781), ('MAXIMUM', 0.8605701454031944)]
Top words for pretrained_BERT neuron indx 7257 [('BBOX', 1.0), ('srid', 0.9450484800331381), ('find_plan_splits', 0.8680393464377275), ('ay', 0.8212780728397018), ('GetBoard', 0.81096232310418)]
Top words for pretrained_BERT neuron indx 3168 [('75', 1.0), ('36', 0.9860748905794043), ('95', 0.8633988848859518), ('69', 0.8310839641932026), ('96', 0.7847939467812568)]
Top words for pretrained_BERT neuron indx 9312 [('agency', 1.0), ('reddit', 0.9900603073774963), ('five', 0.9787216771780533), ('presence', 0.9315438220103377), ('pisa', 0.8790618615552174)]
Top words for pretrained_BERT neuron indx 9314 [('If', 1.0), ('Else', 0.7990779079792419), ('Iq', 0.7496890939115991), ('while', 0.7256038649978118), ('RELATIONS', 0.6895762518108214)]
Top words for pretrained_BERT neuron indx 5239 [('branches', 1.0), ('partial', 0.9943239820646341), ('chunks', 0.9840255938742359), ('implementation', 0.9604710734651557), ('sets', 0.9489787656314891)]
Top words for pretrained_BERT neuron indx 9340 [('scheme', 1.0), ('"happy_birthday"', 0.9256195268570926), ('createreport', 0.9034947260742613), ('Assign', 0.9007973791666631), ('openwatch', 0.8220884600134168)]
Top words for pretrained_BERT neuron indx 9352 [('MultiPolygon', 1.0), ('Int', 0.9229017053240259), ('512', 0.8583413835923193), ('If', 0.8473056681690697), ('horizon', 0.8360911955796514)]
Top words for pretrained_BERT neuron indx 7317 [('if', 1.0), ('while', 0.9531818385658943), ('secret', 0.9431056342789187), ('If', 0.9162422974115538), ('or', 0.8812446153996519)]
Top words for pretrained_BERT neuron indx 9377 [('variables', 1.0), ('exists', 0.9878720409105743), ('microseconds', 0.9754485986312296), ('False', 0.9403014494332109), ('milliseconds', 0.9016298478559739)]
Top words for pretrained_BERT neuron indx 5294 [('identical', 1.0), ('duplicating', 0.9053529818444979), ('Column', 0.9032521223470238), ('sites', 0.9030769314961209), ('Criteria', 0.8984933551054524)]
Top words for pretrained_BERT neuron indx 1204 [('choice', 1.0), ('props', 0.9913512194970785), ('Manager', 0.9571163192479818), ('ct', 0.9277598923592342), ('Output', 0.9257074127701415)]
Top words for pretrained_BERT neuron indx 5313 [('http', 1.0), ('302', 0.9564484960706412), ('http11', 0.9555361049401351), ('services', 0.9260899347181144), ('23', 0.9246097729438911)]
Top words for pretrained_BERT neuron indx 7367 [('organization', 1.0), ('Subject', 0.9000191899220059), ('Mesh', 0.8899830462095356), ('region', 0.8446835658453377), ('Region', 0.8246041128664209)]
Top words for pretrained_BERT neuron indx 7379 [('Provider', 1.0), ('oslo', 0.9718815631908551), ('broker', 0.8320661056711464), ('2.1', 0.8157582827051038), ('0.04', 0.79885917354924)]
Top words for pretrained_BERT neuron indx 3299 [('WAY', 1.0), ('WAYS', 0.8847650464039614), ('Geo', 0.7853465476784809), ('simplify', 0.7803779028965253), ('celery', 0.7405020467721987)]
Top words for pretrained_BERT neuron indx 3302 [('convert', 1.0), ('destroy', 0.8912517168854582), ('pass', 0.86803072695005), ('purge', 0.8366020318606432), ('clean', 0.808924125857232)]
Top words for pretrained_BERT neuron indx 7399 [('999999', 1.0), ('or', 0.9246373687934191), ('1800', 0.9159313007491161), ('LoadUser', 0.8689101825118172), ('"http://"', 0.8390337875895878)]
Top words for pretrained_BERT neuron indx 7408 [('GetMirror', 1.0), ('GetContent', 0.9463468929408287), ('framing', 0.9409832669616475), ('excepts', 0.9357456555203736), ('AREA', 0.916411263100828)]
Top words for pretrained_BERT neuron indx 9468 [('sender', 1.0), ('Renderer', 0.8657341279657285), ('ADVERTISE', 0.857006381980713), ('actions', 0.8560926879682517), ('renderers', 0.828629743263046)]
Top words for pretrained_BERT neuron indx 9472 [('functional', 1.0), ('interval', 0.9567196953552799), ('sender', 0.9338176023126314), ('Plugin', 0.8820161043744708), ('principal', 0.8287246185440309)]
Top words for pretrained_BERT neuron indx 9474 [('plural', 1.0), ('ALPHABET', 0.9070251337131728), ('audit', 0.8529199744938525), ('flat', 0.8400061099243017), ('Column', 0.8333559310183973)]
Top words for pretrained_BERT neuron indx 9477 [('oslo', 1.0), ('81.4471435546875', 0.9403538113948214), ('Int', 0.9348950955594979), ('"error"', 0.8547428780758688), ('ContextTask', 0.8470240136809256)]
Top words for pretrained_BERT neuron indx 7431 [('ur', 1.0), ('up', 0.9223284171214018), ('117', 0.9158290069006647), ('avail', 0.8777651400890437), ('identical', 0.8763503037967928)]
Top words for pretrained_BERT neuron indx 7432 [('62', 1.0), ('75', 0.996771975359936), ('window', 0.9901362193138847), ('"oslo"', 0.9766714120425566), ('33', 0.9718939200456467)]
Top words for pretrained_BERT neuron indx 1299 [('ssl', 1.0), ('RELATIONS', 0.9890584042302112), ('Billboard', 0.9818226438594396), ('contents', 0.9129647735661993), ('RELEASE', 0.9123256994097358)]
Top words for pretrained_BERT neuron indx 9495 [('If', 1.0), ('google', 0.7424077061747996), ('REF', 0.685098777439186), ('if', 0.650305882573201), ('On', 0.6269361375127596)]
Top words for pretrained_BERT neuron indx 7450 [('"multiple"', 1.0), ('OK', 0.996498638832831), ('"Text"', 0.9946826449428029), ('"oslo"', 0.9624297712925436), ('"Resource"', 0.9378484390525432)]
Top words for pretrained_BERT neuron indx 5417 [('ex', 1.0), ('302', 0.9474250243542017), ('204', 0.9456696606051148), ('trial', 0.9338259679248366), ('framing', 0.8906406556005394)]
Top words for pretrained_BERT neuron indx 7468 [('bk', 1.0), ('by', 0.8944192043968239), ('On', 0.7598803028101095), ('ON', 0.7598803028101095), ('from', 0.6924457944141311)]
Top words for pretrained_BERT neuron indx 9517 [('PIECE', 1.0), ('21', 0.9356359775385928), ('dir', 0.8434745700623417), ('bk', 0.7769693263656661), ('five', 0.7684632631357913)]
Top words for pretrained_BERT neuron indx 3380 [('and', 1.0), ('in', 0.937575482322325), ('is', 0.9336249551198733), ('with', 0.8418897458912594), ('as', 0.8326306242939852)]
Top words for pretrained_BERT neuron indx 9533 [('MINIMUM', 1.0), ('python', 0.9949693443351112), ('quota', 0.9767662564168971), ('baseline', 0.8976605194264818), ('REFERENCES', 0.8486597177160393)]
Top words for pretrained_BERT neuron indx 5438 [('EGP', 1.0), ('ND', 0.9878872499781717), ('ndt', 0.982277581973191), ('IGP', 0.8813254340261778), ('OSM', 0.85364656483014)]
Top words for pretrained_BERT neuron indx 3393 [('WAYS', 1.0), ('WAY', 0.7956804805196497), ('confirm', 0.7301759579694606), ('hidden', 0.7268672098955474), ('1800', 0.7205007105903021)]
Top words for pretrained_BERT neuron indx 7497 [('"data"', 1.0), ('pattern', 0.980193932885938), ('"multiple"', 0.9349749400968211), ('ur', 0.9338854730348706), ('"sequence"', 0.910853698253388)]
Top words for pretrained_BERT neuron indx 1356 [('alt', 1.0), ('mac', 0.9509859995728628), ('select', 0.9401305611422143), ('counts', 0.9121492893575786), ('commits', 0.9074965830572415)]
Top words for pretrained_BERT neuron indx 7500 [('pid', 1.0), ('one', 0.9352417482088411), ('rd', 0.8901792034588318), ('CREATING', 0.8699348015361863), ('future', 0.8591080927057599)]
Top words for pretrained_BERT neuron indx 7507 [('buttons', 1.0), ('NODES', 0.9834762040010375), ('button', 0.9633377789013032), ('Column', 0.9447376349556439), ('Geo', 0.9440325546550881)]
Top words for pretrained_BERT neuron indx 7519 [('42', 1.0), ('providers', 0.7524068585395329), ('Parent', 0.693949547785008), ('within', 0.6911208666284985), ('other', 0.6582548525676638)]
Top words for pretrained_BERT neuron indx 5472 [('decimal', 1.0), ('geos', 0.9418303459732197), ('tls', 0.9338263956575613), ('compat', 0.929471232136902), ('bson', 0.9242329985546578)]
Top words for pretrained_BERT neuron indx 3428 [('MEMBER', 1.0), ('TAG', 0.9998747679856506), ('store', 0.9898093971608963), ('Tag', 0.9749657475745527), ('def', 0.9545570239147356)]
Top words for pretrained_BERT neuron indx 5482 [('oslo', 1.0), ('2014', 0.9356719126877365), ('fifteen', 0.8727325330251986), ('187', 0.8356932139436084), ('second_branch', 0.8254326597544678)]
Top words for pretrained_BERT neuron indx 7537 [('secret', 1.0), ('PIECE', 0.7011191750633597), ('abstract', 0.6707896508381378), ('height', 0.6677343774286095), ('ahead', 0.6665652821182229)]
Top words for pretrained_BERT neuron indx 9588 [('File', 1.0), ('scheme', 0.8943813755172169), ('Migration', 0.8856889341952294), ('400', 0.7289527684315631), ('40', 0.6750066020448698)]
Top words for pretrained_BERT neuron indx 9590 [('StringType', 1.0), ('TRANSITIVE', 0.9817224071888774), ('hour', 0.9352624155627699), ('READY', 0.9261007320532911), ('Genie2', 0.9255935298721628)]
Top words for pretrained_BERT neuron indx 1401 [('999999', 1.0), ('asset', 0.8867344423139178), ('brightness', 0.8798235259938076), ('called', 0.8443911443879071), ('3128', 0.8377973675545706)]
Top words for pretrained_BERT neuron indx 1403 [('apache', 1.0), ('Venue', 0.9985040770692502), ('signed', 0.9492769815158573), ('venue', 0.9435881906415077), ('signals', 0.8951957141195326)]
Top words for pretrained_BERT neuron indx 7554 [('"SUCCEEDED"', 1.0), ('unicode', 0.9682615624598832), ('On', 0.9585692917556093), ('ON', 0.9585692917556093), ('23', 0.9276138983056625)]
Top words for pretrained_BERT neuron indx 1413 [('quality', 1.0), ('abstract', 0.935212865730625), ('each', 0.9134960897705556), ('interval', 0.9092258287672539), ('profile', 0.8955776155110204)]
Top words for pretrained_BERT neuron indx 9609 [('Crawler', 1.0), ('ex', 0.9429930979278868), ('unicode', 0.8589573977584735), ('Authorization', 0.8460615431656062), ('composite', 0.809415306367233)]
Top words for pretrained_BERT neuron indx 7564 [('999999', 1.0), ('intersects', 0.9983939947832909), ('compute', 0.9180662195195463), ('0.04', 0.8555493179179872), ('remember', 0.8408601688176326)]
Top words for pretrained_BERT neuron indx 5517 [('unicode', 1.0), ('buttons', 0.9357943106869446), ('sans', 0.856732180079341), ('commands', 0.8490567285647072), ('deploy', 0.8131246780201301)]
Top words for pretrained_BERT neuron indx 7568 [('tell', 1.0), ('READY', 0.9400409643322479), ('PROVISION', 0.7653102007355076), ('RESERVE', 0.7602526219485556), ('submit', 0.7287399176087521)]
Top words for pretrained_BERT neuron indx 1431 [('blank', 1.0), ('sid', 0.9831925970113499), ('prefixLen', 0.9512239128002654), ('quote', 0.9021970513713654), ('35', 0.8503102667995664)]
Top words for pretrained_BERT neuron indx 7579 [('"warning"', 1.0), ('"x"', 0.943184935295028), ('"shared"', 0.9308279859718803), ('"display"', 0.8929278497817882), ('36', 0.853981804684291)]
Top words for pretrained_BERT neuron indx 1440 [('Column', 1.0), ('ADVERTISE', 0.9464519515984214), ('purpose', 0.9065596283249048), ('closing', 0.8419542683716796), ('secret', 0.8070693973009845)]
Top words for pretrained_BERT neuron indx 1451 [('RESERVE', 1.0), ('reserve', 0.9978078243766973), ('discovery', 0.7180906528219019), ('95', 0.7180471805094004), ('splits', 0.6747079888467405)]
Top words for pretrained_BERT neuron indx 9658 [('69', 1.0), ('emitter', 0.8414600432027757), ('14', 0.7973818878895803), ('purpose', 0.7382713243122156), ('depth', 0.6999134286329086)]
Top words for pretrained_BERT neuron indx 7611 [('fifteen', 1.0), ('deploy', 0.836627314523759), ('destroy', 0.740623443070381), ('five', 0.7124171698999332), ('tell', 0.71015381506121)]
Top words for pretrained_BERT neuron indx 1469 [('choice', 1.0), ('sts', 0.9152760369563215), ('license', 0.8461663957143865), ('enabled', 0.8419132859468522), ('display', 0.7861123449530804)]
Top words for pretrained_BERT neuron indx 9665 [('80', 1.0), ('302', 0.9504479523966233), ('95', 0.9486049381655678), ('75', 0.935717675097353), ('importRTs', 0.9226352178532901)]
Top words for pretrained_BERT neuron indx 7619 [('organization', 1.0), ('Padding', 0.8930169002924838), ('Bytes', 0.8857265089696132), ('"://"', 0.8552201211671767), ('not', 0.808686750263334)]
Top words for pretrained_BERT neuron indx 7636 [('python', 1.0), ('Iq', 0.9386412968782182), ('broker', 0.898633216297995), ('Route', 0.7778171600569735), ('behind', 0.7772726425565356)]
Top words for pretrained_BERT neuron indx 5591 [('On', 1.0), ('ON', 1.0), ('services', 0.7989089102595555), ('reservation', 0.7966479255283012), ('seen', 0.7565275492257117)]
Top words for pretrained_BERT neuron indx 7642 [('with', 1.0), ('bk', 0.9761195274499972), ('Criteria', 0.9043855056568371), ('criteria', 0.8563437838735309), ('Label', 0.8225503303859238)]
Top words for pretrained_BERT neuron indx 5601 [('listen', 1.0), ('WITHDRAW', 0.9471007031106423), ('Widget', 0.8997715712613504), ('Else', 0.895900133848592), ('broadcast', 0.8662867769537673)]
Top words for pretrained_BERT neuron indx 9697 [('GEOSGeometry', 1.0), ('127', 0.9608876823073781), ('year', 0.9171472905698316), ('branch', 0.8615066885183598), ('ts', 0.8601558834915474)]
Top words for pretrained_BERT neuron indx 5606 [('2014', 1.0), ('define', 0.9427533346282266), ('BOUNDS', 0.9362981303639571), ('127', 0.9255133034833254), ('pass', 0.9253070793305889)]
Top words for pretrained_BERT neuron indx 1511 [('patterns', 1.0), ('tv', 0.9750733356265369), ('policy', 0.96821290604728), ('uid', 0.9645897936244678), ('enable', 0.9559040613998857)]
Top words for pretrained_BERT neuron indx 5608 [('score', 1.0), ('trial', 0.9628165064736204), ('kw', 0.9050436542683367), ('chunks', 0.8930029984949454), ('ADVERTISE', 0.8808760354444508)]
Top words for pretrained_BERT neuron indx 7662 [('CANCEL', 1.0), ('fifteen', 0.9319446806611884), ('cancel', 0.8834120554823014), ('List', 0.8502532602760751), ('GetBoard', 0.8250722499898149)]
Top words for pretrained_BERT neuron indx 7667 [('within', 1.0), ('VALUE', 0.9401756086444454), ('negotiate', 0.9114697801172582), ('DBPORT', 0.8815429682154972), ('mins', 0.8348336213455086)]
Top words for pretrained_BERT neuron indx 7668 [('for', 1.0), ('descriptor', 0.997018044447778), ('Descriptor', 0.9717369668152918), ('17', 0.9117447483106913), ('0o555', 0.8778388253897355)]
Top words for pretrained_BERT neuron indx 5631 [('Delay', 1.0), ('25', 0.9345416133327916), ('Billboard', 0.8809327927439004), ('no', 0.8481452958663528), ('apache', 0.8343157189315545)]
Top words for pretrained_BERT neuron indx 3587 [('topology', 1.0), ('decimal', 0.923616095164236), ('80', 0.9024566511324816), ('OK', 0.8979496006961684), ('direct', 0.8877929059564015)]
Top words for pretrained_BERT neuron indx 1543 [('erase', 1.0), ('Simple', 0.949161513782641), ('200', 0.9456810494353827), ('AFI', 0.9387758146533115), ('brightness', 0.9115847813290137)]
Top words for pretrained_BERT neuron indx 7698 [('ax', 1.0), ('plural', 0.9750192485525411), ('each', 0.9629485897820853), ('LOGGING', 0.8815137968329463), ('Simple', 0.8382073846587046)]
Top words for pretrained_BERT neuron indx 7706 [('communities', 1.0), ('"0301000000001122aabbccdd0102030405060708"', 0.9773882750193297), ('"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.9139415432603387), ('"0800305c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.9073810621994631), ('"63646566676869"', 0.893448575923547)]
Top words for pretrained_BERT neuron indx 7708 [('75', 1.0), ('P2PServiceBaseType', 0.8799159083610466), ('venue', 0.8432412872300663), ('MultiPolygon', 0.8244705812029908), ('requires', 0.8136986246726836)]
Top words for pretrained_BERT neuron indx 3615 [('if', 1.0), ('Auditor', 0.8890753643156195), ('If', 0.8853616263315435), ('fragment', 0.840274158106195), ('exception', 0.8114576531740089)]
Top words for pretrained_BERT neuron indx 5669 [('omit', 1.0), ('deferred', 0.984570129549396), ('Region', 0.8971146891403031), ('agency', 0.8506521747500511), ('Subject', 0.7993236237748691)]
Top words for pretrained_BERT neuron indx 9771 [('functional', 1.0), ('imports', 0.9639799814092804), ('with', 0.9371295081406991), ('bson', 0.9353552637427246), ('2014', 0.9227038467265158)]
Top words for pretrained_BERT neuron indx 9772 [('bk', 1.0), ('1800', 0.970736780822791), ('libraries', 0.942598561586561), ('by', 0.8709985214050406), ('MEMBERS', 0.8056665741216844)]
Top words for pretrained_BERT neuron indx 7733 [('VALUE', 1.0), ('MultiPolygon', 0.8845812662083172), ('with', 0.8676951165871728), ('compute', 0.8541494961880668), ('DFConstant', 0.8410808805552513)]
Top words for pretrained_BERT neuron indx 5691 [('with', 1.0), ('quota', 0.956277640550526), ('BOUNDS', 0.9519390459541421), ('ajax', 0.9026765380737611), ('randomize', 0.8895204620654217)]
Top words for pretrained_BERT neuron indx 9799 [('five', 1.0), ('fifteen', 0.8420656946447654), ('55', 0.8338224772659435), ('SECONDS', 0.7987140533039858), ('25', 0.7516094982899615)]
Top words for pretrained_BERT neuron indx 3655 [('old', 1.0), ('agency', 0.9357002749368908), ('called', 0.8472515007365141), ('decimal', 0.8244354301673436), ('CONNECTED', 0.8105636345032383)]
Top words for pretrained_BERT neuron indx 7764 [('GEOSGeometry', 1.0), ('Widget', 0.9913600384380447), ('gf', 0.9692487845651255), ('Redshift', 0.812616091733752), ('decimal', 0.8054536185035764)]
Top words for pretrained_BERT neuron indx 5720 [('42', 1.0), ('ll', 0.9050385470327197), ('decimal', 0.8956886086329995), ('variables', 0.8640426918931684), ('40', 0.7981139328884491)]
Top words for pretrained_BERT neuron indx 7776 [('bson', 1.0), ('oslo', 0.9988325135734218), ('tls', 0.9234589460990287), ('pisa', 0.9160298018702464), ('zone', 0.913564919667739)]
Top words for pretrained_BERT neuron indx 9832 [('microseconds', 1.0), ('milliseconds', 0.7588425953684557), ('CommandMock', 0.7278240890199774), ('trello', 0.6777778204412898), ('AFI', 0.6649208675539824)]
Top words for pretrained_BERT neuron indx 5737 [('alembic', 1.0), ('__exit__', 0.9982909637524777), ('VALUE', 0.9914099225988484), ('55', 0.9892520903844263), ('__description__', 0.9774844083161942)]
Top words for pretrained_BERT neuron indx 9835 [('registerDecoder', 1.0), ('getreport', 0.9317523995768027), ('RELATION', 0.9261920152378799), ('reflection', 0.9244489422175013), ('getplans', 0.8925489703099868)]
Top words for pretrained_BERT neuron indx 9859 [('2.1', 1.0), ('tagtuple', 0.8554074629030034), ('redistricting', 0.8544637572865477), ('calculators', 0.8303675254590043), ('reddit', 0.8248003218295795)]
Top words for pretrained_BERT neuron indx 7817 [('flat', 1.0), ('within', 0.8936015427416452), ('frame', 0.8596508321559224), ('created', 0.7871686119138795), ('millis', 0.7636361860628649)]
Top words for pretrained_BERT neuron indx 9869 [('If', 1.0), ('Seq', 0.9914193487747955), ('LoggedIn', 0.9348619684703392), ('subscriptions', 0.9152385500918937), ('backends', 0.9009787381017067)]
Top words for pretrained_BERT neuron indx 3726 [('OSM', 1.0), ('PIECE', 0.9667215894299225), ('within', 0.8948534303861886), ('lon__lt', 0.8463251887418924), ('Repository', 0.8194466574843265)]
Top words for pretrained_BERT neuron indx 5781 [('CONNECTED', 1.0), ('success', 0.967254596538423), ('reflection', 0.9567129192187552), ('Migration', 0.9199237291432764), ('twisted', 0.9183853894551962)]
Top words for pretrained_BERT neuron indx 7832 [('buttons', 1.0), ('Always', 0.9897892349858849), ('2014', 0.8876921214886788), ('except', 0.8678310729399641), ('processors', 0.7986592259626862)]
Top words for pretrained_BERT neuron indx 9881 [('187', 1.0), ('TERMINATE', 0.8669780413248906), ('Job', 0.8410784885570978), ('terminate', 0.8249488852959562), ('Auditor', 0.7850937197476765)]
Top words for pretrained_BERT neuron indx 3744 [('purpose', 1.0), ('protocol', 0.7990529752594534), ('CONNECTED', 0.7688050876117605), ('composite', 0.7486223693573728), ('Point', 0.7398238554165227)]
Top words for pretrained_BERT neuron indx 5795 [('except', 1.0), ('with', 0.8782073449985162), ('if', 0.8671585030178021), ('bagpipe', 0.8096615020359326), ('oslo', 0.803476701023588)]
Top words for pretrained_BERT neuron indx 5802 [('pattern', 1.0), ('capacity', 0.9986691176816159), ('composite', 0.969295450261072), ('width', 0.9133826127721882), ('moderate', 0.9026512032183996)]
Top words for pretrained_BERT neuron indx 7862 [('secret', 1.0), ('ah', 0.9901081597296665), ('Asset', 0.9795759104144427), ('REFERENCES', 0.9775386693992881), ('1970', 0.9162023161285264)]
Top words for pretrained_BERT neuron indx 3771 [('getType', 1.0), ('Off', 0.9941243873908187), ('quota', 0.9930996174349207), ('loading', 0.9373059321606532), ('enabled', 0.8784748419098882)]
Top words for pretrained_BERT neuron indx 5826 [('ignore', 1.0), ('Default', 0.9778483975595894), ('tell', 0.9606183085444377), ('75', 0.9227140828536875), ('"FAILED"', 0.9044152228588115)]
Top words for pretrained_BERT neuron indx 5827 [('template', 1.0), ('seek', 0.975762861869026), ('bk', 0.964322327486838), ('operator', 0.955026324975829), ('pk', 0.9475625224193501)]
Top words for pretrained_BERT neuron indx 3791 [('cancel', 1.0), ('python', 0.975089145553206), ('closing', 0.9670471941198826), ('ah', 0.9667155210237252), ('CANCEL', 0.9652390712290023)]
Top words for pretrained_BERT neuron indx 1766 [('Proto', 1.0), ('v2', 0.906952087283568), ('communities', 0.7948087105560531), ('BOUNDS', 0.7870848276467283), ('genie', 0.7855340204367589)]
Top words for pretrained_BERT neuron indx 7929 [('15596', 1.0), ('15598', 0.9555752509395558), ('detect', 0.9223451608727874), ('15597', 0.9013039235114012), ('89.999999999999992', 0.8497055046911923)]
Top words for pretrained_BERT neuron indx 3833 [('criterion', 1.0), ('Task', 0.9795798905394509), ('exception', 0.9524385419656537), ('ROLE', 0.8579044260405807), ('exists', 0.7992564540379307)]
Top words for pretrained_BERT neuron indx 7945 [('in', 1.0), ('1800', 0.9167788927457055), ('utc', 0.9155293489391567), ('90.0', 0.8803807864786278), ('milliseconds', 0.8456917981814758)]
Top words for pretrained_BERT neuron indx 1802 [('ELEMENT', 1.0), ('Prefix', 0.9105467337900879), ('element', 0.8638384006961066), ('digest', 0.7974091411570153), ('Digest', 0.7836151087963992)]
Top words for pretrained_BERT neuron indx 5905 [('decimal', 1.0), ('excepts', 0.9025966043647206), ('has', 0.784874335949904), ('old', 0.7586780550343113), ('If', 0.739682556610609)]
Top words for pretrained_BERT neuron indx 5907 [('providers', 1.0), ('validators', 0.901382490183887), ('Verifier', 0.8958428637092185), ('remember', 0.8891896186423641), ('Auditor', 0.8873197725640327)]
Top words for pretrained_BERT neuron indx 7965 [('erase', 1.0), ('no', 0.9979774482488549), ('principal', 0.8941428224361357), ('zone', 0.8873951192305894), ('opacity', 0.8655491056058705)]
Top words for pretrained_BERT neuron indx 7973 [('sets', 1.0), ('Region', 0.9875855241971375), ('is', 0.9515106619838783), ('Subject', 0.8901301149095919), ('deferred', 0.8895278948614671)]
Top words for pretrained_BERT neuron indx 5928 [('providers', 1.0), ('backwards', 0.9789706906159017), ('by', 0.9431373016510967), ('decoded', 0.9247579879602899), ('meth', 0.8813184181951698)]
Top words for pretrained_BERT neuron indx 5931 [('MEMBER', 1.0), ('Module', 0.9633763603641327), ('Invalid', 0.9561620375509678), ('functional', 0.9386400068561029), ('ADVERTISE', 0.8736674456472662)]
Top words for pretrained_BERT neuron indx 1844 [('and', 1.0), ('in', 0.907933708790136), ('to', 0.8531923830407232), ('is', 0.8480226399220433), ('".."', 0.846639740618333)]
Top words for pretrained_BERT neuron indx 1853 [('baseline', 1.0), ('python', 0.8993209489804841), ('bk', 0.8539711513517068), ('MAXIMUM', 0.8214299392550827), ('email', 0.7536423499459046)]
Top words for pretrained_BERT neuron indx 7999 [('750', 1.0), ('3785', 0.9496977074818447), ('74.616338', 0.9327965782586812), ('is', 0.9168091347465521), ('4095', 0.9099605163633783)]
Top words for pretrained_BERT neuron indx 3913 [('42', 1.0), ('If', 0.9747296624325167), ('return', 0.9094420212382842), ('import', 0.8885114406773741), ('execute', 0.8690659296094095)]
Top words for pretrained_BERT neuron indx 3971 [('space', 1.0), ('vol', 0.992451228077872), ('if', 0.9163760097481218), ('ms', 0.8917846075749516), ('Switch', 0.8506327213002705)]
Top words for pretrained_BERT neuron indx 8070 [('42', 1.0), ('75', 0.9619317470618053), ('2014', 0.8974451809967002), ('"0"', 0.8810297463640423), ('"r"', 0.7795966135413958)]
Top words for pretrained_BERT neuron indx 6030 [('flat', 1.0), ('called', 0.833717186035708), ('def', 0.7530856935023537), ('95', 0.7428843009443987), ('import', 0.7041629933353475)]
Top words for pretrained_BERT neuron indx 6032 [('tell', 1.0), ('agency', 0.8402320756938125), ('negotiate', 0.7084149380459248), ('READY', 0.6590556379896975), ('BOUNDS', 0.648653433999444)]
Top words for pretrained_BERT neuron indx 1937 [('ts', 1.0), ('nh', 0.9027549433323768), ('Core', 0.8276138851646608), ('USAGE', 0.7921512084649815), ('Billboard', 0.7581468824716788)]
Top words for pretrained_BERT neuron indx 6046 [('TYPE', 1.0), ('sdi', 0.9280962225486462), ('directionality', 0.8926380501604918), ('topology', 0.8316777590386208), ('DistrictFile', 0.815388293467288)]
Top words for pretrained_BERT neuron indx 6050 [('implementation', 1.0), ('decimal', 0.9348591760768215), ('continue', 0.8564647145742543), ('Parameter', 0.7580302341490386), ('enclosure', 0.7305326824671659)]
Top words for pretrained_BERT neuron indx 6058 [('NODES', 1.0), ('sender', 0.9531021296644908), ('startTime', 0.8568699711701574), ('with', 0.8567895944996975), ('Adapter', 0.8435075480039088)]
Top words for pretrained_BERT neuron indx 6075 [('1800', 1.0), ('behind', 0.9370454845174782), ('WAYS', 0.865175732360103), ('KeyboardInterrupt', 0.8138990071270769), ('75', 0.7983979053778648)]
Top words for pretrained_BERT neuron indx 6081 [('services', 1.0), ('MEMBERS', 0.8965112602812704), ('synchronized', 0.8641888766306425), ('GENERATOR', 0.8423431240149185), ('continue', 0.8135303651589351)]
Top words for pretrained_BERT neuron indx 8147 [('oslo', 1.0), ('Provider', 0.9736605971216193), ('broker', 0.9263603416447922), ('If', 0.8725670788338254), ('"{0}.{1}.{2}"', 0.8489997245527497)]
Top words for pretrained_BERT neuron indx 2009 [('asset', 1.0), ('Asset', 0.999794520162673), ('yinit', 0.9254823335417505), ('delay', 0.921326275421489), ('processors', 0.9091522614145766)]
Top words for pretrained_BERT neuron indx 4067 [('WAY', 1.0), ('WAYS', 0.9742262731088802), ('celery', 0.9494386904778749), ('simplify', 0.9017311712272357), ('files', 0.8828075850044275)]
Top words for pretrained_BERT neuron indx 8163 [('False', 1.0), ('intersects', 0.9765988522282076), ('exabgp', 0.9563804094484574), ('ElasticSearchServiceItem', 0.9201056372428991), ('runner', 0.9035120204864512)]
Top words for pretrained_BERT neuron indx 8167 [('oslo', 1.0), ('999999', 0.987369968090329), ('"y"', 0.9371146600392735), ('or', 0.8980642772176277), ('ay', 0.8534421330387825)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0180
Epoch: [2/10], Loss: 0.0124
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.38
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0178
Epoch: [2/10], Loss: 0.0124
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.38
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0179
Epoch: [2/10], Loss: 0.0124
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0070
Epoch: [9/10], Loss: 0.0067
Epoch: [10/10], Loss: 0.0064
Score (accuracy) of the probe: 0.38
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0187
Epoch: [2/10], Loss: 0.0136
Epoch: [3/10], Loss: 0.0110
Epoch: [4/10], Loss: 0.0106
Epoch: [5/10], Loss: 0.0101
Epoch: [6/10], Loss: 0.0098
Epoch: [7/10], Loss: 0.0096
Epoch: [8/10], Loss: 0.0096
Epoch: [9/10], Loss: 0.0094
Epoch: [10/10], Loss: 0.0093
Score (accuracy) of the probe: 0.38

The best l1=0, the best l2=0.01 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.32
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.16

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.5012419274714357
----------------------------------------------------------------
