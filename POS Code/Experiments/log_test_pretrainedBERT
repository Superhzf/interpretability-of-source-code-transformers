Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
7656 13.0
Number of tokens:  72951
length of source dictionary:  5099
length of target dictionary:  42
72951
Total instances: 72951
[')', 'DigestItem', 'max_districts', 'IntEnum', '_extractErrorMessage', 'keyfile', 'compatible_view', 'vwwn', 'release_range_ids', '0.1', 'zope', 'sampleArgArray', 'ntlm_client', '"1.2.3"', 'REFRESH_TOKEN_LEN', 'subscribers', 'ref', 'GetInt', 'Plugin', 'ERROR']
Number of samples:  72951
Stats: Labels with their frequencies in the final set
NAME 23204
NEWLINE 6586
DOT 5889
LPAR 5444
RPAR 5263
KEYWORD 5018
COMMA 4364
EQUAL 3897
COLON 2622
DEDENT 1878
INDENT 1593
NUMBER 1356
LSQB 1291
RSQB 1267
NL 1069
STRING 550
LBRACE 293
EQEQUAL 226
RBRACE 211
PLUS 200
PERCENT 109
STAR 94
MINUS 83
AT 61
DOUBLESTAR 60
GREATER 59
PLUSEQUAL 52
NOTEQUAL 44
LEFTSHIFT 31
LESS 29
LESSEQUAL 18
COMMENT 15
GREATEREQUAL 15
SEMI 13
VBAR 12
SLASH 11
TILDE 7
ELLIPSIS 6
AMPER 5
MINEQUAL 3
ERRORTOKEN 2
RIGHTSHIFT 1
pretrained_BERT distribution after trauncating:
{0: 0.7701805629314923, 3: 0.16655602761550717, 2: 0.045007966011683484, 1: 0.01825544344131705}
{0: 23204, 3: 5018, 2: 1356, 1: 550}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
5985 13.0
Number of tokens:  64699
length of source dictionary:  3727
length of target dictionary:  42
64699
Total instances: 64699
[')', 'tupl', 'tp', 'pq', 'set_order', '"sequence(target+3\\\'+5\\\')"', 'end_location', 'check_unregistered', 'test__pretty', 'testmod', 'infile', 'mid', '9', 'pearsonr', 'files_to_test', 'stocksAtThisPath', 'oldpath', 'setup_class', 'rowstart', 'spec']
Number of samples:  64699
Stats: Labels with their frequencies in the final set
NAME 20893
NEWLINE 5444
DOT 5083
COMMA 4481
RPAR 4279
LPAR 4277
KEYWORD 3639
EQUAL 3459
NUMBER 2218
COLON 1972
LSQB 1939
RSQB 1927
DEDENT 1387
INDENT 1203
NL 540
STRING 324
MINUS 262
PLUS 248
STAR 236
EQEQUAL 141
LBRACE 128
RBRACE 126
SLASH 122
PERCENT 69
DOUBLESTAR 55
PLUSEQUAL 50
GREATER 47
NOTEQUAL 32
COMMENT 22
LESS 20
STAREQUAL 16
GREATEREQUAL 16
AT 10
MINEQUAL 7
SEMI 7
VBAR 6
LESSEQUAL 5
AMPER 3
SLASHEQUAL 2
DOUBLESLASH 2
TILDE 1
LEFTSHIFT 1
pretrained_BERT distribution after trauncating:
{0: 0.7716997857723277, 3: 0.134409396468937, 2: 0.08192361675408141, 1: 0.011967201004653911}
{0: 20893, 3: 3639, 2: 2218, 1: 324}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 13506, 3: 1019, 1: 491, 2: 136})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({2: 2039, 0: 1882, 3: 68, 1: 37})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (13636, 9984)
The shape of the validation set: (1516, 9984)
The shape of the testing set: (4026, 9984)
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0011
Epoch: [4/10], Loss: 0.0007
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0101
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0011
Epoch: [4/10], Loss: 0.0007
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0100
Epoch: [2/10], Loss: 0.0043
Epoch: [3/10], Loss: 0.0013
Epoch: [4/10], Loss: 0.0009
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0004
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0113
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0030
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0025
Score (accuracy) of the probe: 0.90
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0175
Epoch: [2/10], Loss: 0.0140
Epoch: [3/10], Loss: 0.0119
Epoch: [4/10], Loss: 0.0122
Epoch: [5/10], Loss: 0.0118
Epoch: [6/10], Loss: 0.0112
Epoch: [7/10], Loss: 0.0107
Epoch: [8/10], Loss: 0.0100
Epoch: [9/10], Loss: 0.0093
Epoch: [10/10], Loss: 0.0087
Score (accuracy) of the probe: 0.82
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0297
Epoch: [2/10], Loss: 0.0202
Epoch: [3/10], Loss: 0.0184
Epoch: [4/10], Loss: 0.0168
Epoch: [5/10], Loss: 0.0153
Epoch: [6/10], Loss: 0.0141
Epoch: [7/10], Loss: 0.0129
Epoch: [8/10], Loss: 0.0119
Epoch: [9/10], Loss: 0.0110
Epoch: [10/10], Loss: 0.0102
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=10 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.51
{'__OVERALL__': 0.5096870342771982, 'NAME': 1.0, 'STRING': 0.8108108108108109, 'NUMBER': 0.06866110838646396, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0053
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0052
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0092
Epoch: [2/10], Loss: 0.0054
Epoch: [3/10], Loss: 0.0039
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0098
Epoch: [2/10], Loss: 0.0064
Epoch: [3/10], Loss: 0.0051
Epoch: [4/10], Loss: 0.0044
Epoch: [5/10], Loss: 0.0040
Epoch: [6/10], Loss: 0.0037
Epoch: [7/10], Loss: 0.0034
Epoch: [8/10], Loss: 0.0032
Epoch: [9/10], Loss: 0.0030
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0146
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0055
Epoch: [10/10], Loss: 0.0052
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0253
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0042
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0105
Epoch: [2/10], Loss: 0.0070
Epoch: [3/10], Loss: 0.0056
Epoch: [4/10], Loss: 0.0048
Epoch: [5/10], Loss: 0.0043
Epoch: [6/10], Loss: 0.0039
Epoch: [7/10], Loss: 0.0037
Epoch: [8/10], Loss: 0.0034
Epoch: [9/10], Loss: 0.0032
Epoch: [10/10], Loss: 0.0030
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0150
Epoch: [2/10], Loss: 0.0107
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0086
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0056
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0258
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0060
Epoch: [3/10], Loss: 0.0044
Epoch: [4/10], Loss: 0.0035
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0097
Epoch: [2/10], Loss: 0.0061
Epoch: [3/10], Loss: 0.0044
Epoch: [4/10], Loss: 0.0035
Epoch: [5/10], Loss: 0.0029
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0097
Epoch: [2/10], Loss: 0.0061
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0036
Epoch: [5/10], Loss: 0.0030
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0100
Epoch: [2/10], Loss: 0.0069
Epoch: [3/10], Loss: 0.0055
Epoch: [4/10], Loss: 0.0048
Epoch: [5/10], Loss: 0.0043
Epoch: [6/10], Loss: 0.0039
Epoch: [7/10], Loss: 0.0036
Epoch: [8/10], Loss: 0.0034
Epoch: [9/10], Loss: 0.0032
Epoch: [10/10], Loss: 0.0030
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0152
Epoch: [2/10], Loss: 0.0109
Epoch: [3/10], Loss: 0.0097
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0254
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0092
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0042
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0042
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0066
Epoch: [3/10], Loss: 0.0053
Epoch: [4/10], Loss: 0.0046
Epoch: [5/10], Loss: 0.0041
Epoch: [6/10], Loss: 0.0038
Epoch: [7/10], Loss: 0.0035
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0145
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0059
Epoch: [9/10], Loss: 0.0055
Epoch: [10/10], Loss: 0.0051
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0252
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0054
Epoch: [3/10], Loss: 0.0040
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0100
Epoch: [2/10], Loss: 0.0068
Epoch: [3/10], Loss: 0.0054
Epoch: [4/10], Loss: 0.0047
Epoch: [5/10], Loss: 0.0042
Epoch: [6/10], Loss: 0.0039
Epoch: [7/10], Loss: 0.0036
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0030
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0144
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0063
Epoch: [8/10], Loss: 0.0058
Epoch: [9/10], Loss: 0.0054
Epoch: [10/10], Loss: 0.0051
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0255
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0055
Epoch: [3/10], Loss: 0.0040
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0043
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0066
Epoch: [3/10], Loss: 0.0053
Epoch: [4/10], Loss: 0.0046
Epoch: [5/10], Loss: 0.0042
Epoch: [6/10], Loss: 0.0038
Epoch: [7/10], Loss: 0.0035
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0144
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0068
Epoch: [7/10], Loss: 0.0062
Epoch: [8/10], Loss: 0.0057
Epoch: [9/10], Loss: 0.0053
Epoch: [10/10], Loss: 0.0050
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0255
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0050
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0051
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0053
Epoch: [3/10], Loss: 0.0039
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0061
Epoch: [3/10], Loss: 0.0049
Epoch: [4/10], Loss: 0.0043
Epoch: [5/10], Loss: 0.0039
Epoch: [6/10], Loss: 0.0036
Epoch: [7/10], Loss: 0.0033
Epoch: [8/10], Loss: 0.0031
Epoch: [9/10], Loss: 0.0030
Epoch: [10/10], Loss: 0.0028
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0144
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0063
Epoch: [8/10], Loss: 0.0059
Epoch: [9/10], Loss: 0.0054
Epoch: [10/10], Loss: 0.0051
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0255
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0073
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0060
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0047
Epoch: [4/10], Loss: 0.0041
Epoch: [5/10], Loss: 0.0037
Epoch: [6/10], Loss: 0.0034
Epoch: [7/10], Loss: 0.0032
Epoch: [8/10], Loss: 0.0030
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0139
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0067
Epoch: [7/10], Loss: 0.0061
Epoch: [8/10], Loss: 0.0057
Epoch: [9/10], Loss: 0.0053
Epoch: [10/10], Loss: 0.0049
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0250
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0032
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0014
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0032
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0014
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0047
Epoch: [4/10], Loss: 0.0041
Epoch: [5/10], Loss: 0.0037
Epoch: [6/10], Loss: 0.0034
Epoch: [7/10], Loss: 0.0032
Epoch: [8/10], Loss: 0.0030
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0133
Epoch: [2/10], Loss: 0.0098
Epoch: [3/10], Loss: 0.0088
Epoch: [4/10], Loss: 0.0079
Epoch: [5/10], Loss: 0.0072
Epoch: [6/10], Loss: 0.0065
Epoch: [7/10], Loss: 0.0060
Epoch: [8/10], Loss: 0.0055
Epoch: [9/10], Loss: 0.0051
Epoch: [10/10], Loss: 0.0048
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0255
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=10 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0076
Epoch: [2/10], Loss: 0.0044
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0023
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0016
Epoch: [7/10], Loss: 0.0013
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0032
Epoch: [4/10], Loss: 0.0024
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0016
Epoch: [7/10], Loss: 0.0014
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0047
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0085
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0044
Epoch: [4/10], Loss: 0.0039
Epoch: [5/10], Loss: 0.0035
Epoch: [6/10], Loss: 0.0032
Epoch: [7/10], Loss: 0.0030
Epoch: [8/10], Loss: 0.0029
Epoch: [9/10], Loss: 0.0027
Epoch: [10/10], Loss: 0.0026
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0139
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0088
Epoch: [4/10], Loss: 0.0080
Epoch: [5/10], Loss: 0.0073
Epoch: [6/10], Loss: 0.0066
Epoch: [7/10], Loss: 0.0060
Epoch: [8/10], Loss: 0.0056
Epoch: [9/10], Loss: 0.0052
Epoch: [10/10], Loss: 0.0048
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0248
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=10 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0050
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0060
Epoch: [3/10], Loss: 0.0048
Epoch: [4/10], Loss: 0.0042
Epoch: [5/10], Loss: 0.0037
Epoch: [6/10], Loss: 0.0034
Epoch: [7/10], Loss: 0.0032
Epoch: [8/10], Loss: 0.0030
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0141
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0067
Epoch: [7/10], Loss: 0.0062
Epoch: [8/10], Loss: 0.0057
Epoch: [9/10], Loss: 0.0052
Epoch: [10/10], Loss: 0.0049
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0251
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=10 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0051
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0051
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0053
Epoch: [3/10], Loss: 0.0038
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0021
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0062
Epoch: [3/10], Loss: 0.0050
Epoch: [4/10], Loss: 0.0043
Epoch: [5/10], Loss: 0.0039
Epoch: [6/10], Loss: 0.0035
Epoch: [7/10], Loss: 0.0033
Epoch: [8/10], Loss: 0.0031
Epoch: [9/10], Loss: 0.0029
Epoch: [10/10], Loss: 0.0028
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0141
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0068
Epoch: [7/10], Loss: 0.0062
Epoch: [8/10], Loss: 0.0057
Epoch: [9/10], Loss: 0.0053
Epoch: [10/10], Loss: 0.0049
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0256
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0067
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=10 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0055
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0043
Epoch: [4/10], Loss: 0.0035
Epoch: [5/10], Loss: 0.0029
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0067
Epoch: [3/10], Loss: 0.0055
Epoch: [4/10], Loss: 0.0047
Epoch: [5/10], Loss: 0.0042
Epoch: [6/10], Loss: 0.0038
Epoch: [7/10], Loss: 0.0036
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0031
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0146
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0063
Epoch: [8/10], Loss: 0.0058
Epoch: [9/10], Loss: 0.0054
Epoch: [10/10], Loss: 0.0050
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0255
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=10 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.47

pretrained_BERT top neurons
array([4096,    5, 6155, 6157,   15, 6159,   17, 2065, 6160,   32, 4130,
       4134, 6186, 8235,   42, 6192, 6198, 8248, 6208,   64, 8266,   78,
       8273, 4179, 6227, 4182, 8280, 4196, 2148, 8297, 8299, 4209,  115,
        116, 4217, 4222, 6271, 6284, 4243, 8347, 8354, 2211,  163, 4258,
       4262, 6314, 4267, 8364, 2228, 4286, 4290, 8388, 8390,  207, 6356,
        212, 2265, 6363, 4318, 2273, 2283, 6384, 8436, 6393, 4347, 4350,
       2309, 8461, 8463,  272,  277, 8469,  279, 6434, 2341, 2346, 4395,
       8496, 6450,  308, 2358,  318, 8510, 2368, 8512, 4425, 6475, 8544,
       4457, 2411, 2414, 8571,  382, 6526, 6528, 8575, 4482, 8579, 2437,
       6534, 8587, 2444, 8588, 4499, 4500, 6547, 2457,  419,  422, 6566,
       4524, 2477, 8624, 6579, 4537, 8637, 6590, 6594, 4547,  455,  457,
       8652, 8660, 2516, 8666, 4577, 2529, 8683, 8687, 4594, 8692,  502,
       8700, 8703, 8709, 4620, 4623, 2576, 8721,  531, 4631, 6679, 8738,
       4645, 4650, 6699, 8752, 8754, 2612, 4662, 2616, 2622, 4672, 6729,
       8787, 2643, 2649, 8793, 4699, 8797, 8798, 6761, 4715,  619, 4718,
       2673, 2681,  634, 8828, 2686, 4748, 2707, 4755, 8851, 2726, 4778,
       6828, 2735, 8883,  695, 2749, 8897, 8898, 2754, 6852, 2757, 8907,
       4820, 4826, 4827, 8935, 4843, 8944,  754, 2811, 4864, 2821,  773,
       6923, 6925,  783, 6927, 2833, 8983, 2842, 6942,  799, 8992, 4898,
       6954, 2859, 9003,  810, 6966, 9020, 6976,  832, 2883, 9034, 9041,
       4947, 9048, 4964, 9065,  875, 7022, 9072, 4977,  883, 4985, 7037,
       4990, 4993, 9090, 9096, 7052, 9107, 5011, 2963,  921,  927, 9122,
       5026, 5030, 7082, 5035, 9132, 9140, 5054, 5058, 7108, 9156, 9159,
       9161, 7116,  975, 7124, 7130, 3041,  998, 7147, 9202, 5115, 7173,
       3077, 5133, 9231, 1040, 3089, 5141, 9237, 5143, 7192, 1047, 1053,
       7202, 5156, 9253, 3109, 3114, 5163, 9264, 7218, 1076, 3126, 1086,
       3136, 7233, 3141, 9291, 9293, 7252, 5208, 7257, 3163, 9312, 5225,
       3179, 9341, 1150, 7294, 9345, 5250, 7302, 9350, 3212, 5266, 5267,
       5268, 7315, 9368, 7330, 1190, 7334, 3242, 5292, 1199, 7344, 7347,
       9396, 5299, 9400, 7358, 5316, 1221, 1223, 7371, 9420, 1229, 3284,
       7385, 5345, 7402, 9451, 9455, 7409, 3328, 9476, 9477, 1285, 3334,
       9478, 9482, 3344, 5392, 3362, 9513, 5418, 7467, 5424, 7473, 9520,
       1331, 5430, 3384, 9529, 5440, 1353, 7498, 3411, 5462, 7512, 9561,
       3417, 3428, 9572, 7529, 7531, 5486, 7536, 3441, 9586, 9592, 3449,
       9596, 3454, 9606, 5516, 1421, 3475, 5523, 7579, 1437, 1439, 7586,
       1443, 9635, 3494, 5543, 5546, 3499, 7596, 9651, 1463, 9659, 7617,
       3522, 7620, 9675, 9680, 1490, 5588, 9685, 9690, 5594, 5595, 7649,
       9707, 5611, 3579, 7693, 9741, 1551, 7695, 9751, 9760, 5666, 9768,
       7722, 3627, 1578, 7723, 7728, 5687, 1600, 7744, 3651, 1609, 3657,
       9809, 5715, 7763, 9816, 1638, 9833, 3689, 1643, 1651, 5747, 5753,
       7803, 7805, 5758, 1669, 5766, 9863, 9864, 7820, 3727, 9875, 3732,
       5779, 9878, 3731, 1689, 9881, 3741, 9890, 5794, 5798, 7850, 3756,
       1709, 9902, 5811, 3767, 7864, 9915, 5822, 9920, 5826, 7876, 7884,
       1743, 9936, 7892, 9941, 1748, 1752, 7898, 3809, 1775, 5883, 7935,
       7941, 1800, 3855, 1808, 5911, 1821, 7970, 3877, 3882, 5931, 7986,
       1844, 3894, 1854, 3904, 1866, 8019, 5993, 3947, 3950, 1918, 6018,
       3979, 3980, 1939, 3987, 8089, 1954, 1958, 6060, 1967, 8115, 6067,
       8126, 8130, 6084, 1989, 8135, 6088, 8137, 8139, 4052, 8153, 6113,
       8163, 8176, 2033])
pretrained_BERT top neurons per class
{'NAME': array([8709, 7052, 6284, 1689, 5822,  783, 5516, 6590, 8721,   15, 4577,
       9864, 5054, 2273, 6828, 8019, 8544, 3809, 8364, 3041,  422, 7820,
       8660, 5715, 7596, 5058, 9477, 8176, 4718, 8130, 8235, 9041, 2821,
       8687, 4748, 3212, 9293, 6594, 3411, 6356, 5931, 9941, 7358, 9878,
       9863, 2211, 9451, 5826, 9096, 6699, 6060, 8248, 8787, 1669, 1989,
       2437, 8898, 9312, 9132, 7467, 2735, 8683, 9072, 3428, 3627, 4947,
       2444, 9768, 6923, 3950,  163, 7941, 2859, 8273, 2283, 1551, 7892,
       4500, 4524, 5163, 1190, 4179, 4395, 8828, 1199, 1221, 4631, 5268,
       1958, 9875, 4623, 1443, 2457, 9455, 9482, 1967, 5345, 4290, 7536,
       4699, 1752, 8944, 3855,   17, 4964, 4286, 3732, 8126, 6528, 7124,
       9003, 3522, 4196, 8588, 2754, 7022, 9592, 2726, 9685, 9596, 9809,
       9690, 1490, 8798, 6159, 9920, 6155, 9659, 5486, 2414, 3756, 9107,
       8935, 5266, 6384,  921, 9476, 3980, 4547, 2757, 8700, 8436, 9368,
        455, 1800, 2148, 2265, 5292]), 'STRING': array([8571, 8709, 7529, 6761, 1076, 5225, 4243, 9833, 5993,  308, 8297,
       5779, 9707, 7884, 8983, 3689,  318,  277, 9476,  998, 6534, 4457,
       8992, 5011, 3475, 9065, 1229, 9760, 5156, 7037, 9572, 3384, 8347,
       7941, 7202, 5766, 4267, 9881, 6186, 7970, 7803, 2616, 6954,  115,
       8703, 8354, 7722, 3242, 5546, 2612, 1844, 5666,  455, 7805, 5588,
       8752, 4778, 1223, 9253, 8163, 5687, 8897,  883, 2033, 2228, 9816,
       9122, 4096, 6927, 1651, 3109, 8587, 6579, 1086, 7850, 2707,   78,
       2622,  116, 4898, 9341, 3141, 8135, 8660, 3727, 7876,  799, 5811,
       8390, 1866, 3882, 7252, 5883, 3877, 7344, 9890, 5418, 7302, 3328,
       5035, 6393, 8280, 7473, 7173, 6475, 3114, 8469, 4864, 4130, 3499,
       9048, 4347, 4650, 7116, 1285, 8579, 1578, 6314, 7082, 3651, 8463,
       6594, 8652, 1939, 3362, 5141,  634, 8299, 9090, 9420, 5543,  419,
       9680,  927, 8137, 1854, 5115, 6434, 9020, 9875,  754, 8738, 8797,
       9751, 9231,  531, 7579, 7617, 7935, 2341, 9345, 7108, 7586, 9586,
       8692, 7531, 4820, 7695]), 'NUMBER': array([4820, 4052, 6356, 5588, 1600, 2368, 4977, 2516, 3904, 4499, 1150,
       3441, 4209, 4672, 8883, 1643, 2673, 5345, 5030, 4222, 8115, 4990,
       1463, 7294, 5798, 3284, 2529,  382, 4262, 6976, 3136, 7347, 5758,
       7620, 7744, 8660, 7649, 6084, 3494, 5440, 5026, 7218, 5250, 1743,
       7124, 7986, 6852, 5794, 1748, 7728, 6526, 9264,  207, 8388, 9350,
       6579, 7402, 4347, 2686, 6547, 1821, 3089, 6925, 3179, 1609,  832,
       1709, 5133, 1053, 6192, 4993, 9156, 3987, 6227, 6113, 2643, 6018,
       3454, 9635, 3947,  695, 1918,  975, 5208, 1954, 4482, 8754, 9140,
       2842, 2411, 7233, 6208, 4699,  212, 5523, 9606, 9651, 3731, 5424,
       8496, 2477, 8512, 8153, 4715, 7334, 2811,  502, 5267, 8089, 5462,
       2963, 5316, 4258, 9159, 4755, 6271, 7892,   64, 7512, 5747, 3767,
       7385, 7763, 4620, 3979, 3741, 5115,  875, 7192, 6157, 4243, 3163,
       4134, 6450, 7330, 8588, 3579, 1638, 6566]), 'KEYWORD': array([7124, 5418, 6356, 4820,  883, 8666, 7693, 4662, 6186, 4650, 8139,
         42, 3114, 8907, 2346, 5430,  773,    5, 6925, 4826, 7892, 7130,
       3077,  810, 6954, 6966, 3882, 1040, 2358, 2833, 9561, 9237, 9396,
       9651, 5666, 7371, 5594, 6198, 4217, 6363, 8266, 8660, 6547, 5143,
       3894, 5911,  279, 7898, 3344, 6088, 4537, 5753, 9400, 9513, 1808,
       4827, 2065, 5588, 2681, 7722, 9936, 1353,   17, 9680, 3454, 7257,
       4318, 3877, 9034, 8883, 9520, 6679, 6942, 3126, 7409,  272,  619,
       6160, 1437, 8752, 4052, 8115, 9161, 3109, 9253, 3441, 4990, 1047,
       2309, 9291, 4843, 7723, 6729, 2649, 8637, 8461, 8575, 4985, 9041,
       9529,  457, 4645, 9751, 5595, 8721, 5299, 1439, 9231, 4182, 8624,
         32, 2883, 8851, 1578, 5392, 7864, 3449, 9675, 2576, 9881, 1775,
       4425, 5747, 3499, 5611, 4594, 4222, 7315, 1331, 8793, 4267, 3334,
       7147, 9202, 2749, 9816, 9809, 9741, 8510, 4350, 3417, 1421, 9902,
       9915, 8469, 3657, 7498, 6067, 9478])}
The shape of selected features (13636, 531)
The shape of the training set: (13636, 531)
The shape of the validation set: (1516, 531)
The shape of the testing set: (4026, 531)
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0061
Epoch: [3/10], Loss: 0.0049
Epoch: [4/10], Loss: 0.0041
Epoch: [5/10], Loss: 0.0035
Epoch: [6/10], Loss: 0.0030
Epoch: [7/10], Loss: 0.0027
Epoch: [8/10], Loss: 0.0024
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0062
Epoch: [3/10], Loss: 0.0049
Epoch: [4/10], Loss: 0.0041
Epoch: [5/10], Loss: 0.0035
Epoch: [6/10], Loss: 0.0030
Epoch: [7/10], Loss: 0.0027
Epoch: [8/10], Loss: 0.0024
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0093
Epoch: [2/10], Loss: 0.0065
Epoch: [3/10], Loss: 0.0052
Epoch: [4/10], Loss: 0.0044
Epoch: [5/10], Loss: 0.0037
Epoch: [6/10], Loss: 0.0033
Epoch: [7/10], Loss: 0.0029
Epoch: [8/10], Loss: 0.0026
Epoch: [9/10], Loss: 0.0024
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0103
Epoch: [2/10], Loss: 0.0074
Epoch: [3/10], Loss: 0.0062
Epoch: [4/10], Loss: 0.0054
Epoch: [5/10], Loss: 0.0049
Epoch: [6/10], Loss: 0.0045
Epoch: [7/10], Loss: 0.0041
Epoch: [8/10], Loss: 0.0038
Epoch: [9/10], Loss: 0.0035
Epoch: [10/10], Loss: 0.0033
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0145
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0080
Epoch: [5/10], Loss: 0.0073
Epoch: [6/10], Loss: 0.0067
Epoch: [7/10], Loss: 0.0062
Epoch: [8/10], Loss: 0.0057
Epoch: [9/10], Loss: 0.0053
Epoch: [10/10], Loss: 0.0050
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0274
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.47
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0099
Epoch: [2/10], Loss: 0.0074
Epoch: [3/10], Loss: 0.0063
Epoch: [4/10], Loss: 0.0054
Epoch: [5/10], Loss: 0.0048
Epoch: [6/10], Loss: 0.0042
Epoch: [7/10], Loss: 0.0037
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0030
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0094
Epoch: [2/10], Loss: 0.0073
Epoch: [3/10], Loss: 0.0062
Epoch: [4/10], Loss: 0.0053
Epoch: [5/10], Loss: 0.0047
Epoch: [6/10], Loss: 0.0041
Epoch: [7/10], Loss: 0.0037
Epoch: [8/10], Loss: 0.0033
Epoch: [9/10], Loss: 0.0030
Epoch: [10/10], Loss: 0.0027
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0098
Epoch: [2/10], Loss: 0.0076
Epoch: [3/10], Loss: 0.0065
Epoch: [4/10], Loss: 0.0057
Epoch: [5/10], Loss: 0.0050
Epoch: [6/10], Loss: 0.0044
Epoch: [7/10], Loss: 0.0040
Epoch: [8/10], Loss: 0.0036
Epoch: [9/10], Loss: 0.0032
Epoch: [10/10], Loss: 0.0029
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0108
Epoch: [2/10], Loss: 0.0085
Epoch: [3/10], Loss: 0.0073
Epoch: [4/10], Loss: 0.0065
Epoch: [5/10], Loss: 0.0058
Epoch: [6/10], Loss: 0.0053
Epoch: [7/10], Loss: 0.0048
Epoch: [8/10], Loss: 0.0044
Epoch: [9/10], Loss: 0.0040
Epoch: [10/10], Loss: 0.0037
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0156
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0353
Epoch: [2/10], Loss: 0.0097
Epoch: [3/10], Loss: 0.0088
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0054
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=1 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.47
{'__OVERALL__': 0.4674615002483855, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:1882,KW_NAME:68
NAME_KW:0,KW_KW:0
NAME_STRING:0,KW_other:0
NAME_NUMBER:0
NAME_STRING_list:[]
NAME_NUMBER_list:[]
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.47
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 4096 [('Geo', 1.0), ('topology', 0.9110617869008969), ('RELATIONS', 0.8784604504343067), ('PRIORITY', 0.8646602139843954), ('from', 0.8628395923195993)]
Top words for pretrained_BERT neuron indx 5 [('sublime', 1.0), ('month', 0.7761481001310883), ('RELEASE', 0.7504232549207436), ('relay', 0.7457227957702592), ('license', 0.6698229663292175)]
Top words for pretrained_BERT neuron indx 6155 [('187', 1.0), ('28', 0.9696606498128627), ('69', 0.9615670372825715), ('18', 0.9549593060383855), ('17', 0.9433608438276366)]
Top words for pretrained_BERT neuron indx 6157 [('On', 1.0), ('ON', 1.0), ('builtins', 0.8451404352799264), ('CREATING', 0.8418748085162604), ('to', 0.795483017013156)]
Top words for pretrained_BERT neuron indx 15 [('sock', 1.0), ('ajax', 0.7898320547107883), ('break', 0.7797566389239774), ('slug', 0.6986523454015331), ('MEMBER', 0.68856386778053)]
Top words for pretrained_BERT neuron indx 6159 [('as', 1.0), ('venue', 0.9588600784496847), ('0.04', 0.8615864855507244), ('"KILLED"', 0.8185844836388597), ('__b', 0.7871707149171955)]
Top words for pretrained_BERT neuron indx 17 [('abstract', 1.0), ('Instance', 0.8618731176581883), ('hyper', 0.8243582609527874), ('rest', 0.7602775634705263), ('fail', 0.7061051558304924)]
Top words for pretrained_BERT neuron indx 2065 [('ping', 1.0), ('fixed', 0.9590777587541904), ('Post', 0.9039391098517161), ('mkSub', 0.8984077868880752), ('hour', 0.8775671843798502)]
Top words for pretrained_BERT neuron indx 6160 [('62', 1.0), ('Else', 0.7979690506266378), ('42', 0.7650457344323321), ('with', 0.7196718952138651), ('within', 0.7133544203526591)]
Top words for pretrained_BERT neuron indx 32 [('authorized', 1.0), ('Plan', 0.9152902663660005), ('Label', 0.8945579676019246), ('plan', 0.8748416180219323), ('Unauthorized', 0.8688055475640457)]
Top words for pretrained_BERT neuron indx 4130 [('functional', 1.0), ('fabric', 0.8951102742509699), ('joinall', 0.8619270115287927), ('warn', 0.8555362248708851), ('Delay', 0.8352224235192198)]
Top words for pretrained_BERT neuron indx 4134 [('detect', 1.0), ('localize', 0.7591610540226643), ('frame', 0.7528204355117363), ('has', 0.7462089532220264), ('identical', 0.7341568502520556)]
Top words for pretrained_BERT neuron indx 6186 [('decorators', 1.0), ('baseline', 0.9811072301860105), ('buffer', 0.9197702695477953), ('unicode', 0.9105747279415178), ('services', 0.9053364460904619)]
Top words for pretrained_BERT neuron indx 8235 [('bson', 1.0), ('advertiser', 0.9987240351293267), ('runner', 0.8750724140385668), ('agency', 0.861752992964548), ('VERSION', 0.8611053713465228)]
Top words for pretrained_BERT neuron indx 42 [('unicode', 1.0), ('sr', 0.9236520868781501), ('encoding', 0.8898429629039388), ('yield', 0.8593190980532698), ('quota', 0.8547911882452333)]
Top words for pretrained_BERT neuron indx 6192 [('scheme', 1.0), ('break', 0.924533152894867), ('PIECE', 0.8942339487049306), ('nexthop', 0.8914260475774302), ('flat', 0.8715964185974694)]
Top words for pretrained_BERT neuron indx 6198 [('sha', 1.0), ('installed', 0.9741912600456861), ('LAT', 0.8853117601172289), ('mesh', 0.8812665116819273), ('startTime', 0.8351747209005516)]
Top words for pretrained_BERT neuron indx 8248 [('user_functions', 1.0), ('bare', 0.8378965996438813), ('BOUNDS', 0.7889717492100716), ('lon', 0.7630544835923943), ('Signature', 0.7153815212931507)]
Top words for pretrained_BERT neuron indx 6208 [('512', 1.0), ('behind', 0.9171536414139867), ('Distance', 0.868617626359952), ('999999', 0.8560719445552357), ('synchronized', 0.8267125234208579)]
Top words for pretrained_BERT neuron indx 64 [('Tab', 1.0), ('synchronized', 0.849083835672398), ('Message', 0.8130367044993536), ('authorized', 0.8033608185107095), ('resolve', 0.7975240958601068)]
Top words for pretrained_BERT neuron indx 8266 [('comments', 1.0), ('forwards', 0.9510642508301833), ('destroy', 0.880130432628108), ('TRANSITIVE', 0.8787953378238104), ('except', 0.8335645236984024)]
Top words for pretrained_BERT neuron indx 78 [('Unauthorized', 1.0), ('roster', 0.9139975278540913), ('owner', 0.8918130579321284), ('commit', 0.8775234338037937), ('Commit', 0.8746382078503891)]
Top words for pretrained_BERT neuron indx 8273 [('providers', 1.0), ('CREATING', 0.9550348167086121), ('File', 0.7857674170301697), ('services', 0.7573999402768089), ('OK', 0.7440421752956703)]
Top words for pretrained_BERT neuron indx 4179 [('CANCEL', 1.0), ('scheme', 0.981960863512019), ('zope', 0.8444267976786034), ('initial', 0.7783388745645009), ('secret', 0.7773968618278864)]
Top words for pretrained_BERT neuron indx 6227 [('Location', 1.0), ('False', 0.9868567965794579), ('Presence', 0.9850152709546481), ('"height"', 0.8951925321980317), ('Gallery', 0.8890801461603661)]
Top words for pretrained_BERT neuron indx 4182 [('CREATING', 1.0), ('LON', 0.9571469672582193), ('criterion', 0.9496277020261109), ('lon', 0.934483349136865), ('rollback', 0.9229614178242495)]
Top words for pretrained_BERT neuron indx 8280 [('CREATING', 1.0), ('pytz', 0.9753094020699277), ('750', 0.9486994805812511), ('LGMap', 0.9132947348563986), ('23.61432859499169', 0.9071380627036446)]
Top words for pretrained_BERT neuron indx 4196 [('Column', 1.0), ('inst', 0.7345915711695458), ('organization', 0.7317944005787885), ('MEMBER', 0.726756518069276), ('TAG', 0.7238159064113329)]
Top words for pretrained_BERT neuron indx 2148 [('loop', 1.0), ('Basic', 0.8195493199831101), ('Instance', 0.7715417633238364), ('visitor', 0.7070372563795109), ('18', 0.6841999272640609)]
Top words for pretrained_BERT neuron indx 8297 [('201', 1.0), ('187', 0.9447296684855683), ('cancel', 0.8745416431281727), ('other', 0.7917770559306309), ('Allow', 0.7799263311166873)]
Top words for pretrained_BERT neuron indx 8299 [('reflection', 1.0), ('aspect', 0.9935874869986979), ('ND', 0.9782812024864259), ('collect', 0.9546179321660319), ('checkreport', 0.9302341337941639)]
Top words for pretrained_BERT neuron indx 4209 [('bare', 1.0), ('number', 0.8082054656788116), ('TYPE', 0.776689862093211), ('ERROR', 0.7719696569787755), ('TRACEPOINTS', 0.7635833812412074)]
Top words for pretrained_BERT neuron indx 115 [('Auditor', 1.0), ('synchronized', 0.8643176227898289), ('terminate', 0.8544052685815974), ('auditor', 0.8540693524152583), ('TERMINATE', 0.8171064454054415)]
Top words for pretrained_BERT neuron indx 116 [('INCOMPLETE', 1.0), ('topology', 0.910904805092258), ('compute', 0.829119727145922), ('identical', 0.803905336311763), ('Protocol', 0.7934346582549928)]
Top words for pretrained_BERT neuron indx 4217 [('CREATING', 1.0), ('CANCEL', 0.7762328127537769), ('INFO', 0.7439737415888885), ('SON', 0.7430662720192608), ('relay', 0.7073418166879276)]
Top words for pretrained_BERT neuron indx 4222 [('SUCCESS', 1.0), ('calendar', 0.9416404141096484), ('success', 0.9238759200030122), ('wait', 0.8944353849105334), ('collect', 0.8830113692350283)]
Top words for pretrained_BERT neuron indx 6271 [('intersects', 1.0), ('patterns', 0.9967250857392986), ('number', 0.9441518089233017), ('750', 0.9032163272201338), ('sr', 0.9018561816432448)]
Top words for pretrained_BERT neuron indx 6284 [('minutes', 1.0), ('compute', 0.9343119340016041), ('completed', 0.8311988411642477), ('80', 0.7739922146640701), ('variables', 0.7200295753558574)]
Top words for pretrained_BERT neuron indx 4243 [('sid', 1.0), ('plural', 0.8247836622579346), ('decimal', 0.8022884474086464), ('operations', 0.7362681329626785), ('File', 0.7150453580251451)]
Top words for pretrained_BERT neuron indx 8347 [('"shared"', 1.0), ('"-I"', 0.8837366426937906), ('"warning"', 0.8825195864530871), ('"secret"', 0.8474610017455702), ('"x"', 0.8310520559292905)]
Top words for pretrained_BERT neuron indx 8354 [('materials', 1.0), ('sublime', 0.9874715489767889), ('scenario', 0.9626524546604289), ('Stretch', 0.9536231012564095), ('enclosure', 0.948327362336709)]
Top words for pretrained_BERT neuron indx 2211 [('props', 1.0), ('sim', 0.9302085696407889), ('stamp', 0.889544879578288), ('dom', 0.8834079128784025), ('branches', 0.8561826440942136)]
Top words for pretrained_BERT neuron indx 163 [('FILES', 1.0), ('files', 0.9983807061845311), ('buttons', 0.9816389678216421), ('bodies', 0.8537109253897635), ('responses', 0.7929352471678788)]
Top words for pretrained_BERT neuron indx 4258 [('outgoing', 1.0), ('Wire', 0.6937024497304513), ('ts', 0.6790728372314042), ('35', 0.65625151700801), ('warn', 0.6548791519898324)]
Top words for pretrained_BERT neuron indx 4262 [('18', 1.0), ('36', 0.9763026149393984), ('119', 0.9602949799415534), ('23', 0.9552914987235533), ('35', 0.9118584967769131)]
Top words for pretrained_BERT neuron indx 6314 [('blank', 1.0), ('mins', 0.9716327153410745), ('severity', 0.936705637911264), ('decimal', 0.9282674661919282), ('BRIGHTNESS', 0.9077394106709195)]
Top words for pretrained_BERT neuron indx 4267 [('OK', 1.0), ('1970', 0.9126167540833009), ('next', 0.912209598400902), ('discovery', 0.8689059690220139), ('nsa', 0.8660342444603604)]
Top words for pretrained_BERT neuron indx 8364 [('Int', 1.0), ('next', 0.9734569175959158), ('runner', 0.9687685899118367), ('Reg', 0.94055995865488), ('long', 0.9205453614152534)]
Top words for pretrained_BERT neuron indx 2228 [('62', 1.0), ('detect', 0.8914714510579109), ('42', 0.8714731045563168), ('33', 0.8583261770904869), ('single', 0.8174823942293511)]
Top words for pretrained_BERT neuron indx 4286 [('available', 1.0), ('choice', 0.7759866684987478), ('ahead', 0.7626014714070729), ('simple', 0.7495600507444252), ('200', 0.7459166288576479)]
Top words for pretrained_BERT neuron indx 4290 [('notes', 1.0), ('Default', 0.9832314028324319), ('ignore', 0.9367118925980499), ('Job', 0.8565888106866594), ('Else', 0.8538197562529585)]
Top words for pretrained_BERT neuron indx 8388 [('Label', 1.0), ('prop', 0.8780970657548004), ('117', 0.8229822264694069), ('None', 0.8036091223764473), ('scenario', 0.7902176598249798)]
Top words for pretrained_BERT neuron indx 8390 [('75', 1.0), ('17', 0.7175607754506917), ('400', 0.7088648758862007), ('18', 0.6706169700056095), ('intersects', 0.6533157470134585)]
Top words for pretrained_BERT neuron indx 207 [('active', 1.0), ('settings', 0.932725049790522), ('mail', 0.9234723790317434), ('AddField', 0.9176761578502495), ('SETTINGS', 0.9171900888026706)]
Top words for pretrained_BERT neuron indx 6356 [('750', 1.0), ('future', 0.9112081047664251), ('75', 0.8619809066138949), ('repeat', 0.831848446889376), ('principal', 0.8004843897828683)]
Top words for pretrained_BERT neuron indx 212 [('stat', 1.0), ('listen', 0.9907504992234303), ('package', 0.9018082198429537), ('Subject', 0.8961876820797785), ('select', 0.8895880420474797)]
Top words for pretrained_BERT neuron indx 2265 [('socket', 1.0), ('purpose', 0.9590920976134711), ('quota', 0.9029085531376946), ('Task', 0.9013675628313788), ('assets', 0.8811292214844234)]
Top words for pretrained_BERT neuron indx 6363 [('utl', 1.0), ('MANIFEST', 0.984444336301545), ('raise', 0.9538407301279964), ('0o555', 0.9417310585568649), ('created', 0.9330740334137255)]
Top words for pretrained_BERT neuron indx 4318 [('dir', 1.0), ('sa', 0.8879421580492597), ('nsa', 0.8388511683408936), ('capacity', 0.7660981118494857), ('Geo', 0.7657665626228639)]
Top words for pretrained_BERT neuron indx 2273 [('current', 1.0), ('acquire', 0.9709443764861113), ('slug', 0.9188251620990501), ('detect', 0.9178084762201276), ('201', 0.9007722549929456)]
Top words for pretrained_BERT neuron indx 2283 [('code', 1.0), ('clone', 0.8452056144076713), ('register', 0.6981866119550949), ('activity', 0.6685977229185694), ('setter', 0.6416838911642758)]
Top words for pretrained_BERT neuron indx 6384 [('scheme', 1.0), ('WITHDRAW', 0.7622578818929426), ('sr', 0.7368311623816316), ('partial', 0.7272833099943005), ('33', 0.7157909019652196)]
Top words for pretrained_BERT neuron indx 8436 [('"FAILED"', 1.0), ('17', 0.9524328240805952), ('"SUCCEEDED"', 0.885672784414824), ('Watcher', 0.8749639845526049), ('descriptor', 0.8708612054459011)]
Top words for pretrained_BERT neuron indx 6393 [('RESERVE', 1.0), ('PROVISION', 0.9644878023997433), ('detect', 0.9246766740644087), ('0xFF', 0.8458072026993704), ('Http404', 0.840655177242216)]
Top words for pretrained_BERT neuron indx 4347 [('period', 1.0), ('If', 0.9941217548139936), ('auditor', 0.9820265011518311), ('TYPE', 0.9615623406994005), ('functions', 0.9504890962375842)]
Top words for pretrained_BERT neuron indx 4350 [('TRANSITIVE', 1.0), ('unquote', 0.947613434211109), ('RELATIONS', 0.8876174231793452), ('"key"', 0.8514252453286104), ('single', 0.8228122914030364)]
Top words for pretrained_BERT neuron indx 2309 [('sublime', 1.0), ('relay', 0.9252630310838417), ('lb', 0.8642668331893674), ('scheme', 0.8259117808985363), ('sha', 0.7571383250048299)]
Top words for pretrained_BERT neuron indx 8461 [('Region', 1.0), ('millis', 0.840676307624027), ('closing', 0.797679595680598), ('milliseconds', 0.7538041763773241), ('reactor', 0.7168751238804553)]
Top words for pretrained_BERT neuron indx 8463 [('District', 1.0), ('Plugin', 0.9473288324721483), ('Region', 0.9229932334876068), ('venue', 0.9033832644462979), ('region', 0.8970313519315921)]
Top words for pretrained_BERT neuron indx 272 [('license', 1.0), ('prop', 0.9911190764929279), ('materials', 0.9249637299336646), ('broker', 0.8741504537706639), ('processes', 0.8577288991194377)]
Top words for pretrained_BERT neuron indx 277 [('READY', 1.0), ('aspect', 0.814516608748367), ('ready', 0.8093431809184434), ('utc', 0.7339472935534905), ('quality', 0.6950734437994535)]
Top words for pretrained_BERT neuron indx 8469 [('blank', 1.0), ('polygon', 0.8574536770563894), ('tv', 0.851666972298362), ('crop_height', 0.8487054450406943), ('forget', 0.8164138149328429)]
Top words for pretrained_BERT neuron indx 279 [('LOGGING', 1.0), ('Cached', 0.9200890040771778), ('targets', 0.9033901593343351), ('twisted', 0.8832049056711446), ('zone', 0.8451523583994998)]
Top words for pretrained_BERT neuron indx 6434 [('"include"', 1.0), ('"define"', 0.9612294139964225), ('"KILLED"', 0.950072158235293), ('south', 0.8893060490962952), ('stores', 0.8884997338518149)]
Top words for pretrained_BERT neuron indx 2341 [('plural', 1.0), ('75', 0.8542435593230377), ('branches', 0.7739982889112511), ('63', 0.7564260320239574), ('80', 0.7402641580748798)]
Top words for pretrained_BERT neuron indx 2346 [('unicode', 1.0), ('revision', 0.9076068768853932), ('Byte', 0.8517071273698671), ('Bytes', 0.8514170490587897), ('advance', 0.8211157575271207)]
Top words for pretrained_BERT neuron indx 4395 [('Parameter', 1.0), ('Module', 0.9352249231820635), ('MEMBER', 0.9172356809623929), ('patch', 0.9060472187389214), ('Invalid', 0.8994886835042397)]
Top words for pretrained_BERT neuron indx 8496 [('nexthop', 1.0), ('created', 0.9928015115990831), ('scheme', 0.9730026389430655), ('512', 0.9651295026402222), ('flat', 0.9603475880782087)]
Top words for pretrained_BERT neuron indx 6450 [('and', 1.0), ('internet', 0.8941768487805422), ('Item', 0.8413571846963048), ('Struct', 0.7255210957206912), ('http', 0.7039341376847883)]
Top words for pretrained_BERT neuron indx 308 [('and', 1.0), ('to', 0.867833621017307), ('in', 0.867726722143447), ('".."', 0.8665045777521424), ('with', 0.7247832718323066)]
Top words for pretrained_BERT neuron indx 2358 [('seek', 1.0), ('query', 0.8940789293287863), ('Task', 0.8754505254202245), ('assets', 0.8671797231820071), ('installed', 0.8303957681164568)]
Top words for pretrained_BERT neuron indx 318 [('repeat', 1.0), ('Manager', 0.7843199533678911), ('manager', 0.7487929389323892), ('WAYS', 0.7460532110247053), ('commit', 0.7386850931501349)]
Top words for pretrained_BERT neuron indx 8510 [('mins', 1.0), ('ip', 0.9425559499472012), ('kls', 0.8682478489637817), ('35', 0.856227933245661), ('or', 0.8560758570390048)]
Top words for pretrained_BERT neuron indx 2368 [('512', 1.0), ('authorized', 0.8357992074147292), ('synchronized', 0.7976386680239561), ('upgrade', 0.780160248469043), ('fifteen', 0.7444277205997546)]
Top words for pretrained_BERT neuron indx 8512 [('512', 1.0), ('31', 0.9306122032413816), ('behind', 0.9097385490233918), ('Tab', 0.9048659460091371), ('stat', 0.8239955402704738)]
Top words for pretrained_BERT neuron indx 4425 [('fragment', 1.0), ('bare', 0.9199026641548214), ('pattern', 0.9144452690772763), ('fin', 0.7156038251956854), ('interfaces', 0.7000094960434228)]
Top words for pretrained_BERT neuron indx 6475 [('INCOMPLETE', 1.0), ('ROLE', 0.9948198695978718), ('polygon', 0.9799250903102019), ('CACHES', 0.9635618645521642), ('"0.14.0"', 0.9533511907043788)]
Top words for pretrained_BERT neuron indx 8544 [('69', 1.0), ('31', 0.9606617551892787), ('127', 0.9377595692382907), ('presence', 0.9008760666674049), ('oslo', 0.8745469162449231)]
Top words for pretrained_BERT neuron indx 4457 [('NODES', 1.0), ('187', 0.9446395946941808), ('Allow', 0.9374351884733555), ('201', 0.9313445240250494), ('CANCEL', 0.9144495732392918)]
Top words for pretrained_BERT neuron indx 2411 [('200', 1.0), ('500', 0.9394162860148647), ('75', 0.797014820406423), ('512', 0.7875688202322547), ('organization', 0.7730871588807495)]
Top words for pretrained_BERT neuron indx 2414 [('69', 1.0), ('panels', 0.9892180904179277), ('plans', 0.9875504890210041), ('organization', 0.9429074603735694), ('2014', 0.9235426617386261)]
Top words for pretrained_BERT neuron indx 8571 [('75', 1.0), ('topology', 0.980384295648466), ('"y"', 0.9705588574916664), ('187', 0.9421257216338447), ('"file"', 0.9394470147524919)]
Top words for pretrained_BERT neuron indx 382 [('remember', 1.0), ('feed', 0.6998572353920669), ('raise', 0.6868134842182844), ('Geo', 0.684881933730302), ('realm', 0.627888184239794)]
Top words for pretrained_BERT neuron indx 6526 [('SUCCESS', 1.0), ('Criteria', 0.9975983395104999), ('restart', 0.8806623293958095), ('success', 0.8793931618025626), ('RELEASE', 0.8766269295050348)]
Top words for pretrained_BERT neuron indx 6528 [('62', 1.0), ('23', 0.9712139636534716), ('187', 0.9545601275714527), ('24', 0.930919713211397), ('512', 0.9306723879781292)]
Top words for pretrained_BERT neuron indx 8575 [('"Height"', 1.0), ('"include"', 0.9166671107997084), ('providers', 0.9063050737882635), ('calendar', 0.9048501559154865), ('"height"', 0.8996305598071827)]
Top words for pretrained_BERT neuron indx 4482 [('WAY', 1.0), ('On', 0.9335610367775466), ('ON', 0.9335610367775466), ('Wire', 0.8644997764365028), ('vol', 0.8427555029339251)]
Top words for pretrained_BERT neuron indx 8579 [('horizon', 1.0), ('oslo', 0.9625304340923982), ('Output', 0.8783663748239839), ('height', 0.8339248983348889), ('pyramid', 0.8334385191444207)]
Top words for pretrained_BERT neuron indx 2437 [('1970', 1.0), ('advance', 0.8625762269955761), ('requires', 0.8362490196269946), ('POST', 0.7297972423368195), ('Post', 0.7179767770583374)]
Top words for pretrained_BERT neuron indx 6534 [('"pv"', 1.0), ('"0"', 0.9881031410263699), ('42', 0.9645636553355929), ('"cards"', 0.9436003372077698), ('"r"', 0.9041450700838851)]
Top words for pretrained_BERT neuron indx 8587 [('86400', 1.0), ('"0301000000001122aabbccdd0102030405060708"', 0.9379651250307935), ('"0800305c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.7416002336709094), ('Simulator', 0.7395515714871412), ('submit', 0.7294060210479288)]
Top words for pretrained_BERT neuron indx 2444 [('minutes', 1.0), ('authorized', 0.9699147809224169), ('PIECE', 0.9298464963132653), ('compute', 0.8921920780020965), ('MANIFEST', 0.8060106468640664)]
Top words for pretrained_BERT neuron indx 8588 [('minutes', 1.0), ('25', 0.9700903700461206), ('80', 0.9398434327531888), ('75', 0.9317697328787297), ('compute', 0.882871950872366)]
Top words for pretrained_BERT neuron indx 4499 [('75', 1.0), ('3785', 0.9001706973546069), ('300', 0.8771968470650863), ('95', 0.8606309566575828), ('800', 0.8458780494911969)]
Top words for pretrained_BERT neuron indx 4500 [('month', 1.0), ('ALPHABET', 0.8763113800948069), ('Video', 0.8646273829182737), ('google', 0.8063560754533922), ('principal', 0.8060757393246358)]
Top words for pretrained_BERT neuron indx 6547 [('oslo', 1.0), ('Else', 0.9299374608272739), ('principal', 0.7657325528846197), ('sid', 0.7514093864380174), ('28', 0.7256547296519875)]
Top words for pretrained_BERT neuron indx 2457 [('cb', 1.0), ('translation', 0.9254804194383834), ('NewCard', 0.9075585899242913), ('communities', 0.906310264556502), ('video', 0.9059991003815078)]
Top words for pretrained_BERT neuron indx 419 [('jtype', 1.0), ('ping', 0.80343705454112), ('StringType', 0.7785142804286421), ('long', 0.756525890198997), ('INCOMPLETE', 0.7395052948488768)]
Top words for pretrained_BERT neuron indx 422 [('LOGGING', 1.0), ('def', 0.9917683589622631), ('Int', 0.9889759788278424), ('VALUE', 0.9564799364130293), ('listen', 0.9282747609484502)]
Top words for pretrained_BERT neuron indx 6566 [('36', 1.0), ('23', 0.8974223267307392), ('119', 0.8740661905878151), ('302', 0.8634234841381466), ('31', 0.862797863226397)]
Top words for pretrained_BERT neuron indx 4524 [('runner', 1.0), ('include', 0.9779534283098841), ('long', 0.945276541561338), ('Int', 0.9400556678575013), ('symmetric', 0.9217671292186769)]
Top words for pretrained_BERT neuron indx 2477 [('204', 1.0), ('bare', 0.9665792972242002), ('us', 0.9416524754981176), ('62', 0.9053791971230544), ('imports', 0.9016810959929622)]
Top words for pretrained_BERT neuron indx 8624 [('opener', 1.0), ('"|"', 0.8797810376846231), ('entries', 0.8787099624689853), ('READY', 0.8194878815865319), ('comments', 0.8088211436091383)]
Top words for pretrained_BERT neuron indx 6579 [('nh', 1.0), ('splits', 0.9548344816839657), ('ah', 0.9389476340892476), ('discovery', 0.9176479917786385), ('33', 0.9151128320438384)]
Top words for pretrained_BERT neuron indx 4537 [('transfer', 1.0), ('agency', 0.9338054464920041), ('advertiser', 0.8578379507967708), ('apache', 0.850234701000698), ('http', 0.8278330661575923)]
Top words for pretrained_BERT neuron indx 8637 [('five', 1.0), ('millis', 0.8882761644538091), ('package', 0.847595228896455), ('Geo', 0.8250726366436659), ('capacity', 0.77026085963064)]
Top words for pretrained_BERT neuron indx 6590 [('completed', 1.0), ('available', 0.917301303646502), ('intersects', 0.8655510229290663), ('INFO', 0.8634915195333136), ('USAGE', 0.8540195807993808)]
Top words for pretrained_BERT neuron indx 6594 [('75', 1.0), ('ignore', 0.9823815592771502), ('quota', 0.8977098913965317), ('Instance', 0.8770667727171505), ('tell', 0.8581284412522088)]
Top words for pretrained_BERT neuron indx 4547 [('Padding', 1.0), ('clone', 0.8962146091481649), ('ll', 0.8256743093168464), ('begin', 0.8200842767478306), ('renderers', 0.7954339346369197)]
Top words for pretrained_BERT neuron indx 455 [('Error', 1.0), ('ERROR', 0.9463499538446437), ('payload', 0.8779644433921789), ('socket', 0.8594137342481057), ('Invalid', 0.8550007711211248)]
Top words for pretrained_BERT neuron indx 457 [('Flag', 1.0), ('FLAG', 0.9667571731520338), ('context', 0.8622931277863378), ('Context', 0.7709694276618012), ('ENVIRONMENT', 0.7684529376077737)]
Top words for pretrained_BERT neuron indx 8652 [('def', 1.0), ('25', 0.9277989914569448), ('acquire', 0.9115651125234853), ('"KILLED"', 0.8997398239070404), ('redistricting', 0.8673391979222642)]
Top words for pretrained_BERT neuron indx 8660 [('principal', 1.0), ('recordings', 0.9412395256686501), ('plural', 0.9376395452909368), ('future', 0.9079630693853384), ('tenant', 0.9048928732375541)]
Top words for pretrained_BERT neuron indx 2516 [('repeat', 1.0), ('750', 0.9072754303973568), ('75', 0.9037158467490602), ('wait', 0.8734392213922617), ('400', 0.8538879164164564)]
Top words for pretrained_BERT neuron indx 8666 [('STP', 1.0), ('activate', 0.7873218397651169), ('qdict', 0.782115892137777), ('Region', 0.7415154716161126), ('TAGS', 0.7161941313793228)]
Top words for pretrained_BERT neuron indx 4577 [('negotiate', 1.0), ('201', 0.89028289542342), ('functions', 0.8335258283059991), ('800', 0.829966875787716), ('750', 0.7701907677672615)]
Top words for pretrained_BERT neuron indx 2529 [('inc', 1.0), ('authentication', 0.8638484098372685), ('2014', 0.8532617909054183), ('1970', 0.7893803293433521), ('trello', 0.789207063189088)]
Top words for pretrained_BERT neuron indx 8683 [('tornado', 1.0), ('discovery', 0.9135688506160037), ('500', 0.8348115339596942), ('single', 0.8307366575757721), ('tz_abbr', 0.8184236042126518)]
Top words for pretrained_BERT neuron indx 8687 [('"http://"', 1.0), ('117', 0.9472859597745767), ('119', 0.9400975817871808), ('33', 0.8841497392833593), ('17', 0.861250391242084)]
Top words for pretrained_BERT neuron indx 4594 [('ts', 1.0), ('five', 0.9253127646815578), ('bk', 0.9199227899934803), ('cb', 0.8688460914553314), ('ll', 0.8627176584528865)]
Top words for pretrained_BERT neuron indx 8692 [('119', 1.0), ('117', 0.8584258986791771), ('33', 0.8420563483043446), ('187', 0.8337896632483158), ('directionality', 0.8160857084650901)]
Top words for pretrained_BERT neuron indx 502 [('fixed', 1.0), ('loads', 0.8984701770045399), ('purpose', 0.8888402268260537), ('feature', 0.8851422829150458), ('material', 0.8740106038806155)]
Top words for pretrained_BERT neuron indx 8700 [('sim', 1.0), ('sender', 0.9131739159414083), ('5001', 0.8925677502643642), ('800', 0.8920962200531045), ('actions', 0.8664289714994635)]
Top words for pretrained_BERT neuron indx 8703 [('functions', 1.0), ('spawn', 0.89618781759986), ('Provider', 0.815324683044573), ('PYTHON_VERSION', 0.8118190953428475), ('resources', 0.8019758094814791)]
Top words for pretrained_BERT neuron indx 8709 [('81.4471435546875', 1.0), ('74.616338', 0.9310541993409623), ('"--version"', 0.8645688350745692), ('23.61432859499169', 0.816873354432727), ('33', 0.8107445657671736)]
Top words for pretrained_BERT neuron indx 4620 [('750', 1.0), ('installed', 0.9434500182538815), ('GetRange', 0.9396851651090519), ('with', 0.8970427377244354), ('Else', 0.859280320104033)]
Top words for pretrained_BERT neuron indx 4623 [('google', 1.0), ('remember', 0.9517621883003367), ('as', 0.9453575248980537), ('south', 0.9047988705886281), ('linkDown', 0.898818031583076)]
Top words for pretrained_BERT neuron indx 2576 [('license', 1.0), ('web', 0.8901794276205518), ('uri', 0.860883588684797), ('transaction', 0.7612481130200275), ('prop', 0.7485276184029569)]
Top words for pretrained_BERT neuron indx 8721 [('panels', 1.0), ('Clock', 0.8566954907038189), ('FLAG', 0.8320158120151815), ('Label', 0.7971003804337564), ('region', 0.7899223315603108)]
Top words for pretrained_BERT neuron indx 531 [('splits', 1.0), ('Geo', 0.989789078311502), ('tc', 0.9426538363430921), ('quota', 0.8926617479375047), ('stanza', 0.8884421409152757)]
Top words for pretrained_BERT neuron indx 4631 [('organization', 1.0), ('31', 0.9561058843627532), ('continue', 0.9551622622062504), ('wait', 0.8793189628915833), ('material', 0.79760566391525)]
Top words for pretrained_BERT neuron indx 6679 [('15598', 1.0), ('Http404', 0.9645250040916299), ('15597', 0.9058039578246586), ('15596', 0.871700542968271), ('0x02', 0.8259817218297051)]
Top words for pretrained_BERT neuron indx 8738 [('ax', 1.0), ('bindings', 0.989169885569574), ('"include"', 0.9673014146880475), ('"eu-west-1"', 0.8715178255887558), ('"define"', 0.8389784492917103)]
Top words for pretrained_BERT neuron indx 4645 [('resolve', 1.0), ('plural', 0.979109352669334), ('missing', 0.8172943141953307), ('Core', 0.7956017202125361), ('rollback', 0.7940105475081798)]
Top words for pretrained_BERT neuron indx 4650 [('baseline', 1.0), ('forwards', 0.9193458134035946), ('resolve', 0.8994966738726592), ('advance', 0.8961605382089173), ('spawn', 0.8882710641835709)]
Top words for pretrained_BERT neuron indx 6699 [('MEMBER', 1.0), ('functional', 0.9955339333855322), ('ADVERTISE', 0.9814640283017187), ('Invalid', 0.9767426935245664), ('Module', 0.9712782470039694)]
Top words for pretrained_BERT neuron indx 8752 [('Cat', 1.0), ('ts', 0.9145589493637915), ('sans', 0.8165468554541717), ('opener', 0.7879615027279263), ('lon__lt', 0.7604338134780644)]
Top words for pretrained_BERT neuron indx 8754 [('answer', 1.0), ('next', 0.988661105548806), ('Item', 0.8889846420210819), ('Subject', 0.8717173907606052), ('nextset', 0.7926538503495213)]
Top words for pretrained_BERT neuron indx 2612 [('and', 1.0), ('in', 0.9248110907160317), ('is', 0.9078516486382139), ('with', 0.8005722119590688), ('as', 0.8000503080771721)]
Top words for pretrained_BERT neuron indx 4662 [('installed', 1.0), ('sha', 0.9650633215540153), ('TAG', 0.9365086383118162), ('ri', 0.889513228233674), ('TAGS', 0.8636132390427166)]
Top words for pretrained_BERT neuron indx 2616 [('Simple', 1.0), ('single', 0.9592777357253077), ('geos', 0.9008351907547457), ('simple', 0.8312511745367178), ('organization', 0.82451834947674)]
Top words for pretrained_BERT neuron indx 2622 [('dr', 1.0), ('pa', 0.8589783896800748), ('branch', 0.8291005734423983), ('delay', 0.8284580512334825), ('deploy', 0.8104474515205932)]
Top words for pretrained_BERT neuron indx 4672 [('512', 1.0), ('Distance', 0.8575325533257832), ('89.999999999999992', 0.8444206339595552), ('behind', 0.8372696340316468), ('encoding', 0.8276260458824425)]
Top words for pretrained_BERT neuron indx 6729 [('fragment', 1.0), ('criterion', 0.9820494365735064), ('pattern', 0.9718965702073195), ('ur', 0.9501406896835506), ('2.1', 0.9422853036265831)]
Top words for pretrained_BERT neuron indx 8787 [('five', 1.0), ('do', 0.9673026152959107), ('variables', 0.9466147224024062), ('to', 0.9325162795022459), ('FILES', 0.9158879174011391)]
Top words for pretrained_BERT neuron indx 2643 [('scheme', 1.0), ('CANCEL', 0.9628814149988237), ('moving', 0.9254531048173432), ('sr', 0.8919361254842445), ('begin', 0.8019316032226833)]
Top words for pretrained_BERT neuron indx 2649 [('tasa', 1.0), ('header', 0.9225984358414823), ('WAYNODES', 0.9005275513961993), ('cdef', 0.867377372725098), ('pt1', 0.848364591185559)]
Top words for pretrained_BERT neuron indx 8793 [('ay', 1.0), ('ax', 0.7578768570782722), ('communities', 0.7568724323424824), ('construct', 0.7520932125752775), ('BBOX', 0.7428286258220828)]
Top words for pretrained_BERT neuron indx 4699 [('Cat', 1.0), ('Switch', 0.8841393796269705), ('assets', 0.8324040447668953), ('next', 0.782429389463477), ('capitalize', 0.7603504305461459)]
Top words for pretrained_BERT neuron indx 8797 [('purpose', 1.0), ('"purpose"', 0.9065333492064026), ('oslo', 0.9006750849020486), ('"-v"', 0.8736198463148211), ('Criteria', 0.8657780400166606)]
Top words for pretrained_BERT neuron indx 8798 [('dom', 1.0), ('afi', 0.9200422834931179), ('timezone', 0.9128419462057477), ('DeReference', 0.8768554232952074), ('pushkin', 0.8609225454657803)]
Top words for pretrained_BERT neuron indx 6761 [('187', 1.0), ('201', 0.9298990577733379), ('cancel', 0.8435759651828606), ('Allow', 0.8134126979981366), ('CANCEL', 0.8061457072327524)]
Top words for pretrained_BERT neuron indx 4715 [('200', 1.0), ('nsa', 0.9391207694826955), ('500', 0.86622534294817), ('512', 0.8171020509904171), ('quote', 0.7965077282609163)]
Top words for pretrained_BERT neuron indx 619 [('afi', 1.0), ('AFI', 0.964682782502111), ('ORIGIN', 0.944225331370275), ('Parent', 0.8583616287148343), ('form', 0.8553715337468247)]
Top words for pretrained_BERT neuron indx 4718 [('69', 1.0), ('117', 0.8009019126679072), ('63', 0.761641955564176), ('62', 0.7615487856303561), ('95', 0.7475532934619125)]
Top words for pretrained_BERT neuron indx 2673 [('bare', 1.0), ('number', 0.869493912838695), ('demo', 0.7932993156342208), ('execute', 0.74237621925489), ('twisted', 0.7167446242155671)]
Top words for pretrained_BERT neuron indx 2681 [('CREATING', 1.0), ('Presence', 0.7920724041411797), ('INFO', 0.7577971930679558), ('24', 0.7413964750279454), ('collect', 0.7291840488284232)]
Top words for pretrained_BERT neuron indx 634 [('opener', 1.0), ('context', 0.7641437236604838), ('Filter', 0.7373721936441315), ('realm', 0.6550422537886151), ('medium', 0.6475614824112905)]
Top words for pretrained_BERT neuron indx 8828 [('42', 1.0), ('tv', 0.9139073313304297), ('69', 0.8531299651085695), ('443', 0.7880263860143208), ('5001', 0.7770418665206732)]
Top words for pretrained_BERT neuron indx 2686 [('SUCCESS', 1.0), ('remember', 0.9678932340948437), ('Action', 0.9046456126546849), ('success', 0.9004782596845808), ('wait', 0.8824607635222843)]
Top words for pretrained_BERT neuron indx 4748 [('minutes', 1.0), ('compute', 0.8744625883304007), ('texture', 0.7405017964027014), ('PIECE', 0.7175580612823506), ('minute', 0.7114149068166803)]
Top words for pretrained_BERT neuron indx 2707 [('sid', 1.0), ('principal', 0.8861941911230736), ('expand', 0.8263019983871669), ('uss', 0.7792053400413734), ('decimal', 0.7216630073011338)]
Top words for pretrained_BERT neuron indx 4755 [('75', 1.0), ('35', 0.9237454653248914), ('69', 0.856047472853448), ('23', 0.8380644372128114), ('Unauthorized', 0.827315159764888)]
Top words for pretrained_BERT neuron indx 8851 [('28', 1.0), ('south', 0.8770121892029671), ('oslo', 0.8206494843969073), ('plural', 0.8008892634599697), ('Else', 0.7847499802321612)]
Top words for pretrained_BERT neuron indx 2726 [('119', 1.0), ('required', 0.9966101878603649), ('18', 0.9488903194541127), ('reactor', 0.9475917449769935), ('23', 0.890470211046017)]
Top words for pretrained_BERT neuron indx 4778 [('42', 1.0), ('severity', 0.9107040172516067), ('blank', 0.8946645571678024), ('score', 0.8924014796942071), ('is', 0.8411573118379199)]
Top words for pretrained_BERT neuron indx 6828 [('runner', 1.0), ('long', 0.9132114898209296), ('license', 0.8740222179708845), ('Int', 0.8655835405244914), ('Reg', 0.8419618285684359)]
Top words for pretrained_BERT neuron indx 2735 [('internet', 1.0), ('512', 0.819696260786846), ('composite', 0.8080452463432813), ('25', 0.7639111452960631), ('Basic', 0.7508826044744242)]
Top words for pretrained_BERT neuron indx 8883 [('33', 1.0), ('ah', 0.9463182204073859), ('splits', 0.8508421961179115), ('nh', 0.8134322666911329), ('ex', 0.796551675413729)]
Top words for pretrained_BERT neuron indx 695 [('texture', 1.0), ('policy', 0.9375961016235551), ('operator', 0.8891299674802542), ('notes', 0.8809069930188815), ('PATHS', 0.8778977655084992)]
Top words for pretrained_BERT neuron indx 2749 [('vol', 1.0), ('Invalid', 0.9654513709785604), ('ps', 0.9333339455589951), ('nclk', 0.9081448052264544), ('venue', 0.9079778523291152)]
Top words for pretrained_BERT neuron indx 8897 [('secs', 1.0), ('95', 0.9734818277677564), ('75', 0.9486562566630943), ('horizon', 0.779997749235031), ('80', 0.7769256922018539)]
Top words for pretrained_BERT neuron indx 8898 [('quota', 1.0), ('75', 0.8721999894999077), ('ignore', 0.8340613316681574), ('tell', 0.7564157620417792), ('WITHDRAW', 0.7403385723309988)]
Top words for pretrained_BERT neuron indx 2754 [('BOUNDS', 1.0), ('sans', 0.9916202980016788), ('notes', 0.9642464370471604), ('Provider', 0.908429520727647), ('Job', 0.8757069736035628)]
Top words for pretrained_BERT neuron indx 6852 [('Label', 1.0), ('None', 0.8943778070185182), ('twisted', 0.8607333110842084), ('Delay', 0.7300763625375933), ('ahead', 0.7279768649697452)]
Top words for pretrained_BERT neuron indx 2757 [('Cat', 1.0), ('visit', 0.8339072569889336), ('expand', 0.711348027720894), ('NODES', 0.6909207843868352), ('handlers', 0.6807208820960372)]
Top words for pretrained_BERT neuron indx 8907 [('five', 1.0), ('interval', 0.9711692494220538), ('qset', 0.8924702356034718), ('submit', 0.8713210835169628), ('TAG', 0.853235832746876)]
Top words for pretrained_BERT neuron indx 4820 [('75', 1.0), ('750', 0.9450317570739197), ('principal', 0.9397887408099512), ('wait', 0.9255840188193845), ('95', 0.9134398817606271)]
Top words for pretrained_BERT neuron indx 4826 [('MAXIMUM', 1.0), ('MINIMUM', 0.9794378248783597), ('fabric', 0.9685676090104687), ('Failure', 0.9628315233680612), ('Delay', 0.9606060374767866)]
Top words for pretrained_BERT neuron indx 4827 [('3600', 1.0), ('300', 0.9720371019859968), ('90.0', 0.961678941392037), ('180.0', 0.9526253913462676), ('15000', 0.930218722451972)]
Top words for pretrained_BERT neuron indx 8935 [('"y"', 1.0), ('printplan', 0.9693168447316822), ('ay', 0.9281934404519142), ('oslo', 0.8607288374271831), ('999999', 0.8472583179355604)]
Top words for pretrained_BERT neuron indx 4843 [('REFERENCES', 1.0), ('missing', 0.7498674679604652), ('DEFAULT', 0.7143359159873091), ('BOUNDS', 0.7071002317185003), ('calendar', 0.7037995000170055)]
Top words for pretrained_BERT neuron indx 8944 [('excepts', 1.0), ('recordings', 0.8959424531859956), ('187', 0.853818649525977), ('STATUS', 0.8486028812089602), ('18', 0.8478320659409381)]
Top words for pretrained_BERT neuron indx 754 [('bk', 1.0), ('el', 0.9345065552331034), ('span', 0.851924103872619), ('confirm', 0.7955281197191302), ('backwards', 0.7954190619575114)]
Top words for pretrained_BERT neuron indx 2811 [('If', 1.0), ('if', 0.984987408021022), ('functions', 0.8896592141748473), ('Signature', 0.8186890464106709), ('scenario', 0.796853403810357)]
Top words for pretrained_BERT neuron indx 4864 [('AFI', 1.0), ('lat', 0.9774809622372658), ('initial', 0.9343925050214955), ('tell', 0.9272268519294811), ('from', 0.9231175226008318)]
Top words for pretrained_BERT neuron indx 2821 [('ORIGIN', 1.0), ('55', 0.9604277596882768), ('3785', 0.9210752261299691), ('Else', 0.9043644962459173), ('resource', 0.8484694994644589)]
Top words for pretrained_BERT neuron indx 773 [('sublime', 1.0), ('Card', 0.9439810639631399), ('relay', 0.9131039101935904), ('40', 0.8310075787003914), ('month', 0.8233796359972735)]
Top words for pretrained_BERT neuron indx 6923 [('17', 1.0), ('21', 0.9951607397823512), ('18', 0.993721985258276), ('69', 0.9194473168730842), ('187', 0.9108148924784657)]
Top words for pretrained_BERT neuron indx 6925 [('builtins', 1.0), ('On', 0.9607099562498848), ('ON', 0.9607099562498848), ('except', 0.9256127850396557), ('communities', 0.8516279606069685)]
Top words for pretrained_BERT neuron indx 783 [('dom', 1.0), ('sock', 0.997607294733046), ('PIECE', 0.9187280473583955), ('ajax', 0.9046810072524382), ('linkDown', 0.8134958112120781)]
Top words for pretrained_BERT neuron indx 6927 [('venue', 1.0), ('as', 0.8559713294928816), ('Plugin', 0.8202690595451894), ('0.04', 0.7673564829465274), ('up', 0.7402714965202598)]
Top words for pretrained_BERT neuron indx 2833 [('day', 1.0), ('month', 0.9012613828614429), ('hour', 0.8701161286474929), ('minute', 0.8630176082988876), ('plugin', 0.8592040877003265)]
Top words for pretrained_BERT neuron indx 8983 [('Criteria', 1.0), ('original', 0.7358762273404147), ('changed', 0.7327783809146984), ('full_name', 0.7268818615131178), ('lock', 0.7155210457712198)]
Top words for pretrained_BERT neuron indx 2842 [('pa', 1.0), ('selection', 0.8961943262192489), ('cm', 0.7375957204509421), ('OK', 0.7350171253966669), ('2014', 0.7139698870208361)]
Top words for pretrained_BERT neuron indx 6942 [('next', 1.0), ('Event', 0.9244538899866889), ('by', 0.8152907266727533), ('pisa', 0.8116968358219481), ('oid', 0.7857307588039457)]
Top words for pretrained_BERT neuron indx 799 [('Auditor', 1.0), ('fin', 0.9912114888290263), ('auditor', 0.9310953080138765), ('regions', 0.9310930290314444), ('lb', 0.8204351568820171)]
Top words for pretrained_BERT neuron indx 8992 [('delay', 1.0), ('opener', 0.9944615243059762), ('bandwidth', 0.9863795227350124), ('Delay', 0.9400125310709629), ('117', 0.9223680626506591)]
Top words for pretrained_BERT neuron indx 4898 [('functional', 1.0), ('construct', 0.8356396308390294), ('Delay', 0.8355629792125709), ('probe', 0.8219270903736307), ('"KILLED"', 0.8174150943885491)]
Top words for pretrained_BERT neuron indx 6954 [('decorators', 1.0), ('baseline', 0.9510035612162532), ('buffer', 0.9448767188449978), ('CONNECTED', 0.9016623589228139), ('unicode', 0.8925954716219011)]
Top words for pretrained_BERT neuron indx 2859 [('clean', 1.0), ('Update', 0.9647530060048379), ('audit', 0.8692242351783775), ('functional', 0.7979916656190332), ('bson', 0.7752818907350675)]
Top words for pretrained_BERT neuron indx 9003 [('bson', 1.0), ('with', 0.9199800059619653), ('functional', 0.909201428473008), ('class', 0.9016102246893732), ('1970', 0.8893952176617023)]
Top words for pretrained_BERT neuron indx 810 [('capacity', 1.0), ('encoding', 0.9827537497826179), ('sr', 0.9516180768208015), ('unicode', 0.9125453346382636), ('revision', 0.9051122906134259)]
Top words for pretrained_BERT neuron indx 6966 [('startTime', 1.0), ('LAT', 0.9690929256219516), ('READY', 0.9098294344223588), ('sha', 0.887640730734549), ('mesh', 0.8626547683998581)]
Top words for pretrained_BERT neuron indx 9020 [('venue', 1.0), ('cb', 0.8884613859515896), ('Venue', 0.8821424630291373), ('multiple', 0.8561023969226107), ('1411135000', 0.808344886869754)]
Top words for pretrained_BERT neuron indx 6976 [('512', 1.0), ('behind', 0.9294456286908721), ('fifteen', 0.915875653842766), ('80', 0.8828342912299245), ('999999', 0.8501893349097832)]
Top words for pretrained_BERT neuron indx 832 [('Tab', 1.0), ('authorized', 0.9156677619678288), ('synchronized', 0.832740408554148), ('Message', 0.7988616254188695), ('512', 0.7727542626745324)]
Top words for pretrained_BERT neuron indx 2883 [('current', 1.0), ('mail', 0.8887752174445995), ('ax', 0.8878617843687092), ('targets', 0.8672769897232192), ('entry', 0.8433537952461597)]
Top words for pretrained_BERT neuron indx 9034 [('targets', 1.0), ('forwards', 0.9055024159972648), ('destroy', 0.9001869244171301), ('Job', 0.8960999050883804), ('CONNECTED', 0.871581768107249)]
Top words for pretrained_BERT neuron indx 9041 [('providers', 1.0), ('services', 0.9852917989543077), ('quota', 0.9463587193552268), ('CREATING', 0.8799912322450376), ('resources', 0.8776964686792392)]
Top words for pretrained_BERT neuron indx 4947 [('CANCEL', 1.0), ('scheme', 0.9169176173353434), ('initial', 0.8941828692689051), ('View', 0.8374136288807937), ('zope', 0.7969309390087734)]
Top words for pretrained_BERT neuron indx 9048 [('750', 1.0), ('CREATING', 0.9818096307247199), ('rslt', 0.9367677864279362), ('pytz', 0.9356811782591927), ('emailfile', 0.9022621719194789)]
Top words for pretrained_BERT neuron indx 4964 [('Column', 1.0), ('MEMBER', 0.8396391639244458), ('def', 0.7606936191216956), ('flat', 0.6996175685776379), ('23', 0.695159510200421)]
Top words for pretrained_BERT neuron indx 9065 [('187', 1.0), ('201', 0.9851494689463345), ('302', 0.8990731028169283), ('cancel', 0.8512321990871559), ('handle', 0.783133663311675)]
Top words for pretrained_BERT neuron indx 875 [('organization', 1.0), ('agency', 0.9702060610003717), ('200', 0.9374292816467448), ('activity', 0.9180056727666486), ('500', 0.8598110815317607)]
Top words for pretrained_BERT neuron indx 7022 [('69', 1.0), ('117', 0.8337113828083842), ('119', 0.7214454126653127), ('organization', 0.662940982213472), ('55', 0.6461663210584155)]
Top words for pretrained_BERT neuron indx 9072 [('Recording', 1.0), ('recordings', 0.9907460615629385), ('video', 0.9850228460375915), ('Video', 0.9745568905428148), ('62', 0.9490368443506616)]
Top words for pretrained_BERT neuron indx 4977 [('bare', 1.0), ('fifteen', 0.9732286464538904), ('ERROR', 0.957740534906405), ('number', 0.8549997174871098), ('internet', 0.8359118164367596)]
Top words for pretrained_BERT neuron indx 883 [('engine', 1.0), ('year', 0.8861279273339088), ('auditor', 0.8106474834093487), ('plans', 0.8058360530474977), ('payload', 0.7737611658250981)]
Top words for pretrained_BERT neuron indx 4985 [('CREATING', 1.0), ('CANCEL', 0.9532894324647271), ('topology', 0.879173904803044), ('SON', 0.8152103222446896), ('INFO', 0.7841341012641572)]
Top words for pretrained_BERT neuron indx 7037 [('tell', 1.0), ('called', 0.9008067393988615), ('File', 0.892308726132946), ('CREATING', 0.8392936701763777), ('communities', 0.8377330466191296)]
Top words for pretrained_BERT neuron indx 4990 [('SUCCESS', 1.0), ('negotiate', 0.9560509482062195), ('calendar', 0.9163230407981718), ('success', 0.8745111229163196), ('collect', 0.8676421994989423)]
Top words for pretrained_BERT neuron indx 4993 [('reason', 1.0), ('backwards', 0.9608887949580307), ('filtered', 0.8603150778448356), ('Else', 0.8503568074547135), ('PROVISION', 0.8355349560046649)]
Top words for pretrained_BERT neuron indx 9090 [('"SUCCEEDED"', 1.0), ('SON', 0.8389165418425398), ('ll', 0.8162645761941998), ('"warning"', 0.8000853417128312), ('cm', 0.7891754416671076)]
Top words for pretrained_BERT neuron indx 9096 [('with', 1.0), ('ur', 0.9125754582097483), ('PROVISION', 0.8991540520341885), ('187', 0.8414210685068485), ('204', 0.824725998926951)]
Top words for pretrained_BERT neuron indx 7052 [('compute', 1.0), ('minutes', 0.97370501680164), ('completed', 0.8792559131515016), ('Int', 0.852646646628264), ('80', 0.8490287228530402)]
Top words for pretrained_BERT neuron indx 9107 [('extent', 1.0), ('http', 0.8429446875579837), ('OK', 0.7474958402236167), ('HTTP_PORT', 0.7474234672894848), ('remote', 0.69488218283136)]
Top words for pretrained_BERT neuron indx 5011 [('sid', 1.0), ('decimal', 0.9108371788253788), ('principal', 0.8644311253974318), ('plural', 0.8641479268064327), ('31', 0.8302628223159338)]
Top words for pretrained_BERT neuron indx 2963 [('safi', 1.0), ('SAFI', 0.9537106453880793), ('Document', 0.8497844084002761), ('75', 0.8189057439598927), ('disp', 0.8143919748018372)]
Top words for pretrained_BERT neuron indx 921 [('responses', 1.0), ('video', 0.9848519224034687), ('page', 0.9788485531129141), ('interface', 0.902492890439181), ('Presence', 0.8687987133256715)]
Top words for pretrained_BERT neuron indx 927 [('201', 1.0), ('302', 0.9649452199744686), ('"Height"', 0.9225817370590105), ('"label"', 0.9182789714576003), ('"Width"', 0.8867571812685014)]
Top words for pretrained_BERT neuron indx 9122 [('WAY', 1.0), ('enclosure', 0.882504907536093), ('materials', 0.8495373737978213), ('scenario', 0.8444639507754899), ('sublime', 0.8172645035179226)]
Top words for pretrained_BERT neuron indx 5026 [('outgoing', 1.0), ('Wire', 0.8912792434052027), ('35', 0.7518434320013051), ('receive', 0.7335370078677194), ('forwards', 0.7117958867830806)]
Top words for pretrained_BERT neuron indx 5030 [('18', 1.0), ('119', 0.9820528982895985), ('36', 0.9318956685293237), ('23', 0.9310825791565576), ('117', 0.8741256256040133)]
Top words for pretrained_BERT neuron indx 7082 [('blank', 1.0), ('upstream', 0.9835005051566967), ('mins', 0.9400331369996332), ('BRIGHTNESS', 0.9105466264743266), ('missing', 0.9014665486054686)]
Top words for pretrained_BERT neuron indx 5035 [('1970', 1.0), ('continue', 0.8937767991586857), ('next', 0.8370875828819315), ('repeat', 0.8065257335107531), ('pisa', 0.7885468829866381)]
Top words for pretrained_BERT neuron indx 9132 [('next', 1.0), ('runner', 0.9775714017016754), ('long', 0.9332169681016992), ('Reg', 0.872680700577815), ('five', 0.8530673239434737)]
Top words for pretrained_BERT neuron indx 9140 [('69', 1.0), ('400', 0.9773340990160374), ('62', 0.8914765891533853), ('PIECE', 0.8836346774874414), ('"HEAD"', 0.8167161518196018)]
Top words for pretrained_BERT neuron indx 5054 [('available', 1.0), ('200', 0.9070843421168812), ('completed', 0.829575593508781), ('extent', 0.8120856793902028), ('choice', 0.7976073649871596)]
Top words for pretrained_BERT neuron indx 5058 [('ignore', 1.0), ('Default', 0.920131641762547), ('sourceSTP', 0.8921444383264081), ('Else', 0.8750111086397425), ('MAXIMUM', 0.8348663035257121)]
Top words for pretrained_BERT neuron indx 7108 [('40', 1.0), ('bandwidth', 0.9543577972129127), ('quality', 0.7952614108228357), ('400', 0.7800507312511981), ('capacity', 0.7793208546711342)]
Top words for pretrained_BERT neuron indx 9156 [('prop', 1.0), ('Label', 0.9698088887366688), ('scenario', 0.8218401185733241), ('117', 0.816116021681749), ('None', 0.7780424124641109)]
Top words for pretrained_BERT neuron indx 9159 [('READY', 1.0), ('69', 0.9911803152962442), ('75', 0.8860699978065605), ('55', 0.8689036527183372), ('35', 0.8336930908885364)]
Top words for pretrained_BERT neuron indx 9161 [('SON', 1.0), ('443', 0.8296129264222423), ('simple', 0.8056967403926418), ('clock', 0.7727240168222856), ('framing', 0.7657289250197805)]
Top words for pretrained_BERT neuron indx 7116 [('epoch_milliseconds', 1.0), ('epoch_microseconds', 0.8453240716919864), ('"KILLED"', 0.838384565746997), ('milliseconds', 0.8286083511732606), ('five', 0.8250537101137811)]
Top words for pretrained_BERT neuron indx 975 [('active', 1.0), ('200', 0.8954551146484078), ('400', 0.8612911214165705), ('750', 0.8515027932711536), ('span', 0.8469899895141804)]
Top words for pretrained_BERT neuron indx 7124 [('principal', 1.0), ('repeat', 0.9967013592333934), ('TERMINATE', 0.9266065439300266), ('VRF', 0.8883667349004135), ('notes', 0.8532968304234537)]
Top words for pretrained_BERT neuron indx 7130 [('STP', 1.0), ('IntType', 0.8457174080517239), ('rjust', 0.7667567619099608), ('simple', 0.7662397040615144), ('74.616338', 0.7533738865315784)]
Top words for pretrained_BERT neuron indx 3041 [('201', 1.0), ('negotiate', 0.9327729672975426), ('detect', 0.8711364384651552), ('acquire', 0.8611902730294564), ('15000', 0.8185389742555407)]
Top words for pretrained_BERT neuron indx 998 [('Proto', 1.0), ('length', 0.9124551404244597), ('year', 0.889284345579294), ('deploy', 0.887834113913292), ('v2', 0.8728250961651141)]
Top words for pretrained_BERT neuron indx 7147 [('tornado', 1.0), ('setLevel', 0.8367443159230084), ('Invalid', 0.8153194955193169), ('with_tz', 0.8041756333525739), ('discovery', 0.7957733987876896)]
Top words for pretrained_BERT neuron indx 9202 [('ts', 1.0), ('sid', 0.9307768402682788), ('el', 0.923379252885519), ('bk', 0.8165950346818136), ('auditor', 0.7836354376516546)]
Top words for pretrained_BERT neuron indx 5115 [('processes', 1.0), ('functions', 0.9829234764230967), ('If', 0.9715356724216047), ('Simple', 0.9714547058557762), ('if', 0.9100866870863582)]
Top words for pretrained_BERT neuron indx 7173 [('"--version"', 1.0), ('"--include"', 0.972763954647047), ('"--top"', 0.9643461981082811), ('Int', 0.9478163139429149), ('"daytime"', 0.9131439104193909)]
Top words for pretrained_BERT neuron indx 3077 [('sublime', 1.0), ('relay', 0.9862238913964043), ('lb', 0.9712237290479081), ('scheme', 0.9071604433276146), ('Video', 0.8439289989519836)]
Top words for pretrained_BERT neuron indx 5133 [('installed', 1.0), ('Point', 0.997085093642218), ('stores', 0.9084505616898557), ('available', 0.8834923730164121), ('calendar', 0.8801066196808279)]
Top words for pretrained_BERT neuron indx 9231 [('Region', 1.0), ('District', 0.9693453419429048), ('Plugin', 0.9529047707878188), ('0.04', 0.8861661860368982), ('do', 0.8805203147036639)]
Top words for pretrained_BERT neuron indx 1040 [('web', 1.0), ('license', 0.9588771508128763), ('detect', 0.8981011709656335), ('prop', 0.8878125682733022), ('Gallery', 0.8792149567290163)]
Top words for pretrained_BERT neuron indx 3089 [('play', 1.0), ('provision', 0.9427725571632842), ('visitor', 0.9368851367966483), ('ignore', 0.9188736175537042), ('destroy', 0.8830086922019589)]
Top words for pretrained_BERT neuron indx 5141 [('None', 1.0), ('or', 0.9843491363947049), ('changed', 0.9632497710442871), ('installed', 0.9432163774020708), ('Else', 0.941304741926026)]
Top words for pretrained_BERT neuron indx 9237 [('authorization', 1.0), ('blank', 0.9156612768753186), ('inc', 0.7834370231014411), ('internet', 0.7658778777390048), ('FSM', 0.7405880327677635)]
Top words for pretrained_BERT neuron indx 5143 [('Http404', 1.0), ('cover', 0.9789255451034423), ('15598', 0.9331388559895833), ('Origin', 0.9329980071490304), ('1411135000', 0.9126857432755253)]
Top words for pretrained_BERT neuron indx 7192 [('with', 1.0), ('2014', 0.8892730704534431), ('multiple', 0.8294611028146012), ('sites', 0.7778751175075971), ('collect', 0.7429346355765438)]
Top words for pretrained_BERT neuron indx 1047 [('twisted', 1.0), ('LOGGING', 0.9809629014901983), ('span', 0.9182501591337044), ('targets', 0.9104813679143022), ('getJob', 0.9045105297728704)]
Top words for pretrained_BERT neuron indx 1053 [('Instance', 1.0), ('hour', 0.8831791087588529), ('sha1', 0.8729807931525078), ('management', 0.8649580943545042), ('include', 0.8568643049168135)]
Top words for pretrained_BERT neuron indx 7202 [('"KILLED"', 1.0), ('"define"', 0.9770363050733379), ('"include"', 0.9520272983890574), ('"SUCCEEDED"', 0.7885744993489536), ('"FAILED"', 0.7461651242041862)]
Top words for pretrained_BERT neuron indx 5156 [('each', 1.0), ('62', 0.7173035387806184), ('CheckUpdate', 0.555801777588417), ('1970', 0.5527836583623083), ('MAXSIGLINES', 0.5454158581821311)]
Top words for pretrained_BERT neuron indx 9253 [('wait', 1.0), ('fail', 0.9397198277858015), ('_property', 0.9357634152499092), ('plural', 0.8475449248211816), ('resolve', 0.8457193451053793)]
Top words for pretrained_BERT neuron indx 3109 [('plural', 1.0), ('75', 0.747156203610863), ('63', 0.7323005898248313), ('80', 0.7075988869823909), ('looking_glass', 0.7041404075915327)]
Top words for pretrained_BERT neuron indx 3114 [('unicode', 1.0), ('Bytes', 0.9022128644578179), ('listen', 0.8690549352069189), ('revision', 0.8543360302078075), ('resolve', 0.84715135074764)]
Top words for pretrained_BERT neuron indx 5163 [('MEMBER', 1.0), ('Module', 0.9714005726710978), ('Invalid', 0.8556415964508681), ('functional', 0.8336160778827317), ('ADVERTISE', 0.8300261609165694)]
Top words for pretrained_BERT neuron indx 9264 [('ex', 1.0), ('ip', 0.9851749505541506), ('mpls', 0.952340466523797), ('notes', 0.9147443881836271), ('512', 0.9068592128645245)]
Top words for pretrained_BERT neuron indx 7218 [('next', 1.0), ('and', 0.9065677434947634), ('200', 0.8660306957691879), ('187', 0.8429161364899782), ('internet', 0.8320028136044667)]
Top words for pretrained_BERT neuron indx 1076 [('and', 1.0), ('in', 0.8906884490921863), ('".."', 0.8685345141037353), ('to', 0.8322022686215242), ('is', 0.7514481175687243)]
Top words for pretrained_BERT neuron indx 3126 [('seek', 1.0), ('installed', 0.9866935495035574), ('Task', 0.7970091125588975), ('ur', 0.7925685953895025), ('sa', 0.7702627889357272)]
Top words for pretrained_BERT neuron indx 1086 [('Manager', 1.0), ('manager', 0.9095791986340388), ('repeat', 0.9029455888031036), ('dr', 0.867860808393302), ('submit', 0.8153408314943741)]
Top words for pretrained_BERT neuron indx 3136 [('512', 1.0), ('encoding', 0.9658077455801503), ('authorized', 0.8467096203572989), ('fifteen', 0.8416168433192956), ('Authorization', 0.830567658509209)]
Top words for pretrained_BERT neuron indx 7233 [('record', 1.0), ('Allow', 0.9747132293245848), ('moving', 0.936542450361006), ('oslo', 0.9174862576565507), ('1800', 0.9123682343356249)]
Top words for pretrained_BERT neuron indx 3141 [('Reg', 1.0), ('include', 0.9762409547129705), ('resource', 0.8520526275753594), ('display', 0.8503411749766071), ('search', 0.8494074300674853)]
Top words for pretrained_BERT neuron indx 9291 [('http', 1.0), ('urls', 0.8801910119894767), ('PayloadError', 0.8554856381696699), ('mins', 0.8498041424081624), ('google', 0.8330027300452421)]
Top words for pretrained_BERT neuron indx 9293 [('Else', 1.0), ('excinfo', 0.7860709290661604), ('UserInfo', 0.7568326037292952), ('If', 0.7140868985247864), ('postinfo', 0.6791662644159591)]
Top words for pretrained_BERT neuron indx 7252 [('"submit"', 1.0), ('"*"', 0.9815000588221142), ('"{}-{}-{}"', 0.9433310179713147), ('"thumb"', 0.9225994231680553), ('"view"', 0.9138974473409646)]
Top words for pretrained_BERT neuron indx 5208 [('1800', 1.0), ('800', 0.9748997356849268), ('200', 0.8686854245320003), ('75', 0.8559289498758158), ('15000', 0.8376820405283112)]
Top words for pretrained_BERT neuron indx 7257 [('BBOX', 1.0), ('srid', 0.9450484800331381), ('find_plan_splits', 0.8680393464377275), ('ay', 0.8212780728397018), ('GetBoard', 0.81096232310418)]
Top words for pretrained_BERT neuron indx 3163 [('abstract', 1.0), ('Cat', 0.9850105543967063), ('assets', 0.9390191756240919), ('capitalize', 0.8875264241815982), ('deploy', 0.8859482930035972)]
Top words for pretrained_BERT neuron indx 9312 [('agency', 1.0), ('reddit', 0.9900603073774963), ('five', 0.9787216771780533), ('presence', 0.9315438220103377), ('pisa', 0.8790618615552174)]
Top words for pretrained_BERT neuron indx 5225 [('187', 1.0), ('201', 0.9703652427702137), ('NODES', 0.9675116293451864), ('Allow', 0.9576681181586164), ('CANCEL', 0.9298823891360011)]
Top words for pretrained_BERT neuron indx 3179 [('200', 1.0), ('500', 0.9258928693525634), ('512', 0.7889133601044517), ('75', 0.7013425062551865), ('nsa', 0.6825740986351542)]
Top words for pretrained_BERT neuron indx 9341 [('startTime', 1.0), ('ORIGIN', 0.8831834512360349), ('pb', 0.8589825472273019), ('bv', 0.8554151348686114), ('redistricting', 0.8283465963983047)]
Top words for pretrained_BERT neuron indx 1150 [('remember', 1.0), ('raise', 0.872837051924275), ('SUCCESS', 0.8181918219476451), ('vol', 0.8118421217248534), ('fifteen', 0.7986400772933574)]
Top words for pretrained_BERT neuron indx 7294 [('SUCCESS', 1.0), ('Criteria', 0.9843414763356789), ('restart', 0.9339693191923438), ('success', 0.9244293440677298), ('RELEASE', 0.9218823257437276)]
Top words for pretrained_BERT neuron indx 9345 [('Tab', 1.0), ('DatastoreBase', 0.9372426927082188), ('oslo', 0.9061593840046052), ('http11', 0.8951134147701783), ('Auditor', 0.8835315679727339)]
Top words for pretrained_BERT neuron indx 5250 [('WAY', 1.0), ('moving', 0.8574312062217806), ('REFERENCES', 0.8244223225858023), ('builtins', 0.8115988260886943), ('On', 0.7951764578254092)]
Top words for pretrained_BERT neuron indx 7302 [('42', 1.0), ('75', 0.9661295117985114), ('"pv"', 0.8548816402082282), ('"0"', 0.8518973546346165), ('"r"', 0.8352459688582247)]
Top words for pretrained_BERT neuron indx 9350 [('subscribers', 1.0), ('from', 0.9919880359567428), ('millis', 0.9721675330880134), ('RouteDistinguisher', 0.9620307690222871), ('ElasticSearchServiceTestCase', 0.8756740934521794)]
Top words for pretrained_BERT neuron indx 3212 [('minutes', 1.0), ('compute', 0.8666344263606879), ('texture', 0.8010408972914282), ('authorized', 0.7715819191208908), ('districts', 0.7134813581694079)]
Top words for pretrained_BERT neuron indx 5266 [('scheme', 1.0), ('south', 0.8916720013168965), ('NODE', 0.8125466400848667), ('window', 0.7880195996954676), ('interface', 0.7626978159751436)]
Top words for pretrained_BERT neuron indx 5267 [('1800', 1.0), ('Document', 0.9867989873164941), ('Filter', 0.9272982948128926), ('95', 0.9173327696956894), ('75', 0.9114596380617542)]
Top words for pretrained_BERT neuron indx 5268 [('month', 1.0), ('ALPHABET', 0.857101690009748), ('groups', 0.8017587982769618), ('Video', 0.7783824027079049), ('2014', 0.7356472085187865)]
Top words for pretrained_BERT neuron indx 7315 [('oslo', 1.0), ('Else', 0.8522572378894505), ('south', 0.8401605729334408), ('28', 0.7988829120801217), ('sid', 0.7491979027346853)]
Top words for pretrained_BERT neuron indx 9368 [('HTTP_PORT', 1.0), ('implementation', 0.9511237822188943), ('Else', 0.9396971614138073), ('operator', 0.9116813220841659), ('functional', 0.9028305777678117)]
Top words for pretrained_BERT neuron indx 7330 [('outgoing', 1.0), ('fifteen', 0.9156112804358726), ('Else', 0.8686200187975601), ('If', 0.8014498413564551), ('tell', 0.8012399306428786)]
Top words for pretrained_BERT neuron indx 1190 [('3785', 1.0), ('subscribers', 0.9838397795362457), ('def', 0.9502458152749942), ('reactor', 0.9313538375065886), ('119', 0.9130963392055548)]
Top words for pretrained_BERT neuron indx 7334 [('36', 1.0), ('302', 0.9281438049227142), ('31', 0.8351034817975813), ('127', 0.8293151756715402), ('23', 0.8269480636799751)]
Top words for pretrained_BERT neuron indx 3242 [('400', 1.0), ('blank', 0.9203579628905209), ('512', 0.9039193479441469), ('missing', 0.9014461363404191), ('Assign', 0.8911700301821802)]
Top words for pretrained_BERT neuron indx 5292 [('long', 1.0), ('Int', 0.9544241902395817), ('runner', 0.9387974731738611), ('Reg', 0.9117403579909202), ('include', 0.7854443720080292)]
Top words for pretrained_BERT neuron indx 1199 [('composite', 1.0), ('forget', 0.8084522702055768), ('internet', 0.7995500952147463), ('principal', 0.7967405569038473), ('25', 0.7920088872801377)]
Top words for pretrained_BERT neuron indx 7344 [('pushkin', 1.0), ('CREATING', 0.9912485940022577), ('spawn', 0.9508669142962808), ('blend', 0.7876193235588582), ('pa', 0.7307447866022356)]
Top words for pretrained_BERT neuron indx 7347 [('ah', 1.0), ('ex', 0.8799867396677761), ('discovery', 0.8758551896760661), ('nh', 0.8647096808050743), ('33', 0.8608123831051453)]
Top words for pretrained_BERT neuron indx 9396 [('"http://localhost:8080/genie"', 1.0), ('"HTTP"', 0.8842775587099373), ('"https://accounts.google.com/o/oauth2/token"', 0.8318984774569225), ('"boards"', 0.808414277314321), ('"id"', 0.7999342345991892)]
Top words for pretrained_BERT neuron indx 5299 [('Clock', 1.0), ('clock', 0.8943793991123163), ('127', 0.889034426464307), ('platforms', 0.812948463629281), ('deploy', 0.7961425521190953)]
Top words for pretrained_BERT neuron indx 9400 [('branch', 1.0), ('spawn', 0.8678134654182014), ('fetch', 0.7368431104093575), ('GEOSGeometry', 0.7068040447544668), ('Criteria', 0.6747712624100168)]
Top words for pretrained_BERT neuron indx 7358 [('completed', 1.0), ('intersects', 0.9823027682566524), ('available', 0.9141277782553651), ('INFO', 0.8875382574386472), ('ahead', 0.8780336914754069)]
Top words for pretrained_BERT neuron indx 5316 [('rules', 1.0), ('None', 0.9266514386276941), ('prop', 0.7914627215801086), ('Label', 0.7871558727801138), ('GENERATOR', 0.7770943556817492)]
Top words for pretrained_BERT neuron indx 1221 [('Cat', 1.0), ('visit', 0.7848454953362847), ('SUCCESS', 0.6610540895121819), ('choice', 0.6532968902574179), ('processors', 0.6299162867600807)]
Top words for pretrained_BERT neuron indx 1223 [('socket', 1.0), ('Lock', 0.9812576379586568), ('Error', 0.9784150400417247), ('Invalid', 0.9489034405094396), ('lock', 0.942819332840129)]
Top words for pretrained_BERT neuron indx 7371 [('interval', 1.0), ('TAG', 0.9739029524956974), ('five', 0.9109947130703344), ('one', 0.9066979891110304), ('ELEMENT', 0.8904348441564577)]
Top words for pretrained_BERT neuron indx 9420 [('REAGGREGATING', 1.0), ('acquire', 0.9181058792238864), ('28', 0.9140776267610133), ('CommitsList', 0.9110881166498405), ('ur', 0.8795827577615855)]
Top words for pretrained_BERT neuron indx 1229 [('USAGE', 1.0), ('macAddress', 0.9654165464562955), ('GetMirror', 0.9057235273296707), ('RELATION', 0.8967894523778885), ('macAdress', 0.8417225638286153)]
Top words for pretrained_BERT neuron indx 3284 [('75', 1.0), ('wait', 0.9850963874571889), ('repeat', 0.9422477502107448), ('principal', 0.9058967927177094), ('future', 0.8856860804062119)]
Top words for pretrained_BERT neuron indx 7385 [('ip', 1.0), ('Int', 0.8983983749464474), ('discovery', 0.8120295941076054), ('Failure', 0.7209066320948077), ('reflection', 0.7152623712385443)]
Top words for pretrained_BERT neuron indx 5345 [('libraries', 1.0), ('201', 0.9762628958476633), ('750', 0.9302058744493155), ('functions', 0.9155297794729734), ('187', 0.9078005834288735)]
Top words for pretrained_BERT neuron indx 7402 [('302', 1.0), ('300', 0.9454212861672338), ('strict', 0.9316312225550303), ('five', 0.8950757034021141), ('1800', 0.8836641521797123)]
Top words for pretrained_BERT neuron indx 9451 [('services', 1.0), ('discovery', 0.9829062172501628), ('set_tz', 0.9781394140839286), ('bv', 0.9589970410889495), ('tornado', 0.9206561904659413)]
Top words for pretrained_BERT neuron indx 9455 [('"http://"', 1.0), ('sim', 0.9166351751941348), ('"://"', 0.8576365911070899), ('If', 0.831353746825205), ('"Text"', 0.8006303929513573)]
Top words for pretrained_BERT neuron indx 7409 [('74.616338', 1.0), ('each', 0.951833428451199), ('services', 0.8788754571929231), ('MEMBASE', 0.8689496885765673), ('"--mem"', 0.8386174548875348)]
Top words for pretrained_BERT neuron indx 3328 [('PRIORITY', 1.0), ('tell', 0.8706370292641642), ('Off', 0.8517104924464494), ('initial', 0.7967310169846834), ('interval', 0.7930106933695795)]
Top words for pretrained_BERT neuron indx 9476 [('mesh', 1.0), ('alt', 0.9153131118247343), ('sim', 0.911534332101049), ('Mesh', 0.8576202665032977), ('sid', 0.7681723849548733)]
Top words for pretrained_BERT neuron indx 9477 [('oslo', 1.0), ('81.4471435546875', 0.9403538113948214), ('Int', 0.9348950955594979), ('"error"', 0.8547428780758688), ('ContextTask', 0.8470240136809256)]
Top words for pretrained_BERT neuron indx 1285 [('symmetric', 1.0), ('stretch_particles', 0.8439155608837042), ('nh', 0.8315222230120775), ('FQDN', 0.826531392438159), ('expand', 0.8034524522915294)]
Top words for pretrained_BERT neuron indx 3334 [('select', 1.0), ('Assign', 0.961264309719909), ('Asset', 0.9609983980520086), ('62', 0.9241570455663518), ('props', 0.9217519691083427)]
Top words for pretrained_BERT neuron indx 9478 [('Clock', 1.0), ('calendar', 0.9595881698682927), ('clock', 0.9260759473545941), ('utc', 0.8587492900823936), ('timegm', 0.8057078463277005)]
Top words for pretrained_BERT neuron indx 9482 [('interval', 1.0), ('Integer', 0.7895662535777578), ('If', 0.769119243017468), ('day', 0.7679528567903516), ('polygon', 0.7526840665749478)]
Top words for pretrained_BERT neuron indx 3344 [('web', 1.0), ('ep', 0.9273082272381242), ('alt', 0.8795347711035476), ('urandom', 0.8672104677862451), ('license', 0.8540810451193702)]
Top words for pretrained_BERT neuron indx 5392 [('ALPHABET', 1.0), ('62', 0.9746842672049684), ('If', 0.8686703151636871), ('severity', 0.8313780429836565), ('reverse', 0.7753957319582848)]
Top words for pretrained_BERT neuron indx 3362 [('functional', 1.0), ('frame', 0.9372998195337168), ('Frame', 0.8633361293804553), ('Wire', 0.8525037087938436), ('Cat', 0.8360596401314838)]
Top words for pretrained_BERT neuron indx 9513 [('62', 1.0), ('Mesh', 0.8682583606381165), ('mesh1', 0.8511234230422062), ('polygon', 0.8220651206800014), ('orgs', 0.8118848515708558)]
Top words for pretrained_BERT neuron indx 5418 [('baseline', 1.0), ('advance', 0.9717293070130375), ('decorators', 0.9558177795734042), ('listen', 0.9288868584144498), ('buffer', 0.9109499989819551)]
Top words for pretrained_BERT neuron indx 7467 [('Invalid', 1.0), ('MEMBER', 0.9935949898928542), ('Module', 0.9843456170458765), ('advertiser', 0.9656015396940976), ('ADVERTISE', 0.9100630407893002)]
Top words for pretrained_BERT neuron indx 5424 [('scheme', 1.0), ('break', 0.9120435197523817), ('PIECE', 0.8927549385555985), ('edit', 0.8490656323665543), ('flat', 0.8084280559278039)]
Top words for pretrained_BERT neuron indx 7473 [('discovery', 1.0), ('ts', 0.8668642927009454), ('basicString', 0.7654819813807621), ('hour', 0.7616188930704108), ('sdi', 0.7569783496937957)]
Top words for pretrained_BERT neuron indx 9520 [('sans', 1.0), ('Cat', 0.9935868874911016), ('el', 0.8907798482672813), ('opener', 0.8789816157619988), ('abc', 0.8760587748453929)]
Top words for pretrained_BERT neuron indx 1331 [('sd', 1.0), ('fifteen', 0.985951119951786), ('zone', 0.9688390327096978), ('password', 0.9500220766826425), ('25', 0.9490558704096042)]
Top words for pretrained_BERT neuron indx 5430 [('installed', 1.0), ('sha', 0.9177581983839764), ('TAG', 0.8721978438714034), ('LAT', 0.856836814572207), ('ri', 0.8231479028349066)]
Top words for pretrained_BERT neuron indx 3384 [('single', 1.0), ('application', 0.9919685828265474), ('organization', 0.9239135224393457), ('number', 0.9091225595117177), ('Simple', 0.8281873056144675)]
Top words for pretrained_BERT neuron indx 9529 [('.3', 1.0), ('On', 0.9991013765131646), ('ON', 0.9991013765131646), ('View', 0.9924461606133088), ('flags', 0.988405293887387)]
Top words for pretrained_BERT neuron indx 5440 [('behind', 1.0), ('512', 0.9691014603549485), ('Distance', 0.9658049330692051), ('CONNECTED', 0.9151300633193632), ('encoding', 0.8937892110031858)]
Top words for pretrained_BERT neuron indx 1353 [('fragment', 1.0), ('ct', 0.8115362146860652), ('Integer', 0.6987605947401073), ('pattern', 0.6727454356065804), ('define', 0.6700987742567907)]
Top words for pretrained_BERT neuron indx 7498 [('TRANSITIVE', 1.0), ('except', 0.9500771687888158), ('aspect', 0.9242508127919964), ('destroy', 0.9110006885737472), ('future', 0.9070493652168581)]
Top words for pretrained_BERT neuron indx 3411 [('CANCEL', 1.0), ('scheme', 0.9546528882530108), ('zope', 0.8478438639966877), ('secret', 0.8382556142263552), ('75', 0.7914943804815349)]
Top words for pretrained_BERT neuron indx 5462 [('Geo', 1.0), ('TERMINATE', 0.7911179519374812), ('minutes', 0.7782311952742001), ('sim', 0.7638202054290995), ('strings', 0.7608830750478079)]
Top words for pretrained_BERT neuron indx 7512 [('750', 1.0), ('1800', 0.9302940844700157), ('800', 0.8993169426101402), ('200', 0.8885991690432137), ('8000', 0.8623171668448221)]
Top words for pretrained_BERT neuron indx 9561 [('fabric', 1.0), ('addheaders', 0.9713712659691838), ('Truefrom', 0.920298477842271), ('pk', 0.9127999498061333), ('constlist', 0.903661426047736)]
Top words for pretrained_BERT neuron indx 3417 [('quota', 1.0), ('day', 0.939780656749273), ('YoungestInFront', 0.9300804257642736), ('tasa', 0.9276673238731863), ('Integer', 0.8996297116017814)]
Top words for pretrained_BERT neuron indx 3428 [('MEMBER', 1.0), ('TAG', 0.9998747679856506), ('store', 0.9898093971608963), ('Tag', 0.9749657475745527), ('def', 0.9545570239147356)]
Top words for pretrained_BERT neuron indx 9572 [('strings', 1.0), ('redistricting', 0.9229699241919367), ('chunks', 0.9129442237476583), ('requests', 0.8879759289904328), ('ScoreFunction', 0.8591097200902711)]
Top words for pretrained_BERT neuron indx 7529 [('187', 1.0), ('201', 0.9924148945592018), ('cancel', 0.9205714870233791), ('Allow', 0.8912195778489953), ('other', 0.8668404363061498)]
Top words for pretrained_BERT neuron indx 7531 [('RELATION', 1.0), ('collect', 0.9912780677347881), ('Label', 0.8581794981482201), ('checkreport', 0.8439489122908382), ('resolve', 0.8285645941109714)]
Top words for pretrained_BERT neuron indx 5486 [('69', 1.0), ('117', 0.833670422690504), ('63', 0.7608802465698468), ('organization', 0.7596972449905656), ('platforms', 0.7596656037750796)]
Top words for pretrained_BERT neuron indx 7536 [('62', 1.0), ('video', 0.9670933712635953), ('Recording', 0.9501054203060351), ('purpose', 0.9323530704145585), ('Video', 0.9162294759146634)]
Top words for pretrained_BERT neuron indx 3441 [('bare', 1.0), ('number', 0.906907009284599), ('TYPE', 0.7852805334837742), ('ERROR', 0.7690074492159631), ('SCALE_FACTOR', 0.7416720112620856)]
Top words for pretrained_BERT neuron indx 9586 [('Label', 1.0), ('secret', 0.9340865061435055), ('sr', 0.9226383165509465), ('28', 0.9169949622308897), ('89.999999999999992', 0.9025652597079745)]
Top words for pretrained_BERT neuron indx 9592 [('oslo', 1.0), ('80', 0.9098572307972874), ('GEODOC', 0.8687963534086325), ('other', 0.86863799664555), ('Action', 0.8608182630845731)]
Top words for pretrained_BERT neuron indx 3449 [('CREATING', 1.0), ('video', 0.707403483602715), ('Presence', 0.6641283931693971), ('INFO', 0.6583757614571144), ('opcode', 0.6468776418357873)]
Top words for pretrained_BERT neuron indx 9596 [('69', 1.0), ('tv', 0.8690727909700168), ('42', 0.799192581696348), ('25', 0.7710615173031597), ('443', 0.7214751169345729)]
Top words for pretrained_BERT neuron indx 3454 [('success', 1.0), ('SUCCESS', 0.96539219110612), ('wait', 0.941655054622662), ('Board', 0.8344766806084883), ('remember', 0.8256264700810866)]
Top words for pretrained_BERT neuron indx 9606 [('fifteen', 1.0), ('42', 0.9888503322681143), ('"0"', 0.9670088849964567), ('API', 0.9470686865715546), ('"0.1.9"', 0.8725888833919426)]
Top words for pretrained_BERT neuron indx 5516 [('minutes', 1.0), ('compute', 0.8980832862001648), ('MANIFEST', 0.7096311695021201), ('texture', 0.7061876018041833), ('districts', 0.6813478478703894)]
Top words for pretrained_BERT neuron indx 1421 [('ps', 1.0), ('nh', 0.988200820464923), ('ping', 0.9312079250897347), ('TRANSITIVE', 0.9263381338148503), ('ex', 0.9143424596695546)]
Top words for pretrained_BERT neuron indx 3475 [('sid', 1.0), ('principal', 0.8389766927518452), ('plural', 0.8329498798650368), ('decimal', 0.8064033678126005), ('oslo', 0.8014885958404582)]
Top words for pretrained_BERT neuron indx 5523 [('Parameter', 1.0), ('exists', 0.9754308472227443), ('calendar', 0.936432062893461), ('hour', 0.8850698865670621), ('23', 0.8804388580584571)]
Top words for pretrained_BERT neuron indx 7579 [('"warning"', 1.0), ('"x"', 0.943184935295028), ('"shared"', 0.9308279859718803), ('"display"', 0.8929278497817882), ('36', 0.853981804684291)]
Top words for pretrained_BERT neuron indx 1437 [('principal', 1.0), ('Address', 0.8971183079642715), ('address', 0.8259874848470454), ('CONNECTED', 0.8224118987890204), ('stamp', 0.8116807768273837)]
Top words for pretrained_BERT neuron indx 1439 [('feed', 1.0), ('quality', 0.8511007186521542), ('bare', 0.8375656291225334), ('principal', 0.7776949191134392), ('answer', 0.7705364742445006)]
Top words for pretrained_BERT neuron indx 7586 [('materials', 1.0), ('implementation', 0.9836771895590442), ('enclosure', 0.9653542630625165), ('scenario', 0.948128473649292), ('sublime', 0.9382186000974709)]
Top words for pretrained_BERT neuron indx 1443 [('props', 1.0), ('branches', 0.9757327318424757), ('stamp', 0.9277847661082061), ('branch', 0.9044528711054906), ('Gallery', 0.8944235201923055)]
Top words for pretrained_BERT neuron indx 9635 [('oslo', 1.0), ('tenant', 0.834193579532099), ('up', 0.7916347148271623), ('calculators', 0.7714818060421127), ('zope', 0.7317656566387063)]
Top words for pretrained_BERT neuron indx 3494 [('18', 1.0), ('23', 0.9672934860095095), ('reactor', 0.9108989161937724), ('36', 0.9028476447117997), ('14', 0.9025634713048591)]
Top words for pretrained_BERT neuron indx 5543 [('created', 1.0), ('installed', 0.9161322240119956), ('closing', 0.8473714128395538), ('Else', 0.8386481982926692), ('reddit', 0.8278039087995219)]
Top words for pretrained_BERT neuron indx 5546 [('severity', 1.0), ('blank', 0.9144490677168314), ('42', 0.9142158428100445), ('ROLE', 0.9078600737534299), ('topology', 0.8699437065742222)]
Top words for pretrained_BERT neuron indx 3499 [('OK', 1.0), ('nsa', 0.9547886404146048), ('repeat', 0.8199923039061566), ('discovery', 0.7870858718356097), ('execute', 0.755851871550396)]
Top words for pretrained_BERT neuron indx 7596 [('runner', 1.0), ('Int', 0.9784168262256996), ('Reg', 0.9170285515303065), ('license', 0.8552204938913152), ('next', 0.8548028065514355)]
Top words for pretrained_BERT neuron indx 9651 [('33', 1.0), ('ex', 0.9317568836877257), ('splits', 0.8566067089380938), ('secret', 0.8204144711354455), ('mail', 0.7903631507891538)]
Top words for pretrained_BERT neuron indx 1463 [('PATHS', 1.0), ('texture', 0.9799400347880252), ('Document', 0.8547283589430711), ('Reg', 0.8406714337944837), ('policy', 0.8341635881176279)]
Top words for pretrained_BERT neuron indx 9659 [('999999', 1.0), ('21', 0.9066747701384269), ('Geo', 0.8611250117072081), ('"eu-west-1"', 0.8334482531529404), ('"us-east-1"', 0.7686732985944551)]
Top words for pretrained_BERT neuron indx 7617 [('material', 1.0), ('csrf', 0.8613559971387525), ('Util', 0.8607857727196827), ('lat__gt', 0.8419499083553874), ('23', 0.8384014999982783)]
Top words for pretrained_BERT neuron indx 3522 [('sans', 1.0), ('notes', 0.976619561695476), ('BOUNDS', 0.9131455776263304), ('ignore', 0.8853499392311783), ('texture', 0.8614192529905502)]
Top words for pretrained_BERT neuron indx 7620 [('Label', 1.0), ('None', 0.8863804292597828), ('prop', 0.8544260151324258), ('visitor', 0.8415964536857843), ('117', 0.7897635845883498)]
Top words for pretrained_BERT neuron indx 9675 [('submit', 1.0), ('Geo', 0.9853127556809468), ('five', 0.9653629962326145), ('"SUCCEEDED"', 0.954854585191995), ('qset', 0.9088213050615551)]
Top words for pretrained_BERT neuron indx 9680 [('fifteen', 1.0), ('Criteria', 0.9961164112318788), ('tornado', 0.9411424251065985), ('five', 0.8719412945883889), ('simulation', 0.8100330306139549)]
Top words for pretrained_BERT neuron indx 1490 [('tries', 1.0), ('try', 0.9879905622802566), ('stamp', 0.9538920160635717), ('checkout', 0.8361860901502274), ('stanza', 0.8165808968969515)]
Top words for pretrained_BERT neuron indx 5588 [('75', 1.0), ('750', 0.9675312673474917), ('repeat', 0.9517551982853194), ('wait', 0.9137167262211027), ('principal', 0.9133552091441515)]
Top words for pretrained_BERT neuron indx 9685 [('IntType', 1.0), ('187', 0.9547206809973946), ('Int', 0.9419676280083753), ('Provider', 0.9053627596054502), ('day', 0.8837172359643085)]
Top words for pretrained_BERT neuron indx 9690 [('purpose', 1.0), ('Basic', 0.9403799232048587), ('authentication', 0.9289107059519969), ('receiver', 0.899484052973565), ('except', 0.8409451501654129)]
Top words for pretrained_BERT neuron indx 5594 [('MAXIMUM', 1.0), ('apache', 0.8946548843928658), ('command', 0.871274955815157), ('INCOMPLETE', 0.8496499828630725), ('gis', 0.8219395250728253)]
Top words for pretrained_BERT neuron indx 5595 [('ip', 1.0), ('bare', 0.994981499223198), ('manager', 0.9829536228843468), ('raise', 0.9111414696842364), ('controlflow', 0.8972855359710564)]
Top words for pretrained_BERT neuron indx 7649 [('horizon', 1.0), ('201', 0.9617537135171524), ('443', 0.9595734221455786), ('1800', 0.9472127732241751), ('465', 0.8558328501422897)]
Top words for pretrained_BERT neuron indx 9707 [('decimal', 1.0), ('ALPHABET', 0.9949186551526086), ('scheme', 0.9330812213112714), ('internet', 0.9161881178534586), ('SIGINT', 0.9125948366906491)]
Top words for pretrained_BERT neuron indx 5611 [('REFERENCES', 1.0), ('Invalid', 0.8634707556204667), ('success', 0.8452744959627297), ('BOUNDS', 0.8262460176968804), ('setLevel', 0.8158590973692765)]
Top words for pretrained_BERT neuron indx 3579 [('If', 1.0), ('if', 0.9651739750753808), ('Signature', 0.7889845373028543), ('functions', 0.7772194672981209), ('TYPE', 0.7562873144135398)]
Top words for pretrained_BERT neuron indx 7693 [('Region', 1.0), ('fetchall', 0.8213165416373648), ('Job', 0.7904358027679366), ('except', 0.7779772659373847), ('tries', 0.7484599618313881)]
Top words for pretrained_BERT neuron indx 9741 [('decimal', 1.0), ('srid', 0.9356583566556408), ('try', 0.9258974713185497), ('ID', 0.9256430079665767), ('reflection', 0.8411586725328491)]
Top words for pretrained_BERT neuron indx 1551 [('sock', 1.0), ('remember', 0.9465056574070623), ('dom', 0.881269422208135), ('linkDown', 0.8335671069157762), ('ajax', 0.8300293095858575)]
Top words for pretrained_BERT neuron indx 7695 [('Plugin', 1.0), ('venue', 0.9914179251713048), ('do', 0.8330629941253024), ('Card', 0.8128813695391506), ('PlugIn', 0.8125337536852495)]
Top words for pretrained_BERT neuron indx 9751 [('package', 1.0), ('Criteria', 0.9355375407096298), ('sim', 0.8914343019827319), ('medium', 0.8842539938967776), ('capitalize', 0.8514772512668579)]
Top words for pretrained_BERT neuron indx 9760 [('opener', 1.0), ('broker', 0.9939326027996684), ('bandwidth', 0.8419135076079596), ('twisted', 0.8367924217354837), ('Parameter', 0.8075158277966726)]
Top words for pretrained_BERT neuron indx 5666 [('"KILLED"', 1.0), ('principal', 0.9460580638616845), ('functional', 0.878156639492725), ('Delay', 0.876000092818039), ('signed', 0.875504374804414)]
Top words for pretrained_BERT neuron indx 9768 [('backwards', 1.0), ('unicode', 0.9810192973759234), ('auditor', 0.9756877272130413), ('200', 0.9406760396504789), ('ready', 0.867439879245624)]
Top words for pretrained_BERT neuron indx 7722 [('decorators', 1.0), ('baseline', 0.9484675450514515), ('Widget', 0.87889586658125), ('ntime', 0.8737605875473233), ('decorator', 0.8671627803837713)]
Top words for pretrained_BERT neuron indx 3627 [('clean', 1.0), ('Update', 0.9417272929892044), ('audit', 0.8440314885641813), ('Invalid', 0.8308204189019317), ('VERSION', 0.8242062085323333)]
Top words for pretrained_BERT neuron indx 1578 [('revision', 1.0), ('unicode', 0.9876549407530155), ('buffer', 0.9270388050746793), ('Bytes', 0.9228846725141039), ('spawn', 0.8969305355002641)]
Top words for pretrained_BERT neuron indx 7723 [('bare', 1.0), ('terminate', 0.9956438483178944), ('parameter', 0.9695449539481803), ('selection', 0.9134945853164841), ('lat__gt', 0.8982969353336169)]
Top words for pretrained_BERT neuron indx 7728 [('nexthop', 1.0), ('flat', 0.9347473616623585), ('created', 0.910092194911826), ('512', 0.8533982690551742), ('ex', 0.8402467465008984)]
Top words for pretrained_BERT neuron indx 5687 [('minutes', 1.0), ('"shared"', 0.9037680073986105), ('"daytime"', 0.8818330118322588), ('"KILLED"', 0.870612061283005), ('created', 0.8696316275055493)]
Top words for pretrained_BERT neuron indx 1600 [('512', 1.0), ('fifteen', 0.8938873933678592), ('synchronized', 0.8602827104210292), ('upgrade', 0.8467008914552735), ('authorized', 0.8204449554706241)]
Top words for pretrained_BERT neuron indx 7744 [('512', 1.0), ('behind', 0.8889106201872249), ('fifteen', 0.857382490861426), ('Tab', 0.8495769882002944), ('31', 0.8303351601690043)]
Top words for pretrained_BERT neuron indx 3651 [('ax', 1.0), ('current', 0.8899951543499484), ('targets', 0.8793924810676069), ('processes', 0.7737923342763987), ('bodies', 0.7626842064454913)]
Top words for pretrained_BERT neuron indx 1609 [('42', 1.0), ('Always', 0.7667837137966983), ('75', 0.7452448493627273), ('400', 0.7283206239339456), ('exception', 0.7104831970434456)]
Top words for pretrained_BERT neuron indx 3657 [('fragment', 1.0), ('pattern', 0.8420247440663594), ('bare', 0.7271583894088542), ('ct', 0.699431546944428), ('fin', 0.6497272005725742)]
Top words for pretrained_BERT neuron indx 9809 [('services', 1.0), ('quota', 0.6805057971056079), ('width', 0.6648221848848082), ('actions', 0.6361432969645562), ('Column', 0.6246744945032577)]
Top words for pretrained_BERT neuron indx 5715 [('CANCEL', 1.0), ('zope', 0.9747737315408284), ('204', 0.9467511613369762), ('five', 0.9368064330483222), ('initial', 0.9068213579123027)]
Top words for pretrained_BERT neuron indx 7763 [('translation', 1.0), ('Presence', 0.9759035367021813), ('Location', 0.9548045783990036), ('period', 0.9436332750460019), ('presence', 0.9245336233519744)]
Top words for pretrained_BERT neuron indx 9816 [('8000', 1.0), ('Geolevel', 0.9928799046272964), ('CREATING', 0.9882073141622028), ('20000', 0.9738127233532214), ('SocketLevelTest', 0.9645704262400715)]
Top words for pretrained_BERT neuron indx 1638 [('District', 1.0), ('district', 0.9094705744419916), ('send', 0.9004958107718765), ('password', 0.8846786503554859), ('sha', 0.8527881751586275)]
Top words for pretrained_BERT neuron indx 9833 [('instances', 1.0), ('302', 0.9873813935008694), ('processors', 0.9676832700677181), ('NODES', 0.9622762113217342), ('handle', 0.9478628808066859)]
Top words for pretrained_BERT neuron indx 3689 [('NODES', 1.0), ('201', 0.967402244711681), ('CANCEL', 0.8896084428207898), ('processors', 0.8886379808879628), ('Allow', 0.869554128419661)]
Top words for pretrained_BERT neuron indx 1643 [('200', 1.0), ('500', 0.91670264215805), ('activity', 0.8105969099827565), ('nsa', 0.7880295785765299), ('agency', 0.7874052040252723)]
Top words for pretrained_BERT neuron indx 1651 [('payload', 1.0), ('engine', 0.9369059985959187), ('plans', 0.9160633590422356), ('strategy', 0.8904158370530157), ('synchronized', 0.882427136496948)]
Top words for pretrained_BERT neuron indx 5747 [('tell', 1.0), ('identical', 0.8669039543427157), ('digest', 0.8493013629210431), ('blend', 0.8312711583327304), ('five', 0.8281768015188953)]
Top words for pretrained_BERT neuron indx 5753 [('CANCEL', 1.0), ('CREATING', 0.9254095148284961), ('each', 0.9097599928642703), ('INFO', 0.8785984393370745), ('SON', 0.8380453564820044)]
Top words for pretrained_BERT neuron indx 7803 [('"include"', 1.0), ('"file"', 0.8545609475999342), ('"multiple"', 0.8322968193717487), ('mins', 0.8318021297359632), ('"queue"', 0.8303898859104246)]
Top words for pretrained_BERT neuron indx 7805 [('tell', 1.0), ('with', 0.98534667242446), ('File', 0.9487217131473009), ('old', 0.8814929680498815), ('ADVERTISE', 0.8270118120799308)]
Top words for pretrained_BERT neuron indx 5758 [('SUCCESS', 1.0), ('calendar', 0.927480910587499), ('Criteria', 0.9253249327993033), ('collect', 0.8852619833569576), ('negotiate', 0.8785722332853283)]
Top words for pretrained_BERT neuron indx 1669 [('1970', 1.0), ('advance', 0.9296751446235098), ('requires', 0.9128154051868215), ('REQUIRES', 0.7946797219644889), ('enable', 0.7867018591906919)]
Top words for pretrained_BERT neuron indx 5766 [('"FAILED"', 1.0), ('"-D"', 0.9872083503202106), ('"pv"', 0.9512704544178814), ('"-t"', 0.9483417416046064), ('"cards"', 0.9431052361923244)]
Top words for pretrained_BERT neuron indx 9863 [('dom', 1.0), ('implementation', 0.8745255957381195), ('affinity', 0.7721015590931842), ('year', 0.7559805914182377), ('capacity', 0.7376129639732614)]
Top words for pretrained_BERT neuron indx 9864 [('IntType', 1.0), ('14', 0.9721265403375944), ('sr', 0.9575470865979889), ('2014', 0.9493499995330263), ('LongType', 0.9397849123000248)]
Top words for pretrained_BERT neuron indx 7820 [('minutes', 1.0), ('25', 0.9871056849293193), ('compute', 0.9704878381747696), ('75', 0.9497409096943282), ('completed', 0.9216288120944218)]
Top words for pretrained_BERT neuron indx 3727 [('Always', 1.0), ('tenant', 0.8879752719944821), ('fifteen', 0.8448170638731043), ('appstruct', 0.8186549001226601), ('month', 0.8160644875548347)]
Top words for pretrained_BERT neuron indx 9875 [('OK', 1.0), ('extent', 0.9535440247647029), ('fabric', 0.907471820242587), ('remote', 0.8504334986569805), ('"-I"', 0.8196103631816295)]
Top words for pretrained_BERT neuron indx 3732 [('WITHDRAW', 1.0), ('Video', 0.8041166530873408), ('month', 0.7793612628781853), ('principal', 0.7457158490766862), ('video', 0.7320824572089036)]
Top words for pretrained_BERT neuron indx 5779 [('oslo', 1.0), ('sid', 0.7527352657180458), ('28', 0.7480553776423035), ('Else', 0.7476444409623237), ('decimal', 0.7235196145836786)]
Top words for pretrained_BERT neuron indx 9878 [('remember', 1.0), ('Account', 0.9999813978705033), ('medium', 0.9729194635992335), ('flat', 0.9253053505424534), ('domain', 0.9213765302263107)]
Top words for pretrained_BERT neuron indx 3731 [('Document', 1.0), ('200', 0.9397168186478164), ('300', 0.8982178586910388), ('1800', 0.8884497158518799), ('400', 0.8685490915718482)]
Top words for pretrained_BERT neuron indx 1689 [('video', 1.0), ('cb', 0.9904814803796302), ('translation', 0.9887410209338998), ('communities', 0.9559251449414002), ('responses', 0.9551566556389003)]
Top words for pretrained_BERT neuron indx 9881 [('187', 1.0), ('TERMINATE', 0.8669780413248906), ('Job', 0.8410784885570978), ('terminate', 0.8249488852959562), ('Auditor', 0.7850937197476765)]
Top words for pretrained_BERT neuron indx 3741 [('video', 1.0), ('principal', 0.950582928765482), ('Core', 0.9487857868434195), ('channel', 0.9358543487788222), ('Entity', 0.8742965388923052)]
Top words for pretrained_BERT neuron indx 9890 [('Int', 1.0), ('WAY', 0.7948837357410392), ('materials', 0.7763341403859915), ('purpose', 0.7698893699564123), ('decimal', 0.7668839904869141)]
Top words for pretrained_BERT neuron indx 5794 [('outgoing', 1.0), ('Wire', 0.8736014744712848), ('forwards', 0.8168024079142752), ('35', 0.7439914838798434), ('3785', 0.7435198316009364)]
Top words for pretrained_BERT neuron indx 5798 [('302', 1.0), ('36', 0.9937673803367414), ('18', 0.947350355689954), ('119', 0.9402794028629223), ('35', 0.937007610211602)]
Top words for pretrained_BERT neuron indx 7850 [('score', 1.0), ('missing', 0.9888751479068059), ('minutes', 0.9706657024954717), ('blank', 0.9480470755617074), ('upstream', 0.9246269060155876)]
Top words for pretrained_BERT neuron indx 3756 [('while', 1.0), ('Int', 0.9902547565683565), ('Reg', 0.9792335292772814), ('runner', 0.9606180735621805), ('month', 0.9122712695924474)]
Top words for pretrained_BERT neuron indx 1709 [('imports', 1.0), ('Integer', 0.9797460435438803), ('204', 0.9659203343991062), ('us', 0.958745618904547), ('3142', 0.9289984103693547)]
Top words for pretrained_BERT neuron indx 9902 [('AREA', 1.0), ('pa', 0.8981111257156728), ('milliseconds', 0.8849371707251856), ('Distance', 0.8845345399205674), ('GEOSGeometry', 0.8411926089297613)]
Top words for pretrained_BERT neuron indx 5811 [('ah', 1.0), ('splits', 0.9982278647406668), ('nh', 0.9920465592415848), ('ex', 0.9328362682429033), ('discovery', 0.931892585976913)]
Top words for pretrained_BERT neuron indx 3767 [('long', 1.0), ('policy', 0.8725018091350718), ('ll', 0.8708005194598247), ('META', 0.8313359030362143), ('zone', 0.8081172354817624)]
Top words for pretrained_BERT neuron indx 7864 [('branch', 1.0), ('cb', 0.8873135674553931), ('spawn', 0.8542529102958826), ('GEODOC', 0.8250424136329365), ('geos', 0.8211420114947998)]
Top words for pretrained_BERT neuron indx 9915 [('fifteen', 1.0), ('35', 0.8752649382683013), ('tell', 0.8740810292000734), ('8000', 0.8183373977533077), ('1800', 0.8140367009843543)]
Top words for pretrained_BERT neuron indx 5822 [('available', 1.0), ('choice', 0.8488739101165518), ('READY', 0.8333292293368179), ('200', 0.8233103318214343), ('simulation', 0.8138346429876939)]
Top words for pretrained_BERT neuron indx 9920 [('62', 1.0), ('HTTPForbidden', 0.9611489149121915), ('implementation', 0.9525942783112875), ('operations', 0.8904096691138298), ('operation', 0.8877160251477472)]
Top words for pretrained_BERT neuron indx 5826 [('ignore', 1.0), ('Default', 0.9778483975595894), ('tell', 0.9606183085444377), ('75', 0.9227140828536875), ('"FAILED"', 0.9044152228588115)]
Top words for pretrained_BERT neuron indx 7876 [('strict', 1.0), ('bandwidth', 0.9913454719003162), ('40', 0.9455166244179034), ('capacity', 0.8746713176148221), ('quality', 0.8163829771982125)]
Top words for pretrained_BERT neuron indx 7884 [('AFI', 1.0), ('def', 0.9918649918357867), ('acquire', 0.9414621507914949), ('redistricting', 0.9105804378124502), ('"KILLED"', 0.9072485947023309)]
Top words for pretrained_BERT neuron indx 1743 [('deploy', 1.0), ('tell', 0.9643655842781825), ('active', 0.9553281475610103), ('400', 0.943909921370519), ('200', 0.9395705899591337)]
Top words for pretrained_BERT neuron indx 9936 [('openstack', 1.0), ('VALUE', 0.9610646968993561), ('contenttypes', 0.8174023179513027), ('reddit', 0.7921011153139091), ('afi', 0.7841295350538537)]
Top words for pretrained_BERT neuron indx 7892 [('notes', 1.0), ('principal', 0.994980850111697), ('TERMINATE', 0.941151169908661), ('repeat', 0.9006442313114362), ('VRF', 0.8734115547800739)]
Top words for pretrained_BERT neuron indx 9941 [('horizon', 1.0), ('63', 0.9549035294136651), ('Clock', 0.9084589838305037), ('secret', 0.866013231582579), ('providers', 0.8590678420475286)]
Top words for pretrained_BERT neuron indx 1748 [('repeat', 1.0), ('wait', 0.9479893792940554), ('principal', 0.9128069435261875), ('stat', 0.8012188766348142), ('75', 0.7796773088729827)]
Top words for pretrained_BERT neuron indx 1752 [('medium', 1.0), ('"2:00:00:00"', 0.9711766315528506), ('Core', 0.8563243421582543), ('75', 0.8374541177262677), ('long', 0.808537567021284)]
Top words for pretrained_BERT neuron indx 7898 [('STP', 1.0), ('Region', 0.8216916196505957), ('qdict', 0.8215316698967059), ('MAIL_USERNAME', 0.7658529505421371), ('rjust', 0.7483131812362516)]
Top words for pretrained_BERT neuron indx 3809 [('negotiate', 1.0), ('functions', 0.9151597337541935), ('detect', 0.8950869408557123), ('15000', 0.8929426239617765), ('acquire', 0.892289625788983)]
Top words for pretrained_BERT neuron indx 1775 [('within', 1.0), ('members', 0.921428496782594), ('communities', 0.7735611209740799), ('hostname', 0.7484992287046223), ('medium', 0.739288771607828)]
Top words for pretrained_BERT neuron indx 5883 [('processes', 1.0), ('Simple', 0.965436661593662), ('CONNECTED', 0.9366766370325997), ('functions', 0.9011006557031197), ('activity', 0.8887374189721716)]
Top words for pretrained_BERT neuron indx 7935 [('Mesh', 1.0), ('spawn', 0.958192190898659), ('mesh', 0.919697712903304), ('se', 0.9074516249268666), ('LoggedIn', 0.8828752312020969)]
Top words for pretrained_BERT neuron indx 7941 [('recordings', 1.0), ('Int', 0.9778992482312738), ('"--version"', 0.9468656296959167), ('"--include"', 0.9075214547010046), ('"--top"', 0.9008805195864357)]
Top words for pretrained_BERT neuron indx 1800 [('clean', 1.0), ('sets', 0.952911473468401), ('File', 0.9453571189731432), ('Distance', 0.9415345196142362), ('sans', 0.8928371197176438)]
Top words for pretrained_BERT neuron indx 3855 [('linkDown', 1.0), ('break', 0.9185846417724659), ('simulation', 0.9160530826565878), ('GET', 0.9021373003189443), ('GA_DOMAIN', 0.8626648347971708)]
Top words for pretrained_BERT neuron indx 1808 [('web', 1.0), ('license', 0.9620459368307988), ('repository', 0.7952074893339809), ('transaction', 0.7779817325068292), ('broker', 0.7715977556039618)]
Top words for pretrained_BERT neuron indx 5911 [('Http404', 1.0), ('cover', 0.9475230637242158), ('15598', 0.9310420425235914), ('15597', 0.8960516289233127), ('0x00000001', 0.868075421021655)]
Top words for pretrained_BERT neuron indx 1821 [('Instance', 1.0), ('wait', 0.9873982466396032), ('pisa', 0.9730888392721879), ('Basic', 0.9570105446783829), ('hour', 0.9278581353888649)]
Top words for pretrained_BERT neuron indx 7970 [('"define"', 1.0), ('"KILLED"', 0.9952595174839848), ('"include"', 0.9840784253666249), ('visit', 0.9445842346194162), ('millis', 0.9275011287533985)]
Top words for pretrained_BERT neuron indx 3877 [('plural', 1.0), ('resolve', 0.6513420696735147), ('Server', 0.6385457676539603), ('GENERATOR', 0.6369197085838866), ('branches', 0.6305716956420321)]
Top words for pretrained_BERT neuron indx 3882 [('advance', 1.0), ('resolve', 0.9561420803414329), ('Bytes', 0.9214046662049724), ('forwards', 0.9177306621336683), ('unicode', 0.9010779263741204)]
Top words for pretrained_BERT neuron indx 5931 [('MEMBER', 1.0), ('Module', 0.9633763603641327), ('Invalid', 0.9561620375509678), ('functional', 0.9386400068561029), ('ADVERTISE', 0.8736674456472662)]
Top words for pretrained_BERT neuron indx 7986 [('next', 1.0), ('and', 0.8914313593099438), ('answer', 0.8409111500792873), ('Item', 0.8288002048886552), ('else', 0.8153109236573269)]
Top words for pretrained_BERT neuron indx 1844 [('and', 1.0), ('in', 0.907933708790136), ('to', 0.8531923830407232), ('is', 0.8480226399220433), ('".."', 0.846639740618333)]
Top words for pretrained_BERT neuron indx 3894 [('TAG', 1.0), ('installed', 0.9899694919842705), ('seek', 0.9812539600453358), ('sha', 0.8567409395705277), ('TAGS', 0.8474631028861717)]
Top words for pretrained_BERT neuron indx 1854 [('repeat', 1.0), ('dr', 0.8970962826725778), ('pa', 0.8759545013090707), ('submit', 0.8309827313869741), ('Manager', 0.821541329503194)]
Top words for pretrained_BERT neuron indx 3904 [('512', 1.0), ('encoding', 0.8892132653558007), ('fifteen', 0.8792658202708619), ('synchronized', 0.8237288128820315), ('15598', 0.7418949339928356)]
Top words for pretrained_BERT neuron indx 1866 [('Task', 1.0), ('Job', 0.8639699087128152), ('client', 0.8178559785993106), ('other', 0.8112805083544073), ('outgoing', 0.8039564589578753)]
Top words for pretrained_BERT neuron indx 8019 [('initial', 1.0), ('startpoint', 0.9172582253157194), ('translation', 0.9162756893400182), ('walk', 0.8777957656669406), ('moving', 0.866100612980225)]
Top words for pretrained_BERT neuron indx 5993 [('187', 1.0), ('201', 0.9550743364485884), ('Allow', 0.9368819674921284), ('cancel', 0.9284651404161922), ('CANCEL', 0.8767823962769387)]
Top words for pretrained_BERT neuron indx 3947 [('200', 1.0), ('500', 0.9213922430641284), ('nsa', 0.9082536830728185), ('75', 0.8616785742124127), ('512', 0.80458077967219)]
Top words for pretrained_BERT neuron indx 3950 [('69', 1.0), ('62', 0.8195388011213518), ('117', 0.7881421689230607), ('organization', 0.768586287865485), ('afi', 0.7355222811043771)]
Top words for pretrained_BERT neuron indx 1918 [('remember', 1.0), ('Geo', 0.9887631233360734), ('SUCCESS', 0.9865728030579767), ('wait', 0.8804672020910277), ('success', 0.8706749227787863)]
Top words for pretrained_BERT neuron indx 6018 [('WAY', 1.0), ('REFERENCES', 0.8848943890871305), ('moving', 0.8499356935952805), ('agency', 0.8430486045720237), ('REF', 0.8190673981940958)]
Top words for pretrained_BERT neuron indx 3979 [('REF', 1.0), ('999999', 0.9679495739831), ('ADVERTISE', 0.9314637916495376), ('getTo', 0.8994296374794623), ('2150', 0.8318414979974407)]
Top words for pretrained_BERT neuron indx 3980 [('minutes', 1.0), ('compute', 0.8744633163016974), ('texture', 0.798891982465518), ('year', 0.7981224939123037), ('uss', 0.7570305163752947)]
Top words for pretrained_BERT neuron indx 1939 [('sid', 1.0), ('principal', 0.8341503877917774), ('expand', 0.7899400972353634), ('oslo', 0.7555514939556403), ('uss', 0.6960027486394504)]
Top words for pretrained_BERT neuron indx 3987 [('25', 1.0), ('35', 0.9527208484386881), ('14', 0.948209225419945), ('75', 0.9402832072998905), ('18', 0.9046118961799882)]
Top words for pretrained_BERT neuron indx 8089 [('69', 1.0), ('five', 0.9543185055536269), ('55', 0.9072796964566533), ('simple', 0.8692016741813615), ('number', 0.848787527306611)]
Top words for pretrained_BERT neuron indx 1954 [('119', 1.0), ('reason', 0.9515448756408024), ('3785', 0.9254481768596264), ('commands', 0.9191638142083552), ('props', 0.9156425286186202)]
Top words for pretrained_BERT neuron indx 1958 [('119', 1.0), ('18', 0.9273713313604008), ('3785', 0.9116793345750861), ('def', 0.8822303439223409), ('reactor', 0.8683885278588135)]
Top words for pretrained_BERT neuron indx 6060 [('long', 1.0), ('runner', 0.9393971113381563), ('Int', 0.9363771726355817), ('translation', 0.8254265685100599), ('Reg', 0.7938172423676034)]
Top words for pretrained_BERT neuron indx 1967 [('composite', 1.0), ('internet', 0.9601961156406689), ('security', 0.8749390050654795), ('up', 0.7536725332784577), ('synchronized', 0.6951923809597765)]
Top words for pretrained_BERT neuron indx 8115 [('ah', 1.0), ('splits', 0.8564149543896636), ('33', 0.8529339586222368), ('discovery', 0.8356396802683003), ('nh', 0.8131973837732929)]
Top words for pretrained_BERT neuron indx 6067 [('127', 1.0), ('Clock', 0.9926010261777878), ('Billboard', 0.9339452895027177), ('subscribers', 0.9243477735857911), ('platforms', 0.9079856020761639)]
Top words for pretrained_BERT neuron indx 8126 [('completed', 1.0), ('INFO', 0.8838463774126865), ('choice', 0.8766663898596474), ('ct', 0.8763013972873145), ('notes', 0.8623934523224965)]
Top words for pretrained_BERT neuron indx 8130 [('quota', 1.0), ('75', 0.9601454352838671), ('http', 0.7566361855181716), ('ignore', 0.7215701408053472), ('Instance', 0.7140982400088438)]
Top words for pretrained_BERT neuron indx 6084 [('Label', 1.0), ('rules', 0.9513484063021936), ('None', 0.8985232909828491), ('Delay', 0.8271803431124213), ('GENERATOR', 0.8138006989984177)]
Top words for pretrained_BERT neuron indx 1989 [('Cat', 1.0), ('committed', 0.7118760980048207), ('translation', 0.69708655788541), ('processors', 0.6955740664355224), ('NODES', 0.695453426493789)]
Top words for pretrained_BERT neuron indx 8135 [('Subject', 1.0), ('organization', 0.9815261892908537), ('Mesh', 0.9807517137162348), ('Region', 0.9484837519161147), ('discovery', 0.9398679767222412)]
Top words for pretrained_BERT neuron indx 6088 [('Label', 1.0), ('each', 0.9972760402147169), ('sites', 0.975997615452939), ('called', 0.9298576328945223), ('hyper', 0.8793612646193186)]
Top words for pretrained_BERT neuron indx 8137 [('has', 1.0), ('FLAG', 0.9658527524231271), ('compute', 0.9456428040571939), ('lat', 0.870075218274048), ('forget', 0.8610666508395619)]
Top words for pretrained_BERT neuron indx 8139 [('five', 1.0), ('interval', 0.9386735873891541), ('one', 0.8843557583741818), ('TAG', 0.8332607823722638), ('qset', 0.8299924582213827)]
Top words for pretrained_BERT neuron indx 4052 [('principal', 1.0), ('wait', 0.9127498259101305), ('repeat', 0.890083758756206), ('75', 0.830950133480987), ('extended', 0.8112593052288342)]
Top words for pretrained_BERT neuron indx 8153 [('ip', 1.0), ('Int', 0.9255044833691014), ('reflection', 0.7578572301893349), ('Failure', 0.7380280453874328), ('Criteria', 0.6803125846945528)]
Top words for pretrained_BERT neuron indx 6113 [('activate', 1.0), ('1800', 0.9132162206842707), ('187', 0.8849392414155035), ('negotiate', 0.8103257472267924), ('302', 0.7950500089069468)]
Top words for pretrained_BERT neuron indx 8163 [('False', 1.0), ('intersects', 0.9765988522282076), ('exabgp', 0.9563804094484574), ('ElasticSearchServiceItem', 0.9201056372428991), ('runner', 0.9035120204864512)]
Top words for pretrained_BERT neuron indx 8176 [('STATUS', 1.0), ('excepts', 0.9786248429079034), ('mapByExtent', 0.9658767756545146), ('18', 0.9393253209062812), ('framing', 0.8651525183859035)]
Top words for pretrained_BERT neuron indx 2033 [('hour', 1.0), ('slot', 0.961165958186885), ('begin', 0.9566570742144368), ('ct', 0.9439169359698758), ('sts', 0.932566713718892)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0180
Epoch: [2/10], Loss: 0.0124
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.32
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0177
Epoch: [2/10], Loss: 0.0123
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0058
Score (accuracy) of the probe: 0.32
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0180
Epoch: [2/10], Loss: 0.0123
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0062
Score (accuracy) of the probe: 0.32
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0189
Epoch: [2/10], Loss: 0.0137
Epoch: [3/10], Loss: 0.0108
Epoch: [4/10], Loss: 0.0101
Epoch: [5/10], Loss: 0.0095
Epoch: [6/10], Loss: 0.0094
Epoch: [7/10], Loss: 0.0092
Epoch: [8/10], Loss: 0.0093
Epoch: [9/10], Loss: 0.0091
Epoch: [10/10], Loss: 0.0093
Score (accuracy) of the probe: 0.27
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0239
Epoch: [2/10], Loss: 0.0206
Epoch: [3/10], Loss: 0.0206
Epoch: [4/10], Loss: 0.0205
Epoch: [5/10], Loss: 0.0205
Epoch: [6/10], Loss: 0.0206
Epoch: [7/10], Loss: 0.0205
Epoch: [8/10], Loss: 0.0206
Epoch: [9/10], Loss: 0.0206
Epoch: [10/10], Loss: 0.0206
Score (accuracy) of the probe: 0.24
Training classification probe
Creating model...
Number of training instances: 13636
Number of classes: 4
Epoch: [1/10], Loss: 0.0279
Epoch: [2/10], Loss: 0.0203
Epoch: [3/10], Loss: 0.0202
Epoch: [4/10], Loss: 0.0201
Epoch: [5/10], Loss: 0.0201
Epoch: [6/10], Loss: 0.0201
Epoch: [7/10], Loss: 0.0201
Epoch: [8/10], Loss: 0.0201
Epoch: [9/10], Loss: 0.0201
Epoch: [10/10], Loss: 0.0201
Score (accuracy) of the probe: 0.29

The best l1=0, the best l2=0.01 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.27
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.22

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.2446597118728266
----------------------------------------------------------------
