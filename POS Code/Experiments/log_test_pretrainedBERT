Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
1289 13.0
Number of tokens:  11684
length of source dictionary:  1042
length of target dictionary:  35
11684
Total instances: 11684
['get_server_profile_template_by_name', 'probed', 'sp_desc', 'return', 'OldestInFront', 'class', 'dumps', '_activity', 'STRLEN', 'tzs', 'standard_library', 'parent', 'def', '@', 'register_opts', 'readline', '_userid', 'bootmode', 'readfp', 'child']
Number of samples:  11684
Stats: Labels with their frequencies in the final set
NAME 3656
NEWLINE 1172
KEYWORD 905
LPAR 870
RPAR 866
DOT 858
EQUAL 597
COMMA 576
COLON 447
DEDENT 369
INDENT 293
LSQB 204
RSQB 204
NUMBER 190
NL 117
STRING 82
EQEQUAL 48
PLUS 33
LBRACE 25
STAR 24
RBRACE 24
MINUS 22
PERCENT 22
AT 14
PLUSEQUAL 12
GREATER 11
NOTEQUAL 10
DOUBLESTAR 8
LESS 7
SLASH 5
COMMENT 4
GREATEREQUAL 3
MINEQUAL 3
LESSEQUAL 2
SEMI 1
pretrained_BERT distribution after trauncating:
{0: 0.7564659631698738, 3: 0.1872542933995448, 2: 0.03931305607283261, 1: 0.01696668735774881}
{0: 3656, 3: 905, 2: 190, 1: 82}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
494 13.0
Number of tokens:  6400
length of source dictionary:  482
length of target dictionary:  34
6400
Total instances: 6400
['MOCK_MODULES', 'return', 'steps', 'class', 'copyright', 'autocrop', 'parent', 'def', '@', 'results', 'dot', 'describable', 'moves', 'mock', '0.01', 'None', '10', 'outdeltas', 'gather_losses_and_scores', 'not']
Number of samples:  6400
Stats: Labels with their frequencies in the final set
NAME 1721
COMMA 798
NUMBER 482
RPAR 439
LPAR 437
NEWLINE 433
DOT 348
KEYWORD 336
COLON 293
EQUAL 241
LSQB 233
RSQB 228
DEDENT 97
INDENT 82
STAR 62
NL 60
EQEQUAL 29
PLUS 26
MINUS 15
DOUBLESTAR 7
SLASH 6
AT 6
STRING 4
LBRACE 3
RBRACE 3
STAREQUAL 2
PERCENT 2
GREATER 1
LESS 1
COMMENT 1
GREATEREQUAL 1
PLUSEQUAL 1
LESSEQUAL 1
AMPER 1
pretrained_BERT distribution after trauncating:
{0: 0.6767597325992922, 2: 0.18953991348800628, 3: 0.1321274085725521, 1: 0.0015729453401494297}
{0: 1721, 2: 482, 3: 336, 1: 4}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 3656, 3: 905, 2: 190, 1: 82})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({0: 1454, 2: 87, 3: 24, 1: 4})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (4349, 9984)
The shape of the validation set: (484, 9984)
The shape of the testing set: (1569, 9984)
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0044
Epoch: [2/10], Loss: 0.0004
Epoch: [3/10], Loss: 0.0001
Epoch: [4/10], Loss: 0.0001
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0045
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0001
Epoch: [4/10], Loss: 0.0001
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0044
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0056
Epoch: [2/10], Loss: 0.0019
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.88
{'__OVERALL__': 0.8820905035054175, 'NAME': 0.8727647867950481, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0044
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8368387507966858, 'NAME': 0.8404401650618982, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0041
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.822817080943276, 'NAME': 0.8253094910591472, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0027
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0041
Epoch: [3/10], Loss: 0.0028
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0014
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0010
Epoch: [9/10], Loss: 0.0009
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0089
Epoch: [2/10], Loss: 0.0047
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0022
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.8202676864244742, 'NAME': 0.8218707015130674, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.041666666666666664}
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0027
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0010
Epoch: [9/10], Loss: 0.0009
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8444869343530912, 'NAME': 0.8342503438789546, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.875}
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0092
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.83
{'__OVERALL__': 0.8311026131293817, 'NAME': 0.8177441540577717, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.8209050350541747, 'NAME': 0.8067400275103164, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0033
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0033
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0043
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8444869343530912, 'NAME': 0.8321870701513068, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0072
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0020
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.87
{'__OVERALL__': 0.8693435309114086, 'NAME': 0.859009628610729, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0066
Epoch: [2/10], Loss: 0.0027
Epoch: [3/10], Loss: 0.0017
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0010
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0030
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0019
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.89
{'__OVERALL__': 0.8852772466539197, 'NAME': 0.8762035763411279, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0067
Epoch: [2/10], Loss: 0.0025
Epoch: [3/10], Loss: 0.0016
Epoch: [4/10], Loss: 0.0012
Epoch: [5/10], Loss: 0.0009
Epoch: [6/10], Loss: 0.0007
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0066
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0017
Epoch: [4/10], Loss: 0.0012
Epoch: [5/10], Loss: 0.0009
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0018
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0028
Epoch: [4/10], Loss: 0.0024
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0021
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0018
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.91
{'__OVERALL__': 0.9145952836201402, 'NAME': 0.9078404401650619, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0071
Epoch: [2/10], Loss: 0.0030
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0030
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0019
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.89
{'__OVERALL__': 0.894200127469726, 'NAME': 0.8858321870701513, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0068
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0065
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0020
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.90
{'__OVERALL__': 0.8980242192479286, 'NAME': 0.889958734525447, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0071
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0027
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0017
Epoch: [6/10], Loss: 0.0014
Epoch: [7/10], Loss: 0.0013
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0045
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0023
Epoch: [10/10], Loss: 0.0022
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.86
{'__OVERALL__': 0.8623326959847036, 'NAME': 0.8514442916093535, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.93

pretrained_BERT top neurons
array([   2, 2061, 8206, 2071, 2074, 6172, 6174, 2079,   40, 8241, 8246,
         58, 2106, 2119,   78,   79, 4190,   94, 6240, 4193, 4194, 4195,
       2152, 8303, 6263, 2169, 6267, 4225, 6274, 2177, 2183, 6284, 6286,
       8335, 6287, 2193, 4247, 2200, 8344, 8347, 6300, 4253, 8350, 8351,
       8357, 2213, 4272, 8370, 4282, 4284, 6339, 8389,  203, 8396, 4312,
        221, 2271, 4320,  225, 6374, 6378,  235, 8436, 4343, 2295, 8451,
        262, 4360, 6408, 6410, 8464, 8474,  286,  300,  307, 6452,  310,
       4416, 4425, 8523, 6475,  333, 6483, 6489,  350,  354, 6499,  357,
       6504, 2413, 6515,  376,  380, 4477, 8572,  385, 6530,  395, 4496,
       4497, 2450, 2451, 6551,  411, 6563, 4517,  425,  429, 6575, 8623,
        432, 8625,  435, 6580, 2487, 4539,  444, 8638, 4543, 8643, 6595,
        451, 2516,  472, 6616,  473, 2523, 8673, 8682, 2539, 6642,  499,
       6667, 4622, 4628, 8728,  538, 4636, 8733, 2592,  551, 8755, 2612,
        566, 6711, 8767,  583, 4679, 6729, 6732, 8787, 4692, 8793,  604,
       2654, 8806, 4714, 8812,  621,  620, 8815,  624,  627, 4724,  633,
       4731,  636, 6780, 2689, 2690, 8838, 8845, 6797, 4751, 8848,  655,
       8852, 8855, 2711, 2715,  672, 8867, 6821,  678,  677, 2726, 6825,
       2731, 2745, 2748,  706, 2755,  709, 8901, 6856,  715, 6867, 6870,
        726, 4826, 8924, 2782, 4834, 6885, 4842, 4843,  759, 6908, 8968,
       6926, 8974, 8976, 2833, 6930, 8989, 6942,  808, 9007, 2864, 4916,
       9013,  830, 9023, 2880, 2887, 4936, 9033, 4939, 9041, 6996, 6997,
       7003, 4963, 9071, 4979,  885, 7035,  897, 4993, 5006,  911, 2960,
       5015, 9116, 9118, 9119, 5024, 9123,  931, 9125, 2981, 9129, 7082,
        940, 2990, 5044,  958,  961, 7107, 9155, 7115,  971, 7119, 3023,
       9167, 7123, 7125, 7127, 7138, 5094, 7146, 1003, 1008, 7177, 9229,
       7191, 9246, 9247, 9256, 7218, 1075, 7220, 1078, 5184, 5188, 3143,
       5193, 1101, 7251, 9300, 7263, 7266, 1123, 7267, 9322, 3179, 3181,
       9326, 7279, 9329, 5240, 5243, 1148, 5245, 9340, 3198, 7296, 1153,
       1163, 3212, 7309, 5261, 3215, 7312, 7317, 7319, 9372, 7331, 3235,
       5285, 7341, 7343, 1200, 9394, 5304, 1209, 1212, 1219, 7363, 7379,
       7380, 5331, 5334, 7384, 1241, 9442, 3299, 3302, 9450, 3307, 7402,
       7408, 7410, 7419, 7427, 9477, 7432, 1296, 1303, 9501, 9502, 3360,
       5416, 9517, 3379, 1334, 7479, 1338, 3387, 3396, 9540, 7492, 1351,
       5451, 3403, 7506, 5460, 1384, 9580, 5485, 1392, 7546, 5499, 1403,
       7549, 1404, 9602, 1415, 1419, 7564, 7565, 5518, 5519, 9616, 1425,
       7572, 9623, 9625, 5530, 3491, 1445, 7589, 3494, 9647, 7603, 7608,
       3513, 3516, 7615, 1471, 1474, 7621, 7624, 5579, 1483, 3537, 7635,
       7646, 1503, 7648, 7656, 1513, 5610, 7660, 9715, 7668, 5621, 1527,
       3584, 5635, 5636, 1539, 9736, 7694, 7710, 9771, 3638, 9784, 9791,
       3648, 3649, 3655, 5715, 7765, 5727, 7779, 5732, 7790, 9839, 3696,
       3707, 7804, 3709, 1659, 7807, 3713, 9859, 3719, 5773, 1679, 9875,
       5783, 9881, 7836, 5790, 9887, 9886, 5795, 9893, 3753, 5807, 9906,
       3771, 3775, 7875, 5827, 7883, 3798, 5848, 5856, 5859, 7912, 3817,
       7914, 1771, 5874, 7929, 7935, 5896, 5902, 7965, 5919, 7986, 7991,
       3898, 5952, 3911, 8019, 8024, 1886, 3947, 8049, 3966, 1921, 8076,
       8077, 6029, 3983, 8080, 8087, 3994, 1952, 8099, 1958, 8102, 4009,
       4010, 8111, 1987, 8133, 2009, 4063, 8160, 8163, 4088, 4095])
pretrained_BERT top neurons per class
{'NAME': array([4692, 6452, 2745, 6489, 5499, 8848, 7343, 7875,  566, 4939, 7656,
       3516,  385, 5188, 8357, 9125, 9580, 6563,  225, 4539, 8845,  395,
       8436, 9442, 7668, 7331, 9859, 9071, 9602, 5460, 1003, 1445, 5783,
        376,  538, 7220,  583, 9616, 8838, 6942, 8111, 7107,  380, 2200,
       9502, 1384, 3655,  808, 4477, 9007, 6575,  286, 2193, 7765, 8812,
       8623, 3513, 3771, 8787, 4842, 6267, 5285, 4320, 7549, 6997, 3307,
       8968, 1771, 8335, 7589, 5732, 1219, 7427, 4622, 9784, 1351, 8976,
       7146, 2009, 7710, 6284, 5094, 1334,  432, 8163, 9623, 4195, 4843,
       7564, 3181, 3709, 7380, 1474, 7115, 7914, 9229,  235, 1403, 3299,
       2690, 8246, 6821, 6870, 1148,  307, 2152, 4360,  678, 6287, 9246,
       7317, 5245, 7251, 8806, 9771, 7384, 5856, 7191, 9625, 9394, 9116,
       5902, 2981, 9256, 4272, 7119, 5610, 6174, 7312, 8733, 7419, 2654,
        911, 7408, 6530, 5243, 4751, 3696,  940, 6286,  709, 7804, 8389,
       8019, 8160,  706, 5304,  971, 3966, 6515, 3143, 4253, 5859]), 'STRING': array([9602, 4692, 8673, 7965, 2748, 8845,  333, 2887, 2152, 2654, 7191,
       2592, 5783, 8855, 7624, 8968, 7572,  672, 8087, 9623, 8848, 3143,
       9013, 3379, 7432, 2009, 3707, 5856, 6870, 3215, 7177, 6885, 7343,
        350, 4312, 4360, 8160, 5896, 9736, 6551, 7660, 9033, 6172, 5807,
        472, 9580, 5451, 1296, 4190, 4253, 5518, 3537, 4539, 5579, 4284,
       3584, 4679,  444, 1078, 4916, 5848, 4724, 6616, 7779, 9893, 8924,
       7125, 1153, 3302, 4343, 1403, 3911, 3360, 5519, 4636, 9155, 9501,
       2880, 1163, 1679,  633, 1886, 2079, 1212, 6339,  473, 3212, 5015,
       1003, 3403,    2, 7836, 8347, 7309, 9517, 4497, 8838, 9616, 9300,
       6374, 7506, 2612, 2295, 1075, 8643, 8370, 6410, 8396, 8787, 4009,
       9647, 8625, 8852, 9340, 5636, 9906, 7929,  395, 6530,  357, 6856,
       3983, 3516, 1419, 8163, 7379, 7312, 4194, 7331, 6300, 3638,  425,
       1241, 2169, 8350,  566, 5635,   79, 8755, 3648, 5006, 2782, 9118,
       4834,  262, 4963,  897]), 'NUMBER': array([5795, 7312, 9616, 7146, 2689, 4225, 8924, 8572,  538, 8080, 4979,
        354, 4247, 2880, 2539, 6240, 1404,  677, 4193, 8815, 8682, 6274,
       3798, 8848, 3947, 8076, 8099, 1958, 5579, 1483,  726, 2152, 8077,
       3491, 2864, 9450, 6499,  300, 5285, 5952,  885, 1952, 6825, 1539,
       1921, 6504, 7296, 6642, 5024, 2074, 2271,  636, 2711, 4416,  621,
        432,   58,  709, 4425, 4916, 7003,  499, 9123, 8474, 2450, 7127,
       2715, 1123, 5715, 6856, 3516, 9839, 8303, 1503, 4692, 3753,  620,
       7410, 6483,  604, 6732, 2213,  931, 5621, 1209, 6711,  715,  310,
       5874, 5245, 7912, 2413, 5240, 6729, 8767, 7621, 3179, 7790, 1200,
       7914, 6780, 4714,  551, 6408, 6870, 7267, 6263,   94, 8451, 6926,
       5919, 8344, 3775,  435, 3648, 7138, 4088, 2516,   78, 9715, 5184,
        203, 2833, 9129, 3994, 7807, 7402, 2487, 3649, 3235, 7615, 8206,
       9155, 7694, 6563, 1008, 7123, 7564, 3387,  759, 5243, 7546,  333,
       4936, 5193, 1659, 6908, 9326, 9580, 7479, 5530,  411, 4826]), 'KEYWORD': array([6797,  429, 7565, 3181, 9887, 9372,  620, 6867, 5334,  627,  333,
       6489, 8974,  221, 7279, 5261, 9477, 3396,  808, 8351, 2009, 6595,
       5827, 8643, 8102, 7218, 2193,  940, 2071, 8019, 4543, 8867, 8793,
       9791, 7991, 9247, 3198, 1392, 4063, 1212, 9540, 6267, 9023, 8024,
       8241, 2177, 7804,  961, 7363, 5416, 2960, 9450, 9119, 2755,  566,
        624, 7263, 1471, 8638, 4993, 5044, 6551, 3023,  604, 7648,  444,
       7082, 8077, 9881, 5331, 2119, 7319, 3713, 6930, 2451, 2183, 3494,
        451, 8464, 1415, 5790, 7341,  385, 4517, 9167, 4628, 6029, 2523,
        958, 5773, 7266, 2106, 4010, 1527, 1101, 8206, 6284, 5727, 7986,
       9322, 8523, 7492, 8901, 1513, 7935, 7603, 5485, 8049, 4095, 2748,
       9886, 8133, 3898, 7883, 8728, 9329, 6378, 7608, 8989, 2726, 3817,
       2731, 6286, 4724, 1987, 2061, 2990, 9041, 7410, 7635,   40, 9875,
       7035, 3719, 7646,  655, 1425, 4282, 6667, 7621, 1338, 6475, 4731,
        830, 6996, 6580, 4539, 4272, 1303, 4496])}
The shape of selected features (4349, 516)
The shape of the training set: (4349, 516)
The shape of the validation set: (484, 516)
The shape of the testing set: (1569, 516)
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0066
Epoch: [2/10], Loss: 0.0020
Epoch: [3/10], Loss: 0.0012
Epoch: [4/10], Loss: 0.0008
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0061
Epoch: [2/10], Loss: 0.0019
Epoch: [3/10], Loss: 0.0011
Epoch: [4/10], Loss: 0.0008
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0022
Epoch: [3/10], Loss: 0.0013
Epoch: [4/10], Loss: 0.0010
Epoch: [5/10], Loss: 0.0008
Epoch: [6/10], Loss: 0.0007
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0068
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0018
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.1 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.92
{'__OVERALL__': 0.9158699808795411, 'NAME': 0.9092159559834938, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0085
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0085
Epoch: [2/10], Loss: 0.0047
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0057
Epoch: [3/10], Loss: 0.0043
Epoch: [4/10], Loss: 0.0036
Epoch: [5/10], Loss: 0.0032
Epoch: [6/10], Loss: 0.0030
Epoch: [7/10], Loss: 0.0028
Epoch: [8/10], Loss: 0.0027
Epoch: [9/10], Loss: 0.0026
Epoch: [10/10], Loss: 0.0025
Score (accuracy) of the probe: 0.94

The best l1=0, the best l2=0.1 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.90
{'__OVERALL__': 0.89993626513703, 'NAME': 0.8920220082530949, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 2 [('sts', 1.0), ('reactor', 0.936245849589313), ('parent', 0.8559823771262485), ('stanza', 0.84438410415494), ('root', 0.8436092807796476)]
Top words for pretrained_BERT neuron indx 2061 [('Register', 1.0), ('id', 0.8837235904498117), ('calendar', 0.8661794610636743), ('routes', 0.8154093686863738), ('Simple', 0.8144039966104045)]
Top words for pretrained_BERT neuron indx 8206 [('not', 1.0), ('META', 0.9170837441898863), ('is', 0.8725185718572507), ('strip', 0.8345946280143538), ('credential', 0.8091498049485961)]
Top words for pretrained_BERT neuron indx 2071 [('seek', 1.0), ('token', 0.951586174200817), ('3700', 0.8237137498902446), ('probe', 0.8118148287159225), ('3600', 0.7789804214732011)]
Top words for pretrained_BERT neuron indx 2074 [('timegm', 1.0), ('def', 0.9941416689693352), ('root', 0.9618604791388826), ('minutes', 0.9467559900294161), ('tzlocal', 0.8745765729696694)]
Top words for pretrained_BERT neuron indx 6172 [('loads', 1.0), ('us', 0.895888149567007), ('View', 0.8310894222514946), ('objects', 0.8131855945072295), ('to', 0.8008497249996924)]
Top words for pretrained_BERT neuron indx 6174 [('os', 1.0), ('boot', 0.9594546597893783), ('future', 0.9479473914098389), ('Register', 0.9106872981700571), ('description', 0.9092631844502164)]
Top words for pretrained_BERT neuron indx 2079 [('description', 1.0), ('direct', 0.9725965831202334), ('models', 0.9380063191725477), ('if', 0.9186650083319022), ('errors', 0.915188392002063)]
Top words for pretrained_BERT neuron indx 40 [('def', 1.0), ('loads', 0.9342712971306635), ('len', 0.9088785307866365), ('int', 0.9078090872136991), ('upper', 0.8952335001942214)]
Top words for pretrained_BERT neuron indx 8241 [('milliseconds', 1.0), ('hour', 0.896601821304875), ('epoch_milliseconds', 0.8904168023739399), ('mesh', 0.8605916437920471), ('m', 0.8282922351830985)]
Top words for pretrained_BERT neuron indx 8246 [('Simple', 1.0), ('Exception', 0.9846228676607427), ('"happy_birthday"', 0.7848946117638042), ('HorizontalBillboard', 0.7759091196292085), ('VerticalBillboard', 0.7734641305034612)]
Top words for pretrained_BERT neuron indx 58 [('put', 1.0), ('post', 0.9778486355484641), ('horizon', 0.9706870600238204), ('Post', 0.8943096704089292), ('cmp', 0.8520885893202883)]
Top words for pretrained_BERT neuron indx 2106 [('baseline', 1.0), ('uss', 0.9551120608444964), ('bind', 0.9419263317216807), ('os', 0.9335509091845737), ('GET', 0.8878588417604392)]
Top words for pretrained_BERT neuron indx 2119 [('Exception', 1.0), ('horizon', 0.7184468659793094), ('break', 0.7004699241384889), ('local', 0.635706795037468), ('action', 0.6062086856097443)]
Top words for pretrained_BERT neuron indx 78 [('Unauthorized', 1.0), ('roster', 0.8811498878222052), ('name', 0.8283959067959085), ('endswith', 0.7651786547223819), ('else', 0.730892320708726)]
Top words for pretrained_BERT neuron indx 79 [('calendar', 1.0), ('boot', 0.917015601569825), ('enclosure', 0.8461873832166048), ('Simple', 0.8198825944688768), ('servers', 0.8158198650134453)]
Top words for pretrained_BERT neuron indx 4190 [('all', 1.0), ('timezone', 0.9927935035697252), ('unicode', 0.9462894882248857), ('astimezone', 0.8213702684242645), ('long', 0.8107701036098611)]
Top words for pretrained_BERT neuron indx 94 [('affinity', 1.0), ('identity', 0.9674582257319454), ('authentication', 0.8355526210161719), ('key', 0.7899693137558232), ('os', 0.7757677248572954)]
Top words for pretrained_BERT neuron indx 6240 [('models', 1.0), ('core', 0.9270444072446349), ('oslo', 0.9235809294953774), ('field', 0.9186497968418386), ('12', 0.8551027630729335)]
Top words for pretrained_BERT neuron indx 4193 [('long', 1.0), ('repr', 0.9264301360969933), ('component', 0.8341622060638716), ('project', 0.8126958115310525), ('second', 0.7807602896087997)]
Top words for pretrained_BERT neuron indx 4194 [('contents', 1.0), ('Distance', 0.7884186095757935), ('template', 0.7385034249864161), ('format', 0.7219218621645231), ('context', 0.6535409609429214)]
Top words for pretrained_BERT neuron indx 4195 [('6', 1.0), ('sans', 0.9995739259515849), ('other', 0.9385849703034057), ('60', 0.8970058572088951), ('else', 0.8268690732377764)]
Top words for pretrained_BERT neuron indx 2152 [('local', 1.0), ('us', 0.9758417675737223), ('None', 0.9635625040567269), ('purpose', 0.9604376371562441), ('Distance', 0.8749856668009215)]
Top words for pretrained_BERT neuron indx 8303 [('core', 1.0), ('all', 0.7828248115142661), ('8', 0.7804147157386832), ('constants', 0.7647577955002818), ('__future__', 0.7484091769763075)]
Top words for pretrained_BERT neuron indx 6263 [('local', 1.0), ('None', 0.9665851981644333), ('12', 0.9610727472506042), ('or', 0.9194588090795092), ('kwargs', 0.9113680240165595)]
Top words for pretrained_BERT neuron indx 2169 [('common', 1.0), ('wait', 0.7772457272496828), ('info', 0.6930572223796836), ('800', 0.6316282734692915), ('600', 0.6016015117908098)]
Top words for pretrained_BERT neuron indx 6267 [('mins', 1.0), ('minutes', 0.9036467920305115), ('millis', 0.8374041071169371), ('name', 0.7527550820373062), ('30', 0.7463092866474071)]
Top words for pretrained_BERT neuron indx 4225 [('seek', 1.0), ('pop', 0.7504656729234388), ('14', 0.7127964524944516), ('slug', 0.669348042604827), ('On', 0.6617362466930294)]
Top words for pretrained_BERT neuron indx 6274 [('close', 1.0), ('86400', 0.9729475436653104), ('main', 0.9701141004060388), ('Tab', 0.9635572018376127), ('800', 0.9560480884528251)]
Top words for pretrained_BERT neuron indx 2177 [('m', 1.0), ('REQUEST', 0.8723590894558956), ('request', 0.849054874053441), ('choices', 0.8070748393335404), ('st', 0.7760041098057878)]
Top words for pretrained_BERT neuron indx 2183 [('filter', 1.0), ('day', 0.9853073910944249), ('broadcast', 0.9842554651619697), ('item', 0.9714045527664993), ('sans', 0.9023447133215813)]
Top words for pretrained_BERT neuron indx 6284 [('minutes', 1.0), ('seconds', 0.8686619745492516), ('key', 0.8385397711717282), ('80', 0.831730127951887), ('stanza', 0.8111742835536798)]
Top words for pretrained_BERT neuron indx 6286 [('wait', 1.0), ('loads', 0.9817892052616818), ('Off', 0.9735775552535143), ('scope', 0.9530527703904808), ('to', 0.9517129860783643)]
Top words for pretrained_BERT neuron indx 8335 [('600', 1.0), ('15', 0.9794011855360898), ('60', 0.9505084710989569), ('400', 0.8268354596963333), ('30', 0.8257338697581358)]
Top words for pretrained_BERT neuron indx 6287 [('Unauthorized', 1.0), ('patch', 0.9991632168047792), ('long', 0.9226659080201635), ('and', 0.8471422878333459), ('port', 0.8153475439024609)]
Top words for pretrained_BERT neuron indx 2193 [('affinity', 1.0), ('format', 0.9872949126340972), ('month', 0.9730183874957282), ('srv', 0.9381080730328079), ('f', 0.901250290959376)]
Top words for pretrained_BERT neuron indx 4247 [('enabled', 1.0), ('loads', 0.8486400250588473), ('META', 0.8293898480669889), ('GET', 0.8205214435135983), ('not', 0.793165381892433)]
Top words for pretrained_BERT neuron indx 2200 [('purpose', 1.0), ('300', 0.8849816959986981), ('future', 0.8510305580046749), ('Session', 0.8346028435534059), ('8000', 0.8269921600507325)]
Top words for pretrained_BERT neuron indx 8344 [('bind', 1.0), ('seconds', 0.9204444172498955), ('1000', 0.918241223801101), ('session', 0.851978563947666), ('time', 0.8090970031494285)]
Top words for pretrained_BERT neuron indx 8347 [('"view"', 1.0), ('seconds', 0.8535484348859204), ('"purpose"', 0.7961920636188903), ('authorization', 0.7456502712412502), ('"Host"', 0.7448705091986463)]
Top words for pretrained_BERT neuron indx 6300 [('wait', 1.0), ('logging', 0.9197522192701829), ('dest', 0.8459274566557464), ('long', 0.8152960745764176), ('resource', 0.7789102082010627)]
Top words for pretrained_BERT neuron indx 4253 [('try', 1.0), ('help', 0.8928765452003986), ('BlendProbes', 0.8076360417500689), ('LoadUser', 0.7716325249480672), ('feature', 0.7690704320909193)]
Top words for pretrained_BERT neuron indx 8350 [('future', 1.0), ('requests', 0.9352997673934375), ('".."', 0.8501114780976738), ('List', 0.8411722530025318), ('filename', 0.8113358324513061)]
Top words for pretrained_BERT neuron indx 8351 [('bare', 1.0), ('e', 0.6923356232071394), ('Post', 0.6422303989836938), ('uss', 0.6106056722727161), ('boot', 0.60637012184917)]
Top words for pretrained_BERT neuron indx 8357 [('META', 1.0), ('if', 0.893866396485173), ('5', 0.8790107319543438), ('for', 0.7428073725424065), ('6', 0.7134351965885241)]
Top words for pretrained_BERT neuron indx 2213 [('raise', 1.0), ('META', 0.8902968358549782), ('super', 0.7712794463955509), ('Mesh', 0.7456512325632805), ('id', 0.7417258390044884)]
Top words for pretrained_BERT neuron indx 4272 [('86400', 1.0), ('24', 0.9112303695613962), ('find', 0.7924574280449475), ('setup', 0.7468606738332334), ('4', 0.7368030962461175)]
Top words for pretrained_BERT neuron indx 8370 [('choices', 1.0), ('Node', 0.951060807596727), ('strip', 0.9380986254655528), ('9', 0.9338936380827809), ('closing', 0.9134147185365444)]
Top words for pretrained_BERT neuron indx 4282 [('BlendProbes', 1.0), ('authorized', 0.9662541066312245), ('Distance', 0.9352837657301388), ('set', 0.9232625571372447), ('128', 0.9133458094371975)]
Top words for pretrained_BERT neuron indx 4284 [('id', 1.0), ('hpov', 0.998171457526764), ('None', 0.9653451842658959), ('tzs', 0.9305392245699254), ('other', 0.913182026603208)]
Top words for pretrained_BERT neuron indx 6339 [('component', 1.0), ('VerticalBillboard', 0.9746696512270656), ('class', 0.9587982857281355), ('HorizontalBillboard', 0.942095045687073), ('16', 0.8830672065562337)]
Top words for pretrained_BERT neuron indx 8389 [('authorization', 1.0), ('common', 0.9371594754622814), ('tastypie', 0.9123558617763706), ('7', 0.8939134790828474), ('type', 0.8868564573207526)]
Top words for pretrained_BERT neuron indx 203 [('loads', 1.0), ('operand', 0.9187980567090557), ('format', 0.8822154225576634), ('post', 0.860015846923984), ('Post', 0.8259754296141243)]
Top words for pretrained_BERT neuron indx 8396 [('\\\'"\\\'', 1.0), ('"\\\\n"', 0.792775581357695), ('seconds', 0.7568401939022218), ('9', 0.6695400764875953), ('"happy_birthday"', 0.6196496396487732)]
Top words for pretrained_BERT neuron indx 4312 [('utc', 1.0), ('contents', 0.9087237146410786), ('Unauthorized', 0.8915867156783597), ('common', 0.8900635087557854), ('iq', 0.8822570650475908)]
Top words for pretrained_BERT neuron indx 221 [('identity', 1.0), ('zone', 0.991183149116628), ('boot', 0.8911379203607833), ('seek', 0.8418243161640723), ('_hash', 0.8100116603893054)]
Top words for pretrained_BERT neuron indx 2271 [('bare', 1.0), ('domain', 0.9470655826178775), ('ms', 0.84355833093553), ('purpose', 0.8017431903225776), ('send', 0.7628782218505141)]
Top words for pretrained_BERT neuron indx 4320 [('to', 1.0), ('range', 0.9986770085527397), ('logging', 0.9212542354245767), ('token', 0.9041733588723578), ('request', 0.8963140404534908)]
Top words for pretrained_BERT neuron indx 225 [('9', 1.0), ('7', 0.7997133282747931), ('8', 0.7014700468608752), ('contents', 0.5983869598478223), ('5', 0.5801366824946123)]
Top words for pretrained_BERT neuron indx 6374 [('1000', 1.0), ('mesh2', 0.9591461745404235), ('v', 0.9542063786291242), ('1800', 0.9084345052541738), ('mesh', 0.8384688253556766)]
Top words for pretrained_BERT neuron indx 6378 [('Off', 1.0), ('append', 0.7815126990705865), ('class', 0.7748112609313637), ('shts', 0.7661200889699145), ('help', 0.7613120550849535)]
Top words for pretrained_BERT neuron indx 235 [('proxy', 1.0), ('future', 0.9284528746831692), ('calendar', 0.9066804893483315), ('m', 0.8250417520198565), ('Node', 0.8006806850743703)]
Top words for pretrained_BERT neuron indx 8436 [('1000', 1.0), ('17', 0.9315254142056125), ('300', 0.7559386783773382), ('12', 0.72282884830309), ('force', 0.7007073873795475)]
Top words for pretrained_BERT neuron indx 4343 [('1800', 1.0), ('300', 0.7479951256705607), ('60', 0.7293733334171207), ('600', 0.7205291066801565), ('15', 0.6867650016024331)]
Top words for pretrained_BERT neuron indx 2295 [('Unauthorized', 1.0), ('zone', 0.8964246055973537), ('bind', 0.8269913399514421), ('E', 0.7483059744637542), ('pass', 0.7139983793262439)]
Top words for pretrained_BERT neuron indx 8451 [('bootModeSetting', 1.0), ('tastypie', 0.9713535145027129), ('HorizontalBillboard', 0.9447760469224619), ('VerticalBillboard', 0.9154208357720804), ('profileResource', 0.9040150974224758)]
Top words for pretrained_BERT neuron indx 262 [('identity', 1.0), ('stanza', 0.9674037820562253), ('Distance', 0.908238027915585), ('ping', 0.8855093266157709), ('1', 0.8747146708353128)]
Top words for pretrained_BERT neuron indx 4360 [('pop', 1.0), ('con', 0.8802434344712359), ('count', 0.868613775673139), ('direct', 0.7517463753094608), ('On', 0.7436499147422333)]
Top words for pretrained_BERT neuron indx 6408 [('format', 1.0), ('save', 0.9424480866898094), ('render', 0.920095876395241), ('setup', 0.903407539697541), ('description', 0.8831912090659831)]
Top words for pretrained_BERT neuron indx 6410 [('set', 1.0), ('digest', 0.8789499447137111), ('group', 0.8308475123545921), ('core', 0.7979390884811839), ('Digest', 0.7564387389615032)]
Top words for pretrained_BERT neuron indx 8464 [('with', 1.0), ('NAMELEN', 0.9488662465340775), ('IOError', 0.946721365975069), ('log', 0.8638378979044686), ('constants', 0.850971714678265)]
Top words for pretrained_BERT neuron indx 8474 [('component', 1.0), ('Off', 0.9861286648556432), ('models', 0.8944921325474048), ('ZmqProxy', 0.8736434519515769), ('core', 0.8723931155727964)]
Top words for pretrained_BERT neuron indx 286 [('add', 1.0), ('context', 0.9587305081353885), ('dt', 0.9489571046522692), ('error', 0.9055950097686262), ('super', 0.8708234414717716)]
Top words for pretrained_BERT neuron indx 300 [('calendar', 1.0), ('elem', 0.9459807565941484), ('Profile', 0.9421051378934364), ('k', 0.9250092603499361), ('profile', 0.8646418734260854)]
Top words for pretrained_BERT neuron indx 307 [('close', 1.0), ('loads', 0.8641050089638863), ('profile', 0.7532140801689028), ('Profile', 0.7396754313178998), ('partition', 0.7337005644365212)]
Top words for pretrained_BERT neuron indx 6452 [('Billboard', 1.0), ('with', 0.8536827549684461), ('unicode', 0.7740554778965971), ('int', 0.7626957680790729), ('in', 0.735734602959138)]
Top words for pretrained_BERT neuron indx 310 [('strip', 1.0), ('Distance', 0.8196584701731107), ('material', 0.5834584153157901), ('return', 0.5758292822449027), ('__class__', 0.5591294564803369)]
Top words for pretrained_BERT neuron indx 4416 [('minutes', 1.0), ('seconds', 0.8751192445701953), ('def', 0.8651412456993636), ('vCard', 0.8631803855890626), ('sorted', 0.7994766063321032)]
Top words for pretrained_BERT neuron indx 4425 [('bare', 1.0), ('put', 0.7570031498861872), ('read', 0.7345114854956627), ('LoadUser', 0.6809873431763523), ('GetBoard', 0.6498121325772519)]
Top words for pretrained_BERT neuron indx 8523 [('BlendProbes', 1.0), ('common', 0.9755938890606346), ('exceptions', 0.8565810457188022), ('microseconds', 0.8341230664330144), ('"oslo"', 0.820518328880944)]
Top words for pretrained_BERT neuron indx 6475 [('choices', 1.0), ('"%s/%s"', 0.9526014249811223), ('Simple', 0.9506099718849583), ('mesh', 0.9128019871672292), ('"%s@%s"', 0.8750839810722019)]
Top words for pretrained_BERT neuron indx 333 [('parent', 1.0), ('enclosure', 0.9473998067638004), ('24', 0.9432696062100182), ('Unauthorized', 0.9365271062723761), ('horizon', 0.8737237269370443)]
Top words for pretrained_BERT neuron indx 6483 [('View', 1.0), ('action', 0.9614911117933567), ('recv', 0.9272254226952086), ('feature', 0.880434639575084), ('routes', 0.7990444120150586)]
Top words for pretrained_BERT neuron indx 6489 [('IDLEN', 1.0), ('Stretch', 0.9972330788033485), ('IPLEN', 0.9938042354366307), ('GetBoard', 0.9111651993337515), ('type', 0.9057711825910143)]
Top words for pretrained_BERT neuron indx 350 [('Exception', 1.0), ('exceptions', 0.9135832484253225), ('digest', 0.8479160786829476), ('ranges', 0.8435779335875855), ('Digest', 0.7887741170612712)]
Top words for pretrained_BERT neuron indx 354 [('info', 1.0), ('servers', 0.9717993290405551), ('collectorBody', 0.9013179876363584), ('template', 0.8818183867178918), ('long', 0.8329443641159732)]
Top words for pretrained_BERT neuron indx 6499 [('sans', 1.0), ('alt', 0.8013661712898706), ('utc', 0.7861207393841646), ('default', 0.7509349019626499), ('6', 0.7468203180029983)]
Top words for pretrained_BERT neuron indx 357 [('contents', 1.0), ('boot', 0.9955828659722931), ('Stretch', 0.8084651695925386), ('seek', 0.7320572253287179), ('class', 0.7268138826840159)]
Top words for pretrained_BERT neuron indx 6504 [('put', 1.0), ('upper', 0.898403660348333), ('80', 0.827630288922036), ('count', 0.7453073334393089), ('division', 0.7197109812633552)]
Top words for pretrained_BERT neuron indx 2413 [('5', 1.0), ('E', 0.8036093666305202), ('hour', 0.7889628047265068), ('group', 0.7294723490533073), ('e', 0.7293493459127112)]
Top words for pretrained_BERT neuron indx 6515 [('digest', 1.0), ('horizon', 0.9995745378146782), ('k', 0.940187822451057), ('NotFound', 0.9200052274499975), ('verbose', 0.8658828306566673)]
Top words for pretrained_BERT neuron indx 376 [('len', 1.0), ('Unauthorized', 0.9672007723530469), ('entity', 0.9285107747193517), ('calendar', 0.9092458029461379), ('rpc', 0.8914604896440547)]
Top words for pretrained_BERT neuron indx 380 [('slug', 1.0), ('try', 0.8542994699747746), ('read', 0.8453653924585214), ('unicode', 0.839462117822173), ('alt', 0.8034148008468631)]
Top words for pretrained_BERT neuron indx 4477 [('300', 1.0), ('17', 0.9594122752387613), ('12', 0.8029103466248403), ('32', 0.7931868585564373), ('600', 0.7886528421274601)]
Top words for pretrained_BERT neuron indx 8572 [('with', 1.0), ('for', 0.9931826809114327), ('unicode', 0.9395002992130791), ('"happy_birthday"', 0.9122954079444691), ('"Name"', 0.8880958029309038)]
Top words for pretrained_BERT neuron indx 385 [('proxy', 1.0), ('filters', 0.7906254938419407), ('seek', 0.5915492930005309), ('0', 0.564519586386292), ('put', 0.5267507992536274)]
Top words for pretrained_BERT neuron indx 6530 [('Off', 1.0), ('as', 0.9575248953037425), ('Simple', 0.8304168880604166), ('required', 0.8105824615500757), ('Mesh', 0.8084636289992422)]
Top words for pretrained_BERT neuron indx 395 [('enclosuregroup', 1.0), ('line', 0.9773172410663844), ('required', 0.9630857379818643), ('end', 0.9618261199343204), ('server', 0.9092151691578361)]
Top words for pretrained_BERT neuron indx 4496 [('On', 1.0), ('if', 0.704646598740026), ('Register', 0.6833842366050764), ('stanza', 0.6616718647007476), ('property', 0.6615628643706424)]
Top words for pretrained_BERT neuron indx 4497 [('format', 1.0), ('uss', 0.7911982774729392), ('E', 0.775851677174351), ('srv', 0.7668472729178601), ('proxy', 0.7566381663166267)]
Top words for pretrained_BERT neuron indx 2450 [('iq', 1.0), ('servers', 0.9913382884718799), ('server', 0.9732202242934382), ('count', 0.9712570500774098), ('Post', 0.9593357979382505)]
Top words for pretrained_BERT neuron indx 2451 [('future', 1.0), ('Unauthorized', 0.9333993449250294), ('20', 0.8695605471995599), ('16', 0.8491608747811903), ('32', 0.8468315602676982)]
Top words for pretrained_BERT neuron indx 6551 [('requests', 1.0), ('GET', 0.9218043557760957), ('store', 0.9125073060187993), ('1', 0.8956635843173832), ('1800', 0.8689233241060149)]
Top words for pretrained_BERT neuron indx 411 [('blocking', 1.0), ('servers', 0.979204350915736), ('pass', 0.9584477281118162), ('server', 0.9253015772968243), ('choices', 0.8485057947197908)]
Top words for pretrained_BERT neuron indx 6563 [('except', 1.0), ('if', 0.9242341864879582), ('get_profile_networks', 0.8361322742619024), ('get_profile_compliance_preview', 0.8249881775975781), ('get_task_associated_resource', 0.7945458821444868)]
Top words for pretrained_BERT neuron indx 4517 [('META', 1.0), ('description', 0.8563757334054407), ('raise', 0.8121616143560738), ('Mesh', 0.6994015110648635), ('if', 0.6960231796148839)]
Top words for pretrained_BERT neuron indx 425 [('Simple', 1.0), ('ref', 0.7611236333637144), ('core', 0.7154241897162524), ('super', 0.7035832258545991), ('class', 0.6886067107738949)]
Top words for pretrained_BERT neuron indx 429 [('Exception', 1.0), ('item', 0.8957320900414909), ('resource', 0.8795800045408636), ('settings', 0.8259064287536493), ('modes', 0.8149288459623826)]
Top words for pretrained_BERT neuron indx 6575 [('bare', 1.0), ('affinity', 0.9200353452711587), ('objects', 0.8739425908544228), ('created', 0.8419659294387224), ('On', 0.8195873489528593)]
Top words for pretrained_BERT neuron indx 8623 [('4', 1.0), ('"Host"', 0.9151062035944407), ('result', 0.8169530259992619), ('if', 0.8137241948775269), ('5', 0.8077054507364614)]
Top words for pretrained_BERT neuron indx 432 [('Billboard', 1.0), ('read', 0.892382872280277), ('digest', 0.7174901828280705), ('Digest', 0.715088094772378), ('re', 0.6256160630714481)]
Top words for pretrained_BERT neuron indx 8625 [('minutes', 1.0), ('sans', 0.979846028135596), ('servers', 0.9635980709321624), ('ranges', 0.8998326516265429), ('VerticalBillboard', 0.8804626196200046)]
Top words for pretrained_BERT neuron indx 435 [('split', 1.0), ('start', 0.9867028627896532), ('1000', 0.7473928499620323), ('all', 0.7356277100366228), ('try', 0.6786425137134647)]
Top words for pretrained_BERT neuron indx 6580 [('utcnow', 1.0), ('host', 0.9708884034701313), ('Simple', 0.9558344585862616), ('or', 0.92669216023271), ('On', 0.8462084393197818)]
Top words for pretrained_BERT neuron indx 2487 [('created', 1.0), ('us', 0.8777202103725968), ('token', 0.7735699719883994), ('Mesh', 0.7473292042224534), ('connection', 0.7187701731698543)]
Top words for pretrained_BERT neuron indx 4539 [('milliseconds', 1.0), ('microseconds', 0.8974799653463564), ('e', 0.8241807018728093), ('Tab', 0.8226993875159633), ('600', 0.6407332142524444)]
Top words for pretrained_BERT neuron indx 444 [('Tab', 1.0), ('bare', 0.9987414138375286), ('default', 0.9221222625498069), ('division', 0.8950740404405905), ('objects', 0.8710030616436114)]
Top words for pretrained_BERT neuron indx 8638 [('Off', 1.0), ('sans', 0.9964078784345164), ('s', 0.9425018372081724), ('VerticalBillboard', 0.865370144304351), ('HorizontalBillboard', 0.8444714458372811)]
Top words for pretrained_BERT neuron indx 4543 [('os', 1.0), ('sts', 0.8024093274246189), ('List', 0.7973471058453375), ('enum', 0.7873150242918615), ('sorted', 0.7169200450993252)]
Top words for pretrained_BERT neuron indx 8643 [('17', 1.0), ('24', 0.8558435322066454), ('30', 0.8137709382805256), ('receive_shadows', 0.7376621152553984), ('16', 0.7286732130279727)]
Top words for pretrained_BERT neuron indx 6595 [('template', 1.0), ('seek', 0.9205289996235168), ('None', 0.8384874009419859), ('part', 0.8127227104749682), ('parts', 0.7514701180896397)]
Top words for pretrained_BERT neuron indx 451 [('Component', 1.0), ('len', 0.9765113610786967), ('render', 0.9605461322528669), ('component', 0.9229139733750865), ('dt', 0.9157709471299161)]
Top words for pretrained_BERT neuron indx 2516 [('wait', 1.0), ('400', 0.9153598773168208), ('1000', 0.9022670237649656), ('stat', 0.8704058064137857), ('future', 0.8299959007103184)]
Top words for pretrained_BERT neuron indx 472 [('Simple', 1.0), ('recv', 0.9933390189138046), ('us', 0.9791176979971896), ('common', 0.9468378505627719), ('baseline', 0.8549087032619336)]
Top words for pretrained_BERT neuron indx 6616 [('Unauthorized', 1.0), ('seconds', 0.8186926039862052), ('except', 0.7854672464607998), ('millis', 0.7185453404291641), ('iq', 0.7089992255618183)]
Top words for pretrained_BERT neuron indx 473 [('script', 1.0), ('day', 0.891914433042789), ('message', 0.864261736944102), ('year', 0.8038410082876745), ('300', 0.7778186237332053)]
Top words for pretrained_BERT neuron indx 2523 [('uss', 1.0), ('0', 0.9863164613090898), ('32', 0.9463434947331402), ('close', 0.8415623791774781), ('128', 0.8168590161674067)]
Top words for pretrained_BERT neuron indx 8673 [('presence', 1.0), ('__long__', 0.9595838546816889), ('blocking', 0.9222316136718671), ('settings', 0.91123371071305), ('ARTICLE_TITLE_LEN', 0.8260219393587064)]
Top words for pretrained_BERT neuron indx 8682 [('minutes', 1.0), ('ms', 0.9366265299703569), ('to', 0.745907226831704), ('shts', 0.74010993266518), ('minute', 0.7159592685260484)]
Top words for pretrained_BERT neuron indx 2539 [('calendar', 1.0), ('Node', 0.9478985397977282), ('resource', 0.890941872946992), ('os', 0.8867828179427777), ('upper', 0.8587210490031719)]
Top words for pretrained_BERT neuron indx 6642 [('int', 1.0), ('val', 0.8264420641113429), ('connection', 0.8162219542069742), ('second', 0.8048770478876326), ('zone', 0.7524025168688169)]
Top words for pretrained_BERT neuron indx 499 [('except', 1.0), ('slug', 0.7668681517812282), ('NoPerm', 0.7549942615384129), ('setup', 0.7129584588106266), ('prange', 0.7045695525522567)]
Top words for pretrained_BERT neuron indx 6667 [('NAMELEN', 1.0), ('ShadowsOnly', 0.9443113009659123), ('sorted', 0.9344534840881473), ('def', 0.9308392304328311), ('group', 0.9196383009777968)]
Top words for pretrained_BERT neuron indx 4622 [('force', 1.0), ('8', 0.8209479015062471), ('oslo', 0.7749492689509883), ('key', 0.7666961867099275), ('Off', 0.7161757102028182)]
Top words for pretrained_BERT neuron indx 4628 [('REQUEST', 1.0), ('v', 0.9721867050965988), ('filter', 0.9705740472922108), ('requests', 0.9320003970424545), ('log', 0.8843189170469505)]
Top words for pretrained_BERT neuron indx 8728 [('and', 1.0), ('pdb', 0.9803969016808897), ('is', 0.9208833245502541), ('closing', 0.8415054799536676), ('find', 0.8353685627545521)]
Top words for pretrained_BERT neuron indx 538 [('minutes', 1.0), ('def', 0.8457911493218765), ('target', 0.7884895619561261), ('entity', 0.6974890279776486), ('port', 0.6843029110146801)]
Top words for pretrained_BERT neuron indx 4636 [('host', 1.0), ('requests', 0.9340942712750905), ('error', 0.9279234008146868), ('loads', 0.9250338363613096), ('fcs', 0.8940922071970754)]
Top words for pretrained_BERT neuron indx 8733 [('log', 1.0), ('400', 0.8348864798973814), ('5', 0.7989731176659037), ('7', 0.7683306032556336), ('zone', 0.7314758315841444)]
Top words for pretrained_BERT neuron indx 2592 [('state', 1.0), ('npos', 0.9399012759884257), ('class', 0.9206230624797556), ('common', 0.8653633829980814), ('stanza', 0.8616594015788034)]
Top words for pretrained_BERT neuron indx 551 [('calendar', 1.0), ('result', 0.9543682976506548), ('push', 0.9408569260080213), ('add', 0.8976392580838572), ('pop', 0.8234582553737104)]
Top words for pretrained_BERT neuron indx 8755 [('4', 1.0), ('"r"', 0.9864940368023333), ('""', 0.9859099291960232), ('loads', 0.9202799947354003), ('log', 0.9163645369108611)]
Top words for pretrained_BERT neuron indx 2612 [('and', 1.0), ('in', 0.9235152523625362), ('is', 0.9101227245249192), ('with', 0.7949423830942748), ('as', 0.7944057375277966)]
Top words for pretrained_BERT neuron indx 566 [('break', 1.0), ('Exception', 0.7155481358239871), ('pass', 0.7092714503826708), ('presence', 0.6860002446910849), ('save', 0.6513670592329777)]
Top words for pretrained_BERT neuron indx 6711 [('9', 1.0), ('8000', 0.8753130631889654), ('servers', 0.8497640002855393), ('20000', 0.8361127492006604), ('authorization', 0.8242696898145123)]
Top words for pretrained_BERT neuron indx 8767 [('is', 1.0), ('HorizontalBillboard', 0.9152099199516346), ('VerticalBillboard', 0.9077479847556048), ('for', 0.8820919875687178), ('future', 0.8442379268891774)]
Top words for pretrained_BERT neuron indx 583 [('horizon', 1.0), ('Exception', 0.974558538581688), ('count', 0.9311320637802605), ('action', 0.8537849045614408), ('enclosure', 0.795919299709174)]
Top words for pretrained_BERT neuron indx 4679 [('link', 1.0), ('Unauthorized', 0.9579084415265894), ('find', 0.9321592334695217), ('uss', 0.9312568824202916), ('objects', 0.9307203097707283)]
Top words for pretrained_BERT neuron indx 6729 [('put', 1.0), ('loads', 0.9525468094444468), ('root', 0.8860551734977816), ('get', 0.844536960272115), ('type', 0.8308669768441531)]
Top words for pretrained_BERT neuron indx 6732 [('sorted', 1.0), ('replace', 0.9452914594678273), ('utc', 0.9396539460543722), ('future', 0.9153174379035811), ('List', 0.9098976548899332)]
Top words for pretrained_BERT neuron indx 8787 [('to', 1.0), ('86400', 0.773092212200443), ('action', 0.7600212634012818), ('mesh1', 0.7585528097112595), ('epoch_milliseconds', 0.7354558305897869)]
Top words for pretrained_BERT neuron indx 4692 [('is', 1.0), ('E', 0.9473978618742539), ('with', 0.9432346934324138), ('secs', 0.9244554051025792), ('f', 0.9145571366766284)]
Top words for pretrained_BERT neuron indx 8793 [('7', 1.0), ('secs', 0.8350161965365648), ('8', 0.8179571841820937), ('i', 0.7868062730248352), ('all', 0.7846159608528552)]
Top words for pretrained_BERT neuron indx 604 [('material', 1.0), ('setup', 0.9782838864723102), ('enclosure', 0.9758360062361268), ('seconds', 0.9398226363663833), ('parent', 0.8379518955498847)]
Top words for pretrained_BERT neuron indx 2654 [('unicode', 1.0), ('all', 0.8111786304666839), ('digest', 0.8090130251435138), ('calendar', 0.7583492767909225), ('Digest', 0.7463173803835087)]
Top words for pretrained_BERT neuron indx 8806 [('exceptions', 1.0), ('parts', 0.8989198423455884), ('part', 0.8942496184772591), ('material', 0.8431986595401686), ('False', 0.8400341620795323)]
Top words for pretrained_BERT neuron indx 4714 [('oslo', 1.0), ('1800', 0.742127793058138), ('models', 0.7373758126067397), ('16', 0.7368489511696625), ('15', 0.7217089867883555)]
Top words for pretrained_BERT neuron indx 8812 [('created', 1.0), ('nargs', 0.9538069663429948), ('boot', 0.9365865632761308), ('6', 0.9238251864551607), ('8', 0.8987059946927045)]
Top words for pretrained_BERT neuron indx 621 [('core', 1.0), ('session', 0.8579959810710661), ('parts', 0.8539301797924688), ('Session', 0.8481068195529344), ('rpc', 0.6983198222890095)]
Top words for pretrained_BERT neuron indx 620 [('render', 1.0), ('resource', 0.7057031754079115), ('result', 0.6914933347295272), ('False', 0.6885083190150552), ('seek', 0.6688162695290023)]
Top words for pretrained_BERT neuron indx 8815 [('".."', 1.0), ('with', 0.8780503362650398), ('"oslo"', 0.8595230948538113), ('"purpose"', 0.8243639246969662), ('horizon', 0.8088652919352229)]
Top words for pretrained_BERT neuron indx 624 [('info', 1.0), ('division', 0.8518671393129603), ('route', 0.7233564742039141), ('day', 0.7000484883134449), ('required', 0.6760066943835624)]
Top words for pretrained_BERT neuron indx 627 [('operand', 1.0), ('filter', 0.9931958270038126), ('closing', 0.9142029782121136), ('traceback', 0.8439122389541283), ('project', 0.8222172241806855)]
Top words for pretrained_BERT neuron indx 4724 [('exceptions', 1.0), ('settings', 0.8921797098299112), ('24', 0.8671741784412502), ('models', 0.7572170617562993), ('text', 0.7177890464531669)]
Top words for pretrained_BERT neuron indx 633 [('common', 1.0), ('child', 0.9528641941353128), ('title', 0.9166934594231262), ('line', 0.7075932644190812), ('print', 0.6622632857807257)]
Top words for pretrained_BERT neuron indx 4731 [('30', 1.0), ('loads', 0.94773919568242), ('mins', 0.9368557374060387), ('long', 0.9107380703421316), ('1', 0.8974085867172733)]
Top words for pretrained_BERT neuron indx 636 [('Stretch', 1.0), ('True', 0.9643896717386262), ('modes', 0.9418147660542869), ('boardname', 0.9299821485031622), ('push', 0.9249221266832806)]
Top words for pretrained_BERT neuron indx 6780 [('horizon', 1.0), ('Register', 0.9283689475083433), ('dt', 0.8743667413891598), ('Stretch', 0.8537064761810615), ('True', 0.818337970882586)]
Top words for pretrained_BERT neuron indx 2689 [('seek', 1.0), ('proxy', 0.7671833926825871), ('put', 0.754600185271734), ('filters', 0.7387781199960056), ('0', 0.6961565287839245)]
Top words for pretrained_BERT neuron indx 2690 [('Library', 1.0), ('i', 0.9392611443353696), ('dict', 0.8173982983130103), ('E', 0.8099229914679796), ('eg', 0.8061975117057739)]
Top words for pretrained_BERT neuron indx 8838 [('"r"', 1.0), ('config', 0.9689632202163585), ('"Name"', 0.9479112903460966), ('0', 0.913275743445353), ('4', 0.847768791188758)]
Top words for pretrained_BERT neuron indx 8845 [('end', 1.0), ('hour', 0.7757265271487149), ('long', 0.7001465641741705), ('task', 0.6940630458703907), ('6', 0.6463401580162473)]
Top words for pretrained_BERT neuron indx 6797 [('pdb', 1.0), ('9', 0.9928044087523453), ('blocking', 0.8480204026351259), ('continue', 0.7525476803383704), ('if', 0.7336042297464841)]
Top words for pretrained_BERT neuron indx 4751 [('patch', 1.0), ('long', 0.9776778507466204), ('Unauthorized', 0.9507259442077591), ('materials', 0.93500617380065), ('authentication', 0.9176273197572176)]
Top words for pretrained_BERT neuron indx 8848 [('m', 1.0), ('s', 0.9368849093636661), ('f', 0.9311602834181808), ('models', 0.9124615610914297), ('i', 0.8286391250821052)]
Top words for pretrained_BERT neuron indx 655 [('baseline', 1.0), ('division', 0.7886499683438569), ('v', 0.7720019331962928), ('logging', 0.7592610209532563), ('month', 0.7526927788876101)]
Top words for pretrained_BERT neuron indx 8852 [('with', 1.0), ('nsanetime', 0.8481446578378066), ('YoungestInFront', 0.8330770896222165), ('NetworkProfileTab', 0.8138273204605575), ('sorted', 0.8063739499816405)]
Top words for pretrained_BERT neuron indx 8855 [('list', 1.0), ('requests', 0.9882856972758364), ('META', 0.9429475148501176), ('1', 0.9037745045752488), ('store', 0.8665086252954627)]
Top words for pretrained_BERT neuron indx 2711 [('META', 1.0), ('loads', 0.8664151898266317), ('not', 0.81942882487531), ('enabled', 0.7547547816494408), ('bind', 0.7516960944798535)]
Top words for pretrained_BERT neuron indx 2715 [('push', 1.0), ('blocking', 0.9400774224137327), ('models', 0.9344312836448309), ('field', 0.8943878466137398), ('server', 0.8937050001582173)]
Top words for pretrained_BERT neuron indx 672 [('seek', 1.0), ('horizon', 0.9052082017429929), ('len', 0.8992393018015726), ('bind', 0.8966234424341889), ('resource', 0.8962760858287291)]
Top words for pretrained_BERT neuron indx 8867 [('if', 1.0), ('except', 0.8530577412489061), ('Tab', 0.7867558122469417), ('post', 0.7491751667155039), ('oslo', 0.7104660656406204)]
Top words for pretrained_BERT neuron indx 6821 [('META', 1.0), ('5', 0.9556431375345055), ('if', 0.9032977140915407), ('Mesh', 0.7746402456912173), ('description', 0.7738393797876914)]
Top words for pretrained_BERT neuron indx 678 [('baseline', 1.0), ('store', 0.875193643074653), ('log', 0.6789670427772971), ('Billboard', 0.671552466854405), ('scope', 0.6288437132950888)]
Top words for pretrained_BERT neuron indx 677 [('month', 1.0), ('script', 0.9774166054369664), ('format', 0.8791344661227792), ('raise', 0.8790650013562795), ('E', 0.8015987714296584)]
Top words for pretrained_BERT neuron indx 2726 [('required', 1.0), ('reactor', 0.9476664796785937), ('count', 0.9255406355385011), ('12', 0.8876683301097632), ('14', 0.8838634126229669)]
Top words for pretrained_BERT neuron indx 6825 [('created', 1.0), ('80', 0.9923212719563598), ('pdb', 0.9139878982895548), ('authentication', 0.9003932003515596), ('token', 0.8696808801399057)]
Top words for pretrained_BERT neuron indx 2731 [('Exception', 1.0), ('sts', 0.9507923603346816), ('task', 0.9132332003728882), ('main', 0.9030574239599031), ('continue', 0.8952915908243209)]
Top words for pretrained_BERT neuron indx 2745 [('9', 1.0), ('body', 0.9267695649081171), ('6', 0.8956778138688269), ('root', 0.8548457392189287), ('600', 0.8347997076319661)]
Top words for pretrained_BERT neuron indx 2748 [('hpov', 1.0), ('required', 0.9833782725535491), ('hour', 0.96545540430221), ('break', 0.9551248643641549), ('id', 0.9141439024421621)]
Top words for pretrained_BERT neuron indx 706 [('Library', 1.0), ('log', 0.9751075701679729), ('context', 0.8663909677143549), ('close', 0.8482841214610712), ('Log', 0.8345944827674621)]
Top words for pretrained_BERT neuron indx 2755 [('render', 1.0), ('template', 0.9946105819727502), ('mtime', 0.9527676316024523), ('NoPerm', 0.9415627202361125), ('Tab', 0.876680210173612)]
Top words for pretrained_BERT neuron indx 709 [('authentication', 1.0), ('Unauthorized', 0.9947471288204675), ('authorized', 0.992602718683526), ('match', 0.9401718703902866), ('print', 0.8549401245401659)]
Top words for pretrained_BERT neuron indx 8901 [('32', 1.0), ('META', 0.9328557650466842), ('20', 0.8615584604480379), ('800', 0.8594602637656475), ('NotFound', 0.8575603120057473)]
Top words for pretrained_BERT neuron indx 6856 [('enum', 1.0), ('14', 0.9682947189422774), ('0', 0.9255479063226941), ('9', 0.8703163646062716), ('40', 0.8669104815518461)]
Top words for pretrained_BERT neuron indx 715 [('settings', 1.0), ('0', 0.7201015594186205), ('minute', 0.7061828621893123), ('authorized', 0.6556288542354446), ('message', 0.6431201664861613)]
Top words for pretrained_BERT neuron indx 6867 [('Off', 1.0), ('store', 0.8905277320613573), ('fcs', 0.8723502405251149), ('end', 0.8608037504108862), ('config', 0.8411493964049296)]
Top words for pretrained_BERT neuron indx 6870 [('while', 1.0), ('blocking', 0.7884803254480099), ('except', 0.7744432409277181), ('7', 0.7636382324935104), ('wait', 0.7484732486363579)]
Top words for pretrained_BERT neuron indx 726 [('count', 1.0), ('close', 0.9975396837972607), ('def', 0.8005438775325308), ('info', 0.748460195824752), ('Node', 0.736778999979279)]
Top words for pretrained_BERT neuron indx 4826 [('replace', 1.0), ('objects', 0.9632541465675002), ('component', 0.9617625329829574), ('MAXCLUB', 0.9596276503785655), ('required', 0.8789569805365771)]
Top words for pretrained_BERT neuron indx 8924 [('minutes', 1.0), ('80', 0.8545078415677299), ('v', 0.8259540211310659), ('secs', 0.8096205841170199), ('millis', 0.8087197751802205)]
Top words for pretrained_BERT neuron indx 2782 [('uss', 1.0), ('Node', 0.8890792147240882), ('name', 0.8544823009667403), ('NoPerm', 0.838428970812278), ('setup', 0.836822450753372)]
Top words for pretrained_BERT neuron indx 4834 [('seconds', 1.0), ('Stretch', 0.9801970850989263), ('Mesh', 0.9521455611122568), ('project', 0.9250144289040902), ('while', 0.8680077249313434)]
Top words for pretrained_BERT neuron indx 6885 [('month', 1.0), ('12', 0.9813611630473061), ('day', 0.9270257196191304), ('wait', 0.9067434867901286), ('year', 0.9050677237290485)]
Top words for pretrained_BERT neuron indx 4842 [('Off', 1.0), ('push', 0.9703328570032861), ('description', 0.9526284755797689), ('seconds', 0.9252573521325856), ('class', 0.9129079695039051)]
Top words for pretrained_BERT neuron indx 4843 [('e', 1.0), ('m', 0.9519123529850816), ('Node', 0.9284686662182212), ('calendar', 0.8958723098448174), ('E', 0.8619647283229547)]
Top words for pretrained_BERT neuron indx 759 [('exceptions', 1.0), ('zone', 0.841643059115488), ('Unauthorized', 0.8332315541939056), ('class', 0.8259943631587083), ('Exception', 0.7962151173036638)]
Top words for pretrained_BERT neuron indx 6908 [('calendar', 1.0), ('wait', 0.9196744042093231), ('component', 0.8943389857866916), ('contents', 0.8681927770996507), ('zone', 0.8502918109779354)]
Top words for pretrained_BERT neuron indx 8968 [('pop', 1.0), ('count', 0.7470079692614202), ('128', 0.7291155688118424), ('80', 0.7128913549196539), ('"oslo"', 0.7092786133949809)]
Top words for pretrained_BERT neuron indx 6926 [('force', 1.0), ('Off', 0.8120931695167226), ('8', 0.7900787112094715), ('all', 0.7819593379011948), ('open', 0.7725345299440239)]
Top words for pretrained_BERT neuron indx 8974 [('META', 1.0), ('with', 0.8918746007734331), ('not', 0.8676445574897786), ('except', 0.8492600292343382), ('stanza', 0.8083115800493945)]
Top words for pretrained_BERT neuron indx 8976 [('400', 1.0), ('128', 0.9200521381165105), ('0', 0.8790703674376202), ('project', 0.8554410614773684), ('__copyright__', 0.8323119276295735)]
Top words for pretrained_BERT neuron indx 2833 [('hour', 1.0), ('minute', 0.9636645381215823), ('day', 0.947524377443752), ('month', 0.8544910998555804), ('ping', 0.8067139655862847)]
Top words for pretrained_BERT neuron indx 6930 [('log', 1.0), ('second', 0.8900666899870354), ('Simple', 0.8899310795569303), ('port', 0.8432683702206888), ('range', 0.8148524921834079)]
Top words for pretrained_BERT neuron indx 8989 [('resource', 1.0), ('horizon', 0.8990372212589566), ('to', 0.8983290646949891), ('STEAL_AFTER_SEEN', 0.8787046696158014), ('created', 0.7896070279218708)]
Top words for pretrained_BERT neuron indx 6942 [('future', 1.0), ('os', 0.9209322721591803), ('action', 0.9202841015987135), ('boot', 0.9035989593516423), ('second', 0.8932006931854265)]
Top words for pretrained_BERT neuron indx 808 [('upper', 1.0), ('materials', 0.8464331047719686), ('body', 0.7737884661081675), ('second', 0.7576293015391601), ('def', 0.7489661813497599)]
Top words for pretrained_BERT neuron indx 9007 [('9', 1.0), ('Off', 0.68962715621564), ('uss', 0.6280193528835797), ('6', 0.5950511179940766), ('replace', 0.594767553061048)]
Top words for pretrained_BERT neuron indx 2864 [('pop', 1.0), ('authorization', 0.9241575712548606), ('body', 0.9133711763666288), ('direct', 0.896594623264606), ('year', 0.8832112833257667)]
Top words for pretrained_BERT neuron indx 4916 [('with', 1.0), ('is', 0.9005772618316399), ('and', 0.833678304920813), ('as', 0.8139470003487391), ('in', 0.8012346571608824)]
Top words for pretrained_BERT neuron indx 9013 [('day', 1.0), ('v', 0.9808368400971567), ('absolute_import', 0.9245034254815165), ('pop', 0.8856172129612659), ('hour', 0.8818059739071179)]
Top words for pretrained_BERT neuron indx 830 [('15', 1.0), ('oslo', 0.9605362426415064), ('store', 0.9579739795349465), ('millis', 0.9399937793863545), ('contents', 0.9276117401209923)]
Top words for pretrained_BERT neuron indx 9023 [('else', 1.0), ('while', 0.9595319061418608), ('or', 0.8851943735875537), ('17', 0.8008555120188304), ('put', 0.7913602837377139)]
Top words for pretrained_BERT neuron indx 2880 [('slug', 1.0), ('sorted', 0.9852373176109678), ('20', 0.9387416708360807), ('count', 0.9266188997946431), ('vCard', 0.8531575951856203)]
Top words for pretrained_BERT neuron indx 2887 [('Exception', 1.0), ('Distance', 0.5967145698895314), ('message', 0.5883586283141307), ('View', 0.5702590015637974), ('break', 0.5655576068955879)]
Top words for pretrained_BERT neuron indx 4936 [('post', 1.0), ('9', 0.9298803913775214), ('future', 0.8572441604999741), ('False', 0.8229661602484272), ('default', 0.8186486973171301)]
Top words for pretrained_BERT neuron indx 9033 [('bare', 1.0), ('5', 0.9704223920872895), ('put', 0.9375826174971035), ('oslo', 0.9139816999061353), ('hasattr', 0.8559900569704535)]
Top words for pretrained_BERT neuron indx 4939 [('On', 1.0), ('List', 0.745785289393707), ('verbatim', 0.7234964909597488), ('required', 0.7107645699975222), ('Mesh', 0.6765182039818173)]
Top words for pretrained_BERT neuron indx 9041 [('objects', 1.0), ('Mesh', 0.9055236165678089), ('purpose', 0.8368460382050311), ('Log', 0.8244639471094921), ('Distance', 0.8002391660496487)]
Top words for pretrained_BERT neuron indx 6996 [('script', 1.0), ('except', 0.9702256966421239), ('with', 0.9286553041390376), ('tokens', 0.8885979577351797), ('str', 0.7835377709256991)]
Top words for pretrained_BERT neuron indx 6997 [('in', 1.0), ('seconds', 0.7466158521801465), ('minutes', 0.6809209149934168), ('objects', 0.6485318813836071), ('E', 0.625106045412419)]
Top words for pretrained_BERT neuron indx 7003 [('META', 1.0), ('ms', 0.6614624290733845), ('probe', 0.6227037220424265), ('raise', 0.6103411427227927), ('Tab', 0.5965217381882875)]
Top words for pretrained_BERT neuron indx 4963 [('sans', 1.0), ('other', 0.9276701075082324), ('6', 0.9050366021909125), ('default', 0.8737782093914215), ('else', 0.8122440334123056)]
Top words for pretrained_BERT neuron indx 9071 [('core', 1.0), ('to', 0.726696336783791), ('__future__', 0.6828805873240759), ('8', 0.6820860352404473), ('constants', 0.6584317146670384)]
Top words for pretrained_BERT neuron indx 4979 [('match', 1.0), ('digest', 0.9381012339769015), ('Log', 0.9364003010430432), ('len', 0.9347902682856934), ('9', 0.9094604182505205)]
Top words for pretrained_BERT neuron indx 885 [('join', 1.0), ('minute', 0.9958008467348918), ('server', 0.8929181213696659), ('servers', 0.8798781442193928), ('closing', 0.8402651455450304)]
Top words for pretrained_BERT neuron indx 7035 [('mins', 1.0), ('minutes', 0.8428794229557027), ('seconds', 0.7527847214627017), ('millis', 0.7146744030279286), ('secs', 0.7124283470935829)]
Top words for pretrained_BERT neuron indx 897 [('False', 1.0), ('start', 0.9756003538552216), ('seconds', 0.9538233999804926), ('materials', 0.9436655027183304), ('import', 0.8632881621467546)]
Top words for pretrained_BERT neuron indx 4993 [('encode', 1.0), ('seek', 0.9996109112639433), ('except', 0.9043053716409097), ('filter', 0.8905077489070118), ('end', 0.8657535811864451)]
Top words for pretrained_BERT neuron indx 5006 [('ping', 1.0), ('Register', 0.9911824044907865), ('Simple', 0.9899920292944254), ('1000', 0.9754481661554391), ('pop', 0.9614976036366408)]
Top words for pretrained_BERT neuron indx 911 [('body', 1.0), ('reactor', 0.9370576098799548), ('patch', 0.8753992143412624), ('format', 0.8337391181037289), ('dt', 0.8332704862450121)]
Top words for pretrained_BERT neuron indx 2960 [('group', 1.0), ('On', 0.8849415184255693), ('except', 0.6891035127837895), ('tag', 0.6847590448076167), ('default', 0.6699370990294253)]
Top words for pretrained_BERT neuron indx 5015 [('enabled', 1.0), ('GET', 0.8846101293857712), ('loads', 0.8809147443329731), ('requests', 0.8089737313032593), ('bind', 0.8059852308414887)]
Top words for pretrained_BERT neuron indx 9116 [('7', 1.0), ('baseline', 0.862601439987613), ('9', 0.851843683065092), ('entity', 0.775086211731512), ('17', 0.737627788148059)]
Top words for pretrained_BERT neuron indx 9118 [('requests', 1.0), ('List', 0.7665492518866835), ('ShadowsOnly', 0.626089172693208), ('View', 0.6074303580237843), ('Mesh', 0.5969725814239082)]
Top words for pretrained_BERT neuron indx 9119 [('bare', 1.0), ('uss', 0.6538366269165932), ('Post', 0.610115999769837), ('encode', 0.5932320943290474), ('e', 0.5796515360094453)]
Top words for pretrained_BERT neuron indx 5024 [('80', 1.0), ('target', 0.9575048012142303), ('32', 0.957348450727865), ('40', 0.9220477024132487), ('60', 0.889027031825846)]
Top words for pretrained_BERT neuron indx 9123 [('k', 1.0), ('v', 0.9816368400995561), ('second', 0.9254190017365176), ('continue', 0.8485647247947707), ('partition', 0.8201827056244287)]
Top words for pretrained_BERT neuron indx 931 [('choices', 1.0), ('requests', 0.8828966692707916), ('tag', 0.8479677963255371), ('body', 0.8444860465173092), ('oslo', 0.8427423181719019)]
Top words for pretrained_BERT neuron indx 9125 [('META', 1.0), ('if', 0.8260026115289699), ('5', 0.7978705940541384), ('with', 0.7373166749859236), ('except', 0.7181854120255851)]
Top words for pretrained_BERT neuron indx 2981 [('raise', 1.0), ('META', 0.9779728465957498), ('description', 0.8910816818344561), ('id', 0.8745435557570488), ('super', 0.8386571351603513)]
Top words for pretrained_BERT neuron indx 9129 [('META', 1.0), ('enclosure', 0.9518525368165103), ('80', 0.9072766721495593), ('token', 0.8812865457357232), ('purpose', 0.8746525017789802)]
Top words for pretrained_BERT neuron indx 7082 [('minutes', 1.0), ('force', 0.6909757626783627), ('E', 0.6743044155502885), ('mins', 0.6462341878834714), ('max', 0.6181126076831716)]
Top words for pretrained_BERT neuron indx 940 [('proxy', 1.0), ('component', 0.9856852891282157), ('type', 0.9271152672096424), ('features', 0.9137366407462716), ('add', 0.8664853468327695)]
Top words for pretrained_BERT neuron indx 2990 [('0', 1.0), ('800', 0.933612311768302), ('5', 0.9018024927779126), ('or', 0.8794745062254441), ('True', 0.8681354899389531)]
Top words for pretrained_BERT neuron indx 5044 [('main', 1.0), ('On', 0.9215822358672805), ('utc', 0.8707365448539877), ('zone', 0.8321627229742371), ('purpose', 0.7910398076629637)]
Top words for pretrained_BERT neuron indx 958 [('1', 1.0), ('authorization', 0.9154589783868614), ('Off', 0.9006642690393686), ('patch', 0.889709469457556), ('2', 0.8796526175320777)]
Top words for pretrained_BERT neuron indx 961 [('except', 1.0), ('errors', 0.9760820147539591), ('object', 0.9134770909739846), ('path', 0.8605298224594969), ('tag', 0.8473326293576583)]
Top words for pretrained_BERT neuron indx 7107 [('24', 1.0), ('VerticalBillboard', 0.9869132293968863), ('component', 0.979955265800505), ('MAXBOARD', 0.9685849761365878), ('HorizontalBillboard', 0.9501927915426205)]
Top words for pretrained_BERT neuron indx 9155 [('32', 1.0), ('80', 0.8838119019772118), ('and', 0.8536546776833353), ('ntime', 0.819418310129213), ('nsanetime', 0.8138822044490972)]
Top words for pretrained_BERT neuron indx 7115 [('__name__', 1.0), ('super', 0.9417776164977202), ('600', 0.9343394572756442), ('__version__', 0.8888802312170838), ('1024', 0.8850257032140918)]
Top words for pretrained_BERT neuron indx 971 [('hour', 1.0), ('400', 0.8848994226253485), ('parts', 0.8627872075432733), ('Post', 0.8215640127114913), ('prange', 0.8125512861209991)]
Top words for pretrained_BERT neuron indx 7119 [('with', 1.0), ('closing', 0.8695533466183276), ('seek', 0.827215997883331), ('17', 0.8099721609820282), ('log', 0.7848851446545628)]
Top words for pretrained_BERT neuron indx 3023 [('parts', 1.0), ('part', 0.8377708347093871), ('None', 0.83229238611115), ('closing', 0.732582374393002), ('open', 0.7146808703773497)]
Top words for pretrained_BERT neuron indx 9167 [('9', 1.0), ('1000', 0.9156110033016629), ('oslo', 0.9074136500747133), ('128', 0.8696515220629527), ('600', 0.8278865391274809)]
Top words for pretrained_BERT neuron indx 7123 [('stanza', 1.0), ('try', 0.9849438273629261), ('sans', 0.9742921060641513), ('repr', 0.9650710037701948), ('9', 0.9536801864860266)]
Top words for pretrained_BERT neuron indx 7125 [('or', 1.0), ('if', 0.9964976245452536), ('save', 0.996238034289884), ('description', 0.9411962583442756), ('prange', 0.904783615775751)]
Top words for pretrained_BERT neuron indx 7127 [('or', 1.0), ('if', 0.8961856991708897), ('request', 0.8022619553012545), ('openstack', 0.7709104889234921), ('proxy', 0.7455293858013327)]
Top words for pretrained_BERT neuron indx 7138 [('Stretch', 1.0), ('Mesh', 0.8765497338973901), ('Distance', 0.871818037058897), ('On', 0.7977451939638821), ('mesh', 0.7894715011875896)]
Top words for pretrained_BERT neuron indx 5094 [('millis', 1.0), ('types', 0.9960505638496817), ('context', 0.9464532172202536), ('type', 0.9391815006355909), ('common', 0.9390535558084234)]
Top words for pretrained_BERT neuron indx 7146 [('Off', 1.0), ('minutes', 0.9785628619863269), ('class', 0.8975368293875816), ('to', 0.853463037452035), ('On', 0.8345336191169409)]
Top words for pretrained_BERT neuron indx 1003 [('View', 1.0), ('alt', 0.9536682435751411), ('tag', 0.9008051101694553), ('from', 0.8727032074717465), ('m', 0.8517870596557793)]
Top words for pretrained_BERT neuron indx 1008 [('boot', 1.0), ('break', 0.9686906179992588), ('sans', 0.9173279178835302), ('400', 0.8895847749421031), ('scope', 0.8872239283885708)]
Top words for pretrained_BERT neuron indx 7177 [('upper', 1.0), ('1800', 0.9019797959713574), ('timezone', 0.8056148172087082), ('Unauthorized', 0.7984372983115361), ('in', 0.792536867630365)]
Top words for pretrained_BERT neuron indx 9229 [('decode', 1.0), ('millis', 0.9881741020438678), ('ref', 0.9049025707320723), ('proxy', 0.8971514503290464), ('7', 0.8968794245129682)]
Top words for pretrained_BERT neuron indx 7191 [('all', 1.0), ('long', 0.9770634537807116), ('session', 0.9430263588179583), ('Session', 0.9212031488039782), ('ref', 0.8264965842155667)]
Top words for pretrained_BERT neuron indx 9246 [('future', 1.0), ('os', 0.711460001703143), ('Log', 0.6722939654591407), ('action', 0.66927665576337), ('View', 0.6519143232492488)]
Top words for pretrained_BERT neuron indx 9247 [('i', 1.0), ('exceptions', 0.9746952138772994), ('identity', 0.7583272400764944), ('17', 0.7135009509118154), ('pxe', 0.6921847238099502)]
Top words for pretrained_BERT neuron indx 9256 [('9', 1.0), ('40', 0.7964303714752963), ('60', 0.7497644820463677), ('server', 0.7429341434062299), ('to', 0.6632061871024867)]
Top words for pretrained_BERT neuron indx 7218 [('E', 1.0), ('and', 0.9368099829503418), ('400', 0.9159829457968776), ('1000', 0.9115606114607797), ('dict', 0.8821621699426591)]
Top words for pretrained_BERT neuron indx 1075 [('loads', 1.0), ('close', 0.8435099381354231), ('day', 0.6632784079115938), ('common', 0.6510762335720989), ('k', 0.6452560679824556)]
Top words for pretrained_BERT neuron indx 7220 [('Billboard', 1.0), ('int', 0.7585172569675563), ('unicode', 0.7214355103773448), ('HorizontalBillboard', 0.7124420245666806), ('VerticalBillboard', 0.6688631913043861)]
Top words for pretrained_BERT neuron indx 1078 [('strip', 1.0), ('Distance', 0.8747494538484043), ('common', 0.813750616085083), ('val', 0.8058968155877505), ('Billboard', 0.7577501799990519)]
Top words for pretrained_BERT neuron indx 5184 [('minutes', 1.0), ('def', 0.9956873417281923), ('count', 0.9380803091881691), ('vCard', 0.9294643680011286), ('slug', 0.8924351334298882)]
Top words for pretrained_BERT neuron indx 5188 [('k', 1.0), ('stanza', 0.7780941080138636), ('300', 0.7563605249262481), ('if', 0.720660583013832), ('kls', 0.6761822359346512)]
Top words for pretrained_BERT neuron indx 3143 [('link', 1.0), ('800', 0.9009951826412436), ('objects', 0.8726351256024113), ('find', 0.8221400019161718), ('open', 0.807540504162023)]
Top words for pretrained_BERT neuron indx 5193 [('bare', 1.0), ('read', 0.8127912382745108), ('loads', 0.7916034409901446), ('5', 0.7280466627319778), ('port', 0.721136228705534)]
Top words for pretrained_BERT neuron indx 1101 [('GET', 1.0), ('day', 0.9993303454230943), ('get', 0.9904945390846615), ('other', 0.9619576600572441), ('v', 0.9488540808695562)]
Top words for pretrained_BERT neuron indx 7251 [('to', 1.0), ('e', 0.9537395031596488), ('group', 0.9420291832547896), ('View', 0.9309111915432666), ('recv', 0.8901325461998228)]
Top words for pretrained_BERT neuron indx 9300 [('VerticalBillboard', 1.0), ('post', 0.995255885860211), ('milliseconds', 0.9586132362702255), ('tokens', 0.9569128633487841), ('\\\'"\\\'', 0.9556813825376675)]
Top words for pretrained_BERT neuron indx 7263 [('32', 1.0), ('80', 0.8787113125106789), ('3', 0.8770519479075617), ('30', 0.8593247872739098), ('write', 0.8411085405200541)]
Top words for pretrained_BERT neuron indx 7266 [('template', 1.0), ('contents', 0.9862088605477194), ('try', 0.8727911191354047), ('__name__', 0.8160109090246875), ('context', 0.7999502636112279)]
Top words for pretrained_BERT neuron indx 1123 [('Stretch', 1.0), ('materials', 0.8538508810717284), ('domain', 0.7570054109660117), ('12', 0.7519091841849909), ('60', 0.7140162648110295)]
Top words for pretrained_BERT neuron indx 7267 [('60', 1.0), ('error', 0.9767151191612066), ('6', 0.9366881591016517), ('alt', 0.9363980104736216), ('sans', 0.9195569171792388)]
Top words for pretrained_BERT neuron indx 9322 [('17', 1.0), ('1', 0.9881390881723506), ('1800', 0.8121736839198184), ('3', 0.7924793741049916), ('3700', 0.7835753227725828)]
Top words for pretrained_BERT neuron indx 3179 [('600', 1.0), ('20', 0.9227613400565658), ('60', 0.8878992256299112), ('activity', 0.8280645762649759), ('5', 0.7701236029908967)]
Top words for pretrained_BERT neuron indx 3181 [('5', 1.0), ('id', 0.9248283258684186), ('tokens', 0.9016610507225401), ('to', 0.864957169181829), ('title', 0.8261302610475675)]
Top words for pretrained_BERT neuron indx 9326 [('80', 1.0), ('1800', 0.8948403762085356), ('800', 0.88941839663169), ('17', 0.8818690477790825), ('core', 0.8484777405104155)]
Top words for pretrained_BERT neuron indx 7279 [('Mesh', 1.0), ('".."', 0.9875052086531677), ('PY2', 0.9798993841078892), ('8000', 0.9738973613619142), ('Simple', 0.969348391534123)]
Top words for pretrained_BERT neuron indx 9329 [('Library', 1.0), ('Node', 0.9059215358949226), ('identity', 0.8142107696488826), ('serverProfileTemplateUri', 0.7106306427636889), ('NetworkProfileTab', 0.6853526834589637)]
Top words for pretrained_BERT neuron indx 5240 [('Unauthorized', 1.0), ('oslo', 0.8905388442578879), ('end', 0.8813726729129894), ('id', 0.8777699771280336), ('ignore', 0.8716115488131193)]
Top words for pretrained_BERT neuron indx 5243 [('List', 1.0), ('os', 0.8514480380505932), ('proxy', 0.8441310919943201), ('time', 0.7843964848352449), ('list', 0.7603756349403065)]
Top words for pretrained_BERT neuron indx 1148 [('slug', 1.0), ('80', 0.7968390584005038), ('read', 0.7432413301496942), ('loads', 0.7419637869354482), ('14', 0.6834930303891318)]
Top words for pretrained_BERT neuron indx 5245 [('300', 1.0), ('30', 0.8581448164582579), ('17', 0.839223733089607), ('32', 0.7821000091480733), ('12', 0.7416050079899799)]
Top words for pretrained_BERT neuron indx 9340 [('core', 1.0), ('"happy_birthday"', 0.920051110310564), ('oslo', 0.8458277038494966), ('MAXCLUB', 0.8293845906373911), ('bind', 0.827614374088044)]
Top words for pretrained_BERT neuron indx 3198 [('Exception', 1.0), ('requests', 0.9754520090951453), ('k', 0.9505747691085764), ('put', 0.8584333513128664), ('wait', 0.8576147095896292)]
Top words for pretrained_BERT neuron indx 7296 [('7', 1.0), ('9', 0.9047907526287093), ('24', 0.8272269212703087), ('2', 0.7502755320277948), ('".."', 0.6837997772440222)]
Top words for pretrained_BERT neuron indx 1153 [('proxy', 1.0), ('filters', 0.8453550433309733), ('seek', 0.7803156660631596), ('k', 0.6950509287752384), ('parent', 0.6547940844552136)]
Top words for pretrained_BERT neuron indx 1163 [('end', 1.0), ('required', 0.8696595493698294), ('unpack', 0.8439160484643026), ('servers', 0.8292460675633808), ('ntime', 0.8243969492646953)]
Top words for pretrained_BERT neuron indx 3212 [('minutes', 1.0), ('key', 0.9110534837554741), ('authorized', 0.8507554621985842), ('seconds', 0.8426347226997201), ('uss', 0.779684833731483)]
Top words for pretrained_BERT neuron indx 7309 [('end', 1.0), ('core', 0.8902212587571143), ('not', 0.8640133434792894), ('context', 0.7998934262963798), ('7', 0.7937324683774013)]
Top words for pretrained_BERT neuron indx 5261 [('enabled', 1.0), ('baseline', 0.9540232597070994), ('9', 0.9350615183622162), ('Distance', 0.8336618351222345), ('hour', 0.8079540158773734)]
Top words for pretrained_BERT neuron indx 3215 [('minutes', 1.0), ('Unauthorized', 0.9984601711856564), ('authentication', 0.9284449861550548), ('patch', 0.9058498418496131), ('and', 0.8725270620305259)]
Top words for pretrained_BERT neuron indx 7312 [('models', 1.0), ('"HTTP_BEARER_TOKEN"', 0.8677637918414148), ('s', 0.8474462318457051), ('m', 0.8392100951915334), ('materials', 0.8348441349189066)]
Top words for pretrained_BERT neuron indx 7317 [('upper', 1.0), ('6', 0.8339771712423687), ('broadcast', 0.8117895104639047), ('if', 0.8071223908094598), ('created', 0.7307815237500629)]
Top words for pretrained_BERT neuron indx 7319 [('1800', 1.0), ('GET', 0.9378603615238201), ('store', 0.8769868312822612), ('1', 0.8456810865607445), ('"m_ReflectionProbeUsage"', 0.8174176557775067)]
Top words for pretrained_BERT neuron indx 9372 [('exceptions', 1.0), ('RequestContext', 0.9839918814904602), ('resource', 0.9700465005211509), ('minute', 0.8291863227623442), ('post', 0.8113693262283147)]
Top words for pretrained_BERT neuron indx 7331 [('if', 1.0), ('get_profile_available_storage_systems', 0.9197857283649599), ('get_profile_networks', 0.9152798196910444), ('with', 0.886705271850755), ('except', 0.8371665985200492)]
Top words for pretrained_BERT neuron indx 3235 [('identity', 1.0), ('strip', 0.9051324195209538), ('View', 0.8744378245871316), ('tag', 0.8421068873268894), ('e', 0.7620621485073892)]
Top words for pretrained_BERT neuron indx 5285 [('META', 1.0), ('description', 0.8538160661779151), ('if', 0.810516133453191), ('Mesh', 0.7355684968488376), ('template', 0.6531527664631913)]
Top words for pretrained_BERT neuron indx 7341 [('True', 1.0), ('created', 0.9993506711101521), ('if', 0.9648140192707688), ('day', 0.9587013679049486), ('xmpp', 0.9391452627020231)]
Top words for pretrained_BERT neuron indx 7343 [('7', 1.0), ('created', 0.9789229988541172), ('day', 0.900776671304528), ('affinity', 0.8716845709576052), ('hour', 0.849937484554668)]
Top words for pretrained_BERT neuron indx 1200 [('Billboard', 1.0), ('find', 0.8726856483542224), ('read', 0.833247536239078), ('loads', 0.8143511169639435), ('raise', 0.8033333276590778)]
Top words for pretrained_BERT neuron indx 9394 [('save', 1.0), ('month', 0.9645789871315734), ('open', 0.9218919811046203), ('os', 0.916493640481168), ('GetItem', 0.8763429000605956)]
Top words for pretrained_BERT neuron indx 5304 [('group', 1.0), ('oslo', 0.9192385944820218), ('List', 0.8197771888671531), ('mesh', 0.786573557516161), ('2', 0.7736073881536305)]
Top words for pretrained_BERT neuron indx 1209 [('month', 1.0), ('minute', 0.8997536341164772), ('server', 0.884331223456652), ('minutes', 0.8532958786887902), ('Stretch', 0.8240495483851793)]
Top words for pretrained_BERT neuron indx 1212 [('port', 1.0), ('material', 0.9213536547420613), ('f', 0.9025363521946165), ('blocking', 0.8545527115469259), ('Tab', 0.8168011490458927)]
Top words for pretrained_BERT neuron indx 1219 [('render', 1.0), ('state', 0.9944516454801091), ('len', 0.9754299467283912), ('seek', 0.9692784784822291), ('def', 0.9489880664366186)]
Top words for pretrained_BERT neuron indx 7363 [('template', 1.0), ('seek', 0.8878095661222407), ('None', 0.8686664322162635), ('part', 0.8194032874795767), ('pxe', 0.7546755958595999)]
Top words for pretrained_BERT neuron indx 7379 [('oslo', 1.0), ('other', 0.8218730807771838), ('server', 0.7744727224291527), ('enabled', 0.7643673300198053), ('link', 0.744292464826763)]
Top words for pretrained_BERT neuron indx 7380 [('Unauthorized', 1.0), ('closing', 0.8683814764598997), ('purpose', 0.8512353135300409), ('MSG', 0.8229134775572847), ('return', 0.7801069187458327)]
Top words for pretrained_BERT neuron indx 5331 [('format', 1.0), ('tzs', 0.839041979870218), ('property', 0.8083212661048427), ('stat', 0.7961108671066385), ('core', 0.7952161324580426)]
Top words for pretrained_BERT neuron indx 5334 [('count', 1.0), ('close', 0.9664062055283432), ('while', 0.8449294463693201), ('value', 0.8287007697605958), ('log', 0.8219823839297122)]
Top words for pretrained_BERT neuron indx 7384 [('or', 1.0), ('Unauthorized', 0.992776976656103), ('seconds', 0.9075364092209679), ('purpose', 0.8444007845560764), ('try', 0.8382787096540538)]
Top words for pretrained_BERT neuron indx 1241 [('script', 1.0), ('300', 0.9166355387638849), ('year', 0.8685721812728758), ('message', 0.8662614587262183), ('day', 0.8503711303426874)]
Top words for pretrained_BERT neuron indx 9442 [('Mesh', 1.0), ('models', 0.9292157356203433), ('__copyright__', 0.9092917293087166), ('MAXCLUB', 0.8543096947825785), ('os', 0.8068642761844813)]
Top words for pretrained_BERT neuron indx 3299 [('to', 1.0), ('zone', 0.9824231095588868), ('save', 0.9725687977062228), ('Plugin', 0.919621784072022), ('secs', 0.9186383583336251)]
Top words for pretrained_BERT neuron indx 3302 [('title', 1.0), ('message', 0.8859333600601179), ('v', 0.8819934412768163), ('calendar', 0.8724767572426982), ('pass', 0.8603377640788544)]
Top words for pretrained_BERT neuron indx 9450 [('Renderer', 1.0), ('7', 0.9746858848373473), ('ms', 0.9282199668331292), ('serverProfileTemplateUri', 0.8676818780161071), ('millis', 0.8674563171519506)]
Top words for pretrained_BERT neuron indx 3307 [('calendar', 1.0), ('Library', 0.8479526192244927), ('E', 0.8217968664650466), ('Node', 0.7649726380747426), ('m', 0.7399427423166641)]
Top words for pretrained_BERT neuron indx 7402 [('300', 1.0), ('1800', 0.9336386672707986), ('800', 0.9204946757192247), ('400', 0.8397524192510825), ('3600', 0.7810868133482541)]
Top words for pretrained_BERT neuron indx 7408 [('GetMirror', 1.0), ('GetContent', 0.9450881535048127), ('".."', 0.7835607435844022), ('E', 0.7626567020288505), ('ny_dt', 0.7614534251240795)]
Top words for pretrained_BERT neuron indx 7410 [('int', 1.0), ('us', 0.8513959524575773), ('connection', 0.814804645435423), ('zone', 0.7906980503262664), ('val', 0.7617957683765674)]
Top words for pretrained_BERT neuron indx 7419 [('activity', 1.0), ('Simple', 0.8889382764119989), ('post', 0.8703696625013821), ('resource', 0.8676614587608341), ('GetUID', 0.8467948891884173)]
Top words for pretrained_BERT neuron indx 7427 [('16', 1.0), ('put', 0.9939889394271146), ('17', 0.9693514460150078), ('realpath', 0.9683714451536067), ('long', 0.9449623078366057)]
Top words for pretrained_BERT neuron indx 9477 [('oslo', 1.0), ('os', 0.9284246234680532), ('80', 0.8942871292023754), ('component', 0.7713560217332921), ('Node', 0.7187361378225868)]
Top words for pretrained_BERT neuron indx 7432 [('pop', 1.0), ('count', 0.8206061048397045), ('"oslo"', 0.7489862001076556), ('40', 0.7266923324516541), ('log', 0.7148070328263462)]
Top words for pretrained_BERT neuron indx 1296 [('ignore', 1.0), ('os', 0.9813887962510114), ('profile', 0.9780198758248768), ('root', 0.9560243078771904), ('Profile', 0.9484521652338683)]
Top words for pretrained_BERT neuron indx 1303 [('seek', 1.0), ('server', 0.7460121785491614), ('find', 0.680925160596506), ('probe', 0.6795103498355665), ('logging', 0.6491900748461737)]
Top words for pretrained_BERT neuron indx 9501 [('5', 1.0), ('6', 0.9663194307288654), ('7', 0.896409068718847), ('log', 0.7861932686111299), ('oslo', 0.7670386237217264)]
Top words for pretrained_BERT neuron indx 9502 [('Distance', 1.0), ('BoardManager', 0.9773224593953846), ('kwargs', 0.9556407655136893), ('Library', 0.939967263728733), ('else', 0.8722917068975188)]
Top words for pretrained_BERT neuron indx 3360 [('state', 1.0), ('npos', 0.9921070207770156), ('ignore', 0.8842102113960557), ('stanza', 0.8527555847870074), ('recv', 0.8517899521623836)]
Top words for pretrained_BERT neuron indx 5416 [('name', 1.0), ('9', 0.9069294916338436), ('filters', 0.8641508685961536), ('24', 0.8622014564064969), ('to', 0.8201902853626557)]
Top words for pretrained_BERT neuron indx 9517 [('match', 1.0), ('info', 0.952492294251042), ('refresh', 0.795570764316765), ('"oslo"', 0.7804587847052121), ('sanedelta', 0.7491454465583037)]
Top words for pretrained_BERT neuron indx 3379 [('loads', 1.0), ('created', 0.6254502425795783), ('max', 0.621006626408394), ('Node', 0.6198508231584823), ('find', 0.5859389403177349)]
Top words for pretrained_BERT neuron indx 1334 [('Exception', 1.0), ('pass', 0.9531866672687307), ('store', 0.9329180853435357), ('break', 0.866041922212158), ('field', 0.7472755099751983)]
Top words for pretrained_BERT neuron indx 7479 [('9', 1.0), ('servers', 0.77771251066107), ('1000', 0.7737334917443921), ('False', 0.7731980121552371), ('7', 0.7496069121452154)]
Top words for pretrained_BERT neuron indx 1338 [('len', 1.0), ('uss', 0.8362495237622227), ('baseline', 0.8149667863116283), ('us', 0.7564038809594336), ('bind', 0.7157284113969379)]
Top words for pretrained_BERT neuron indx 3387 [('with', 1.0), ('sorted', 0.8954014098841534), ('part', 0.8261727604442982), ('replace', 0.824574601951191), ('max', 0.8198570467843407)]
Top words for pretrained_BERT neuron indx 3396 [('iq', 1.0), ('minutes', 0.9641497570072797), ('affinity', 0.8868800466656035), ('connection', 0.8220037858518473), ('required', 0.7990116662742425)]
Top words for pretrained_BERT neuron indx 9540 [('iq', 1.0), ('for', 0.9848994239944986), ('link', 0.9761879514675177), ('and', 0.9457023564735039), ('E', 0.8992935710777779)]
Top words for pretrained_BERT neuron indx 7492 [('if', 1.0), ('m', 0.7413818753769824), ('error', 0.6861231030888357), ('state', 0.685244659990042), ('stanza', 0.6845348753023128)]
Top words for pretrained_BERT neuron indx 1351 [('Exception', 1.0), ('except', 0.7413088614678691), ('action', 0.7308966604464683), ('horizon', 0.7268914737844372), ('break', 0.7256321064617308)]
Top words for pretrained_BERT neuron indx 5451 [('7', 1.0), ('300', 0.977648311263551), ('month', 0.9239761750123902), ('find', 0.881881107657955), ('8', 0.8056098697044897)]
Top words for pretrained_BERT neuron indx 3403 [('identity', 1.0), ('List', 0.834960488711661), ('format', 0.8094091266282009), ('partition', 0.8069279743410324), ('META', 0.7624314382270758)]
Top words for pretrained_BERT neuron indx 7506 [('86400', 1.0), ('tzinfo', 0.9506050592962397), ('milliseconds', 0.8385893449053325), ('is', 0.7844988617911652), ('long', 0.7681426446165374)]
Top words for pretrained_BERT neuron indx 5460 [('with', 1.0), ('"Host"', 0.7320280296507736), ('except', 0.7167052991088978), ('vCard', 0.6988654455313095), ('not', 0.6812759281440123)]
Top words for pretrained_BERT neuron indx 1384 [('us', 1.0), ('pass', 0.9678748526900598), ('authorized', 0.9412775051644667), ('pooltype', 0.9243529796976063), ('Unauthorized', 0.8392368132631776)]
Top words for pretrained_BERT neuron indx 9580 [('7', 1.0), ('15', 0.9925834331062051), ('8000', 0.9481685713590092), ('6', 0.9381108948803808), ('nargs', 0.8804393331902134)]
Top words for pretrained_BERT neuron indx 5485 [('set', 1.0), ('title', 0.9764393555177104), ('boot', 0.9642027168634165), ('i', 0.9567029180995047), ('id', 0.9119537984733049)]
Top words for pretrained_BERT neuron indx 1392 [('info', 1.0), ('division', 0.9447924241555468), ('split', 0.7754786213304938), ('required', 0.7744986037643434), ('dt', 0.7660134855763655)]
Top words for pretrained_BERT neuron indx 7546 [('300', 1.0), ('800', 0.8941525939654578), ('30', 0.8559285083786429), ('80', 0.8427314085896709), ('40', 0.8332239306396518)]
Top words for pretrained_BERT neuron indx 5499 [('mins', 1.0), ('30', 0.8667760608473951), ('millis', 0.8524569021797643), ('GetMirror', 0.7967012233160792), ('long', 0.7765446455773622)]
Top words for pretrained_BERT neuron indx 1403 [('ignore', 1.0), ('add', 0.9827682588844208), ('local', 0.972687733260063), ('context', 0.9562165621543461), ('path', 0.9246575112779306)]
Top words for pretrained_BERT neuron indx 7549 [('300', 1.0), ('32', 0.8890939423924324), ('17', 0.8652946397416565), ('time', 0.8606513194579969), ('Distance', 0.8438809774349273)]
Top words for pretrained_BERT neuron indx 1404 [('push', 1.0), ('UCache', 0.9040044243250591), ('modes', 0.8454023354168431), ('True', 0.7994434569710012), ('Stretch', 0.7699812384219031)]
Top words for pretrained_BERT neuron indx 9602 [('20', 1.0), ('Distance', 0.9386705506928963), ('type', 0.81269203174492), ('40', 0.7744120135187058), ('1000', 0.7308223449179249)]
Top words for pretrained_BERT neuron indx 1415 [('day', 1.0), ('filter', 0.8947066261541265), ('item', 0.8752553091433224), ('month', 0.8622401214802099), ('View', 0.8199716106031096)]
Top words for pretrained_BERT neuron indx 1419 [('error', 1.0), ('24', 0.9399312710605698), ('match', 0.8927300075227378), ('probe', 0.8630489402764493), ('probe_anchor', 0.8443072114540469)]
Top words for pretrained_BERT neuron indx 7564 [('40', 1.0), ('Authorization', 0.9732372188537438), ('title', 0.9678428360534305), ('9', 0.9500124249100679), ('800', 0.8721945717159633)]
Top words for pretrained_BERT neuron indx 7565 [('9', 1.0), ('pdb', 0.898809531251107), ('".."', 0.8105107718106401), ('if', 0.7558750326648881), ('for', 0.6481765059543347)]
Top words for pretrained_BERT neuron indx 5518 [('sorted', 1.0), ('f', 0.8498765018141697), ('required', 0.8271849779375908), ('v', 0.754432518771131), ('to', 0.7516468993282708)]
Top words for pretrained_BERT neuron indx 5519 [('patch', 1.0), ('Unauthorized', 0.871028365357104), ('and', 0.8645463343563201), ('long', 0.8466751519051351), ('format', 0.7919211556974596)]
Top words for pretrained_BERT neuron indx 9616 [('seek', 1.0), ('method', 0.7867065391747086), ('f', 0.725135293539411), ('META', 0.7122186923608428), ('mesh2', 0.7037087972224707)]
Top words for pretrained_BERT neuron indx 1425 [('affinity', 1.0), ('host', 0.9218545008117669), ('month', 0.9187578766838166), ('E', 0.8817143373530772), ('method', 0.8725827322869533)]
Top words for pretrained_BERT neuron indx 7572 [('month', 1.0), ('get_resources', 0.7647008408403736), ('12', 0.749707677937811), ('consume_in_thread', 0.7430301668415024), ('types', 0.7362744671586484)]
Top words for pretrained_BERT neuron indx 9623 [('META', 1.0), ('store', 0.8732684093697756), ('__copyright__', 0.8690671144547568), ('component', 0.8005055978058757), ('requests', 0.7930577605782525)]
Top words for pretrained_BERT neuron indx 9625 [('PYTHON_VERSION', 1.0), ('17', 0.8933749530335244), ('version_info', 0.8933370169106964), ('800', 0.8920551389015151), ('LoadUser', 0.8907659588368007)]
Top words for pretrained_BERT neuron indx 5530 [('ref', 1.0), ('log', 0.9500385357794037), ('E', 0.8781212432698334), ('1', 0.767822171433835), ('e', 0.7183968839144578)]
Top words for pretrained_BERT neuron indx 3491 [('Tab', 1.0), ('Off', 0.8841399218750781), ('ping', 0.8703716627421506), ('wait', 0.820572933107038), ('with', 0.8146091037454303)]
Top words for pretrained_BERT neuron indx 1445 [('raise', 1.0), ('month', 0.949909930232695), ('script', 0.9022764079767837), ('root', 0.8705727742524741), ('direct', 0.7534257277126463)]
Top words for pretrained_BERT neuron indx 7589 [('META', 1.0), ('5', 0.8565079253928375), ('if', 0.8322235595127961), ('4', 0.7150839145917692), ('2', 0.6998596599005659)]
Top words for pretrained_BERT neuron indx 3494 [('14', 1.0), ('reactor', 0.9962546743572661), ('12', 0.9803206383842503), ('force', 0.9307210884981522), ('required', 0.9201890057343525)]
Top words for pretrained_BERT neuron indx 9647 [('mins', 1.0), ('On', 0.9761040451784544), ('month', 0.9468276771844691), ('hour', 0.9131021965425492), ('minutes', 0.8771347410957219)]
Top words for pretrained_BERT neuron indx 7603 [('Billboard', 1.0), ('1', 0.817300685545491), ('choices', 0.7790059557638302), ('filters', 0.7472649626125137), ('microseconds', 0.7348655326874771)]
Top words for pretrained_BERT neuron indx 7608 [('List', 1.0), ('2', 0.8957656703893049), ('7', 0.8443528124889449), ('9', 0.7680302199319123), ('domain', 0.7341100530997671)]
Top words for pretrained_BERT neuron indx 3513 [('root', 1.0), ('body', 0.9324165603191338), ('9', 0.9320309977733398), ('6', 0.9162509899061075), ('server', 0.8222300570292085)]
Top words for pretrained_BERT neuron indx 3516 [('hpov', 1.0), ('port', 0.9631664295863805), ('id', 0.9627855210423297), ('tz', 0.9505009832506285), ('required', 0.9426534583239661)]
Top words for pretrained_BERT neuron indx 7615 [('os', 1.0), ('enum', 0.9804827539435188), ('unicode', 0.8642954659780047), ('sans', 0.8273537620822936), ('ms', 0.8114666691281216)]
Top words for pretrained_BERT neuron indx 1471 [('dt', 1.0), ('os', 0.8450344379857349), ('items', 0.8406420213868426), ('val', 0.8191945959985697), ('item', 0.8129193901618386)]
Top words for pretrained_BERT neuron indx 1474 [('seconds', 1.0), ('minutes', 0.8210967944297872), ('Board', 0.8179333731904153), ('log', 0.7565590329004278), ('with', 0.7540892907774946)]
Top words for pretrained_BERT neuron indx 7621 [('tastypie', 1.0), ('type', 0.9988793666101211), ('range', 0.9460566881767296), ('7', 0.908268840824916), ('common', 0.8830983534072095)]
Top words for pretrained_BERT neuron indx 7624 [('0', 1.0), ('1', 0.9730017095168499), ('HorizontalBillboard', 0.9455630164171357), ('VerticalBillboard', 0.9377707199893524), ('MAXBOARD', 0.9230923490480046)]
Top words for pretrained_BERT neuron indx 5579 [('minutes', 1.0), ('Tab', 0.9663746746011972), ('fcsans', 0.8968280096529254), ('routes', 0.8425031619488061), ('Board', 0.8410723206076898)]
Top words for pretrained_BERT neuron indx 1483 [('settings', 1.0), ('minute', 0.7974393877561801), ('0', 0.7755969080875768), ('message', 0.6985548976055187), ('context', 0.6867998666142324)]
Top words for pretrained_BERT neuron indx 3537 [('affinity', 1.0), ('end', 0.7934832995887143), ('domain', 0.7885437076478559), ('seek', 0.7150575682745632), ('except', 0.6991088382397586)]
Top words for pretrained_BERT neuron indx 7635 [('Off', 1.0), ('upper', 0.9835977299638422), ('seek', 0.8858848622905501), ('14', 0.8653993112947344), ('end', 0.8265777701422505)]
Top words for pretrained_BERT neuron indx 7646 [('8', 1.0), ('send', 0.9601175565521026), ('parse', 0.9414230284132712), ('5', 0.9395085193100469), ('12', 0.8588740380011445)]
Top words for pretrained_BERT neuron indx 1503 [('bare', 1.0), ('error', 0.9413514652064728), ('domain', 0.8336722633066806), ('purpose', 0.7678886864280589), ('component', 0.741741315248929)]
Top words for pretrained_BERT neuron indx 7648 [('128', 1.0), ('alt', 0.9533692484642261), ('context', 0.9281620369831391), ('v', 0.9197777079649514), ('all', 0.8976028241436558)]
Top words for pretrained_BERT neuron indx 7656 [('e', 1.0), ('600', 0.9026681617369597), ('or', 0.8847931344862195), ('to', 0.8812606290982624), ('format', 0.8550546771447306)]
Top words for pretrained_BERT neuron indx 1513 [('description', 1.0), ('range', 0.9824452979198659), ('presence', 0.9254088047249626), ('find', 0.8946545722420769), ('item', 0.8343745558354588)]
Top words for pretrained_BERT neuron indx 5610 [('class', 1.0), ('Off', 0.9821923438288077), ('seconds', 0.9068459442626633), ('help', 0.8937457648527781), ('sans', 0.8599654500802572)]
Top words for pretrained_BERT neuron indx 7660 [('logging', 1.0), ('post', 0.8996032539851039), ('seconds', 0.879235096033523), ('localize', 0.8758028833176171), ('key', 0.8743387152705278)]
Top words for pretrained_BERT neuron indx 9715 [('7', 1.0), ('60', 0.9189153347763687), ('milliseconds', 0.91865363726215), ('django', 0.8211786457651625), ('hpOneView', 0.8125755430447485)]
Top words for pretrained_BERT neuron indx 7668 [('2', 1.0), ('seconds', 0.9981020702086286), ('minutes', 0.9841951433780382), ('for', 0.9769853666190172), ('1000', 0.9514151731362187)]
Top words for pretrained_BERT neuron indx 5621 [('14', 1.0), ('direct', 0.9939721755331917), ('IOError', 0.9713157888561176), ('IDLEN', 0.9639994455606662), ('close', 0.9508590365246373)]
Top words for pretrained_BERT neuron indx 1527 [('Unauthorized', 1.0), ('zone', 0.9778412471110092), ('exceptions', 0.9633006323454418), ('upper', 0.9394931084851386), ('save', 0.8878764511369519)]
Top words for pretrained_BERT neuron indx 3584 [('component', 1.0), ('other', 0.8772283443938359), ('Component', 0.8720913715173886), ('break', 0.8708818613471189), ('route', 0.8491915594358558)]
Top words for pretrained_BERT neuron indx 5635 [('board', 1.0), ('Board', 0.9896432861982177), ('mesh', 0.9763302114966487), ('with', 0.9412624606549564), ('enabled', 0.9233821540518348)]
Top words for pretrained_BERT neuron indx 5636 [('mesh', 1.0), ('title', 0.9404047469411909), ('read', 0.8573081450598161), ('class', 0.7586134583012039), ('Mesh', 0.7495927008033538)]
Top words for pretrained_BERT neuron indx 1539 [('authentication', 1.0), ('strip', 0.9084801735408311), ('0', 0.8840520649070345), ('board', 0.8771268616166947), ('host', 0.8533299613897996)]
Top words for pretrained_BERT neuron indx 9736 [('pop', 1.0), ('12', 0.7192780368252714), ('proxy', 0.7106946738523574), ('128', 0.6972688483162439), ('log', 0.6955642153743388)]
Top words for pretrained_BERT neuron indx 7694 [('force', 1.0), ('8', 0.8626111974971186), ('800', 0.834412584824632), ('15', 0.8156493857290761), ('5', 0.7880057359881478)]
Top words for pretrained_BERT neuron indx 7710 [('future', 1.0), ('boot', 0.8049965995296313), ('action', 0.7375180442617912), ('os', 0.7319206673176277), ('filters', 0.7097017859509914)]
Top words for pretrained_BERT neuron indx 9771 [('7', 1.0), ('sans', 0.9775298562980675), ('with', 0.9117901867014326), ('hour', 0.8100944322809028), ('while', 0.7806730095009603)]
Top words for pretrained_BERT neuron indx 3638 [('24', 1.0), ('Exception', 0.8272766760191428), ('pass', 0.6795009192929689), ('break', 0.6669629251039071), ('port', 0.646767209900563)]
Top words for pretrained_BERT neuron indx 9784 [('sorting_layer_id', 1.0), ('render_mode', 0.93382703128224), ('def', 0.900041139901306), ('NetworkProfileTab', 0.8878727094404025), ('st_mode', 0.8823068913380212)]
Top words for pretrained_BERT neuron indx 9791 [('False', 1.0), ('else', 0.8759142370859352), ('while', 0.8547854061725074), ('put', 0.8342067468696), ('error', 0.8295452661506224)]
Top words for pretrained_BERT neuron indx 3648 [('sorted', 1.0), ('vCard', 0.9745943083810689), ('count', 0.9236754810711186), ('minutes', 0.8802895477908856), ('20', 0.8637304607285534)]
Top words for pretrained_BERT neuron indx 3649 [('Tab', 1.0), ('5', 0.9984383122605037), ('attachpos', 0.990021833204412), ('prange', 0.9728438810228833), ('12', 0.9683880487779889)]
Top words for pretrained_BERT neuron indx 3655 [('to', 1.0), ('Exception', 0.905343084124394), ('not', 0.7228070793952688), ('con', 0.719883815471336), ('local', 0.6562475199361092)]
Top words for pretrained_BERT neuron indx 5715 [('action', 1.0), ('routes', 0.842629757977637), ('enum', 0.8034888628174789), ('verbatim', 0.7835420890839433), ('bare', 0.7723238929506051)]
Top words for pretrained_BERT neuron indx 7765 [('in', 1.0), ('E', 0.8564800448741821), ('seconds', 0.767941239054313), ('objects', 0.6648096333279521), ('horizon', 0.6556038025447319)]
Top words for pretrained_BERT neuron indx 5727 [('32', 1.0), ('24', 0.823141085840192), ('80', 0.7756543020606466), ('3', 0.762685263225454), ('30', 0.7606901477726129)]
Top words for pretrained_BERT neuron indx 7779 [('as', 1.0), ('exit', 0.9239762426373179), ('Post', 0.8972265694646542), ('stat', 0.8838344925402195), ('title', 0.8647620835784098)]
Top words for pretrained_BERT neuron indx 5732 [('seconds', 1.0), ('affinity', 0.9304698639029922), ('name', 0.921837739094191), ('v', 0.8623771311060274), ('minute', 0.8033373040457478)]
Top words for pretrained_BERT neuron indx 7790 [('80', 1.0), ('17', 0.9378566617427744), ('14', 0.9049099329229778), ('mins', 0.7715606770201747), ('utc', 0.7279217164608616)]
Top words for pretrained_BERT neuron indx 9839 [('core', 1.0), ('tastypie', 0.7856080151797875), ('else', 0.7312419676462684), ('oslo', 0.7144977280883524), ('utcnow', 0.7035150071166019)]
Top words for pretrained_BERT neuron indx 3696 [('info', 1.0), ('us', 0.9860872377324628), ('Profile', 0.8943640177392232), ('division', 0.8449939598838184), ('day', 0.7883721099121034)]
Top words for pretrained_BERT neuron indx 3707 [('proxy', 1.0), ('context', 0.9819172377619545), ('path', 0.9182727932243626), ('local', 0.9043620768107306), ('dt', 0.8191867900142985)]
Top words for pretrained_BERT neuron indx 7804 [('with', 1.0), ('for', 0.7076600327528899), ('core', 0.6972476170513953), ('oslo', 0.6544820956375144), ('and', 0.6436140424348168)]
Top words for pretrained_BERT neuron indx 3709 [('parent', 1.0), ('300', 0.9510916355691049), ('6', 0.8545777585351922), ('reactor', 0.8508616289066439), ('match', 0.8461814523729674)]
Top words for pretrained_BERT neuron indx 1659 [('6', 1.0), ('exceptions', 0.9579329914549729), ('partition', 0.8606202365071868), ('60', 0.8432448596698482), ('slug', 0.8001606250876725)]
Top words for pretrained_BERT neuron indx 7807 [('day', 1.0), ('for', 0.9193574004546621), ('models', 0.8684662478217923), ('calendar', 0.8374716043086085), ('""', 0.8175910962773222)]
Top words for pretrained_BERT neuron indx 3713 [('Session', 1.0), ('credential', 0.9005735961632725), ('session', 0.896910844047067), ('future', 0.8817037000695445), ('REQUEST', 0.8810367559720301)]
Top words for pretrained_BERT neuron indx 9859 [('bool', 1.0), ('7', 0.9732580420132241), ('readline', 0.9312352314664862), ('9', 0.9068420367286177), ('REQUEST', 0.8739136992164606)]
Top words for pretrained_BERT neuron indx 3719 [('broadcast', 1.0), ('day', 0.9963243071944329), ('month', 0.9549346724442257), ('alt', 0.888362922955248), ('filter', 0.8734663566906739)]
Top words for pretrained_BERT neuron indx 5773 [('end', 1.0), ('sent_close', 0.9063508375677111), ('1', 0.9054987953306146), ('0', 0.8553330634276032), ('root', 0.8293129028619532)]
Top words for pretrained_BERT neuron indx 1679 [('patch', 1.0), ('f', 0.9660789858508542), ('Unauthorized', 0.9310122321773902), ('authentication', 0.9096986166736458), ('dt', 0.8855896421573467)]
Top words for pretrained_BERT neuron indx 9875 [('render', 1.0), ('"Name"', 0.8888486651621079), ('id', 0.8710164190923321), ('clone', 0.8484182291899867), ('32', 0.7654754237355395)]
Top words for pretrained_BERT neuron indx 5783 [('loads', 1.0), ('bind', 0.961212575750646), ('List', 0.9395207192667133), ('requests', 0.9349685018123614), ('enabled', 0.9004266956853677)]
Top words for pretrained_BERT neuron indx 9881 [('7', 1.0), ('24', 0.9948688524563419), ('IntEnum', 0.9487444823278691), ('20', 0.8829702087714041), ('group', 0.8789910080929937)]
Top words for pretrained_BERT neuron indx 7836 [('logging', 1.0), ('fcs', 0.9700307706704921), ('resource', 0.9695319947739022), ('wait', 0.9498883211690914), ('dest', 0.9393602281348762)]
Top words for pretrained_BERT neuron indx 5790 [('max', 1.0), ('add_argument', 0.9899580609461665), ('exceptions', 0.9858617775642284), ('component', 0.9293652082065766), ('count', 0.8816965690653017)]
Top words for pretrained_BERT neuron indx 9887 [('bare', 1.0), ('uss', 0.8345863046371561), ('UserInfo', 0.7990436573807279), ('servers', 0.7978830988780046), ('millis', 0.7964956733730014)]
Top words for pretrained_BERT neuron indx 9886 [('View', 1.0), ('alt', 0.9656920585188488), ('requests', 0.9648831806366857), ('9', 0.943772955435797), ('oslo', 0.8837819508487406)]
Top words for pretrained_BERT neuron indx 5795 [('except', 1.0), ('with', 0.8648222678787537), ('if', 0.8506476438523076), ('oslo', 0.7818786908532235), ('7', 0.7582534082558751)]
Top words for pretrained_BERT neuron indx 9893 [('5', 1.0), ('META', 0.9172447156876381), ('E', 0.861182724687965), ('except', 0.8541269774883178), ('month', 0.8174536804522493)]
Top words for pretrained_BERT neuron indx 3753 [('80', 1.0), ('800', 0.9883737549878309), ('600', 0.8845112218094413), ('script', 0.8647792472586774), ('NoPerm', 0.8145288075883605)]
Top words for pretrained_BERT neuron indx 5807 [('Billboard', 1.0), ('created', 0.9584902215286136), ('bare', 0.9035965333374242), ('affinity', 0.86701253257927), ('authorized', 0.8385974955509318)]
Top words for pretrained_BERT neuron indx 9906 [('Node', 1.0), ('400', 0.932235446607811), ('META', 0.9275780560112177), ('9', 0.9120635085446186), ('v', 0.8966169164336472)]
Top words for pretrained_BERT neuron indx 3771 [('enabled', 1.0), ('match', 0.9971623937705815), ('Off', 0.8889307571250573), ('requests', 0.8762967922462183), ('GetBoard', 0.8619146937383447)]
Top words for pretrained_BERT neuron indx 3775 [('os', 1.0), ('List', 0.9190429580937415), ('enum', 0.8989027546294414), ('ms', 0.7937141820183794), ('items', 0.7211903186211246)]
Top words for pretrained_BERT neuron indx 7875 [('24', 1.0), ('17', 0.946268016219997), ('30', 0.9174615528337561), ('receive_shadows', 0.9148041222349647), ('component', 0.9110831664894901)]
Top words for pretrained_BERT neuron indx 5827 [('template', 1.0), ('seek', 0.8795381034615952), ('None', 0.7640935515860299), ('shts', 0.7594772100071481), ('parts', 0.7495297220189775)]
Top words for pretrained_BERT neuron indx 7883 [('super', 1.0), ('Distance', 0.9551899000163829), ('On', 0.9461377143142065), ('1024', 0.9291629369682954), ('help', 0.9264326394709329)]
Top words for pretrained_BERT neuron indx 3798 [('count', 1.0), ('close', 0.8193917022562075), ('value', 0.815752387753003), ('while', 0.8118698263914685), ('17', 0.782223183898838)]
Top words for pretrained_BERT neuron indx 5848 [('Unauthorized', 1.0), ('except', 0.8029096021331394), ('40', 0.8001597756230867), ('result', 0.7892280510203359), ('iq', 0.7664980840489463)]
Top words for pretrained_BERT neuron indx 5856 [('logging', 1.0), ('META', 0.9882931278036192), ('int', 0.9350363943465699), ('with', 0.8209413428033732), ('log', 0.8116104133456385)]
Top words for pretrained_BERT neuron indx 5859 [('host', 1.0), ('send', 0.9885378054525426), ('False', 0.9882877588005101), ('return', 0.9406762684716289), ('day', 0.8878827081067299)]
Top words for pretrained_BERT neuron indx 7912 [('fileno', 1.0), ('st_mode', 0.9198712635967452), ('affinity', 0.822347098268858), ('parts', 0.814962729460948), ('Unauthorized', 0.8113354655783132)]
Top words for pretrained_BERT neuron indx 3817 [('description', 1.0), ('range', 0.9300464092112917), ('find', 0.9030620271848478), ('long', 0.8852202586361515), ('presence', 0.8694701513837254)]
Top words for pretrained_BERT neuron indx 7914 [('minutes', 1.0), ('to', 0.9625022187713859), ('Off', 0.8922012778014251), ('millis', 0.8309712717874563), ('digest', 0.7926656293068329)]
Top words for pretrained_BERT neuron indx 1771 [('resource', 1.0), ('calendar', 0.8962693361091099), ('Node', 0.8865480343760657), ('1000', 0.8473269815110221), ('upper', 0.827278236355398)]
Top words for pretrained_BERT neuron indx 5874 [('int', 1.0), ('second', 0.8867936833188951), ('val', 0.8817564247018206), ('ping', 0.8467875907030269), ('other', 0.8047242545035118)]
Top words for pretrained_BERT neuron indx 7929 [('1024', 1.0), ('stanza', 0.8645232002862269), ('ignore', 0.8197008977726646), ('seek', 0.7905604306619717), ('pxe', 0.7892985031203509)]
Top words for pretrained_BERT neuron indx 7935 [('Mesh', 1.0), ('mesh', 0.9190703623782934), ('Billboard', 0.7841970634689976), ('Stretch', 0.7599409910384909), ('materials', 0.7317002276741713)]
Top words for pretrained_BERT neuron indx 5896 [('pop', 1.0), ('count', 0.8036643120576814), ('con', 0.7600630875099157), ('On', 0.7357723320557426), ('close', 0.7296963150635933)]
Top words for pretrained_BERT neuron indx 5902 [('META', 1.0), ('9', 0.925508246459775), ('not', 0.8472491004442807), ('re', 0.8170378980084364), ('requests', 0.7780611960140486)]
Top words for pretrained_BERT neuron indx 7965 [('log', 1.0), ('7', 0.8458378583411341), ('""', 0.7724771704043208), ('zone', 0.7521827111821252), ('sts', 0.7142043329788279)]
Top words for pretrained_BERT neuron indx 5919 [('GET', 1.0), ('REQUEST', 0.8973308341670878), ('upper', 0.8868227367788138), ('models', 0.8575785527768335), ('horizon', 0.8564614308951386)]
Top words for pretrained_BERT neuron indx 7986 [('and', 1.0), ('else', 0.9162363232713352), ('st', 0.8953939560740733), ('400', 0.8865758170390752), ('save', 0.876158096573118)]
Top words for pretrained_BERT neuron indx 7991 [('force', 1.0), ('or', 0.9659787184903376), ('future', 0.862957758978145), ('created', 0.8596355071612671), ('help', 0.8195656136488624)]
Top words for pretrained_BERT neuron indx 3898 [('Stretch', 1.0), ('horizon', 0.979788707285398), ('800', 0.9743344515498722), ('Billboard', 0.9563442539884279), ('ranges', 0.948668031926748)]
Top words for pretrained_BERT neuron indx 5952 [('slug', 1.0), ('def', 0.9850506792585574), ('count', 0.8584885960375911), ('minutes', 0.8409098917559783), ('vCard', 0.840904071187831)]
Top words for pretrained_BERT neuron indx 3911 [('link', 1.0), ('purpose', 0.9402676685460277), ('uss', 0.9322210835524775), ('800', 0.9218630569767341), ('objects', 0.9184200713299778)]
Top words for pretrained_BERT neuron indx 8019 [('to', 1.0), ('e', 0.931160045073854), ('group', 0.870697636889326), ('action', 0.8002489509249421), ('View', 0.7922231870821604)]
Top words for pretrained_BERT neuron indx 8024 [('send', 1.0), ('sorted', 0.9769117760167519), ('log', 0.907398296235831), ('enabled', 0.9005566953282799), ('Unauthorized', 0.8791246606289181)]
Top words for pretrained_BERT neuron indx 1886 [('unicode', 1.0), ('all', 0.8389216668992485), ('digest', 0.7608225615357613), ('ranges', 0.7480261020577402), ('Digest', 0.6726117514656872)]
Top words for pretrained_BERT neuron indx 3947 [('600', 1.0), ('Stretch', 0.9430833181330044), ('affinity', 0.9396860922071159), ('Tab', 0.9292708186780297), ('mins', 0.9064200470762102)]
Top words for pretrained_BERT neuron indx 8049 [('and', 1.0), ('milliseconds', 0.9320732899191815), ('"oslo"', 0.9310548062648755), ('oslo', 0.9087743926221463), ('millis', 0.8638479293071024)]
Top words for pretrained_BERT neuron indx 3966 [('seconds', 1.0), ('wait', 0.9676018557551738), ('requests', 0.9482821200003138), ('servers', 0.9378234338803564), ('proxy', 0.9174873293544888)]
Top words for pretrained_BERT neuron indx 1921 [('proxy', 1.0), ('seek', 0.9771405803037397), ('filters', 0.9317436611333723), ('put', 0.8012817978770085), ('send', 0.748823000432833)]
Top words for pretrained_BERT neuron indx 8076 [('sts', 1.0), ('store', 0.9112263616140547), ('stanza', 0.9004988522251871), ('os', 0.841184279741317), ('False', 0.818148484340484)]
Top words for pretrained_BERT neuron indx 8077 [('end', 1.0), ('presence', 0.9355929091807802), ('hour', 0.8587188873309488), ('action', 0.8264701712303524), ('second', 0.8207074332142125)]
Top words for pretrained_BERT neuron indx 6029 [('9', 1.0), ('authorization', 0.8516820703636991), ('pdb', 0.8329787732744441), ('Register', 0.8061644975805594), ('if', 0.8037197902221515)]
Top words for pretrained_BERT neuron indx 3983 [('Unauthorized', 1.0), ('patch', 0.9315761137451535), ('long', 0.8720639415006517), ('authentication', 0.8297871466890139), ('and', 0.8205559719982631)]
Top words for pretrained_BERT neuron indx 8080 [('models', 1.0), ('s', 0.7957642022882759), ('m', 0.7814409843676784), ('materials', 0.7317930322419463), ('calendar', 0.7212847264282513)]
Top words for pretrained_BERT neuron indx 8087 [('GET', 1.0), ('requests', 0.975696431827039), ('store', 0.9233135519653971), ('max', 0.9029774917247758), ('1800', 0.8782397147201143)]
Top words for pretrained_BERT neuron indx 3994 [('log', 1.0), ('ref', 0.9529074681665776), ('128', 0.8785899058143608), ('1', 0.781692140358399), ('False', 0.763277026961232)]
Top words for pretrained_BERT neuron indx 1952 [('all', 1.0), ('32', 0.8775794162571631), ('80', 0.8533790881435863), ('enabled', 0.8407401455077799), ('40', 0.8223260710056399)]
Top words for pretrained_BERT neuron indx 8099 [('if', 1.0), ('except', 0.8382830014686536), ('get_profile_available_storage_systems', 0.706247711209979), ('post', 0.7054924265742181), ('with', 0.6698582950189959)]
Top words for pretrained_BERT neuron indx 1958 [('def', 1.0), ('reactor', 0.9869866742193465), ('force', 0.9288368085406562), ('14', 0.9196991473976799), ('count', 0.8688234211778783)]
Top words for pretrained_BERT neuron indx 8102 [('6', 1.0), ('reactor', 0.8784198593366161), ('24', 0.7866879055032435), ('9', 0.7511727736119315), ('body', 0.7451680500158615)]
Top words for pretrained_BERT neuron indx 4009 [('128', 1.0), ('connection', 0.9059636825561913), ('post', 0.7554088262714868), ('Off', 0.7278452490315398), ('requests', 0.7070059610469188)]
Top words for pretrained_BERT neuron indx 4010 [('minutes', 1.0), ('60', 0.7012937489682493), ('force', 0.6910798240810725), ('is', 0.6769234390289002), ('script', 0.6683798759390691)]
Top words for pretrained_BERT neuron indx 8111 [('7', 1.0), ('hour', 0.9946942222573563), ('month', 0.9648618982780953), ('second', 0.9280183181457567), ('seconds', 0.9268509570902811)]
Top words for pretrained_BERT neuron indx 1987 [('render', 1.0), ('template', 0.9272376615493996), ('exceptions', 0.8956841095196044), ('mtime', 0.8677644518792824), ('contents', 0.8672035674013966)]
Top words for pretrained_BERT neuron indx 8133 [('force', 1.0), ('32', 0.9940653360053212), ('12', 0.9834235007288173), ('800', 0.9616452981352617), ('META', 0.9311729795900717)]
Top words for pretrained_BERT neuron indx 2009 [('pass', 1.0), ('300', 0.9973819842290575), ('task', 0.9054121958268675), ('models', 0.9048059749933244), ('reactor', 0.9024427615903385)]
Top words for pretrained_BERT neuron indx 4063 [('stanza', 1.0), ('secs', 0.9199827910707046), ('1800', 0.9175847960575855), ('On', 0.7913423072657776), ('1', 0.7606663833635688)]
Top words for pretrained_BERT neuron indx 8160 [('end', 1.0), ('logging', 0.9869207602621968), ('calendar', 0.9476208130209202), ('META', 0.9472677099022684), ('register', 0.9060639125242054)]
Top words for pretrained_BERT neuron indx 8163 [('False', 1.0), ('utcfromtimestamp', 0.9537423787992385), ('host', 0.8460233450126499), ('millis', 0.8337861302681683), ('PolicyProfileTab', 0.8226708881347886)]
Top words for pretrained_BERT neuron indx 4088 [('E', 1.0), ('tout', 0.8500942264527224), ('unpack', 0.8293334052822581), ('desc', 0.8276074988830593), ('probed', 0.8055566943496559)]
Top words for pretrained_BERT neuron indx 4095 [('Billboard', 1.0), ('blocking', 0.9223531861961521), ('localize', 0.8849019706410234), ('Session', 0.851894877370059), ('title', 0.8497590961196066)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0107
Epoch: [2/10], Loss: 0.0060
Epoch: [3/10], Loss: 0.0047
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0032
Epoch: [6/10], Loss: 0.0028
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.68
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0107
Epoch: [2/10], Loss: 0.0063
Epoch: [3/10], Loss: 0.0039
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0033
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0026
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0024
Epoch: [10/10], Loss: 0.0023
Score (accuracy) of the probe: 0.68
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0106
Epoch: [2/10], Loss: 0.0061
Epoch: [3/10], Loss: 0.0041
Epoch: [4/10], Loss: 0.0034
Epoch: [5/10], Loss: 0.0033
Epoch: [6/10], Loss: 0.0037
Epoch: [7/10], Loss: 0.0029
Epoch: [8/10], Loss: 0.0030
Epoch: [9/10], Loss: 0.0026
Epoch: [10/10], Loss: 0.0024
Score (accuracy) of the probe: 0.68
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0117
Epoch: [2/10], Loss: 0.0074
Epoch: [3/10], Loss: 0.0054
Epoch: [4/10], Loss: 0.0046
Epoch: [5/10], Loss: 0.0045
Epoch: [6/10], Loss: 0.0041
Epoch: [7/10], Loss: 0.0039
Epoch: [8/10], Loss: 0.0037
Epoch: [9/10], Loss: 0.0038
Epoch: [10/10], Loss: 0.0038
Score (accuracy) of the probe: 0.69

The best l1=0, the best l2=0.1 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.29
{'__OVERALL__': 0.289993626513703, 'NAME': 0.3116883116883117, 'STRING': 0.2918287937743191, 'NUMBER': 0.31313131313131315, 'KEYWORD': 0.22972972972972974}
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.33

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.5920968769917145
----------------------------------------------------------------
