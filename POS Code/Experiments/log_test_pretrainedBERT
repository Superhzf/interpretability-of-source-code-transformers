Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
1289 13.0
Number of tokens:  1042
length of source dictionary:  1042
length of target dictionary:  34
1042
Total instances: 1042
['hasattr', 'readline', 'my_pid', 'get_server_by_name', ')', '_loginid', 'direct', 'allocate_pool_ids', 'pytz', ';', 'mesh', 'django', 'ny_dt', 'MAXSIGLINES', 'to_jid', 'GetModTime', 'encode', 'zone', 'us', 'get_members']
Number of samples:  1042
Stats: Labels with their frequencies in the final set
NAME 876
STRING 72
NUMBER 36
KEYWORD 25
COMMENT 4
NL 1
LPAR 1
DOT 1
RPAR 1
COLON 1
EQUAL 1
COMMA 1
INDENT 1
DEDENT 1
LSQB 1
RSQB 1
AT 1
STAR 1
EQEQUAL 1
MINUS 1
PLUS 1
PERCENT 1
GREATER 1
NOTEQUAL 1
PLUSEQUAL 1
GREATEREQUAL 1
LESS 1
MINEQUAL 1
LBRACE 1
RBRACE 1
LESSEQUAL 1
DOUBLESTAR 1
SLASH 1
SEMI 1

pretrained_BERT distribution:
{0: 876, 1: 72, 2: 36, 3: 25, 4: 4, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1}
pretrained_BERT distribution after trauncating:
{0: 0.8681863230921705, 1: 0.07135777998017839, 2: 0.035678889990089196, 3: 0.024777006937561942}
{0: 876, 1: 72, 2: 36, 3: 25}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
494 13.0
Number of tokens:  482
length of source dictionary:  482
length of target dictionary:  33
482
Total instances: 482
['environ', ')', 'add_mv', 'dbeta_tmp', 'size', 'get_html_theme_path', 'softmax', 'mul', 'inputs', '0.7', '&', 'te_cost', 'b1', 'results', 'MagicMock', 'true_labels', 'mu', 'test_exponential', 'crop2', 'aggregate']
Number of samples:  482
Stats: Labels with their frequencies in the final set
NAME 400
NUMBER 27
KEYWORD 22
STRING 4
COMMA 1
NEWLINE 1
DOT 1
LPAR 1
RPAR 1
EQUAL 1
COLON 1
DEDENT 1
INDENT 1
LBRACE 1
RBRACE 1
LSQB 1
RSQB 1
MINUS 1
SLASH 1
AT 1
EQEQUAL 1
GREATER 1
STAREQUAL 1
LESS 1
DOUBLESTAR 1
STAR 1
PLUS 1
COMMENT 1
GREATEREQUAL 1
PLUSEQUAL 1
LESSEQUAL 1
PERCENT 1
AMPER 1

pretrained_BERT distribution:
{0: 400, 1: 27, 2: 22, 3: 4, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1}
pretrained_BERT distribution after trauncating:
{0: 0.8830022075055187, 1: 0.059602649006622516, 2: 0.04856512141280353, 3: 0.008830022075055188}
{0: 400, 1: 27, 2: 22, 3: 4}
{'NAME': 0, 'NUMBER': 1, 'KEYWORD': 2, 'STRING': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 835, 1: 72, 2: 25, 3: 14})
The distribution of classes in testing:
Counter({0: 400, 2: 27, 3: 12, 1: 4})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (851, 9984)
The shape of the validation set: (95, 9984)
The shape of the testing set: (443, 9984)
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0177
Epoch: [2/10], Loss: 0.0071
Epoch: [3/10], Loss: 0.0051
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0183
Epoch: [2/10], Loss: 0.0078
Epoch: [3/10], Loss: 0.0051
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0182
Epoch: [2/10], Loss: 0.0078
Epoch: [3/10], Loss: 0.0054
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0017
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0189
Epoch: [2/10], Loss: 0.0083
Epoch: [3/10], Loss: 0.0065
Epoch: [4/10], Loss: 0.0043
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0019
Epoch: [8/10], Loss: 0.0018
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.01 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8397291196388262, 'NAME': 0.83, 'STRING': 1.0, 'NUMBER': 0.9629629629629629, 'KEYWORD': 0.8333333333333334}
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0086
Epoch: [5/10], Loss: 0.0080
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.83
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0097
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0078
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0069
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.79
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0076
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0063
Epoch: [10/10], Loss: 0.0060
Score (accuracy) of the probe: 0.78
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0134
Epoch: [2/10], Loss: 0.0115
Epoch: [3/10], Loss: 0.0105
Epoch: [4/10], Loss: 0.0098
Epoch: [5/10], Loss: 0.0092
Epoch: [6/10], Loss: 0.0087
Epoch: [7/10], Loss: 0.0082
Epoch: [8/10], Loss: 0.0078
Epoch: [9/10], Loss: 0.0075
Epoch: [10/10], Loss: 0.0071
Score (accuracy) of the probe: 0.80

The best l1=0, the best l2=0 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.62
{'__OVERALL__': 0.6207674943566591, 'NAME': 0.595, 'STRING': 1.0, 'NUMBER': 0.9259259259259259, 'KEYWORD': 0.6666666666666666}
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.76
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0078
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0069
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0062
Score (accuracy) of the probe: 0.75
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0063
Epoch: [10/10], Loss: 0.0060
Score (accuracy) of the probe: 0.79
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0132
Epoch: [2/10], Loss: 0.0113
Epoch: [3/10], Loss: 0.0103
Epoch: [4/10], Loss: 0.0096
Epoch: [5/10], Loss: 0.0091
Epoch: [6/10], Loss: 0.0086
Epoch: [7/10], Loss: 0.0081
Epoch: [8/10], Loss: 0.0077
Epoch: [9/10], Loss: 0.0074
Epoch: [10/10], Loss: 0.0071
Score (accuracy) of the probe: 0.84

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.64
{'__OVERALL__': 0.6388261851015802, 'NAME': 0.6175, 'STRING': 1.0, 'NUMBER': 0.9629629629629629, 'KEYWORD': 0.5}
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.73
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0126
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0065
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.76
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0108
Epoch: [3/10], Loss: 0.0098
Epoch: [4/10], Loss: 0.0090
Epoch: [5/10], Loss: 0.0084
Epoch: [6/10], Loss: 0.0079
Epoch: [7/10], Loss: 0.0074
Epoch: [8/10], Loss: 0.0070
Epoch: [9/10], Loss: 0.0066
Epoch: [10/10], Loss: 0.0063
Score (accuracy) of the probe: 0.80
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0131
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0083
Epoch: [7/10], Loss: 0.0079
Epoch: [8/10], Loss: 0.0076
Epoch: [9/10], Loss: 0.0072
Epoch: [10/10], Loss: 0.0070
Score (accuracy) of the probe: 0.77

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.64
{'__OVERALL__': 0.636568848758465, 'NAME': 0.615, 'STRING': 1.0, 'NUMBER': 0.9629629629629629, 'KEYWORD': 0.5}
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0107
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0060
Score (accuracy) of the probe: 0.78
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0129
Epoch: [2/10], Loss: 0.0107
Epoch: [3/10], Loss: 0.0097
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0072
Epoch: [8/10], Loss: 0.0068
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.72
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0076
Epoch: [7/10], Loss: 0.0071
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0060
Score (accuracy) of the probe: 0.79
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0131
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0083
Epoch: [7/10], Loss: 0.0079
Epoch: [8/10], Loss: 0.0075
Epoch: [9/10], Loss: 0.0072
Epoch: [10/10], Loss: 0.0069
Score (accuracy) of the probe: 0.78

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.64
{'__OVERALL__': 0.6410835214446953, 'NAME': 0.6075, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.8333333333333334}
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0128
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0080
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.81
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0129
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0081
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.85
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0119
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0077
Epoch: [6/10], Loss: 0.0072
Epoch: [7/10], Loss: 0.0068
Epoch: [8/10], Loss: 0.0064
Epoch: [9/10], Loss: 0.0060
Epoch: [10/10], Loss: 0.0057
Score (accuracy) of the probe: 0.84
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0133
Epoch: [2/10], Loss: 0.0113
Epoch: [3/10], Loss: 0.0103
Epoch: [4/10], Loss: 0.0095
Epoch: [5/10], Loss: 0.0089
Epoch: [6/10], Loss: 0.0084
Epoch: [7/10], Loss: 0.0079
Epoch: [8/10], Loss: 0.0075
Epoch: [9/10], Loss: 0.0072
Epoch: [10/10], Loss: 0.0069
Score (accuracy) of the probe: 0.84

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.66
{'__OVERALL__': 0.6591422121896162, 'NAME': 0.6525, 'STRING': 1.0, 'NUMBER': 0.6666666666666666, 'KEYWORD': 0.75}
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0128
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0094
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0073
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0064
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0057
Score (accuracy) of the probe: 0.84
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.86
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0087
Epoch: [5/10], Loss: 0.0080
Epoch: [6/10], Loss: 0.0075
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.81
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0110
Epoch: [3/10], Loss: 0.0100
Epoch: [4/10], Loss: 0.0092
Epoch: [5/10], Loss: 0.0086
Epoch: [6/10], Loss: 0.0081
Epoch: [7/10], Loss: 0.0077
Epoch: [8/10], Loss: 0.0073
Epoch: [9/10], Loss: 0.0070
Epoch: [10/10], Loss: 0.0067
Score (accuracy) of the probe: 0.83

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.68
{'__OVERALL__': 0.6794582392776524, 'NAME': 0.665, 'STRING': 1.0, 'NUMBER': 0.7777777777777778, 'KEYWORD': 0.8333333333333334}
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.85
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 0.86
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 0.86
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0134
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0100
Epoch: [4/10], Loss: 0.0093
Epoch: [5/10], Loss: 0.0087
Epoch: [6/10], Loss: 0.0082
Epoch: [7/10], Loss: 0.0078
Epoch: [8/10], Loss: 0.0074
Epoch: [9/10], Loss: 0.0071
Epoch: [10/10], Loss: 0.0068
Score (accuracy) of the probe: 0.88

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.67
{'__OVERALL__': 0.6659142212189616, 'NAME': 0.6675, 'STRING': 1.0, 'NUMBER': 0.5925925925925926, 'KEYWORD': 0.6666666666666666}
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0063
Epoch: [9/10], Loss: 0.0059
Epoch: [10/10], Loss: 0.0056
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0078
Epoch: [6/10], Loss: 0.0073
Epoch: [7/10], Loss: 0.0068
Epoch: [8/10], Loss: 0.0064
Epoch: [9/10], Loss: 0.0061
Epoch: [10/10], Loss: 0.0057
Score (accuracy) of the probe: 0.85
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0103
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0138
Epoch: [2/10], Loss: 0.0113
Epoch: [3/10], Loss: 0.0102
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0083
Epoch: [7/10], Loss: 0.0078
Epoch: [8/10], Loss: 0.0075
Epoch: [9/10], Loss: 0.0071
Epoch: [10/10], Loss: 0.0068
Score (accuracy) of the probe: 0.86

The best l1=0, the best l2=0 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.65
{'__OVERALL__': 0.6478555304740407, 'NAME': 0.66, 'STRING': 1.0, 'NUMBER': 0.48148148148148145, 'KEYWORD': 0.5}
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0054
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0088
Epoch: [4/10], Loss: 0.0080
Epoch: [5/10], Loss: 0.0074
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0054
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0131
Epoch: [2/10], Loss: 0.0109
Epoch: [3/10], Loss: 0.0098
Epoch: [4/10], Loss: 0.0090
Epoch: [5/10], Loss: 0.0084
Epoch: [6/10], Loss: 0.0079
Epoch: [7/10], Loss: 0.0074
Epoch: [8/10], Loss: 0.0071
Epoch: [9/10], Loss: 0.0067
Epoch: [10/10], Loss: 0.0064
Score (accuracy) of the probe: 0.91

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.70
{'__OVERALL__': 0.7020316027088036, 'NAME': 0.7075, 'STRING': 1.0, 'NUMBER': 0.6666666666666666, 'KEYWORD': 0.5}
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0117
Epoch: [2/10], Loss: 0.0095
Epoch: [3/10], Loss: 0.0085
Epoch: [4/10], Loss: 0.0077
Epoch: [5/10], Loss: 0.0070
Epoch: [6/10], Loss: 0.0065
Epoch: [7/10], Loss: 0.0060
Epoch: [8/10], Loss: 0.0056
Epoch: [9/10], Loss: 0.0052
Epoch: [10/10], Loss: 0.0049
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0097
Epoch: [3/10], Loss: 0.0086
Epoch: [4/10], Loss: 0.0078
Epoch: [5/10], Loss: 0.0071
Epoch: [6/10], Loss: 0.0065
Epoch: [7/10], Loss: 0.0060
Epoch: [8/10], Loss: 0.0056
Epoch: [9/10], Loss: 0.0052
Epoch: [10/10], Loss: 0.0049
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0117
Epoch: [2/10], Loss: 0.0096
Epoch: [3/10], Loss: 0.0086
Epoch: [4/10], Loss: 0.0078
Epoch: [5/10], Loss: 0.0071
Epoch: [6/10], Loss: 0.0066
Epoch: [7/10], Loss: 0.0061
Epoch: [8/10], Loss: 0.0057
Epoch: [9/10], Loss: 0.0053
Epoch: [10/10], Loss: 0.0050
Score (accuracy) of the probe: 0.92
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0093
Epoch: [4/10], Loss: 0.0085
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0066
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0059
Score (accuracy) of the probe: 0.91

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.73
{'__OVERALL__': 0.7291196388261851, 'NAME': 0.7175, 'STRING': 1.0, 'NUMBER': 0.8888888888888888, 'KEYWORD': 0.6666666666666666}
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0119
Epoch: [2/10], Loss: 0.0098
Epoch: [3/10], Loss: 0.0087
Epoch: [4/10], Loss: 0.0079
Epoch: [5/10], Loss: 0.0073
Epoch: [6/10], Loss: 0.0068
Epoch: [7/10], Loss: 0.0063
Epoch: [8/10], Loss: 0.0059
Epoch: [9/10], Loss: 0.0055
Epoch: [10/10], Loss: 0.0052
Score (accuracy) of the probe: 0.87
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0089
Epoch: [4/10], Loss: 0.0081
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 0.85
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0128
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0083
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0066
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.88
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0129
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0069
Epoch: [9/10], Loss: 0.0066
Epoch: [10/10], Loss: 0.0063
Score (accuracy) of the probe: 0.86

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.73
{'__OVERALL__': 0.7268623024830699, 'NAME': 0.7125, 'STRING': 1.0, 'NUMBER': 0.8518518518518519, 'KEYWORD': 0.8333333333333334}
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0125
Epoch: [2/10], Loss: 0.0101
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0075
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0057
Epoch: [10/10], Loss: 0.0054
Score (accuracy) of the probe: 0.84
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0127
Epoch: [2/10], Loss: 0.0102
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0082
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0070
Epoch: [7/10], Loss: 0.0065
Epoch: [8/10], Loss: 0.0061
Epoch: [9/10], Loss: 0.0058
Epoch: [10/10], Loss: 0.0054
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0120
Epoch: [2/10], Loss: 0.0097
Epoch: [3/10], Loss: 0.0087
Epoch: [4/10], Loss: 0.0079
Epoch: [5/10], Loss: 0.0073
Epoch: [6/10], Loss: 0.0068
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0060
Epoch: [9/10], Loss: 0.0056
Epoch: [10/10], Loss: 0.0053
Score (accuracy) of the probe: 0.89
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0130
Epoch: [2/10], Loss: 0.0107
Epoch: [3/10], Loss: 0.0097
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0083
Epoch: [6/10], Loss: 0.0078
Epoch: [7/10], Loss: 0.0074
Epoch: [8/10], Loss: 0.0070
Epoch: [9/10], Loss: 0.0067
Epoch: [10/10], Loss: 0.0064
Score (accuracy) of the probe: 0.89

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.71
{'__OVERALL__': 0.7110609480812641, 'NAME': 0.7, 'STRING': 1.0, 'NUMBER': 0.8518518518518519, 'KEYWORD': 0.6666666666666666}
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0091
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0079
Epoch: [6/10], Loss: 0.0074
Epoch: [7/10], Loss: 0.0070
Epoch: [8/10], Loss: 0.0067
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.83
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0129
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0070
Epoch: [9/10], Loss: 0.0067
Epoch: [10/10], Loss: 0.0064
Score (accuracy) of the probe: 0.80
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0128
Epoch: [2/10], Loss: 0.0105
Epoch: [3/10], Loss: 0.0095
Epoch: [4/10], Loss: 0.0088
Epoch: [5/10], Loss: 0.0082
Epoch: [6/10], Loss: 0.0077
Epoch: [7/10], Loss: 0.0073
Epoch: [8/10], Loss: 0.0070
Epoch: [9/10], Loss: 0.0066
Epoch: [10/10], Loss: 0.0064
Score (accuracy) of the probe: 0.83
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0134
Epoch: [2/10], Loss: 0.0112
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0084
Epoch: [7/10], Loss: 0.0080
Epoch: [8/10], Loss: 0.0077
Epoch: [9/10], Loss: 0.0074
Epoch: [10/10], Loss: 0.0071
Score (accuracy) of the probe: 0.85

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.64
{'__OVERALL__': 0.6433408577878104, 'NAME': 0.6525, 'STRING': 1.0, 'NUMBER': 0.5185185185185185, 'KEYWORD': 0.5}
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.90

pretrained_BERT top neurons
array([   0, 2055, 8200, 4108,   13, 6157,   15, 8204,   16,   21, 2070,
       8215, 4124,   31, 6175,   40, 6189, 4147, 4159, 2114, 6212, 8262,
         73, 6218, 8276, 2136, 8280, 8284, 4188,   94, 2144, 4193,   98,
       4197, 2150, 6245,  106, 6252,  117, 2167, 2173,  128, 8322, 4226,
        139, 4237, 6287, 6294,  157, 2208, 8357, 2219, 4276, 2237,  195,
       8390,  199,  203, 2255, 4306,  213, 2262, 8407, 6359, 4314,  220,
        222, 8415,  230, 2280, 8424, 8429, 8435,  248, 8442,  254, 8451,
       4357,  262, 2310, 4360, 8459, 2315, 4368, 2325, 4375, 6423, 6428,
       6434, 6440, 4394,  305, 8497,  307,  308, 6459, 8510, 6464, 4419,
       2373, 2375,  333, 8525,  336, 6484, 4447,  357,  370, 6516, 4477,
        383,  384, 6534, 6537, 8585, 6540,  397, 4498, 2457,  412,  415,
       8624, 6578, 4530, 6587, 8636, 4541, 4543, 2499, 6597, 4550,  455,
        471, 6618, 2523, 8673, 2531, 2533, 4582, 2534, 2541, 4590, 6661,
       6664,  521, 8712, 4619, 6668, 4622, 4623, 6679,  540, 8733, 4637,
       2588, 8739,  550, 4657, 8755, 2612, 6710, 2619, 8768,  596,  599,
        600, 2661, 4718,  622, 8815, 6772, 6781, 6783, 6784, 8838, 8839,
       6803, 6807,  669, 6822, 2728, 8873, 2730,  690, 2742, 4793, 6843,
        701, 8896, 8901, 6854,  714, 8915,  726,  729,  737, 6886, 4842,
       4845,  750,  752, 6899, 2804, 8952, 6906, 8965, 8968, 8972, 2829,
       8976, 4892, 6940, 4898, 2852,  808, 6957, 4915, 9015, 4923, 9020,
       2876, 2875, 2882, 2883, 6980, 9033,  844, 6989, 2903, 9054, 4963,
       2917,  870, 7020,  885, 2935,  898, 7048, 2957, 9111, 2969, 9115,
       2973, 7070, 2976,  928, 9125, 5046, 9151, 5058, 7108, 5061, 7115,
        981, 3030, 9175, 7126, 5082, 3038,  995, 3048, 9197, 3054, 1006,
       1008, 9203, 7155, 9210, 1030, 5128, 5129, 7181, 5136, 3093, 7191,
       7195, 7197, 1054, 9254, 3112, 3117, 1073, 1075, 1076, 7223, 1092,
       9286, 1098, 1101, 7248, 7252, 1125, 3173, 9317, 3181, 5245, 1151,
       7298, 1154, 7302, 1173, 3225, 1180, 1183, 5280, 3237, 7337, 7340,
       5298, 3252, 1204, 7355, 9404, 3260, 5309, 1215, 3267, 1225, 3275,
       5332, 1237, 3287, 9436, 5345, 3299, 3309, 1265, 9468, 7429, 5381,
       1287, 7432, 1289, 9480, 5387, 1290, 5390, 5391, 1302, 3356, 1316,
       7469, 9517, 3379, 3380, 1336, 5435, 3387, 3392, 1348, 7497, 7508,
       5460, 3420, 1376, 5472, 3431, 1387, 3437, 3444, 7545, 7549, 1405,
       7551, 7552, 3457, 9605, 5512, 1425, 9620, 1437, 5538, 7589, 5541,
       3493, 1458, 5556, 9658, 5564, 1469, 1471, 1477, 7622, 9680, 9683,
       1492, 9685, 7636, 1494, 5591, 3546, 3549, 1505, 7660, 5613, 1518,
       9711, 1520, 7667, 1525, 3592, 9736, 5644, 3597, 1557, 5660, 7708,
       5667, 1576, 3627, 1581, 7725, 9775, 1585, 5688, 5691, 3650, 3651,
       9796, 1612, 7757, 1628, 3679, 7794, 7799, 5756, 7804, 9860, 3718,
       3719, 5769, 7817, 3729, 7828, 5780, 3735, 9882, 7836, 1702, 7849,
       3762, 9908, 7861, 7860, 5817, 3773, 5826, 7875, 7876, 5829, 1731,
       1739, 3789, 1742, 9940, 1749, 3798, 7895, 5856, 7905, 9955, 1763,
       7910, 5863, 1768, 3822, 9971, 1788, 3840, 5893, 5904, 3861, 7959,
       3868, 3885, 3889, 1844, 1851, 1869, 8020, 8027, 1893, 1895, 3949,
       8060, 3965, 6013, 1920, 3970, 8069, 8080, 6034, 6039, 1948, 4005,
       8118, 8123, 6085, 6086, 8135, 4046, 8150, 2007, 6103, 8154, 6117,
       8171, 4077, 6126, 6128, 6131, 8184])
pretrained_BERT top neurons per class
{'NAME': array([7191, 7959,  262, 2144, 7589, 1844, 4550, 5129, 1425,   31, 4375,
        726, 1469, 4147, 5061, 7181, 7757, 6294, 8357, 2280, 1076, 6034,
       7508, 5345, 1518,  333, 3379, 8451, 5245, 3392, 7469, 1494,  117,
       4622, 5460, 9955, 3299, 3237, 7432,  199, 6252, 1869,  521, 4619,
       1287, 9125, 4498, 4419,   15, 1073, 7355,  600, 6843, 6540, 9775,
       7549, 5691, 5829, 4360, 5644, 9197,  701, 2935, 2070, 5660,  357,
         13, 7108, 1125, 7020, 7636, 8915, 2007, 6618, 8838,  471,  195,
       6459,   40, 6428, 2523, 1477,  336, 8459, 4368, 2255, 2531, 6597,
       3798, 9175, 2882, 9151,  752, 9020, 1289, 1920,  230, 4124, 9480,
       5128, 7298, 8673, 2661, 4108, 6679, 5769, 8968, 5387, 1437, 3267,
       6781, 6086, 1458, 8322, 7861, 4892, 4237, 4718, 2055, 8755, 3735,
        540, 2804, 1154, 7545, 7622, 1851,  737, 2114, 7252, 5817, 3651,
       5280, 7876, 8901, 6464, 1471, 2541, 4657, 8976, 1581, 8952, 1302,
       7497, 8733, 8215,  455, 3117]), 'STRING': array([6940, 5856, 9254, 1151,  752, 6661, 3054,   98, 4159, 1742, 3093,
        384, 2457,  669, 2070, 4541,  870, 6428,   31, 4046,  412, 9404,
       5826, 1290, 3861,  981, 7197, 3822, 9940, 8624, 9680, 1302, 4077,
       6423, 9605, 9197, 9971, 4898, 1183, 2531,  383, 1437, 1008, 5391,
       7552,  203, 5332, 2935, 5541, 3546, 3420, 2167, 3252, 1376, 4276,
       9203, 2237, 1265, 7660, 9468, 1788,  622, 2876, 7905, 6459, 6287,
       7861, 6039, 8357, 8118, 1075, 4193, 5472, 9210, 8839, 6807, 6103,
       7708, 5863, 8965, 1425,  844, 1749, 7828, 3549,  308, 9620, 8123,
       3173, 5136, 1225, 9658, 5058, 2375, 2852,  599, 4368, 5381, 6664,
       7817, 6537, 7070, 7876, 9115, 7337, 4314, 8442,  808, 3048, 7223,
         73, 7725, 8284, 7429, 4915, 2325, 5591, 3627, 7191, 8952,   21,
        254, 9711, 7667, 8636, 1237, 3117,  370, 3868, 8184, 3437, 1180,
       3457,  726,  305, 8510,  701, 3965, 7757, 7794, 7252, 6854, 7340,
       1492, 2728, 3380, 3030, 5460, 5435, 9015,  750, 8200, 6157,  157,
       3592, 8154, 3650, 3275, 4845]), 'NUMBER': array([8525, 7757, 2661, 8407, 6189, 3379, 1076, 1348, 4550, 6957, 6989,
        521, 3267, 1215, 7298, 6434, 8768, 6428, 3679, 6578,  750, 2829,
       1204, 3048, 3431, 4637, 3356, 6175, 1289, 9658, 2619,  222, 3112,
       6484, 9685, 5298, 2742, 1895, 8739, 4197, 5904,  213, 1183, 5564,
       2533, 4005,  550, 2315,  248, 9517, 3840, 4530, 1893, 7895, 1869,
       2150, 7191, 8080, 7551, 2457, 5082, 9436, 1505, 8027, 3885, 6128,
       1075, 6440, 1520, 3762, 3387, 5769, 2373, 8712, 4543, 2917, 6218,
       3718, 8435,   94,  117, 6126, 4447, 4108, 3789, 2499, 9404, 4306,
        885, 4718, 6822,    0, 1525, 9882, 9711, 1092, 5046, 3225, 1576,
       1387, 5688, 4923,  737, 8390, 3260, 2973, 9033, 7126, 3970, 2136,
       6980, 6784, 5512,  308, 8171, 9908, 9860, 1768,  714, 6587, 2957,
       4237, 8972, 1006, 5538, 7248, 8150, 1336, 3444, 1557, 5556, 6013,
       6783, 2173, 6803, 6294, 3889, 7181, 8415, 4590, 2903, 6359, 9683,
       6212, 4226, 5756, 6459, 4582, 4793, 6245, 2875,  220, 6516,  128,
       8280, 1763, 8896, 7155, 4394]), 'KEYWORD': array([7191, 7252,  521,  262, 4237, 7757, 1183, 3651, 8838, 2612, 3719,
       1030, 4477, 3309, 9197, 6534, 8322, 3773, 7432, 1101, 5460, 6252,
        139, 1125, 3650, 2531, 3493,  106, 4623, 6906, 1316, 2523, 1844,
       3299, 7048, 8915, 1869, 3181, 5691,  690, 4357, 1287,   31, 4622,
       1585, 9317, 8060, 3380, 5667, 6131, 2976, 7302, 2310, 2534,   98,
       6117,  415, 2883,  397, 6899, 3729, 8733, 6940, 1173, 2219, 1376,
       8673, 4159, 6128,  898, 5390, 8204, 5893, 5129, 5309, 5061, 3379,
       4842, 4915, 1948, 1405,   40, 4541, 2237, 7545, 8262, 7910, 9054,
       3112, 3627, 2730, 1180,  307, 9210,  600, 6886,   16, 1702, 7836,
         15, 6772, 4375, 3287, 8020, 2262, 1612, 8424, 9111,  333, 3038,
        596, 7667, 6464, 9286, 1054, 8276, 1098, 7799,  599, 2315, 7860,
       8815, 5613, 6710, 3597, 8585, 2208, 6668, 2588, 9605, 4963, 8429,
       7875, 9736,  928, 1628, 1731,  995, 8497, 7849, 6085, 1739, 4188,
       7337, 5660, 8135, 8873, 7804, 3949, 8069, 5780, 2969, 7115,  729,
       9796, 7195, 3735])}
The shape of selected features (851, 512)
The shape of the training set: (851, 512)
The shape of the validation set: (95, 512)
The shape of the testing set: (443, 512)
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0084
Epoch: [4/10], Loss: 0.0073
Epoch: [5/10], Loss: 0.0064
Epoch: [6/10], Loss: 0.0057
Epoch: [7/10], Loss: 0.0051
Epoch: [8/10], Loss: 0.0046
Epoch: [9/10], Loss: 0.0042
Epoch: [10/10], Loss: 0.0038
Score (accuracy) of the probe: 0.95
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0099
Epoch: [3/10], Loss: 0.0085
Epoch: [4/10], Loss: 0.0074
Epoch: [5/10], Loss: 0.0065
Epoch: [6/10], Loss: 0.0058
Epoch: [7/10], Loss: 0.0052
Epoch: [8/10], Loss: 0.0047
Epoch: [9/10], Loss: 0.0042
Epoch: [10/10], Loss: 0.0039
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0124
Epoch: [2/10], Loss: 0.0100
Epoch: [3/10], Loss: 0.0086
Epoch: [4/10], Loss: 0.0075
Epoch: [5/10], Loss: 0.0066
Epoch: [6/10], Loss: 0.0059
Epoch: [7/10], Loss: 0.0053
Epoch: [8/10], Loss: 0.0048
Epoch: [9/10], Loss: 0.0044
Epoch: [10/10], Loss: 0.0040
Score (accuracy) of the probe: 0.94
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0134
Epoch: [2/10], Loss: 0.0110
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0084
Epoch: [5/10], Loss: 0.0076
Epoch: [6/10], Loss: 0.0069
Epoch: [7/10], Loss: 0.0063
Epoch: [8/10], Loss: 0.0059
Epoch: [9/10], Loss: 0.0055
Epoch: [10/10], Loss: 0.0051
Score (accuracy) of the probe: 0.94

The best l1=0, the best l2=0 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.75
{'__OVERALL__': 0.7494356659142212, 'NAME': 0.7725, 'STRING': 1.0, 'NUMBER': 0.3333333333333333, 'KEYWORD': 0.8333333333333334}
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.90
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0122
Epoch: [2/10], Loss: 0.0110
Epoch: [3/10], Loss: 0.0101
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0082
Epoch: [7/10], Loss: 0.0077
Epoch: [8/10], Loss: 0.0073
Epoch: [9/10], Loss: 0.0069
Epoch: [10/10], Loss: 0.0065
Score (accuracy) of the probe: 0.80
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0129
Epoch: [2/10], Loss: 0.0115
Epoch: [3/10], Loss: 0.0105
Epoch: [4/10], Loss: 0.0097
Epoch: [5/10], Loss: 0.0091
Epoch: [6/10], Loss: 0.0085
Epoch: [7/10], Loss: 0.0080
Epoch: [8/10], Loss: 0.0076
Epoch: [9/10], Loss: 0.0072
Epoch: [10/10], Loss: 0.0068
Score (accuracy) of the probe: 0.76
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0123
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0102
Epoch: [4/10], Loss: 0.0094
Epoch: [5/10], Loss: 0.0088
Epoch: [6/10], Loss: 0.0083
Epoch: [7/10], Loss: 0.0078
Epoch: [8/10], Loss: 0.0074
Epoch: [9/10], Loss: 0.0070
Epoch: [10/10], Loss: 0.0066
Score (accuracy) of the probe: 0.82
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0133
Epoch: [2/10], Loss: 0.0121
Epoch: [3/10], Loss: 0.0112
Epoch: [4/10], Loss: 0.0105
Epoch: [5/10], Loss: 0.0099
Epoch: [6/10], Loss: 0.0093
Epoch: [7/10], Loss: 0.0088
Epoch: [8/10], Loss: 0.0084
Epoch: [9/10], Loss: 0.0080
Epoch: [10/10], Loss: 0.0077
Score (accuracy) of the probe: 0.78

The best l1=0, the best l2=0.01 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.63
{'__OVERALL__': 0.6275395033860045, 'NAME': 0.63, 'STRING': 1.0, 'NUMBER': 0.5925925925925926, 'KEYWORD': 0.5}
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.90
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 0 [('broadcast', 1.0), ('purpose', 0.9541024415259733), ('Stretch', 0.9412582470547126), ('scope', 0.919399249746982), ('Component', 0.8424544287627638)]
Top words for pretrained_BERT neuron indx 2055 [('filters', 1.0), ('f', 0.9933481163001449), ('seconds', 0.8723980058228384), ('uss', 0.8361487998026631), ('META', 0.8324758144351372)]
Top words for pretrained_BERT neuron indx 8200 [('pop', 1.0), ('60', 0.9106400031341467), ('80', 0.8996562704881859), ('1000', 0.8938247634403679), ('600', 0.8919998546209075)]
Top words for pretrained_BERT neuron indx 4108 [('Board', 1.0), ('direct', 0.9971459590100529), ('REQUEST', 0.941373065968001), ('render', 0.8890278498503502), ('i', 0.8749723555879919)]
Top words for pretrained_BERT neuron indx 13 [('field', 1.0), ('item', 0.9090791803642527), ('year', 0.8452370078830994), ('blocking', 0.7474586019005676), ('1000', 0.7404204037470309)]
Top words for pretrained_BERT neuron indx 6157 [('On', 1.0), ('builtins', 0.8373668703301205), ('ping', 0.798924813649951), ('IsSECANC', 0.7804835892002338), ('required', 0.7433094639703894)]
Top words for pretrained_BERT neuron indx 15 [('break', 1.0), ('slug', 0.8746834047622207), ('format', 0.8436382244899377), ('put', 0.7576288697117772), ('META', 0.7512174239717748)]
Top words for pretrained_BERT neuron indx 8204 [('end', 1.0), ('16', 0.9677555980695298), ('60', 0.9608949443583407), ('40', 0.9565970931459002), ('task', 0.9154181829608014)]
Top words for pretrained_BERT neuron indx 16 [('Board', 1.0), ('board', 0.7785906538579009), ('patch', 0.6406361889362672), ('stanza', 0.585770996056506), ('info', 0.5471971759909344)]
Top words for pretrained_BERT neuron indx 21 [('def', 1.0), ('user', 0.9671963691871117), ('models', 0.9661720583369803), ('zone', 0.9498142286383158), ('connection', 0.8954232887908103)]
Top words for pretrained_BERT neuron indx 2070 [('print', 1.0), ('k', 0.9625534057286073), ('clone', 0.9274553118174453), ('domain', 0.9259386212505673), ('open', 0.9059926431233521)]
Top words for pretrained_BERT neuron indx 8215 [('title', 1.0), ('"../../%s"', 0.9534365285800043), ('direct', 0.9324002525423555), ('decode', 0.9321875539964564), ('ds_owner_created', 0.902235052707149)]
Top words for pretrained_BERT neuron indx 4124 [('sorted', 1.0), ('View', 0.9717685532028685), ('""', 0.8167815209530883), ('Plugin', 0.7618461819623226), ('boot', 0.7554914545471325)]
Top words for pretrained_BERT neuron indx 31 [('Node', 1.0), ('objects', 0.9830036380247986), ('loads', 0.9735048580400586), ('token', 0.9060497653013085), ('ndt', 0.8914818612582961)]
Top words for pretrained_BERT neuron indx 6175 [('exceptions', 1.0), ('local', 0.9262107800185714), ('vwwn', 0.8614478376542943), ('models', 0.8468126840073014), ('traceback', 0.7455431690198386)]
Top words for pretrained_BERT neuron indx 40 [('def', 1.0), ('scope', 0.9357802471520117), ('int', 0.9263849770959423), ('loads', 0.9125700313269081), ('upper', 0.8981059299972222)]
Top words for pretrained_BERT neuron indx 6189 [('calendar', 1.0), ('description', 0.9899983957814009), ('item', 0.9566249816699832), ('parts', 0.8346864647807041), ('30', 0.8127733281623956)]
Top words for pretrained_BERT neuron indx 4147 [('loads', 1.0), ('"Host"', 0.7141178357437681), ('"r"', 0.6762442591358181), ('"Name"', 0.6567256661434353), ('""', 0.6563790590950223)]
Top words for pretrained_BERT neuron indx 4159 [('user', 1.0), ('start', 0.8507704408486703), ('Authorization', 0.8298882141537867), ('to', 0.8295410266944232), ('text', 0.8009516872021663)]
Top words for pretrained_BERT neuron indx 2114 [('upper', 1.0), ('wait', 0.8626842104990061), ('stanza', 0.829214133792304), ('help', 0.7993629135574672), ('settings', 0.7691838620680351)]
Top words for pretrained_BERT neuron indx 6212 [('action', 1.0), ('SaneTime', 0.9872866378063507), ('sanetime', 0.9152668939206179), ('time', 0.9151709544697428), ('class', 0.8747066024913158)]
Top words for pretrained_BERT neuron indx 8262 [('oslo', 1.0), ('find', 0.912282575429302), ('86400', 0.9052771545307289), ('message', 0.9027597727518591), ('Authorization', 0.8507515524944911)]
Top words for pretrained_BERT neuron indx 73 [('future', 1.0), ('utc', 0.9763772129200454), ('match', 0.9576060045634153), ('Unauthorized', 0.8488757985701004), ('False', 0.8037632185200992)]
Top words for pretrained_BERT neuron indx 6218 [('upper', 1.0), ('link', 0.8622959276894627), ('continue', 0.8238536972353455), ('host', 0.8087259617258531), ('alt', 0.7927101810913665)]
Top words for pretrained_BERT neuron indx 8276 [('token', 1.0), ('Exception', 0.9963670156775711), ('modes', 0.9881879563031324), ('help', 0.9398910406148097), ('vwwn', 0.9212499797242469)]
Top words for pretrained_BERT neuron indx 2136 [('created', 1.0), ('calendar', 0.9930649019476571), ('Register', 0.8741092967325459), ('task', 0.8527740671940658), ('register', 0.8424806396422623)]
Top words for pretrained_BERT neuron indx 8280 [('kls', 1.0), ('600', 0.9625612063056093), ('pytz', 0.9268742930760544), ('pxe', 0.8748560043607), ('config', 0.8613221548332783)]
Top words for pretrained_BERT neuron indx 8284 [('stat', 1.0), ('ms', 0.9580056537950876), ('utc', 0.8512582971648228), ('to', 0.820734646258647), ('end', 0.7643852805004646)]
Top words for pretrained_BERT neuron indx 4188 [('Log', 1.0), ('st', 0.8938652299712863), ('purpose', 0.8538156682281381), ('put', 0.713486559690595), ('loads', 0.7053769791563019)]
Top words for pretrained_BERT neuron indx 94 [('affinity', 1.0), ('identity', 0.9725634004224342), ('authentication', 0.8380002382022914), ('key', 0.791495817874774), ('session', 0.7030089253794803)]
Top words for pretrained_BERT neuron indx 2144 [('Log', 1.0), ('body', 0.933601791541185), ('common', 0.8526974600615969), ('line', 0.84366630741154), ('reactor', 0.8333143894648358)]
Top words for pretrained_BERT neuron indx 4193 [('second', 1.0), ('long', 0.919456229202189), ('repr', 0.8545019900220466), ('\\\'"\\\'', 0.8269307746737937), ('utc_datetime', 0.7662677280604989)]
Top words for pretrained_BERT neuron indx 98 [('hour', 1.0), ('minute', 0.9351631138596687), ('ms', 0.8795011604780231), ('iq', 0.8294832409111155), ('resource', 0.8225935968177597)]
Top words for pretrained_BERT neuron indx 4197 [('script', 1.0), ('contents', 0.8656251428541288), ('Off', 0.7967446181355294), ('""', 0.7679836315541474), ('group', 0.7223078919653564)]
Top words for pretrained_BERT neuron indx 2150 [('authorization', 1.0), ('LoadUser', 0.8056654531775186), ('script', 0.7972446581985251), ('resource', 0.7480006454064952), ('unicode', 0.7459299852795211)]
Top words for pretrained_BERT neuron indx 6245 [('patch', 1.0), ('replace', 0.8142140591097612), ('alt', 0.8126531261886288), ('route', 0.794543180457749), ('add', 0.7848848323869767)]
Top words for pretrained_BERT neuron indx 106 [('add', 1.0), ('GET', 0.9620856565106511), ('probe', 0.9332662902360389), ('activity', 0.9328161067218115), ('authorized', 0.9307652125975768)]
Top words for pretrained_BERT neuron indx 6252 [('authentication', 1.0), ('k', 0.9221165040488506), ('"oslo"', 0.9033448749128654), ('"Name"', 0.8820375326445318), ('exceptions', 0.8612034725828)]
Top words for pretrained_BERT neuron indx 117 [('minute', 1.0), ('join', 0.9019744157695692), ('target', 0.8563563232960155), ('component', 0.8518928079141367), ('server', 0.8388007077256812)]
Top words for pretrained_BERT neuron indx 2167 [('child', 1.0), ('send', 0.9306836394391359), ('prange', 0.8390965406776391), ('force', 0.8352002250224426), ('ref', 0.8331527039750952)]
Top words for pretrained_BERT neuron indx 2173 [('match', 1.0), ('reactor', 0.9135734913635709), ('class', 0.8868055009005956), ('continue', 0.844398156124818), ('while', 0.8303069847975308)]
Top words for pretrained_BERT neuron indx 128 [('f', 1.0), ('prange', 0.7439040730805204), ('freshtime', 0.7308313626397538), ('boot', 0.7187236224285535), ('hour', 0.7173011573649151)]
Top words for pretrained_BERT neuron indx 8322 [('end', 1.0), ('unicode', 0.8924236707396649), ('On', 0.8485003736611412), ('child', 0.8055323191332364), ('identity', 0.7716786646733579)]
Top words for pretrained_BERT neuron indx 4226 [('upper', 1.0), ('Mesh', 0.9350526320011416), ('Off', 0.9346091747710551), ('as', 0.9332089367338233), ('title', 0.9225077412559356)]
Top words for pretrained_BERT neuron indx 139 [('utc', 1.0), ('utcnow', 0.8794712329199594), ('reactor', 0.8181120847135982), ('endswith', 0.7415183798077446), ('disable_manage_boot', 0.7349212964604881)]
Top words for pretrained_BERT neuron indx 4237 [('close', 1.0), ('Billboard', 0.9748133400377804), ('slug', 0.9277852221301116), ('Simple', 0.8846947664542082), ('re', 0.858969531005803)]
Top words for pretrained_BERT neuron indx 6287 [('Unauthorized', 1.0), ('patch', 0.999181014635374), ('long', 0.9243079867940582), ('port', 0.8261407775045871), ('servers', 0.7886410406805405)]
Top words for pretrained_BERT neuron indx 6294 [('def', 1.0), ('Session', 0.6860085309188039), ('part', 0.6615538872238582), ('Util', 0.63646069002191), ('View', 0.6100104103177683)]
Top words for pretrained_BERT neuron indx 157 [('help', 1.0), ('Unauthorized', 0.8944375697853634), ('models', 0.8836273053710441), ('int', 0.8384116984786045), ('GetInt', 0.7978202936543591)]
Top words for pretrained_BERT neuron indx 2208 [('purpose', 1.0), ('key', 0.989799701516163), ('Exception', 0.9310981641188726), ('info', 0.8432817347445474), ('authorized', 0.8372197399036871)]
Top words for pretrained_BERT neuron indx 8357 [('if', 1.0), ('META', 0.9214870871968129), ('1800', 0.7066530678243613), ('400', 0.6901527916192977), ('14', 0.6651867544519667)]
Top words for pretrained_BERT neuron indx 2219 [('Exception', 1.0), ('split', 0.8248787706393228), ('filter', 0.7986596926469693), ('uss', 0.7797300243251841), ('port', 0.7705922179131788)]
Top words for pretrained_BERT neuron indx 4276 [('utc', 1.0), ('link', 0.9105449377851036), ('partition', 0.828320352552046), ('main', 0.7860524309419228), ('utcnow', 0.7670249514546562)]
Top words for pretrained_BERT neuron indx 2237 [('enabled', 1.0), ('Node', 0.898814841699704), ('other', 0.8515890852962995), ('sts', 0.7959014023276405), ('None', 0.7892253894689821)]
Top words for pretrained_BERT neuron indx 195 [('add', 1.0), ('reactor', 0.8317328899680987), ('material', 0.8083987524906315), ('error', 0.8006356469566076), ('mtime', 0.7337451124259456)]
Top words for pretrained_BERT neuron indx 8390 [('600', 1.0), ('20', 0.9434419958724868), ('domain', 0.9076723549083568), ('400', 0.8926381159557877), ('1024', 0.8921566509392209)]
Top words for pretrained_BERT neuron indx 199 [('presence', 1.0), ('slug', 0.8166824354073738), ('60', 0.7995690380530188), ('80', 0.7658016264207859), ('boot', 0.7594794996857733)]
Top words for pretrained_BERT neuron indx 203 [('loads', 1.0), ('operand', 0.9638397998078724), ('startswith', 0.9187956305520608), ('probe', 0.8788001344449654), ('format', 0.8771432876846141)]
Top words for pretrained_BERT neuron indx 2255 [('parts', 1.0), ('part', 0.8236360899024884), ('None', 0.785716925356684), ('key', 0.7629552311008366), ('closing', 0.7621215163210969)]
Top words for pretrained_BERT neuron indx 4306 [('materials', 1.0), ('15', 0.9640652311227937), ('17', 0.9530931597066714), ('800', 0.9212012003418624), ('30', 0.8462043795530405)]
Top words for pretrained_BERT neuron indx 213 [('exit', 1.0), ('line', 0.9943089498374184), ('val', 0.9498200278011298), ('write', 0.9442242303011763), ('close', 0.9352945237360282)]
Top words for pretrained_BERT neuron indx 2262 [('count', 1.0), ('seek', 0.9891025765965301), ('close', 0.9707754005167959), ('while', 0.8536856995201181), ('closing', 0.8324036913990402)]
Top words for pretrained_BERT neuron indx 8407 [('upper', 1.0), ('to', 0.9317382873985615), ('REQUEST', 0.749556245111983), ('us', 0.7104091862016972), ('core', 0.710303708276335)]
Top words for pretrained_BERT neuron indx 6359 [('from', 1.0), ('openstack', 0.9625317101481835), ('Authorization', 0.9615096868067061), ('9', 0.9489478315407154), ('to', 0.9126245734926564)]
Top words for pretrained_BERT neuron indx 4314 [('Tab', 1.0), ('Profile', 0.7762297507790323), ('import', 0.7651216185999334), ('as', 0.6843238698584165), ('PY2', 0.6047368904556961)]
Top words for pretrained_BERT neuron indx 220 [('Log', 1.0), ('logging', 0.9204499219435507), ('error', 0.8726840104450206), ('log', 0.8684055152274885), ('connection', 0.8205643593329633)]
Top words for pretrained_BERT neuron indx 222 [('item', 1.0), ('description', 0.9911464295709503), ('return', 0.9636945987637422), ('probe', 0.8635669207003558), ('routes', 0.8550313935327294)]
Top words for pretrained_BERT neuron indx 8415 [('replace', 1.0), ('us', 0.921030434831245), ('9', 0.9186111192526413), ('False', 0.8110569090042248), ('tz', 0.8048535421353558)]
Top words for pretrained_BERT neuron indx 230 [('calendar', 1.0), ('v', 0.985249358357714), ('register', 0.8225069420098561), ('digest', 0.8191654587635807), ('patch', 0.8080653455208908)]
Top words for pretrained_BERT neuron indx 2280 [('REQUEST', 1.0), ('int', 0.9993000746737052), ('probe', 0.9730612663253483), ('push', 0.9511593586253402), ('read', 0.9218520030563941)]
Top words for pretrained_BERT neuron indx 8424 [('600', 1.0), ('authorization', 0.849935851772957), ('import', 0.8476276393639742), ('3700', 0.8459670899305076), ('format', 0.8384054654913754)]
Top words for pretrained_BERT neuron indx 8429 [('128', 1.0), ('repr', 0.9733747842570138), ('pop', 0.8747842905624492), ('Distance', 0.8442057018079167), ('16', 0.8138989242222534)]
Top words for pretrained_BERT neuron indx 8435 [('seconds', 1.0), ('400', 0.978846420087767), ('E', 0.9781080433473229), ('600', 0.9236098544956861), ('add', 0.8567887457930833)]
Top words for pretrained_BERT neuron indx 248 [('profile', 1.0), ('Profile', 0.9592287039413705), ('board', 0.952023846158776), ('logging', 0.9368907988487087), ('partition', 0.8784581074256809)]
Top words for pretrained_BERT neuron indx 8442 [('add', 1.0), ('return', 0.9534167485026874), ('future', 0.9284471891654683), ('session', 0.8984446323907932), ('argparse', 0.8924260972715102)]
Top words for pretrained_BERT neuron indx 254 [('root', 1.0), ('enabled', 0.9831997100598608), ('sorted', 0.9087618806923494), ('slug', 0.8466372973989769), ('route', 0.8408032502602423)]
Top words for pretrained_BERT neuron indx 8451 [('80', 1.0), ('if', 0.8947181953794062), ('20', 0.7957854977897645), ('hasattr', 0.7691835918049604), ('30', 0.7679776642586446)]
Top words for pretrained_BERT neuron indx 4357 [('sanetime', 1.0), ('Exception', 0.922431516744672), ('oslo', 0.8913578346180238), ('tastypie', 0.8817738979944659), ('resource', 0.8676321426538459)]
Top words for pretrained_BERT neuron indx 262 [('identity', 1.0), ('stanza', 0.9694626746440145), ('zone', 0.8555129974119958), ('ping', 0.8487875353683252), ('Distance', 0.7877083682619527)]
Top words for pretrained_BERT neuron indx 2310 [('20000', 1.0), ('ignore', 0.9075397195240855), ('8000', 0.8744108079040122), ('800', 0.8206802646899753), ('format', 0.7935776279088285)]
Top words for pretrained_BERT neuron indx 4360 [('con', 1.0), ('pop', 0.9604719113262591), ('re', 0.7551073841973486), ('1000', 0.7397553062448706), ('400', 0.7344899716351749)]
Top words for pretrained_BERT neuron indx 8459 [('14', 1.0), ('9', 0.8999513870129602), ('17', 0.8086839682831208), ('import', 0.7871446826704587), ('15', 0.7194033813649108)]
Top words for pretrained_BERT neuron indx 2315 [('year', 1.0), ('key', 0.9432486931257745), ('choices', 0.9009630705599158), ('domain', 0.8545560069716062), ('context', 0.8351804635603622)]
Top words for pretrained_BERT neuron indx 4368 [('pop', 1.0), ('ignore', 0.8947157548438386), ('types', 0.8295492177794435), ('log', 0.7982694647107184), ('400', 0.7927589014950034)]
Top words for pretrained_BERT neuron indx 2325 [('method', 1.0), ('start', 0.990059136847429), ('Off', 0.9131683264779015), ('pop', 0.9081382770348172), ('types', 0.8841985272926178)]
Top words for pretrained_BERT neuron indx 4375 [('token', 1.0), ('86400', 0.9217300637831378), ('3600', 0.887196770549467), ('item', 0.8801394471972873), ('80', 0.8785005247950227)]
Top words for pretrained_BERT neuron indx 6423 [('replace', 1.0), ('session', 0.9415016700884511), ('Session', 0.9166098354840576), ('ref', 0.8635627756908032), ('loads', 0.7803531567497463)]
Top words for pretrained_BERT neuron indx 6428 [('View', 1.0), ('if', 0.9488813188042668), ('url', 0.8761714049330238), ('Plugin', 0.846333860079992), ('None', 0.7691955834038209)]
Top words for pretrained_BERT neuron indx 6434 [('route', 1.0), ('modes', 0.9770205984214393), ('routes', 0.8896362884575785), ('List', 0.8710151627000711), ('created', 0.8640079758435907)]
Top words for pretrained_BERT neuron indx 6440 [('from', 1.0), ('nsanetime', 0.7189062032237875), ('False', 0.7081561885028962), ('IsSECANC', 0.6950599060358542), ('url', 0.6826578515253473)]
Top words for pretrained_BERT neuron indx 4394 [('pop', 1.0), ('digest', 0.9135267649797308), ('sorted', 0.8680765539646143), ('Digest', 0.8591098755613534), ('strip', 0.7526283734459162)]
Top words for pretrained_BERT neuron indx 305 [('identity', 1.0), ('error', 0.9112002858217254), ('utc', 0.7864092354631974), ('domain', 0.784628447896039), ('replace', 0.7397815908859828)]
Top words for pretrained_BERT neuron indx 8497 [('wait', 1.0), ('seek', 0.9894230029259912), ('Authorization', 0.9435374588210284), ('authorization', 0.9241744218323084), ('msgbox', 0.8690664013743747)]
Top words for pretrained_BERT neuron indx 307 [('close', 1.0), ('loads', 0.8321363124703902), ('partition', 0.7256524268343756), ('Profile', 0.7237465043611263), ('roster', 0.6913081337516109)]
Top words for pretrained_BERT neuron indx 308 [('".."', 1.0), ('to', 0.9867403510237927), ('with', 0.8343859976152751), ('""', 0.7803293137970155), ('"../../%s"', 0.7395643377567517)]
Top words for pretrained_BERT neuron indx 6459 [('sorted', 1.0), ('with', 0.9708883808412826), ('long', 0.8845108591227738), ('profile', 0.8662582574552009), ('wait', 0.8183737820763541)]
Top words for pretrained_BERT neuron indx 8510 [('mins', 1.0), ('kls', 0.853212216009615), ('ms', 0.8339920710943333), ('millis', 0.824925071395114), ('us', 0.8065990236654624)]
Top words for pretrained_BERT neuron indx 6464 [('seek', 1.0), ('find', 0.9383967741876159), ('Board', 0.9100216067177375), ('close', 0.8557609638173109), ('META', 0.7858151058979742)]
Top words for pretrained_BERT neuron indx 4419 [('local', 1.0), ('id', 0.9164497805934984), ('target', 0.8687493700181093), ('v', 0.8145574938077701), ('int', 0.7979017493316106)]
Top words for pretrained_BERT neuron indx 2373 [('resource', 1.0), ('val', 0.8914092942762984), ('bare', 0.8497490447186609), ('sans', 0.7665271901048988), ('kls', 0.7625524318729666)]
Top words for pretrained_BERT neuron indx 2375 [('link', 1.0), ('dt', 0.8752796509411701), ('count', 0.7957358620282805), ('if', 0.7553518837015121), ('purpose', 0.746460401880525)]
Top words for pretrained_BERT neuron indx 333 [('24', 1.0), ('Unauthorized', 0.9929125996027518), ('enclosure', 0.9823657006343189), ('main', 0.9481312240469908), ('horizon', 0.926897504222984)]
Top words for pretrained_BERT neuron indx 8525 [('postinfo', 1.0), ('closing', 0.9809295023311845), ('Stretch', 0.8823758079070536), ('Tab', 0.8702249630014105), ('rosters', 0.8294432234856305)]
Top words for pretrained_BERT neuron indx 336 [('hour', 1.0), ('objects', 0.9624441571770519), ('domain', 0.940203382412957), ('enclosure', 0.9165541547557586), ('exceptions', 0.8999456374606074)]
Top words for pretrained_BERT neuron indx 6484 [('".."', 1.0), ('""', 0.9820569991742524), ('9', 0.9358414453001355), ('"Port"', 0.8646335389596325), ('"Attach"', 0.8151160578007368)]
Top words for pretrained_BERT neuron indx 4447 [('other', 1.0), ('state', 0.9283426480757502), ('dict', 0.9243499160956826), ('child', 0.9227308913274812), ('operand', 0.864362817755978)]
Top words for pretrained_BERT neuron indx 357 [('boot', 1.0), ('contents', 0.8722259392479665), ('Stretch', 0.765687294585199), ('link', 0.7546432060596474), ('title', 0.7071524798099849)]
Top words for pretrained_BERT neuron indx 370 [('domain', 1.0), ('token', 0.8572699599976381), ('format', 0.840722546825463), ('bind', 0.8338180555373668), ('Log', 0.8087750514475267)]
Top words for pretrained_BERT neuron indx 6516 [('ref', 1.0), ('text', 0.867452278979598), ('us', 0.7609584446217234), ('24', 0.7330347667536723), ('connection', 0.7098584122547601)]
Top words for pretrained_BERT neuron indx 4477 [('300', 1.0), ('17', 0.9594403079729918), ('30', 0.8837788868508527), ('reactor', 0.8226069028955755), ('32', 0.7933300477661818)]
Top words for pretrained_BERT neuron indx 383 [('child', 1.0), ('minute', 0.9216111154840926), ('presence', 0.8776294485701396), ('proxy', 0.8425981523418244), ('key', 0.8362170049845022)]
Top words for pretrained_BERT neuron indx 384 [('Profile', 1.0), ('strip', 0.9950766816685415), ('wait', 0.9804547963984203), ('profile', 0.9507998078699179), ('probe', 0.8232296879316384)]
Top words for pretrained_BERT neuron indx 6534 [('"purpose"', 1.0), ('"r"', 0.9561115591738898), ('"gbk"', 0.8381329473010982), ('"oslo"', 0.8334175970655353), ('"Path"', 0.771104211392251)]
Top words for pretrained_BERT neuron indx 6537 [('contents', 1.0), ('user', 0.9013714962812527), ('credential', 0.789884404075907), ('core', 0.7679381610544753), ('startswith', 0.763542039949798)]
Top words for pretrained_BERT neuron indx 8585 [('tz', 1.0), ('send', 0.8683518781404241), ('tzinfo', 0.8151792651941187), ('created', 0.7925011128923336), ('f', 0.7752508675335056)]
Top words for pretrained_BERT neuron indx 6540 [('sts', 1.0), ('store', 0.827980312013715), ('stanza', 0.7290938182086231), ('long', 0.7017883091605722), ('args', 0.6660310149199207)]
Top words for pretrained_BERT neuron indx 397 [('utc', 1.0), ('decode', 0.9355066049476727), ('sts', 0.9066294998946224), ('datetime', 0.8247282102876271), ('while', 0.8060146790289258)]
Top words for pretrained_BERT neuron indx 4498 [('text', 1.0), ('put', 0.9564011032520449), ('replace', 0.7578700719433923), ('strip', 0.724427083990307), ('render', 0.6741372717141428)]
Top words for pretrained_BERT neuron indx 2457 [('main', 1.0), ('domain', 0.923878244293465), ('proxy', 0.7990618537326967), ('boot', 0.7983779270062412), ('utc', 0.7976158372253338)]
Top words for pretrained_BERT neuron indx 412 [('count', 1.0), ('sorted', 0.8616370646051545), ('Component', 0.7702485001265443), ('created', 0.7578123925050733), ('while', 0.7512625767761341)]
Top words for pretrained_BERT neuron indx 415 [('import', 1.0), ('patch', 0.9336866961221258), ('local', 0.8312536460867939), ('vsn', 0.8044807223392823), ('action', 0.8021166777734549)]
Top words for pretrained_BERT neuron indx 8624 [('""', 1.0), ('sans', 0.8794238695825912), ('milliseconds', 0.7480501703414743), ('millis', 0.7461597403430369), ('Billboard', 0.7217262026116895)]
Top words for pretrained_BERT neuron indx 6578 [('exit', 1.0), ('start', 0.8595833113709439), ('push', 0.8216217944756563), ('idList', 0.8190044267089314), ('features', 0.7894723210277308)]
Top words for pretrained_BERT neuron indx 4530 [('30', 1.0), ('Mesh', 0.9791540706751344), ('choices', 0.9686879101590736), ('if', 0.9626190606708941), ('replace', 0.899583882182671)]
Top words for pretrained_BERT neuron indx 6587 [('slug', 1.0), ('v', 0.9434848392740144), ('connection', 0.87987395894547), ('with', 0.8373411146460246), ('us', 0.8201590711057974)]
Top words for pretrained_BERT neuron indx 8636 [('message', 1.0), ('route', 0.9537246802996083), ('connection', 0.9038214805716509), ('partition', 0.8817377727365093), ('1000', 0.8776470639875876)]
Top words for pretrained_BERT neuron indx 4541 [('Node', 1.0), ('None', 0.8274757974813033), ('v', 0.7137315120499345), ('Off', 0.6771850805816206), ('encode', 0.6664903220316426)]
Top words for pretrained_BERT neuron indx 4543 [('enum', 1.0), ('sts', 0.9698020443408538), ('List', 0.9685214714071406), ('iq', 0.8953233830486318), ('hpOneView', 0.8533874342132673)]
Top words for pretrained_BERT neuron indx 2499 [('Exception', 1.0), ('clone', 0.9281023238312649), ('Board', 0.9269861744758207), ('domain', 0.9178381950507762), ('material', 0.8321279601306916)]
Top words for pretrained_BERT neuron indx 6597 [('bind', 1.0), ('30', 0.9284594010798997), ('300', 0.914391917744753), ('20', 0.9107049297160649), ('32', 0.9107045629853834)]
Top words for pretrained_BERT neuron indx 4550 [('80', 1.0), ('40', 0.9616211133162204), ('20', 0.868495590702905), ('400', 0.8493788299881772), ('60', 0.8398177693603973)]
Top words for pretrained_BERT neuron indx 455 [('error', 1.0), ('dt', 0.6768642880763206), ('write', 0.6735597205583833), ('oslo', 0.6674143279191868), ('choices', 0.6604580927833926)]
Top words for pretrained_BERT neuron indx 471 [('stat', 1.0), ('reactor', 0.6415225670666314), ('host', 0.5832762623084534), ('META', 0.5504447075892938), ('ranges', 0.5300444728646122)]
Top words for pretrained_BERT neuron indx 6618 [('20', 1.0), ('30', 0.9726105722304563), ('parts', 0.9482085873559746), ('wait', 0.8952410517970808), ('32', 0.8895819745798264)]
Top words for pretrained_BERT neuron indx 2523 [('128', 1.0), ('32', 0.9687936216052035), ('minute', 0.9407137105355091), ('uss', 0.9098067994278931), ('hour', 0.8875344983850822)]
Top words for pretrained_BERT neuron indx 8673 [('blocking', 1.0), ('presence', 0.8996854737414685), ('__long__', 0.8606693446878722), ('ignore', 0.810712233366215), ('ARTICLE_TITLE_LEN', 0.7317339803179298)]
Top words for pretrained_BERT neuron indx 2531 [('save', 1.0), ('boot', 0.8770747213726318), ('login', 0.8051129184623009), ('def', 0.791293257610629), ('join', 0.7892845423358027)]
Top words for pretrained_BERT neuron indx 2533 [('strip', 1.0), ('Simple', 0.9789796227694592), ('core', 0.9330342587734402), ('force', 0.9025652724033832), ('1000', 0.8913456617595521)]
Top words for pretrained_BERT neuron indx 4582 [('ignore', 1.0), ('24', 0.8037700188665461), ('us', 0.7881693984956955), ('purpose', 0.767244597548074), ('other', 0.7613206805341078)]
Top words for pretrained_BERT neuron indx 2534 [('title', 1.0), ('v', 0.9982617382453308), ('message', 0.7465338440610656), ('direct', 0.728744273713713), ('state', 0.7266893904648737)]
Top words for pretrained_BERT neuron indx 2541 [('title', 1.0), ('unicode', 0.9712720557789146), ('upper', 0.9150213044465518), ('egs', 0.7924695905182969), ('end', 0.7909139429477162)]
Top words for pretrained_BERT neuron indx 4590 [('List', 1.0), ('GetBoard', 0.9795228722205289), ('Board', 0.8970347165366248), ('Component', 0.8643192686477583), ('24', 0.8568735886724337)]
Top words for pretrained_BERT neuron indx 6661 [('models', 1.0), ('year', 0.8805543999601716), ('tz', 0.8229873515814005), ('authentication', 0.7705572738950052), ('month', 0.7491552244358789)]
Top words for pretrained_BERT neuron indx 6664 [('pop', 1.0), ('con', 0.8821568774869101), ('600', 0.8433375506849082), ('400', 0.8133500109393768), ('40', 0.7730838216914164)]
Top words for pretrained_BERT neuron indx 521 [('class', 1.0), ('save', 0.922109573892824), ('us', 0.9217373733152617), ('profile', 0.9103293495727132), ('BlendProbes', 0.8685046238433449)]
Top words for pretrained_BERT neuron indx 8712 [('save', 1.0), ('Board', 0.882529847879735), ('body', 0.8742211794977032), ('hpov', 0.8715827532136787), ('"!@#$%"', 0.8261301809552374)]
Top words for pretrained_BERT neuron indx 4619 [('14', 1.0), ('Off', 0.960728650911685), ('Exception', 0.8992989044927087), ('16', 0.8547845451450401), ('400', 0.8416314298364023)]
Top words for pretrained_BERT neuron indx 6668 [('task', 1.0), ('end', 0.9553177745133182), ('v', 0.8304706261749066), ('On', 0.8034160915169688), ('tastypie', 0.7395182046370841)]
Top words for pretrained_BERT neuron indx 4622 [('key', 1.0), ('force', 0.966987790486565), ('choices', 0.8458558728626131), ('enclosure', 0.7700431087839176), ('oslo', 0.7495966610549943)]
Top words for pretrained_BERT neuron indx 4623 [('key', 1.0), ('as', 0.990240067559306), ('break', 0.7248089891608711), ('Tab', 0.7042802834969452), ('Plugin', 0.6959474698677761)]
Top words for pretrained_BERT neuron indx 6679 [('3600', 1.0), ('def', 0.9488868292916776), ('decode', 0.935874851995653), ('3700', 0.9272203385411519), ('800', 0.9265475819520412)]
Top words for pretrained_BERT neuron indx 540 [('Board', 1.0), ('created', 0.9736386554369424), ('enabled', 0.9160554876073689), ('part', 0.9150592108787411), ('False', 0.9022732006065773)]
Top words for pretrained_BERT neuron indx 8733 [('log', 1.0), ('Log', 0.7705195343093956), ('400', 0.7642139317566541), ('zone', 0.7306946224289068), ('800', 0.6317189566356283)]
Top words for pretrained_BERT neuron indx 4637 [('session', 1.0), ('action', 0.8793163950596489), ('sans', 0.8521666460372087), ('32', 0.8307721435963398), ('other', 0.7448539604518404)]
Top words for pretrained_BERT neuron indx 2588 [('sorted', 1.0), ('View', 0.8482510357943354), ('v', 0.7223301077545736), ('port', 0.6746936565837365), ('resource', 0.6720421429456113)]
Top words for pretrained_BERT neuron indx 8739 [('pop', 1.0), ('entity', 0.9430421851561346), ('template', 0.9109472233029504), ('routes', 0.8971478701447853), ('us', 0.8771990723884463)]
Top words for pretrained_BERT neuron indx 550 [('servers', 1.0), ('Unauthorized', 0.977921227488852), ('routes', 0.9558688452005034), ('ranges', 0.8936157757400756), ('pass', 0.8534969820371597)]
Top words for pretrained_BERT neuron indx 4657 [('Authorization', 1.0), ('end', 0.9092544136419815), ('required', 0.8941423615458158), ('authorization', 0.8671060886877549), ('24', 0.8303812566576758)]
Top words for pretrained_BERT neuron indx 8755 [('""', 1.0), ('"r"', 0.9490722930416878), ('"purpose"', 0.8261358218639449), ('loads', 0.817536559206994), ('log', 0.8139103869547241)]
Top words for pretrained_BERT neuron indx 2612 [('as', 1.0), ('with', 0.986124523395788), ('from', 0.9282798240910204), ('".."', 0.8717667046279615), ('to', 0.8258761667211725)]
Top words for pretrained_BERT neuron indx 6710 [('logging', 1.0), ('from', 0.9755342743258414), ('as', 0.8990798941105576), ('find', 0.8387233011967411), ('Exception', 0.8086356445855611)]
Top words for pretrained_BERT neuron indx 2619 [('field', 1.0), ('part', 0.9896328470951983), ('sorted', 0.9626532253364593), ('ping', 0.9176688916653801), ('LoadUser', 0.9168903679043978)]
Top words for pretrained_BERT neuron indx 8768 [('while', 1.0), ('if', 0.9585437396475428), ('local', 0.9314944581102096), ('WeakLocal', 0.886356009019974), ('find', 0.8173517283446936)]
Top words for pretrained_BERT neuron indx 596 [('800', 1.0), ('stanza', 0.9485991480073748), ('alt', 0.7752509866458743), ('wait', 0.7704726615281344), ('clone', 0.733758073343799)]
Top words for pretrained_BERT neuron indx 599 [('1000', 1.0), ('objects', 0.9333793941168708), ('View', 0.890806502806513), ('break', 0.8777325210645002), ('sans', 0.8746107751408555)]
Top words for pretrained_BERT neuron indx 600 [('connection', 1.0), ('oslo', 0.9964591409020591), ('future', 0.9917617940279466), ('Register', 0.9863078856318109), ('register', 0.9711130930289624)]
Top words for pretrained_BERT neuron indx 2661 [('contents', 1.0), ('arg', 0.7109199508163212), ('closing', 0.681452966309991), ('boot', 0.6748180817664837), ('link', 0.6699609077857631)]
Top words for pretrained_BERT neuron indx 4718 [('Session', 1.0), ('slug', 0.846460347255012), ('stanza', 0.8440956145700934), ('affinity', 0.7984114346489724), ('utc', 0.7328811366728547)]
Top words for pretrained_BERT neuron indx 622 [('probe', 1.0), ('unpack', 0.9893680452717201), ('other', 0.9253412578045415), ('Library', 0.9118145668440204), ('parts', 0.9115663974081258)]
Top words for pretrained_BERT neuron indx 8815 [('".."', 1.0), ('with', 0.879395894312433), ('"oslo"', 0.8610731023979618), ('"purpose"', 0.8075930877229842), ('if', 0.7972484817104027)]
Top words for pretrained_BERT neuron indx 6772 [('""', 1.0), ('find', 0.9440125533324709), ('request', 0.8982615549863542), ('bool', 0.8552991018988317), ('pid', 0.8417941758544407)]
Top words for pretrained_BERT neuron indx 6781 [('300', 1.0), ('30', 0.9062339218892873), ('continue', 0.8944608326246299), ('Distance', 0.888926697662731), ('time', 0.8704149590798361)]
Top words for pretrained_BERT neuron indx 6783 [('open', 1.0), ('Unauthorized', 0.994265071175358), ('Tab', 0.8971225462015654), ('as', 0.8854917193487863), ('closing', 0.8779302253817601)]
Top words for pretrained_BERT neuron indx 6784 [('300', 1.0), ('oslo', 0.9459694778257578), ('unicode', 0.9367366876209535), ('ignore', 0.9188675548523042), ('localize', 0.8855985270524841)]
Top words for pretrained_BERT neuron indx 8838 [('"Name"', 1.0), ('"r"', 0.9391471250471506), ('"purpose"', 0.8603852675485318), ('stat', 0.7943736278237788), ('config', 0.7559064027981697)]
Top words for pretrained_BERT neuron indx 8839 [('close', 1.0), ('24', 0.8521701890731642), ('postinfo', 0.7911982103509309), ('blocking', 0.7152008961218063), ('val', 0.6888527849807742)]
Top words for pretrained_BERT neuron indx 6803 [('600', 1.0), ('month', 0.9357103005646404), ('types', 0.9239067995993648), ('1000', 0.8617801185118217), ('as', 0.8282309923956687)]
Top words for pretrained_BERT neuron indx 6807 [('Board', 1.0), ('40', 0.8836983523536918), ('pop', 0.861724077084198), ('32', 0.8299095700914095), ('field', 0.8158071726274523)]
Top words for pretrained_BERT neuron indx 669 [('Board', 1.0), ('board', 0.9802112484554407), ('boardname', 0.9607358418477064), ('print', 0.8771902618341131), ('patch', 0.8623578672322809)]
Top words for pretrained_BERT neuron indx 6822 [('store', 1.0), ('print', 0.8816328466985771), ('match', 0.8738157911296275), ('False', 0.8426675598023783), ('400', 0.8413259437827908)]
Top words for pretrained_BERT neuron indx 2728 [('host', 1.0), ('port', 0.9499903185543038), ('connection', 0.8905041601375355), ('field', 0.850204044497681), ('"Resource"', 0.7895133097264248)]
Top words for pretrained_BERT neuron indx 8873 [('as', 1.0), ('month', 0.9695046506152297), ('sanetime', 0.8875883925582893), ('tz', 0.8714929724776306), ('PDSAuthorization', 0.8209397226760089)]
Top words for pretrained_BERT neuron indx 2730 [('digest', 1.0), ('Digest', 0.9513723674820659), ('child', 0.891026923553221), ('Post', 0.8075920517211984), ('long', 0.7135299156596734)]
Top words for pretrained_BERT neuron indx 690 [('if', 1.0), ('Mesh', 0.9536254614069292), ('mesh', 0.9536254614069292), ('action', 0.9210094465244125), ('authorization', 0.9168126540226126)]
Top words for pretrained_BERT neuron indx 2742 [('root', 1.0), ('description', 0.9383683561220107), ('route', 0.877848238673668), ('sorted', 0.8260225130811681), ('Tab', 0.8155976779116982)]
Top words for pretrained_BERT neuron indx 4793 [('GET', 1.0), ('year', 0.9323865500440291), ('split', 0.9317226510627075), ('mins', 0.9255755541017356), ('minutes', 0.8883356314642844)]
Top words for pretrained_BERT neuron indx 6843 [('other', 1.0), ('tzinfo', 0.9258798235291289), ('save', 0.8323575464297106), ('add', 0.8260022582148774), ('str', 0.8214625784498487)]
Top words for pretrained_BERT neuron indx 701 [('sts', 1.0), ('META', 0.9582377391366501), ('reactor', 0.8004806729399565), ('long', 0.7976757667267306), ('v', 0.7836184666771829)]
Top words for pretrained_BERT neuron indx 8896 [('import', 1.0), ('identity', 0.9555454016591314), ('body', 0.9530351752348757), ('Authorization', 0.920284480651775), ('authorization', 0.8561119675233394)]
Top words for pretrained_BERT neuron indx 8901 [('32', 1.0), ('20', 0.9913646714284752), ('800', 0.8651223585289649), ('META', 0.8549846113654099), ('materials', 0.8513883569836063)]
Top words for pretrained_BERT neuron indx 6854 [('20', 1.0), ('60', 0.9647065244351218), ('40', 0.9529356663192206), ('600', 0.9312851722741832), ('1800', 0.9107618226208767)]
Top words for pretrained_BERT neuron indx 714 [('info', 1.0), ('partition', 0.9159798964277405), ('scope', 0.8468865392888755), ('template', 0.7733954986402513), ('objects', 0.7591820949878842)]
Top words for pretrained_BERT neuron indx 8915 [('import', 1.0), ('link', 0.942285570002152), ('oslo', 0.8771926885756566), ('field', 0.8702822653278671), ('session', 0.8282274596857544)]
Top words for pretrained_BERT neuron indx 726 [('close', 1.0), ('count', 0.8791521873617467), ('Exception', 0.7834592030859813), ('def', 0.7362281642699198), ('reactor', 0.7083748666802511)]
Top words for pretrained_BERT neuron indx 729 [('line', 1.0), ('activity', 0.9848923903185153), ('purpose', 0.7860562847732135), ('utc', 0.7709485125336103), ('task', 0.7692806120508234)]
Top words for pretrained_BERT neuron indx 737 [('horizon', 1.0), ('con', 0.8385640941347453), ('proxy', 0.828903300735732), ('800', 0.8067250813214047), ('hour', 0.7926743201953609)]
Top words for pretrained_BERT neuron indx 6886 [('ignore', 1.0), ('feature', 0.8698119428958392), ('port', 0.8319616365869791), ('24', 0.7707508504204856), ('future', 0.7656030504897792)]
Top words for pretrained_BERT neuron indx 4842 [('eg', 1.0), ('description', 0.998352671389238), ('i', 0.9746046270643741), ('contents', 0.8852721443766441), ('Off', 0.8815981857562633)]
Top words for pretrained_BERT neuron indx 4845 [('broadcast', 1.0), ('while', 0.942400477413195), ('domain', 0.8805327770780617), ('post', 0.7570403238194102), ('unicode', 0.7240252586814862)]
Top words for pretrained_BERT neuron indx 750 [('component', 1.0), ('Component', 0.9325800880909485), ('Exception', 0.9054254646047319), ('max', 0.8243196670129821), ('replace', 0.7789469534540218)]
Top words for pretrained_BERT neuron indx 752 [('slug', 1.0), ('re', 0.9930972467413378), ('exceptions', 0.8605749862642058), ('EffectiveId', 0.8011582084189749), ('direct', 0.7738850881001212)]
Top words for pretrained_BERT neuron indx 6899 [('add', 1.0), ('600', 0.8730217521072992), ('1000', 0.8517307816090649), ('E', 0.8328350415180114), ('seconds', 0.7500753264579247)]
Top words for pretrained_BERT neuron indx 2804 [('__title__', 1.0), ('find', 0.9958582338962487), ('models', 0.9930617341482131), ('f', 0.9910775443052238), ('features', 0.9851983245659526)]
Top words for pretrained_BERT neuron indx 8952 [('META', 1.0), ('materials', 0.944228032182178), ('sts', 0.7813999366868808), ('put', 0.7245313485267754), ('direct', 0.7141432399592816)]
Top words for pretrained_BERT neuron indx 6906 [('Stretch', 1.0), ('Session', 0.9145735744113326), ('authJID', 0.8030965479850641), ('fileno', 0.784695509493727), ('material', 0.7587314657873531)]
Top words for pretrained_BERT neuron indx 8965 [('utc', 1.0), ('tz', 0.8524944813344579), ('VerticalBillboard', 0.790321764856191), ('HorizontalBillboard', 0.7603354474645903), ('9', 0.7304238857110718)]
Top words for pretrained_BERT neuron indx 8968 [('pop', 1.0), ('80', 0.9422441397759144), ('400', 0.8908083879351821), ('"oslo"', 0.8724465914584806), ('600', 0.8723871932584267)]
Top words for pretrained_BERT neuron indx 8972 [('60', 1.0), ('17', 0.9364889808084088), ('40', 0.8672856665970279), ('end', 0.8256279000609174), ('task', 0.8189419930988495)]
Top words for pretrained_BERT neuron indx 2829 [('Register', 1.0), ('direct', 0.9779602696453098), ('calendar', 0.9171038442821906), ('clone', 0.8784278350642023), ('Simple', 0.8774125894385975)]
Top words for pretrained_BERT neuron indx 8976 [('400', 1.0), ('128', 0.9363261711019784), ('32', 0.7459412385147057), ('if', 0.6875862842389572), ('server', 0.6245369864437816)]
Top words for pretrained_BERT neuron indx 4892 [('View', 1.0), ('sorted', 0.8639696682468831), ('if', 0.8626339367334765), ('boot', 0.8378191096923842), ('url', 0.8227593067792948)]
Top words for pretrained_BERT neuron indx 6940 [('us', 1.0), ('to', 0.9433083564715377), ('loads', 0.7819259022538826), ('host', 0.740910836300361), ('common', 0.7386931068941944)]
Top words for pretrained_BERT neuron indx 4898 [('objects', 1.0), ('link', 0.9816501163692785), ('probe', 0.956900698215671), ('features', 0.9377753297129557), ('body', 0.9212659425911559)]
Top words for pretrained_BERT neuron indx 2852 [('add', 1.0), ('host', 0.9643960727996645), ('Simple', 0.9442962068477987), ('con', 0.8302886763002617), ('types', 0.817461594225947)]
Top words for pretrained_BERT neuron indx 808 [('upper', 1.0), ('body', 0.7874886988137666), ('if', 0.7591699770297311), ('materials', 0.7367499141575002), ('second', 0.7216870926709957)]
Top words for pretrained_BERT neuron indx 6957 [('description', 1.0), ('calendar', 0.9755028347322346), ('url', 0.9359986014501664), ('Digest', 0.8684406889283242), ('stat', 0.8550939625217442)]
Top words for pretrained_BERT neuron indx 4915 [('loads', 1.0), ('""', 0.7784796910043695), ('"Host"', 0.7626331810856247), ('"r"', 0.7440556799770639), ('"Name"', 0.7430655973845987)]
Top words for pretrained_BERT neuron indx 9015 [('authorization', 1.0), ('alt', 0.9906680299775907), ('match', 0.9634597598346337), ('9', 0.9572970302238712), ('if', 0.8774745910512006)]
Top words for pretrained_BERT neuron indx 4923 [('sorted', 1.0), ('with', 0.9549997881958846), ('profile', 0.9128681617013985), ('long', 0.7340299963710539), ('identity', 0.7096402989927194)]
Top words for pretrained_BERT neuron indx 9020 [('split', 1.0), ('sts', 0.9204075004404474), ('30', 0.8870735041992569), ('15', 0.8622636286128275), ('16', 0.8238585702761226)]
Top words for pretrained_BERT neuron indx 2876 [('uss', 1.0), ('enclosure', 0.94525215810995), ('host', 0.9026142190385716), ('key', 0.8762363624562625), ('split', 0.851409866825587)]
Top words for pretrained_BERT neuron indx 2875 [('part', 1.0), ('if', 0.8751157162439017), ('main', 0.7711302784205639), ('f', 0.7588945126534703), ('year', 0.7431113534865211)]
Top words for pretrained_BERT neuron indx 2882 [('settings', 1.0), ('stanza', 0.9963812520611758), ('startswith', 0.9693306150797287), ('help', 0.9627133077942758), ('wait', 0.9564712452554268)]
Top words for pretrained_BERT neuron indx 2883 [('ref', 1.0), ('id', 0.952251618930921), ('contents', 0.9011483929427102), ('future', 0.8740060216963405), ('split', 0.7859513783266572)]
Top words for pretrained_BERT neuron indx 6980 [('time', 1.0), ('action', 0.8506124929459432), ('sanetime', 0.8348309486736004), ('minutes', 0.8215912337064881), ('class', 0.7892803962955932)]
Top words for pretrained_BERT neuron indx 9033 [('put', 1.0), ('part', 0.9516701275401558), ('bare', 0.9319229547831577), ('oslo', 0.9015674494818956), ('hasattr', 0.8845877823443988)]
Top words for pretrained_BERT neuron indx 844 [('baseline', 1.0), ('View', 0.9844391390545036), ('format', 0.9321319546284919), ('log', 0.9148208374098479), ('wait', 0.9131376553625628)]
Top words for pretrained_BERT neuron indx 6989 [('".."', 1.0), ('postinfo', 0.9220114308526531), ('to', 0.8232598794704665), ('Simple', 0.7961988706346306), ('9', 0.7654214787942787)]
Top words for pretrained_BERT neuron indx 2903 [('host', 1.0), ('On', 0.9313405183213765), ('pop', 0.9151730092051096), ('types', 0.8086678643790104), ('type', 0.7989187152413183)]
Top words for pretrained_BERT neuron indx 9054 [('re', 1.0), ('f', 0.945222113011205), ('server', 0.8258477186805061), ('created', 0.739544778680295), ('end', 0.6306994777643175)]
Top words for pretrained_BERT neuron indx 4963 [('other', 1.0), ('sans', 0.8107687481601394), ('proxy', 0.7397993026822202), ('alt', 0.7237655780697932), ('ref', 0.7156112861262028)]
Top words for pretrained_BERT neuron indx 2917 [('ref', 1.0), ('Billboard', 0.9958096744845197), ('def', 0.9715004865757056), ('Log', 0.903427094036525), ('re', 0.861677598160509)]
Top words for pretrained_BERT neuron indx 870 [('state', 1.0), ('Tab', 0.8721664078343715), ('closing', 0.8690846630751516), ('add', 0.8390404090793195), ('seconds', 0.8017579768552531)]
Top words for pretrained_BERT neuron indx 7020 [('k', 1.0), ('mins', 0.8955332069871951), ('authentication', 0.844894385659493), ('"view"', 0.8231093968972589), ('"Name"', 0.8168803941260402)]
Top words for pretrained_BERT neuron indx 885 [('join', 1.0), ('minute', 0.9913488018682519), ('v', 0.8959121315606136), ('modes', 0.8894030748526409), ('other', 0.8870458961773914)]
Top words for pretrained_BERT neuron indx 2935 [('ref', 1.0), ('force', 0.9237098859762548), ('blocking', 0.8588238273060995), ('parts', 0.7809108908357215), ('Log', 0.7175383458901005)]
Top words for pretrained_BERT neuron indx 898 [('close', 1.0), ('format', 0.8671504101337161), ('link', 0.8038559031944665), ('find', 0.7049940561318392), ('key', 0.6994867561818857)]
Top words for pretrained_BERT neuron indx 7048 [('86400', 1.0), ('int', 0.9889975721059121), ('end', 0.9808060989716406), ('horizon', 0.9002069430144021), ('i', 0.8778110183172533)]
Top words for pretrained_BERT neuron indx 2957 [('24', 1.0), ('force', 0.9949429410663482), ('long', 0.9704294844920462), ('800', 0.9366068391618348), ('to', 0.9358920863688739)]
Top words for pretrained_BERT neuron indx 9111 [('40', 1.0), ('20', 0.8794880597253241), ('32', 0.7911163509459819), ('pop', 0.7742576855603865), ('60', 0.7113765575742765)]
Top words for pretrained_BERT neuron indx 2969 [('break', 1.0), ('local', 0.9111177894548618), ('exit', 0.9060371659847243), ('scope', 0.8375414612449869), ('user', 0.7961470230698376)]
Top words for pretrained_BERT neuron indx 9115 [('seconds', 1.0), ('"purpose"', 0.9979499440984648), ('end', 0.9123892614301455), ('epoch_seconds', 0.9117781956119422), ('requests', 0.8956867217447169)]
Top words for pretrained_BERT neuron indx 2973 [('core', 1.0), ('entity', 0.6946609323701703), ('store', 0.5609402099287466), ('profile', 0.5581846885675186), ('1000', 0.5501453621872311)]
Top words for pretrained_BERT neuron indx 7070 [('baseline', 1.0), ('max', 0.9832078116321261), ('context', 0.9632701281474287), ('15', 0.9606864774950414), ('30', 0.9095229192418375)]
Top words for pretrained_BERT neuron indx 2976 [('purpose', 1.0), ('match', 0.6854708421368618), ('key', 0.6549279411849548), ('authorized', 0.6463555392858679), ('replace', 0.6132097777928316)]
Top words for pretrained_BERT neuron indx 928 [('META', 1.0), ('1800', 0.6346095462208375), ('close', 0.5566571645786008), ('cert', 0.5168548818099391), ('count', 0.5023616911585703)]
Top words for pretrained_BERT neuron indx 9125 [('META', 1.0), ('if', 0.922365242972411), ('400', 0.8435460410415712), ('with', 0.8053562607030222), ('14', 0.7324594624060244)]
Top words for pretrained_BERT neuron indx 5046 [('root', 1.0), ('types', 0.956143324879773), ('modes', 0.9306952776692351), ('description', 0.8915353619324174), ('probe', 0.8380605272365541)]
Top words for pretrained_BERT neuron indx 9151 [('unicode', 1.0), ('sans', 0.8322557516289074), ('passwd', 0.7974075909696993), ('max', 0.7812990188678258), ('def', 0.7426908852141955)]
Top words for pretrained_BERT neuron indx 5058 [('text', 1.0), ('ignore', 0.9910665490878078), ('month', 0.7387692334198785), ('help', 0.7355360774423615), ('types', 0.7296381193349777)]
Top words for pretrained_BERT neuron indx 7108 [('40', 1.0), ('time', 0.9983737299029355), ('force', 0.9079797464435047), ('60', 0.8960983516957313), ('400', 0.8935647160562291)]
Top words for pretrained_BERT neuron indx 5061 [('bind', 1.0), ('direct', 0.9490830527147424), ('objects', 0.9234006618094267), ('filters', 0.9198169314130586), ('strip', 0.9192678943231752)]
Top words for pretrained_BERT neuron indx 7115 [('600', 1.0), ('REQUEST', 0.9387771506784567), ('import', 0.9033816853096299), ('Session', 0.8868258637062356), ('text', 0.860043651879841)]
Top words for pretrained_BERT neuron indx 981 [('line', 1.0), ('purpose', 0.9791896649442093), ('replace', 0.9632094876628797), ('st', 0.9563617586415947), ('val', 0.9032261918800517)]
Top words for pretrained_BERT neuron indx 3030 [('count', 1.0), ('close', 0.9376214996663175), ('seek', 0.888452086165796), ('while', 0.7999812080137835), ('wait', 0.7879029879598519)]
Top words for pretrained_BERT neuron indx 9175 [('upper', 1.0), ('REQUEST', 0.9797204721215089), ('15', 0.9643580314527535), ('to', 0.8733204811786338), ('core', 0.7516562863523278)]
Top words for pretrained_BERT neuron indx 7126 [('core', 1.0), ('unicode', 0.8625472526155802), ('int', 0.8547297403410972), ('def', 0.8485537893122276), ('re', 0.8158797871356553)]
Top words for pretrained_BERT neuron indx 5082 [('Tab', 1.0), ('import', 0.938740829787761), ('parts', 0.8319909032142639), ('32', 0.7697210047476686), ('entity', 0.7661724621335647)]
Top words for pretrained_BERT neuron indx 3038 [('k', 1.0), ('post', 0.9256747515886469), ('port', 0.9224133638401698), ('Post', 0.8388666614171056), ('link', 0.7857978671977754)]
Top words for pretrained_BERT neuron indx 995 [('if', 1.0), ('scope', 0.9215193681913103), ('state', 0.8843294770015806), ('from', 0.8721008531082046), ('while', 0.856613520047422)]
Top words for pretrained_BERT neuron indx 3048 [('False', 1.0), ('REQUEST', 0.9956832832989556), ('type', 0.8335152920411659), ('uri', 0.8004122146993659), ('probe', 0.7749667638529081)]
Top words for pretrained_BERT neuron indx 9197 [('17', 1.0), ('1800', 0.9662944144842528), ('requests', 0.9591765999548995), ('repr', 0.909601916794758), ('save', 0.9042856588333863)]
Top words for pretrained_BERT neuron indx 3054 [('Component', 1.0), ('component', 0.9773315515013311), ('count', 0.9383113733530654), ('Board', 0.8988618198740133), ('board', 0.8899683378030374)]
Top words for pretrained_BERT neuron indx 1006 [('modes', 1.0), ('60', 0.9533996391024346), ('task', 0.8869243091341221), ('st', 0.8660697346438946), ('30', 0.849397163534242)]
Top words for pretrained_BERT neuron indx 1008 [('break', 1.0), ('boot', 0.8281173105882984), ('400', 0.8255324625232134), ('material', 0.8005378242209299), ('scope', 0.7808901706359916)]
Top words for pretrained_BERT neuron indx 9203 [('600', 1.0), ('E', 0.9583945530514074), ('ping', 0.924000221571937), ('add', 0.8515557424674451), ('1000', 0.840496898627154)]
Top words for pretrained_BERT neuron indx 7155 [('route', 1.0), ('ignore', 0.9760076268969726), ('created', 0.8893813731071333), ('REQUEST', 0.852037220551804), ('minutes', 0.8215770320700173)]
Top words for pretrained_BERT neuron indx 9210 [('Session', 1.0), ('egs', 0.9724622254376394), ('future', 0.8810084342575211), ('description', 0.8557444895506473), ('session', 0.8483752448272824)]
Top words for pretrained_BERT neuron indx 1030 [('child', 1.0), ('Post', 0.9196315156056146), ('identity', 0.9125981162511213), ('post', 0.8699352989372016), ('ping', 0.8616085997135727)]
Top words for pretrained_BERT neuron indx 5128 [('con', 1.0), ('pop', 0.9093411877797872), ('re', 0.8015648514475788), ('On', 0.7802210757479646), ('1000', 0.7727201295009973)]
Top words for pretrained_BERT neuron indx 5129 [('shortcuts', 1.0), ('utc', 0.9552510283148307), ('re', 0.9171597682830321), ('def', 0.8971340838075987), ('servers', 0.8546072487617271)]
Top words for pretrained_BERT neuron indx 7181 [('feature', 1.0), ('id', 0.9589607428553518), ('bind', 0.8884867108422436), ('identity', 0.8591814596870295), ('write', 0.7890325067973624)]
Top words for pretrained_BERT neuron indx 5136 [('types', 1.0), ('pop', 0.9081336322391563), ('Exception', 0.8913405679446691), ('400', 0.8616003941956653), ('log', 0.8583534655398037)]
Top words for pretrained_BERT neuron indx 3093 [('start', 1.0), ('parts', 0.9697871349648054), ('time', 0.8781344056053765), ('argv', 0.8620440246978524), ('META', 0.826630606098223)]
Top words for pretrained_BERT neuron indx 7191 [('session', 1.0), ('alt', 0.9938691655885088), ('replace', 0.9863204544405687), ('Session', 0.9369603692186002), ('ref', 0.9256651647033013)]
Top words for pretrained_BERT neuron indx 7195 [('bare', 1.0), ('Off', 0.9472982658474155), ('_closed', 0.8585719853711877), ('choices', 0.8412121295439314), ('recv_close', 0.787979569005139)]
Top words for pretrained_BERT neuron indx 7197 [('1024', 1.0), ('""', 0.9437950345711331), ('400', 0.8915590963199921), ('Session', 0.8895377822644218), ('other', 0.8019215525096821)]
Top words for pretrained_BERT neuron indx 1054 [('add', 1.0), ('context', 0.8185061225564925), ('val', 0.8038239500229932), ('Component', 0.7715884733284384), ('filters', 0.7618446252437883)]
Top words for pretrained_BERT neuron indx 9254 [('identity', 1.0), ('f', 0.8753449838268877), ('error', 0.8658168295343716), ('make_boot_settings_dict', 0.8216323794335783), ('board', 0.8156809981232671)]
Top words for pretrained_BERT neuron indx 3112 [('upper', 1.0), ('to', 0.8836946311534853), ('server', 0.8818594887766895), ('second', 0.8130375959856982), ('body', 0.7322646771964124)]
Top words for pretrained_BERT neuron indx 3117 [('calendar', 1.0), ('state', 0.9489106355587712), ('digest', 0.8198092423742456), ('k', 0.7426670069844808), ('child', 0.7078874246296883)]
Top words for pretrained_BERT neuron indx 1073 [('identity', 1.0), ('replace', 0.8940099659244526), ('error', 0.8475207241775755), ('domain', 0.8023791969505273), ('split', 0.7975872667007181)]
Top words for pretrained_BERT neuron indx 1075 [('loads', 1.0), ('close', 0.868006488327786), ('k', 0.7368122076495747), ('push', 0.693422450759868), ('find', 0.6692658061876596)]
Top words for pretrained_BERT neuron indx 1076 [('".."', 1.0), ('to', 0.9925258721576068), ('as', 0.8349396712205293), ('with', 0.8265402212874843), ('from', 0.7570611643495766)]
Top words for pretrained_BERT neuron indx 7223 [('force', 1.0), ('enclosure', 0.9544083607328353), ('tz', 0.848644985293065), ('action', 0.8023578003607569), ('blocking', 0.6744419897184203)]
Top words for pretrained_BERT neuron indx 1092 [('iq', 1.0), ('minutes', 0.7978908903437153), ('View', 0.7844219725130741), ('val', 0.7192000433281741), ('proxy', 0.6784375556796272)]
Top words for pretrained_BERT neuron indx 9286 [('link', 1.0), ('token', 0.9992268483847798), ('materials', 0.9610447134639336), ('i', 0.8634072311113195), ('start', 0.8611510865936877)]
Top words for pretrained_BERT neuron indx 1098 [('other', 1.0), ('task', 0.9629099717889108), ('activity', 0.908126583944273), ('material', 0.8774358492479734), ('IsSECANC', 0.7680146436249942)]
Top words for pretrained_BERT neuron indx 1101 [('other', 1.0), ('day', 0.8776453458014196), ('horizon', 0.866444178559387), ('types', 0.8560706432064544), ('GET', 0.8510426705733868)]
Top words for pretrained_BERT neuron indx 7248 [('""', 1.0), ('title', 0.9183005569855738), ('MAXSIGLINES', 0.8287518600201124), ('datastore_owner_uuid', 0.7314934956503669), ('second', 0.7239198895676837)]
Top words for pretrained_BERT neuron indx 7252 [('""', 1.0), ('"view"', 0.9157637953763302), ('"Port"', 0.8916855238312725), ('"Attach"', 0.8617711053192303), ('".."', 0.8429514702454702)]
Top words for pretrained_BERT neuron indx 1125 [('boot', 1.0), ('contents', 0.8327085838592141), ('part', 0.821841162906614), ('v', 0.7748545465161357), ('body', 0.7229307546107853)]
Top words for pretrained_BERT neuron indx 3173 [('patch', 1.0), ('add', 0.9637651165678467), ('ping', 0.9339816468833001), ('route', 0.9251897026658363), ('stanza', 0.8693299063764558)]
Top words for pretrained_BERT neuron indx 9317 [('patch', 1.0), ('alt', 0.9117966083980037), ('repr', 0.7824694938726451), ('On', 0.7015591439993729), ('split', 0.6910031094039873)]
Top words for pretrained_BERT neuron indx 3181 [('hour', 1.0), ('E', 0.9193536085246983), ('to', 0.8226650921978844), ('minute', 0.8038865249796655), ('id', 0.7583334174163892)]
Top words for pretrained_BERT neuron indx 5245 [('300', 1.0), ('30', 0.9844615894196906), ('17', 0.8376771321640951), ('32', 0.7800037869368222), ('400', 0.7422766610154975)]
Top words for pretrained_BERT neuron indx 1151 [('child', 1.0), ('if', 0.8852551429470976), ('128', 0.8082460507749315), ('enclosure', 0.7472049292923113), ('join', 0.7301124401598768)]
Top words for pretrained_BERT neuron indx 7298 [('as', 1.0), ('20', 0.738220618919058), ('16', 0.6530161621756786), ('Off', 0.649649869708781), ('mesh1', 0.602459474978598)]
Top words for pretrained_BERT neuron indx 1154 [('dict', 1.0), ('import', 0.9414035776685248), ('16', 0.9408605232977236), ('connection', 0.9104879201998387), ('14', 0.8439190647563704)]
Top words for pretrained_BERT neuron indx 7302 [('"purpose"', 1.0), ('"r"', 0.9584210353421322), ('info', 0.8025921551380507), ('"gbk"', 0.766984649267961), ('600', 0.7643306062972861)]
Top words for pretrained_BERT neuron indx 1173 [('server', 1.0), ('request', 0.8661003589457206), ('purpose', 0.6946014783408776), ('minute', 0.6940177544763318), ('models', 0.6869786021197078)]
Top words for pretrained_BERT neuron indx 3225 [('proxy', 1.0), ('main', 0.9895668403496426), ('presence', 0.9194300499144521), ('boot', 0.8074933014770814), ('utc', 0.7975903427436046)]
Top words for pretrained_BERT neuron indx 1180 [('Component', 1.0), ('count', 0.9287878731808881), ('sorted', 0.9121068936191472), ('domain', 0.8096532015976475), ('component', 0.7909183235201535)]
Top words for pretrained_BERT neuron indx 1183 [('local', 1.0), ('month', 0.8321834259527935), ('exceptions', 0.8021211999794059), ('action', 0.7849332297598098), ('Post', 0.7838082032901827)]
Top words for pretrained_BERT neuron indx 5280 [('purpose', 1.0), ('main', 0.6408853953017748), ('part', 0.6350709399868734), ('key', 0.629004250758881), ('title', 0.6231512959088796)]
Top words for pretrained_BERT neuron indx 3237 [('group', 1.0), ('False', 0.965708734136187), ('close', 0.9486261574562869), ('9', 0.9437780482111198), ('i', 0.8917799908748179)]
Top words for pretrained_BERT neuron indx 7337 [('as', 1.0), ('Node', 0.6919758878416283), ('created', 0.687166099619452), ('continue', 0.6855055763099537), ('long', 0.6639464495045907)]
Top words for pretrained_BERT neuron indx 7340 [('end', 1.0), ('ping', 0.8824903134953481), ('uss', 0.8823014355169474), ('int', 0.7699753140359491), ('port', 0.743512124526088)]
Top words for pretrained_BERT neuron indx 5298 [('choices', 1.0), ('replace', 0.9581008445827037), ('return', 0.9502365346207268), ('if', 0.7707231204500965), ('30', 0.7671670245131551)]
Top words for pretrained_BERT neuron indx 3252 [('getint', 1.0), ('purpose', 0.9761153054960132), ('minute', 0.9038730934705014), ('long', 0.8916298839553386), ('log', 0.8813183851679077)]
Top words for pretrained_BERT neuron indx 1204 [('exceptions', 1.0), ('core', 0.9498693057078563), ('strip', 0.9287177880908097), ('Exception', 0.8634362919891266), ('unicode', 0.8528261940752531)]
Top words for pretrained_BERT neuron indx 7355 [('v', 1.0), ('other', 0.972341504520773), ('9', 0.9605950984561947), ('slug', 0.953338459361835), ('Plugin', 0.9054397475814429)]
Top words for pretrained_BERT neuron indx 9404 [('vsn', 1.0), ('MSG', 0.9828306779477808), ('svc', 0.9292939152031199), ('route', 0.8542275237361007), ('message', 0.8515310269204592)]
Top words for pretrained_BERT neuron indx 3260 [('View', 1.0), ('connection', 0.9668138713363551), ('description', 0.8565854006954678), ('1000', 0.8525040341174228), ('broadcast', 0.8257662008025071)]
Top words for pretrained_BERT neuron indx 5309 [('Node', 1.0), ('None', 0.8131882968000042), ('v', 0.7091114401460985), ('rosters', 0.6285099676710068), ('Off', 0.6100753472711857)]
Top words for pretrained_BERT neuron indx 1215 [('int', 1.0), ('E', 0.9806034554357431), ('enabled', 0.9563508169471792), ('direct', 0.8896434148624643), ('write', 0.8883655020068817)]
Top words for pretrained_BERT neuron indx 3267 [('clone', 1.0), ('match', 0.9941938867517756), ('part', 0.9472465695160678), ('Exception', 0.9289407615409558), ('Board', 0.9269304323078333)]
Top words for pretrained_BERT neuron indx 1225 [('blocking', 1.0), ('sorted', 0.8239755377194984), ('requests', 0.814159503753015), ('day', 0.7682558703993155), ('choices', 0.6981755120368848)]
Top words for pretrained_BERT neuron indx 3275 [('400', 1.0), ('600', 0.9394390313172788), ('300', 0.9070477469736266), ('Log', 0.9008306632760261), ('board', 0.8759033403203227)]
Top words for pretrained_BERT neuron indx 5332 [('route', 1.0), ('close', 0.8925311186133524), ('E', 0.790635959562662), ('child', 0.7537524098227417), ('Simple', 0.7217732004878002)]
Top words for pretrained_BERT neuron indx 1237 [('future', 1.0), ('Off', 0.9393245043028108), ('continue', 0.9026782344618389), ('17', 0.8191399501669383), ('enabled', 0.8135565868923987)]
Top words for pretrained_BERT neuron indx 3287 [('import', 1.0), ('str', 0.9489103121327641), ('parser', 0.8113753567991203), ('enabled', 0.7982744778743858), ('enclosure', 0.6812863362128451)]
Top words for pretrained_BERT neuron indx 9436 [('materials', 1.0), ('token', 0.846921863493196), ('method', 0.8190234874936707), ('sans', 0.7830605293558998), ('identity', 0.7708724543354313)]
Top words for pretrained_BERT neuron indx 5345 [('800', 1.0), ('stanza', 0.9942181629377683), ('Unauthorized', 0.9777744437734944), ('close', 0.9421680102386637), ('1800', 0.9403948862036731)]
Top words for pretrained_BERT neuron indx 3299 [('save', 1.0), ('zone', 0.8872202726493253), ('from', 0.849978522434), ('to', 0.8467892235261675), ('def', 0.839150298079643)]
Top words for pretrained_BERT neuron indx 3309 [('unicode', 1.0), ('title', 0.9193569212341502), ('child', 0.8713144899605807), ('E', 0.8461689686433589), ('broadcast', 0.8152818469284963)]
Top words for pretrained_BERT neuron indx 1265 [('common', 1.0), ('objects', 0.9198861865007344), ('hour', 0.8599283227449661), ('v', 0.8440906171074014), ('preload', 0.8415874081271159)]
Top words for pretrained_BERT neuron indx 9468 [('enclosure', 1.0), ('entity', 0.8577711983734456), ('task', 0.7500432838748031), ('purpose', 0.6969137639657529), ('refresh', 0.690568558593343)]
Top words for pretrained_BERT neuron indx 7429 [('core', 1.0), ('tz', 0.943392040733818), ('features', 0.933120500595934), ('models', 0.8989829447232015), ('year', 0.8744788646393609)]
Top words for pretrained_BERT neuron indx 5381 [('Node', 1.0), ('from', 0.9611336282825934), ('REQUEST', 0.9461254719440105), ('authorization', 0.9053189219781431), ('authentication', 0.8832356139182537)]
Top words for pretrained_BERT neuron indx 1287 [('filters', 1.0), ('f', 0.8398400723551879), ('seconds', 0.8035792018158299), ('enabled', 0.7983312330331794), ('Digest', 0.7917975353328252)]
Top words for pretrained_BERT neuron indx 7432 [('pop', 1.0), ('"oslo"', 0.9090711312104564), ('40', 0.8837637755322058), ('con', 0.877603045720808), ('profile', 0.8564040967130745)]
Top words for pretrained_BERT neuron indx 1289 [('other', 1.0), ('profile', 0.9074373396690565), ('us', 0.9042301159676515), ('Profile', 0.8124435417915453), ('models', 0.7624511050745655)]
Top words for pretrained_BERT neuron indx 9480 [('save', 1.0), ('hpov', 0.888140046667956), ('read', 0.8542655966510352), ('debug', 0.7555553797516984), ('"!@#$%"', 0.7511679225702139)]
Top words for pretrained_BERT neuron indx 5387 [('400', 1.0), ('9', 0.9861260598172947), ('sorted', 0.9765344201814119), ('16', 0.9067940571694894), ('14', 0.8970964244800887)]
Top words for pretrained_BERT neuron indx 1290 [('""', 1.0), ('body', 0.9139623971953739), ('message', 0.864016051747364), ('Register', 0.8312205559097043), ('main', 0.8272237794965634)]
Top words for pretrained_BERT neuron indx 5390 [('key', 1.0), ('force', 0.9749402484538203), ('enclosure', 0.9453103332326686), ('Off', 0.8324692033198783), ('zone', 0.814280921983402)]
Top words for pretrained_BERT neuron indx 5391 [('key', 1.0), ('as', 0.9419365390522458), ('context', 0.8827777004352307), ('break', 0.8811547775273234), ('us', 0.8589578248810179)]
Top words for pretrained_BERT neuron indx 1302 [('k', 1.0), ('domain', 0.9840045177154148), ('clone', 0.933316427804261), ('ref', 0.8277381571537162), ('print', 0.8267814355133054)]
Top words for pretrained_BERT neuron indx 3356 [('sorted', 1.0), ('View', 0.973632521990314), ('""', 0.7606593605629973), ('port', 0.7368012671663013), ('identity', 0.7251661103983373)]
Top words for pretrained_BERT neuron indx 1316 [('start', 1.0), ('resource', 0.9022250555833148), ('host', 0.8907871056844814), ('us', 0.8879199154316039), ('root', 0.872095841479528)]
Top words for pretrained_BERT neuron indx 7469 [('800', 1.0), ('1000', 0.9769218191396255), ('core', 0.9624968666039658), ('1024', 0.9237105080244573), ('8000', 0.8925329124249365)]
Top words for pretrained_BERT neuron indx 9517 [('alt', 1.0), ('match', 0.987051709534582), ('k', 0.9419774256798816), ('refresh', 0.8972890508177626), ('"oslo"', 0.778540079603584)]
Top words for pretrained_BERT neuron indx 3379 [('loads', 1.0), ('""', 0.6584053700506745), ('main', 0.6580721981422847), ('stat', 0.6433147183325884), ('"Host"', 0.621171736738377)]
Top words for pretrained_BERT neuron indx 3380 [('with', 1.0), ('as', 0.9807370373459139), ('from', 0.8738069776697256), ('On', 0.7325755136554278), ('features', 0.7081593701538829)]
Top words for pretrained_BERT neuron indx 1336 [('Component', 1.0), ('component', 0.9960506488546307), ('task', 0.9605692064323464), ('modes', 0.7931255804335201), ('policy', 0.7763413949067449)]
Top words for pretrained_BERT neuron indx 5435 [('features', 1.0), ('v', 0.9797951489490703), ('parser', 0.8118916094595814), ('add', 0.8066347282382965), ('Distance', 0.7445911427816496)]
Top words for pretrained_BERT neuron indx 3387 [('with', 1.0), ('sorted', 0.8784989098715614), ('start', 0.8534600643284991), ('end', 0.837055737557456), ('max', 0.8186067811013703)]
Top words for pretrained_BERT neuron indx 3392 [('print', 1.0), ('find', 0.9964502935284674), ('body', 0.8345015278528738), ('close', 0.8279207484894741), ('View', 0.8110949964959763)]
Top words for pretrained_BERT neuron indx 1348 [('id', 1.0), ('template', 0.842778865459998), ('powerRequest', 0.8206643286150326), ('timezone', 0.7424838293320545), ('month', 0.7348888454262534)]
Top words for pretrained_BERT neuron indx 7497 [('put', 1.0), ('types', 0.9678777163911003), ('loads', 0.9644665912143354), ('part', 0.9378628310915049), ('hasattr', 0.9354554913924936)]
Top words for pretrained_BERT neuron indx 7508 [('token', 1.0), ('xmpp_read', 0.9221471241405459), ('PY2', 0.919759823941455), ('modes', 0.8796965350268112), ('xmpp', 0.8447130916346131)]
Top words for pretrained_BERT neuron indx 5460 [('as', 1.0), ('with', 0.9562663072302161), ('while', 0.8191672529940452), ('return', 0.7969441127845132), ('import', 0.7836790110789223)]
Top words for pretrained_BERT neuron indx 3420 [('st', 1.0), ('loads', 0.8369011279195688), ('Log', 0.791430593954681), ('purpose', 0.7522109212265615), ('32', 0.7455000975273105)]
Top words for pretrained_BERT neuron indx 1376 [('Log', 1.0), ('line', 0.8338608063628987), ('start', 0.8135424174856584), ('uss', 0.7877883943542865), ('xmlns', 0.7830974757380799)]
Top words for pretrained_BERT neuron indx 5472 [('tz', 1.0), ('long', 0.9574494012172636), ('features', 0.7737806743108409), ('models', 0.7693484249342053), ('core', 0.7669031023701053)]
Top words for pretrained_BERT neuron indx 3431 [('broadcast', 1.0), ('field', 0.9894502476689616), ('types', 0.9683440606225904), ('materials', 0.9674178491599418), ('E', 0.9605038088765493)]
Top words for pretrained_BERT neuron indx 1387 [('broadcast', 1.0), ('policy', 0.9992771151276651), ('group', 0.9768690391979901), ('slug', 0.959926268317736), ('logging', 0.9435513574163963)]
Top words for pretrained_BERT neuron indx 3437 [('action', 1.0), ('""', 0.9785473862569551), ('exit', 0.9387269993456883), ('feature', 0.9249557142648984), ('E', 0.9110165146068335)]
Top words for pretrained_BERT neuron indx 3444 [('root', 1.0), ('ref', 0.9274485643274456), ('key', 0.9242278292991933), ('connection', 0.7803713552547428), ('contextlib', 0.7191627079646482)]
Top words for pretrained_BERT neuron indx 7545 [('while', 1.0), ('k', 0.9670426433154322), ('contents', 0.9627490176810253), ('if', 0.948320495979762), ('from', 0.894836934333964)]
Top words for pretrained_BERT neuron indx 7549 [('30', 1.0), ('300', 0.9730431996975187), ('32', 0.8686017987166376), ('17', 0.8461897944994483), ('time', 0.8175995698458463)]
Top words for pretrained_BERT neuron indx 1405 [('class', 1.0), ('match', 0.870796237644266), ('reactor', 0.858373328677579), ('direct', 0.8187200806541879), ('loads', 0.8121115456921791)]
Top words for pretrained_BERT neuron indx 7551 [('open', 1.0), ('as', 0.9174369540957396), ('Unauthorized', 0.8655402655867829), ('Tab', 0.8424715888588368), ('closing', 0.8086838612766003)]
Top words for pretrained_BERT neuron indx 7552 [('300', 1.0), ('30', 0.9720097470385779), ('40', 0.9507111253565498), ('oslo', 0.9337755560955422), ('20', 0.9037618845423152)]
Top words for pretrained_BERT neuron indx 3457 [('seek', 1.0), ('proxy', 0.8467010525952031), ('filters', 0.8170704493075355), ('long', 0.7362925263270824), ('request', 0.6926938801448937)]
Top words for pretrained_BERT neuron indx 9605 [('"list"', 1.0), ('Tab', 0.9699587811379762), ('"Path"', 0.841917861745804), ('SaneDelta', 0.8397516044225529), ('strip', 0.8307975610764948)]
Top words for pretrained_BERT neuron indx 5512 [('int', 1.0), ('horizon', 0.939253408887973), ('purpose', 0.9209299251963944), ('passwd', 0.8051054368555349), ('__hash__', 0.7758064179073472)]
Top words for pretrained_BERT neuron indx 1425 [('affinity', 1.0), ('month', 0.9395533026500439), ('iq', 0.9107655641170902), ('host', 0.9064931690802295), ('method', 0.8928952016321634)]
Top words for pretrained_BERT neuron indx 9620 [('REQUEST', 1.0), ('def', 0.797974390852931), ('post', 0.793571196715179), ('biosSettings', 0.7712730510157897), ('request', 0.7642652006743693)]
Top words for pretrained_BERT neuron indx 1437 [('core', 1.0), ('main', 0.767777467441797), ('"Resource"', 0.7244874902807201), ('entity', 0.6933482743801629), ('resource', 0.6834955736202684)]
Top words for pretrained_BERT neuron indx 5538 [('LoadUser', 1.0), ('calendar', 0.9154269194501375), ('session', 0.9127407319715296), ('pytz', 0.8728475354817352), ('identity', 0.8501661765499786)]
Top words for pretrained_BERT neuron indx 7589 [('if', 1.0), ('META', 0.9879546847860783), ('400', 0.7837149677057309), ('E', 0.7459654143389295), ('60', 0.7035375528416616)]
Top words for pretrained_BERT neuron indx 5541 [('False', 1.0), ('child', 0.9411083895634142), ('title', 0.9237494061762502), ('filters', 0.8997877872922322), ('wait', 0.8936693388008298)]
Top words for pretrained_BERT neuron indx 3493 [('log', 1.0), ('Log', 0.9214537128215263), ('logging', 0.8140588332933375), ('affinity', 0.8100863958535442), ('choices', 0.8024883407702855)]
Top words for pretrained_BERT neuron indx 1458 [('if', 1.0), ('Mesh', 0.9975977697098743), ('mesh', 0.9934536643183525), ('30', 0.9461149072693553), ('method', 0.9412821422816402)]
Top words for pretrained_BERT neuron indx 5556 [('group', 1.0), ('part', 0.9629400171103275), ('common', 0.9508824844246068), ('horizon', 0.9080718254367212), ('break', 0.876390277337795)]
Top words for pretrained_BERT neuron indx 9658 [('purpose', 1.0), ('14', 0.9292045859786051), ('xmlns', 0.8027771090515612), ('group', 0.7977011284422127), ('Log', 0.7793126787574902)]
Top words for pretrained_BERT neuron indx 5564 [('1000', 1.0), ('View', 0.9017950612529985), ('connection', 0.8747102588978961), ('description', 0.8275707568400154), ('False', 0.7743694041731054)]
Top words for pretrained_BERT neuron indx 1469 [('enabled', 1.0), ('description', 0.9864959100380271), ('sts', 0.9435994877255903), ('board', 0.8716856990211415), ('META', 0.83777534070953)]
Top words for pretrained_BERT neuron indx 1471 [('dt', 1.0), ('json', 0.8994974269425285), ('val', 0.8430315134020058), ('id', 0.8109276519898729), ('item', 0.7734934126710481)]
Top words for pretrained_BERT neuron indx 1477 [('authentication', 1.0), ('match', 0.7591159307611589), ('direct', 0.7530029202023173), ('description', 0.7368420694312822), ('9', 0.7350531958832137)]
Top words for pretrained_BERT neuron indx 7622 [('400', 1.0), ('60', 0.9824281799451317), ('20', 0.9783121302126287), ('600', 0.9236997645478648), ('40', 0.9069936968890034)]
Top words for pretrained_BERT neuron indx 9680 [('val', 1.0), ('register', 0.9390040379569953), ('affinity', 0.9293446077509417), ('hpOneView', 0.845238775262799), ('month', 0.8216192960864145)]
Top words for pretrained_BERT neuron indx 9683 [('oslo', 1.0), ('import', 0.8698650105545138), ('error', 0.8440688971543853), ('field', 0.8075137371507919), ('link', 0.8033262696680764)]
Top words for pretrained_BERT neuron indx 1492 [('child', 1.0), ('strip', 0.8884384906131737), ('feature', 0.8668147200793684), ('connection', 0.7605553931572727), ('blocking', 0.7445826904211438)]
Top words for pretrained_BERT neuron indx 9685 [('int', 1.0), ('us', 0.7894622040920861), ('render', 0.7831174392740892), ('86400', 0.7149979168479655), ('title', 0.712996208392758)]
Top words for pretrained_BERT neuron indx 7636 [('route', 1.0), ('iq', 0.8742292508650896), ('line', 0.8628901910009731), ('E', 0.7870076641977442), ('filter', 0.7577203628524708)]
Top words for pretrained_BERT neuron indx 1494 [('count', 1.0), ('close', 0.9892597441177561), ('wait', 0.7055529422413698), ('def', 0.6961106341879593), ('seek', 0.6684185287132078)]
Top words for pretrained_BERT neuron indx 5591 [('On', 1.0), ('to', 0.8413632573272015), ('"Host"', 0.757558580611187), ('return', 0.729724440055223), ('stanza', 0.7260410694069338)]
Top words for pretrained_BERT neuron indx 3546 [('Tab', 1.0), ('Profile', 0.8575885919310233), ('logging', 0.8493839594381343), ('as', 0.7633967524591433), ('save', 0.7075443548319703)]
Top words for pretrained_BERT neuron indx 3549 [('Node', 1.0), ('horizon', 0.9870159286728909), ('token', 0.9352301001277877), ('proxy', 0.9323527744921856), ('text', 0.8896559604095787)]
Top words for pretrained_BERT neuron indx 1505 [('con', 1.0), ('proxy', 0.8224847768189089), ('material', 0.7741063058921421), ('CONF', 0.7634920558248586), ('types', 0.7306256412668888)]
Top words for pretrained_BERT neuron indx 7660 [('post', 1.0), ('logging', 0.9620722937555463), ('save', 0.8934377800092154), ('delete', 0.8669757869000514), ('View', 0.8345912558638157)]
Top words for pretrained_BERT neuron indx 5613 [('domain', 1.0), ('broadcast', 0.9514184089085004), ('post', 0.9328816623451291), ('ref', 0.8643886277114985), ('bind', 0.8502647505588509)]
Top words for pretrained_BERT neuron indx 1518 [('component', 1.0), ('Component', 0.9861276795183552), ('replace', 0.8200734818977674), ('count', 0.8017548033993246), ('Exception', 0.7927481243004325)]
Top words for pretrained_BERT neuron indx 9711 [('month', 1.0), ('Node', 0.8903018783209246), ('int', 0.8739781629392938), ('year', 0.8172728219796814), ('META', 0.8011968167334877)]
Top words for pretrained_BERT neuron indx 1520 [('re', 1.0), ('slug', 0.9413505057649603), ('exceptions', 0.8794094166122282), ('context', 0.8739871218773507), ('enclosure', 0.859843190582451)]
Top words for pretrained_BERT neuron indx 7667 [('E', 1.0), ('seconds', 0.9518408034679383), ('add', 0.8527541539347424), ('mins', 0.8103967242439362), ('core', 0.7902497151874261)]
Top words for pretrained_BERT neuron indx 1525 [('replace', 1.0), ('force', 0.9336576610955614), ('token', 0.9183215576869014), ('domain', 0.8840782424191597), ('activity', 0.87504644638573)]
Top words for pretrained_BERT neuron indx 3592 [('pop', 1.0), ('con', 0.9438303957536568), ('On', 0.8255814384672392), ('128', 0.8029463881298766), ('count', 0.7915602615837088)]
Top words for pretrained_BERT neuron indx 9736 [('pop', 1.0), ('profile', 0.7955865735531953), ('minutes', 0.7412113991672383), ('128', 0.740158046915518), ('log', 0.6949900793176635)]
Top words for pretrained_BERT neuron indx 5644 [('800', 1.0), ('600', 0.9766713070504626), ('Board', 0.9324482947314913), ('60', 0.8499070665946333), ('400', 0.8214938747514183)]
Top words for pretrained_BERT neuron indx 3597 [('alt', 1.0), ('direct', 0.9821046727305313), ('main', 0.9768829503756965), ('clone', 0.9016673743616932), ('calendar', 0.8960021094942866)]
Top words for pretrained_BERT neuron indx 1557 [('import', 1.0), ('def', 0.9110793720495348), ('k', 0.9070182274458832), ('parts', 0.8546557095598517), ('Off', 0.8363630386364528)]
Top words for pretrained_BERT neuron indx 5660 [('if', 1.0), ('View', 0.9995875375937565), ('url', 0.9259873574367188), ('sorted', 0.8559823118131754), ('Plugin', 0.8532554265437047)]
Top words for pretrained_BERT neuron indx 7708 [('loads', 1.0), ('MAXSIGLINES', 0.9479343592261983), ('if', 0.9449920897282322), ('child', 0.9353183439483287), ('from', 0.9134301846287259)]
Top words for pretrained_BERT neuron indx 5667 [('save', 1.0), ('link', 0.9653928751485586), ('On', 0.8963984338650123), ('description', 0.8619191633801248), ('Distance', 0.8501731509718358)]
Top words for pretrained_BERT neuron indx 1576 [('upper', 1.0), ('body', 0.8499835148513828), ('stanza', 0.7566297890608494), ('strip', 0.740707062120111), ('if', 0.7042611687290065)]
Top words for pretrained_BERT neuron indx 3627 [('patch', 1.0), ('open', 0.9020496341737273), ('bare', 0.8219670587900909), ('Node', 0.7828581163006689), ('token', 0.7386480899618633)]
Top words for pretrained_BERT neuron indx 1581 [('calendar', 1.0), ('k', 0.9221497834113481), ('state', 0.8975201499512934), ('v', 0.7811965416295525), ('20', 0.7782097950098754)]
Top words for pretrained_BERT neuron indx 7725 [('url', 1.0), ('identity', 0.9214393946497663), ('v', 0.8738582872594675), ('method', 0.8579926191952496), ('calendar', 0.8249394309853145)]
Top words for pretrained_BERT neuron indx 9775 [('9', 1.0), ('32', 0.807771466429445), ('1024', 0.7773622915713762), ('128', 0.69882496953092), ('40', 0.6863787371145867)]
Top words for pretrained_BERT neuron indx 1585 [('core', 1.0), ('enabled', 0.8989598357792644), ('count', 0.8946281097037941), ('required', 0.8903139255395649), ('Authorization', 0.8281094193307358)]
Top words for pretrained_BERT neuron indx 5688 [('Simple', 1.0), ('send', 0.8552850332183735), ('long', 0.8271045928802447), ('sans', 0.7962751667887774), ('child', 0.7948931636751041)]
Top words for pretrained_BERT neuron indx 5691 [('sorted', 1.0), ('long', 0.9352525256352212), ('with', 0.8290592494226984), ('profile', 0.7966625433094583), ('core', 0.7226199451776611)]
Top words for pretrained_BERT neuron indx 3650 [('stanza', 1.0), ('startswith', 0.9858007060331987), ('settings', 0.9507003211885935), ('help', 0.9139359885498805), ('wait', 0.91020769930298)]
Top words for pretrained_BERT neuron indx 3651 [('id', 1.0), ('ref', 0.9013756658187847), ('dt', 0.8285137217076862), ('identity', 0.8207940003359001), ('future', 0.7996671844345009)]
Top words for pretrained_BERT neuron indx 9796 [('if', 1.0), ('unicode', 0.9665338446972865), ('f', 0.9593146924728445), ('strftime', 0.9405180295792291), ('as', 0.8064385721137258)]
Top words for pretrained_BERT neuron indx 1612 [('View', 1.0), ('format', 0.9330919005856152), ('proxy', 0.9157501588233017), ('baseline', 0.8735942169561118), ('clone', 0.8311975700395547)]
Top words for pretrained_BERT neuron indx 7757 [('postinfo', 1.0), ('presence', 0.9774581595313747), ('closing', 0.8390617856551267), ('UserInfo', 0.814526480642101), ('enclosure', 0.7984839550047435)]
Top words for pretrained_BERT neuron indx 1628 [('GET', 1.0), ('part', 0.9906620807601131), ('builtins', 0.7868708121723144), ('as', 0.7697221052711567), ('Digest', 0.7669698370735115)]
Top words for pretrained_BERT neuron indx 3679 [('settings', 1.0), ('ret', 0.9706188570671851), ('us', 0.9017455376001497), ('dict', 0.8762821319472066), ('error', 0.854185077883678)]
Top words for pretrained_BERT neuron indx 7794 [('body', 1.0), ('enclosure', 0.9418404978879613), ('choices', 0.9030989475713503), ('info', 0.8870157905659434), ('presence', 0.8457393502188528)]
Top words for pretrained_BERT neuron indx 7799 [('local', 1.0), ('minutes', 0.8893446319452033), ('sht', 0.8865461592698398), ('part', 0.7675437769174598), ('14', 0.7247397039361283)]
Top words for pretrained_BERT neuron indx 5756 [('600', 1.0), ('int', 0.8919784392479178), ('800', 0.8781903990931955), ('3600', 0.8652799807189903), ('1800', 0.844392549417465)]
Top words for pretrained_BERT neuron indx 7804 [('with', 1.0), ('enclosureGroupUri', 0.6799714819337312), ('Billboard', 0.6279094245995702), ('core', 0.6257428729845557), ('description', 0.6226667024722151)]
Top words for pretrained_BERT neuron indx 9860 [('push', 1.0), ('Tab', 0.7249006030198452), ('__status__', 0.7153299130918006), ('end', 0.7125803324334274), ('__license__', 0.6970326523026)]
Top words for pretrained_BERT neuron indx 3718 [('help', 1.0), ('unicode', 0.9541088271104183), ('settings', 0.8789176205340838), ('state', 0.8580441768927773), ('slug', 0.8069359276070263)]
Top words for pretrained_BERT neuron indx 3719 [('day', 1.0), ('month', 0.9414672632559876), ('filter', 0.915712993070884), ('broadcast', 0.8988446262946771), ('alt', 0.8060588541766444)]
Top words for pretrained_BERT neuron indx 5769 [('user', 1.0), ('contents', 0.8868786283515604), ('1800', 0.8146808265334984), ('server', 0.7783579638098651), ('print', 0.7294874277183205)]
Top words for pretrained_BERT neuron indx 7817 [('tz', 1.0), ('created', 0.8359197070534157), ('millis', 0.8104968000841185), ('v', 0.7839489401188005), ('dt', 0.7737073992166495)]
Top words for pretrained_BERT neuron indx 3729 [('format', 1.0), ('proxy', 0.8779689568436186), ('List', 0.8626213590094097), ('srv', 0.8580713068939843), ('E', 0.8393121456228173)]
Top words for pretrained_BERT neuron indx 7828 [('digest', 1.0), ('eg', 0.9536048208248825), ('strip', 0.9341600759033148), ('zone', 0.8711794190518712), ('uss', 0.7713415219831714)]
Top words for pretrained_BERT neuron indx 5780 [('minutes', 1.0), ('seconds', 0.9111562911451673), ('line', 0.8502732798505078), ('contents', 0.8215284608028289), ('boardname', 0.7906218609216098)]
Top words for pretrained_BERT neuron indx 3735 [('context', 1.0), ('40', 0.8706647813264923), ('field', 0.8634604575240766), ('con', 0.8492630503508837), ('pop', 0.8453357600152493)]
Top words for pretrained_BERT neuron indx 9882 [('write', 1.0), ('GET', 0.9941338882062805), ('connection', 0.953192248438706), ('tz', 0.8704680394460498), ('add', 0.8681081344187328)]
Top words for pretrained_BERT neuron indx 7836 [('logging', 1.0), ('resource', 0.8487927449429314), ('method', 0.7859098768222398), ('patch', 0.7847691264549667), ('user', 0.7715265001695106)]
Top words for pretrained_BERT neuron indx 1702 [('strip', 1.0), ('format', 0.9200596207010473), ('render', 0.9122659645373272), ('user', 0.9097393032261304), ('partition', 0.908543801974521)]
Top words for pretrained_BERT neuron indx 7849 [('_user', 1.0), ('join', 0.9616698086059773), ('connection', 0.9488931671228752), ('from', 0.9414879204846435), ('__hash__', 0.9061999645497417)]
Top words for pretrained_BERT neuron indx 3762 [('int', 1.0), ('Mesh', 0.947382559218434), ('if', 0.9166615924185054), ('choices', 0.9080107661514298), ('30', 0.8942904559690029)]
Top words for pretrained_BERT neuron indx 9908 [('millis', 1.0), ('400', 0.869054168655454), ('Library', 0.8534586812775791), ('request', 0.816911688858551), ('milliseconds', 0.8085008178509383)]
Top words for pretrained_BERT neuron indx 7861 [('open', 1.0), ('contents', 0.9894091205800288), ('settings', 0.9090689326947359), ('pop', 0.8704144644603131), ('reactor', 0.8600149422675307)]
Top words for pretrained_BERT neuron indx 7860 [('ms', 1.0), ('count', 0.9526389331848062), ('common', 0.9471584332572439), ('mesh', 0.9321288925019569), ('milliseconds', 0.894176214534328)]
Top words for pretrained_BERT neuron indx 5817 [('body', 1.0), ('root', 0.9370964501096554), ('server', 0.8798060240286343), ('other', 0.8513626573681701), ('board', 0.7643269783345457)]
Top words for pretrained_BERT neuron indx 3773 [('Node', 1.0), ('enabled', 0.8202941940069892), ('other', 0.7655933270332328), ('reactor', 0.7381500640771493), ('v', 0.7057760697819334)]
Top words for pretrained_BERT neuron indx 5826 [('ignore', 1.0), ('text', 0.9840574293114328), ('help', 0.8101504344346206), ('types', 0.7875732693953972), ('sorted', 0.7701610333417734)]
Top words for pretrained_BERT neuron indx 7875 [('component', 1.0), ('if', 0.9545302672426708), ('django', 0.9208221136945122), ('24', 0.9016700514253255), ('17', 0.8482027666254618)]
Top words for pretrained_BERT neuron indx 7876 [('time', 1.0), ('40', 0.8831767186780644), ('force', 0.8818892930363994), ('400', 0.88109772605331), ('60', 0.8321251654453818)]
Top words for pretrained_BERT neuron indx 5829 [('20', 1.0), ('help', 0.9910065063940761), ('300', 0.9221690887041138), ('uss', 0.9070334372035085), ('bind', 0.8597641773560789)]
Top words for pretrained_BERT neuron indx 1731 [('match', 1.0), ('clone', 0.9328369870508249), ('material', 0.8708359723230126), ('MAXBOARD', 0.8159257801757342), ('error', 0.8087387092246144)]
Top words for pretrained_BERT neuron indx 1739 [('400', 1.0), ('300', 0.8946773162652016), ('Log', 0.7374467270008226), ('board', 0.7266495639615277), ('800', 0.7065968756962829)]
Top words for pretrained_BERT neuron indx 3789 [('bare', 1.0), ('clone', 0.8598569391653144), ('join', 0.8365633591894254), ('wait', 0.7793857254320856), ('uss', 0.7540285735030617)]
Top words for pretrained_BERT neuron indx 1742 [('ping', 1.0), ('force', 0.871111756587552), ('exceptions', 0.8597579744667962), ('break', 0.8557686604621221), ('loads', 0.8465760717819815)]
Top words for pretrained_BERT neuron indx 9940 [('patch', 1.0), ('to', 0.9920667375745511), ('enclosure', 0.9355172676598091), ('REQUEST', 0.8585493340785315), ('parse', 0.8254943440031294)]
Top words for pretrained_BERT neuron indx 1749 [('st', 1.0), ('replace', 0.867069633636234), ('exit', 0.7623343585057448), ('save', 0.7404154701287011), ('write', 0.7383095519097128)]
Top words for pretrained_BERT neuron indx 3798 [('close', 1.0), ('count', 0.9960351918378701), ('while', 0.9218320573181538), ('17', 0.8959599809248838), ('uss', 0.8335366859908557)]
Top words for pretrained_BERT neuron indx 7895 [('openstack', 1.0), ('from', 0.7739520453529349), ('part', 0.7483541539411899), ('Profile', 0.7205982874631394), ('9', 0.7051766309476154)]
Top words for pretrained_BERT neuron indx 5856 [('logging', 1.0), ('int', 0.8843933704763141), ('META', 0.875755191718573), ('end', 0.8466063403777485), ('token', 0.7348130473961376)]
Top words for pretrained_BERT neuron indx 7905 [('blocking', 1.0), ('__long__', 0.8501171934555605), ('vwwn', 0.8433910582611464), ('vsn', 0.8128669737263851), ('egs', 0.7971895605170143)]
Top words for pretrained_BERT neuron indx 9955 [('enclosure', 1.0), ('15', 0.9010245608943508), ('20000', 0.8987198021045046), ('1800', 0.8674385852546386), ('Tab', 0.8079670177207082)]
Top words for pretrained_BERT neuron indx 1763 [('activity', 1.0), ('st_mtime', 0.9594185417970328), ('boot', 0.9576692249006079), ('if', 0.9344537363542493), ('unicode', 0.930391948414393)]
Top words for pretrained_BERT neuron indx 7910 [('message', 1.0), ('other', 0.9940854761985505), ('send', 0.9882166028785178), ('end', 0.9739620325538919), ('enclosure', 0.9335946754227057)]
Top words for pretrained_BERT neuron indx 5863 [('1800', 1.0), ('86400', 0.9957308306245887), ('oslo', 0.9246165959160806), ('3600', 0.893759151854903), ('Unauthorized', 0.8579232313320393)]
Top words for pretrained_BERT neuron indx 1768 [('contents', 1.0), ('required', 0.9910950994428208), ('zone', 0.9511800949005628), ('split', 0.9241990877942889), ('f', 0.8186359345378884)]
Top words for pretrained_BERT neuron indx 3822 [('count', 1.0), ('Board', 0.9909148605178968), ('List', 0.9848449154067468), ('Component', 0.9685973729980664), ('component', 0.9412483288109018)]
Top words for pretrained_BERT neuron indx 9971 [('purpose', 1.0), ('exit', 0.8916467536032503), ('error', 0.8719198864888368), ('activity', 0.850095580023708), ('128', 0.7824177255841359)]
Top words for pretrained_BERT neuron indx 1788 [('Profile', 1.0), ('sts', 0.9485770594231396), ('profile', 0.9368004310501331), ('8000', 0.7818012331817669), ('policy', 0.7120915768205613)]
Top words for pretrained_BERT neuron indx 3840 [('split', 1.0), ('domain', 0.9683504750480233), ('Profile', 0.9460010937718417), ('IsSysop', 0.9069394953584765), ('struct', 0.8753334129780478)]
Top words for pretrained_BERT neuron indx 5893 [('models', 1.0), ('tz', 0.6764381682526603), ('month', 0.6455163278522918), ('oslo', 0.6286905709407866), ('year', 0.6265965024295173)]
Top words for pretrained_BERT neuron indx 5904 [('types', 1.0), ('400', 0.9506019943761824), ('exceptions', 0.8963274118167399), ('log', 0.8505510655115116), ('pop', 0.8301191394679591)]
Top words for pretrained_BERT neuron indx 3861 [('if', 1.0), ('url', 0.9540588896376258), ('Log', 0.9357438972974149), ('type', 0.9195635393485696), ('uri', 0.8760074557300538)]
Top words for pretrained_BERT neuron indx 7959 [('replace', 1.0), ('alt', 0.9564676837175796), ('session', 0.8883895506127237), ('ref', 0.8474534713857435), ('80', 0.8364986711323232)]
Top words for pretrained_BERT neuron indx 3868 [('host', 1.0), ('loads', 0.9663528132486183), ('View', 0.9544857401428353), ('requests', 0.8877244598223575), ('save', 0.8279585338562675)]
Top words for pretrained_BERT neuron indx 3885 [('state', 1.0), ('calendar', 0.8111749752958738), ('digest', 0.8013911401542418), ('"r"', 0.6645448984352552), ('"view"', 0.6200869825524293)]
Top words for pretrained_BERT neuron indx 3889 [('required', 1.0), ('Authorization', 0.8735755733379994), ('core', 0.871305468709557), ('msgbox', 0.8054977130536046), ('24', 0.7733225520555456)]
Top words for pretrained_BERT neuron indx 1844 [('to', 1.0), ('".."', 0.9715949540094723), ('as', 0.9084014050141024), ('from', 0.865238261331083), ('On', 0.8625204619814633)]
Top words for pretrained_BERT neuron indx 1851 [('session', 1.0), ('Session', 0.9975351059199018), ('routes', 0.9530028360834196), ('field', 0.9222437019334414), ('ping', 0.9025885306929653)]
Top words for pretrained_BERT neuron indx 1869 [('main', 1.0), ('other', 0.9713248903813457), ('types', 0.96709870467094), ('day', 0.9008705014076446), ('v', 0.8705361137706058)]
Top words for pretrained_BERT neuron indx 8020 [('REQUEST', 1.0), ('""', 0.9959313910911554), ('end', 0.9419316696000721), ('"view"', 0.9304631764699469), ('ignore', 0.8450535393393137)]
Top words for pretrained_BERT neuron indx 8027 [('token', 1.0), ('break', 0.8584325019920058), ('__title__', 0.8388677863805386), ('enclosure', 0.8375336013479009), ('baseline', 0.8344776418875138)]
Top words for pretrained_BERT neuron indx 1893 [('contents', 1.0), ('boot', 0.9222618835593032), ('v', 0.7502550548249388), ('Tab', 0.6985495424977463), ('Board', 0.6825826864045427)]
Top words for pretrained_BERT neuron indx 1895 [('utc', 1.0), ('enclosure', 0.9696949247787434), ('error', 0.8918963708133846), ('field', 0.8853710056224122), ('stanza', 0.8651672797004634)]
Top words for pretrained_BERT neuron indx 3949 [('Authorization', 1.0), ('hour', 0.9394265055894017), ('to', 0.9127817517712674), ('con', 0.8817135483215931), ('day', 0.8623250027859432)]
Top words for pretrained_BERT neuron indx 8060 [('9', 1.0), ('1800', 0.9668130148098415), ('14', 0.8727258889892765), ('800', 0.8686300887808226), ('1000', 0.8427756297649197)]
Top words for pretrained_BERT neuron indx 3965 [('baseline', 1.0), ('upper', 0.806800671106702), ('help', 0.7857868612059613), ('GET', 0.65373278775361), ('reactor', 0.6343550682877314)]
Top words for pretrained_BERT neuron indx 6013 [('300', 1.0), ('continue', 0.9613135767875955), ('30', 0.921982723917802), ('time', 0.9034587258803364), ('return', 0.8738513749553005)]
Top words for pretrained_BERT neuron indx 1920 [('profile', 1.0), ('Profile', 0.8992228452135507), ('probe', 0.8604540548209604), ('128', 0.8486644387025111), ('add', 0.7991517741924291)]
Top words for pretrained_BERT neuron indx 3970 [('close', 1.0), ('zone', 0.844588910898442), ('state', 0.821131470710663), ('List', 0.8145626426170156), ('View', 0.8111253878419307)]
Top words for pretrained_BERT neuron indx 8069 [('strip', 1.0), ('Tab', 0.9645045592112023), ('part', 0.8315616683033948), ('patch', 0.794402332093782), ('baseline', 0.7838433401423524)]
Top words for pretrained_BERT neuron indx 8080 [('models', 1.0), ('i', 0.9300474266169239), ('args', 0.8478289625222749), ('calendar', 0.8331060868174052), ('f', 0.8185359670317067)]
Top words for pretrained_BERT neuron indx 6034 [('put', 1.0), ('text', 0.9254468478438306), ('""', 0.8050976861160604), ('as', 0.7444818073256485), ('Node', 0.7404205701589806)]
Top words for pretrained_BERT neuron indx 6039 [('Board', 1.0), ('pop', 0.9677015425989149), ('Mesh', 0.8670248179201414), ('context', 0.8495915142077536), ('40', 0.8463890811077047)]
Top words for pretrained_BERT neuron indx 1948 [('Component', 1.0), ('sorted', 0.930483730425876), ('Simple', 0.853275517008853), ('On', 0.8434937770730436), ('sans', 0.8387077325501063)]
Top words for pretrained_BERT neuron indx 4005 [('False', 1.0), ('choices', 0.910334610493852), ('other', 0.8511158213145039), ('group', 0.8116767794671227), ('requests', 0.809318628790687)]
Top words for pretrained_BERT neuron indx 8118 [('description', 1.0), ('modes', 0.9779323365527072), ('link', 0.9391326607232254), ('Simple', 0.7572970563884904), ('root', 0.7321637980364265)]
Top words for pretrained_BERT neuron indx 8123 [('query', 1.0), ('".."', 0.9608521924533304), ('15', 0.9382318285763979), ('slug', 0.9131854774139021), ('""', 0.8995913889567306)]
Top words for pretrained_BERT neuron indx 6085 [('type', 1.0), ('tastypie', 0.9733372107553794), ('common', 0.963825986182704), ('__long__', 0.913113494425639), ('material', 0.9100983170695159)]
Top words for pretrained_BERT neuron indx 6086 [('domain', 1.0), ('scope', 0.8805074962324834), ('with', 0.8182479698202674), ('def', 0.8003890944962482), ('con', 0.7826903406269391)]
Top words for pretrained_BERT neuron indx 8135 [('main', 1.0), ('Mesh', 0.9428518759000507), ('group', 0.9303726174715474), ('models', 0.8834174356624794), ('long', 0.8776534806020045)]
Top words for pretrained_BERT neuron indx 4046 [('loads', 1.0), ('split', 0.9996263925279559), ('main', 0.9727711316207922), ('ping', 0.8966759873055166), ('sans', 0.895187224126793)]
Top words for pretrained_BERT neuron indx 8150 [('9', 1.0), ('Log', 0.6999525217016208), ('600', 0.682327476604385), ('v', 0.6611110922492437), ('log', 0.6326141511775494)]
Top words for pretrained_BERT neuron indx 2007 [('stat', 1.0), ('horizon', 0.9228657033113199), ('"purpose"', 0.8214432194283541), ('oslo', 0.7826465177940577), ('ref', 0.7804192141482991)]
Top words for pretrained_BERT neuron indx 6103 [('to', 1.0), ('max', 0.8561813959421342), ('utc', 0.8237038050397444), ('us', 0.7942954449497077), ('List', 0.7499378679302826)]
Top words for pretrained_BERT neuron indx 8154 [('Tab', 1.0), ('features', 0.923728536117749), ('error', 0.9139142027876589), ('while', 0.910893424126197), ('purpose', 0.8916437851785478)]
Top words for pretrained_BERT neuron indx 6117 [('month', 1.0), ('year', 0.9339377409088714), ('day', 0.7912773254068725), ('contents', 0.7705090952355114), ('log', 0.7274446074495258)]
Top words for pretrained_BERT neuron indx 8171 [('features', 1.0), ('import', 0.9448630282443031), ('link', 0.9295096034944734), ('from', 0.8378874656979104), ('seek', 0.8222086137802379)]
Top words for pretrained_BERT neuron indx 4077 [('unicode', 1.0), ('domain', 0.8700647576965489), ('broadcast', 0.8592543827023339), ('Billboard', 0.8123132909805172), ('"sysmail"', 0.7923345626941295)]
Top words for pretrained_BERT neuron indx 6126 [('GetBoard', 1.0), ('Mesh', 0.9310607737311141), ('List', 0.9300801436746361), ('Board', 0.8151667671073614), ('24', 0.8052105388065512)]
Top words for pretrained_BERT neuron indx 6128 [('error', 1.0), ('alt', 0.7738994501051163), ('def', 0.7683119108601122), ('authentication', 0.7634145565196963), ('store', 0.7432301615998421)]
Top words for pretrained_BERT neuron indx 6131 [('400', 1.0), ('add', 0.9603015524603193), ('600', 0.9480991524658597), ('1000', 0.929758288241918), ('purpose', 0.8465149492472593)]
Top words for pretrained_BERT neuron indx 8184 [('META', 1.0), ('materials', 0.8897763655307529), ('push', 0.8129966854717368), ('put', 0.7314647280532418), ('direct', 0.7263666850151619)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0145
Epoch: [2/10], Loss: 0.0104
Epoch: [3/10], Loss: 0.0083
Epoch: [4/10], Loss: 0.0073
Epoch: [5/10], Loss: 0.0061
Epoch: [6/10], Loss: 0.0054
Epoch: [7/10], Loss: 0.0048
Epoch: [8/10], Loss: 0.0047
Epoch: [9/10], Loss: 0.0043
Epoch: [10/10], Loss: 0.0046
Score (accuracy) of the probe: 0.22
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0147
Epoch: [2/10], Loss: 0.0109
Epoch: [3/10], Loss: 0.0090
Epoch: [4/10], Loss: 0.0075
Epoch: [5/10], Loss: 0.0066
Epoch: [6/10], Loss: 0.0060
Epoch: [7/10], Loss: 0.0051
Epoch: [8/10], Loss: 0.0047
Epoch: [9/10], Loss: 0.0041
Epoch: [10/10], Loss: 0.0040
Score (accuracy) of the probe: 0.19
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0145
Epoch: [2/10], Loss: 0.0106
Epoch: [3/10], Loss: 0.0085
Epoch: [4/10], Loss: 0.0070
Epoch: [5/10], Loss: 0.0061
Epoch: [6/10], Loss: 0.0055
Epoch: [7/10], Loss: 0.0050
Epoch: [8/10], Loss: 0.0047
Epoch: [9/10], Loss: 0.0043
Epoch: [10/10], Loss: 0.0048
Score (accuracy) of the probe: 0.22
Training classification probe
Creating model...
Number of training instances: 851
Number of classes: 4
Epoch: [1/10], Loss: 0.0154
Epoch: [2/10], Loss: 0.0111
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0086
Epoch: [5/10], Loss: 0.0080
Epoch: [6/10], Loss: 0.0076
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0065
Epoch: [9/10], Loss: 0.0063
Epoch: [10/10], Loss: 0.0055
Score (accuracy) of the probe: 0.19

The best l1=0, the best l2=0 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.26
{'__OVERALL__': 0.2618510158013544, 'NAME': 0.2616822429906542, 'STRING': 0.2871287128712871, 'NUMBER': 0.19708029197080293, 'KEYWORD': 0.32653061224489793}
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.22

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.5778781038374718
----------------------------------------------------------------
