Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
1289 13.0
Number of tokens:  11684
length of source dictionary:  1042
length of target dictionary:  35
11684
Total instances: 11684
['replace', '"bearer_token"', '_closed', '400', 'Session', 'purpose', 'reactor', 'bool', 'GetModTime', 'epoch_secs', 'authentication', 'register_opts', 'get_storage_vol_template_policy', 'basestring', 'Post', 'absolute_import', 'get_context_data', 'set_eula', 'EffectiveId', '__license__']
Number of samples:  11684
Stats: Labels with their frequencies in the final set
NAME 3656
NEWLINE 1172
KEYWORD 905
LPAR 870
RPAR 866
DOT 858
EQUAL 597
COMMA 576
COLON 447
DEDENT 369
INDENT 293
LSQB 204
RSQB 204
NUMBER 190
NL 117
STRING 82
EQEQUAL 48
PLUS 33
LBRACE 25
STAR 24
RBRACE 24
MINUS 22
PERCENT 22
AT 14
PLUSEQUAL 12
GREATER 11
NOTEQUAL 10
DOUBLESTAR 8
LESS 7
SLASH 5
COMMENT 4
GREATEREQUAL 3
MINEQUAL 3
LESSEQUAL 2
SEMI 1
pretrained_BERT distribution after trauncating:
{0: 0.7564659631698738, 3: 0.1872542933995448, 2: 0.03931305607283261, 1: 0.01696668735774881}
{0: 3656, 3: 905, 2: 190, 1: 82}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
494 13.0
Number of tokens:  6400
length of source dictionary:  482
length of target dictionary:  34
6400
Total instances: 6400
['merge', 'result_eval', 'source_suffix', 'data', '0.7', 'toolbox', 'x', 'sgru', '_h', 'crop1', 'crop0', 'crop_test', 'OrderedDict', 'a', 'man_pages', 'AssertionError', 'input_size', 'add_param', 'mult_add_st', 'path']
Number of samples:  6400
Stats: Labels with their frequencies in the final set
NAME 1721
COMMA 798
NUMBER 482
RPAR 439
LPAR 437
NEWLINE 433
DOT 348
KEYWORD 336
COLON 293
EQUAL 241
LSQB 233
RSQB 228
DEDENT 97
INDENT 82
STAR 62
NL 60
EQEQUAL 29
PLUS 26
MINUS 15
DOUBLESTAR 7
SLASH 6
AT 6
STRING 4
LBRACE 3
RBRACE 3
STAREQUAL 2
PERCENT 2
GREATER 1
LESS 1
COMMENT 1
GREATEREQUAL 1
PLUSEQUAL 1
LESSEQUAL 1
AMPER 1
pretrained_BERT distribution after trauncating:
{0: 0.6767597325992922, 2: 0.18953991348800628, 3: 0.1321274085725521, 1: 0.0015729453401494297}
{0: 1721, 2: 482, 3: 336, 1: 4}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 3656, 3: 905, 2: 190, 1: 82})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({0: 394, 2: 87, 3: 24, 1: 4})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (4349, 9984)
The shape of the validation set: (484, 9984)
The shape of the testing set: (509, 9984)
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0043
Epoch: [2/10], Loss: 0.0004
Epoch: [3/10], Loss: 0.0001
Epoch: [4/10], Loss: 0.0001
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0043
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0002
Epoch: [4/10], Loss: 0.0001
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0055
Epoch: [2/10], Loss: 0.0018
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.72
{'__OVERALL__': 0.7190569744597249, 'NAME': 0.6370558375634517, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0076
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0092
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.71
{'__OVERALL__': 0.7111984282907662, 'NAME': 0.6878172588832487, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0093
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.63
{'__OVERALL__': 0.630648330058939, 'NAME': 0.583756345177665, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0042
Epoch: [3/10], Loss: 0.0028
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0014
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0010
Epoch: [9/10], Loss: 0.0009
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0093
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0022
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.59
{'__OVERALL__': 0.587426326129666, 'NAME': 0.5279187817258884, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0094
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.63
{'__OVERALL__': 0.6345776031434185, 'NAME': 0.5355329949238579, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.875}
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.64
{'__OVERALL__': 0.6385068762278978, 'NAME': 0.5329949238578681, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0076
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0045
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.63
{'__OVERALL__': 0.6267190569744597, 'NAME': 0.5177664974619289, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0033
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0076
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0042
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.68
{'__OVERALL__': 0.6817288801571709, 'NAME': 0.5888324873096447, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0072
Epoch: [2/10], Loss: 0.0030
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0073
Epoch: [2/10], Loss: 0.0030
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0020
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.70
{'__OVERALL__': 0.6994106090373281, 'NAME': 0.6116751269035533, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0071
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0018
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0010
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0070
Epoch: [2/10], Loss: 0.0027
Epoch: [3/10], Loss: 0.0018
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0010
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0072
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0030
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0019
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.72
{'__OVERALL__': 0.7210216110019646, 'NAME': 0.6395939086294417, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0065
Epoch: [2/10], Loss: 0.0025
Epoch: [3/10], Loss: 0.0016
Epoch: [4/10], Loss: 0.0012
Epoch: [5/10], Loss: 0.0009
Epoch: [6/10], Loss: 0.0007
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0017
Epoch: [4/10], Loss: 0.0012
Epoch: [5/10], Loss: 0.0010
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0027
Epoch: [3/10], Loss: 0.0018
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0076
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0028
Epoch: [4/10], Loss: 0.0024
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0018
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.74
{'__OVERALL__': 0.7387033398821218, 'NAME': 0.6624365482233503, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0072
Epoch: [2/10], Loss: 0.0030
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0070
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0066
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0019
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.76
{'__OVERALL__': 0.7583497053045186, 'NAME': 0.6878172588832487, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0071
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0070
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0070
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0041
Epoch: [3/10], Loss: 0.0032
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0020
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.72
{'__OVERALL__': 0.7229862475442044, 'NAME': 0.6421319796954315, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0010
Epoch: [9/10], Loss: 0.0009
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0073
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0017
Epoch: [6/10], Loss: 0.0014
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0025
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0023
Epoch: [10/10], Loss: 0.0022
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.67
{'__OVERALL__': 0.6699410609037328, 'NAME': 0.5736040609137056, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.77

pretrained_BERT top neurons
array([8194, 4103, 2055, 8204, 4109, 6158, 6162, 2071,   26, 8218, 6172,
       2079,   35,   38,   40, 2096, 8241, 4147, 4148,   62, 8257, 2119,
       4171,   79, 2139, 4190, 6247, 2152, 4206,  111, 2160, 6266, 2171,
       2173,  127, 6274, 6284,  142, 6286, 2192, 2193, 4247, 2200, 8347,
       4251, 8350, 8351,  160, 4259, 2213, 4262, 6313, 6314, 4267, 8371,
       8376, 4282, 4284, 6334, 2239, 8384, 2241, 2242, 6347, 6351, 2262,
       6362,  221, 8419, 8421, 6378,  235,  240, 8434, 8436, 6389, 2295,
       8439,  257, 2307,  262,  272,  279, 8476, 8478,  286,  307, 6452,
       6459, 8523,  333, 8533, 6489, 8539, 6500, 6504, 2409, 2418,  380,
       8572,  385, 6530,  389, 4489, 6540, 6541, 6551,  410, 8604,  415,
       6563,  422, 4521,  429, 6575, 8625, 4539,  444, 6595,  451, 6599,
       4566,  472, 6616, 6618, 8669,  478, 6624, 6626, 8682, 2539, 2538,
        499,  503, 8697, 8709,  517, 6664, 8713, 6669, 6670, 4622, 2576,
       4627,  535, 6679,  538, 8733, 8751,  560, 8753, 6719, 6720, 8767,
       2628, 4679,  583, 2631, 4685, 8787, 4692, 8793,  604, 2654,  614,
       4713, 8812, 6765, 6767,  624, 8815,  627, 4727, 4731,  636,  635,
       4734, 2689, 4738, 8838, 8842, 8844, 8845, 4750, 6799, 8848,  657,
       2705, 6797, 8852,  656, 4751, 8855, 8867, 6821, 2726,  680, 6840,
       2745, 2748, 2754, 4803, 8901,  710, 8903, 6856,  712, 4811, 6870,
        726, 8924, 6892,  753, 8955, 8964, 4874, 4875,  782, 2830, 8976,
       6928, 6930,  788, 6942, 2847, 4897, 4902, 6952, 2864, 9009,  818,
       4916, 9013, 9023, 2887, 9033, 4939, 9041, 6997, 7003, 7006, 4958,
       7008, 4961, 4963,  868, 2920, 9071, 7031, 7033, 7034, 7035, 2938,
       4993,  898,  899, 7044, 7052, 7059, 5016, 7068, 9119, 2976,  928,
       9123, 9125, 7081, 9151, 7107, 5059,  969, 7115, 3023,  979, 7137,
       5091, 5094, 7144, 7146, 1003, 7155, 7157, 1026, 9218, 3077, 7177,
       7178, 9229, 9242, 1050, 7197, 9246, 3103, 7205, 7208, 9261, 7220,
       1078, 9274, 5184, 5188, 3146, 1101, 3162, 7260, 1122, 1129, 3181,
       5229, 9332, 5240, 5243, 1148, 3198, 7296, 1153, 5250, 7308, 7317,
       7319, 9372, 7331, 1196, 7343, 5297, 3251, 5304, 1209, 1212, 1218,
       1219, 9411, 3269, 7376, 5334, 1241, 9442, 3299, 7395, 3302, 9447,
       9448, 9450, 9471, 9475, 9477, 3339, 7438, 5394, 9495, 5404, 9501,
       3360, 3361, 7473, 7488, 1351, 3411, 5469, 3422, 5472, 3427, 1384,
       5482, 9580, 5485, 1404, 3453, 3457, 5508, 9606, 7560, 5516, 7565,
       9616, 1424, 7571, 7572, 9620, 3475, 9623, 5528, 9625, 9627, 3487,
       7583, 5539, 9635, 1445, 3491, 3494, 5545, 5549, 1454, 5559, 7608,
       7609, 3516, 1474, 3523, 1477, 1480, 9674, 1494, 9692, 9694, 9696,
       9697, 7653, 5606, 1513, 5610, 7660, 9715, 7668, 3582, 5631, 3584,
       5635, 9732, 9736, 3592, 3600, 7698, 5654, 7708, 7710, 9771, 5684,
       9784, 5691, 3648, 7745, 3655, 9801, 7764, 7765, 7774, 5731, 7779,
       5747, 7801, 1659, 3707, 1662, 7810, 1666, 7812, 5772, 9869, 5773,
       3731, 5783, 9879, 9881, 7837, 9887, 5795, 9891, 9893, 9896, 5807,
       5823, 1729, 3778, 7875, 7883, 9935, 3791, 3798, 3799, 1757, 7902,
       7905, 7906, 5862, 9962, 7914, 7929, 1786, 7942, 7949, 5902, 7959,
       7965, 1846, 7999, 5952, 5953, 5956, 3949, 5997, 5999, 3952, 8048,
       3956, 6007, 3970, 8076, 8077, 8080, 1937, 6033, 8087, 8099, 6053,
       4009, 4023, 4024, 8121, 1986, 1987, 8131, 6088, 2000, 2005, 2009,
       8156, 4074, 4075, 8172, 4079, 8178])
pretrained_BERT top neurons per class
{'NAME': array([1003, 7343, 6452, 7331, 7668, 7220, 9125, 8845, 8476, 9580, 4079,
       6563, 6624, 1474, 8478, 7812, 4171, 7146, 6618, 4539, 8682, 5807,
       8812, 3949, 3655, 8964,  538, 4916, 5482, 6575, 4750, 8848, 2242,
       9623, 6942, 4902, 9495, 2152, 3299,  422,   35, 9033, 9151,  624,
       8204, 1209, 1662, 8976,  286, 7107, 8855, 5902, 9041, 2538, 8436,
       6500, 7395, 5684, 6599, 1454, 7008, 2193, 3427, 9442,  710, 7044,
        389, 8697, 2745, 9013, 4009, 9696, 8076, 4963,  142, 7710, 5188,
       6870,  726, 7698, 6266, 5394, 7774, 4731, 1148, 6856, 7376, 2976,
       1659, 3778, 1477, 2160, 7006, 5999, 6930, 3487, 5304, 5094, 1351,
       2920,  535, 4627, 2307, 4811, 4803, 1384, 4734, 9771, 7137, 9448,
       1219, 8838, 7653,  380, 1513, 9625, 4679, 8376,   62, 4262, 5731,
       6007, 8903, 2409, 5997, 5539, 8178, 8844,  410, 7560,  604, 7959,
       6767, 3457,   38,  444, 4566, 9896, 3453, 1129, 6284, 8539, 4074,
       8709, 7157,   26, 5091, 8733,  472, 5059, 5862, 3422, 2173, 7875,
       4148]), 'STRING': array([6626,  444, 9580, 8855, 7965, 1212, 4284,  429, 6284, 1241, 1219,
       9623, 5783, 7572, 7052, 3422, 7560, 6664,  583, 6489, 8733, 7764,
       4009, 1351,  257, 7081, 7929, 6172, 8087,  385, 4875, 9736, 3516,
       2262, 5635, 6452, 4539, 7801, 7779, 7144, 4148, 6313, 4692, 7660,
       2576, 9962, 7031, 2654, 6799,   40, 2119, 8842, 4958, 6378, 7068,
       3302,  478, 7197, 8713, 5606, 9274, 9477, 3360,  657, 7942, 5610,
       4961, 7008,  560, 3584, 2009, 7319, 7115, 8156, 2847, 8625, 2705,
       9501, 5953, 1101, 7810, 6541, 4103, 8848,  240, 2171, 3707, 9332,
       6997, 4713, 4190, 9692,  680, 5472, 3269, 9620, 6334, 7155, 7177,
       8421,  389, 8924, 9616, 7034, 5795, 6247, 1729, 1003, 9125, 4874,
       2418, 3592,  535, 2920, 9879, 5528, 7208, 3146, 6928,  422, 8121,
       7902, 8218, 7609, 3339, 5240, 7343, 9697, 9627, 7296, 9694,  726,
       7905, 5952, 1987, 5404, 9635, 9869, 5631, 9261, 8347, 7837, 4147,
       3600, 6670, 2079, 9475,  111, 2239, 3799,  262, 8257, 9801]), 'NUMBER': array([8848, 7331, 8434, 9616, 2539, 6504, 6378,  538, 5795, 1986, 4993,
       7914, 1122,  410, 4075, 5469, 2689, 9071,  614, 4539, 8787, 6551,
       8478, 2631, 3457, 1218,  415, 5297, 9246, 9450,  604,  726, 7044,
       5783, 6088, 4521, 3487,   79, 6892, 6351, 1494, 5508, 5240, 1026,
       3181,  636, 1666,  782,  307, 6362, 5654, 9242, 6389, 8077, 8815,
       1454, 4961, 9891, 3251, 8419, 2864, 1078, 1404, 4627, 4622, 1101,
       7708,  560, 6563, 9229, 2005, 9447, 8572, 5747, 3952, 7059, 6053,
       8852, 4206, 9732, 8476, 1050, 1445, 4247,  333, 5243, 8080, 1474,
       5823, 5184, 2745, 1153, 2213, 4251, 6616, 9784,  279, 7308, 6274,
       7488, 4685, 5731, 2000, 2096,  503, 7571, 4023, 6286, 2295, 6669,
       9123, 6347,  753, 7003, 5691,  127, 3970, 3516,  517, 6720, 4259,
       2241, 2705, 8384, 3427, 3491, 6821, 3648, 2754, 5559, 7745, 7810,
       7999, 9694, 5549, 7906, 9893, 9715, 6459, 1846, 3731, 8955, 2055,
        499, 7107, 4727,  635, 3494,  818, 4024, 4738]), 'KEYWORD': array([ 429, 9119, 6797, 1937, 9372, 2887, 8523, 9935, 7565, 6930, 8351,
       3523, 6595, 6162, 5773,  221, 6670, 4993, 2071, 9869, 8901, 8682,
       4282, 9887, 8376, 9881, 8572, 2830, 7583, 5334, 9477, 6719, 8867,
       5772, 8077, 3791, 9125, 3198, 9471, 7317, 7438, 2628, 7033, 8241,
       2748, 6765,  499, 2239, 6500, 2192, 4267,  627, 8178, 9580, 6618,
       5485,  451, 4622, 3162, 7608, 7035, 8787, 5016, 6840,  656,  262,
       4489, 8172, 1513, 2139, 3798, 7260, 3361, 5250, 1196, 3077, 7765,
       7949, 6679,  538, 9606,  788, 9218,  868, 9023, 1786, 3956, 6563,
       2726, 3475, 2119,  928, 3582, 8793,  898, 4939, 6540, 8845,  160,
       8099,  272, 8533, 7473, 6284, 8371, 6551, 8604, 9674, 5545, 7205,
        969, 8350,  979, 1101, 6314, 4734, 8767, 8751, 3411, 6158, 5229,
       4897,  235, 1241, 9009, 1480, 9411,  444,  899, 9736, 7178, 5956,
       3103, 3023, 8194, 6952, 1757, 8669, 2200, 8131, 4751, 8048, 7653,
       6530, 6033, 2938,  712, 7883, 8753, 1424, 5516, 8439, 4109])}
The shape of selected features (4349, 523)
The shape of the training set: (4349, 523)
The shape of the validation set: (484, 523)
The shape of the testing set: (509, 523)
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0071
Epoch: [2/10], Loss: 0.0022
Epoch: [3/10], Loss: 0.0013
Epoch: [4/10], Loss: 0.0009
Epoch: [5/10], Loss: 0.0007
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0059
Epoch: [2/10], Loss: 0.0019
Epoch: [3/10], Loss: 0.0011
Epoch: [4/10], Loss: 0.0008
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0060
Epoch: [2/10], Loss: 0.0019
Epoch: [3/10], Loss: 0.0012
Epoch: [4/10], Loss: 0.0009
Epoch: [5/10], Loss: 0.0007
Epoch: [6/10], Loss: 0.0006
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.01 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.80
{'__OVERALL__': 0.7976424361493124, 'NAME': 0.7385786802030457, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.77
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0051
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0013
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0091
Epoch: [2/10], Loss: 0.0053
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0020
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0095
Epoch: [2/10], Loss: 0.0058
Epoch: [3/10], Loss: 0.0044
Epoch: [4/10], Loss: 0.0037
Epoch: [5/10], Loss: 0.0033
Epoch: [6/10], Loss: 0.0030
Epoch: [7/10], Loss: 0.0028
Epoch: [8/10], Loss: 0.0027
Epoch: [9/10], Loss: 0.0026
Epoch: [10/10], Loss: 0.0025
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.87
{'__OVERALL__': 0.8742632612966601, 'NAME': 0.8451776649746193, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.875}
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.77
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 8194 [('zone', 1.0), ('local', 0.7890889436911074), ('vCard', 0.757809844306073), ('main', 0.7509707675645527), ('parts', 0.7362470445157049)]
Top words for pretrained_BERT neuron indx 4103 [('oslo', 1.0), ('Unauthorized', 0.8316942990173852), ('long', 0.8065809317641529), ('not', 0.7950176233529102), ('upper', 0.7648369447500072)]
Top words for pretrained_BERT neuron indx 2055 [('m', 1.0), ('f', 0.9918370249946658), ('open', 0.9377205402184069), ('filters', 0.9357109000622114), ('seconds', 0.8815923632403254)]
Top words for pretrained_BERT neuron indx 8204 [('6', 1.0), ('40', 0.9990579730809405), ('On', 0.9713507996595363), ('v', 0.9527206473478074), ('17', 0.9521950036806235)]
Top words for pretrained_BERT neuron indx 4109 [('bind', 1.0), ('property', 0.9014251545518852), ('super', 0.8978405824736223), ('ranges', 0.881156781856214), ('body', 0.8761013670062116)]
Top words for pretrained_BERT neuron indx 6158 [('force', 1.0), ('15', 0.9016414171618456), ('oslo', 0.8363861497727939), ('8', 0.8256133812371609), ('Off', 0.78428962786243)]
Top words for pretrained_BERT neuron indx 6162 [('log', 1.0), ('port', 0.997582680401369), ('logging', 0.9750314650751042), ('minutes', 0.9121818546156945), ('True', 0.8823792552679065)]
Top words for pretrained_BERT neuron indx 2071 [('seek', 1.0), ('token', 0.951586174200817), ('3700', 0.8237137498902446), ('probe', 0.8118148287159225), ('3600', 0.7789804214732011)]
Top words for pretrained_BERT neuron indx 26 [('parent', 1.0), ('models', 0.9359985145111186), ('local', 0.8650174944683152), ('part', 0.8579414449905916), ('strip', 0.8253173468243151)]
Top words for pretrained_BERT neuron indx 8218 [('15', 1.0), ('"gbk"', 0.8696187188323817), ('url', 0.8522001724352899), ('"Resource"', 0.7938274450048856), ('ignore', 0.789105911151114)]
Top words for pretrained_BERT neuron indx 6172 [('loads', 1.0), ('us', 0.895888149567007), ('View', 0.8310894222514946), ('objects', 0.8131855945072295), ('to', 0.8008497249996924)]
Top words for pretrained_BERT neuron indx 2079 [('description', 1.0), ('direct', 0.9725965831202334), ('models', 0.9380063191725477), ('if', 0.9186650083319022), ('errors', 0.915188392002063)]
Top words for pretrained_BERT neuron indx 35 [('port', 1.0), ('add', 0.9562320541839228), ('direct', 0.9279740287240726), ('store', 0.8810437465430411), ('force', 0.8444965853014765)]
Top words for pretrained_BERT neuron indx 38 [('exceptions', 1.0), ('strip', 0.8894807620020142), ('300', 0.6687526249284376), ('filter', 0.6460999261502302), ('slug', 0.6022539623275177)]
Top words for pretrained_BERT neuron indx 40 [('def', 1.0), ('loads', 0.9342712971306635), ('len', 0.9088785307866365), ('int', 0.9078090872136991), ('upper', 0.8952335001942214)]
Top words for pretrained_BERT neuron indx 2096 [('year', 1.0), ('pop', 0.9911563466310727), ('routes', 0.938711386612856), ('body', 0.8787267963668591), ('contents', 0.8598816269421382)]
Top words for pretrained_BERT neuron indx 8241 [('milliseconds', 1.0), ('hour', 0.896601821304875), ('epoch_milliseconds', 0.8904168023739399), ('mesh', 0.8605916437920471), ('m', 0.8282922351830985)]
Top words for pretrained_BERT neuron indx 4147 [('loads', 1.0), ('"Host"', 0.684908188512412), ('"r"', 0.6721084335996064), ('"Name"', 0.6284939845119974), ('title', 0.6059511540791849)]
Top words for pretrained_BERT neuron indx 4148 [('with', 1.0), ('and', 0.9889259016008153), ('is', 0.9783548329714781), ('in', 0.9332094387042836), ('as', 0.8471281071549034)]
Top words for pretrained_BERT neuron indx 62 [('1000', 1.0), ('int', 0.885318335833985), ('META', 0.8480768070690107), ('9', 0.8375491922015716), ('unpack', 0.8257276982480479)]
Top words for pretrained_BERT neuron indx 8257 [('if', 1.0), ('seek', 0.9245329548225759), ('for', 0.9147860503284067), ('purpose', 0.8849261923048978), ('24', 0.8603533926518642)]
Top words for pretrained_BERT neuron indx 2119 [('Exception', 1.0), ('horizon', 0.7184468659793094), ('break', 0.7004699241384889), ('local', 0.635706795037468), ('action', 0.6062086856097443)]
Top words for pretrained_BERT neuron indx 4171 [('identity', 1.0), ('type', 0.9257116833158221), ('core', 0.8126881115089721), ('choices', 0.7860584553003316), ('REQUEST', 0.7739885053601441)]
Top words for pretrained_BERT neuron indx 79 [('calendar', 1.0), ('boot', 0.917015601569825), ('enclosure', 0.8461873832166048), ('Simple', 0.8198825944688768), ('servers', 0.8158198650134453)]
Top words for pretrained_BERT neuron indx 2139 [('contents', 1.0), ('error', 0.986724296648073), ('items', 0.9411013444008995), ('ranges', 0.9056368478309161), ('title', 0.905371622526593)]
Top words for pretrained_BERT neuron indx 4190 [('all', 1.0), ('timezone', 0.9927935035697252), ('unicode', 0.9462894882248857), ('astimezone', 0.8213702684242645), ('long', 0.8107701036098611)]
Top words for pretrained_BERT neuron indx 6247 [('META', 1.0), ('REQUEST', 0.8920350118452587), ('closing', 0.8854127369250937), ('sorted', 0.8744524978670127), ('authentication', 0.8129615876616698)]
Top words for pretrained_BERT neuron indx 2152 [('local', 1.0), ('us', 0.9758417675737223), ('None', 0.9635625040567269), ('purpose', 0.9604376371562441), ('Distance', 0.8749856668009215)]
Top words for pretrained_BERT neuron indx 4206 [('with', 1.0), ('sts', 0.9980842029695726), ('put', 0.9762217725983738), ('errors', 0.921680526632643), ('decode', 0.8939426119808359)]
Top words for pretrained_BERT neuron indx 111 [('context', 1.0), ('port', 0.9801454954934314), ('close', 0.9691920175466734), ('def', 0.9355587768974173), ('post', 0.9145660069862886)]
Top words for pretrained_BERT neuron indx 2160 [('info', 1.0), ('division', 0.9609002478946403), ('day', 0.8509709859654869), ('connection', 0.7601561452587171), ('us', 0.759780772477592)]
Top words for pretrained_BERT neuron indx 6266 [('7', 1.0), ('Tab', 0.889736047111155), ('from', 0.8549281307898692), ('other', 0.7755067198230361), ('sanetime', 0.7715176679993366)]
Top words for pretrained_BERT neuron indx 2171 [('path', 1.0), ('local', 0.8939712355344664), ('proxy', 0.8937753325549611), ('add', 0.8466242177933565), ('context', 0.7611229796403762)]
Top words for pretrained_BERT neuron indx 2173 [('match', 1.0), ('6', 0.9854018892832158), ('parent', 0.8875714887251713), ('loads', 0.8428158735420227), ('continue', 0.8386315181516041)]
Top words for pretrained_BERT neuron indx 127 [('unicode', 1.0), ('HorizontalBillboard', 0.7671359643741602), ('serialNumberType', 0.7265428079822049), ('VerticalBillboard', 0.7083063184535608), ('Exception', 0.6512293613696658)]
Top words for pretrained_BERT neuron indx 6274 [('close', 1.0), ('86400', 0.9729475436653104), ('main', 0.9701141004060388), ('Tab', 0.9635572018376127), ('800', 0.9560480884528251)]
Top words for pretrained_BERT neuron indx 6284 [('minutes', 1.0), ('seconds', 0.8686619745492516), ('key', 0.8385397711717282), ('80', 0.831730127951887), ('stanza', 0.8111742835536798)]
Top words for pretrained_BERT neuron indx 142 [('v', 1.0), ('scope', 0.985944436338986), ('Off', 0.9134386359956291), ('port', 0.8003403744182468), ('ms', 0.7860792359402329)]
Top words for pretrained_BERT neuron indx 6286 [('wait', 1.0), ('loads', 0.9817892052616818), ('Off', 0.9735775552535143), ('scope', 0.9530527703904808), ('to', 0.9517129860783643)]
Top words for pretrained_BERT neuron indx 2192 [('group', 1.0), ('On', 0.6996349049582988), ('tag', 0.6480414256642817), ('identity', 0.605590915298918), ('Simple', 0.5984906435979778)]
Top words for pretrained_BERT neuron indx 2193 [('affinity', 1.0), ('format', 0.9872949126340972), ('month', 0.9730183874957282), ('srv', 0.9381080730328079), ('f', 0.901250290959376)]
Top words for pretrained_BERT neuron indx 4247 [('enabled', 1.0), ('loads', 0.8486400250588473), ('META', 0.8293898480669889), ('GET', 0.8205214435135983), ('not', 0.793165381892433)]
Top words for pretrained_BERT neuron indx 2200 [('purpose', 1.0), ('300', 0.8849816959986981), ('future', 0.8510305580046749), ('Session', 0.8346028435534059), ('8000', 0.8269921600507325)]
Top words for pretrained_BERT neuron indx 8347 [('"view"', 1.0), ('seconds', 0.8535484348859204), ('"purpose"', 0.7961920636188903), ('authorization', 0.7456502712412502), ('"Host"', 0.7448705091986463)]
Top words for pretrained_BERT neuron indx 4251 [('Authorization', 1.0), ('authorization', 0.9270730267333525), ('request', 0.9048871087539118), ('push', 0.9044735426412016), ('authorized', 0.8930227527762474)]
Top words for pretrained_BERT neuron indx 8350 [('future', 1.0), ('requests', 0.9352997673934375), ('".."', 0.8501114780976738), ('List', 0.8411722530025318), ('filename', 0.8113358324513061)]
Top words for pretrained_BERT neuron indx 8351 [('bare', 1.0), ('e', 0.6923356232071394), ('Post', 0.6422303989836938), ('uss', 0.6106056722727161), ('boot', 0.60637012184917)]
Top words for pretrained_BERT neuron indx 160 [('META', 1.0), ('division', 0.9581263932682195), ('count', 0.7486198653202251), ('setup', 0.7119997635072446), ('GetMirror', 0.7119279608875174)]
Top words for pretrained_BERT neuron indx 4259 [('Tab', 1.0), ('Off', 0.8522335434450546), ('7', 0.7449712896916322), ('method', 0.702493233624971), ('with', 0.6908512457738227)]
Top words for pretrained_BERT neuron indx 2213 [('raise', 1.0), ('META', 0.8902968358549782), ('super', 0.7712794463955509), ('Mesh', 0.7456512325632805), ('id', 0.7417258390044884)]
Top words for pretrained_BERT neuron indx 4262 [('14', 1.0), ('12', 0.9634106671348953), ('count', 0.8812979543811484), ('15', 0.878901830926967), ('reactor', 0.8654733728159574)]
Top words for pretrained_BERT neuron indx 6313 [('connection', 1.0), ('join', 0.9879099867097406), ('__hash__', 0.9846078712494546), ('help', 0.9829863556292215), ('__int__', 0.9703685595715889)]
Top words for pretrained_BERT neuron indx 6314 [('minutes', 1.0), ('sorted', 0.6429980526500071), ('seconds', 0.6196482202908351), ('mins', 0.609944022887693), ('force', 0.6094151626480843)]
Top words for pretrained_BERT neuron indx 4267 [('msghead', 1.0), ('1800', 0.9968043111051579), ('get_resources', 0.9920908149639871), ('continue', 0.9789591995066381), ('hpov', 0.9783459130807465)]
Top words for pretrained_BERT neuron indx 8371 [('Billboard', 1.0), ('presence', 0.7863620338843995), ('Stretch', 0.7810110559062318), ('BlendProbes', 0.7754840510595925), ('1', 0.7543269759724262)]
Top words for pretrained_BERT neuron indx 8376 [('2', 1.0), ('List', 0.9941069972290792), ('list', 0.8679136136561881), ('UCache', 0.8056379468510803), ('pytz', 0.7845530679219666)]
Top words for pretrained_BERT neuron indx 4282 [('BlendProbes', 1.0), ('authorized', 0.9662541066312245), ('Distance', 0.9352837657301388), ('set', 0.9232625571372447), ('128', 0.9133458094371975)]
Top words for pretrained_BERT neuron indx 4284 [('id', 1.0), ('hpov', 0.998171457526764), ('None', 0.9653451842658959), ('tzs', 0.9305392245699254), ('other', 0.913182026603208)]
Top words for pretrained_BERT neuron indx 6334 [('sans', 1.0), ('authorized', 0.9857229192649156), ('open', 0.9589772507364158), ('required', 0.8779955022556649), ('upper', 0.8680088650667642)]
Top words for pretrained_BERT neuron indx 2239 [('List', 1.0), ('os', 0.9083383935602015), ('day', 0.8973553409261757), ('60', 0.8609331516853015), ('error', 0.8466331576237189)]
Top words for pretrained_BERT neuron indx 8384 [('minutes', 1.0), ('division', 0.9270646503032225), ('"oslo"', 0.8700651253270046), ('property', 0.8502978085321785), ('"r"', 0.8249070157977922)]
Top words for pretrained_BERT neuron indx 2241 [('close', 1.0), ('int', 0.9383598647060891), ('IsBM', 0.9115927621213236), ('material', 0.9076738349524754), ('Distance', 0.9071407828689116)]
Top words for pretrained_BERT neuron indx 2242 [('seconds', 1.0), ('time', 0.7987805432635432), ('minutes', 0.7856458251338537), ('Board', 0.7066670878789956), ('from', 0.689683752876508)]
Top words for pretrained_BERT neuron indx 6347 [('re', 1.0), ('Tab', 0.9870187005928658), ('openstack', 0.9723721238627855), ('while', 0.9693783234408014), ('minutes', 0.9474795352176862)]
Top words for pretrained_BERT neuron indx 6351 [('closing', 1.0), ('core', 0.9424276118134244), ('seek', 0.8529343694505906), ('log', 0.7909583639953389), ('write', 0.782061418530896)]
Top words for pretrained_BERT neuron indx 2262 [('count', 1.0), ('seek', 0.9033571072321542), ('close', 0.84169888740781), ('info', 0.7853456007556991), ('reactor', 0.7791274145537049)]
Top words for pretrained_BERT neuron indx 6362 [('component', 1.0), ('Plugin', 0.9559844469747142), ('filename', 0.8726088478065642), ('as', 0.8671470322352779), ('vCard', 0.8540840180928418)]
Top words for pretrained_BERT neuron indx 221 [('identity', 1.0), ('zone', 0.991183149116628), ('boot', 0.8911379203607833), ('seek', 0.8418243161640723), ('_hash', 0.8100116603893054)]
Top words for pretrained_BERT neuron indx 8419 [('mesh3', 1.0), ('Board', 0.9659962742555277), ('future', 0.9576853227594729), ('close', 0.9370919101068961), ('other', 0.9349882360604541)]
Top words for pretrained_BERT neuron indx 8421 [('month', 1.0), ('day', 0.8910486850519295), ('proxy', 0.8411995491891441), ('year', 0.8388416052911485), ('12', 0.6914451568272881)]
Top words for pretrained_BERT neuron indx 6378 [('Off', 1.0), ('append', 0.7815126990705865), ('class', 0.7748112609313637), ('shts', 0.7661200889699145), ('help', 0.7613120550849535)]
Top words for pretrained_BERT neuron indx 235 [('proxy', 1.0), ('future', 0.9284528746831692), ('calendar', 0.9066804893483315), ('m', 0.8250417520198565), ('Node', 0.8006806850743703)]
Top words for pretrained_BERT neuron indx 240 [('boot', 1.0), ('utc', 0.9564044999089493), ('query', 0.9508499718712862), ('sans', 0.9133576658796527), ('scope', 0.9054600081139216)]
Top words for pretrained_BERT neuron indx 8434 [('9', 1.0), ('7', 0.8683338398455634), ('mesh', 0.8665008068183664), ('Mesh', 0.8360070232384913), ('parent', 0.8142163828557394)]
Top words for pretrained_BERT neuron indx 8436 [('1000', 1.0), ('17', 0.9315254142056125), ('300', 0.7559386783773382), ('12', 0.72282884830309), ('force', 0.7007073873795475)]
Top words for pretrained_BERT neuron indx 6389 [('oslo', 1.0), ('14', 0.9563420588521032), ('continue', 0.9477912729713154), ('setup', 0.9291999518416687), ('7', 0.920284774874702)]
Top words for pretrained_BERT neuron indx 2295 [('Unauthorized', 1.0), ('zone', 0.8964246055973537), ('bind', 0.8269913399514421), ('E', 0.7483059744637542), ('pass', 0.7139983793262439)]
Top words for pretrained_BERT neuron indx 8439 [('oslo', 1.0), ('created', 0.9049817481547207), ('month', 0.6750908428740663), ('config', 0.6311605254505193), ('purpose', 0.6189609973858856)]
Top words for pretrained_BERT neuron indx 257 [('entity', 1.0), ('Node', 0.8311902352861604), ('True', 0.8237270611234773), ('dt', 0.7925183208140871), ('parent', 0.7593230655754474)]
Top words for pretrained_BERT neuron indx 2307 [('authentication', 1.0), ('board', 0.9204520890683596), ('host', 0.9137372762546807), ('part', 0.9065025574966187), ('delete', 0.9025468510081636)]
Top words for pretrained_BERT neuron indx 262 [('identity', 1.0), ('stanza', 0.9674037820562253), ('Distance', 0.908238027915585), ('ping', 0.8855093266157709), ('1', 0.8747146708353128)]
Top words for pretrained_BERT neuron indx 272 [('materials', 1.0), ('count', 0.8727751732031261), ('dt', 0.8241972336382497), ('False', 0.8233708838391668), ('unicode', 0.7273821445156622)]
Top words for pretrained_BERT neuron indx 279 [('logging', 1.0), ('target', 0.8712336551839593), ('zone', 0.8617453715728368), ('YoungestInFront', 0.6712899173650443), ('second', 0.6705585844808927)]
Top words for pretrained_BERT neuron indx 8476 [('20', 1.0), ('MAXSIGLINES', 0.8321266823936111), ('Mesh', 0.7543779423907694), ('baseline', 0.7356698095590579), ('60', 0.7246825058466686)]
Top words for pretrained_BERT neuron indx 8478 [('future', 1.0), ('boot', 0.739072752741817), ('action', 0.6998839710500069), ('os', 0.6860436296746129), ('blocking', 0.6609373241648163)]
Top words for pretrained_BERT neuron indx 286 [('add', 1.0), ('context', 0.9587305081353885), ('dt', 0.9489571046522692), ('error', 0.9055950097686262), ('super', 0.8708234414717716)]
Top words for pretrained_BERT neuron indx 307 [('close', 1.0), ('loads', 0.8641050089638863), ('profile', 0.7532140801689028), ('Profile', 0.7396754313178998), ('partition', 0.7337005644365212)]
Top words for pretrained_BERT neuron indx 6452 [('Billboard', 1.0), ('with', 0.8536827549684461), ('unicode', 0.7740554778965971), ('int', 0.7626957680790729), ('in', 0.735734602959138)]
Top words for pretrained_BERT neuron indx 6459 [('sorted', 1.0), ('long', 0.9165343266301255), ('wait', 0.8545958133161431), ('with', 0.821079811868423), ('presence', 0.6769395666923559)]
Top words for pretrained_BERT neuron indx 8523 [('BlendProbes', 1.0), ('common', 0.9755938890606346), ('exceptions', 0.8565810457188022), ('microseconds', 0.8341230664330144), ('"oslo"', 0.820518328880944)]
Top words for pretrained_BERT neuron indx 333 [('parent', 1.0), ('enclosure', 0.9473998067638004), ('24', 0.9432696062100182), ('Unauthorized', 0.9365271062723761), ('horizon', 0.8737237269370443)]
Top words for pretrained_BERT neuron indx 8533 [('17', 1.0), ('E', 0.8699426392126077), ('is', 0.8421651502367337), ('6', 0.8008883718610159), ('seconds', 0.6854530669259471)]
Top words for pretrained_BERT neuron indx 6489 [('IDLEN', 1.0), ('Stretch', 0.9972330788033485), ('IPLEN', 0.9938042354366307), ('GetBoard', 0.9111651993337515), ('type', 0.9057711825910143)]
Top words for pretrained_BERT neuron indx 8539 [('META', 1.0), ('ms', 0.8153894447911147), ('created', 0.7174678895001263), ('probe', 0.7013584764861373), ('alt', 0.6393343387803162)]
Top words for pretrained_BERT neuron indx 6500 [('name', 1.0), ('affinity', 0.9009060665677089), ('minutes', 0.880473854705796), ('seconds', 0.8598874314753402), ('join', 0.8037478885262639)]
Top words for pretrained_BERT neuron indx 6504 [('put', 1.0), ('upper', 0.898403660348333), ('80', 0.827630288922036), ('count', 0.7453073334393089), ('division', 0.7197109812633552)]
Top words for pretrained_BERT neuron indx 2409 [('year', 1.0), ('second', 0.9590320966292062), ('replace', 0.9184589358253306), ('day', 0.844429452331836), ('sht', 0.8211881696828112)]
Top words for pretrained_BERT neuron indx 2418 [('5', 1.0), ('3', 0.9111698699826257), ('context', 0.8797958246056422), ('contextlib', 0.7274997527682445), ('2', 0.7132350443919925)]
Top words for pretrained_BERT neuron indx 380 [('slug', 1.0), ('try', 0.8542994699747746), ('read', 0.8453653924585214), ('unicode', 0.839462117822173), ('alt', 0.8034148008468631)]
Top words for pretrained_BERT neuron indx 8572 [('with', 1.0), ('for', 0.9931826809114327), ('unicode', 0.9395002992130791), ('"happy_birthday"', 0.9122954079444691), ('"Name"', 0.8880958029309038)]
Top words for pretrained_BERT neuron indx 385 [('proxy', 1.0), ('filters', 0.7906254938419407), ('seek', 0.5915492930005309), ('0', 0.564519586386292), ('put', 0.5267507992536274)]
Top words for pretrained_BERT neuron indx 6530 [('Off', 1.0), ('as', 0.9575248953037425), ('Simple', 0.8304168880604166), ('required', 0.8105824615500757), ('Mesh', 0.8084636289992422)]
Top words for pretrained_BERT neuron indx 389 [('format', 1.0), ('Library', 0.9971034328569384), ('f', 0.9829714274400031), ('stanza', 0.9692373184437737), ('root', 0.9388176915820116)]
Top words for pretrained_BERT neuron indx 4489 [('k', 1.0), ('microseconds', 0.8934360511213345), ('3700', 0.88522431508093), ('kls', 0.8542341936118539), ('1024', 0.8452069833194024)]
Top words for pretrained_BERT neuron indx 6540 [('sts', 1.0), ('store', 0.9799543304011731), ('stanza', 0.9287982621961404), ('long', 0.8953255866005517), ('os', 0.8656048587035381)]
Top words for pretrained_BERT neuron indx 6541 [('end', 1.0), ('1', 0.9276364856245092), ('second', 0.8799657937591195), ('hour', 0.8628982342623829), ('context', 0.8364831833427157)]
Top words for pretrained_BERT neuron indx 6551 [('requests', 1.0), ('GET', 0.9218043557760957), ('store', 0.9125073060187993), ('1', 0.8956635843173832), ('1800', 0.8689233241060149)]
Top words for pretrained_BERT neuron indx 410 [('super', 1.0), ('probe', 0.9645683220062816), ('render', 0.9559130185092042), ('title', 0.908857051795176), ('stanza', 0.9057225831657111)]
Top words for pretrained_BERT neuron indx 8604 [('resource', 1.0), ('minute', 0.839002398770016), ('RequestContext', 0.7143240290291651), ('attr', 0.7105502032958375), ('dest', 0.6969686907171818)]
Top words for pretrained_BERT neuron indx 415 [('tag', 1.0), ('import', 0.991644810614632), ('patch', 0.9461401922154027), ('stanza', 0.8820258093553408), ('action', 0.8565586818248049)]
Top words for pretrained_BERT neuron indx 6563 [('except', 1.0), ('if', 0.9242341864879582), ('get_profile_networks', 0.8361322742619024), ('get_profile_compliance_preview', 0.8249881775975781), ('get_task_associated_resource', 0.7945458821444868)]
Top words for pretrained_BERT neuron indx 422 [('logging', 1.0), ('def', 0.9314606772699404), ('models', 0.88776788301845), ('value', 0.8761648574011124), ('contents', 0.8192493352005473)]
Top words for pretrained_BERT neuron indx 4521 [('80', 1.0), ('800', 0.9643782594189644), ('sans', 0.9449135750754369), ('setup', 0.8637939820929956), ('script', 0.8394409612990209)]
Top words for pretrained_BERT neuron indx 429 [('Exception', 1.0), ('item', 0.8957320900414909), ('resource', 0.8795800045408636), ('settings', 0.8259064287536493), ('modes', 0.8149288459623826)]
Top words for pretrained_BERT neuron indx 6575 [('bare', 1.0), ('affinity', 0.9200353452711587), ('objects', 0.8739425908544228), ('created', 0.8419659294387224), ('On', 0.8195873489528593)]
Top words for pretrained_BERT neuron indx 8625 [('minutes', 1.0), ('sans', 0.979846028135596), ('servers', 0.9635980709321624), ('ranges', 0.8998326516265429), ('VerticalBillboard', 0.8804626196200046)]
Top words for pretrained_BERT neuron indx 4539 [('milliseconds', 1.0), ('microseconds', 0.8974799653463564), ('e', 0.8241807018728093), ('Tab', 0.8226993875159633), ('600', 0.6407332142524444)]
Top words for pretrained_BERT neuron indx 444 [('Tab', 1.0), ('bare', 0.9987414138375286), ('default', 0.9221222625498069), ('division', 0.8950740404405905), ('objects', 0.8710030616436114)]
Top words for pretrained_BERT neuron indx 6595 [('template', 1.0), ('seek', 0.9205289996235168), ('None', 0.8384874009419859), ('part', 0.8127227104749682), ('parts', 0.7514701180896397)]
Top words for pretrained_BERT neuron indx 451 [('Component', 1.0), ('len', 0.9765113610786967), ('render', 0.9605461322528669), ('component', 0.9229139733750865), ('dt', 0.9157709471299161)]
Top words for pretrained_BERT neuron indx 6599 [('error', 1.0), ('Mesh', 0.9764779053234598), ('group', 0.9418715781885544), ('main', 0.902977985471582), ('range', 0.8894377883787165)]
Top words for pretrained_BERT neuron indx 4566 [('17', 1.0), ('except', 0.9093480054673154), ('count', 0.8991599022003924), ('value', 0.8296365953574132), ('20', 0.7868046314953234)]
Top words for pretrained_BERT neuron indx 472 [('Simple', 1.0), ('recv', 0.9933390189138046), ('us', 0.9791176979971896), ('common', 0.9468378505627719), ('baseline', 0.8549087032619336)]
Top words for pretrained_BERT neuron indx 6616 [('Unauthorized', 1.0), ('seconds', 0.8186926039862052), ('except', 0.7854672464607998), ('millis', 0.7185453404291641), ('iq', 0.7089992255618183)]
Top words for pretrained_BERT neuron indx 6618 [('wait', 1.0), ('META', 0.9714211047786242), ('32', 0.9480478831724056), ('60', 0.9351206783183564), ('purpose', 0.9255331004834836)]
Top words for pretrained_BERT neuron indx 8669 [('month', 1.0), ('from', 0.92299499160705), ('BoardManager', 0.910585555834001), ('seek', 0.9028779203813875), ('PYTHON_VERSION', 0.8918862228020396)]
Top words for pretrained_BERT neuron indx 478 [('purpose', 1.0), ('raise', 0.8982681710143421), ('reactor', 0.8372048309407297), ('open', 0.7910493848289475), ('sts', 0.7472284073445703)]
Top words for pretrained_BERT neuron indx 6624 [('logging', 1.0), ('end', 0.9254269053423664), ('META', 0.8600184201656792), ('max', 0.8407260367666618), ('log', 0.8297759414281026)]
Top words for pretrained_BERT neuron indx 6626 [('clone', 1.0), ('verbatim', 0.9752315903676616), ('mins', 0.9357142315220854), ('type', 0.9302684121613077), ('format', 0.9187768281497891)]
Top words for pretrained_BERT neuron indx 8682 [('minutes', 1.0), ('ms', 0.9366265299703569), ('to', 0.745907226831704), ('shts', 0.74010993266518), ('minute', 0.7159592685260484)]
Top words for pretrained_BERT neuron indx 2539 [('calendar', 1.0), ('Node', 0.9478985397977282), ('resource', 0.890941872946992), ('os', 0.8867828179427777), ('upper', 0.8587210490031719)]
Top words for pretrained_BERT neuron indx 2538 [('push', 1.0), ('register', 0.9560247567732035), ('description', 0.9528474654222379), ('seek', 0.9158770005336091), ('pass', 0.9130151191145482)]
Top words for pretrained_BERT neuron indx 499 [('except', 1.0), ('slug', 0.7668681517812282), ('NoPerm', 0.7549942615384129), ('setup', 0.7129584588106266), ('prange', 0.7045695525522567)]
Top words for pretrained_BERT neuron indx 503 [('def', 1.0), ('sorted', 0.8672712267306255), ('defval', 0.8323569867500948), ('View', 0.7218718356746354), ('try', 0.6995573900153216)]
Top words for pretrained_BERT neuron indx 8697 [('ignore', 1.0), ('all', 0.7962457960475434), ('presence', 0.7741586025638693), ('pxe', 0.6947308138187915), ('acceptEULA', 0.6582802193983144)]
Top words for pretrained_BERT neuron indx 8709 [('80', 1.0), ('Mesh', 0.8850836912693851), ('baynum', 0.8653718494785347), ('"purpose"', 0.8605148389811722), ('long', 0.8514676874244913)]
Top words for pretrained_BERT neuron indx 517 [('horizon', 1.0), ('baseline', 0.6696247008282108), ('sts', 0.601703008505949), ('scope', 0.6000430732045388), ('1', 0.5786113041219544)]
Top words for pretrained_BERT neuron indx 6664 [('pop', 1.0), ('count', 0.7813805304758539), ('con', 0.690862627645714), ('log', 0.6668944392653546), ('On', 0.6631908096259219)]
Top words for pretrained_BERT neuron indx 8713 [('in', 1.0), ('utcnow', 0.9860230697306082), ('1800', 0.9798658492970987), ('milliseconds', 0.9206556861577873), ('timezone', 0.8665472534790692)]
Top words for pretrained_BERT neuron indx 6669 [('division', 1.0), ('calendar', 0.9641817413123697), ('unicode', 0.9161271029905759), ('builtins', 0.8153545842409643), ('repr', 0.798532481027814)]
Top words for pretrained_BERT neuron indx 6670 [('META', 1.0), ('re', 0.8050995349487995), ('not', 0.7701689947449443), ('modes', 0.7649202304533911), ('9', 0.7425994229333175)]
Top words for pretrained_BERT neuron indx 4622 [('force', 1.0), ('8', 0.8209479015062471), ('oslo', 0.7749492689509883), ('key', 0.7666961867099275), ('Off', 0.7161757102028182)]
Top words for pretrained_BERT neuron indx 2576 [('uri', 1.0), ('tzinfo', 0.9530361762137366), ('state', 0.9109730420135762), ('setup', 0.9081567866969295), ('match', 0.8948825543114836)]
Top words for pretrained_BERT neuron indx 4627 [('close', 1.0), ('post', 0.7228336220424164), ('__version__', 0.7037550883126714), ('__title__', 0.6935073574114354), ('24', 0.6816909849835643)]
Top words for pretrained_BERT neuron indx 535 [('server', 1.0), ('find', 0.9503459372653571), ('exceptions', 0.947014103528969), ('Exception', 0.9421920583133828), ('seek', 0.9371943321882585)]
Top words for pretrained_BERT neuron indx 6679 [('3600', 1.0), ('decode', 0.989624811686905), ('3700', 0.9627772527192353), ('800', 0.9620720656493494), ('128', 0.9480269824082684)]
Top words for pretrained_BERT neuron indx 538 [('minutes', 1.0), ('def', 0.8457911493218765), ('target', 0.7884895619561261), ('entity', 0.6974890279776486), ('port', 0.6843029110146801)]
Top words for pretrained_BERT neuron indx 8733 [('log', 1.0), ('400', 0.8348864798973814), ('5', 0.7989731176659037), ('7', 0.7683306032556336), ('zone', 0.7314758315841444)]
Top words for pretrained_BERT neuron indx 8751 [('route', 1.0), ('group', 0.9269560696260313), ('arg', 0.8960279271528883), ('time', 0.8801109040640663), ('delete', 0.8777090826736084)]
Top words for pretrained_BERT neuron indx 560 [('patch', 1.0), ('choices', 0.9732368238092586), ('port', 0.9167978148164194), ('render', 0.9104417198418052), ('stat', 0.9055316218720996)]
Top words for pretrained_BERT neuron indx 8753 [('8', 1.0), ('logging', 0.9173875597412603), ('__copyright__', 0.913649261858548), ('created', 0.9103802358654548), ('Digest', 0.9092904948071926)]
Top words for pretrained_BERT neuron indx 6719 [('else', 1.0), ('error', 0.9150186810278094), ('17', 0.885480332383207), ('put', 0.8218879797805873), ('False', 0.7883392391701278)]
Top words for pretrained_BERT neuron indx 6720 [('def', 1.0), ('count', 0.9988535642157524), ('slug', 0.9937850671453808), ('future', 0.9287445446142383), ('partition', 0.8884175163024898)]
Top words for pretrained_BERT neuron indx 8767 [('is', 1.0), ('HorizontalBillboard', 0.9152099199516346), ('VerticalBillboard', 0.9077479847556048), ('for', 0.8820919875687178), ('future', 0.8442379268891774)]
Top words for pretrained_BERT neuron indx 2628 [('iq', 1.0), ('required', 0.9363696757443274), ('minutes', 0.9005199912171362), ('affinity', 0.8549936666148594), ('division', 0.8090900106300365)]
Top words for pretrained_BERT neuron indx 4679 [('link', 1.0), ('Unauthorized', 0.9579084415265894), ('find', 0.9321592334695217), ('uss', 0.9312568824202916), ('objects', 0.9307203097707283)]
Top words for pretrained_BERT neuron indx 583 [('horizon', 1.0), ('Exception', 0.974558538581688), ('count', 0.9311320637802605), ('action', 0.8537849045614408), ('enclosure', 0.795919299709174)]
Top words for pretrained_BERT neuron indx 2631 [('log', 1.0), ('affinity', 0.832342076567559), ('super', 0.7628043648863886), ('None', 0.7438410880006477), ('line', 0.7172125413197961)]
Top words for pretrained_BERT neuron indx 4685 [('UserInfo', 1.0), ('to', 0.8724643149945643), ('IDLEN', 0.8225609666496339), ('On', 0.8092305380414094), ('postinfo', 0.7647580460099955)]
Top words for pretrained_BERT neuron indx 8787 [('to', 1.0), ('86400', 0.773092212200443), ('action', 0.7600212634012818), ('mesh1', 0.7585528097112595), ('epoch_milliseconds', 0.7354558305897869)]
Top words for pretrained_BERT neuron indx 4692 [('is', 1.0), ('E', 0.9473978618742539), ('with', 0.9432346934324138), ('secs', 0.9244554051025792), ('f', 0.9145571366766284)]
Top words for pretrained_BERT neuron indx 8793 [('7', 1.0), ('secs', 0.8350161965365648), ('8', 0.8179571841820937), ('i', 0.7868062730248352), ('all', 0.7846159608528552)]
Top words for pretrained_BERT neuron indx 604 [('material', 1.0), ('setup', 0.9782838864723102), ('enclosure', 0.9758360062361268), ('seconds', 0.9398226363663833), ('parent', 0.8379518955498847)]
Top words for pretrained_BERT neuron indx 2654 [('unicode', 1.0), ('all', 0.8111786304666839), ('digest', 0.8090130251435138), ('calendar', 0.7583492767909225), ('Digest', 0.7463173803835087)]
Top words for pretrained_BERT neuron indx 614 [('affinity', 1.0), ('bind', 0.9765769210789521), ('unicode', 0.968291699741611), ('clone', 0.9223460295035661), ('Billboard', 0.8972624270848599)]
Top words for pretrained_BERT neuron indx 4713 [('1800', 1.0), ('17', 0.9937264244590034), ('300', 0.991545717508974), ('to', 0.92360383262477), ('strip', 0.8959764018452798)]
Top words for pretrained_BERT neuron indx 8812 [('created', 1.0), ('nargs', 0.9538069663429948), ('boot', 0.9365865632761308), ('6', 0.9238251864551607), ('8', 0.8987059946927045)]
Top words for pretrained_BERT neuron indx 6765 [('types', 1.0), ('core', 0.9816651036164445), ('sanetime', 0.9150738032491021), ('slug', 0.897950471365766), ('wait', 0.8804460776118984)]
Top words for pretrained_BERT neuron indx 6767 [('all', 1.0), ('import', 0.9687676514108736), ('8', 0.9124995523749798), ('else', 0.8522053886579852), ('core', 0.8249120274693935)]
Top words for pretrained_BERT neuron indx 624 [('info', 1.0), ('division', 0.8518671393129603), ('route', 0.7233564742039141), ('day', 0.7000484883134449), ('required', 0.6760066943835624)]
Top words for pretrained_BERT neuron indx 8815 [('".."', 1.0), ('with', 0.8780503362650398), ('"oslo"', 0.8595230948538113), ('"purpose"', 0.8243639246969662), ('horizon', 0.8088652919352229)]
Top words for pretrained_BERT neuron indx 627 [('operand', 1.0), ('filter', 0.9931958270038126), ('closing', 0.9142029782121136), ('traceback', 0.8439122389541283), ('project', 0.8222172241806855)]
Top words for pretrained_BERT neuron indx 4727 [('or', 1.0), ('all', 0.7902456849857097), ('utc', 0.7850335366937675), ('broadcast', 0.7814256105848616), ('None', 0.7660423836677844)]
Top words for pretrained_BERT neuron indx 4731 [('30', 1.0), ('loads', 0.94773919568242), ('mins', 0.9368557374060387), ('long', 0.9107380703421316), ('1', 0.8974085867172733)]
Top words for pretrained_BERT neuron indx 636 [('Stretch', 1.0), ('True', 0.9643896717386262), ('modes', 0.9418147660542869), ('boardname', 0.9299821485031622), ('push', 0.9249221266832806)]
Top words for pretrained_BERT neuron indx 635 [('def', 1.0), ('ignore', 0.9721466044925651), ('path', 0.8938135609890956), ('settings', 0.8850501887824279), ('localize', 0.8464740548318054)]
Top words for pretrained_BERT neuron indx 4734 [('seconds', 1.0), ('requests', 0.9910284979839299), ('9', 0.9166760044120338), ('project', 0.8066139352301384), ('direct', 0.799947786723451)]
Top words for pretrained_BERT neuron indx 2689 [('seek', 1.0), ('proxy', 0.7671833926825871), ('put', 0.754600185271734), ('filters', 0.7387781199960056), ('0', 0.6961565287839245)]
Top words for pretrained_BERT neuron indx 4738 [('close', 1.0), ('List', 0.9055184035102812), ('feature', 0.8466550716164953), ('main', 0.8343821225272041), ('state', 0.8322557854250374)]
Top words for pretrained_BERT neuron indx 8838 [('"r"', 1.0), ('config', 0.9689632202163585), ('"Name"', 0.9479112903460966), ('0', 0.913275743445353), ('4', 0.847768791188758)]
Top words for pretrained_BERT neuron indx 8842 [('seconds', 1.0), ('400', 0.9788840470069865), ('list', 0.8843497418665454), ('from', 0.8487947942560449), ('created', 0.8321490111169044)]
Top words for pretrained_BERT neuron indx 8844 [('os', 1.0), ('store', 0.9488149729734877), ('render', 0.9164612992575609), ('stanza', 0.912979325495941), ('False', 0.9070056474279529)]
Top words for pretrained_BERT neuron indx 8845 [('end', 1.0), ('hour', 0.7757265271487149), ('long', 0.7001465641741705), ('task', 0.6940630458703907), ('6', 0.6463401580162473)]
Top words for pretrained_BERT neuron indx 4750 [('sorted', 1.0), ('f', 0.8503195477987364), ('super', 0.8091866336200592), ('scope', 0.7837284702021112), ('timetuple', 0.7788094376331078)]
Top words for pretrained_BERT neuron indx 6799 [('ignore', 1.0), ('6', 0.9795624124217267), ('broadcast', 0.9400785039851702), ('render', 0.9044701456810418), ('v', 0.8594521750120983)]
Top words for pretrained_BERT neuron indx 8848 [('m', 1.0), ('s', 0.9368849093636661), ('f', 0.9311602834181808), ('models', 0.9124615610914297), ('i', 0.8286391250821052)]
Top words for pretrained_BERT neuron indx 657 [('host', 1.0), ('e', 0.9119356941233079), ('affinity', 0.9089027711434996), ('method', 0.8935108562467176), ('E', 0.8844565963680857)]
Top words for pretrained_BERT neuron indx 2705 [('component', 1.0), ('log', 0.8888232187215616), ('text', 0.7263079045654081), ('BlendProbes', 0.6995747774921172), ('feature', 0.683366063130232)]
Top words for pretrained_BERT neuron indx 6797 [('pdb', 1.0), ('9', 0.9928044087523453), ('blocking', 0.8480204026351259), ('continue', 0.7525476803383704), ('if', 0.7336042297464841)]
Top words for pretrained_BERT neuron indx 8852 [('with', 1.0), ('nsanetime', 0.8481446578378066), ('YoungestInFront', 0.8330770896222165), ('NetworkProfileTab', 0.8138273204605575), ('sorted', 0.8063739499816405)]
Top words for pretrained_BERT neuron indx 656 [('Register', 1.0), ('None', 0.8312834809659865), ('Profile', 0.7798912333779864), ('close', 0.7644603998820337), ('save', 0.7625004218319685)]
Top words for pretrained_BERT neuron indx 4751 [('patch', 1.0), ('long', 0.9776778507466204), ('Unauthorized', 0.9507259442077591), ('materials', 0.93500617380065), ('authentication', 0.9176273197572176)]
Top words for pretrained_BERT neuron indx 8855 [('list', 1.0), ('requests', 0.9882856972758364), ('META', 0.9429475148501176), ('1', 0.9037745045752488), ('store', 0.8665086252954627)]
Top words for pretrained_BERT neuron indx 8867 [('if', 1.0), ('except', 0.8530577412489061), ('Tab', 0.7867558122469417), ('post', 0.7491751667155039), ('oslo', 0.7104660656406204)]
Top words for pretrained_BERT neuron indx 6821 [('META', 1.0), ('5', 0.9556431375345055), ('if', 0.9032977140915407), ('Mesh', 0.7746402456912173), ('description', 0.7738393797876914)]
Top words for pretrained_BERT neuron indx 2726 [('required', 1.0), ('reactor', 0.9476664796785937), ('count', 0.9255406355385011), ('12', 0.8876683301097632), ('14', 0.8838634126229669)]
Top words for pretrained_BERT neuron indx 680 [('1800', 1.0), ('sans', 0.7817457606391021), ('probe', 0.7120688205022887), ('calendar', 0.7044285280105099), ('routes', 0.7035737800759455)]
Top words for pretrained_BERT neuron indx 6840 [('List', 1.0), ('oslo', 0.8305827128785183), ('2', 0.8142127294146857), ('GET', 0.7362616364993086), ('tag', 0.7294724753615587)]
Top words for pretrained_BERT neuron indx 2745 [('9', 1.0), ('body', 0.9267695649081171), ('6', 0.8956778138688269), ('root', 0.8548457392189287), ('600', 0.8347997076319661)]
Top words for pretrained_BERT neuron indx 2748 [('hpov', 1.0), ('required', 0.9833782725535491), ('hour', 0.96545540430221), ('break', 0.9551248643641549), ('id', 0.9141439024421621)]
Top words for pretrained_BERT neuron indx 2754 [('ref', 1.0), ('text', 0.9513266015256924), ('sans', 0.8899453903565985), ('help', 0.7876154309311374), ('pop', 0.7875449432502734)]
Top words for pretrained_BERT neuron indx 4803 [('match', 1.0), ('VerticalBillboard', 0.9248391279489577), ('False', 0.8531966474589694), ('component', 0.8470692202692094), ('post', 0.8441824125764693)]
Top words for pretrained_BERT neuron indx 8901 [('32', 1.0), ('META', 0.9328557650466842), ('20', 0.8615584604480379), ('800', 0.8594602637656475), ('NotFound', 0.8575603120057473)]
Top words for pretrained_BERT neuron indx 710 [('Register', 1.0), ('item', 0.8878140544294261), ('reactor', 0.8726924084233371), ('80', 0.8169706775446915), ('id', 0.8096654375165425)]
Top words for pretrained_BERT neuron indx 8903 [('Mesh', 1.0), ('group', 0.9795532932538739), ('main', 0.9269180157107983), ('else', 0.9055493359804369), ('mesh', 0.8744706082922891)]
Top words for pretrained_BERT neuron indx 6856 [('enum', 1.0), ('14', 0.9682947189422774), ('0', 0.9255479063226941), ('9', 0.8703163646062716), ('40', 0.8669104815518461)]
Top words for pretrained_BERT neuron indx 712 [('Mesh', 1.0), ('mesh', 1.0), ('objects', 0.9871409945670564), ('query', 0.9862106293828333), ('start', 0.9125227856747691)]
Top words for pretrained_BERT neuron indx 4811 [('7', 1.0), ('Tab', 0.9707123288594215), ('minutes', 0.9330491646107387), ('fcsans', 0.8693883423313931), ('presence', 0.8637135552325169)]
Top words for pretrained_BERT neuron indx 6870 [('while', 1.0), ('blocking', 0.7884803254480099), ('except', 0.7744432409277181), ('7', 0.7636382324935104), ('wait', 0.7484732486363579)]
Top words for pretrained_BERT neuron indx 726 [('count', 1.0), ('close', 0.9975396837972607), ('def', 0.8005438775325308), ('info', 0.748460195824752), ('Node', 0.736778999979279)]
Top words for pretrained_BERT neuron indx 8924 [('minutes', 1.0), ('80', 0.8545078415677299), ('v', 0.8259540211310659), ('secs', 0.8096205841170199), ('millis', 0.8087197751802205)]
Top words for pretrained_BERT neuron indx 6892 [('delete', 1.0), ('logging', 0.9467272952267207), ('key', 0.8711058800289638), ('post', 0.8237511505561235), ('bool', 0.8181287619518043)]
Top words for pretrained_BERT neuron indx 753 [('modes', 1.0), ('Tab', 0.9754762228731397), ('log', 0.9073156498387088), ('def', 0.8513866969940321), ('17', 0.8342539563867826)]
Top words for pretrained_BERT neuron indx 8955 [('features', 1.0), ('day', 0.9436946398322021), ('utcfromtimestamp', 0.926471496640333), ('activity', 0.8872571827389748), ('month', 0.8545988021893262)]
Top words for pretrained_BERT neuron indx 8964 [('utcnow', 1.0), ('GetUID', 0.8662203605210613), ('utc', 0.8630524167055249), ('seek', 0.7729265572321194), ('int', 0.766258284133103)]
Top words for pretrained_BERT neuron indx 4874 [('set', 1.0), ('Simple', 0.9012036653861348), ('Digest', 0.8323221284373511), ('digest', 0.8082149248554427), ('group', 0.8024755689997195)]
Top words for pretrained_BERT neuron indx 4875 [('common', 1.0), ('7', 0.9263228891666124), ('domain', 0.9117833743954663), ('minutes', 0.8825770242036065), ('timegm', 0.8404615767185082)]
Top words for pretrained_BERT neuron indx 782 [('zone', 1.0), ('key', 0.9798244312034667), ('len', 0.9148567178746537), ('connection', 0.9130335874548199), ('strip', 0.8952104368790763)]
Top words for pretrained_BERT neuron indx 2830 [('domain', 1.0), ('not', 0.933364425895933), ('main', 0.9248952074378123), ('post', 0.9242960082378369), ('division', 0.8508136341555101)]
Top words for pretrained_BERT neuron indx 8976 [('400', 1.0), ('128', 0.9200521381165105), ('0', 0.8790703674376202), ('project', 0.8554410614773684), ('__copyright__', 0.8323119276295735)]
Top words for pretrained_BERT neuron indx 6928 [('NAMELEN', 1.0), ('domain', 0.9124275208924477), ('i', 0.8711852179328188), ('if', 0.8222972869399013), ('error', 0.8189535498285221)]
Top words for pretrained_BERT neuron indx 6930 [('log', 1.0), ('second', 0.8900666899870354), ('Simple', 0.8899310795569303), ('port', 0.8432683702206888), ('range', 0.8148524921834079)]
Top words for pretrained_BERT neuron indx 788 [('v', 1.0), ('format', 0.9523724179762348), ('REQUEST', 0.9377332066169014), ('st', 0.8866249383870219), ('created', 0.831508122928343)]
Top words for pretrained_BERT neuron indx 6942 [('future', 1.0), ('os', 0.9209322721591803), ('action', 0.9202841015987135), ('boot', 0.9035989593516423), ('second', 0.8932006931854265)]
Top words for pretrained_BERT neuron indx 2847 [('port', 1.0), ('description', 0.9600916493864), ('register', 0.8987719937377207), ('direct', 0.885966474992561), ('minute', 0.868157739059946)]
Top words for pretrained_BERT neuron indx 4897 [('text', 1.0), ('4', 0.8614786073198094), ('loads', 0.7926905476103472), ('bare', 0.726287326162415), ('boardname', 0.7259143040953501)]
Top words for pretrained_BERT neuron indx 4902 [('contents', 1.0), ('pop', 0.976290652932286), ('800', 0.9547527998320126), ('Simple', 0.9077857568548533), ('continue', 0.8948388134413863)]
Top words for pretrained_BERT neuron indx 6952 [('closing', 1.0), ('presence', 0.990094917004827), ('to', 0.9406498013714342), ('24', 0.9391386201559399), ('name', 0.9317386274652389)]
Top words for pretrained_BERT neuron indx 2864 [('pop', 1.0), ('authorization', 0.9241575712548606), ('body', 0.9133711763666288), ('direct', 0.896594623264606), ('year', 0.8832112833257667)]
Top words for pretrained_BERT neuron indx 9009 [('component', 1.0), ('all', 0.9994771012607875), ('and', 0.9845048869932629), ('hour', 0.9425010518112421), ('mesh', 0.9424235897564975)]
Top words for pretrained_BERT neuron indx 818 [('GET', 1.0), ('get', 0.9680111235886103), ('direct', 0.9093243760120865), ('ms', 0.8806390381591575), ('boot', 0.8804484023910698)]
Top words for pretrained_BERT neuron indx 4916 [('with', 1.0), ('is', 0.9005772618316399), ('and', 0.833678304920813), ('as', 0.8139470003487391), ('in', 0.8012346571608824)]
Top words for pretrained_BERT neuron indx 9013 [('day', 1.0), ('v', 0.9808368400971567), ('absolute_import', 0.9245034254815165), ('pop', 0.8856172129612659), ('hour', 0.8818059739071179)]
Top words for pretrained_BERT neuron indx 9023 [('else', 1.0), ('while', 0.9595319061418608), ('or', 0.8851943735875537), ('17', 0.8008555120188304), ('put', 0.7913602837377139)]
Top words for pretrained_BERT neuron indx 2887 [('Exception', 1.0), ('Distance', 0.5967145698895314), ('message', 0.5883586283141307), ('View', 0.5702590015637974), ('break', 0.5655576068955879)]
Top words for pretrained_BERT neuron indx 9033 [('bare', 1.0), ('5', 0.9704223920872895), ('put', 0.9375826174971035), ('oslo', 0.9139816999061353), ('hasattr', 0.8559900569704535)]
Top words for pretrained_BERT neuron indx 4939 [('On', 1.0), ('List', 0.745785289393707), ('verbatim', 0.7234964909597488), ('required', 0.7107645699975222), ('Mesh', 0.6765182039818173)]
Top words for pretrained_BERT neuron indx 9041 [('objects', 1.0), ('Mesh', 0.9055236165678089), ('purpose', 0.8368460382050311), ('Log', 0.8244639471094921), ('Distance', 0.8002391660496487)]
Top words for pretrained_BERT neuron indx 6997 [('in', 1.0), ('seconds', 0.7466158521801465), ('minutes', 0.6809209149934168), ('objects', 0.6485318813836071), ('E', 0.625106045412419)]
Top words for pretrained_BERT neuron indx 7003 [('META', 1.0), ('ms', 0.6614624290733845), ('probe', 0.6227037220424265), ('raise', 0.6103411427227927), ('Tab', 0.5965217381882875)]
Top words for pretrained_BERT neuron indx 7006 [('24', 1.0), ('day', 0.95956306191866), ('Unauthorized', 0.8690440139287114), ('minutes', 0.8453267085365351), ('enabled', 0.8247981303327093)]
Top words for pretrained_BERT neuron indx 4958 [('all', 1.0), ('timezone', 0.8437295232183392), ('unicode', 0.7359431056887015), ('horizon', 0.7163269449122022), ('astimezone', 0.6801303095850509)]
Top words for pretrained_BERT neuron indx 7008 [('oslo', 1.0), ('core', 0.8492893050913939), ('shortcuts', 0.8417412111732709), ('or', 0.7947988321350286), ('models', 0.7936453560807356)]
Top words for pretrained_BERT neuron indx 4961 [('is', 1.0), ('project', 0.9818574353813097), ('GetAttachListByType', 0.9476373406057024), ('second', 0.9096812996204595), ('EffectiveId', 0.8995555271948146)]
Top words for pretrained_BERT neuron indx 4963 [('sans', 1.0), ('other', 0.9276701075082324), ('6', 0.9050366021909125), ('default', 0.8737782093914215), ('else', 0.8122440334123056)]
Top words for pretrained_BERT neuron indx 868 [('Tab', 1.0), ('boot', 0.9453485773115015), ('unicode', 0.9205254880362977), ('baseline', 0.9120301614649312), ('items', 0.8415121171604559)]
Top words for pretrained_BERT neuron indx 2920 [('local', 1.0), ('future', 0.9773791782238856), ('None', 0.9428286234889465), ('8', 0.9158680530517251), ('wwnType', 0.8947905054195082)]
Top words for pretrained_BERT neuron indx 9071 [('core', 1.0), ('to', 0.726696336783791), ('__future__', 0.6828805873240759), ('8', 0.6820860352404473), ('constants', 0.6584317146670384)]
Top words for pretrained_BERT neuron indx 7031 [('minutes', 1.0), ('12', 0.8475211797269562), ('seconds', 0.8370510082386123), ('or', 0.7719384939699542), ('None', 0.7551302424542258)]
Top words for pretrained_BERT neuron indx 7033 [('""', 1.0), ('models', 0.8488741658279111), ('is', 0.8251256684623381), ('and', 0.7753606303020851), ('from_', 0.7699843154345074)]
Top words for pretrained_BERT neuron indx 7034 [('to', 1.0), ('other', 0.9525389808343826), ('"purpose"', 0.9104380812841354), ('7', 0.8836474919866276), ('closing', 0.824697947737142)]
Top words for pretrained_BERT neuron indx 7035 [('mins', 1.0), ('minutes', 0.8428794229557027), ('seconds', 0.7527847214627017), ('millis', 0.7146744030279286), ('secs', 0.7124283470935829)]
Top words for pretrained_BERT neuron indx 2938 [('80', 1.0), ('300', 0.997570080161146), ('86400', 0.9556128207958078), ('800', 0.9086401870977477), ('14', 0.8921006153958081)]
Top words for pretrained_BERT neuron indx 4993 [('encode', 1.0), ('seek', 0.9996109112639433), ('except', 0.9043053716409097), ('filter', 0.8905077489070118), ('end', 0.8657535811864451)]
Top words for pretrained_BERT neuron indx 898 [('close', 1.0), ('format', 0.8670095334826842), ('link', 0.7727183933091806), ('find', 0.7137869080342725), ('partition', 0.6558515801681657)]
Top words for pretrained_BERT neuron indx 899 [('print', 1.0), ('dumps', 0.976247686032418), ('not', 0.9125133253520239), ('utc', 0.8821372966382565), ('required', 0.843546675153894)]
Top words for pretrained_BERT neuron indx 7044 [('all', 1.0), ('stanza', 0.8810166622424757), ('return', 0.8698772640999266), ('fcsans', 0.8017587595693082), ('baseline', 0.7976012584932987)]
Top words for pretrained_BERT neuron indx 7052 [('key', 1.0), ('80', 0.9389001318339918), ('minutes', 0.9212379999933596), ('5', 0.9193012349920371), ('\\\'"\\\'', 0.9172104753298951)]
Top words for pretrained_BERT neuron indx 7059 [('E', 1.0), ('calendar', 0.9646660967352007), ('timezone', 0.8574637245203994), ('utcnow', 0.8503238708943778), ('rpc_opts', 0.8406257315223394)]
Top words for pretrained_BERT neuron indx 5016 [('Log', 1.0), ('open', 0.9239298736443057), ('second', 0.8232493691727839), ('probed', 0.8118070826769325), ('tag', 0.8025867599386564)]
Top words for pretrained_BERT neuron indx 7068 [('wait', 1.0), ('long', 0.9131916678424711), ('logging', 0.8921108169574871), ('dest', 0.8552407925936759), ('fcs', 0.8386942867055761)]
Top words for pretrained_BERT neuron indx 9119 [('bare', 1.0), ('uss', 0.6538366269165932), ('Post', 0.610115999769837), ('encode', 0.5932320943290474), ('e', 0.5796515360094453)]
Top words for pretrained_BERT neuron indx 2976 [('purpose', 1.0), ('match', 0.671739679805235), ('closing', 0.6069184516563803), ('hostname', 0.5953662639910211), ('128', 0.5680096504528618)]
Top words for pretrained_BERT neuron indx 928 [('META', 1.0), ('division', 0.8670045500474061), ('1800', 0.6275274752715128), ('close', 0.5336171022044346), ('Post', 0.504596570036033)]
Top words for pretrained_BERT neuron indx 9123 [('k', 1.0), ('v', 0.9816368400995561), ('second', 0.9254190017365176), ('continue', 0.8485647247947707), ('partition', 0.8201827056244287)]
Top words for pretrained_BERT neuron indx 9125 [('META', 1.0), ('if', 0.8260026115289699), ('5', 0.7978705940541384), ('with', 0.7373166749859236), ('except', 0.7181854120255851)]
Top words for pretrained_BERT neuron indx 7081 [('__hash__', 1.0), ('__int__', 0.9763276500585123), ('__class__', 0.9686022509513618), ('__add__', 0.9679103065020991), ('join', 0.9230636417541264)]
Top words for pretrained_BERT neuron indx 9151 [('all', 1.0), ('iq', 0.9264710987767887), ('unicode', 0.904308741735168), ('passwd', 0.8572160251725647), ('max', 0.8301264462622555)]
Top words for pretrained_BERT neuron indx 7107 [('24', 1.0), ('VerticalBillboard', 0.9869132293968863), ('component', 0.979955265800505), ('MAXBOARD', 0.9685849761365878), ('HorizontalBillboard', 0.9501927915426205)]
Top words for pretrained_BERT neuron indx 5059 [('template', 1.0), ('seek', 0.9716001613953391), ('parts', 0.8097403938711494), ('part', 0.7905846393399101), ('contents', 0.7759086792597313)]
Top words for pretrained_BERT neuron indx 969 [('type', 1.0), ('material', 0.9739043497920029), ('config', 0.947665520702659), ('save', 0.9238148050320941), ('seek', 0.9079518880585775)]
Top words for pretrained_BERT neuron indx 7115 [('__name__', 1.0), ('super', 0.9417776164977202), ('600', 0.9343394572756442), ('__version__', 0.8888802312170838), ('1024', 0.8850257032140918)]
Top words for pretrained_BERT neuron indx 3023 [('parts', 1.0), ('part', 0.8377708347093871), ('None', 0.83229238611115), ('closing', 0.732582374393002), ('open', 0.7146808703773497)]
Top words for pretrained_BERT neuron indx 979 [('stanza', 1.0), ('material', 0.8631783519153532), ('models', 0.8520717235021604), ('core', 0.8459775606793338), ('Billboard', 0.7801926687886727)]
Top words for pretrained_BERT neuron indx 7137 [('read', 1.0), ('or', 0.9961471678381139), ('egs', 0.8368882063556538), ('blocking', 0.817446720613495), ('seconds', 0.7974891300228049)]
Top words for pretrained_BERT neuron indx 5091 [('request', 1.0), ('host', 0.9216032452243528), ('vCard', 0.897424115112051), ('day', 0.8351834462880086), ('Tab', 0.8243841069875453)]
Top words for pretrained_BERT neuron indx 5094 [('millis', 1.0), ('types', 0.9960505638496817), ('context', 0.9464532172202536), ('type', 0.9391815006355909), ('common', 0.9390535558084234)]
Top words for pretrained_BERT neuron indx 7144 [('fileno', 1.0), ('st_mode', 0.8363180093940097), ('try', 0.8236461324520823), ('600', 0.8064046128092256), ('Unauthorized', 0.7828976479870768)]
Top words for pretrained_BERT neuron indx 7146 [('Off', 1.0), ('minutes', 0.9785628619863269), ('class', 0.8975368293875816), ('to', 0.853463037452035), ('On', 0.8345336191169409)]
Top words for pretrained_BERT neuron indx 1003 [('View', 1.0), ('alt', 0.9536682435751411), ('tag', 0.9008051101694553), ('from', 0.8727032074717465), ('m', 0.8517870596557793)]
Top words for pretrained_BERT neuron indx 7155 [('REQUEST', 1.0), ('created', 0.9077105780424208), ('minutes', 0.8398598084842539), ('seconds', 0.837225837782729), ('broadcast', 0.78319176131731)]
Top words for pretrained_BERT neuron indx 7157 [('".."', 1.0), ('""', 0.7286201017731011), ('class', 0.7099610544688564), ('else', 0.6498671794643042), ('E', 0.6121476210684996)]
Top words for pretrained_BERT neuron indx 1026 [('zone', 1.0), ('minutes', 0.8350321496950376), ('unicode', 0.7957273279361611), ('upper', 0.7665706219316396), ('oslo', 0.693669052074625)]
Top words for pretrained_BERT neuron indx 9218 [('4', 1.0), ('parse', 0.7656727921894532), ('E', 0.7369363345789446), ('GetMsgCount', 0.6838240370148964), ('__copyright__', 0.6538930059399553)]
Top words for pretrained_BERT neuron indx 3077 [('month', 1.0), ('baynum', 0.9741750855980152), ('Node', 0.9572333666898392), ('all', 0.8479447171165401), ('jid', 0.7929361388985063)]
Top words for pretrained_BERT neuron indx 7177 [('upper', 1.0), ('1800', 0.9019797959713574), ('timezone', 0.8056148172087082), ('Unauthorized', 0.7984372983115361), ('in', 0.792536867630365)]
Top words for pretrained_BERT neuron indx 7178 [('core', 1.0), ('40', 0.9884112659014203), ('set', 0.9184188770225266), ('Tab', 0.9004309964078825), ('group', 0.8701613045699537)]
Top words for pretrained_BERT neuron indx 9229 [('decode', 1.0), ('millis', 0.9881741020438678), ('ref', 0.9049025707320723), ('proxy', 0.8971514503290464), ('7', 0.8968794245129682)]
Top words for pretrained_BERT neuron indx 9242 [('Plugin', 1.0), ('ZmqProxy', 0.853476115382723), ('Off', 0.8270608264778098), ('argv', 0.7989023884432871), ('alt', 0.7717725278900541)]
Top words for pretrained_BERT neuron indx 1050 [('probe', 1.0), ('enclosure', 0.9646743937168473), ('rpc', 0.8766009448325882), ('horizon', 0.8130189070191339), ('post', 0.8082957136467755)]
Top words for pretrained_BERT neuron indx 7197 [('7', 1.0), ('1024', 0.7665545177185459), ('400', 0.7557373782264031), ('""', 0.7439111041944619), ('error', 0.72040251885935)]
Top words for pretrained_BERT neuron indx 9246 [('future', 1.0), ('os', 0.711460001703143), ('Log', 0.6722939654591407), ('action', 0.66927665576337), ('View', 0.6519143232492488)]
Top words for pretrained_BERT neuron indx 3103 [('local', 1.0), ('authenticator', 0.9031071758006479), ('sorted', 0.8336051300676572), ('clone', 0.8118588392397283), ('localize', 0.7923325407523634)]
Top words for pretrained_BERT neuron indx 7205 [('ignore', 1.0), ('Unauthorized', 0.9758010571462298), ('ref', 0.8976751117923888), ('24', 0.8851839068885435), ('Session', 0.8543963457812238)]
Top words for pretrained_BERT neuron indx 7208 [('IsSECANC', 1.0), ('nsanetime', 0.9811034920373821), ('future', 0.8336729818044701), ('PolicyProfileTab', 0.8248363735946954), ('Tab', 0.7858226056052524)]
Top words for pretrained_BERT neuron indx 9261 [('identity', 1.0), ('if', 0.8526075570422206), ('9', 0.7410247824050941), ('7', 0.7192994647440006), ('digest', 0.7046675644282362)]
Top words for pretrained_BERT neuron indx 7220 [('Billboard', 1.0), ('int', 0.7585172569675563), ('unicode', 0.7214355103773448), ('HorizontalBillboard', 0.7124420245666806), ('VerticalBillboard', 0.6688631913043861)]
Top words for pretrained_BERT neuron indx 1078 [('strip', 1.0), ('Distance', 0.8747494538484043), ('common', 0.813750616085083), ('val', 0.8058968155877505), ('Billboard', 0.7577501799990519)]
Top words for pretrained_BERT neuron indx 9274 [('render', 1.0), ('Stretch', 0.8788515032771794), ('enabled', 0.8712180489996274), ('enclosureGroupUri', 0.8329937170142603), ('Distance', 0.8278077547983332)]
Top words for pretrained_BERT neuron indx 5184 [('minutes', 1.0), ('def', 0.9956873417281923), ('count', 0.9380803091881691), ('vCard', 0.9294643680011286), ('slug', 0.8924351334298882)]
Top words for pretrained_BERT neuron indx 5188 [('k', 1.0), ('stanza', 0.7780941080138636), ('300', 0.7563605249262481), ('if', 0.720660583013832), ('kls', 0.6761822359346512)]
Top words for pretrained_BERT neuron indx 3146 [('continue', 1.0), ('upper', 0.9948821815770041), ('routes', 0.8541875863483722), ('utc', 0.830130856225867), ('loads', 0.8115167893981612)]
Top words for pretrained_BERT neuron indx 1101 [('GET', 1.0), ('day', 0.9993303454230943), ('get', 0.9904945390846615), ('other', 0.9619576600572441), ('v', 0.9488540808695562)]
Top words for pretrained_BERT neuron indx 3162 [('800', 1.0), ('300', 0.9794116998775092), ('wait', 0.9516306573917286), ('upper', 0.9297734438032635), ('30', 0.9195008421129315)]
Top words for pretrained_BERT neuron indx 7260 [('all', 1.0), ('7', 0.819699143441928), ('Log', 0.7969080733915275), ('stanza', 0.7689283556974897), ('common', 0.7431051612832438)]
Top words for pretrained_BERT neuron indx 1122 [('collectorBody', 1.0), ('long', 0.9067560117666258), ('format', 0.8650805793111042), ('join', 0.8639751600539468), ('for', 0.8594624002947974)]
Top words for pretrained_BERT neuron indx 1129 [('seconds', 1.0), ('loads', 0.9520801583657805), ('exceptions', 0.9325328527051606), ('exit', 0.8486643866364562), ('dumps', 0.7842817493161282)]
Top words for pretrained_BERT neuron indx 3181 [('5', 1.0), ('id', 0.9248283258684186), ('tokens', 0.9016610507225401), ('to', 0.864957169181829), ('title', 0.8261302610475675)]
Top words for pretrained_BERT neuron indx 5229 [('time', 1.0), ('core', 0.8869716907537099), ('wait', 0.8746629360051299), ('parts', 0.8227185841627231), ('types', 0.8063922884219048)]
Top words for pretrained_BERT neuron indx 9332 [('bool', 1.0), ('material', 0.924461459430815), ('7', 0.8948175396314427), ('materials', 0.8887527623370577), ('seek', 0.8772198646184857)]
Top words for pretrained_BERT neuron indx 5240 [('Unauthorized', 1.0), ('oslo', 0.8905388442578879), ('end', 0.8813726729129894), ('id', 0.8777699771280336), ('ignore', 0.8716115488131193)]
Top words for pretrained_BERT neuron indx 5243 [('List', 1.0), ('os', 0.8514480380505932), ('proxy', 0.8441310919943201), ('time', 0.7843964848352449), ('list', 0.7603756349403065)]
Top words for pretrained_BERT neuron indx 1148 [('slug', 1.0), ('80', 0.7968390584005038), ('read', 0.7432413301496942), ('loads', 0.7419637869354482), ('14', 0.6834930303891318)]
Top words for pretrained_BERT neuron indx 3198 [('Exception', 1.0), ('requests', 0.9754520090951453), ('k', 0.9505747691085764), ('put', 0.8584333513128664), ('wait', 0.8576147095896292)]
Top words for pretrained_BERT neuron indx 7296 [('7', 1.0), ('9', 0.9047907526287093), ('24', 0.8272269212703087), ('2', 0.7502755320277948), ('".."', 0.6837997772440222)]
Top words for pretrained_BERT neuron indx 1153 [('proxy', 1.0), ('filters', 0.8453550433309733), ('seek', 0.7803156660631596), ('k', 0.6950509287752384), ('parent', 0.6547940844552136)]
Top words for pretrained_BERT neuron indx 5250 [('end', 1.0), ('error', 0.9498139013197149), ('builtins', 0.9484282514642935), ('On', 0.927774903646671), ('unicode', 0.8580148304790025)]
Top words for pretrained_BERT neuron indx 7308 [('sts', 1.0), ('stanza', 0.9707428139180959), ('store', 0.9681223226688431), ('False', 0.8840100281077085), ('os', 0.8744331081080144)]
Top words for pretrained_BERT neuron indx 7317 [('upper', 1.0), ('6', 0.8339771712423687), ('broadcast', 0.8117895104639047), ('if', 0.8071223908094598), ('created', 0.7307815237500629)]
Top words for pretrained_BERT neuron indx 7319 [('1800', 1.0), ('GET', 0.9378603615238201), ('store', 0.8769868312822612), ('1', 0.8456810865607445), ('"m_ReflectionProbeUsage"', 0.8174176557775067)]
Top words for pretrained_BERT neuron indx 9372 [('exceptions', 1.0), ('RequestContext', 0.9839918814904602), ('resource', 0.9700465005211509), ('minute', 0.8291863227623442), ('post', 0.8113693262283147)]
Top words for pretrained_BERT neuron indx 7331 [('if', 1.0), ('get_profile_available_storage_systems', 0.9197857283649599), ('get_profile_networks', 0.9152798196910444), ('with', 0.886705271850755), ('except', 0.8371665985200492)]
Top words for pretrained_BERT neuron indx 1196 [('10', 1.0), ('8', 0.8107580997982529), ('path', 0.8001132174503832), ('80', 0.7740936320729568), ('store', 0.7668724332850828)]
Top words for pretrained_BERT neuron indx 7343 [('7', 1.0), ('created', 0.9789229988541172), ('day', 0.900776671304528), ('affinity', 0.8716845709576052), ('hour', 0.849937484554668)]
Top words for pretrained_BERT neuron indx 5297 [('core', 1.0), ('val', 0.9363014772494023), ('host', 0.8370876498422248), ('common', 0.7977060592509345), ('try', 0.7255697518578111)]
Top words for pretrained_BERT neuron indx 3251 [('st', 1.0), ('render_mode', 0.9376859578615274), ('verbose', 0.8799607790319961), ('upper', 0.8755848159619233), ('META', 0.8432344961099069)]
Top words for pretrained_BERT neuron indx 5304 [('group', 1.0), ('oslo', 0.9192385944820218), ('List', 0.8197771888671531), ('mesh', 0.786573557516161), ('2', 0.7736073881536305)]
Top words for pretrained_BERT neuron indx 1209 [('month', 1.0), ('minute', 0.8997536341164772), ('server', 0.884331223456652), ('minutes', 0.8532958786887902), ('Stretch', 0.8240495483851793)]
Top words for pretrained_BERT neuron indx 1212 [('port', 1.0), ('material', 0.9213536547420613), ('f', 0.9025363521946165), ('blocking', 0.8545527115469259), ('Tab', 0.8168011490458927)]
Top words for pretrained_BERT neuron indx 1218 [('sans', 1.0), ('text', 0.7920150483450747), ('pop', 0.7532516978075383), ('server', 0.7399874142004983), ('end', 0.702550112682639)]
Top words for pretrained_BERT neuron indx 1219 [('render', 1.0), ('state', 0.9944516454801091), ('len', 0.9754299467283912), ('seek', 0.9692784784822291), ('def', 0.9489880664366186)]
Top words for pretrained_BERT neuron indx 9411 [('30', 1.0), ('24', 0.9418200821331179), ('False', 0.9314013327958419), ('17', 0.8863362536460115), ('linkfile', 0.8022450203184331)]
Top words for pretrained_BERT neuron indx 3269 [('material', 1.0), ('post', 0.8776619958694485), ('baseline', 0.8248909580691028), ('join', 0.8192532800191833), ('closing', 0.7746080361481822)]
Top words for pretrained_BERT neuron indx 7376 [('utc', 1.0), ('objects', 0.977108321975172), ('authorization', 0.8967490472829119), ('day', 0.8936426225716173), ('description', 0.8867392696285065)]
Top words for pretrained_BERT neuron indx 5334 [('count', 1.0), ('close', 0.9664062055283432), ('while', 0.8449294463693201), ('value', 0.8287007697605958), ('log', 0.8219823839297122)]
Top words for pretrained_BERT neuron indx 1241 [('script', 1.0), ('300', 0.9166355387638849), ('year', 0.8685721812728758), ('message', 0.8662614587262183), ('day', 0.8503711303426874)]
Top words for pretrained_BERT neuron indx 9442 [('Mesh', 1.0), ('models', 0.9292157356203433), ('__copyright__', 0.9092917293087166), ('MAXCLUB', 0.8543096947825785), ('os', 0.8068642761844813)]
Top words for pretrained_BERT neuron indx 3299 [('to', 1.0), ('zone', 0.9824231095588868), ('save', 0.9725687977062228), ('Plugin', 0.919621784072022), ('secs', 0.9186383583336251)]
Top words for pretrained_BERT neuron indx 7395 [('False', 1.0), ('host', 0.8453921779391034), ('utcfromtimestamp', 0.8177167110926025), ('startswith', 0.8020504439085364), ('args', 0.7486234715974159)]
Top words for pretrained_BERT neuron indx 3302 [('title', 1.0), ('message', 0.8859333600601179), ('v', 0.8819934412768163), ('calendar', 0.8724767572426982), ('pass', 0.8603377640788544)]
Top words for pretrained_BERT neuron indx 9447 [('Tab', 1.0), ('root', 0.8644907862423994), ('sans', 0.7303389033359612), ('20', 0.7184908370408982), ('2', 0.7054139342965)]
Top words for pretrained_BERT neuron indx 9448 [('128', 1.0), ('2', 0.859694014819488), ('fileno', 0.8588085208379861), ('get_mode', 0.8277385662613137), ('identity', 0.8228749440292286)]
Top words for pretrained_BERT neuron indx 9450 [('Renderer', 1.0), ('7', 0.9746858848373473), ('ms', 0.9282199668331292), ('serverProfileTemplateUri', 0.8676818780161071), ('millis', 0.8674563171519506)]
Top words for pretrained_BERT neuron indx 9471 [('purpose', 1.0), ('django', 0.9707454153172285), ('pdb', 0.8542544891884417), ('PYTHON_VERSION', 0.843958909977134), ('types', 0.8147403937608031)]
Top words for pretrained_BERT neuron indx 9475 [('17', 1.0), ('15', 0.9664946465563374), ('django', 0.963157618807826), ('is', 0.9518278209531921), ('component', 0.8798088858127991)]
Top words for pretrained_BERT neuron indx 9477 [('oslo', 1.0), ('os', 0.9284246234680532), ('80', 0.8942871292023754), ('component', 0.7713560217332921), ('Node', 0.7187361378225868)]
Top words for pretrained_BERT neuron indx 3339 [('domain', 1.0), ('common', 0.9278844891583484), ('True', 0.8660526744904281), ('for', 0.8431037544654189), ('choices', 0.8012449449254552)]
Top words for pretrained_BERT neuron indx 7438 [('META', 1.0), ('not', 0.8940137821498003), ('is', 0.7501276034301966), ('with', 0.7283600776319377), ('stanza', 0.7067316218535233)]
Top words for pretrained_BERT neuron indx 5394 [('log', 1.0), ('Simple', 0.9341014123589553), ('port', 0.9321193141456517), ('logging', 0.8752983174101869), ('minutes', 0.8529323166782153)]
Top words for pretrained_BERT neuron indx 9495 [('strip', 1.0), ('domain', 0.9877903581087608), ('replace', 0.963346166312059), ('META', 0.9433949962604911), ('if', 0.9217752049229487)]
Top words for pretrained_BERT neuron indx 5404 [('requests', 1.0), ('loads', 0.9625475922215533), ('host', 0.9469933637612188), ('objects', 0.9279665561968024), ('sorted', 0.7051269650720442)]
Top words for pretrained_BERT neuron indx 9501 [('5', 1.0), ('6', 0.9663194307288654), ('7', 0.896409068718847), ('log', 0.7861932686111299), ('oslo', 0.7670386237217264)]
Top words for pretrained_BERT neuron indx 3360 [('state', 1.0), ('npos', 0.9921070207770156), ('ignore', 0.8842102113960557), ('stanza', 0.8527555847870074), ('recv', 0.8517899521623836)]
Top words for pretrained_BERT neuron indx 3361 [('text', 1.0), ('loads', 0.7414877761231075), ('print', 0.7196914983556714), ('bare', 0.7114852734342682), ('stanza', 0.6722187887813353)]
Top words for pretrained_BERT neuron indx 7473 [('m', 1.0), ('Billboard', 0.919474075172944), ('unicode', 0.9051821960769701), ('hour', 0.8969980144204943), ('exit', 0.8896174951140058)]
Top words for pretrained_BERT neuron indx 7488 [('slug', 1.0), ('vCard', 0.9107571859974606), ('def', 0.8983355230002016), ('count', 0.891349913006321), ('future', 0.8017937730909657)]
Top words for pretrained_BERT neuron indx 1351 [('Exception', 1.0), ('except', 0.7413088614678691), ('action', 0.7308966604464683), ('horizon', 0.7268914737844372), ('break', 0.7256321064617308)]
Top words for pretrained_BERT neuron indx 3411 [('local', 1.0), ('to', 0.8945584109979917), ('horizon', 0.8181127400399872), ('View', 0.744040226171845), ('action', 0.6976918949110329)]
Top words for pretrained_BERT neuron indx 5469 [('put', 1.0), ('List', 0.8764814485265884), ('save', 0.8016202118024933), ('StreamClosed', 0.7386983163592012), ('day', 0.6966415417772075)]
Top words for pretrained_BERT neuron indx 3422 [('unicode', 1.0), ('all', 0.8454332350817726), ('timezone', 0.7529394414729712), ('digest', 0.7401958839762072), ('Digest', 0.7073653147018015)]
Top words for pretrained_BERT neuron indx 5472 [('long', 1.0), ('models', 0.9579399416797131), ('core', 0.9551673129050352), ('shortcuts', 0.8694044632150367), ('required', 0.8350106955338984)]
Top words for pretrained_BERT neuron indx 3427 [('400', 1.0), ('6', 0.9776508000345627), ('60', 0.8770354379583141), ('sans', 0.8631612818391169), ('40', 0.839683648784453)]
Top words for pretrained_BERT neuron indx 1384 [('us', 1.0), ('pass', 0.9678748526900598), ('authorized', 0.9412775051644667), ('pooltype', 0.9243529796976063), ('Unauthorized', 0.8392368132631776)]
Top words for pretrained_BERT neuron indx 5482 [('oslo', 1.0), ('models', 0.8452097910478474), ('15', 0.7146167710073116), ('14', 0.6938436778571984), ('16', 0.6830697779645887)]
Top words for pretrained_BERT neuron indx 9580 [('7', 1.0), ('15', 0.9925834331062051), ('8000', 0.9481685713590092), ('6', 0.9381108948803808), ('nargs', 0.8804393331902134)]
Top words for pretrained_BERT neuron indx 5485 [('set', 1.0), ('title', 0.9764393555177104), ('boot', 0.9642027168634165), ('i', 0.9567029180995047), ('id', 0.9119537984733049)]
Top words for pretrained_BERT neuron indx 1404 [('push', 1.0), ('UCache', 0.9040044243250591), ('modes', 0.8454023354168431), ('True', 0.7994434569710012), ('Stretch', 0.7699812384219031)]
Top words for pretrained_BERT neuron indx 3453 [('with', 1.0), ('for', 0.8543901051354159), ('sanetime', 0.7774717629096801), ('1024', 0.7762560497965127), ('as', 0.7624878928764248)]
Top words for pretrained_BERT neuron indx 3457 [('seek', 1.0), ('filters', 0.7652784175083721), ('long', 0.723683209311896), ('proxy', 0.6714210281284853), ('as', 0.6327098699061873)]
Top words for pretrained_BERT neuron indx 5508 [('stanza', 1.0), ('requests', 0.747567288040571), ('1800', 0.7175236142188596), ('long', 0.6540547506445934), ('return', 0.6461001116451497)]
Top words for pretrained_BERT neuron indx 9606 [('0', 1.0), ('authentication', 0.9971746671003746), ('decode', 0.9544759430421877), ('"Name"', 0.9539277700480702), ('1', 0.9306322530572797)]
Top words for pretrained_BERT neuron indx 7560 [('repr', 1.0), ('probe', 0.8144943523283225), ('1024', 0.8122702694609366), ('argv', 0.8021811236026958), ('kls', 0.7436534583079771)]
Top words for pretrained_BERT neuron indx 5516 [('minutes', 1.0), ('stanza', 0.9005288251069493), ('contents', 0.8343186619491528), ('key', 0.8085926843199737), ('seconds', 0.77079672236044)]
Top words for pretrained_BERT neuron indx 7565 [('9', 1.0), ('pdb', 0.898809531251107), ('".."', 0.8105107718106401), ('if', 0.7558750326648881), ('for', 0.6481765059543347)]
Top words for pretrained_BERT neuron indx 9616 [('seek', 1.0), ('method', 0.7867065391747086), ('f', 0.725135293539411), ('META', 0.7122186923608428), ('mesh2', 0.7037087972224707)]
Top words for pretrained_BERT neuron indx 1424 [('group', 1.0), ('On', 0.8023262927910847), ('calendar', 0.7571194065104913), ('Distance', 0.7494592464803187), ('super', 0.7297518981705131)]
Top words for pretrained_BERT neuron indx 7571 [('else', 1.0), ('as', 0.9871094614617736), ('400', 0.9749480390871799), ('600', 0.9666574080063695), ('1800', 0.9239478756766945)]
Top words for pretrained_BERT neuron indx 7572 [('month', 1.0), ('get_resources', 0.7647008408403736), ('12', 0.749707677937811), ('consume_in_thread', 0.7430301668415024), ('types', 0.7362744671586484)]
Top words for pretrained_BERT neuron indx 9620 [('credential', 1.0), ('REQUEST', 0.9985565667575996), ('YoungestInFront', 0.9236756976231374), ('OldestInFront', 0.9130608883985923), ('OLDPASSLEN', 0.903434862249747)]
Top words for pretrained_BERT neuron indx 3475 [('post', 1.0), ('oslo', 0.9694314996739887), ('uss', 0.9566352329008386), ('or', 0.815858156135548), ('continue', 0.7726994714859012)]
Top words for pretrained_BERT neuron indx 9623 [('META', 1.0), ('store', 0.8732684093697756), ('__copyright__', 0.8690671144547568), ('component', 0.8005055978058757), ('requests', 0.7930577605782525)]
Top words for pretrained_BERT neuron indx 5528 [('ret', 1.0), ('e', 0.9953743295884537), ('if', 0.9481966569057348), ('broadcast', 0.9264749239369374), ('kls', 0.8589672884577244)]
Top words for pretrained_BERT neuron indx 9625 [('PYTHON_VERSION', 1.0), ('17', 0.8933749530335244), ('version_info', 0.8933370169106964), ('800', 0.8920551389015151), ('LoadUser', 0.8907659588368007)]
Top words for pretrained_BERT neuron indx 9627 [('authorization', 1.0), ('sans', 0.8052620532413974), ('Authorization', 0.7966002487966305), ('authentication', 0.7380978909517294), ('authorized', 0.6729991853235975)]
Top words for pretrained_BERT neuron indx 3487 [('f', 1.0), ('s', 0.9350723996773862), ('"r"', 0.9037565772369549), ('all', 0.8985241388535153), ('attr', 0.8957283231948326)]
Top words for pretrained_BERT neuron indx 7583 [('bare', 1.0), ('e', 0.6590240018037137), ('created', 0.6417936507332466), ('uss', 0.6208951888922802), ('Post', 0.6126632990712373)]
Top words for pretrained_BERT neuron indx 5539 [('identity', 1.0), ('View', 0.7449990097908556), ('tag', 0.6742407538833621), ('group', 0.6416524873098839), ('line', 0.6347695300617452)]
Top words for pretrained_BERT neuron indx 9635 [('oslo', 1.0), ('Tab', 0.7781966095056627), ('models', 0.7248826567395011), ('8', 0.7234730230569318), ('except', 0.7065841311935483)]
Top words for pretrained_BERT neuron indx 1445 [('raise', 1.0), ('month', 0.949909930232695), ('script', 0.9022764079767837), ('root', 0.8705727742524741), ('direct', 0.7534257277126463)]
Top words for pretrained_BERT neuron indx 3491 [('Tab', 1.0), ('Off', 0.8841399218750781), ('ping', 0.8703716627421506), ('wait', 0.820572933107038), ('with', 0.8146091037454303)]
Top words for pretrained_BERT neuron indx 3494 [('14', 1.0), ('reactor', 0.9962546743572661), ('12', 0.9803206383842503), ('force', 0.9307210884981522), ('required', 0.9201890057343525)]
Top words for pretrained_BERT neuron indx 5545 [('128', 1.0), ('items', 0.9987556717707119), ('requests', 0.942870031313479), ('connection', 0.8867861107111562), ('__hash__', 0.8459856646406568)]
Top words for pretrained_BERT neuron indx 5549 [('bare', 1.0), ('contents', 0.9397610943543552), ('16', 0.9327107153377858), ('IPLEN', 0.9203453961142937), ('Register', 0.8876459306499469)]
Top words for pretrained_BERT neuron indx 1454 [('state', 1.0), ('True', 0.9228816412423255), ('store', 0.9004204354150521), ('common', 0.892638938224397), ('or', 0.8876844427238698)]
Top words for pretrained_BERT neuron indx 5559 [('us', 1.0), ('connection', 0.8822921599877361), ('replace', 0.8754568834851827), ('max', 0.8667170396796442), ('16', 0.8517198271864053)]
Top words for pretrained_BERT neuron indx 7608 [('List', 1.0), ('2', 0.8957656703893049), ('7', 0.8443528124889449), ('9', 0.7680302199319123), ('domain', 0.7341100530997671)]
Top words for pretrained_BERT neuron indx 7609 [('objects', 1.0), ('item', 0.9423715005976204), ('send', 0.8791708393577852), ('group', 0.8719710297099158), ('material', 0.8666939109314069)]
Top words for pretrained_BERT neuron indx 3516 [('hpov', 1.0), ('port', 0.9631664295863805), ('id', 0.9627855210423297), ('tz', 0.9505009832506285), ('required', 0.9426534583239661)]
Top words for pretrained_BERT neuron indx 1474 [('seconds', 1.0), ('minutes', 0.8210967944297872), ('Board', 0.8179333731904153), ('log', 0.7565590329004278), ('with', 0.7540892907774946)]
Top words for pretrained_BERT neuron indx 3523 [('template', 1.0), ('NoPerm', 0.8483645949139862), ('mtime', 0.8326453496481319), ('seek', 0.8183612465376866), ('contents', 0.7570746442716647)]
Top words for pretrained_BERT neuron indx 1477 [('authentication', 1.0), ('description', 0.7918280818837632), ('match', 0.7742599514094388), ('MSG', 0.7013281660779712), ('authorized', 0.7000519365109563)]
Top words for pretrained_BERT neuron indx 1480 [('objects', 1.0), ('ms', 0.9211743566583692), ('send', 0.8759231592998707), ('exceptions', 0.8757290634384184), ('start', 0.8582483784915673)]
Top words for pretrained_BERT neuron indx 9674 [('day', 1.0), ('template_name', 0.9349931275178989), ('seconds', 0.8377910002417647), ('bool', 0.808690600174287), ('super', 0.7991563741033155)]
Top words for pretrained_BERT neuron indx 1494 [('count', 1.0), ('close', 0.915078347223122), ('def', 0.7381483839505852), ('wait', 0.683472048957715), ('info', 0.6537984863374428)]
Top words for pretrained_BERT neuron indx 9692 [('millis', 1.0), ('On', 0.9452975142408234), ('enabled', 0.880203516353285), ('partition', 0.8365641541714464), ('rval', 0.7894337358613769)]
Top words for pretrained_BERT neuron indx 9694 [('Simple', 1.0), ('component', 0.9628935631410288), ('View', 0.9433533679566194), ('5', 0.8544633050291374), ('ref', 0.8421195027246081)]
Top words for pretrained_BERT neuron indx 9696 [('register', 1.0), ('int', 0.9434876701374456), ('calendar', 0.9239196885891576), ('META', 0.8722106174311633), ('end', 0.8637527691857992)]
Top words for pretrained_BERT neuron indx 9697 [('7', 1.0), ('identity', 0.9322403183040779), ('readline', 0.9041343199867427), ('year', 0.8855597967417492), ('9', 0.8412857566254923)]
Top words for pretrained_BERT neuron indx 7653 [('day', 1.0), ('month', 0.9528210408227185), ('wait', 0.8600971407951727), ('year', 0.8577160143727555), ('raise', 0.7923868642460755)]
Top words for pretrained_BERT neuron indx 5606 [('field', 1.0), ('message', 0.9379847396689228), ('v', 0.9323464347334427), ('pass', 0.9285792993340882), ('1800', 0.9247745049024245)]
Top words for pretrained_BERT neuron indx 1513 [('description', 1.0), ('range', 0.9824452979198659), ('presence', 0.9254088047249626), ('find', 0.8946545722420769), ('item', 0.8343745558354588)]
Top words for pretrained_BERT neuron indx 5610 [('class', 1.0), ('Off', 0.9821923438288077), ('seconds', 0.9068459442626633), ('help', 0.8937457648527781), ('sans', 0.8599654500802572)]
Top words for pretrained_BERT neuron indx 7660 [('logging', 1.0), ('post', 0.8996032539851039), ('seconds', 0.879235096033523), ('localize', 0.8758028833176171), ('key', 0.8743387152705278)]
Top words for pretrained_BERT neuron indx 9715 [('7', 1.0), ('60', 0.9189153347763687), ('milliseconds', 0.91865363726215), ('django', 0.8211786457651625), ('hpOneView', 0.8125755430447485)]
Top words for pretrained_BERT neuron indx 7668 [('2', 1.0), ('seconds', 0.9981020702086286), ('minutes', 0.9841951433780382), ('for', 0.9769853666190172), ('1000', 0.9514151731362187)]
Top words for pretrained_BERT neuron indx 3582 [('help', 1.0), ('12', 0.9774915416060027), ('enabled', 0.9632439822124588), ('authenticator', 0.9556813157790474), ('10', 0.9164315756695525)]
Top words for pretrained_BERT neuron indx 5631 [('Billboard', 1.0), ('Mesh', 0.9457613112083793), ('30', 0.8613625755673047), ('Stretch', 0.8060031502807328), ('blocking', 0.8017804556759652)]
Top words for pretrained_BERT neuron indx 3584 [('component', 1.0), ('other', 0.8772283443938359), ('Component', 0.8720913715173886), ('break', 0.8708818613471189), ('route', 0.8491915594358558)]
Top words for pretrained_BERT neuron indx 5635 [('board', 1.0), ('Board', 0.9896432861982177), ('mesh', 0.9763302114966487), ('with', 0.9412624606549564), ('enabled', 0.9233821540518348)]
Top words for pretrained_BERT neuron indx 9732 [('identity', 1.0), ('utcnow', 0.917755249285226), ('int', 0.8697332575929232), ('presence', 0.7477347089046573), ('utc', 0.7066664778848327)]
Top words for pretrained_BERT neuron indx 9736 [('pop', 1.0), ('12', 0.7192780368252714), ('proxy', 0.7106946738523574), ('128', 0.6972688483162439), ('log', 0.6955642153743388)]
Top words for pretrained_BERT neuron indx 3592 [('pop', 1.0), ('count', 0.9365131555317889), ('con', 0.8179488267738572), ('On', 0.7749009116520424), ('calendar', 0.7171542446243391)]
Top words for pretrained_BERT neuron indx 3600 [('e', 1.0), ('re', 0.9718023022069451), ('pop', 0.9321759266044289), ('Profile', 0.9074955541181561), ('continue', 0.9035615246803381)]
Top words for pretrained_BERT neuron indx 7698 [('log', 1.0), ('Simple', 0.7831614237595748), ('range', 0.7279088383207398), ('logging', 0.7090605052970748), ('port', 0.6924782644908734)]
Top words for pretrained_BERT neuron indx 5654 [('authorization', 1.0), ('False', 0.9617105695582511), ('continue', 0.8919296778083288), ('E', 0.8375299223449016), ('horizon', 0.8312285934596949)]
Top words for pretrained_BERT neuron indx 7708 [('loads', 1.0), ('MAXSIGLINES', 0.971611028457871), ('baseline', 0.9338898648513845), ('dateutil', 0.8920123233786774), ('error', 0.8776131991521094)]
Top words for pretrained_BERT neuron indx 7710 [('future', 1.0), ('boot', 0.8049965995296313), ('action', 0.7375180442617912), ('os', 0.7319206673176277), ('filters', 0.7097017859509914)]
Top words for pretrained_BERT neuron indx 9771 [('7', 1.0), ('sans', 0.9775298562980675), ('with', 0.9117901867014326), ('hour', 0.8100944322809028), ('while', 0.7806730095009603)]
Top words for pretrained_BERT neuron indx 5684 [('with', 1.0), ('is', 0.90395388451863), ('in', 0.8397557432393694), ('int', 0.8098756339800371), ('as', 0.7997000512493961)]
Top words for pretrained_BERT neuron indx 9784 [('sorting_layer_id', 1.0), ('render_mode', 0.93382703128224), ('def', 0.900041139901306), ('NetworkProfileTab', 0.8878727094404025), ('st_mode', 0.8823068913380212)]
Top words for pretrained_BERT neuron indx 5691 [('sorted', 1.0), ('long', 0.958271830857662), ('field', 0.7882030215536576), ('with', 0.7648791226751382), ('identity', 0.7108368459262951)]
Top words for pretrained_BERT neuron indx 3648 [('sorted', 1.0), ('vCard', 0.9745943083810689), ('count', 0.9236754810711186), ('minutes', 0.8802895477908856), ('20', 0.8637304607285534)]
Top words for pretrained_BERT neuron indx 7745 [('9', 1.0), ('affinity', 0.8485187717190017), ('7', 0.8419321835534541), ('Mesh', 0.8300029500462234), ('oslo', 0.76235996825455)]
Top words for pretrained_BERT neuron indx 3655 [('to', 1.0), ('Exception', 0.905343084124394), ('not', 0.7228070793952688), ('con', 0.719883815471336), ('local', 0.6562475199361092)]
Top words for pretrained_BERT neuron indx 9801 [('hasattr', 1.0), ('update_server_profile', 0.9346239000070369), ('stream_error', 0.9119624378784393), ('StreamClosed', 0.9097870606769292), ('decode', 0.8883243017326881)]
Top words for pretrained_BERT neuron indx 7764 [('epoch_milliseconds', 1.0), ('affinity', 0.967019031308939), ('milliseconds', 0.950207235026829), ('str', 0.9117155302985828), ('camera_velocity_scale', 0.8880646546446309)]
Top words for pretrained_BERT neuron indx 7765 [('in', 1.0), ('E', 0.8564800448741821), ('seconds', 0.767941239054313), ('objects', 0.6648096333279521), ('horizon', 0.6556038025447319)]
Top words for pretrained_BERT neuron indx 7774 [('minutes', 1.0), ('24', 0.9908987942076187), ('day', 0.9426312691943155), ('seconds', 0.8711489610969161), ('month', 0.8444509894632225)]
Top words for pretrained_BERT neuron indx 5731 [('sans', 1.0), ('error', 0.8368960440566763), ('default', 0.820691328949505), ('ref', 0.7322124882243093), ('400', 0.7307407651467169)]
Top words for pretrained_BERT neuron indx 7779 [('as', 1.0), ('exit', 0.9239762426373179), ('Post', 0.8972265694646542), ('stat', 0.8838344925402195), ('title', 0.8647620835784098)]
Top words for pretrained_BERT neuron indx 5747 [('digest', 1.0), ('horizon', 0.9443465266714337), ('len', 0.9116276150727239), ('seconds', 0.8921475894492203), ('match', 0.8568817593340821)]
Top words for pretrained_BERT neuron indx 7801 [('""', 1.0), ('title', 0.8751508459958491), ('Plugin', 0.8718311583620763), ('is', 0.8509292509630437), ('routes', 0.8499083482221654)]
Top words for pretrained_BERT neuron indx 1659 [('6', 1.0), ('exceptions', 0.9579329914549729), ('partition', 0.8606202365071868), ('60', 0.8432448596698482), ('slug', 0.8001606250876725)]
Top words for pretrained_BERT neuron indx 3707 [('proxy', 1.0), ('context', 0.9819172377619545), ('path', 0.9182727932243626), ('local', 0.9043620768107306), ('dt', 0.8191867900142985)]
Top words for pretrained_BERT neuron indx 1662 [('dt', 1.0), ('requests', 0.9736129135214845), ('600', 0.9141111038617148), ('required', 0.8880209941414837), ('400', 0.8749167822271325)]
Top words for pretrained_BERT neuron indx 7810 [('Tab', 1.0), ('1800', 0.9168051738075991), ('800', 0.8939751010509297), ('8000', 0.8834047246923561), ('86400', 0.8470724512709962)]
Top words for pretrained_BERT neuron indx 1666 [('close', 1.0), ('key', 0.8775685942282755), ('format', 0.8122009802424257), ('link', 0.8089460007032785), ('find', 0.7910589298561598)]
Top words for pretrained_BERT neuron indx 7812 [('all', 1.0), ('return', 0.879257547435915), ('is', 0.8103897605891388), ('uss', 0.7624851443185897), ('day', 0.7415639036278253)]
Top words for pretrained_BERT neuron indx 5772 [('store', 1.0), ('long', 0.9666839764976576), ('stanza', 0.9166028546324401), ('sts', 0.8576250502438099), ('os', 0.840190633334222)]
Top words for pretrained_BERT neuron indx 9869 [('4', 1.0), ('UserInfo', 0.8197945365772709), ('24', 0.8186202156894482), ('6', 0.7957107700772176), ('9', 0.7906688076146164)]
Top words for pretrained_BERT neuron indx 5773 [('end', 1.0), ('sent_close', 0.9063508375677111), ('1', 0.9054987953306146), ('0', 0.8553330634276032), ('root', 0.8293129028619532)]
Top words for pretrained_BERT neuron indx 3731 [('render', 1.0), ('300', 0.9090083720451904), ('1800', 0.8990096846173311), ('partition', 0.8782595767022504), ('1000', 0.8738348892500342)]
Top words for pretrained_BERT neuron indx 5783 [('loads', 1.0), ('bind', 0.961212575750646), ('List', 0.9395207192667133), ('requests', 0.9349685018123614), ('enabled', 0.9004266956853677)]
Top words for pretrained_BERT neuron indx 9879 [('pop', 1.0), ('32', 0.9023164910397222), ('5', 0.897741425689743), ('40', 0.8274671884372534), ('long', 0.7971510545390004)]
Top words for pretrained_BERT neuron indx 9881 [('7', 1.0), ('24', 0.9948688524563419), ('IntEnum', 0.9487444823278691), ('20', 0.8829702087714041), ('group', 0.8789910080929937)]
Top words for pretrained_BERT neuron indx 7837 [('or', 1.0), ('state', 0.7427911778464052), ('sanedelta', 0.7361466260113162), ('routes', 0.7122374322026673), ('NAMELEN', 0.7095007451413883)]
Top words for pretrained_BERT neuron indx 9887 [('bare', 1.0), ('uss', 0.8345863046371561), ('UserInfo', 0.7990436573807279), ('servers', 0.7978830988780046), ('millis', 0.7964956733730014)]
Top words for pretrained_BERT neuron indx 5795 [('except', 1.0), ('with', 0.8648222678787537), ('if', 0.8506476438523076), ('oslo', 0.7818786908532235), ('7', 0.7582534082558751)]
Top words for pretrained_BERT neuron indx 9891 [('v', 1.0), ('k', 0.9981291380659455), ('second', 0.9565120147945742), ('alt', 0.9270362421911819), ('List', 0.8482570467763283)]
Top words for pretrained_BERT neuron indx 9893 [('5', 1.0), ('META', 0.9172447156876381), ('E', 0.861182724687965), ('except', 0.8541269774883178), ('month', 0.8174536804522493)]
Top words for pretrained_BERT neuron indx 9896 [('end', 1.0), ('1800', 0.9288381906092705), ('f', 0.900595787522213), ('description', 0.8709795281206737), ('17', 0.8462322540950863)]
Top words for pretrained_BERT neuron indx 5807 [('Billboard', 1.0), ('created', 0.9584902215286136), ('bare', 0.9035965333374242), ('affinity', 0.86701253257927), ('authorized', 0.8385974955509318)]
Top words for pretrained_BERT neuron indx 5823 [('post', 1.0), ('24', 0.9384744982014723), ('write', 0.8868212565353751), ('link', 0.8232850841289207), ('""', 0.8121005721379653)]
Top words for pretrained_BERT neuron indx 1729 [('except', 1.0), ('split', 0.825909024987081), ('sans', 0.8192650897375527), ('errors', 0.7870621951869269), ('log', 0.7567650934404961)]
Top words for pretrained_BERT neuron indx 3778 [('minutes', 1.0), ('seconds', 0.9489893347732712), ('long', 0.8428097379522015), ('from', 0.7302113460462404), ('log', 0.7062766228327259)]
Top words for pretrained_BERT neuron indx 7875 [('24', 1.0), ('17', 0.946268016219997), ('30', 0.9174615528337561), ('receive_shadows', 0.9148041222349647), ('component', 0.9110831664894901)]
Top words for pretrained_BERT neuron indx 7883 [('super', 1.0), ('Distance', 0.9551899000163829), ('On', 0.9461377143142065), ('1024', 0.9291629369682954), ('help', 0.9264326394709329)]
Top words for pretrained_BERT neuron indx 9935 [('oslo', 1.0), ('9', 0.8646870093972557), ('8000', 0.7863728633232846), ('0', 0.7771269045702603), ('128', 0.7758046795901515)]
Top words for pretrained_BERT neuron indx 3791 [('1000', 1.0), ('closing', 0.957817105927757), ('parts', 0.9453391579681766), ('None', 0.9003417505816628), ('part', 0.8160527508748844)]
Top words for pretrained_BERT neuron indx 3798 [('count', 1.0), ('close', 0.8193917022562075), ('value', 0.815752387753003), ('while', 0.8118698263914685), ('17', 0.782223183898838)]
Top words for pretrained_BERT neuron indx 3799 [('to', 1.0), ('max', 0.9679310815074322), ('types', 0.8600933346265377), ('clone', 0.8187753136883285), ('15', 0.8091981937745261)]
Top words for pretrained_BERT neuron indx 1757 [('zone', 1.0), ('default', 0.9213787568037651), ('_hash', 0.9193083714761571), ('identity', 0.8898870288907816), ('parent', 0.8096426322407111)]
Top words for pretrained_BERT neuron indx 7902 [('s', 1.0), ('k', 0.9789275969861959), ('re', 0.8756062762227966), ('sts', 0.8678867685438195), ('9', 0.8420875435631417)]
Top words for pretrained_BERT neuron indx 7905 [('__long__', 1.0), ('blocking', 0.9609997676088491), ('Library', 0.9305025975147768), ('seconds', 0.9201935287982538), ('or', 0.8898325789883252)]
Top words for pretrained_BERT neuron indx 7906 [('Mesh', 1.0), ('materials', 0.9499800712788049), ('Stretch', 0.9269783030590868), ('Distance', 0.9062634483274374), ('items', 0.8808538879415139)]
Top words for pretrained_BERT neuron indx 5862 [('authorization', 1.0), ('authentication', 0.9199003894743404), ('type', 0.9031154213053006), ('context', 0.9023707408514893), ('1024', 0.838083633431657)]
Top words for pretrained_BERT neuron indx 9962 [('2', 1.0), ('authorization', 0.9457136527119131), ('future', 0.9058636359573989), ('errors', 0.892385643219174), ('pop', 0.8703645895537162)]
Top words for pretrained_BERT neuron indx 7914 [('minutes', 1.0), ('to', 0.9625022187713859), ('Off', 0.8922012778014251), ('millis', 0.8309712717874563), ('digest', 0.7926656293068329)]
Top words for pretrained_BERT neuron indx 7929 [('1024', 1.0), ('stanza', 0.8645232002862269), ('ignore', 0.8197008977726646), ('seek', 0.7905604306619717), ('pxe', 0.7892985031203509)]
Top words for pretrained_BERT neuron indx 1786 [('help', 1.0), ('List', 0.8696851202977562), ('log', 0.8534957870995963), ('start', 0.8231025302448696), ('domain', 0.8066752670027217)]
Top words for pretrained_BERT neuron indx 7942 [('utc', 1.0), ('60', 0.8798476871969089), ('ping', 0.8554306645042549), ('calendar', 0.8402087564718608), ('Post', 0.8302465469958064)]
Top words for pretrained_BERT neuron indx 7949 [('name', 1.0), ('1000', 0.9793868210420423), ('other', 0.9356838814776459), ('strip', 0.9319443792143405), ('and', 0.9273696176375249)]
Top words for pretrained_BERT neuron indx 5902 [('META', 1.0), ('9', 0.925508246459775), ('not', 0.8472491004442807), ('re', 0.8170378980084364), ('requests', 0.7780611960140486)]
Top words for pretrained_BERT neuron indx 7959 [('all', 1.0), ('ref', 0.9830303486941055), ('long', 0.9716981327433994), ('replace', 0.961447417162411), ('NoPerm', 0.9460288898949085)]
Top words for pretrained_BERT neuron indx 7965 [('log', 1.0), ('7', 0.8458378583411341), ('""', 0.7724771704043208), ('zone', 0.7521827111821252), ('sts', 0.7142043329788279)]
Top words for pretrained_BERT neuron indx 1846 [('strip', 1.0), ('Billboard', 0.9562544528124897), ('slug', 0.7398691012789155), ('Distance', 0.6715460497773623), ('replace', 0.6551841553687755)]
Top words for pretrained_BERT neuron indx 7999 [('is', 1.0), ('META', 0.8956667602294092), ('context', 0.849034302974299), ('VerticalBillboard', 0.8436377389397648), ('HorizontalBillboard', 0.8067474705668155)]
Top words for pretrained_BERT neuron indx 5952 [('slug', 1.0), ('def', 0.9850506792585574), ('count', 0.8584885960375911), ('minutes', 0.8409098917559783), ('vCard', 0.840904071187831)]
Top words for pretrained_BERT neuron indx 5953 [('seek', 1.0), ('not', 0.8701601235243874), ('"\\\\n"', 0.74039034944252), ('purpose', 0.6998166669177269), ('14', 0.6969382891316138)]
Top words for pretrained_BERT neuron indx 5956 [('k', 1.0), ('m', 0.9753355171656454), ('state', 0.8803370286085916), ('stanza', 0.8378557738753226), ('milliseconds', 0.8372238506764652)]
Top words for pretrained_BERT neuron indx 3949 [('set', 1.0), ('5', 0.922958425565777), ('Authorization', 0.8689745238927998), ('broadcast', 0.8408613942963378), ('to', 0.7995511576100862)]
Top words for pretrained_BERT neuron indx 5997 [('core', 1.0), ('time', 0.9206922878102854), ('wait', 0.8770130253817715), ('parts', 0.8474143278356366), ('types', 0.7872917327008402)]
Top words for pretrained_BERT neuron indx 5999 [('import', 1.0), ('all', 0.9415026996268434), ('choices', 0.85768160929535), ('Stretch', 0.8372156261462435), ('core', 0.8338650609017713)]
Top words for pretrained_BERT neuron indx 3952 [('project', 1.0), ('enclosure', 0.7331375006732376), ('microseconds', 0.7312582369082846), ('return', 0.7275212086008911), ('objects', 0.7128622668547038)]
Top words for pretrained_BERT neuron indx 8048 [('parent', 1.0), ('blocking', 0.9489626724011976), ('presence', 0.9375689675185084), ('20000', 0.8950194305766349), ('force', 0.8885663582463051)]
Top words for pretrained_BERT neuron indx 3956 [('exceptions', 1.0), ('24', 0.8194288559273945), ('settings', 0.8003362862279197), ('log', 0.7556928480363577), ('constants', 0.7318228024833556)]
Top words for pretrained_BERT neuron indx 6007 [('2', 1.0), ('zone', 0.98178784747324), ('Authorization', 0.9511436419234581), ('direct', 0.8782052712849497), ('builtins', 0.8445127182993579)]
Top words for pretrained_BERT neuron indx 3970 [('close', 1.0), ('state', 0.887555263483098), ('main', 0.8854503882536832), ('feature', 0.8627182783481592), ('zone', 0.8614144325467628)]
Top words for pretrained_BERT neuron indx 8076 [('sts', 1.0), ('store', 0.9112263616140547), ('stanza', 0.9004988522251871), ('os', 0.841184279741317), ('False', 0.818148484340484)]
Top words for pretrained_BERT neuron indx 8077 [('end', 1.0), ('presence', 0.9355929091807802), ('hour', 0.8587188873309488), ('action', 0.8264701712303524), ('second', 0.8207074332142125)]
Top words for pretrained_BERT neuron indx 8080 [('models', 1.0), ('s', 0.7957642022882759), ('m', 0.7814409843676784), ('materials', 0.7317930322419463), ('calendar', 0.7212847264282513)]
Top words for pretrained_BERT neuron indx 1937 [('log', 1.0), ('Billboard', 0.9424803990061182), ('uss', 0.8033013068997806), ('component', 0.7851713237917058), ('text', 0.781515039233273)]
Top words for pretrained_BERT neuron indx 6033 [('uss', 1.0), ('all', 0.9732802215063496), ('context', 0.9710215595963899), ('srv', 0.967510022441926), ('Simple', 0.9570851468278267)]
Top words for pretrained_BERT neuron indx 8087 [('GET', 1.0), ('requests', 0.975696431827039), ('store', 0.9233135519653971), ('max', 0.9029774917247758), ('1800', 0.8782397147201143)]
Top words for pretrained_BERT neuron indx 8099 [('if', 1.0), ('except', 0.8382830014686536), ('get_profile_available_storage_systems', 0.706247711209979), ('post', 0.7054924265742181), ('with', 0.6698582950189959)]
Top words for pretrained_BERT neuron indx 6053 [('META', 1.0), ('if', 0.8855946684949154), ('except', 0.8725547889860955), ('Mesh', 0.8704325450253892), ('description', 0.8560800394613556)]
Top words for pretrained_BERT neuron indx 4009 [('128', 1.0), ('connection', 0.9059636825561913), ('post', 0.7554088262714868), ('Off', 0.7278452490315398), ('requests', 0.7070059610469188)]
Top words for pretrained_BERT neuron indx 4023 [('us', 1.0), ('connection', 0.8998829924852773), ('created', 0.8878973274207896), ('replace', 0.850611888149682), ('Mesh', 0.8017550059812668)]
Top words for pretrained_BERT neuron indx 4024 [('Node', 1.0), ('con', 0.965259756291935), ('to', 0.9335960606533856), ('m', 0.9173460075123525), ('9', 0.8580985400569439)]
Top words for pretrained_BERT neuron indx 8121 [('passwd', 1.0), ('digest', 0.9925968757885176), ('sts', 0.9827048918078154), ('17', 0.9539759262112966), ('2', 0.9221632665154205)]
Top words for pretrained_BERT neuron indx 1986 [('ref', 1.0), ('sans', 0.9241222925189742), ('pop', 0.8965639213022988), ('text', 0.8937588284644921), ('help', 0.8182722000717049)]
Top words for pretrained_BERT neuron indx 1987 [('render', 1.0), ('template', 0.9272376615493996), ('exceptions', 0.8956841095196044), ('mtime', 0.8677644518792824), ('contents', 0.8672035674013966)]
Top words for pretrained_BERT neuron indx 8131 [('template', 1.0), ('None', 0.8290284843164462), ('ndt', 0.8182920921449331), ('unicode', 0.816773304995129), ('NotFound', 0.7762487031898138)]
Top words for pretrained_BERT neuron indx 6088 [('enum', 1.0), ('value', 0.961623945160343), ('MSG', 0.9583918970583618), ('requests', 0.9232568018572935), ('ignore', 0.9174742765956267)]
Top words for pretrained_BERT neuron indx 2000 [('models', 1.0), ('val', 0.9229435616938553), ('objects', 0.8822109063843763), ('day', 0.813459701054454), ('iq', 0.8114284729596613)]
Top words for pretrained_BERT neuron indx 2005 [('Off', 1.0), ('body', 0.9648233508988319), ('log', 0.7290493209444423), ('Component', 0.7218515961206562), ('stanza', 0.7073915798347362)]
Top words for pretrained_BERT neuron indx 2009 [('pass', 1.0), ('300', 0.9973819842290575), ('task', 0.9054121958268675), ('models', 0.9048059749933244), ('reactor', 0.9024427615903385)]
Top words for pretrained_BERT neuron indx 8156 [('secs', 1.0), ('minutes', 0.9639066310716594), ('mins', 0.9208626731344628), ('80', 0.9026939667095008), ('upper', 0.8846028675160786)]
Top words for pretrained_BERT neuron indx 4074 [('Register', 1.0), ('class', 0.9438670067860047), ('register', 0.9385873343890883), ('description', 0.9182646653700133), ('zone', 0.9107780501698916)]
Top words for pretrained_BERT neuron indx 4075 [('m', 1.0), ('Node', 0.9688490207899904), ('e', 0.9632927705050988), ('E', 0.9018793940316538), ('k', 0.8440742550031263)]
Top words for pretrained_BERT neuron indx 8172 [('or', 1.0), ('Board', 0.94747918368779), ('month', 0.9454066973838849), ('Plugin', 0.943462878064931), ('send', 0.9428561669136386)]
Top words for pretrained_BERT neuron indx 4079 [('filename', 1.0), ('800', 0.9738699891161512), ('i', 0.9480693686370713), ('settings', 0.8927141003125071), ('raise', 0.8412039761422428)]
Top words for pretrained_BERT neuron indx 8178 [('int', 1.0), ('domain', 0.9495678091737518), ('zone', 0.918667176167388), ('connection', 0.8798208709273351), ('us', 0.8547838022757294)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0105
Epoch: [2/10], Loss: 0.0068
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0038
Epoch: [5/10], Loss: 0.0032
Epoch: [6/10], Loss: 0.0027
Epoch: [7/10], Loss: 0.0028
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0023
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.65
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0103
Epoch: [2/10], Loss: 0.0066
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0039
Epoch: [5/10], Loss: 0.0032
Epoch: [6/10], Loss: 0.0027
Epoch: [7/10], Loss: 0.0027
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0022
Score (accuracy) of the probe: 0.65
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0104
Epoch: [2/10], Loss: 0.0065
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0039
Epoch: [5/10], Loss: 0.0035
Epoch: [6/10], Loss: 0.0030
Epoch: [7/10], Loss: 0.0030
Epoch: [8/10], Loss: 0.0028
Epoch: [9/10], Loss: 0.0026
Epoch: [10/10], Loss: 0.0025
Score (accuracy) of the probe: 0.65
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0114
Epoch: [2/10], Loss: 0.0079
Epoch: [3/10], Loss: 0.0058
Epoch: [4/10], Loss: 0.0051
Epoch: [5/10], Loss: 0.0045
Epoch: [6/10], Loss: 0.0041
Epoch: [7/10], Loss: 0.0043
Epoch: [8/10], Loss: 0.0042
Epoch: [9/10], Loss: 0.0039
Epoch: [10/10], Loss: 0.0039
Score (accuracy) of the probe: 0.64

The best l1=0, the best l2=0 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.17
{'__OVERALL__': 0.16895874263261296, 'NAME': 0.17218543046357615, 'STRING': 0.1276595744680851, 'NUMBER': 0.07291666666666667, 'KEYWORD': 0.33613445378151263}
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.30

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.5500982318271119
----------------------------------------------------------------
