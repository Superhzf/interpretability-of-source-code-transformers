Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
7656 13.0
Number of tokens:  72951
length of source dictionary:  5099
length of target dictionary:  42
72951
Total instances: 72951
['Protocol_unreachable_error', 'pt1', 'REPORTS_ENABLED', 'DistrictShapeFile', 'FILENAME_LEN', 'is_set', 'splitLine', 'r', 'get_remote', 'reddit', 'RedditUser', '1023', 'rds_security_group', 'firstitem', 'trustWrapper', 'es_domain', '"*"', 'UnregisterHandler', 'storage_backend_timeout', 'utcfromtimestamp']
Number of samples:  72951
Stats: Labels with their frequencies in the final set
NAME 23204
NEWLINE 6586
DOT 5889
LPAR 5444
RPAR 5263
KEYWORD 5018
COMMA 4364
EQUAL 3897
COLON 2622
DEDENT 1878
INDENT 1593
NUMBER 1356
LSQB 1291
RSQB 1267
NL 1069
STRING 550
LBRACE 293
EQEQUAL 226
RBRACE 211
PLUS 200
PERCENT 109
STAR 94
MINUS 83
AT 61
DOUBLESTAR 60
GREATER 59
PLUSEQUAL 52
NOTEQUAL 44
LEFTSHIFT 31
LESS 29
LESSEQUAL 18
COMMENT 15
GREATEREQUAL 15
SEMI 13
VBAR 12
SLASH 11
TILDE 7
ELLIPSIS 6
AMPER 5
MINEQUAL 3
ERRORTOKEN 2
RIGHTSHIFT 1
pretrained_BERT distribution after trauncating:
{0: 0.7701805629314923, 3: 0.16655602761550717, 2: 0.045007966011683484, 1: 0.01825544344131705}
{0: 23204, 3: 5018, 2: 1356, 1: 550}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
5985 13.0
Number of tokens:  64699
length of source dictionary:  3727
length of target dictionary:  42
64699
Total instances: 64699
['orig_index', 'elsize', 'scaler', 'mname', 'set_printoptions', 'uniform', 'pdTimeStamp', 'struct', 'str', 'ln_gauss_seidel', '#f(t,y_t,y_(t-1),X)', 'testmod', 'TestElemwiseMergeLayerMul', 'cmean', 'rcp6', 'assertNotEqual', 'fd_desc2', 'forward_pass', 'r', 'beta_regr']
Number of samples:  64699
Stats: Labels with their frequencies in the final set
NAME 20893
NEWLINE 5444
DOT 5083
COMMA 4481
RPAR 4279
LPAR 4277
KEYWORD 3639
EQUAL 3459
NUMBER 2218
COLON 1972
LSQB 1939
RSQB 1927
DEDENT 1387
INDENT 1203
NL 540
STRING 324
MINUS 262
PLUS 248
STAR 236
EQEQUAL 141
LBRACE 128
RBRACE 126
SLASH 122
PERCENT 69
DOUBLESTAR 55
PLUSEQUAL 50
GREATER 47
NOTEQUAL 32
COMMENT 22
LESS 20
STAREQUAL 16
GREATEREQUAL 16
AT 10
MINEQUAL 7
SEMI 7
VBAR 6
LESSEQUAL 5
AMPER 3
SLASHEQUAL 2
DOUBLESLASH 2
TILDE 1
LEFTSHIFT 1
pretrained_BERT distribution after trauncating:
{0: 0.7716997857723277, 3: 0.134409396468937, 2: 0.08192361675408141, 1: 0.011967201004653911}
{0: 20893, 3: 3639, 2: 2218, 1: 324}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 23204, 3: 5018, 2: 1356, 1: 550})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({0: 1963, 2: 336, 1: 21})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (27115, 9984)
The shape of the validation set: (3013, 9984)
The shape of the testing set: (2320, 9984)
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0012
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0001
Epoch: [4/10], Loss: 0.0000
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0012
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0001
Epoch: [4/10], Loss: 0.0000
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0013
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0024
Epoch: [2/10], Loss: 0.0020
Epoch: [3/10], Loss: 0.0011
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0.001 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.97
{'__OVERALL__': 0.975, 'NAME': 0.9740193581253184, 'STRING': 1.0, 'NUMBER': 0.9791666666666666, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0035
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0033
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0012
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.97
{'__OVERALL__': 0.9741379310344828, 'NAME': 0.9724910850738665, 'STRING': 1.0, 'NUMBER': 0.9821428571428571, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0035
Epoch: [2/10], Loss: 0.0011
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0011
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0005
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0038
Epoch: [2/10], Loss: 0.0013
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0007
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0048
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.97
{'__OVERALL__': 0.9741379310344828, 'NAME': 0.9699439633214467, 'STRING': 1.0, 'NUMBER': 0.9970238095238095, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0012
Epoch: [3/10], Loss: 0.0007
Epoch: [4/10], Loss: 0.0005
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0012
Epoch: [3/10], Loss: 0.0007
Epoch: [4/10], Loss: 0.0005
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0038
Epoch: [2/10], Loss: 0.0014
Epoch: [3/10], Loss: 0.0009
Epoch: [4/10], Loss: 0.0007
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0049
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0022
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.95
{'__OVERALL__': 0.95, 'NAME': 0.9444727457972492, 'STRING': 1.0, 'NUMBER': 0.9791666666666666, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0011
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0011
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0012
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.94
{'__OVERALL__': 0.9392241379310344, 'NAME': 0.9363219561895059, 'STRING': 1.0, 'NUMBER': 0.9523809523809523, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0034
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0034
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0035
Epoch: [2/10], Loss: 0.0012
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0005
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0047
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.95
{'__OVERALL__': 0.9517241379310345, 'NAME': 0.9510952623535405, 'STRING': 1.0, 'NUMBER': 0.9523809523809523, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0034
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0034
Epoch: [2/10], Loss: 0.0011
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0013
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0007
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0047
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0020
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.97

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.94
{'__OVERALL__': 0.944396551724138, 'NAME': 0.9414161996943454, 'STRING': 1.0, 'NUMBER': 0.9583333333333334, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0033
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0034
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0034
Epoch: [2/10], Loss: 0.0012
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0005
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0045
Epoch: [2/10], Loss: 0.0025
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.96
{'__OVERALL__': 0.9556034482758621, 'NAME': 0.9500764136525726, 'STRING': 1.0, 'NUMBER': 0.9851190476190477, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0031
Epoch: [2/10], Loss: 0.0009
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0030
Epoch: [2/10], Loss: 0.0009
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0033
Epoch: [2/10], Loss: 0.0011
Epoch: [3/10], Loss: 0.0007
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0005
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0042
Epoch: [2/10], Loss: 0.0024
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0018
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.97
{'__OVERALL__': 0.9685344827586206, 'NAME': 0.9663779928680591, 'STRING': 1.0, 'NUMBER': 0.9791666666666666, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0030
Epoch: [2/10], Loss: 0.0008
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0031
Epoch: [2/10], Loss: 0.0009
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0031
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0007
Epoch: [4/10], Loss: 0.0005
Epoch: [5/10], Loss: 0.0005
Epoch: [6/10], Loss: 0.0004
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0022
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0018
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.97
{'__OVERALL__': 0.9672413793103448, 'NAME': 0.9648497198166073, 'STRING': 1.0, 'NUMBER': 0.9791666666666666, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0028
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0026
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0028
Epoch: [2/10], Loss: 0.0009
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0005
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0004
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0038
Epoch: [2/10], Loss: 0.0021
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0017
Epoch: [6/10], Loss: 0.0016
Epoch: [7/10], Loss: 0.0015
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.97
{'__OVERALL__': 0.9655172413793104, 'NAME': 0.9612837493632196, 'STRING': 0.8095238095238095, 'NUMBER': 1.0, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0029
Epoch: [2/10], Loss: 0.0008
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0031
Epoch: [2/10], Loss: 0.0009
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0031
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0007
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0005
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0023
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0018
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0013
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.97
{'__OVERALL__': 0.9737068965517242, 'NAME': 0.9709628120224146, 'STRING': 0.8095238095238095, 'NUMBER': 1.0, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0032
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0031
Epoch: [2/10], Loss: 0.0010
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0032
Epoch: [2/10], Loss: 0.0012
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0005
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0044
Epoch: [2/10], Loss: 0.0025
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0017
Epoch: [8/10], Loss: 0.0016
Epoch: [9/10], Loss: 0.0015
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.96
{'__OVERALL__': 0.959051724137931, 'NAME': 0.9526235354049923, 'STRING': 0.9047619047619048, 'NUMBER': 1.0, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0014
Epoch: [3/10], Loss: 0.0008
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0005
Epoch: [6/10], Loss: 0.0004
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0014
Epoch: [3/10], Loss: 0.0009
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0005
Epoch: [6/10], Loss: 0.0004
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0038
Epoch: [2/10], Loss: 0.0015
Epoch: [3/10], Loss: 0.0010
Epoch: [4/10], Loss: 0.0008
Epoch: [5/10], Loss: 0.0007
Epoch: [6/10], Loss: 0.0006
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0049
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0022
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0019
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0016
Epoch: [10/10], Loss: 0.0015
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.95
{'__OVERALL__': 0.9456896551724138, 'NAME': 0.9373408048904738, 'STRING': 0.9047619047619048, 'NUMBER': 0.9970238095238095, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.85

pretrained_BERT top neurons
array([8204, 6162, 2067, 6170, 6172,   35, 2086,   40, 6189,   48, 8241,
       4148, 4151, 8256, 2116, 2119, 8265, 2124, 4179,   91, 4190, 6240,
         99, 2152, 8303, 6258, 2169,  122, 2171,  127, 2177, 8330, 6286,
       6287,  146, 6305, 8357,  170, 2221, 2231,  183, 4284, 2239,  196,
        201, 6360, 2270, 8415,  225, 6369, 2281, 8426, 8434, 8435, 8436,
        246, 4343, 8442, 4350, 2307,  262, 4360,  268,  272, 8466,  279,
       8476, 6429,  286, 8488,  297,  300,  302, 6460,  317,  319, 8523,
        333, 6489,  350, 6500,  357, 2426, 6524, 8572, 2430,  383,  385,
       6530,  395, 2450, 2452,  410, 8609, 6563,  422, 6568,  429, 6573,
       6578,  436, 6580, 6586, 4539, 2494,  447,  460, 6617, 4576, 6626,
       2531,  485, 4585, 8682, 4586, 4596, 6647, 8695, 8697, 6654,  512,
       6664, 8713, 2576, 8721, 4627, 8724,  532, 4634,  538,  540, 8733,
        551, 2604, 8753, 8767, 6719, 4679,  583, 6732, 4686, 6735, 8793,
        604, 8798, 6751, 4704,  615, 4713,  619, 4717,  623,  624,  635,
       4734, 8834, 6797, 6798, 4751, 8848,  658,  672, 6821, 8869,  679,
        682,  686,  689, 8884, 8890, 2748,  701, 8915, 2773,  726, 6870,
        725, 8924,  734, 4840,  745, 2800, 8968, 6930, 6940, 8998, 6952,
        808, 4916, 6967, 4933, 2887, 4936, 9033, 4939, 6989, 6998, 7008,
       9064,  880, 7026, 4979, 7031, 2937, 4993,  898, 2945, 2955, 9100,
       5005, 7054, 7076,  937,  939, 9133,  941, 2999,  951, 3003, 5052,
       5055, 3007, 7119, 7128, 3043, 7144, 9194, 1003, 9204, 1012, 1014,
       5118, 9217, 1030, 5128, 7177, 1040, 9234, 7191, 3098, 7197, 7203,
       3112, 1065, 1068, 7217, 7220, 1076, 1085, 7257, 1118, 9312, 3178,
       7279, 5239, 1148, 9340, 3198, 3199, 1153, 7298, 7312, 9366, 1178,
       7331, 1196, 7346, 9394, 1204, 5309, 1215, 1241, 3299, 7395, 1253,
       9450, 7410, 3316, 9472, 9477, 7432, 3344, 5394, 1299, 9495, 7450,
       5404, 9506, 1319, 5417, 3372, 7471, 9521, 3378, 3380, 1333, 3384,
       5435, 7488, 1345, 1348, 1351, 7497, 3402, 9560, 9563, 3422, 5472,
       7522, 1387, 9586, 5490, 5492, 9590, 1401, 5499, 1404, 1403, 5502,
       3457, 9602, 7560, 7564, 5518, 3472, 3482, 7589, 1447, 1454, 3508,
       3516, 1469, 1471, 5578, 1492, 1494, 9692, 7648, 1504, 1506, 5606,
       7667, 7668, 7674, 7720, 1576, 9772, 5684, 3655, 1614, 9811, 9812,
       7764, 5720, 5726, 7776, 9832, 1645, 7794, 5747, 3705, 7804, 1662,
       7807, 1663, 5761, 1666, 9859, 7823, 1684, 7832, 3737, 7841, 9893,
       1705, 7849, 3757, 9901, 5812, 7862, 9910, 3771, 1729, 9929, 7886,
       7912, 3817, 7914, 1771, 9962, 1780, 9972, 9981, 5886, 7941, 7945,
       1808, 7956, 3868, 7965, 1826, 1836, 1853, 7999, 3911, 8024, 1884,
       1886, 5999, 6013, 3966, 1921, 8070, 6029, 8077, 6032, 8080, 1937,
       1940, 8091, 8102, 8104, 8116, 1999, 2005, 6102, 2007, 2009, 6121,
       4079, 6132])
pretrained_BERT top neurons per class
{'NAME': array([ 225, 7674, 2887, 8442, 9450, 1153, 6489, 7965, 8523, 1454, 3655,
       4634, 1253, 8436, 1003,  460, 9204,  623, 1299, 8793, 4190, 1204,
       3757, 7054,  679, 9901, 6617, 4350, 4539, 9477,  268, 2152, 4585,
        127, 6172, 3457, 8466, 3402, 4343, 5578,  604, 2119, 1148, 7119,
       8733, 7008, 6821, 9472, 7668,  436, 8724, 3422,  350, 1826,  385,
       1662, 8767,  689, 6102, 4627, 3771, 9521, 7914, 6240, 7648, 7220,
       2937, 6287, 6460, 4079, 7279, 6170, 1030, 7956,  726, 5417, 1921,
       9832, 7217,  672, 5118, 2999, 9981, 7807, 1065, 8834, 3112,  880,
       7999, 4179, 2231, 6369, 8924, 7497, 7177, 1085, 7804, 7191, 6013,
       6029, 6162,  183, 6952, 9100, 1494, 5239, 3817, 8713, 2307, 8488,
       8024, 8682, 6930, 7589, 4284, 8357,  422, 5052, 5404, 8265, 1076,
       6132,   40, 3508,  624, 3705, 1666, 1178, 1771, 1469, 5394, 7346,
       1447, 5684, 9234,  635, 8915, 8415,  951,  262, 2169, 8697, 7720,
       5518, 3299,  196, 3966, 4151, 6647]), 'STRING': array([ 225, 7776, 1241,  385,  538, 7667, 9477, 1884, 7128, 8713,  672,
       9033, 6940, 6489, 5606, 8436, 7668,  701, 1469, 9100, 2007, 2009,
       4360, 9893, 4627, 8793,   40, 9901, 1808,  808, 1401, 5055,  512,
       2887, 2169, 3422, 5472, 5309, 1666,  937, 8968,  436, 7008, 2067,
       7471, 6664, 3457, 4585, 7941, 9586,  383, 1299, 9194, 6998, 9563,
       6305, 8869, 2748, 7832, 1663, 6798, 3003, 5239, 8798,  262, 4704,
        485, 9811, 7031, 4586, 6360, 7177,  726, 2221,  357, 7257, 7945,
       4284, 6952, 9962, 8721, 6172, 1684, 8204,  246, 1333, 4713, 8070,
       8609, 7191, 3380, 2937, 5490, 8476, 8435, 1886, 7965, 4148, 6524,
       8848, 7432,  268, 6870, 4916, 8442,   48, 2452,  395, 4933, 3757,
       7823, 4751, 9859, 2576,  635, 3199,  297, 9133, 1118,  658,  460,
       7560, 4576, 6032, 3516, 6735, 8426, 9472, 6563, 8080, 3868, 5499,
       1153, 5128, 7841, 7674, 9692, 8434, 7450, 5005, 6240,  540, 4939]), 'NUMBER': array([7965, 7956, 6870, 1826, 4704, 8442, 5999,  623, 2086, 7119, 1836,
        635, 2887, 3655, 8572, 7804, 7522, 9394, 9366, 7331, 7674, 7564,
       9602, 7197, 2604, 2005, 7807, 8733, 7410,  225, 3482, 8330,  551,
       6102, 1506, 9450, 7312, 6489,  485, 1387, 3178, 4627, 4686,  615,
       7217, 5761, 1403, 3457, 1068, 3098, 9772, 3911,  410, 9495, 8523,
       8256, 3372, 7886, 1780, 9812,  532, 1705, 1645, 5747, 3757, 1663,
        146, 1940, 2999, 9521, 6751, 1404,  300, 6578, 7794, 9340, 7076,
       2231, 4840, 6429, 7999,  127,  279, 4539, 6989, 3299, 1447, 2450,
       9832, 3472, 6360, 4979, 8466, 8303, 6240, 6258,  385, 8998, 3378,
        941, 1012, 8924, 2531, 7298, 3771, 3737, 8724, 8834, 2221, 1196,
        937, 7026,  286, 1471, 1153, 8077, 9506, 2124, 6189,  682, 4679,
       1253, 9100, 1999, 3316, 8091, 7912, 2171,  170, 7144, 7488, 2430,
       4993, 4936,  939, 9929, 1319, 1614, 9217, 9064, 6530, 7128, 7862,
       6732]), 'KEYWORD': array([ 122, 6489, 2887, 1351, 1085, 8793, 1348, 8695, 4350, 8523, 6797,
       4585, 7257,  429, 6162, 3112,  624, 8767, 1345, 3402, 9450, 9901,
        734, 6029, 7914, 6568,  583, 1040, 8572, 1118, 6580, 3043, 9981,
        447,  317, 7220, 6586,  898, 5684, 9972, 6930, 2119, 7764, 7965,
       8024, 2945,  808, 6121,  201,  302, 1937, 7956, 6500, 2239, 2773,
       8869, 6719, 8884, 6286, 1215, 5720,  333, 9394, 5502, 7191, 5492,
       1853,  272, 2494, 8116,  686, 2116, 7432, 9560, 8890, 1471, 2426,
       3966, 5726, 3508, 6654,  551, 1662, 4734, 3384, 4916, 2177, 3007,
       4717,  319, 6967, 2009, 8713, 1014, 9910,   35, 1576, 7720, 3344,
       1387,  726, 8104, 2270, 6170,  350,  619, 2800, 7395, 5239, 5435,
       2955, 5812, 5578, 6573, 1241,  745,   91, 9590, 8753, 8102, 3098,
       7648,  725,  604, 2281, 7849, 7203, 1886, 8241, 4151, 1204, 1492,
       3198, 5417, 6626, 9312, 1504,  225,   99, 5128, 6013, 4704, 1729,
       4596, 5886])}
The shape of selected features (27115, 431)
The shape of the training set: (27115, 431)
The shape of the validation set: (3013, 431)
The shape of the testing set: (2320, 431)
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0027
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0028
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0028
Epoch: [2/10], Loss: 0.0008
Epoch: [3/10], Loss: 0.0006
Epoch: [4/10], Loss: 0.0005
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0004
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0021
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0017
Epoch: [6/10], Loss: 0.0017
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0015
Epoch: [9/10], Loss: 0.0014
Epoch: [10/10], Loss: 0.0014
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.98
{'__OVERALL__': 0.9836206896551725, 'NAME': 0.9842078451349975, 'STRING': 0.8571428571428571, 'NUMBER': 0.9880952380952381, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.85
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0047
Epoch: [2/10], Loss: 0.0016
Epoch: [3/10], Loss: 0.0010
Epoch: [4/10], Loss: 0.0008
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0045
Epoch: [2/10], Loss: 0.0016
Epoch: [3/10], Loss: 0.0010
Epoch: [4/10], Loss: 0.0008
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0048
Epoch: [2/10], Loss: 0.0018
Epoch: [3/10], Loss: 0.0012
Epoch: [4/10], Loss: 0.0010
Epoch: [5/10], Loss: 0.0009
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0055
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0027
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0017
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.96
{'__OVERALL__': 0.9633620689655172, 'NAME': 0.9709628120224146, 'STRING': 0.7619047619047619, 'NUMBER': 0.9315476190476191, 'KEYWORD': nan}
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.85
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 8204 [('within', 1.0), ('python', 0.9242238279843265), ('each', 0.8714714821295653), ('is_cover', 0.8707171856558961), ('DSIZE', 0.8277134843424085)]
Top words for pretrained_BERT neuron indx 6162 [('plural', 1.0), ('LOGGING', 0.9970685225025668), ('synchronized', 0.9656038486436614), ('Q', 0.9482511828261346), ('queue', 0.9418051046804924)]
Top words for pretrained_BERT neuron indx 2067 [('REFERENCES', 1.0), ('RELATIONS', 0.9641964744824425), ('math', 0.9485336702278884), ('int', 0.8436194838583023), ('char', 0.8290097694951031)]
Top words for pretrained_BERT neuron indx 6170 [('ip', 1.0), ('geventclient', 0.9725251215624956), ('services', 0.9181430139843267), ('excepts', 0.9159802194156649), ('detect', 0.9121448530810525)]
Top words for pretrained_BERT neuron indx 6172 [('imports', 1.0), ('loads', 0.9728221655700899), ('after', 0.9377245372662962), ('Bytes', 0.9074599936711043), ('intersects', 0.8938751207713025)]
Top words for pretrained_BERT neuron indx 35 [('res', 1.0), ('el', 0.9754866788466467), ('composite', 0.9517136319056839), ('visitor', 0.9216020310965175), ('reservations', 0.9142660271258217)]
Top words for pretrained_BERT neuron indx 2086 [('button', 1.0), ('feed', 0.9736771700692569), ('security', 0.953189349346409), ('exists', 0.9193327383037136), ('GENERATOR', 0.9130795042424106)]
Top words for pretrained_BERT neuron indx 40 [('Int', 1.0), ('tasks', 0.9962747789968225), ('Asset', 0.990756579535864), ('asset', 0.9647060745246439), ('level', 0.9623502789296592)]
Top words for pretrained_BERT neuron indx 6189 [('21', 1.0), ('20', 0.780884835196995), ('Plan', 0.7586197975259485), ('31', 0.7495834219206574), ('28', 0.7437151223090007)]
Top words for pretrained_BERT neuron indx 48 [('var', 1.0), ('register', 0.8207394104798431), ('reservations', 0.8179704439847492), ('Register', 0.7741172579847889), ('PIECE', 0.7547574616297573)]
Top words for pretrained_BERT neuron indx 8241 [('LookingGlass', 1.0), ('milliseconds', 0.9606786929827097), ('discovery', 0.9601216194226623), ('abstractmethod', 0.9133917892795586), ('ts', 0.8867848000493151)]
Top words for pretrained_BERT neuron indx 4148 [('is', 1.0), ('in', 0.9580935476129431), ('and', 0.9415331943021562), ('with', 0.8736419261524078), ('_', 0.7914017387117268)]
Top words for pretrained_BERT neuron indx 4151 [('purpose', 1.0), ('bindings', 0.9091127309313511), ('notify', 0.8999981100320714), ('zipa', 0.8908983081995041), ('microseconds', 0.8713076451851528)]
Top words for pretrained_BERT neuron indx 8256 [('slug', 1.0), ('plural', 0.852736826328184), ('vCard', 0.8501068575824026), ('Provider', 0.8383036649563319), ('count', 0.8188240510891144)]
Top words for pretrained_BERT neuron indx 2116 [('incoming', 1.0), ('permission', 0.7685751168903033), ('Variable', 0.7477419861759309), ('parents', 0.7414761897588518), ('lambda', 0.7380953115822771)]
Top words for pretrained_BERT neuron indx 2119 [('Exception', 1.0), ('agency', 0.9479092852632858), ('exception', 0.80129722625197), ('Stream', 0.7993955506106709), ('Action', 0.7914986509933154)]
Top words for pretrained_BERT neuron indx 8265 [('pattern', 1.0), ('oslo', 0.9945559580839056), ('glob', 0.9542616554027264), ('465', 0.9539279841672678), ('south', 0.9508998546132621)]
Top words for pretrained_BERT neuron indx 2124 [('sorted', 1.0), ('alt', 0.9280479311868085), ('select', 0.9188052546534924), ('visit', 0.8814750082654372), ('Integer', 0.8552318772470565)]
Top words for pretrained_BERT neuron indx 4179 [('scheme', 1.0), ('CANCEL', 0.9851656247814372), ('zope', 0.8622434281299021), ('file', 0.842156305740939), ('initial', 0.7960486468972533)]
Top words for pretrained_BERT neuron indx 91 [('Cat', 1.0), ('fin', 0.9409327705494515), ('meta', 0.9401264085485999), ('assets', 0.9334330574935678), ('send', 0.9028994515175539)]
Top words for pretrained_BERT neuron indx 4190 [('secret', 1.0), ('timezone', 0.9099833931346114), ('unicode', 0.8686629722564346), ('walker', 0.8629411769377049), ('active', 0.8278369390503423)]
Top words for pretrained_BERT neuron indx 6240 [('95', 1.0), ('31', 0.9436665504447316), ('decimal', 0.9218249132619342), ('forms', 0.8961200380762467), ('tls', 0.8914672811504829)]
Top words for pretrained_BERT neuron indx 99 [('Migration', 1.0), ('File', 0.9798153721224965), ('file', 0.9363947664258304), ('commit', 0.9360950605278345), ('signal', 0.9260534280830361)]
Top words for pretrained_BERT neuron indx 2152 [('null', 1.0), ('us', 0.9829769991847541), ('local', 0.9822648389074264), ('purpose', 0.9676555101049436), ('raises', 0.9542754691537395)]
Top words for pretrained_BERT neuron indx 8303 [('ah', 1.0), ('transfer', 0.9867081142110483), ('convert', 0.9755262053677559), ('after', 0.9683580965626912), ('level', 0.9014229857667162)]
Top words for pretrained_BERT neuron indx 6258 [('google', 1.0), ('available', 0.9824044557190683), ('256', 0.981551172026597), ('button', 0.96476157564517), ('kind', 0.9445681088384213)]
Top words for pretrained_BERT neuron indx 2169 [('common', 1.0), ('999999', 0.9365068094829186), ('3128', 0.8942876477232554), ('INFO', 0.8348451788043925), ('Presence', 0.8310372363079973)]
Top words for pretrained_BERT neuron indx 122 [('convert', 1.0), ('CardOperation', 0.9184003719752896), ('Card', 0.7730782884149157), ('Schedule', 0.738315426392022), ('fin', 0.7311449989604003)]
Top words for pretrained_BERT neuron indx 2171 [('Venue', 1.0), ('signed', 0.9618257641892742), ('ALPHABET', 0.8841561312029741), ('venue', 0.8731197540217656), ('events', 0.8255476413021567)]
Top words for pretrained_BERT neuron indx 127 [('unicode', 1.0), ('apache', 0.8028281166088483), ('http', 0.7865863598544265), ('HorizontalBillboard', 0.6992102921326016), ('flags', 0.6954539152559214)]
Top words for pretrained_BERT neuron indx 2177 [('flags', 1.0), ('m', 0.9609797288809692), ('sites', 0.9125214111476315), ('SpatialReference', 0.8935847052277174), ('st', 0.8905515809811825)]
Top words for pretrained_BERT neuron indx 8330 [('ip', 1.0), ('backwards', 0.7812083862995237), ('severity', 0.7668328388569979), ('xml', 0.7606634555161357), ('Prefix', 0.7181329921229751)]
Top words for pretrained_BERT neuron indx 6286 [('ORIGIN', 1.0), ('values', 0.9473437538189363), ('origin', 0.9390124826298993), ('Origin', 0.923462912520286), ('tasks', 0.9200615262127106)]
Top words for pretrained_BERT neuron indx 6287 [('flash', 1.0), ('credentials', 0.7877207753289188), ('secure', 0.6978883826429408), ('Card', 0.6896671432600854), ('Unauthorized', 0.6778055496756731)]
Top words for pretrained_BERT neuron indx 146 [('count', 1.0), ('iq', 0.9868819403769863), ('purge', 0.9852677692058963), ('nsa', 0.9841516734138998), ('dom', 0.965934960125078)]
Top words for pretrained_BERT neuron indx 6305 [('variables', 1.0), ('opener', 0.8555858024757546), ('False', 0.8279348210521409), ('Variable', 0.8126700651815223), ('exists', 0.7546445711727324)]
Top words for pretrained_BERT neuron indx 8357 [('multiple', 1.0), ('unique', 0.8815546532125669), ('if', 0.8687723038588823), ('keep', 0.8642143036957313), ('top', 0.8317796183446925)]
Top words for pretrained_BERT neuron indx 170 [('labels', 1.0), ('sublime', 0.8662634470408287), ('Container', 0.8478913170802679), ('100', 0.8277178594123562), ('quality', 0.8085995358373855)]
Top words for pretrained_BERT neuron indx 2221 [('title', 1.0), ('page', 0.982260001776196), ('600', 0.969022657179658), ('archive', 0.9116930215056068), ('500', 0.8705756640828791)]
Top words for pretrained_BERT neuron indx 2231 [('path', 1.0), ('accounts', 0.993761749797129), ('cache', 0.9597986184623118), ('tree', 0.940492703509016), ('Command', 0.8880008420916726)]
Top words for pretrained_BERT neuron indx 183 [('reverse', 1.0), ('Dummy', 0.8911789937400132), ('create', 0.8598589859128605), ('discovery', 0.8568447021407162), ('Update', 0.8174858051479292)]
Top words for pretrained_BERT neuron indx 4284 [('df', 1.0), ('sr', 0.9568423219275324), ('id', 0.9476500560421774), ('B', 0.9270391866218501), ('do', 0.9201898123406719)]
Top words for pretrained_BERT neuron indx 2239 [('mac', 1.0), ('db', 0.9893878878409804), ('List', 0.9378818216618927), ('os', 0.89887479758559), ('list', 0.8909925766717646)]
Top words for pretrained_BERT neuron indx 196 [('exception', 1.0), ('Exception', 0.9178513960371981), ('strict', 0.9161817949321412), ('lines', 0.9143973848321733), ('upgrade', 0.9101444829922885)]
Top words for pretrained_BERT neuron indx 201 [('limit', 1.0), ('confirm', 0.9669585948756225), ('cover', 0.9396976422859102), ('flat', 0.9367986844166324), ('typeof', 0.9342886707217173)]
Top words for pretrained_BERT neuron indx 6360 [('unique', 1.0), ('sim', 0.8195347396604383), ('loading', 0.8122644084660916), ('hidden', 0.7391442405701494), ('with', 0.6766963518020519)]
Top words for pretrained_BERT neuron indx 2270 [('stream', 1.0), ('division', 0.9827999766473875), ('zone', 0.9634261049670252), ('horizon', 0.9604892913295143), ('bus', 0.9513020394016531)]
Top words for pretrained_BERT neuron indx 8415 [('insert', 1.0), ('Model', 0.9869547620818563), ('Simulator', 0.8603489777550062), ('Manager', 0.8111892396448213), ('manager', 0.7913267515970883)]
Top words for pretrained_BERT neuron indx 225 [('9', 1.0), ('8', 0.821343872750199), ('7', 0.8118269688226194), ('MULTILINE', 0.7330659959781531), ('jtype', 0.6912569030468595)]
Top words for pretrained_BERT neuron indx 6369 [('Cat', 1.0), ('wait', 0.9807620115837293), ('listen', 0.9760922831464507), ('FSM', 0.949135668238491), ('Int', 0.937783579779541)]
Top words for pretrained_BERT neuron indx 2281 [('j', 1.0), ('Presence', 0.9096659737702542), ('1', 0.8590767162285436), ('presence', 0.8521022012268441), ('p', 0.848303091945106)]
Top words for pretrained_BERT neuron indx 8426 [('flat', 1.0), ('strict', 0.7020008344127489), ('DEFLATED', 0.685117541648026), ('five', 0.6711084247993954), ('blank', 0.6504813571392886)]
Top words for pretrained_BERT neuron indx 8434 [('cid', 1.0), ('sid', 0.9834361951998828), ('ts', 0.9777569824797137), ('el', 0.9488758848447756), ('five', 0.9220116968596059)]
Top words for pretrained_BERT neuron indx 8435 [('Variable', 1.0), ('VALUE', 0.8743619981232833), ('bindings', 0.8730652493638942), ('Frame', 0.8416904285522222), ('95', 0.8380129803757697)]
Top words for pretrained_BERT neuron indx 8436 [('"FAILED"', 1.0), ('"SUCCEEDED"', 0.8900055088794088), ('Watcher', 0.8797025737378146), ('17', 0.8784408160441075), ('descriptor', 0.8757553038646937)]
Top words for pretrained_BERT neuron indx 246 [('register', 1.0), ('remember', 0.9216979259695961), ('Register', 0.9015766321050053), ('choice', 0.8790982204496437), ('levels', 0.8279990154420837)]
Top words for pretrained_BERT neuron indx 4343 [('1800', 1.0), ('Geo', 0.7632471558954329), ('300', 0.7462382117776953), ('600', 0.7185806913248404), ('204', 0.6989024270133778)]
Top words for pretrained_BERT neuron indx 8442 [('y', 1.0), ('U', 0.8372187284967803), ('IFile', 0.7773080900926451), ('five', 0.7642579807979517), ('fifteen', 0.7621028361926403)]
Top words for pretrained_BERT neuron indx 4350 [('TRANSITIVE', 1.0), ('unquote', 0.9462776042387118), ('","', 0.901968573027143), ('"key"', 0.8986367605979837), ('RELATIONS', 0.8847516624996645)]
Top words for pretrained_BERT neuron indx 2307 [('changed', 1.0), ('fragment', 0.9326401182883681), ('ProcessingState', 0.9226810110375102), ('pisa', 0.9182633941486372), ('MINIMUM', 0.9123694780840106)]
Top words for pretrained_BERT neuron indx 262 [('select', 1.0), ('reflection', 0.9523865169602344), ('fixture', 0.9090471433104995), ('abstract', 0.8595446704927885), ('identity', 0.8487051366009081)]
Top words for pretrained_BERT neuron indx 4360 [('pop', 1.0), ('con', 0.8826689638113365), ('choice', 0.8085958240693961), ('window', 0.7803813152709471), ('unique', 0.7695077259197559)]
Top words for pretrained_BERT neuron indx 268 [('else', 1.0), ('Else', 0.9588943184734883), ('twisted', 0.9579877934252418), ('ax', 0.9559579626763571), ('mode', 0.8978970012167867)]
Top words for pretrained_BERT neuron indx 272 [('license', 1.0), ('prop', 0.9912670929460562), ('materials', 0.926214730039012), ('broker', 0.8762485283506134), ('processes', 0.8601007300499858)]
Top words for pretrained_BERT neuron indx 8466 [('Q', 1.0), ('ax', 0.8475649453650795), ('each', 0.8342744585745517), ('plural', 0.7740196636460129), ('realm', 0.7719710473481192)]
Top words for pretrained_BERT neuron indx 279 [('logging', 1.0), ('LOGGING', 0.9465222175547177), ('cache', 0.9158373608765842), ('Cached', 0.8700937603686891), ('targets', 0.8541225930039923)]
Top words for pretrained_BERT neuron indx 8476 [('20', 1.0), ('75', 0.8664697998575954), ('P2PServiceBaseType', 0.80163076237365), ('50', 0.7969163258122929), ('polygon', 0.7843648562328086)]
Top words for pretrained_BERT neuron indx 6429 [('42', 1.0), ('now', 0.9307022621645865), ('I', 0.9086360235814155), ('33', 0.8900747557761767), ('user_functions', 0.8541504927788364)]
Top words for pretrained_BERT neuron indx 286 [('clean', 1.0), ('96', 0.9129542052320992), ('Geo', 0.91196429490014), ('add', 0.8645306523795938), ('image', 0.8156008984990203)]
Top words for pretrained_BERT neuron indx 8488 [('labels', 1.0), ('Presence', 0.8564233921474297), ('management', 0.7483942112267266), ('seconds', 0.7276284854338047), ('south', 0.7193820365840564)]
Top words for pretrained_BERT neuron indx 297 [('char', 1.0), ('protocols', 0.9834372507928766), ('dir', 0.7599779308382267), ('protocol', 0.7075259273559521), ('op', 0.6856467459815314)]
Top words for pretrained_BERT neuron indx 300 [('reset', 1.0), ('el', 0.9792577814252117), ('reference', 0.9273702894489249), ('rd', 0.8901368437229923), ('sim', 0.8720425439142935)]
Top words for pretrained_BERT neuron indx 302 [('resolve', 1.0), ('bodies', 0.9368056235565905), ('Int', 0.9337277165602311), ('def', 0.9328309590804504), ('loading', 0.8178595984152535)]
Top words for pretrained_BERT neuron indx 6460 [('management', 1.0), ('now', 0.9250799073408442), ('listen', 0.8941038201242313), ('256', 0.8231347804826898), ('Repository', 0.7730331752905638)]
Top words for pretrained_BERT neuron indx 317 [('baseline', 1.0), ('scope', 0.8641317051110564), ('bk', 0.8140899525639063), ('TAGS', 0.812203979162059), ('tags', 0.8083011987048351)]
Top words for pretrained_BERT neuron indx 319 [('sp', 1.0), ('Simulator', 0.714446911093371), ('negotiate', 0.7143575938880486), ('detect', 0.6875314813231305), ('lb', 0.6732410004484355)]
Top words for pretrained_BERT neuron indx 8523 [('Clock', 1.0), ('os', 0.9978948518585127), ('HTTP_PORT', 0.9776247544249491), ('BlendProbes', 0.9760674869295526), ('33', 0.9448305703588327)]
Top words for pretrained_BERT neuron indx 333 [('ah', 1.0), ('Parent', 0.861310853839821), ('parent', 0.8475254924011039), ('tornado', 0.8151381232361554), ('sr', 0.8084545004802002)]
Top words for pretrained_BERT neuron indx 6489 [('BBOX', 1.0), ('IGP', 0.9982394940822653), ('orgs', 0.9700465431419245), ('Geo', 0.9696659962359845), ('IDLEN', 0.9599968330111417)]
Top words for pretrained_BERT neuron indx 350 [('Dummy', 1.0), ('chunks', 0.9013492431377127), ('Exception', 0.8747250735024032), ('rows', 0.8576156352806235), ('exceptions', 0.8368534486186628)]
Top words for pretrained_BERT neuron indx 6500 [('Column', 1.0), ('name', 0.9357004523890072), ('affinity', 0.8898844331649889), ('min', 0.8893736811264075), ('resolve', 0.8801712228616131)]
Top words for pretrained_BERT neuron indx 357 [('PROVISION', 1.0), ('tenant', 0.9544113162651017), ('provision', 0.9194349724575628), ('boot', 0.8585796064616471), ('contents', 0.8104340442173744)]
Top words for pretrained_BERT neuron indx 2426 [('submit', 1.0), ('criterion', 0.8341860305071305), ('patterns', 0.781670414654171), ('Card', 0.7696155518410156), ('Mesh', 0.7611759676867531)]
Top words for pretrained_BERT neuron indx 6524 [('42', 1.0), ('69', 0.8181456151057761), ('23', 0.8101668843414228), ('800', 0.7925607054279126), ('36', 0.7920292567027031)]
Top words for pretrained_BERT neuron indx 8572 [('scheme', 1.0), ('finally', 0.9514028262580023), ('agency', 0.8541279917757292), ('"sequence"', 0.8532500351175873), ('for', 0.8526523022384592)]
Top words for pretrained_BERT neuron indx 2430 [('BOUNDS', 1.0), ('Criteria', 0.9374631345615934), ('step', 0.8876839344293562), ('experiments', 0.8568119933399676), ('blank', 0.8336228909518761)]
Top words for pretrained_BERT neuron indx 383 [('MEMBER', 1.0), ('repeat', 0.989793445771708), ('permission', 0.8864809106714824), ('Label', 0.8789487323616477), ('SUCCESS', 0.8280390271328264)]
Top words for pretrained_BERT neuron indx 385 [('strings', 1.0), ('proxy', 0.9824826276307965), ('ax', 0.7699690205695144), ('filters', 0.766994879942656), ('reason', 0.75152894702593)]
Top words for pretrained_BERT neuron indx 6530 [('STATUS', 1.0), ('REFERENCES', 0.9398023376886094), ('first', 0.9066942425237513), ('SECONDS', 0.9066113504439389), ('quality', 0.9057668145286305)]
Top words for pretrained_BERT neuron indx 395 [('flush', 1.0), ('code', 0.8982601604602576), ('tempstore', 0.8889169136106125), ('File', 0.847826352377471), ('processors', 0.8401937260776042)]
Top words for pretrained_BERT neuron indx 2450 [('NODES', 1.0), ('NODE', 0.8544265543537494), ('rows', 0.8339549359650178), ('inverse', 0.8244774584633262), ('nsa', 0.8064984212715434)]
Top words for pretrained_BERT neuron indx 2452 [('hidden', 1.0), ('transform', 0.9978922027726169), ('abc', 0.9455694797958312), ('processes', 0.9354013660924186), ('project', 0.9217413098346423)]
Top words for pretrained_BERT neuron indx 410 [('auditor', 1.0), ('platform', 0.8633501688963212), ('Auditor', 0.8590820504713816), ('revision', 0.7978628513954251), ('transfer', 0.7559439846784493)]
Top words for pretrained_BERT neuron indx 8609 [('exists', 1.0), ('False', 0.9732390992469346), ('Cat', 0.9548357415938864), ('RegisterProtocol', 0.8724500049409051), ('pisa', 0.8717818202520026)]
Top words for pretrained_BERT neuron indx 6563 [('except', 1.0), ('if', 0.9941141724808136), ('with', 0.9772452534244025), ('bagpipe', 0.9123703249211271), ('_property', 0.8855833285928204)]
Top words for pretrained_BERT neuron indx 422 [('logging', 1.0), ('LOGGING', 0.9856469679166892), ('VALUE', 0.9435770398086607), ('def', 0.9420315444888814), ('Int', 0.9370494848267137)]
Top words for pretrained_BERT neuron indx 6568 [('ELEMENT', 1.0), ('RELATION', 0.8994838559672009), ('Tab', 0.8988525769388298), ('Widget', 0.8936590486421905), ('512', 0.8528719411222003)]
Top words for pretrained_BERT neuron indx 429 [('exception', 1.0), ('Exception', 0.970497281153701), ('blend', 0.9225386112451852), ('Filter', 0.9218365915570752), ('load', 0.9019527437480518)]
Top words for pretrained_BERT neuron indx 6573 [('finally', 1.0), ('.3', 0.8181166367483076), ('0.1', 0.8125294341607519), ('agency', 0.8102330917948263), ('2.1', 0.7645167751780576)]
Top words for pretrained_BERT neuron indx 6578 [('activate', 1.0), ('exit', 0.9886012172780927), ('advance', 0.9295645192786216), ('ur', 0.8682943346802191), ('begin', 0.852609488986408)]
Top words for pretrained_BERT neuron indx 436 [('Output', 1.0), ('props', 0.9672646394575567), ('unicode', 0.9242436130936981), ('exceptions', 0.9162515957440306), ('ORIGIN', 0.851918428389738)]
Top words for pretrained_BERT neuron indx 6580 [('relay', 1.0), ('form', 0.960277723490477), ('math', 0.8943327012371152), ('selection', 0.86575882419763), ('author', 0.8434344519865632)]
Top words for pretrained_BERT neuron indx 6586 [('ELEMENT', 1.0), ('flat', 0.9612167181424904), ('south', 0.9253760634434647), ('variable', 0.9106687841894321), ('word', 0.9019442233863593)]
Top words for pretrained_BERT neuron indx 4539 [('milliseconds', 1.0), ('K', 0.9054383480494612), ('microseconds', 0.8971129377563287), ('Tab', 0.8292273598290495), ('e', 0.8009693410660423)]
Top words for pretrained_BERT neuron indx 2494 [('quality', 1.0), ('patch', 0.9567045068343119), ('authorization', 0.8865414355460867), ('levels', 0.834851644443727), ('sans', 0.833172006872328)]
Top words for pretrained_BERT neuron indx 447 [('auditor', 1.0), ('Auditor', 0.9919914246371633), ('reservation', 0.9426536197254601), ('actions', 0.9149867153318724), ('Int', 0.86205113901275)]
Top words for pretrained_BERT neuron indx 460 [('reflection', 1.0), ('35', 0.9164826458580778), ('restart', 0.7879802379653351), ('MINIMUM', 0.7608585806253712), ('MAXIMUM', 0.7220858108854686)]
Top words for pretrained_BERT neuron indx 6617 [('ip', 1.0), ('Int', 0.9016180696633161), ('g', 0.7368564672355812), ('reflection', 0.7203647023620909), ('V', 0.7156201696825638)]
Top words for pretrained_BERT neuron indx 4576 [('extensions', 1.0), ('internet', 0.9368620445739643), ('Integer', 0.9118815256992212), ('registry', 0.9106955628623693), ('address', 0.8970186570121841)]
Top words for pretrained_BERT neuron indx 6626 [('100000', 1.0), ('81.4471435546875', 0.875293745482198), ('flat', 0.8387886416629037), ('omit', 0.8150523043956), ('set_up', 0.8126058564970723)]
Top words for pretrained_BERT neuron indx 2531 [('WAY', 1.0), ('Geo', 0.9216341940672981), ('Projector', 0.8725437269660629), ('simplify', 0.844209613329972), ('Logger', 0.8282798825944466)]
Top words for pretrained_BERT neuron indx 485 [('ports', 1.0), ('RELATIONS', 0.9762298478023852), ('Dataflow', 0.8745800715012046), ('string', 0.8685447172903109), ('STATUS', 0.8505744436579292)]
Top words for pretrained_BERT neuron indx 4585 [('j', 1.0), ('description', 0.6820438000200755), ('simulation', 0.65478743571777), ('Presence', 0.6299657331570775), ('shared', 0.605684312425917)]
Top words for pretrained_BERT neuron indx 8682 [('outgoing', 1.0), ('2014', 0.9803921229124154), ('forwards', 0.9760167741788731), ('incoming', 0.9495287609368865), ('NODES', 0.9458396841668734)]
Top words for pretrained_BERT neuron indx 4586 [('href', 1.0), ('last', 0.9611404714134778), ('upstream', 0.9295327526339902), ('lines', 0.9287156640123947), ('spawn', 0.9111621809860468)]
Top words for pretrained_BERT neuron indx 4596 [('pushkin', 1.0), ('Descriptor', 0.9519344633084833), ('MINIMUM', 0.9418456931636321), ('64', 0.9276661276903656), ('pack', 0.9100235200752962)]
Top words for pretrained_BERT neuron indx 6647 [('within', 1.0), ('sanetime', 0.6966477338471302), ('bson', 0.6492832147603236), ('Criteria', 0.6242349038559312), ('chunks', 0.6180202303144844)]
Top words for pretrained_BERT neuron indx 8695 [('800', 1.0), ('256', 0.9275643279918824), ('128', 0.7845152629329396), ('255', 0.7502727333753424), ('ConfigViewSet', 0.7467492014650823)]
Top words for pretrained_BERT neuron indx 8697 [('destroy', 1.0), ('CREATING', 0.9733474327779302), ('ignore', 0.9605119803796849), ('Authenticated', 0.9307085813086812), ('15596', 0.9158461520299207)]
Top words for pretrained_BERT neuron indx 6654 [('omit', 1.0), ('unquote', 0.8833291946807437), ('"first_commits"', 0.8369491934719802), ('"a"', 0.832035224735536), ('util', 0.8083678105652273)]
Top words for pretrained_BERT neuron indx 512 [('reflection', 1.0), ('demo', 0.9281153429167718), ('dispatch', 0.7489582870332724), ('n', 0.7311741197669045), ('Gallery', 0.724896729954284)]
Top words for pretrained_BERT neuron indx 6664 [('pop', 1.0), ('window', 0.8799423850146108), ('File', 0.7185820073863181), ('con', 0.6989651943014774), ('1970', 0.6917643022880147)]
Top words for pretrained_BERT neuron indx 8713 [('openwatch', 1.0), ('b', 0.9652448334321931), ('1800', 0.9544171430416877), ('setupDatabase', 0.9165041466799322), ('teardownLink', 0.9048907584843779)]
Top words for pretrained_BERT neuron indx 2576 [('license', 1.0), ('web', 0.8938689733327595), ('uri', 0.7983641305498689), ('cnt', 0.7881066628140261), ('prop', 0.7569761996979366)]
Top words for pretrained_BERT neuron indx 8721 [('panels', 1.0), ('FLAG', 0.8407198292527653), ('Label', 0.8076135005173037), ('region', 0.800807379476289), ('labels', 0.7959029663681034)]
Top words for pretrained_BERT neuron indx 4627 [('close', 1.0), ('clear', 0.777750822078097), ('__description__', 0.749960963805805), ('upper', 0.733583674207884), ('USAGE', 0.7303190229030675)]
Top words for pretrained_BERT neuron indx 8724 [('seconds', 1.0), ('author', 0.9331392487413059), ('62', 0.88349781645618), ('broadcast', 0.8823816561882312), ('minimum', 0.8445986959400775)]
Top words for pretrained_BERT neuron indx 532 [('sort', 1.0), ('stats', 0.8638599137360041), ('dispatch', 0.8539085986146611), ('brightness', 0.8435053408151858), ('part', 0.8006005434960504)]
Top words for pretrained_BERT neuron indx 4634 [('services', 1.0), ('helpers', 0.8338747423027707), ('PRIORITY', 0.8122157259826052), ('INCOMPLETE', 0.8114197701700464), ('ACLU_NJ', 0.8044228742016671)]
Top words for pretrained_BERT neuron indx 538 [('minutes', 1.0), ('targets', 0.973828143965641), ('def', 0.8973895383225357), ('Subject', 0.8824574942253176), ('kind', 0.8472858960676306)]
Top words for pretrained_BERT neuron indx 540 [('row', 1.0), ('OK', 0.9534478165163782), ('choice', 0.9454360590936823), ('sha', 0.9116321861135285), ('TAG', 0.8733432182567524)]
Top words for pretrained_BERT neuron indx 8733 [('55', 1.0), ('five', 0.9358732416471858), ('5', 0.8832411892426077), ('500', 0.8705787807034966), ('zone', 0.8080049251849207)]
Top words for pretrained_BERT neuron indx 551 [('build', 1.0), ('ex', 0.9865648193723702), ('inc', 0.946954879768556), ('exec', 0.9454230997622286), ('calendar', 0.9308549398993391)]
Top words for pretrained_BERT neuron indx 2604 [('reset', 1.0), ('results', 0.9872788991636117), ('insert', 0.973308584323441), ('k', 0.9522384159845904), ('el', 0.8999179130846788)]
Top words for pretrained_BERT neuron indx 8753 [('CREATING', 1.0), ('tree', 0.918291313070992), ('intersection', 0.8476448345911569), ('instances', 0.7782332926751973), ('revision', 0.7047858664405205)]
Top words for pretrained_BERT neuron indx 8767 [('Else', 1.0), ('flask', 0.9304090595988503), ('is', 0.8532189349149044), ('If', 0.8082603109291653), ('U', 0.7677650265049986)]
Top words for pretrained_BERT neuron indx 6719 [('Else', 1.0), ('201', 0.9491650400661582), ('sha1', 0.912571930266242), ('error', 0.9034759712995967), ('17', 0.8344104642065562)]
Top words for pretrained_BERT neuron indx 4679 [('WAYS', 1.0), ('min', 0.9642350632374509), ('worker', 0.9427528577763262), ('Site', 0.9412935791142961), ('PROVISION', 0.9360413377369188)]
Top words for pretrained_BERT neuron indx 583 [('lambda', 1.0), ('horizon', 0.9503177684868891), ('exception', 0.9244823965093991), ('Action', 0.9084279911731428), ('Exception', 0.9023275003719714)]
Top words for pretrained_BERT neuron indx 6732 [('clear', 1.0), ('CREATING', 0.9785850092483562), ('I', 0.9749349303786579), ('utc', 0.9563680995677646), ('sorted', 0.943770630941305)]
Top words for pretrained_BERT neuron indx 4686 [('read', 1.0), ('Output', 0.9612020323414344), ('load', 0.9534164077769912), ('is', 0.9007967545445993), ('open', 0.8755757362967108)]
Top words for pretrained_BERT neuron indx 6735 [('cb', 1.0), ('Delay', 0.9746786629752332), ('delay', 0.8913857499215782), ('tries', 0.8616275394751631), ('platforms', 0.8249263941202131)]
Top words for pretrained_BERT neuron indx 8793 [('ay', 1.0), ('I', 0.8868583077278486), ('a', 0.8532628739686168), ('a0', 0.8463444271029069), ('communities', 0.7823955187982263)]
Top words for pretrained_BERT neuron indx 604 [('python', 1.0), ('source', 0.8531089659762091), ('shape', 0.8417905315509763), ('simple', 0.7856806485973489), ('ROLE', 0.78553208397226)]
Top words for pretrained_BERT neuron indx 8798 [('128', 1.0), ('dom', 0.9634941906885764), ('afi', 0.8806833840422387), ('timezone', 0.8797799552558732), ('w', 0.8666919905814146)]
Top words for pretrained_BERT neuron indx 6751 [('42', 1.0), ('other', 0.8019922790239052), ('Parent', 0.7734713162083606), ('parent', 0.7708279355685763), ('monkey', 0.7679932556916397)]
Top words for pretrained_BERT neuron indx 4704 [('300', 1.0), ('69', 0.9390292774838979), ('1800', 0.9352601427846875), ('milliseconds', 0.9170422082810601), ('95', 0.9147924265963687)]
Top words for pretrained_BERT neuron indx 615 [('protocol', 1.0), ('Protocol', 0.9723944671191861), ('prefix', 0.6915145089408818), ('Prefix', 0.6904916506036434), ('audit', 0.6456956908142137)]
Top words for pretrained_BERT neuron indx 4713 [('A', 1.0), ('256', 0.9117356028988893), ('1800', 0.7361900452481791), ('300', 0.7299494259054876), ('512', 0.6651295592957384)]
Top words for pretrained_BERT neuron indx 619 [('add', 1.0), ('afi', 0.9953087509502871), ('AFI', 0.9601731501293942), ('insert', 0.9420469663715153), ('ORIGIN', 0.9389183635710471)]
Top words for pretrained_BERT neuron indx 4717 [('Authorization', 1.0), ('I', 0.9999305673398401), ('exclude', 0.984355631195179), ('Migration', 0.9403619038063824), ('board', 0.9218422796868663)]
Top words for pretrained_BERT neuron indx 623 [('Stretch', 1.0), ('import', 0.9318957216783293), ('imports', 0.9315479195497363), ('Crawler', 0.9159443436102965), ('WAY', 0.9151638603154971)]
Top words for pretrained_BERT neuron indx 624 [('reserve', 1.0), ('socket', 0.9779987173204905), ('RESERVE', 0.9360827715490825), ('Q', 0.8829250385052685), ('q', 0.872045072699266)]
Top words for pretrained_BERT neuron indx 635 [('apache', 1.0), ('pisa', 0.9083104664140825), ('sleep', 0.8767915085974817), ('manager', 0.8594779074178699), ('Venue', 0.8520124571941774)]
Top words for pretrained_BERT neuron indx 4734 [('BOUNDS', 1.0), ('Criteria', 0.8654993561567197), ('criteria', 0.8467120027776817), ('blank', 0.790191813636295), ('criterion', 0.7639574970613575)]
Top words for pretrained_BERT neuron indx 8834 [('20', 1.0), ('WAYS', 0.8092163082012498), ('"multiple"', 0.8066363929445287), ('15', 0.7942198892037541), ('libraries', 0.7801781196621081)]
Top words for pretrained_BERT neuron indx 6797 [('CREATING', 1.0), ('pdb', 0.8281028145709038), ('up', 0.7264577236197645), ('south', 0.6932605393837109), ('V', 0.6870438883642561)]
Top words for pretrained_BERT neuron indx 6798 [('flat', 1.0), ('MSG', 0.7023117335612143), ('95', 0.6699798366220198), ('after', 0.665746722028718), ('ADVERTISE', 0.6241227166851953)]
Top words for pretrained_BERT neuron indx 4751 [('flash', 1.0), ('secure', 0.7523450082991536), ('credentials', 0.7473565038994587), ('protocols', 0.7067158803375343), ('Card', 0.6724415061652312)]
Top words for pretrained_BERT neuron indx 8848 [('75', 1.0), ('assets', 0.9570264520432074), ('f', 0.9456558347898985), ('q', 0.917396900957938), ('auditor', 0.9136458049217254)]
Top words for pretrained_BERT neuron indx 658 [('secret', 1.0), ('mock', 0.793163877329022), ('Mock', 0.7849509672714816), ('ignore', 0.7016148924414208), ('push', 0.7015056910433358)]
Top words for pretrained_BERT neuron indx 672 [('Column', 1.0), ('row', 0.8917651222290345), ('space', 0.7821152556331712), ('len', 0.7677972911167495), ('cover', 0.7583563376062485)]
Top words for pretrained_BERT neuron indx 6821 [('If', 1.0), ('unique', 0.9898749424616781), ('if', 0.9179017172698397), ('META', 0.8984084104515493), ('Mesh', 0.7636147843878356)]
Top words for pretrained_BERT neuron indx 8869 [('image', 1.0), ('from', 0.8719764903023072), ('deploy', 0.8017486939125693), ('experiments', 0.7919208901326653), ('score', 0.7896544567962877)]
Top words for pretrained_BERT neuron indx 679 [('http', 1.0), ('Delay', 0.9636161770177168), ('parts', 0.9293530854948759), ('register', 0.8997419573264445), ('delay', 0.8785465975524812)]
Top words for pretrained_BERT neuron indx 682 [('Error', 1.0), ('ERROR', 0.8907893270922823), ('error', 0.8606710314001567), ('put', 0.7875876715634169), ('insert', 0.7603426662797863)]
Top words for pretrained_BERT neuron indx 686 [('yield', 1.0), ('partial', 0.8440869566744771), ('True', 0.8275563697194461), ('z', 0.7815972240406217), ('random', 0.7772649116779646)]
Top words for pretrained_BERT neuron indx 689 [('within', 1.0), ('boot', 0.8983877305508566), ('sock', 0.8489810451742215), ('visit', 0.792479466557433), ('Core', 0.7762628257093294)]
Top words for pretrained_BERT neuron indx 8884 [('187', 1.0), ('or', 0.8659375937992765), ('Clock', 0.865272745842175), ('intersects', 0.8549152478840226), ('select', 0.8310925509117488)]
Top words for pretrained_BERT neuron indx 8890 [('69', 1.0), ('14', 0.797852680169332), ('119', 0.7203210547014817), ('28', 0.7149630543685916), ('17', 0.7083125967553539)]
Top words for pretrained_BERT neuron indx 2748 [('cleanup', 1.0), ('2014', 0.9273779357598483), ('trial', 0.9215682113063631), ('1970', 0.8515140085056853), ('csrf', 0.7936508890757397)]
Top words for pretrained_BERT neuron indx 701 [('choice', 1.0), ('sublime', 0.9101946832858083), ('sid', 0.8974547513833931), ('sts', 0.8969791215960338), ('backwards', 0.847917498197037)]
Top words for pretrained_BERT neuron indx 8915 [('five', 1.0), ('Provider', 0.9405432531256771), ('oslo', 0.9062138444626618), ('edited', 0.827586724492896), ('broker', 0.8230608468167852)]
Top words for pretrained_BERT neuron indx 2773 [('Off', 1.0), ('inc', 0.8531218604380986), ('flush', 0.7824613923273562), ('exists', 0.7539114293145034), ('body', 0.7137137206141266)]
Top words for pretrained_BERT neuron indx 726 [('count', 1.0), ('close', 0.9968113360533093), ('exists', 0.9758926575388862), ('date', 0.9100254402027819), ('shape', 0.8620739992144983)]
Top words for pretrained_BERT neuron indx 6870 [('fail', 1.0), ('requires', 0.8745552342344695), ('while', 0.8689030424601379), ('inc', 0.8608934604695984), ('tornado', 0.8170368971277048)]
Top words for pretrained_BERT neuron indx 725 [('sets', 1.0), ('management', 0.9642049291039757), ('confirm', 0.9114197202426063), ('views', 0.8576637737431656), ('six', 0.8529993317403146)]
Top words for pretrained_BERT neuron indx 8924 [('sp', 1.0), ('rd', 0.9742759950965301), ('pa', 0.9088058001308071), ('80', 0.8621770916004052), ('cid', 0.856516970867807)]
Top words for pretrained_BERT neuron indx 734 [('Authenticated', 1.0), ('K', 0.9969054205499166), ('Migration', 0.9584400453920744), ('entries', 0.952784560051311), ('reference', 0.917518840501515)]
Top words for pretrained_BERT neuron indx 4840 [('kw', 1.0), ('chunk', 0.9809354527736361), ('chunks', 0.9690492517675375), ('min_version', 0.924146752948267), ('m', 0.9238250254285411)]
Top words for pretrained_BERT neuron indx 745 [('shared', 1.0), ('Item', 0.9295835268664588), ('mail', 0.9172108894300203), ('item', 0.9107818001106672), ('p', 0.8373742096482357)]
Top words for pretrained_BERT neuron indx 2800 [('ROLE', 1.0), ('ax', 0.9999867722421623), ('MANIFEST', 0.9705195396029527), ('srid', 0.9312737034345906), ('ord', 0.8675848682961729)]
Top words for pretrained_BERT neuron indx 8968 [('pop', 1.0), ('window', 0.8377125738189067), ('33', 0.8271860686796417), ('128', 0.7973040790888366), ('62', 0.7406546601313947)]
Top words for pretrained_BERT neuron indx 6930 [('each', 1.0), ('Q', 0.9536099241773307), ('plural', 0.9218499954379443), ('ax', 0.8817174055984863), ('synchronized', 0.8692414322666892)]
Top words for pretrained_BERT neuron indx 6940 [('intersects', 1.0), ('venue', 0.9039411583269129), ('75', 0.9003717731636077), ('requires', 0.8962860268410233), ('"y"', 0.8756462502113714)]
Top words for pretrained_BERT neuron indx 8998 [('five', 1.0), ('layer', 0.6364566105884807), ('p', 0.6354357802894277), ('C', 0.6164707669704602), ('fifteen', 0.6122806953417635)]
Top words for pretrained_BERT neuron indx 6952 [('labels', 1.0), ('cleanup', 0.9145851506218887), ('del', 0.8113150965293549), ('terms', 0.7735859803081119), ('discovery', 0.7682707684749315)]
Top words for pretrained_BERT neuron indx 808 [('asset', 1.0), ('upper', 0.9980072118144246), ('Asset', 0.9811079796395098), ('last', 0.9299176092789324), ('decorators', 0.9234986376432394)]
Top words for pretrained_BERT neuron indx 4916 [('is', 1.0), ('in', 0.921841264011319), ('with', 0.9187976711888487), ('Int', 0.9131283688444406), ('int', 0.8337374996354596)]
Top words for pretrained_BERT neuron indx 6967 [('five', 1.0), ('42', 0.9269051902828165), ('1800', 0.8712595519347098), ('75', 0.8177630816293762), ('fifteen', 0.721859717719464)]
Top words for pretrained_BERT neuron indx 4933 [('protocols', 1.0), ('packet', 0.8736669882445236), ('protocol', 0.8700011816758024), ('sort', 0.8511230919189493), ('save', 0.8454255688927453)]
Top words for pretrained_BERT neuron indx 2887 [('Exception', 1.0), ('agency', 0.8413210044393518), ('exception', 0.779468506529954), ('old', 0.716730014124121), ('translation', 0.6808731722990508)]
Top words for pretrained_BERT neuron indx 4936 [('reference', 1.0), ('stats', 0.992003725247238), ('23', 0.9354789781071263), ('3785', 0.9230015440613077), ('95', 0.9065658999695463)]
Top words for pretrained_BERT neuron indx 9033 [('465', 1.0), ('15597', 0.9688643700893054), ('1025', 0.9559619879093838), ('74.616338', 0.9072419765896785), ('40.167274', 0.883509173677782)]
Top words for pretrained_BERT neuron indx 4939 [('K', 1.0), ('NODES', 0.9103942788943418), ('On', 0.8772376731013012), ('ON', 0.8772376731013012), ('labels', 0.8325042366874903)]
Top words for pretrained_BERT neuron indx 6989 [('RELATION', 1.0), ('".."', 0.8786548241256431), ('excinfo', 0.8555320008096204), ('ADVERTISE', 0.8342348433852826), ('unbase', 0.8211345097485092)]
Top words for pretrained_BERT neuron indx 6998 [('seconds', 1.0), ('sim', 0.9136543754952086), ('fifteen', 0.8541971008771166), ('Geo', 0.842767118334257), ('five', 0.8401699126726423)]
Top words for pretrained_BERT neuron indx 7008 [('"KILLED"', 1.0), ('oslo', 0.9965572457585639), ('bson', 0.9473321371984915), ('95', 0.9313019104167873), ('"SUCCEEDED"', 0.9196492762899612)]
Top words for pretrained_BERT neuron indx 9064 [('microseconds', 1.0), ('all', 0.9346745762703338), ('Else', 0.9319316302984159), ('isalnum', 0.8744141205964147), ('six', 0.839551565765976)]
Top words for pretrained_BERT neuron indx 880 [('button', 1.0), ('sr', 0.9868321851582847), ('Connection', 0.9824628971207447), ('z', 0.9329190087488614), ('setUp', 0.9316636362547631)]
Top words for pretrained_BERT neuron indx 7026 [('button', 1.0), ('available', 0.9778217595490455), ('256', 0.884236430481285), ('kind', 0.8654687218572198), ('Failure', 0.8045102994395916)]
Top words for pretrained_BERT neuron indx 4979 [('tell', 1.0), ('identical', 0.990903312413689), ('match', 0.8401086409034465), ('old', 0.7786257152273247), ('RELATION', 0.7597037318260729)]
Top words for pretrained_BERT neuron indx 7031 [('six', 1.0), ('or', 0.9758137815898145), ('kw', 0.9373239634294616), ('local', 0.9279166156658203), ('None', 0.9269886559064201)]
Top words for pretrained_BERT neuron indx 2937 [('999999', 1.0), ('READY', 0.9130301879862529), ('wait', 0.9101172916777378), ('common', 0.8778937131455394), ('called', 0.8271433203077062)]
Top words for pretrained_BERT neuron indx 4993 [('reason', 1.0), ('backwards', 0.9595484994795007), ('undo', 0.904689156324147), ('filtered', 0.8555283621895876), ('Else', 0.84522883133841)]
Top words for pretrained_BERT neuron indx 898 [('close', 1.0), ('stamp', 0.9304109191450458), ('region', 0.8701116644756053), ('Region', 0.8681783202878494), ('blend', 0.8354835853192533)]
Top words for pretrained_BERT neuron indx 2945 [('flags', 1.0), ('sites', 0.9058889513793255), ('choice', 0.9031431099954345), ('m', 0.8851410554682977), ('key', 0.8664809163526671)]
Top words for pretrained_BERT neuron indx 2955 [('confirm', 1.0), ('SON', 0.7948137061589425), ('op', 0.7185265388541034), ('html', 0.6242688937352904), ('relay', 0.6180233731113871)]
Top words for pretrained_BERT neuron indx 9100 [('999999', 1.0), ('89.999999999999992', 0.8973333763051683), ('intersects', 0.8833378653503465), ('lat__lt', 0.8769144397835839), ('lat__gt', 0.845326740071846)]
Top words for pretrained_BERT neuron indx 5005 [('g', 1.0), ('intersection', 0.9269462017098948), ('Action', 0.8842545310604977), ('DISCONNECTED', 0.8327613115849168), ('81.4471435546875', 0.8226733710643689)]
Top words for pretrained_BERT neuron indx 7054 [('1970', 1.0), ('tv', 0.9480205740620388), ('tasks', 0.9236644640594174), ('v', 0.9135276788387265), ('ORIGIN', 0.8940265717832112)]
Top words for pretrained_BERT neuron indx 7076 [('42', 1.0), ('40', 0.7917139612049786), ('50', 0.7505367198389219), ('sr', 0.7321696128485703), ('qdict', 0.7297397895154948)]
Top words for pretrained_BERT neuron indx 937 [('Connection', 1.0), ('security', 0.9989301200038856), ('socket', 0.9982864938007331), ('128', 0.9715658102851483), ('connectionId', 0.9524374675073018)]
Top words for pretrained_BERT neuron indx 939 [('WAYS', 1.0), ('Variable', 0.9728266673767703), ('inc', 0.9108647399189242), ('request', 0.8997956177890913), ('secret', 0.896440056267256)]
Top words for pretrained_BERT neuron indx 9133 [('mark', 1.0), ('33', 0.9835917381400433), ('score', 0.8740050221989282), ('69', 0.8509225454910333), ('intersects', 0.8413432249113768)]
Top words for pretrained_BERT neuron indx 941 [('imports', 1.0), ('us', 0.9673889692553249), ('results', 0.9561937560160381), ('zone', 0.949739194503967), ('levels', 0.9157005020791724)]
Top words for pretrained_BERT neuron indx 2999 [('path', 1.0), ('accounts', 0.9875760587651464), ('cache', 0.97450765837184), ('round', 0.956240406152552), ('tree', 0.9233808761003878)]
Top words for pretrained_BERT neuron indx 951 [('create', 1.0), ('reverse', 0.9727530607999841), ('discovery', 0.9512682411677637), ('CREATING', 0.9354543497528726), ('created', 0.8775074615671887)]
Top words for pretrained_BERT neuron indx 3003 [('script', 1.0), ('partition', 0.9945839427945662), ('Model', 0.9689298814477365), ('django', 0.8889792995069716), ('django_lean', 0.8874478388810166)]
Top words for pretrained_BERT neuron indx 5052 [('1970', 1.0), ('B', 0.9928649256461781), ('sr', 0.9802627047052761), ('other', 0.9688744614783413), ('is', 0.9677490723159147)]
Top words for pretrained_BERT neuron indx 5055 [('five', 1.0), ('link', 0.6753512332695778), ('restart', 0.6705062069622817), ('generate', 0.6606464403379984), ('0', 0.6604079352833707)]
Top words for pretrained_BERT neuron indx 3007 [('mac', 1.0), ('db', 0.969529306588199), ('os', 0.9559791061684714), ('security', 0.8748695513863851), ('sites', 0.8653082324887788)]
Top words for pretrained_BERT neuron indx 7119 [('five', 1.0), ('closing', 0.8423006205758261), ('sa', 0.811664102069571), ('Manager', 0.7995622440396459), ('C', 0.7876744004992997)]
Top words for pretrained_BERT neuron indx 7128 [('unique', 1.0), ('sim', 0.7468250051750008), ('find_session', 0.7265223987737316), ('hidden', 0.716245942303743), ('lon', 0.7047132815932147)]
Top words for pretrained_BERT neuron indx 3043 [('NODES', 1.0), ('Bytes', 0.8781826018121868), ('TAG', 0.850579182296601), ('document', 0.8495539552981273), ('STATUS', 0.8405394723335001)]
Top words for pretrained_BERT neuron indx 7144 [('score', 1.0), ('fileno', 0.9042856352758215), ('1970', 0.8774723035801911), ('min_version', 0.8768407064312391), ('75', 0.8369847115499587)]
Top words for pretrained_BERT neuron indx 9194 [('flat', 1.0), ('strict', 0.7808140890815314), ('2', 0.6730831956226938), ('events', 0.6699743995116347), ('999999', 0.6688300082433143)]
Top words for pretrained_BERT neuron indx 1003 [('REFERENCES', 1.0), ('events', 0.9879726967943492), ('opener', 0.9843183484541743), ('references', 0.8995479915067005), ('sublime', 0.89106585216893)]
Top words for pretrained_BERT neuron indx 9204 [('"KILLED"', 1.0), ('"SUCCEEDED"', 0.99390119910175), ('"FAILED"', 0.943816904810475), ('TestPermissions', 0.7769397802567174), ('boto', 0.7727312483317396)]
Top words for pretrained_BERT neuron indx 1012 [('WAY', 1.0), ('hyper', 0.9959847519595489), ('WAYS', 0.9791577470831773), ('platform', 0.8996235369211752), ('63', 0.8831788602965136)]
Top words for pretrained_BERT neuron indx 1014 [('Pass', 1.0), ('pass', 0.9226295374138348), ('Register', 0.8779210376118511), ('register', 0.87357879929365), ('result', 0.8201856384420579)]
Top words for pretrained_BERT neuron indx 5118 [('TRANSITIVE', 1.0), ('unquote', 0.9341507539893275), ('first_branch', 0.8181916725546473), ('help', 0.8028308620625599), ('util', 0.7988101614189251)]
Top words for pretrained_BERT neuron indx 9217 [('unicode', 1.0), ('ah', 0.9850088439485866), ('exclude', 0.9371876614645319), ('Component', 0.90430331611526), ('forwards', 0.8884024348974742)]
Top words for pretrained_BERT neuron indx 1030 [('fixture', 1.0), ('reflection', 0.9581024281907509), ('select', 0.9133262913614557), ('Post', 0.9025738630850256), ('props', 0.8902710392415233)]
Top words for pretrained_BERT neuron indx 5128 [('pop', 1.0), ('con', 0.8840454953334604), ('window', 0.8388088383696333), ('On', 0.8204157040681921), ('ON', 0.8204157040681921)]
Top words for pretrained_BERT neuron indx 7177 [('90.0', 1.0), ('upper', 0.9056689877801001), ('1800', 0.8572223525979854), ('999999', 0.8366718397432803), ('forwards', 0.8322003387433168)]
Top words for pretrained_BERT neuron indx 1040 [('web', 1.0), ('license', 0.9603010324496728), ('prop', 0.8916969688921426), ('Gallery', 0.8833970899154151), ('broker', 0.8483990208188444)]
Top words for pretrained_BERT neuron indx 9234 [('purpose', 1.0), ('realm', 0.8941971587421683), ('audit', 0.8793211217046701), ('Module', 0.8714776135670426), ('upstream', 0.8240332963058574)]
Top words for pretrained_BERT neuron indx 7191 [('events', 1.0), ('communities', 0.8725200990034675), ('RELEASE', 0.7993276506760708), ('y', 0.7906615097438079), ('Event', 0.7405481539240067)]
Top words for pretrained_BERT neuron indx 3098 [('PRIORITY', 1.0), ('K', 0.9738107113718243), ('services', 0.9354715434232072), ('LOG', 0.9322784345788266), ('L', 0.8939328481254971)]
Top words for pretrained_BERT neuron indx 7197 [('42', 1.0), ('now', 0.9329384814320663), ('75', 0.8798200240432047), ('I', 0.8774787087979007), ('33', 0.8473882425995637)]
Top words for pretrained_BERT neuron indx 7203 [('OK', 1.0), ('purge', 0.9192150736915535), ('Action', 0.8230447840502968), ('gf', 0.7842560878216137), ('CREATING', 0.7708294038427492)]
Top words for pretrained_BERT neuron indx 3112 [('minimum', 1.0), ('name', 0.9875475969325025), ('labels', 0.9866537872614405), ('answer', 0.9794600462775993), ('upper', 0.9700530941095031)]
Top words for pretrained_BERT neuron indx 1065 [('Connection', 1.0), ('protocols', 0.977479277503645), ('n', 0.96582360436637), ('char', 0.9213711878994127), ('cb', 0.8951252967476565)]
Top words for pretrained_BERT neuron indx 1068 [('reset', 1.0), ('el', 0.9414388496597624), ('insert', 0.9357052087668948), ('rd', 0.9189937084693397), ('checkout', 0.9092635677202422)]
Top words for pretrained_BERT neuron indx 7217 [('sorted', 1.0), ('intersection', 0.9790240707490203), ('CREATING', 0.9726520574346926), ('begin', 0.9683136951611825), ('setUp', 0.9336487527999123)]
Top words for pretrained_BERT neuron indx 7220 [('Billboard', 1.0), ('WARNING', 0.883161386534797), ('int', 0.8145808029633383), ('Int', 0.8067877462786808), ('LazyObject', 0.7317310590681028)]
Top words for pretrained_BERT neuron indx 1076 [('and', 1.0), ('in', 0.8934896199728226), ('".."', 0.8662209208778443), ('to', 0.8290575651892734), ('","', 0.8032292721052583)]
Top words for pretrained_BERT neuron indx 1085 [('baseline', 1.0), ('else', 0.8395723059520339), ('Else', 0.7943471386868961), ('bk', 0.7837004702798951), ('1800', 0.7708137166917544)]
Top words for pretrained_BERT neuron indx 7257 [('BBOX', 1.0), ('srid', 0.9459695242194663), ('I', 0.9003214248606545), ('a', 0.8439391438069312), ('find_plan_splits', 0.8367286076112933)]
Top words for pretrained_BERT neuron indx 1118 [('rows', 1.0), ('Dummy', 0.9940221830413025), ('driver', 0.9491888938315679), ('manager', 0.9296706083225729), ('secret', 0.9144069976422481)]
Top words for pretrained_BERT neuron indx 9312 [('agency', 1.0), ('reddit', 0.9897458779661049), ('five', 0.9780484971893536), ('pisa', 0.9385112531006767), ('presence', 0.9293780319461065)]
Top words for pretrained_BERT neuron indx 3178 [('fifteen', 1.0), ('2014', 0.8233866507554299), ('Wire', 0.8107411047777007), ('oslo', 0.7639458014650661), ('experiments', 0.7088041760543796)]
Top words for pretrained_BERT neuron indx 7279 [('Label', 1.0), ('period', 0.9842576728889019), ('symmetric', 0.9062400687381218), ('CONNECTED', 0.874002027964065), ('flat', 0.8703643074335684)]
Top words for pretrained_BERT neuron indx 5239 [('implementation', 1.0), ('Card', 0.923324382933728), ('Authorization', 0.9199502118020273), ('branches', 0.8980919519145316), ('partial', 0.8925966053542456)]
Top words for pretrained_BERT neuron indx 1148 [('slug', 1.0), ('agency', 0.8311260610903691), ('topology', 0.8069576592065846), ('read', 0.792043883947004), ('math', 0.7769435943484925)]
Top words for pretrained_BERT neuron indx 9340 [('scheme', 1.0), ('createreport', 0.983932702953907), ('Assign', 0.981121380129201), ('"happy_birthday"', 0.9224763493381535), ('openwatch', 0.8990863680385527)]
Top words for pretrained_BERT neuron indx 3198 [('BOUNDS', 1.0), ('experiments', 0.9427391160755216), ('now', 0.789017061223394), ('step', 0.7739599515758797), ('exception', 0.7734242829306059)]
Top words for pretrained_BERT neuron indx 3199 [('ps', 1.0), ('I', 0.9403315881924945), ('rules', 0.9047763443964635), ('top', 0.8899907595570533), ('other', 0.8596332922586224)]
Top words for pretrained_BERT neuron indx 1153 [('proxy', 1.0), ('strings', 0.9971691075984968), ('MANIFEST', 0.8306057746655977), ('filters', 0.8267460747459741), ('reason', 0.8181478007718417)]
Top words for pretrained_BERT neuron indx 7298 [('a1', 1.0), ('first', 0.9708605427328721), ('STATUS', 0.9581174440486503), ('I', 0.91507354784551), ('REFERENCES', 0.9111087545874086)]
Top words for pretrained_BERT neuron indx 7312 [('a', 1.0), ('A', 0.9685643350997891), ('a0', 0.7199009934420788), ('Action', 0.7079925809787854), ('recordings', 0.6879365778866806)]
Top words for pretrained_BERT neuron indx 9366 [('services', 1.0), ('ip', 0.9879638719278779), ('core', 0.9016887595081313), ('events', 0.8826671783203184), ('providers', 0.8488325732850982)]
Top words for pretrained_BERT neuron indx 1178 [('transfer', 1.0), ('platform', 0.9343945666494354), ('rv', 0.8073885999120378), ('line', 0.8025586914722392), ('probed', 0.7991304172379898)]
Top words for pretrained_BERT neuron indx 7331 [('if', 1.0), ('while', 0.89143597508366), ('except', 0.8543408605920518), ('get_profile_available_storage_systems', 0.8478700488914799), ('get_profile_networks', 0.8435515172602004)]
Top words for pretrained_BERT neuron indx 1196 [('10', 1.0), ('registry', 0.9650278031678978), ('advance', 0.9449808318816787), ('height', 0.8925559836200399), ('80', 0.882310009011287)]
Top words for pretrained_BERT neuron indx 7346 [('exit', 1.0), ('advance', 0.977694730770598), ('activate', 0.9771257977295844), ('south', 0.9588391080586025), ('ur', 0.909256201569257)]
Top words for pretrained_BERT neuron indx 9394 [('revision', 1.0), ('packet', 0.9663201545775708), ('Delay', 0.9116118338688263), ('Timestamp_reply', 0.9037876133845891), ('Label', 0.8775752846318775)]
Top words for pretrained_BERT neuron indx 1204 [('a2', 1.0), ('props', 0.9000943733160968), ('exceptions', 0.8830851507123387), ('choice', 0.8793010736028016), ('ct', 0.8432715902657193)]
Top words for pretrained_BERT neuron indx 5309 [('Node', 1.0), ('node', 0.9453814771019992), ('None', 0.9327760423393303), ('communities', 0.8128732239815729), ('Proto', 0.8067584595221117)]
Top words for pretrained_BERT neuron indx 1215 [('IntType', 1.0), ('mail', 0.9768222437456059), ('Auditor', 0.9760861704407623), ('e', 0.9207848890836087), ('direct', 0.9140380260667981)]
Top words for pretrained_BERT neuron indx 1241 [('asset', 1.0), ('Asset', 0.9385001174413575), ('missing', 0.934597561821412), ('word', 0.8972829846756822), ('script', 0.8970576263802256)]
Top words for pretrained_BERT neuron indx 3299 [('WAY', 1.0), ('optimizer', 0.9313498610577129), ('WAYS', 0.8813616362406941), ('Geo', 0.838074577620502), ('simplify', 0.8329592091461899)]
Top words for pretrained_BERT neuron indx 7395 [('RESERVE', 1.0), ('False', 0.9569020322350136), ('runner', 0.934682248066692), ('exabgp', 0.9254176260045996), ('intersects', 0.8998661140578136)]
Top words for pretrained_BERT neuron indx 1253 [('STATUS', 1.0), ('displays', 0.9900729176520161), ('status', 0.8977199719083888), ('Dataflow', 0.8630368049524022), ('string', 0.855191922785866)]
Top words for pretrained_BERT neuron indx 9450 [('Column', 1.0), ('product', 0.8754065875406478), ('89.999999999999992', 0.845461274912985), ('convert', 0.8395770988457915), ('2014', 0.8382744064186852)]
Top words for pretrained_BERT neuron indx 7410 [('Int', 1.0), ('int', 0.9060750418629057), ('TERMINATE', 0.8298837490347412), ('var', 0.8163807503313116), ('extended', 0.8077712343296921)]
Top words for pretrained_BERT neuron indx 3316 [('View', 1.0), ('WAY', 0.824817242081275), ('127', 0.7902397606653114), ('avail', 0.7479770031090591), ('second', 0.7398316079136339)]
Top words for pretrained_BERT neuron indx 9472 [('functional', 1.0), ('interval', 0.9555071888863649), ('sender', 0.9338586066269084), ('Plugin', 0.8820892090309308), ('principal', 0.8288307520868577)]
Top words for pretrained_BERT neuron indx 9477 [('o', 1.0), ('oslo', 0.9823196109986295), ('os', 0.9650050886884619), ('81.4471435546875', 0.9249032716516421), ('Int', 0.9196486540770992)]
Top words for pretrained_BERT neuron indx 7432 [('pop', 1.0), ('window', 0.8096143651519182), ('File', 0.7390815982285686), ('62', 0.7206686854585653), ('75', 0.7181865839869452)]
Top words for pretrained_BERT neuron indx 3344 [('web', 1.0), ('ep', 0.930649130993241), ('alt', 0.885071370373817), ('license', 0.8607874651409004), ('comp', 0.8190050728927667)]
Top words for pretrained_BERT neuron indx 5394 [('ax', 1.0), ('plural', 0.9795253094266335), ('synchronized', 0.9727153741447154), ('512', 0.9544771227560688), ('Simple', 0.9293753049381608)]
Top words for pretrained_BERT neuron indx 1299 [('count', 1.0), ('ssl', 0.8833544417206364), ('RELATIONS', 0.8739342575838597), ('Billboard', 0.8677046671445316), ('contents', 0.8084213931870907)]
Top words for pretrained_BERT neuron indx 9495 [('If', 1.0), ('top', 0.9117576785326005), ('google', 0.7852170718599123), ('replace', 0.6987534498789713), ('REF', 0.6773619808945364)]
Top words for pretrained_BERT neuron indx 7450 [('"multiple"', 1.0), ('OK', 0.9965821822075137), ('"Text"', 0.9948094830699433), ('"oslo"', 0.9633258773248331), ('15', 0.9501315339695733)]
Top words for pretrained_BERT neuron indx 5404 [('loads', 1.0), ('Bytes', 0.973627489037973), ('host', 0.9308801277920681), ('Byte', 0.9265313154454554), ('requests', 0.9202855246601567)]
Top words for pretrained_BERT neuron indx 9506 [('bindings', 1.0), ('ax', 0.8965742151258088), ('21', 0.8545288198231953), ('SSLContext', 0.85358086761291), ('pxe', 0.8512877190825296)]
Top words for pretrained_BERT neuron indx 1319 [('exec', 1.0), ('inc', 0.8305087764194745), ('targets', 0.8167436741537104), ('ex', 0.7559498360478556), ('re', 0.7492607194859178)]
Top words for pretrained_BERT neuron indx 5417 [('ex', 1.0), ('cid', 0.983439532427706), ('302', 0.9729072850024564), ('204', 0.9711289804194686), ('trial', 0.9591302513009973)]
Top words for pretrained_BERT neuron indx 3372 [('k', 1.0), ('dictionary', 0.9394918470617772), ('Commit', 0.9374619870178286), ('reset', 0.8966625344850097), ('round', 0.893799509262458)]
Top words for pretrained_BERT neuron indx 7471 [('ah', 1.0), ('intersects', 0.9602581968911431), ('pattern', 0.9261354604339715), ('monkey', 0.9254054361924683), ('language', 0.9177601606448389)]
Top words for pretrained_BERT neuron indx 9521 [('Node', 1.0), ('tree', 0.9349757476591983), ('CREATING', 0.810929830907542), ('branch', 0.8053444651893035), ('branches', 0.7687624174876435)]
Top words for pretrained_BERT neuron indx 3378 [('1000', 1.0), ('info', 0.9416675924169425), ('INFO', 0.9260081418569939), ('month', 0.8587047103793685), ('do', 0.8091175213536711)]
Top words for pretrained_BERT neuron indx 3380 [('and', 1.0), ('is', 0.9744078749050397), ('in', 0.9573312859882485), ('with', 0.7938157695051871), ('as', 0.7445340063322183)]
Top words for pretrained_BERT neuron indx 1333 [('os', 1.0), ('processes', 0.8928845503987012), ('ports', 0.8454973864205285), ('import', 0.8290926014826971), ('pyramid', 0.8181275555155622)]
Top words for pretrained_BERT neuron indx 3384 [('single', 1.0), ('application', 0.9916204505500579), ('organization', 0.920615873268288), ('number', 0.9051838060330198), ('Simple', 0.8207407518636709)]
Top words for pretrained_BERT neuron indx 5435 [('monkey', 1.0), ('89.999999999999992', 0.9912338969126758), ('incoming', 0.919728506783913), ('62', 0.9095273469798653), ('READY', 0.8321811733049997)]
Top words for pretrained_BERT neuron indx 7488 [('plural', 1.0), ('slug', 0.9565574876955513), ('operation', 0.9458754147669396), ('count', 0.8915190829549079), ('def', 0.8780155592039223)]
Top words for pretrained_BERT neuron indx 1345 [('material', 1.0), ('huffman', 0.8648148086953831), ('cancel', 0.8421932701894767), ('187', 0.7546251638352668), ('select', 0.7482246810988902)]
Top words for pretrained_BERT neuron indx 1348 [('incoming', 1.0), ('Variable', 0.8173753151662928), ('CRITICAL', 0.7938551822244863), ('variable', 0.7800067451244723), ('critical', 0.7663342456997584)]
Top words for pretrained_BERT neuron indx 1351 [('old', 1.0), ('Exception', 0.9343122233416662), ('Stream', 0.8848805694170844), ('OK', 0.8244591632609114), ('exception', 0.7656853296135218)]
Top words for pretrained_BERT neuron indx 7497 [('"data"', 1.0), ('pattern', 0.9808676227560295), ('"multiple"', 0.9371866805487485), ('ur', 0.9361342709072974), ('"sequence"', 0.9138858159090582)]
Top words for pretrained_BERT neuron indx 3402 [('tasks', 1.0), ('imports', 0.9475714390514476), ('API', 0.926533231653983), ('remove', 0.9254230028968496), ('REFERENCES', 0.9069166930497209)]
Top words for pretrained_BERT neuron indx 9560 [('sans', 1.0), ('http', 0.9672287816192281), ('ALPHABET', 0.8383975782443819), ('sorted', 0.7426019165325195), ('g', 0.7267226488443982)]
Top words for pretrained_BERT neuron indx 9563 [('Account', 1.0), ('requesthandlers', 0.9613691412522337), ('z', 0.845266283624256), ('j', 0.827893063615095), ('RELEASE', 0.8248945909125435)]
Top words for pretrained_BERT neuron indx 3422 [('unicode', 1.0), ('secret', 0.9934047901753117), ('active', 0.9541111667038812), ('walker', 0.9518351787432127), ('order', 0.8162343124844599)]
Top words for pretrained_BERT neuron indx 5472 [('decimal', 1.0), ('geos', 0.9440150878551576), ('tls', 0.9363117096820031), ('compat', 0.9321200867670911), ('bson', 0.9270786127202093)]
Top words for pretrained_BERT neuron indx 7522 [('Thread', 1.0), ('path', 0.9014241571968595), ('Cat', 0.8268393312118526), ('branch', 0.8030712985343682), ('Else', 0.7917627159529153)]
Top words for pretrained_BERT neuron indx 1387 [('metadata', 1.0), ('afi', 0.996194139447606), ('tasks', 0.9831870380551654), ('AFI', 0.9704371565218134), ('Plan', 0.962459158522903)]
Top words for pretrained_BERT neuron indx 9586 [('secret', 1.0), ('Label', 0.9919312338593503), ('Mock', 0.9866345343493849), ('CACHES', 0.9331775007501767), ('sr', 0.9122559737950411)]
Top words for pretrained_BERT neuron indx 5490 [('5', 1.0), ('runner', 0.9871310746378352), ('five', 0.9664117397019055), ('3', 0.947118997620058), ('button', 0.9251229030765572)]
Top words for pretrained_BERT neuron indx 5492 [('relay', 1.0), ('INCOMPLETE', 0.9839262982376354), ('topology', 0.9643378599922617), ('manager', 0.94828323573386), ('forget', 0.9406593445661634)]
Top words for pretrained_BERT neuron indx 9590 [('cluster', 1.0), ('a', 0.8510551826704768), ('StringType', 0.8213031812639211), ('TRANSITIVE', 0.8061747550275029), ('char', 0.7854189289049517)]
Top words for pretrained_BERT neuron indx 1401 [('999999', 1.0), ('common', 0.9564868640937697), ('brightness', 0.8808636894399902), ('asset', 0.8704027931323948), ('called', 0.8457380320878313)]
Top words for pretrained_BERT neuron indx 5499 [('Action', 1.0), ('mins', 0.959916563909581), ('quot', 0.8654387075820547), ('displays', 0.858298864540006), ('GeoFieldTest', 0.8346768167187654)]
Top words for pretrained_BERT neuron indx 1404 [('push', 1.0), ('copy', 0.9626738729178743), ('management', 0.9380631560300625), ('auditor', 0.9377597657014631), ('UCache', 0.926183131012081)]
Top words for pretrained_BERT neuron indx 1403 [('apache', 1.0), ('Venue', 0.9986001563024296), ('venue', 0.9472118819950819), ('http', 0.8711259962409538), ('pisa', 0.844730818621865)]
Top words for pretrained_BERT neuron indx 5502 [('BOUNDS', 1.0), ('criteria', 0.7322577828326543), ('blank', 0.7289909127572756), ('Criteria', 0.7134983142273438), ('j', 0.6995839227327838)]
Top words for pretrained_BERT neuron indx 3457 [('seek', 1.0), ('inc', 0.8787696790148063), ('MANIFEST', 0.861134571856443), ('reason', 0.850879490195594), ('backwards', 0.838433041998758)]
Top words for pretrained_BERT neuron indx 9602 [('Basic', 1.0), ('100', 0.9790779009774043), ('Distance', 0.9092569983246998), ('20', 0.8837122253092283), ('AFI', 0.8691771322968662)]
Top words for pretrained_BERT neuron indx 7560 [('3785', 1.0), ('201', 0.9431514248453737), ('1023', 0.9395514866176854), ('204', 0.9328134200828871), ('2014', 0.8848600318652922)]
Top words for pretrained_BERT neuron indx 7564 [('999999', 1.0), ('intersects', 0.9442859726211417), ('n', 0.8864515478028357), ('compute', 0.8661330865838585), ('0.04', 0.8594605956275555)]
Top words for pretrained_BERT neuron indx 5518 [('ORIGIN', 1.0), ('values', 0.9300626738212849), ('origin', 0.8820003973774547), ('sorted', 0.8449083697548351), ('Origin', 0.8361806768668726)]
Top words for pretrained_BERT neuron indx 3472 [('A', 1.0), ('result', 0.955104186877986), ('values', 0.8789892974282393), ('flask', 0.87528413679129), ('document', 0.8677885704308629)]
Top words for pretrained_BERT neuron indx 3482 [('long', 1.0), ('transfer', 0.8869943075364956), ('rv', 0.7770908730386974), ('acquire', 0.7760199027610841), ('probed', 0.725898661351682)]
Top words for pretrained_BERT neuron indx 7589 [('unique', 1.0), ('If', 0.9856246800871112), ('META', 0.931047415459286), ('if', 0.9217343406582769), ('multiple', 0.859703530668646)]
Top words for pretrained_BERT neuron indx 1447 [('operation', 1.0), ('symmetric', 0.8883566557425661), ('afi', 0.8771174099488027), ('TAGS', 0.850790350787013), ('installed', 0.8470256678558924)]
Top words for pretrained_BERT neuron indx 1454 [('yield', 1.0), ('cancel', 0.847972227322222), ('expected', 0.7768335243579992), ('state', 0.7563743356513551), ('partial', 0.7161619320166138)]
Top words for pretrained_BERT neuron indx 3508 [('division', 1.0), ('imports', 0.9984361054413775), ('Basic', 0.9391828819710478), ('a2', 0.8989168680739679), ('math', 0.8938556956478179)]
Top words for pretrained_BERT neuron indx 3516 [('expected', 1.0), ('cleanup', 0.9768173051122779), ('trial', 0.9554855216224865), ('B', 0.8941445397679548), ('hpov', 0.8716912917961656)]
Top words for pretrained_BERT neuron indx 1469 [('choice', 1.0), ('sts', 0.9147814200153689), ('mode', 0.8633326957696736), ('license', 0.8569435277492585), ('enabled', 0.8526656056179298)]
Top words for pretrained_BERT neuron indx 1471 [('management', 1.0), ('dt', 0.8418453299598675), ('realm', 0.7518892297192008), ('security', 0.7367508569516972), ('doc', 0.7288733979521103)]
Top words for pretrained_BERT neuron indx 5578 [('tell', 1.0), ('plural', 0.8511986605528619), ('word', 0.8324370992731219), ('return', 0.7991432729662902), ('next', 0.7479234603539711)]
Top words for pretrained_BERT neuron indx 1492 [('security', 1.0), ('product', 0.840181114803622), ('child', 0.8199178125136668), ('strip', 0.6729218555269846), ('feature', 0.6728824235997866)]
Top words for pretrained_BERT neuron indx 1494 [('count', 1.0), ('close', 0.8846402416411147), ('exists', 0.8822732751911567), ('counts', 0.7888466710276798), ('shape', 0.7729125934205868)]
Top words for pretrained_BERT neuron indx 9692 [('sr', 1.0), ('sd', 0.8710304979303738), ('millis', 0.8664032810928757), ('rd', 0.8619197116008235), ('d', 0.8551732666409932)]
Top words for pretrained_BERT neuron indx 7648 [('internet', 1.0), ('Integer', 0.9206495106277757), ('comment', 0.7710528176580294), ('registry', 0.7689280529405806), ('204', 0.7453679721726308)]
Top words for pretrained_BERT neuron indx 1504 [('alt', 1.0), ('extensions', 0.9787536916116313), ('space', 0.9619360825229158), ('Context', 0.9234476945295875), ('security', 0.8666133745805282)]
Top words for pretrained_BERT neuron indx 1506 [('a1', 1.0), ('keep', 0.9014627300428697), ('cm', 0.8436927391798132), ('submit', 0.8297831166784894), ('chunks', 0.8089202995124162)]
Top words for pretrained_BERT neuron indx 5606 [('V', 1.0), ('2014', 0.7898584934528213), ('v', 0.7784792035605249), ('define', 0.743754425785429), ('BOUNDS', 0.7385557210556064)]
Top words for pretrained_BERT neuron indx 7667 [('Variable', 1.0), ('a', 0.8958337064233244), ('within', 0.8902511394292921), ('DBPORT', 0.8822762557312022), ('7', 0.84145935128757)]
Top words for pretrained_BERT neuron indx 7668 [('descriptor', 1.0), ('Descriptor', 0.9757777436673026), ('for', 0.9066398504750318), ('"FAILED"', 0.8811730693940177), ('2', 0.8484598176354172)]
Top words for pretrained_BERT neuron indx 7674 [('U', 1.0), ('0.8', 0.9500147820461542), ('authJID', 0.9277295923002279), ('y', 0.9136523661090742), ('getTo', 0.8816202285018688)]
Top words for pretrained_BERT neuron indx 7720 [('labels', 1.0), ('cleanup', 0.8281518969502145), ('62', 0.7535574765706021), ('redistricting', 0.7371716796572477), ('Presence', 0.7264845838590647)]
Top words for pretrained_BERT neuron indx 1576 [('upper', 1.0), ('Asset', 0.980675605840055), ('cm', 0.9791190754189589), ('asset', 0.9644377404426943), ('Presence', 0.9542349000593635)]
Top words for pretrained_BERT neuron indx 9772 [('bk', 1.0), ('1800', 0.9945517352817581), ('libraries', 0.9419047855106307), ('by', 0.8694395557102595), ('g', 0.8150032795706048)]
Top words for pretrained_BERT neuron indx 5684 [('is', 1.0), ('in', 0.9738579121843717), ('Int', 0.9506853339993846), ('with', 0.8969303484942689), ('six', 0.8880675906385723)]
Top words for pretrained_BERT neuron indx 3655 [('old', 1.0), ('agency', 0.9829810058585439), ('Exception', 0.9620166956569763), ('called', 0.8923718086420543), ('50', 0.8552008464827117)]
Top words for pretrained_BERT neuron indx 1614 [('repeat', 1.0), ('Unauthorized', 0.9746873841955663), ('read', 0.9633872110014893), ('CHANGESETS', 0.9464844029449786), ('endswith', 0.9126698362740958)]
Top words for pretrained_BERT neuron indx 9811 [('TERMINATE', 1.0), ('GEOSGeometry', 0.9903043617973343), ('y', 0.9559018871299116), ('month', 0.8902543186409406), ('enabled', 0.8809245036252089)]
Top words for pretrained_BERT neuron indx 9812 [('http11', 1.0), ('finally', 0.9652020125333364), ('hpack', 0.9260420164502519), ('30', 0.8863731673562655), ('DistrictFile', 0.8858243739179422)]
Top words for pretrained_BERT neuron indx 7764 [('GEOSGeometry', 1.0), ('Widget', 0.9914987065030246), ('gf', 0.9376054898703421), ('Redshift', 0.815627018870405), ('BRIGHTNESS', 0.8050835020046189)]
Top words for pretrained_BERT neuron indx 5720 [('42', 1.0), ('ll', 0.9607673261160667), ('decimal', 0.9511438672537517), ('variables', 0.8600654750566675), ('lb', 0.8217330705103407)]
Top words for pretrained_BERT neuron indx 5726 [('unicode', 1.0), ('secret', 0.9689147850140346), ('all', 0.943992340352948), ('timezone', 0.9410069280918867), ('horizon', 0.906247872353656)]
Top words for pretrained_BERT neuron indx 7776 [('oslo', 1.0), ('bson', 0.9851930806266562), ('forms', 0.9655936645217341), ('zone', 0.9153143153893117), ('tls', 0.909174330842891)]
Top words for pretrained_BERT neuron indx 9832 [('microseconds', 1.0), ('milliseconds', 0.7629986129055829), ('CommandMock', 0.7325146597736807), ('trello', 0.68333088035034), ('AFI', 0.6706954836465956)]
Top words for pretrained_BERT neuron indx 1645 [('five', 1.0), ('bk', 0.9532381397478243), ('se', 0.909540064928822), ('panel', 0.8931661513734767), ('33', 0.8634768342372763)]
Top words for pretrained_BERT neuron indx 7794 [('available', 1.0), ('button', 0.930294306613728), ('256', 0.8907130173476516), ('Failure', 0.8889186473290037), ('LOG', 0.8832160956882713)]
Top words for pretrained_BERT neuron indx 5747 [('tell', 1.0), ('mark', 0.9952160729739723), ('identical', 0.8647905053185005), ('digest', 0.846908367598183), ('match', 0.8429963284433653)]
Top words for pretrained_BERT neuron indx 3705 [('READY', 1.0), ('999999', 0.9314476327341293), ('Account', 0.9263502129362039), ('common', 0.9172971929615297), ('wait', 0.9136074617858697)]
Top words for pretrained_BERT neuron indx 7804 [('2014', 1.0), ('within', 0.8952818181614267), ('calculators', 0.8424301827337303), ('1970', 0.8254942038052918), ('missing', 0.805392481685082)]
Top words for pretrained_BERT neuron indx 1662 [('providers', 1.0), ('BOUNDS', 0.9867961052418396), ('panels', 0.9518339179665252), ('dt', 0.9070202777754268), ('step', 0.8963217326738514)]
Top words for pretrained_BERT neuron indx 7807 [('I', 1.0), ('patterns', 0.8846544795292787), ('"Height"', 0.8687207835466862), ('"height"', 0.8320795597563553), ('"Width"', 0.8024886644315643)]
Top words for pretrained_BERT neuron indx 1663 [('302', 1.0), ('187', 0.9168668382383557), ('95', 0.9058098231656113), ('1800', 0.8865062387799953), ('realm', 0.8830820079895958)]
Top words for pretrained_BERT neuron indx 5761 [('reason', 1.0), ('K', 0.9564771658440938), ('PROVISION', 0.8832590993813049), ('backwards', 0.8546679891349326), ('undo', 0.8465442153089182)]
Top words for pretrained_BERT neuron indx 1666 [('tenant', 1.0), ('close', 0.9941009997657827), ('south', 0.9181260089107843), ('lower', 0.8495411166760496), ('available', 0.8455295390129715)]
Top words for pretrained_BERT neuron indx 9859 [('2.1', 1.0), ('forms', 0.8872184171553809), ('bool', 0.8818518247297452), ('tagtuple', 0.8550024318746616), ('redistricting', 0.8540560642892063)]
Top words for pretrained_BERT neuron indx 7823 [('flash', 1.0), ('credentials', 0.940443815754283), ('Card', 0.8055566922547376), ('secure', 0.7737054311996324), ('port', 0.7730560515642683)]
Top words for pretrained_BERT neuron indx 1684 [('hidden', 1.0), ('abc', 0.9955353741648227), ('transform', 0.9649988685274196), ('super', 0.9095777422405978), ('117', 0.8689867458407836)]
Top words for pretrained_BERT neuron indx 7832 [('buttons', 1.0), ('Always', 0.989668420594917), ('except', 0.9488730062375247), ('2014', 0.9100307824655948), ('1970', 0.7984623142885894)]
Top words for pretrained_BERT neuron indx 3737 [('avail', 1.0), ('FileData', 0.8988734631164473), ('ydata', 0.8475865406072167), ('sts', 0.8345759362438219), ('by', 0.830352978129411)]
Top words for pretrained_BERT neuron indx 7841 [('opener', 1.0), ('exists', 0.9643738962875592), ('pisa', 0.9594593191304034), ('Cat', 0.9516699891769277), ('variables', 0.9272026757646323)]
Top words for pretrained_BERT neuron indx 9893 [('python', 1.0), ('E', 0.9368704201540917), ('getlist', 0.9075296199534161), ('calculators', 0.8919490176172824), ('list', 0.8899614076413864)]
Top words for pretrained_BERT neuron indx 1705 [('Connection', 1.0), ('connection', 0.9212450215317676), ('ns', 0.880198268448438), ('connectionId', 0.856761478886704), ('direct', 0.8316018145554016)]
Top words for pretrained_BERT neuron indx 7849 [('__import__', 1.0), ('intersects', 0.9201663760680335), ('__hash__', 0.9153089834756568), ('__exit__', 0.893331474959629), ('_attribute', 0.8751644296341372)]
Top words for pretrained_BERT neuron indx 3757 [('600', 1.0), ('200', 0.9651439198526237), ('meta', 0.9597751002365587), ('1000', 0.9436706188541518), ('try', 0.8680115454483361)]
Top words for pretrained_BERT neuron indx 9901 [('twisted', 1.0), ('principal', 0.9320715162945279), ('secret', 0.8878498886170995), ('mark', 0.8038632389952071), ('agency', 0.7828584575156294)]
Top words for pretrained_BERT neuron indx 5812 [('math', 1.0), ('cluster', 0.8588376054920088), ('On', 0.7926154862282142), ('ON', 0.7926154862282142), ('relay', 0.7765611320317629)]
Top words for pretrained_BERT neuron indx 7862 [('secret', 1.0), ('ah', 0.99098274167424), ('Asset', 0.9804458915556052), ('REFERENCES', 0.977528747828168), ('a', 0.9387112235310616)]
Top words for pretrained_BERT neuron indx 9910 [('Label', 1.0), ('Point', 0.9918234191571893), ('Integer', 0.9155854670254615), ('labels', 0.8934117348751748), ('org_flagged', 0.888602932379563)]
Top words for pretrained_BERT neuron indx 3771 [('getType', 1.0), ('lib', 0.9201316466411217), ('enabled', 0.8868738533269095), ('license', 0.8576041803994289), ('Off', 0.8563036702456404)]
Top words for pretrained_BERT neuron indx 1729 [('moderate', 1.0), ('except', 0.9859165150649888), ('File', 0.9329284098403107), ('skip', 0.8782427173617883), ('runner', 0.8340497797942535)]
Top words for pretrained_BERT neuron indx 9929 [('sub', 1.0), ('Output', 0.9876053492927186), ('Input', 0.947239931614842), ('If', 0.9367318776287348), ('SON', 0.9182741152947141)]
Top words for pretrained_BERT neuron indx 7886 [('unique', 1.0), ('submit', 0.9700334948388732), ('Core', 0.969320088733851), ('RESERVE', 0.8389150415469494), ('after', 0.8348356814776282)]
Top words for pretrained_BERT neuron indx 7912 [('score', 1.0), ('min_version', 0.9566362950752113), ('fileno', 0.923812275256204), ('advertiser', 0.9137886877061532), ('"0800305c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.8644924736983559)]
Top words for pretrained_BERT neuron indx 3817 [('j', 1.0), ('management', 0.7039938809602628), ('description', 0.6865590587300965), ('Presence', 0.6735050914583033), ('simulation', 0.6475505711597498)]
Top words for pretrained_BERT neuron indx 7914 [('NODES', 1.0), ('mac', 0.9963684759833547), ('outgoing', 0.9698083033814451), ('n', 0.9587247418516424), ('forwards', 0.9384248071289777)]
Top words for pretrained_BERT neuron indx 1771 [('REFERENCES', 1.0), ('upper', 0.9315031904663453), ('resource', 0.916279544357177), ('NODE', 0.9158638738643843), ('license', 0.8841603678571995)]
Top words for pretrained_BERT neuron indx 9962 [('tasks', 1.0), ('lon__gt', 0.8833896100048543), ('lon__lt', 0.8438466371690875), ('version__lte', 0.8276748085217067), ('flat', 0.802227963667778)]
Top words for pretrained_BERT neuron indx 1780 [('WAY', 1.0), ('hyper', 0.8856998594998142), ('view', 0.8013352882012766), ('Geo', 0.784501014831005), ('View', 0.783411953055726)]
Top words for pretrained_BERT neuron indx 9972 [('"SUCCEEDED"', 1.0), ('"FAILED"', 0.9338464038845576), ('descriptor', 0.9289015621128984), ('"KILLED"', 0.9132358113201274), ('AREA', 0.8918523677063955)]
Top words for pretrained_BERT neuron indx 9981 [('listen', 1.0), ('36', 0.9605410200816386), ('recordings', 0.9325105341114092), ('Simulator', 0.8618464363517561), ('35', 0.8239927220040574)]
Top words for pretrained_BERT neuron indx 5886 [('omit', 1.0), ('unquote', 0.8729844515999687), ('View', 0.768040127928837), ('util', 0.7620261442528115), ('contrib', 0.7244510889069833)]
Top words for pretrained_BERT neuron indx 7941 [('recordings', 1.0), ('Int', 0.9856188605589954), ('"--version"', 0.9466581879347318), ('","', 0.9212694482276459), ('"--include"', 0.9071604744465096)]
Top words for pretrained_BERT neuron indx 7945 [('1800', 1.0), ('utc', 0.9986891037012074), ('in', 0.9678497817292098), ('90.0', 0.9618122973178064), ('milliseconds', 0.9254176037604391)]
Top words for pretrained_BERT neuron indx 1808 [('web', 1.0), ('license', 0.9632420048963266), ('repository', 0.8016614698940366), ('broker', 0.7787957516994082), ('transaction', 0.7219490647925083)]
Top words for pretrained_BERT neuron indx 7956 [('mins', 1.0), ('broadcast', 0.9917889453015584), ('millis', 0.924283347833265), ('seconds', 0.9237366664007831), ('sconff', 0.8911599759839085)]
Top words for pretrained_BERT neuron indx 3868 [('polygon', 1.0), ('Update', 0.8667168361964851), ('pass_hint', 0.8531132085624494), ('C', 0.8185929100905832), ('_tuple', 0.7991474141276558)]
Top words for pretrained_BERT neuron indx 7965 [('now', 1.0), ('erase', 0.9128197130400724), ('no', 0.9109406861425539), ('opacity', 0.8203090540672331), ('principal', 0.8144764071927503)]
Top words for pretrained_BERT neuron indx 1826 [('collect', 1.0), ('Wire', 0.947881750456341), ('button', 0.943539805792896), ('warn', 0.8957826077038212), ('step', 0.8940662930491234)]
Top words for pretrained_BERT neuron indx 1836 [('el', 1.0), ('reset', 0.9627052652610044), ('insert', 0.942590304424094), ('k', 0.9240408167858084), ('DEFAULT', 0.8613979778613695)]
Top words for pretrained_BERT neuron indx 1853 [('baseline', 1.0), ('python', 0.8943783719697556), ('maximum', 0.8771596042669564), ('bk', 0.8468022035431271), ('host', 0.8377666910372352)]
Top words for pretrained_BERT neuron indx 7999 [('flask', 1.0), ('750', 0.9001949280333377), ('is', 0.8799255502948276), ('3785', 0.8536654260078725), ('74.616338', 0.8380318916243081)]
Top words for pretrained_BERT neuron indx 3911 [('WAYS', 1.0), ('cipher', 0.9906743155745219), ('upstream', 0.9496589432227229), ('a2', 0.9292776474425303), ('min', 0.9289657562010053)]
Top words for pretrained_BERT neuron indx 8024 [('sender', 1.0), ('ip', 0.8737599867140294), ('Switch', 0.8453266873944454), ('packet', 0.8427302038401637), ('sorted', 0.8293624988104792)]
Top words for pretrained_BERT neuron indx 1884 [('operator', 1.0), ('load', 0.9927258757307063), ('mark', 0.9910986918239464), ('warn', 0.9733950593440748), ('Log', 0.9566891720653228)]
Top words for pretrained_BERT neuron indx 1886 [('unicode', 1.0), ('Dummy', 0.9000637548963057), ('secret', 0.8340122022890747), ('order', 0.8255731419442686), ('mock', 0.7991918066499557)]
Top words for pretrained_BERT neuron indx 5999 [('transfer', 1.0), ('after', 0.9495826968307385), ('translation', 0.9404621291989156), ('imports', 0.8855177001031761), ('convert', 0.8655985373972955)]
Top words for pretrained_BERT neuron indx 6013 [('302', 1.0), ('204', 0.9834749374990486), ('443', 0.9523845506389068), ('28', 0.9345155519456444), ('187', 0.8868204878388937)]
Top words for pretrained_BERT neuron indx 3966 [('BOUNDS', 1.0), ('requires', 0.9160541608542533), ('experiments', 0.828806459613023), ('now', 0.784917391499739), ('Criteria', 0.7846544616824256)]
Top words for pretrained_BERT neuron indx 1921 [('seek', 1.0), ('proxy', 0.9996815860706653), ('MANIFEST', 0.9355117746453468), ('filters', 0.9092937109057384), ('blend', 0.9061557492189137)]
Top words for pretrained_BERT neuron indx 8070 [('42', 1.0), ('75', 0.9597933304799758), ('2014', 0.8916843556246895), ('"0"', 0.8743468024055469), ('"b"', 0.8183332999546945)]
Top words for pretrained_BERT neuron indx 6029 [('restart', 1.0), ('CREATING', 0.9737886215669737), ('width', 0.8302196945384115), ('fab', 0.8202194361683697), ('FSM', 0.8032076050500457)]
Top words for pretrained_BERT neuron indx 8077 [('Action', 1.0), ('Clock', 0.8857464365080693), ('action', 0.7204465018329724), ('Job', 0.7020849855803725), ('g', 0.6681607302925363)]
Top words for pretrained_BERT neuron indx 6032 [('tell', 1.0), ('agency', 0.8446713738865987), ('negotiate', 0.7165168992476628), ('finally', 0.70878708767379), ('READY', 0.6685290999234591)]
Top words for pretrained_BERT neuron indx 8080 [('a', 1.0), ('auditor', 0.9897685693223783), ('venue', 0.963145955720072), ('A', 0.9510237041555504), ('75', 0.9412220669805125)]
Top words for pretrained_BERT neuron indx 1937 [('ts', 1.0), ('nh', 0.8996842331890056), ('Core', 0.8221705132530498), ('USAGE', 0.7855881074366053), ('Billboard', 0.7505100380520454)]
Top words for pretrained_BERT neuron indx 1940 [('exclude', 1.0), ('framing', 0.9805915031966325), ('Subject', 0.9122281537761274), ('seek', 0.8991771402822372), ('probe', 0.8832484984573838)]
Top words for pretrained_BERT neuron indx 8091 [('86400', 1.0), ('117', 0.9345095180419182), ('95', 0.9222923368170352), ('300', 0.9059819756718388), ('17', 0.8477327547237087)]
Top words for pretrained_BERT neuron indx 8102 [('302', 1.0), ('31', 0.9115366466254049), ('6', 0.911002619581923), ('36', 0.9076553850838603), ('127', 0.9023216591724177)]
Top words for pretrained_BERT neuron indx 8104 [('Tab', 1.0), ('next', 0.9932227112701789), ('first', 0.9664958127772413), ('sqrt', 0.8946164557221047), ('command', 0.894261778482388)]
Top words for pretrained_BERT neuron indx 8116 [('relay', 1.0), ('slot', 0.9550589277771125), ('187', 0.9365045234823459), ('math', 0.9330189254159288), ('or', 0.9215750684025766)]
Top words for pretrained_BERT neuron indx 1999 [('info', 1.0), ('INFO', 0.9869528091782623), ('clock', 0.90876738962218), ('flags', 0.874362429575163), ('Criteria', 0.8660418947516886)]
Top words for pretrained_BERT neuron indx 2005 [('Off', 1.0), ('flush', 0.9768125219902706), ('body', 0.964482836492331), ('stanza', 0.8990434150784464), ('rv', 0.8484194691885629)]
Top words for pretrained_BERT neuron indx 6102 [('fail', 1.0), ('requires', 0.7457620487036748), ('destroy', 0.7309659778228934), ('tornado', 0.718407653953222), ('close', 0.7072030524341467)]
Top words for pretrained_BERT neuron indx 2007 [('CONNECTED', 1.0), ('stat', 0.7979088232217929), ('horizon', 0.7599764611498773), ('usage', 0.7182455567114375), ('sr', 0.7181433080780253)]
Top words for pretrained_BERT neuron indx 2009 [('sp', 1.0), ('asset', 0.8733965113088106), ('Asset', 0.8732243112246513), ('word', 0.762442862345104), ('valid', 0.7604198792339393)]
Top words for pretrained_BERT neuron indx 6121 [('j', 1.0), ('simulation', 0.5857032150346566), ('one', 0.5280452653669421), ('Variable', 0.5252455551836351), ('p', 0.5196505575535364)]
Top words for pretrained_BERT neuron indx 4079 [('sp', 1.0), ('u', 0.9717268146971195), ('migrate', 0.9574430186493381), ('values', 0.9107022938441427), ('fileName', 0.905401537631704)]
Top words for pretrained_BERT neuron indx 6132 [('south', 1.0), ('pushkin', 0.9837747345013389), ('cb', 0.9762840312473361), ('binascii', 0.9569527512244231), ('pack', 0.954332512348942)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0090
Epoch: [3/10], Loss: 0.0070
Epoch: [4/10], Loss: 0.0064
Epoch: [5/10], Loss: 0.0060
Epoch: [6/10], Loss: 0.0056
Epoch: [7/10], Loss: 0.0053
Epoch: [8/10], Loss: 0.0050
Epoch: [9/10], Loss: 0.0049
Epoch: [10/10], Loss: 0.0047
Score (accuracy) of the probe: 0.60
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0091
Epoch: [3/10], Loss: 0.0071
Epoch: [4/10], Loss: 0.0065
Epoch: [5/10], Loss: 0.0060
Epoch: [6/10], Loss: 0.0056
Epoch: [7/10], Loss: 0.0053
Epoch: [8/10], Loss: 0.0051
Epoch: [9/10], Loss: 0.0050
Epoch: [10/10], Loss: 0.0048
Score (accuracy) of the probe: 0.61
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0121
Epoch: [2/10], Loss: 0.0092
Epoch: [3/10], Loss: 0.0073
Epoch: [4/10], Loss: 0.0067
Epoch: [5/10], Loss: 0.0063
Epoch: [6/10], Loss: 0.0059
Epoch: [7/10], Loss: 0.0058
Epoch: [8/10], Loss: 0.0055
Epoch: [9/10], Loss: 0.0055
Epoch: [10/10], Loss: 0.0052
Score (accuracy) of the probe: 0.61
Training classification probe
Creating model...
Number of training instances: 27115
Number of classes: 4
Epoch: [1/10], Loss: 0.0132
Epoch: [2/10], Loss: 0.0107
Epoch: [3/10], Loss: 0.0092
Epoch: [4/10], Loss: 0.0089
Epoch: [5/10], Loss: 0.0089
Epoch: [6/10], Loss: 0.0087
Epoch: [7/10], Loss: 0.0088
Epoch: [8/10], Loss: 0.0087
Epoch: [9/10], Loss: 0.0088
Epoch: [10/10], Loss: 0.0089
Score (accuracy) of the probe: 0.59

The best l1=0, the best l2=0.001 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.26
{'__OVERALL__': 0.25646551724137934, 'NAME': 0.22937625754527163, 'STRING': 0.1836441893830703, 'NUMBER': 0.33506044905008636, 'KEYWORD': 0.2906764168190128}
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.24

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.7185344827586206
----------------------------------------------------------------
