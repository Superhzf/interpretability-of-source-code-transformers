Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
1289 13.0
Number of tokens:  11684
length of source dictionary:  1042
length of target dictionary:  35
11684
Total instances: 11684
['def', 'Plugin', '__init__', 'get_utilization', 'svc', 'v', 'ReflectionProbeUsage', '~~', 'symlink', 'astimezone', 'epoch_secs', '###', 'future', 'send_presence', 'force', 'ny_datetime', 'raise', 'associatedLIGs', 'None_', 'MAXCLUB']
Number of samples:  11684
Stats: Labels with their frequencies in the final set
NAME 3656
NEWLINE 1172
KEYWORD 905
LPAR 870
RPAR 866
DOT 858
EQUAL 597
COMMA 576
COLON 447
DEDENT 369
INDENT 293
LSQB 204
RSQB 204
NUMBER 190
NL 117
STRING 82
EQEQUAL 48
PLUS 33
LBRACE 25
STAR 24
RBRACE 24
MINUS 22
PERCENT 22
AT 14
PLUSEQUAL 12
GREATER 11
NOTEQUAL 10
DOUBLESTAR 8
LESS 7
SLASH 5
COMMENT 4
GREATEREQUAL 3
MINEQUAL 3
LESSEQUAL 2
SEMI 1
pretrained_BERT distribution after trauncating:
{0: 0.7564659631698738, 3: 0.1872542933995448, 2: 0.03931305607283261, 1: 0.01696668735774881}
{0: 3656, 3: 905, 2: 190, 1: 82}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
494 13.0
Number of tokens:  6400
length of source dictionary:  482
length of target dictionary:  34
6400
Total instances: 6400
['def', '__init__', 'tensor', 'crop_layer', '~~', 'raise', 'test_crop_inputs', 'tuple', 'subtract_mv', 'results', 'b1_h', '&', 'downsample', 'model', 'in_shapes', 'sigmoid', 'inputs', 'x0', 'modules', 'AssertionError']
Number of samples:  6400
Stats: Labels with their frequencies in the final set
NAME 1721
COMMA 798
NUMBER 482
RPAR 439
LPAR 437
NEWLINE 433
DOT 348
KEYWORD 336
COLON 293
EQUAL 241
LSQB 233
RSQB 228
DEDENT 97
INDENT 82
STAR 62
NL 60
EQEQUAL 29
PLUS 26
MINUS 15
DOUBLESTAR 7
SLASH 6
AT 6
STRING 4
LBRACE 3
RBRACE 3
STAREQUAL 2
PERCENT 2
GREATER 1
LESS 1
COMMENT 1
GREATEREQUAL 1
PLUSEQUAL 1
LESSEQUAL 1
AMPER 1
pretrained_BERT distribution after trauncating:
{0: 0.6767597325992922, 2: 0.18953991348800628, 3: 0.1321274085725521, 1: 0.0015729453401494297}
{0: 1721, 2: 482, 3: 336, 1: 4}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 3656, 3: 905, 2: 190, 1: 82})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({0: 1454, 2: 87, 3: 24, 1: 4})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (4349, 9984)
The shape of the validation set: (484, 9984)
The shape of the testing set: (1569, 9984)
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0002
Epoch: [4/10], Loss: 0.0001
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0043
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0002
Epoch: [4/10], Loss: 0.0001
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0044
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0054
Epoch: [2/10], Loss: 0.0019
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.88
{'__OVERALL__': 0.875717017208413, 'NAME': 0.8658872077028886, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0033
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0076
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0044
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8355640535372849, 'NAME': 0.8390646492434664, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0099
Epoch: [2/10], Loss: 0.0049
Epoch: [3/10], Loss: 0.0037
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0027
Epoch: [6/10], Loss: 0.0025
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.822817080943276, 'NAME': 0.8253094910591472, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.0}
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0039
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0086
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0027
Epoch: [4/10], Loss: 0.0020
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0010
Epoch: [9/10], Loss: 0.0009
Epoch: [10/10], Loss: 0.0008
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0050
Epoch: [3/10], Loss: 0.0038
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0025
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0023
Epoch: [10/10], Loss: 0.0022
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.815806246016571, 'NAME': 0.8170563961485557, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.041666666666666664}
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0087
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.8419375398342893, 'NAME': 0.8314993122420908, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.875}
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0088
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.83
{'__OVERALL__': 0.8272785213511791, 'NAME': 0.813617606602476, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0018
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0045
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0030
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.83
{'__OVERALL__': 0.82855321861058, 'NAME': 0.8149931224209078, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0033
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0081
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0014
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0043
Epoch: [3/10], Loss: 0.0034
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0022
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.85
{'__OVERALL__': 0.847036328871893, 'NAME': 0.8349381017881705, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0079
Epoch: [2/10], Loss: 0.0040
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0027
Epoch: [5/10], Loss: 0.0024
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0020
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.85
{'__OVERALL__': 0.8521351179094965, 'NAME': 0.8404401650618982, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0018
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0010
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0070
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0071
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0030
Epoch: [4/10], Loss: 0.0025
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0021
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0019
Epoch: [10/10], Loss: 0.0018
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.88
{'__OVERALL__': 0.8789037603569152, 'NAME': 0.8700137551581844, 'STRING': 1.0, 'NUMBER': 0.9885057471264368, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0070
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0017
Epoch: [4/10], Loss: 0.0012
Epoch: [5/10], Loss: 0.0009
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0004
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0026
Epoch: [3/10], Loss: 0.0017
Epoch: [4/10], Loss: 0.0012
Epoch: [5/10], Loss: 0.0009
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0070
Epoch: [2/10], Loss: 0.0027
Epoch: [3/10], Loss: 0.0018
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0035
Epoch: [3/10], Loss: 0.0028
Epoch: [4/10], Loss: 0.0024
Epoch: [5/10], Loss: 0.0022
Epoch: [6/10], Loss: 0.0021
Epoch: [7/10], Loss: 0.0020
Epoch: [8/10], Loss: 0.0019
Epoch: [9/10], Loss: 0.0018
Epoch: [10/10], Loss: 0.0018
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.1 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.90
{'__OVERALL__': 0.9031230082855322, 'NAME': 0.8954607977991746, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0067
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0066
Epoch: [2/10], Loss: 0.0028
Epoch: [3/10], Loss: 0.0019
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0011
Epoch: [6/10], Loss: 0.0009
Epoch: [7/10], Loss: 0.0007
Epoch: [8/10], Loss: 0.0006
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0068
Epoch: [2/10], Loss: 0.0029
Epoch: [3/10], Loss: 0.0020
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0007
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0038
Epoch: [3/10], Loss: 0.0030
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0023
Epoch: [6/10], Loss: 0.0022
Epoch: [7/10], Loss: 0.0021
Epoch: [8/10], Loss: 0.0020
Epoch: [9/10], Loss: 0.0019
Epoch: [10/10], Loss: 0.0019
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.88
{'__OVERALL__': 0.8840025493945188, 'NAME': 0.874828060522696, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0073
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0068
Epoch: [2/10], Loss: 0.0030
Epoch: [3/10], Loss: 0.0021
Epoch: [4/10], Loss: 0.0015
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0008
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0068
Epoch: [2/10], Loss: 0.0031
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0017
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0043
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0028
Epoch: [5/10], Loss: 0.0025
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0020
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.90
{'__OVERALL__': 0.8986615678776291, 'NAME': 0.890646492434663, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0026
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0015
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0077
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0010
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0069
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0025
Epoch: [4/10], Loss: 0.0019
Epoch: [5/10], Loss: 0.0016
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0010
Epoch: [9/10], Loss: 0.0009
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0036
Epoch: [4/10], Loss: 0.0031
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0026
Epoch: [7/10], Loss: 0.0024
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0023
Epoch: [10/10], Loss: 0.0022
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.87
{'__OVERALL__': 0.8667941363926067, 'NAME': 0.8562585969738652, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.93

pretrained_BERT top neurons
array([4102, 8200, 4104, 4106, 6155, 8204, 6152,   14,   20, 6172, 2079,
       4132, 4148, 8245,   62, 2112, 4164, 2119, 4171,   76, 2124, 4184,
       4190, 6240, 6241, 4193, 2152, 2160, 6263, 6265, 6266, 6267,  122,
       4225, 8322, 6284,  143, 4242, 4247, 6298, 4253, 4254, 6313, 6314,
        172, 4271, 4272, 2231, 8376, 2239, 4291, 6339, 8389, 6343,  201,
       2262,  215, 6362,  221, 8415, 4320, 6374, 8424, 2281,  237, 8434,
       4338, 6389, 2299, 4351,  257, 4360, 6408,  268, 2317, 2318, 4366,
        272, 6417, 6422,  279,  282, 8476, 8479, 2353, 6450,  307, 6452,
        308, 8501, 4416, 4425, 8523,  333, 6489, 6499, 6504, 2409, 8561,
       6517, 8567,  376,  380, 8572, 6528,  385, 8580,  395, 8590, 6551,
       6563, 4517,  422,  429, 6573,  432,  441, 4539,  444, 2495, 2497,
       8643,  451, 6595, 6616, 6618, 6624, 2538, 2539, 6634,  499, 4616,
       6669, 6670, 4622,  528, 8724, 4629,  538, 8733,  543, 2592,  551,
        560, 2612, 6711, 4676, 6729,  587, 8787, 4692, 8793, 2654, 4713,
       4714, 8812,  620, 8815,  624,  627,  635,  636, 8829, 2689, 8834,
       4739, 8845, 6797, 4751, 8848, 4750, 2705, 8852, 8855, 2711, 2717,
       2718, 8863,  672, 8867, 6821, 2726,  679,  677, 4778, 2745, 2748,
       8895, 8901, 6856, 6857, 4810, 6863, 6867,  725, 6870,  726, 8924,
        736, 6885,  758,  759, 6911, 8964, 4870, 4872, 8972, 4877, 6926,
       2832, 8976, 6942, 6952, 4916, 9013, 9016, 4932, 2887, 9033, 4939,
       7003, 7008,  868, 7015, 2920, 7024, 4979, 4990, 4993, 4994, 7042,
        898, 7049, 9100, 2959, 5015, 5022, 9119, 5024, 9125, 2981, 2983,
       7081, 7082,  940, 2999, 5052,  958, 9151, 7107,  970, 7115, 9167,
       3030, 7134,  990, 9189,  999, 7146, 1003, 1010, 9223, 7197, 7217,
       7218, 1077, 5184, 9281, 7236, 3143, 1101, 7263, 7266, 9322, 7279,
       5239, 5240, 5243, 5245, 3198, 5250, 7309, 7312, 5266, 7317, 7319,
       7325, 7326, 7331, 3255, 5304, 1209, 1218, 1219, 5334, 7384, 7388,
       7392, 7394, 3299, 9442, 3303, 9450, 3306, 3307, 7406, 7428, 3334,
       7436, 1293, 5390, 5394, 1303, 9495, 9501, 3364, 3368, 1333, 3384,
       3387, 3397, 1351, 3414, 9560, 1372, 3422, 1384, 5482, 1387, 9580,
       1392, 7537, 9590, 3447, 1403, 1404, 1405, 9597, 5499, 3457, 9602,
       7560, 5516, 7565, 5518, 5519, 9616, 1425, 7568, 1424, 7572, 9623,
       3479, 9630, 7583, 3491, 7589, 1445, 1447, 5545, 3499, 9647, 5559,
       7608, 3513, 3516, 1469, 3520, 1473, 5571, 7624, 1483, 5579, 1494,
       9694, 9696, 7649, 9697, 5601, 7656, 5610, 9707, 7660, 7662, 7668,
       1527, 3584, 9736, 3592, 1549, 5645, 1550, 1567, 9771, 5684, 5691,
       5694, 3648, 1600, 5700, 3655, 5718, 5725, 5730, 5731, 9844, 7799,
       3707, 7804, 7807, 9859, 7812, 5773, 3727, 3728, 5783, 9881, 5795,
       9891, 9893, 3757, 5807, 7855, 5820, 1729, 7875, 5827, 1742, 9935,
       7888, 9942, 5856, 7905, 3808, 5859, 5862, 7914, 3822, 7920, 7922,
       5878, 7929, 9978, 1798, 5896, 3848, 7959, 1816, 3866, 7965, 1824,
       1828, 1846, 7992, 3902, 7999, 5956, 3911, 1875, 1886, 8038, 3946,
       8044, 3949, 8047, 1911, 1921, 8066, 8076, 8077, 6030, 3982, 8080,
       8081, 6029, 1937, 6040, 1949, 8099, 1958, 4010, 8111, 8114, 1977,
       6081, 4033, 4035, 8131, 1987, 2009, 8156, 4063, 6113, 6126, 8174])
pretrained_BERT top neurons per class
{'NAME': array([7656, 5684, 7331, 6942, 6452, 5795, 6563, 8080, 9580, 9167, 2152,
       6172, 7392, 7279, 6551, 6616,  560, 6618, 9125, 8812,  172, 8845,
       7384, 2999, 1405, 3655, 8044, 4692, 4148, 6504, 4993, 4714,  528,
       2112,  380, 5856, 3334, 9450,  499, 6624, 7312, 8724, 7812, 8424,
       5783, 6870, 4916, 8855,  385, 1798, 7317, 6821,  759, 7146, 3949,
       8964, 9623, 8848, 1958, 2539, 1003,  333, 8787,   76, 6113, 1384,
       9844, 1303, 8077, 8815,  268,  624, 8590, 5518, 6499, 7406, 4360,
       3299, 3447, 7799, 8047, 7436, 4247, 3457, 7319, 2711, 5482, 4102,
        395, 1977, 8829, 3648, 2538,  432, 4320, 2726, 3306, 4994, 4979,
       2748, 1209, 2318,  587,  679, 4713, 3982, 8111, 4939, 5731, 7217,
       2231, 4171, 4810, 5519, 6489,  308,  422, 7015,  272,  543, 4870,
       9881, 2592, 5245,  444, 5807, 7668, 1527, 8200,  940, 1101, 8038,
       3368, 8076, 6952, 6374, 6155, 9616, 9696, 1473, 5956, 1218, 4751,
       9016, 7660, 7589, 7807, 7905, 3757, 7428, 9223, 5394]), 'STRING': array([7560, 6489, 8848, 4351, 8077, 7115, 7875, 4190, 9013, 7331,  538,
       8643,  272, 8834, 6616, 9602, 5304, 4993, 9616, 9623, 5783, 2152,
       1403, 4872, 1219, 8733, 1469, 4104, 7624, 7929, 3143, 3911, 2832,
       1387, 4539, 1886, 6863, 1742, 5015, 6313, 1824, 5878, 2887, 1600,
       7309, 2317, 1003, 8066, 9580, 2654, 1425, 8415, 3822, 3414, 9151,
       4877, 8567, 7662, 7568, 7799, 6528, 8845, 5859, 9736,  635, 4253,
       2239, 4148, 7384, 6408, 4106,  307, 1445, 7134, 8863, 1351, 8099,
       7959, 5773, 7146, 9450, 1816, 7572, 7107, 4676, 6870, 8924, 8815,
       5266, 4254, 8322, 7583, 7920, 1549, 9495, 5896, 5718, 7649, 4360,
       5516, 9859, 9697, 9694, 9033, 1010, 7081, 6241, 2920, 9597, 3902,
       3422, 3584, 5645, 8852,  395, 7855, 9893,  758, 9942, 7394, 3592,
       2612, 8245, 8389, 1333,  376,  385, 4184,  677, 2353, 8501, 1494,
       7197, 7317,  257,  620, 5545, 6126, 6030, 7049, 8976, 6267, 7905,
       8114, 6857]), 'NUMBER': array([6563, 4993, 7331, 8848, 7965, 3648, 2262, 8572, 9616, 5184, 3491,
       1404, 8156, 1403, 7914, 7115, 5052, 3516, 9978, 2409,  677, 4225,
       1372, 2689,  432, 8815, 1445, 4979, 2981, 3030, 5783, 3479, 5795,
       8204, 6797, 2152, 1101, 2079,   62, 7042, 8580, 8081, 8829, 5820,
       8434, 8972, 6389, 1447, 6729, 7875, 1824, 8080,  395, 6040, 3707,
        726, 4193, 6298, 6821, 6711,  636,  538, 6885, 3307,  635, 2112,
       9630, 4692, 6362, 7003, 2983, 5610, 7326, 8845, 3727, 8867, 1875,
       6669, 3255, 6081,  672, 6240, 3387, 5239, 2124, 1483, 7325, 9647,
       4517, 6408,  279, 5240, 5571, 3848, 9736, 9281, 4035, 8733, 4750,
       9100, 4539,  237,  551, 6422, 6343,  282, 9501, 7024, 3866, 5579,
       9707, 2239, 6634,  999, 5015, 5024, 4425, 7589, 8924, 7388, 3303,
       4416, 8476, 7263, 5691, 6417, 7992, 2745, 7197, 5725, 8077, 8787,
       6113, 6517, 6152, 5559, 4242,  441, 4272, 5694, 1846, 5243, 4616,
       2711, 7807, 9891, 1387, 4338, 6263, 8895]), 'KEYWORD': array([9119,  221, 2717, 6029, 4010, 7565, 3384, 4932, 8901, 9623, 7875,
       8376, 5827, 7082, 9935, 7804,  970,  215,  201, 6797, 1392, 6551,
       7608,   20, 2887, 6284, 8131, 6926, 9771,  627,  624, 5601,  429,
       5022, 6670, 5700, 4692,  143, 7279, 8867,  990, 4271,  451, 4778,
       4132, 9891, 6856, 7537, 2281, 7266, 4164,  620, 3808, 9590, 4739,
       8815, 4714, 4254, 9322, 7146, 5250, 7218, 2160, 8561, 9560, 9630,
       8099, 3946, 1937, 6885, 8174, 8793, 9647, 2009, 1816, 5499, 4063,
       4517, 5390, 7922, 6267,  725, 2119, 9189, 3364, 4291, 6573, 2705,
       3949, 8111, 6911, 8523, 7888, 4366, 6595, 1921, 2299, 3728, 1798,
         76, 2152, 1424, 4622, 3499, 1949, 8572, 5862, 7236, 1828, 5394,
       7008, 5730, 6265, 9450,  736, 9442,  868, 1351, 1987,   14, 1911,
        958, 2497, 2959, 1077, 7999, 6374, 6266, 3513, 1550, 6339, 4990,
       6867, 1567, 2718, 3397, 6450, 4033, 1209, 8479, 6240, 6314, 3520,
       5334,  898, 1729, 1293, 3198, 2495, 4629, 1303, 7914, 2689,  122])}
The shape of selected features (4349, 495)
The shape of the training set: (4349, 495)
The shape of the validation set: (484, 495)
The shape of the testing set: (1569, 495)
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0064
Epoch: [2/10], Loss: 0.0021
Epoch: [3/10], Loss: 0.0012
Epoch: [4/10], Loss: 0.0009
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0064
Epoch: [2/10], Loss: 0.0021
Epoch: [3/10], Loss: 0.0012
Epoch: [4/10], Loss: 0.0009
Epoch: [5/10], Loss: 0.0006
Epoch: [6/10], Loss: 0.0005
Epoch: [7/10], Loss: 0.0004
Epoch: [8/10], Loss: 0.0004
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0003
Score (accuracy) of the probe: 0.99
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0066
Epoch: [2/10], Loss: 0.0022
Epoch: [3/10], Loss: 0.0014
Epoch: [4/10], Loss: 0.0010
Epoch: [5/10], Loss: 0.0008
Epoch: [6/10], Loss: 0.0007
Epoch: [7/10], Loss: 0.0006
Epoch: [8/10], Loss: 0.0005
Epoch: [9/10], Loss: 0.0005
Epoch: [10/10], Loss: 0.0004
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0032
Epoch: [3/10], Loss: 0.0024
Epoch: [4/10], Loss: 0.0021
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0018
Epoch: [8/10], Loss: 0.0017
Epoch: [9/10], Loss: 0.0017
Epoch: [10/10], Loss: 0.0016
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.001 for pretrained_BERT_top5%_neurons
Accuracy on the test set of probing pretrained_BERT_top5%_neurons of all layers:
Score (accuracy) of the probe: 0.92
{'__OVERALL__': 0.9216061185468452, 'NAME': 0.9174690508940853, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.875}
Accuracy on the test set of pretrained_BERT_top5%_neurons model using the intercept:
Score (accuracy) of the probe: 0.93
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0042
Epoch: [3/10], Loss: 0.0029
Epoch: [4/10], Loss: 0.0022
Epoch: [5/10], Loss: 0.0018
Epoch: [6/10], Loss: 0.0015
Epoch: [7/10], Loss: 0.0013
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0009
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0078
Epoch: [2/10], Loss: 0.0044
Epoch: [3/10], Loss: 0.0031
Epoch: [4/10], Loss: 0.0023
Epoch: [5/10], Loss: 0.0019
Epoch: [6/10], Loss: 0.0016
Epoch: [7/10], Loss: 0.0014
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0080
Epoch: [2/10], Loss: 0.0046
Epoch: [3/10], Loss: 0.0033
Epoch: [4/10], Loss: 0.0026
Epoch: [5/10], Loss: 0.0021
Epoch: [6/10], Loss: 0.0018
Epoch: [7/10], Loss: 0.0016
Epoch: [8/10], Loss: 0.0014
Epoch: [9/10], Loss: 0.0013
Epoch: [10/10], Loss: 0.0012
Score (accuracy) of the probe: 0.97
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0093
Epoch: [2/10], Loss: 0.0056
Epoch: [3/10], Loss: 0.0042
Epoch: [4/10], Loss: 0.0036
Epoch: [5/10], Loss: 0.0032
Epoch: [6/10], Loss: 0.0029
Epoch: [7/10], Loss: 0.0027
Epoch: [8/10], Loss: 0.0026
Epoch: [9/10], Loss: 0.0025
Epoch: [10/10], Loss: 0.0024
Score (accuracy) of the probe: 0.98

The best l1=0, the best l2=0 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.90
{'__OVERALL__': 0.8954748247291269, 'NAME': 0.8872077028885832, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.93
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 4102 [('write', 1.0), ('utc', 0.9861331607522742), ('passwd', 0.966900327634719), ('ping', 0.9542750357257643), ('2', 0.9477220497625481)]
Top words for pretrained_BERT neuron indx 8200 [('pop', 1.0), ('count', 0.7326807622707762), ('60', 0.7237621182511311), ('1000', 0.7051415358467235), ('40', 0.7006560811867583)]
Top words for pretrained_BERT neuron indx 4104 [('Distance', 1.0), ('""', 0.9894431353567612), ('debug', 0.9433739873023773), ('topid', 0.8139487019205446), ('localize', 0.8036316155557469)]
Top words for pretrained_BERT neuron indx 4106 [('root', 1.0), ('Digest', 0.9795825729455422), ('tag', 0.9156541530970571), ('core', 0.9116120338255793), ('digest', 0.9099151768118403)]
Top words for pretrained_BERT neuron indx 6155 [('7', 1.0), ('9', 0.9237821033526467), ('17', 0.8798314248181615), ('14', 0.8543890447209935), ('12', 0.8513853544616283)]
Top words for pretrained_BERT neuron indx 8204 [('6', 1.0), ('40', 0.9990579730809405), ('On', 0.9713507996595363), ('v', 0.9527206473478074), ('17', 0.9521950036806235)]
Top words for pretrained_BERT neuron indx 6152 [('super', 1.0), ('type', 0.8675334850513828), ('group', 0.7026144014563215), ('items', 0.6963877242921206), ('Register', 0.6900235684453034)]
Top words for pretrained_BERT neuron indx 14 [('connection', 1.0), ('link', 0.9838093831576273), ('key', 0.927353095130522), ('len', 0.8903649072875718), ('Tab', 0.8606218720585523)]
Top words for pretrained_BERT neuron indx 20 [('st', 1.0), ('v', 0.9460825645154204), ('blocking', 0.7859003728618635), ('action', 0.7688472908393672), ('ref', 0.7559595836075697)]
Top words for pretrained_BERT neuron indx 6172 [('loads', 1.0), ('us', 0.895888149567007), ('View', 0.8310894222514946), ('objects', 0.8131855945072295), ('to', 0.8008497249996924)]
Top words for pretrained_BERT neuron indx 2079 [('description', 1.0), ('direct', 0.9725965831202334), ('models', 0.9380063191725477), ('if', 0.9186650083319022), ('errors', 0.915188392002063)]
Top words for pretrained_BERT neuron indx 4132 [('tastypie', 1.0), ('prange', 0.7678686560865982), ('calendar', 0.7504863477030654), ('policy', 0.7292629300573897), ('blocking', 0.7052640691636993)]
Top words for pretrained_BERT neuron indx 4148 [('with', 1.0), ('and', 0.9889259016008153), ('is', 0.9783548329714781), ('in', 0.9332094387042836), ('as', 0.8471281071549034)]
Top words for pretrained_BERT neuron indx 8245 [('v', 1.0), ('with', 0.8575374473968802), ('read', 0.7631677704104702), ('minutes', 0.7179947979908275), ('alt', 0.7096788418019171)]
Top words for pretrained_BERT neuron indx 62 [('1000', 1.0), ('int', 0.885318335833985), ('META', 0.8480768070690107), ('9', 0.8375491922015716), ('unpack', 0.8257276982480479)]
Top words for pretrained_BERT neuron indx 2112 [('slug', 1.0), ('count', 0.8683635938862841), ('sorted', 0.8027739670620049), ('vcard', 0.7992171780170596), ('minute', 0.7829051450422707)]
Top words for pretrained_BERT neuron indx 4164 [('minutes', 1.0), ('iq', 0.821472066964848), ('presence', 0.7594892198180124), ('View', 0.7087524826681183), ('connection', 0.6971308970647494)]
Top words for pretrained_BERT neuron indx 2119 [('Exception', 1.0), ('horizon', 0.7184468659793094), ('break', 0.7004699241384889), ('local', 0.635706795037468), ('action', 0.6062086856097443)]
Top words for pretrained_BERT neuron indx 4171 [('identity', 1.0), ('type', 0.9257116833158221), ('core', 0.8126881115089721), ('choices', 0.7860584553003316), ('REQUEST', 0.7739885053601441)]
Top words for pretrained_BERT neuron indx 76 [('value', 1.0), ('baseline', 0.9296992526019285), ('else', 0.8824013287275062), ('save', 0.8663400087875757), ('proxy', 0.8596036952853255)]
Top words for pretrained_BERT neuron indx 2124 [('sorted', 1.0), ('alt', 0.9005877554775831), ('blocking', 0.6983518007789014), ('int', 0.6970087427604444), ('enabled', 0.651092486583419)]
Top words for pretrained_BERT neuron indx 4184 [('False', 1.0), ('ms', 0.9078205742429944), ('time', 0.9033352375018256), ('EffectiveId', 0.8999522044638899), ('userid', 0.8856184550739793)]
Top words for pretrained_BERT neuron indx 4190 [('all', 1.0), ('timezone', 0.9927935035697252), ('unicode', 0.9462894882248857), ('astimezone', 0.8213702684242645), ('long', 0.8107701036098611)]
Top words for pretrained_BERT neuron indx 6240 [('models', 1.0), ('core', 0.9270444072446349), ('oslo', 0.9235809294953774), ('field', 0.9186497968418386), ('12', 0.8551027630729335)]
Top words for pretrained_BERT neuron indx 6241 [('match', 1.0), ('replace', 0.9226051276980147), ('split', 0.9107972210810538), ('choices', 0.8583691910499139), ('24', 0.8365983900107974)]
Top words for pretrained_BERT neuron indx 4193 [('long', 1.0), ('repr', 0.9264301360969933), ('component', 0.8341622060638716), ('project', 0.8126958115310525), ('second', 0.7807602896087997)]
Top words for pretrained_BERT neuron indx 2152 [('local', 1.0), ('us', 0.9758417675737223), ('None', 0.9635625040567269), ('purpose', 0.9604376371562441), ('Distance', 0.8749856668009215)]
Top words for pretrained_BERT neuron indx 2160 [('info', 1.0), ('division', 0.9609002478946403), ('day', 0.8509709859654869), ('connection', 0.7601561452587171), ('us', 0.759780772477592)]
Top words for pretrained_BERT neuron indx 6263 [('local', 1.0), ('None', 0.9665851981644333), ('12', 0.9610727472506042), ('or', 0.9194588090795092), ('kwargs', 0.9113680240165595)]
Top words for pretrained_BERT neuron indx 6265 [('models', 1.0), ('as', 0.940290423902683), ('and', 0.9130726300036313), ('is', 0.9037333883236537), ('post', 0.8106017070740255)]
Top words for pretrained_BERT neuron indx 6266 [('7', 1.0), ('Tab', 0.889736047111155), ('from', 0.8549281307898692), ('other', 0.7755067198230361), ('sanetime', 0.7715176679993366)]
Top words for pretrained_BERT neuron indx 6267 [('mins', 1.0), ('minutes', 0.9036467920305115), ('millis', 0.8374041071169371), ('name', 0.7527550820373062), ('30', 0.7463092866474071)]
Top words for pretrained_BERT neuron indx 122 [('close', 1.0), ('horizon', 0.9075548477374635), ('startswith', 0.8768534330534811), ('enclosure', 0.8651500058491233), ('datetime', 0.8370257808606417)]
Top words for pretrained_BERT neuron indx 4225 [('seek', 1.0), ('pop', 0.7504656729234388), ('14', 0.7127964524944516), ('slug', 0.669348042604827), ('On', 0.6617362466930294)]
Top words for pretrained_BERT neuron indx 8322 [('end', 1.0), ('unicode', 0.8954318132388899), ('On', 0.8714181582995116), ('"Resource"', 0.8375388370188521), ('False', 0.8222436286822552)]
Top words for pretrained_BERT neuron indx 6284 [('minutes', 1.0), ('seconds', 0.8686619745492516), ('key', 0.8385397711717282), ('80', 0.831730127951887), ('stanza', 0.8111742835536798)]
Top words for pretrained_BERT neuron indx 143 [('dt', 1.0), ('reactor', 0.8150782546245483), ('log', 0.8055349057538667), ('zone', 0.7894415023253436), ('Component', 0.7841141129553563)]
Top words for pretrained_BERT neuron indx 4242 [('identity', 1.0), ('IsSECANC', 0.9074882284183425), ('pop', 0.8603656238892804), ('IsBM', 0.8529671516210277), ('msghead', 0.8213794405592879)]
Top words for pretrained_BERT neuron indx 4247 [('enabled', 1.0), ('loads', 0.8486400250588473), ('META', 0.8293898480669889), ('GET', 0.8205214435135983), ('not', 0.793165381892433)]
Top words for pretrained_BERT neuron indx 6298 [('ref', 1.0), ('E', 0.9082102093025308), ('log', 0.8927824521909127), ('e', 0.8275124295752347), ('False', 0.7995150823480175)]
Top words for pretrained_BERT neuron indx 4253 [('try', 1.0), ('help', 0.8928765452003986), ('BlendProbes', 0.8076360417500689), ('LoadUser', 0.7716325249480672), ('feature', 0.7690704320909193)]
Top words for pretrained_BERT neuron indx 4254 [('add_argument', 1.0), ('tag', 0.991683024208793), ('sans', 0.9670321412892798), ('is_authorized', 0.9147203753533132), ('Post', 0.8435653717734419)]
Top words for pretrained_BERT neuron indx 6313 [('connection', 1.0), ('join', 0.9879099867097406), ('__hash__', 0.9846078712494546), ('help', 0.9829863556292215), ('__int__', 0.9703685595715889)]
Top words for pretrained_BERT neuron indx 6314 [('minutes', 1.0), ('sorted', 0.6429980526500071), ('seconds', 0.6196482202908351), ('mins', 0.609944022887693), ('force', 0.6094151626480843)]
Top words for pretrained_BERT neuron indx 172 [('enclosure', 1.0), ('type', 0.8611958999807372), ('feature', 0.8319819690885153), ('common', 0.825903812675464), ('features', 0.7656191240711654)]
Top words for pretrained_BERT neuron indx 4271 [('On', 1.0), ('authorized', 0.9637404538024437), ('parse', 0.8605422921894073), ('parser', 0.7834450186854546), ('login', 0.777934570533252)]
Top words for pretrained_BERT neuron indx 4272 [('86400', 1.0), ('24', 0.9112303695613962), ('find', 0.7924574280449475), ('setup', 0.7468606738332334), ('4', 0.7368030962461175)]
Top words for pretrained_BERT neuron indx 2231 [('path', 1.0), ('policy', 0.8387325418639138), ('long', 0.8110656484109199), ('log', 0.809936042139956), ('super', 0.7467375409190026)]
Top words for pretrained_BERT neuron indx 8376 [('2', 1.0), ('List', 0.9941069972290792), ('list', 0.8679136136561881), ('UCache', 0.8056379468510803), ('pytz', 0.7845530679219666)]
Top words for pretrained_BERT neuron indx 2239 [('List', 1.0), ('os', 0.9083383935602015), ('day', 0.8973553409261757), ('60', 0.8609331516853015), ('error', 0.8466331576237189)]
Top words for pretrained_BERT neuron indx 4291 [('template', 1.0), ('seek', 0.9028362249589058), ('NoPerm', 0.7748552686213617), ('parts', 0.7694380185732055), ('contents', 0.7443054770509347)]
Top words for pretrained_BERT neuron indx 6339 [('component', 1.0), ('VerticalBillboard', 0.9746696512270656), ('class', 0.9587982857281355), ('HorizontalBillboard', 0.942095045687073), ('16', 0.8830672065562337)]
Top words for pretrained_BERT neuron indx 8389 [('authorization', 1.0), ('common', 0.9371594754622814), ('tastypie', 0.9123558617763706), ('7', 0.8939134790828474), ('type', 0.8868564573207526)]
Top words for pretrained_BERT neuron indx 6343 [('continue', 1.0), ('session', 0.9782366221213181), ('print', 0.960530828130816), ('horizon', 0.9361583207680201), ('field', 0.8917744229937833)]
Top words for pretrained_BERT neuron indx 201 [('type', 1.0), ('parent', 0.9959503891885662), ('render', 0.9706166534645917), ('raise', 0.9323564033679935), ('features', 0.8708427596348883)]
Top words for pretrained_BERT neuron indx 2262 [('count', 1.0), ('seek', 0.9033571072321542), ('close', 0.84169888740781), ('info', 0.7853456007556991), ('reactor', 0.7791274145537049)]
Top words for pretrained_BERT neuron indx 215 [('resource', 1.0), ('stanza', 0.9747678620996842), ('ignore', 0.8998394679940831), ('long', 0.8961753690315657), ('repr', 0.891334012558384)]
Top words for pretrained_BERT neuron indx 6362 [('component', 1.0), ('Plugin', 0.9559844469747142), ('filename', 0.8726088478065642), ('as', 0.8671470322352779), ('vCard', 0.8540840180928418)]
Top words for pretrained_BERT neuron indx 221 [('identity', 1.0), ('zone', 0.991183149116628), ('boot', 0.8911379203607833), ('seek', 0.8418243161640723), ('_hash', 0.8100116603893054)]
Top words for pretrained_BERT neuron indx 8415 [('9', 1.0), ('us', 0.8454344081863114), ('6', 0.840993850398239), ('models', 0.8233177480826384), ('False', 0.793604281848796)]
Top words for pretrained_BERT neuron indx 4320 [('to', 1.0), ('range', 0.9986770085527397), ('logging', 0.9212542354245767), ('token', 0.9041733588723578), ('request', 0.8963140404534908)]
Top words for pretrained_BERT neuron indx 6374 [('1000', 1.0), ('mesh2', 0.9591461745404235), ('v', 0.9542063786291242), ('1800', 0.9084345052541738), ('mesh', 0.8384688253556766)]
Top words for pretrained_BERT neuron indx 8424 [('e', 1.0), ('600', 0.952188356223471), ('format', 0.8847090070582663), ('authorization', 0.785475558667348), ('3700', 0.7815304276635348)]
Top words for pretrained_BERT neuron indx 2281 [('presence', 1.0), ('description', 0.9801953631370043), ('1', 0.9498696483502475), ('find', 0.8684530927649291), ('item', 0.8413819300842174)]
Top words for pretrained_BERT neuron indx 237 [('upper', 1.0), ('stat', 0.9040234662813105), ('modes', 0.821819384287146), ('unicode', 0.7912155986340793), ('Post', 0.7652644043590404)]
Top words for pretrained_BERT neuron indx 8434 [('9', 1.0), ('7', 0.8683338398455634), ('mesh', 0.8665008068183664), ('Mesh', 0.8360070232384913), ('parent', 0.8142163828557394)]
Top words for pretrained_BERT neuron indx 4338 [('long', 1.0), ('_closed', 0.8977077561255064), ('int', 0.8347548348494683), ('second', 0.830387929735916), ('val', 0.8121593565588118)]
Top words for pretrained_BERT neuron indx 6389 [('oslo', 1.0), ('14', 0.9563420588521032), ('continue', 0.9477912729713154), ('setup', 0.9291999518416687), ('7', 0.920284774874702)]
Top words for pretrained_BERT neuron indx 2299 [('Simple', 1.0), ('token', 0.9009918795732751), ('value', 0.8218825370713693), ('Exception', 0.8211499537258051), ('ref', 0.7867129724705693)]
Top words for pretrained_BERT neuron indx 4351 [('to', 1.0), ('division', 0.9317974237555006), ('policy', 0.8085176109717727), ('domain', 0.8068585482129929), ('parent', 0.7960376550533542)]
Top words for pretrained_BERT neuron indx 257 [('entity', 1.0), ('Node', 0.8311902352861604), ('True', 0.8237270611234773), ('dt', 0.7925183208140871), ('parent', 0.7593230655754474)]
Top words for pretrained_BERT neuron indx 4360 [('pop', 1.0), ('con', 0.8802434344712359), ('count', 0.868613775673139), ('direct', 0.7517463753094608), ('On', 0.7436499147422333)]
Top words for pretrained_BERT neuron indx 6408 [('format', 1.0), ('save', 0.9424480866898094), ('render', 0.920095876395241), ('setup', 0.903407539697541), ('description', 0.8831912090659831)]
Top words for pretrained_BERT neuron indx 268 [('else', 1.0), ('os', 0.8587542986535475), ('horizon', 0.8247552726829511), ('modes', 0.816106003823746), ('save', 0.7538963886451491)]
Top words for pretrained_BERT neuron indx 2317 [('objects', 1.0), ('proxy', 0.9407548915445254), ('ms', 0.9199638269540742), ('except', 0.8340115779444424), ('__version__', 0.8316946751572005)]
Top words for pretrained_BERT neuron indx 2318 [('len', 1.0), ('key', 0.9582633940291005), ('force', 0.9165490225449384), ('14', 0.8697168761134569), ('8', 0.8414516589028384)]
Top words for pretrained_BERT neuron indx 4366 [('not', 1.0), ('domain', 0.9196429292504897), ('main', 0.8406688622266063), ('continue', 0.8292263924252432), ('readfp', 0.7418081586677895)]
Top words for pretrained_BERT neuron indx 272 [('materials', 1.0), ('count', 0.8727751732031261), ('dt', 0.8241972336382497), ('False', 0.8233708838391668), ('unicode', 0.7273821445156622)]
Top words for pretrained_BERT neuron indx 6417 [('loads', 1.0), ('9', 0.9719311939749352), ('max', 0.9538458748294476), ('Library', 0.8772201978589851), ('and', 0.872678637988297)]
Top words for pretrained_BERT neuron indx 6422 [('authorization', 1.0), ('pass', 0.956491908926183), ('continue', 0.7948667740184694), ('horizon', 0.7622873658248258), ('long', 0.734695782679741)]
Top words for pretrained_BERT neuron indx 279 [('logging', 1.0), ('target', 0.8712336551839593), ('zone', 0.8617453715728368), ('YoungestInFront', 0.6712899173650443), ('second', 0.6705585844808927)]
Top words for pretrained_BERT neuron indx 282 [('enclosure', 1.0), ('ping', 0.7225360036963269), ('server', 0.6759179965234661), ('v', 0.6606210873646439), ('post', 0.6587514420072603)]
Top words for pretrained_BERT neuron indx 8476 [('20', 1.0), ('MAXSIGLINES', 0.8321266823936111), ('Mesh', 0.7543779423907694), ('baseline', 0.7356698095590579), ('60', 0.7246825058466686)]
Top words for pretrained_BERT neuron indx 8479 [('exceptions', 1.0), ('""', 0.9521252839610819), ('objects', 0.9004112432705935), ('i', 0.8988650208895442), ('items', 0.8860297453659749)]
Top words for pretrained_BERT neuron indx 2353 [('required', 1.0), ('core', 0.9537288733031993), ('count', 0.9465825176295043), ('con', 0.8252891695809595), ('Distance', 0.796417377028678)]
Top words for pretrained_BERT neuron indx 6450 [('and', 1.0), ('pop', 0.8624945721507379), ('E', 0.842838014398741), ('dict', 0.8385715000468522), ('print', 0.7927239905891242)]
Top words for pretrained_BERT neuron indx 307 [('close', 1.0), ('loads', 0.8641050089638863), ('profile', 0.7532140801689028), ('Profile', 0.7396754313178998), ('partition', 0.7337005644365212)]
Top words for pretrained_BERT neuron indx 6452 [('Billboard', 1.0), ('with', 0.8536827549684461), ('unicode', 0.7740554778965971), ('int', 0.7626957680790729), ('in', 0.735734602959138)]
Top words for pretrained_BERT neuron indx 308 [('and', 1.0), ('in', 0.8644678385097134), ('".."', 0.8630981609930353), ('to', 0.8514618690913492), ('with', 0.7177605142876448)]
Top words for pretrained_BERT neuron indx 8501 [('20', 1.0), ('minutes', 0.9597393914402933), ('seconds', 0.9478231838691734), ('9', 0.8961732342606334), ('sanedelta', 0.8903100701976479)]
Top words for pretrained_BERT neuron indx 4416 [('minutes', 1.0), ('seconds', 0.8751192445701953), ('def', 0.8651412456993636), ('vCard', 0.8631803855890626), ('sorted', 0.7994766063321032)]
Top words for pretrained_BERT neuron indx 4425 [('bare', 1.0), ('put', 0.7570031498861872), ('read', 0.7345114854956627), ('LoadUser', 0.6809873431763523), ('GetBoard', 0.6498121325772519)]
Top words for pretrained_BERT neuron indx 8523 [('BlendProbes', 1.0), ('common', 0.9755938890606346), ('exceptions', 0.8565810457188022), ('microseconds', 0.8341230664330144), ('"oslo"', 0.820518328880944)]
Top words for pretrained_BERT neuron indx 333 [('parent', 1.0), ('enclosure', 0.9473998067638004), ('24', 0.9432696062100182), ('Unauthorized', 0.9365271062723761), ('horizon', 0.8737237269370443)]
Top words for pretrained_BERT neuron indx 6489 [('IDLEN', 1.0), ('Stretch', 0.9972330788033485), ('IPLEN', 0.9938042354366307), ('GetBoard', 0.9111651993337515), ('type', 0.9057711825910143)]
Top words for pretrained_BERT neuron indx 6499 [('sans', 1.0), ('alt', 0.8013661712898706), ('utc', 0.7861207393841646), ('default', 0.7509349019626499), ('6', 0.7468203180029983)]
Top words for pretrained_BERT neuron indx 6504 [('put', 1.0), ('upper', 0.898403660348333), ('80', 0.827630288922036), ('count', 0.7453073334393089), ('division', 0.7197109812633552)]
Top words for pretrained_BERT neuron indx 2409 [('year', 1.0), ('second', 0.9590320966292062), ('replace', 0.9184589358253306), ('day', 0.844429452331836), ('sht', 0.8211881696828112)]
Top words for pretrained_BERT neuron indx 8561 [('Library', 1.0), ('9', 0.9383094123515431), ('Billboard', 0.9111237391629433), ('24', 0.8812799536290247), ('7', 0.7917504394340414)]
Top words for pretrained_BERT neuron indx 6517 [('unicode', 1.0), ('default', 0.8934506436991337), ('fcsans', 0.7658101283202855), ('hpov', 0.7431521650280767), ('upper', 0.7369627009836804)]
Top words for pretrained_BERT neuron indx 8567 [('all', 1.0), ('None', 0.9566998874304947), ('or', 0.9307442535406397), ('"oslo"', 0.9058648442142175), ('minutes', 0.8326104712912118)]
Top words for pretrained_BERT neuron indx 376 [('len', 1.0), ('Unauthorized', 0.9672007723530469), ('entity', 0.9285107747193517), ('calendar', 0.9092458029461379), ('rpc', 0.8914604896440547)]
Top words for pretrained_BERT neuron indx 380 [('slug', 1.0), ('try', 0.8542994699747746), ('read', 0.8453653924585214), ('unicode', 0.839462117822173), ('alt', 0.8034148008468631)]
Top words for pretrained_BERT neuron indx 8572 [('with', 1.0), ('for', 0.9931826809114327), ('unicode', 0.9395002992130791), ('"happy_birthday"', 0.9122954079444691), ('"Name"', 0.8880958029309038)]
Top words for pretrained_BERT neuron indx 6528 [('9', 1.0), ('24', 0.9293854496318056), ('12', 0.8896293328651609), ('7', 0.8528123774186703), ('14', 0.8152914039920276)]
Top words for pretrained_BERT neuron indx 385 [('proxy', 1.0), ('filters', 0.7906254938419407), ('seek', 0.5915492930005309), ('0', 0.564519586386292), ('put', 0.5267507992536274)]
Top words for pretrained_BERT neuron indx 8580 [('is', 1.0), ('ndt', 0.9403331400785536), ('all', 0.9239615079115211), ('alt', 0.9041334016058732), ('day', 0.8841607175249662)]
Top words for pretrained_BERT neuron indx 395 [('enclosuregroup', 1.0), ('line', 0.9773172410663844), ('required', 0.9630857379818643), ('end', 0.9618261199343204), ('server', 0.9092151691578361)]
Top words for pretrained_BERT neuron indx 8590 [('Off', 1.0), ('f', 0.9908831273631076), ('v', 0.9889070951679502), ('scope', 0.9764947331671043), ('Board', 0.9715747482138243)]
Top words for pretrained_BERT neuron indx 6551 [('requests', 1.0), ('GET', 0.9218043557760957), ('store', 0.9125073060187993), ('1', 0.8956635843173832), ('1800', 0.8689233241060149)]
Top words for pretrained_BERT neuron indx 6563 [('except', 1.0), ('if', 0.9242341864879582), ('get_profile_networks', 0.8361322742619024), ('get_profile_compliance_preview', 0.8249881775975781), ('get_task_associated_resource', 0.7945458821444868)]
Top words for pretrained_BERT neuron indx 4517 [('META', 1.0), ('description', 0.8563757334054407), ('raise', 0.8121616143560738), ('Mesh', 0.6994015110648635), ('if', 0.6960231796148839)]
Top words for pretrained_BERT neuron indx 422 [('logging', 1.0), ('def', 0.9314606772699404), ('models', 0.88776788301845), ('value', 0.8761648574011124), ('contents', 0.8192493352005473)]
Top words for pretrained_BERT neuron indx 429 [('Exception', 1.0), ('item', 0.8957320900414909), ('resource', 0.8795800045408636), ('settings', 0.8259064287536493), ('modes', 0.8149288459623826)]
Top words for pretrained_BERT neuron indx 6573 [('2', 1.0), ('True', 0.8725830163035), ('component', 0.8427311291754409), ('1', 0.8065339673298395), ('strip', 0.7988073098306422)]
Top words for pretrained_BERT neuron indx 432 [('Billboard', 1.0), ('read', 0.892382872280277), ('digest', 0.7174901828280705), ('Digest', 0.715088094772378), ('re', 0.6256160630714481)]
Top words for pretrained_BERT neuron indx 441 [('exceptions', 1.0), ('proxy', 0.9890687050868479), ('Stretch', 0.870173740875645), ('server', 0.846483203775082), ('minutes', 0.816997521640044)]
Top words for pretrained_BERT neuron indx 4539 [('milliseconds', 1.0), ('microseconds', 0.8974799653463564), ('e', 0.8241807018728093), ('Tab', 0.8226993875159633), ('600', 0.6407332142524444)]
Top words for pretrained_BERT neuron indx 444 [('Tab', 1.0), ('bare', 0.9987414138375286), ('default', 0.9221222625498069), ('division', 0.8950740404405905), ('objects', 0.8710030616436114)]
Top words for pretrained_BERT neuron indx 2495 [('patch', 1.0), ('root', 0.7646837118152132), ('pop', 0.7304855994276037), ('or', 0.7269673342520302), ('day', 0.6637921512392965)]
Top words for pretrained_BERT neuron indx 2497 [('except', 1.0), ('sans', 0.805895912615356), ('errors', 0.7891489725990728), ('message', 0.766999650722899), ('force', 0.7559817531160941)]
Top words for pretrained_BERT neuron indx 8643 [('17', 1.0), ('24', 0.8558435322066454), ('30', 0.8137709382805256), ('receive_shadows', 0.7376621152553984), ('16', 0.7286732130279727)]
Top words for pretrained_BERT neuron indx 451 [('Component', 1.0), ('len', 0.9765113610786967), ('render', 0.9605461322528669), ('component', 0.9229139733750865), ('dt', 0.9157709471299161)]
Top words for pretrained_BERT neuron indx 6595 [('template', 1.0), ('seek', 0.9205289996235168), ('None', 0.8384874009419859), ('part', 0.8127227104749682), ('parts', 0.7514701180896397)]
Top words for pretrained_BERT neuron indx 6616 [('Unauthorized', 1.0), ('seconds', 0.8186926039862052), ('except', 0.7854672464607998), ('millis', 0.7185453404291641), ('iq', 0.7089992255618183)]
Top words for pretrained_BERT neuron indx 6618 [('wait', 1.0), ('META', 0.9714211047786242), ('32', 0.9480478831724056), ('60', 0.9351206783183564), ('purpose', 0.9255331004834836)]
Top words for pretrained_BERT neuron indx 6624 [('logging', 1.0), ('end', 0.9254269053423664), ('META', 0.8600184201656792), ('max', 0.8407260367666618), ('log', 0.8297759414281026)]
Top words for pretrained_BERT neuron indx 2538 [('push', 1.0), ('register', 0.9560247567732035), ('description', 0.9528474654222379), ('seek', 0.9158770005336091), ('pass', 0.9130151191145482)]
Top words for pretrained_BERT neuron indx 2539 [('calendar', 1.0), ('Node', 0.9478985397977282), ('resource', 0.890941872946992), ('os', 0.8867828179427777), ('upper', 0.8587210490031719)]
Top words for pretrained_BERT neuron indx 6634 [('300', 1.0), ('oslo', 0.9540870289293838), ('800', 0.9386852733143015), ('1800', 0.8291363094607969), ('3600', 0.826967060352991)]
Top words for pretrained_BERT neuron indx 499 [('except', 1.0), ('slug', 0.7668681517812282), ('NoPerm', 0.7549942615384129), ('setup', 0.7129584588106266), ('prange', 0.7045695525522567)]
Top words for pretrained_BERT neuron indx 4616 [('super', 1.0), ('group', 0.8993362142876093), ('exit', 0.8830446207407994), ('action', 0.8555643803046923), ('type', 0.8347723207628897)]
Top words for pretrained_BERT neuron indx 6669 [('division', 1.0), ('calendar', 0.9641817413123697), ('unicode', 0.9161271029905759), ('builtins', 0.8153545842409643), ('repr', 0.798532481027814)]
Top words for pretrained_BERT neuron indx 6670 [('META', 1.0), ('re', 0.8050995349487995), ('not', 0.7701689947449443), ('modes', 0.7649202304533911), ('9', 0.7425994229333175)]
Top words for pretrained_BERT neuron indx 4622 [('force', 1.0), ('8', 0.8209479015062471), ('oslo', 0.7749492689509883), ('key', 0.7666961867099275), ('Off', 0.7161757102028182)]
Top words for pretrained_BERT neuron indx 528 [('root', 1.0), ('os', 0.9924616452604259), ('Profile', 0.8569453195171353), ('profile', 0.837342107040537), ('route', 0.8300001335289325)]
Top words for pretrained_BERT neuron indx 8724 [('seconds', 1.0), ('broadcast', 0.7900396075792159), ('iq', 0.7524561323099414), ('minutes', 0.7470256424755072), ('stat', 0.7065808944510041)]
Top words for pretrained_BERT neuron indx 4629 [('start', 1.0), ('division', 0.8568359473791443), ('os', 0.8508339606323174), ('Plugin', 0.8474821913512076), ('minutes', 0.8456760172393308)]
Top words for pretrained_BERT neuron indx 538 [('minutes', 1.0), ('def', 0.8457911493218765), ('target', 0.7884895619561261), ('entity', 0.6974890279776486), ('port', 0.6843029110146801)]
Top words for pretrained_BERT neuron indx 8733 [('log', 1.0), ('400', 0.8348864798973814), ('5', 0.7989731176659037), ('7', 0.7683306032556336), ('zone', 0.7314758315841444)]
Top words for pretrained_BERT neuron indx 543 [('register', 1.0), ('Register', 0.9182293692833293), ('division', 0.8665290571969063), ('Tab', 0.823005999382287), ('contents', 0.8054723322818008)]
Top words for pretrained_BERT neuron indx 2592 [('state', 1.0), ('npos', 0.9399012759884257), ('class', 0.9206230624797556), ('common', 0.8653633829980814), ('stanza', 0.8616594015788034)]
Top words for pretrained_BERT neuron indx 551 [('calendar', 1.0), ('result', 0.9543682976506548), ('push', 0.9408569260080213), ('add', 0.8976392580838572), ('pop', 0.8234582553737104)]
Top words for pretrained_BERT neuron indx 560 [('patch', 1.0), ('choices', 0.9732368238092586), ('port', 0.9167978148164194), ('render', 0.9104417198418052), ('stat', 0.9055316218720996)]
Top words for pretrained_BERT neuron indx 2612 [('and', 1.0), ('in', 0.9235152523625362), ('is', 0.9101227245249192), ('with', 0.7949423830942748), ('as', 0.7944057375277966)]
Top words for pretrained_BERT neuron indx 6711 [('9', 1.0), ('8000', 0.8753130631889654), ('servers', 0.8497640002855393), ('20000', 0.8361127492006604), ('authorization', 0.8242696898145123)]
Top words for pretrained_BERT neuron indx 4676 [('action', 1.0), ('name', 0.8213262568428221), ('Library', 0.8099670939578072), ('filename', 0.7997567224307036), ('9', 0.7949333981451596)]
Top words for pretrained_BERT neuron indx 6729 [('put', 1.0), ('loads', 0.9525468094444468), ('root', 0.8860551734977816), ('get', 0.844536960272115), ('type', 0.8308669768441531)]
Top words for pretrained_BERT neuron indx 587 [('int', 1.0), ('slug', 0.8837108867106334), ('clone', 0.8640477487751753), ('created', 0.8501768523267342), ('ping', 0.8417067169382766)]
Top words for pretrained_BERT neuron indx 8787 [('to', 1.0), ('86400', 0.773092212200443), ('action', 0.7600212634012818), ('mesh1', 0.7585528097112595), ('epoch_milliseconds', 0.7354558305897869)]
Top words for pretrained_BERT neuron indx 4692 [('is', 1.0), ('E', 0.9473978618742539), ('with', 0.9432346934324138), ('secs', 0.9244554051025792), ('f', 0.9145571366766284)]
Top words for pretrained_BERT neuron indx 8793 [('7', 1.0), ('secs', 0.8350161965365648), ('8', 0.8179571841820937), ('i', 0.7868062730248352), ('all', 0.7846159608528552)]
Top words for pretrained_BERT neuron indx 2654 [('unicode', 1.0), ('all', 0.8111786304666839), ('digest', 0.8090130251435138), ('calendar', 0.7583492767909225), ('Digest', 0.7463173803835087)]
Top words for pretrained_BERT neuron indx 4713 [('1800', 1.0), ('17', 0.9937264244590034), ('300', 0.991545717508974), ('to', 0.92360383262477), ('strip', 0.8959764018452798)]
Top words for pretrained_BERT neuron indx 4714 [('oslo', 1.0), ('1800', 0.742127793058138), ('models', 0.7373758126067397), ('16', 0.7368489511696625), ('15', 0.7217089867883555)]
Top words for pretrained_BERT neuron indx 8812 [('created', 1.0), ('nargs', 0.9538069663429948), ('boot', 0.9365865632761308), ('6', 0.9238251864551607), ('8', 0.8987059946927045)]
Top words for pretrained_BERT neuron indx 620 [('render', 1.0), ('resource', 0.7057031754079115), ('result', 0.6914933347295272), ('False', 0.6885083190150552), ('seek', 0.6688162695290023)]
Top words for pretrained_BERT neuron indx 8815 [('".."', 1.0), ('with', 0.8780503362650398), ('"oslo"', 0.8595230948538113), ('"purpose"', 0.8243639246969662), ('horizon', 0.8088652919352229)]
Top words for pretrained_BERT neuron indx 624 [('info', 1.0), ('division', 0.8518671393129603), ('route', 0.7233564742039141), ('day', 0.7000484883134449), ('required', 0.6760066943835624)]
Top words for pretrained_BERT neuron indx 627 [('operand', 1.0), ('filter', 0.9931958270038126), ('closing', 0.9142029782121136), ('traceback', 0.8439122389541283), ('project', 0.8222172241806855)]
Top words for pretrained_BERT neuron indx 635 [('def', 1.0), ('ignore', 0.9721466044925651), ('path', 0.8938135609890956), ('settings', 0.8850501887824279), ('localize', 0.8464740548318054)]
Top words for pretrained_BERT neuron indx 636 [('Stretch', 1.0), ('True', 0.9643896717386262), ('modes', 0.9418147660542869), ('boardname', 0.9299821485031622), ('push', 0.9249221266832806)]
Top words for pretrained_BERT neuron indx 8829 [('ds_owner_created', 1.0), ('get_term_stealed', 0.8976159473505061), ('get_term_read', 0.8617128768073706), ('Distance', 0.8052838741601273), ('"http://%s/bbscon.php?b=xattach&f=%s"', 0.794513704466789)]
Top words for pretrained_BERT neuron indx 2689 [('seek', 1.0), ('proxy', 0.7671833926825871), ('put', 0.754600185271734), ('filters', 0.7387781199960056), ('0', 0.6961565287839245)]
Top words for pretrained_BERT neuron indx 8834 [('20', 1.0), ('Off', 0.704077178857001), ('40', 0.6604359672971012), ('15', 0.6328541273215867), ('mesh1', 0.6265045642011055)]
Top words for pretrained_BERT neuron indx 4739 [('as', 1.0), ('Plugin', 0.8818809148281659), ('if', 0.8748482091216416), ('npos', 0.8514344437508452), ('topid', 0.8258159516528725)]
Top words for pretrained_BERT neuron indx 8845 [('end', 1.0), ('hour', 0.7757265271487149), ('long', 0.7001465641741705), ('task', 0.6940630458703907), ('6', 0.6463401580162473)]
Top words for pretrained_BERT neuron indx 6797 [('pdb', 1.0), ('9', 0.9928044087523453), ('blocking', 0.8480204026351259), ('continue', 0.7525476803383704), ('if', 0.7336042297464841)]
Top words for pretrained_BERT neuron indx 4751 [('patch', 1.0), ('long', 0.9776778507466204), ('Unauthorized', 0.9507259442077591), ('materials', 0.93500617380065), ('authentication', 0.9176273197572176)]
Top words for pretrained_BERT neuron indx 8848 [('m', 1.0), ('s', 0.9368849093636661), ('f', 0.9311602834181808), ('models', 0.9124615610914297), ('i', 0.8286391250821052)]
Top words for pretrained_BERT neuron indx 4750 [('sorted', 1.0), ('f', 0.8503195477987364), ('super', 0.8091866336200592), ('scope', 0.7837284702021112), ('timetuple', 0.7788094376331078)]
Top words for pretrained_BERT neuron indx 2705 [('component', 1.0), ('log', 0.8888232187215616), ('text', 0.7263079045654081), ('BlendProbes', 0.6995747774921172), ('feature', 0.683366063130232)]
Top words for pretrained_BERT neuron indx 8852 [('with', 1.0), ('nsanetime', 0.8481446578378066), ('YoungestInFront', 0.8330770896222165), ('NetworkProfileTab', 0.8138273204605575), ('sorted', 0.8063739499816405)]
Top words for pretrained_BERT neuron indx 8855 [('list', 1.0), ('requests', 0.9882856972758364), ('META', 0.9429475148501176), ('1', 0.9037745045752488), ('store', 0.8665086252954627)]
Top words for pretrained_BERT neuron indx 2711 [('META', 1.0), ('loads', 0.8664151898266317), ('not', 0.81942882487531), ('enabled', 0.7547547816494408), ('bind', 0.7516960944798535)]
Top words for pretrained_BERT neuron indx 2717 [('help', 1.0), ('try', 0.8336237225735259), ('post', 0.8198775469053444), ('presence', 0.8161591992290859), ('30', 0.7575871630899805)]
Top words for pretrained_BERT neuron indx 2718 [('format', 1.0), ('mesh', 0.9724895681868175), ('filters', 0.9558116044004171), ('filter', 0.9532637219476802), ('sans', 0.9522780526120177)]
Top words for pretrained_BERT neuron indx 8863 [('7', 1.0), ('affinity', 0.7372393720086406), ('8', 0.7359969442989901), ('minutes', 0.7328814315158092), ('mesh', 0.7021158302914233)]
Top words for pretrained_BERT neuron indx 672 [('seek', 1.0), ('horizon', 0.9052082017429929), ('len', 0.8992393018015726), ('bind', 0.8966234424341889), ('resource', 0.8962760858287291)]
Top words for pretrained_BERT neuron indx 8867 [('if', 1.0), ('except', 0.8530577412489061), ('Tab', 0.7867558122469417), ('post', 0.7491751667155039), ('oslo', 0.7104660656406204)]
Top words for pretrained_BERT neuron indx 6821 [('META', 1.0), ('5', 0.9556431375345055), ('if', 0.9032977140915407), ('Mesh', 0.7746402456912173), ('description', 0.7738393797876914)]
Top words for pretrained_BERT neuron indx 2726 [('required', 1.0), ('reactor', 0.9476664796785937), ('count', 0.9255406355385011), ('12', 0.8876683301097632), ('14', 0.8838634126229669)]
Top words for pretrained_BERT neuron indx 679 [('loads', 1.0), ('parts', 0.8614358537413555), ('register', 0.8466143779062526), ('route', 0.7018687033159587), ('store', 0.6825268698621606)]
Top words for pretrained_BERT neuron indx 677 [('month', 1.0), ('script', 0.9774166054369664), ('format', 0.8791344661227792), ('raise', 0.8790650013562795), ('E', 0.8015987714296584)]
Top words for pretrained_BERT neuron indx 4778 [('minutes', 1.0), ('is', 0.7852891877805299), ('force', 0.7757721032767262), ('sorted', 0.7343426284337294), ('Profile', 0.6887888937984801)]
Top words for pretrained_BERT neuron indx 2745 [('9', 1.0), ('body', 0.9267695649081171), ('6', 0.8956778138688269), ('root', 0.8548457392189287), ('600', 0.8347997076319661)]
Top words for pretrained_BERT neuron indx 2748 [('hpov', 1.0), ('required', 0.9833782725535491), ('hour', 0.96545540430221), ('break', 0.9551248643641549), ('id', 0.9141439024421621)]
Top words for pretrained_BERT neuron indx 8895 [('write', 1.0), ('minutes', 0.8895311079708428), ('post', 0.7928482766675039), ('24', 0.7587452213891634), ('raise', 0.7427885473282626)]
Top words for pretrained_BERT neuron indx 8901 [('32', 1.0), ('META', 0.9328557650466842), ('20', 0.8615584604480379), ('800', 0.8594602637656475), ('NotFound', 0.8575603120057473)]
Top words for pretrained_BERT neuron indx 6856 [('enum', 1.0), ('14', 0.9682947189422774), ('0', 0.9255479063226941), ('9', 0.8703163646062716), ('40', 0.8669104815518461)]
Top words for pretrained_BERT neuron indx 6857 [('project', 1.0), ('dateutil', 0.8953809564520134), ('9', 0.8647750848479862), ('unpack', 0.7795617670049878), ('task', 0.7331987499144894)]
Top words for pretrained_BERT neuron indx 4810 [('return', 1.0), ('Unauthorized', 0.9555458352806728), ('to', 0.9229431743243709), ('month', 0.9196922419725516), ('day', 0.888071023695346)]
Top words for pretrained_BERT neuron indx 6863 [('1000', 1.0), ('blocking', 0.7401050292810613), ('oslo', 0.6316727408385227), ('created', 0.5683777349146678), ('SaneDelta', 0.5330304361105076)]
Top words for pretrained_BERT neuron indx 6867 [('Off', 1.0), ('store', 0.8905277320613573), ('fcs', 0.8723502405251149), ('end', 0.8608037504108862), ('config', 0.8411493964049296)]
Top words for pretrained_BERT neuron indx 725 [('wait', 1.0), ('set', 0.9712437775966609), ('View', 0.9243827903426258), ('host', 0.9107130882142744), ('millis', 0.8215933625564346)]
Top words for pretrained_BERT neuron indx 6870 [('while', 1.0), ('blocking', 0.7884803254480099), ('except', 0.7744432409277181), ('7', 0.7636382324935104), ('wait', 0.7484732486363579)]
Top words for pretrained_BERT neuron indx 726 [('count', 1.0), ('close', 0.9975396837972607), ('def', 0.8005438775325308), ('info', 0.748460195824752), ('Node', 0.736778999979279)]
Top words for pretrained_BERT neuron indx 8924 [('minutes', 1.0), ('80', 0.8545078415677299), ('v', 0.8259540211310659), ('secs', 0.8096205841170199), ('millis', 0.8087197751802205)]
Top words for pretrained_BERT neuron indx 736 [('calendar', 1.0), ('alt', 0.9892120777693781), ('Mesh', 0.919414697019327), ('mesh', 0.919414697019327), ('proxy', 0.8955836093131122)]
Top words for pretrained_BERT neuron indx 6885 [('month', 1.0), ('12', 0.9813611630473061), ('day', 0.9270257196191304), ('wait', 0.9067434867901286), ('year', 0.9050677237290485)]
Top words for pretrained_BERT neuron indx 758 [('slug', 1.0), ('add', 0.9370969524509273), ('entity', 0.9072317257865448), ('patch', 0.9045067653026136), ('child', 0.8947683443770912)]
Top words for pretrained_BERT neuron indx 759 [('exceptions', 1.0), ('zone', 0.841643059115488), ('Unauthorized', 0.8332315541939056), ('class', 0.8259943631587083), ('Exception', 0.7962151173036638)]
Top words for pretrained_BERT neuron indx 6911 [('upper', 1.0), ('main', 0.8247192112043874), ('boot', 0.7648608824551445), ('v', 0.7291950367505138), ('domain', 0.699407878872057)]
Top words for pretrained_BERT neuron indx 8964 [('utcnow', 1.0), ('GetUID', 0.8662203605210613), ('utc', 0.8630524167055249), ('seek', 0.7729265572321194), ('int', 0.766258284133103)]
Top words for pretrained_BERT neuron indx 4870 [('utc', 1.0), ('write', 0.9937708373767954), ('pass', 0.972533081804235), ('ping', 0.9672081531030918), ('sans', 0.9384801840480937)]
Top words for pretrained_BERT neuron indx 4872 [('""', 1.0), ('Distance', 0.8451752925644684), ('localize', 0.8017776838802695), ('debug', 0.7737044267976975), ('try', 0.7615304337652481)]
Top words for pretrained_BERT neuron indx 8972 [('17', 1.0), ('60', 0.9454946732791477), ('40', 0.9223098954214352), ('request', 0.8788883248097863), ('On', 0.8385568192061281)]
Top words for pretrained_BERT neuron indx 4877 [('property', 1.0), ('bind', 0.960980729260651), ('range', 0.9153724618860755), ('identity', 0.8954614930861409), ('super', 0.8847094265742798)]
Top words for pretrained_BERT neuron indx 6926 [('force', 1.0), ('Off', 0.8120931695167226), ('8', 0.7900787112094715), ('all', 0.7819593379011948), ('open', 0.7725345299440239)]
Top words for pretrained_BERT neuron indx 2832 [('log', 1.0), ('Log', 0.981199958475753), ('e', 0.9375439538501673), ('0', 0.917232317039321), ('token', 0.8891033519654036)]
Top words for pretrained_BERT neuron indx 8976 [('400', 1.0), ('128', 0.9200521381165105), ('0', 0.8790703674376202), ('project', 0.8554410614773684), ('__copyright__', 0.8323119276295735)]
Top words for pretrained_BERT neuron indx 6942 [('future', 1.0), ('os', 0.9209322721591803), ('action', 0.9202841015987135), ('boot', 0.9035989593516423), ('second', 0.8932006931854265)]
Top words for pretrained_BERT neuron indx 6952 [('closing', 1.0), ('presence', 0.990094917004827), ('to', 0.9406498013714342), ('24', 0.9391386201559399), ('name', 0.9317386274652389)]
Top words for pretrained_BERT neuron indx 4916 [('with', 1.0), ('is', 0.9005772618316399), ('and', 0.833678304920813), ('as', 0.8139470003487391), ('in', 0.8012346571608824)]
Top words for pretrained_BERT neuron indx 9013 [('day', 1.0), ('v', 0.9808368400971567), ('absolute_import', 0.9245034254815165), ('pop', 0.8856172129612659), ('hour', 0.8818059739071179)]
Top words for pretrained_BERT neuron indx 9016 [('microseconds', 1.0), ('sorting_layer_id', 0.9038252575642268), ('bare', 0.8911759285142977), ('def', 0.8819611758030365), ('render_mode', 0.8665581412165374)]
Top words for pretrained_BERT neuron indx 4932 [('minutes', 1.0), ('iq', 0.7857519204017687), ('connection', 0.729112572597383), ('second', 0.6933622547199414), ('presence', 0.6747403299671088)]
Top words for pretrained_BERT neuron indx 2887 [('Exception', 1.0), ('Distance', 0.5967145698895314), ('message', 0.5883586283141307), ('View', 0.5702590015637974), ('break', 0.5655576068955879)]
Top words for pretrained_BERT neuron indx 9033 [('bare', 1.0), ('5', 0.9704223920872895), ('put', 0.9375826174971035), ('oslo', 0.9139816999061353), ('hasattr', 0.8559900569704535)]
Top words for pretrained_BERT neuron indx 4939 [('On', 1.0), ('List', 0.745785289393707), ('verbatim', 0.7234964909597488), ('required', 0.7107645699975222), ('Mesh', 0.6765182039818173)]
Top words for pretrained_BERT neuron indx 7003 [('META', 1.0), ('ms', 0.6614624290733845), ('probe', 0.6227037220424265), ('raise', 0.6103411427227927), ('Tab', 0.5965217381882875)]
Top words for pretrained_BERT neuron indx 7008 [('oslo', 1.0), ('core', 0.8492893050913939), ('shortcuts', 0.8417412111732709), ('or', 0.7947988321350286), ('models', 0.7936453560807356)]
Top words for pretrained_BERT neuron indx 868 [('Tab', 1.0), ('boot', 0.9453485773115015), ('unicode', 0.9205254880362977), ('baseline', 0.9120301614649312), ('items', 0.8415121171604559)]
Top words for pretrained_BERT neuron indx 7015 [('META', 1.0), ('REQUEST', 0.8645816353835045), ('sorted', 0.843823411281133), ('closing', 0.7839034194840127), ('future', 0.775173162639412)]
Top words for pretrained_BERT neuron indx 2920 [('local', 1.0), ('future', 0.9773791782238856), ('None', 0.9428286234889465), ('8', 0.9158680530517251), ('wwnType', 0.8947905054195082)]
Top words for pretrained_BERT neuron indx 7024 [('all', 1.0), ('dest', 0.9800529982054316), ('objects', 0.9676749145336385), ('RemoveTags', 0.8489564167405225), ('log', 0.8369708223381609)]
Top words for pretrained_BERT neuron indx 4979 [('match', 1.0), ('digest', 0.9381012339769015), ('Log', 0.9364003010430432), ('len', 0.9347902682856934), ('9', 0.9094604182505205)]
Top words for pretrained_BERT neuron indx 4990 [('1000', 1.0), ('calendar', 0.8567512402007826), ('Tab', 0.8161787111291907), ('clone', 0.815179908602482), ('wait', 0.8091717818957102)]
Top words for pretrained_BERT neuron indx 4993 [('encode', 1.0), ('seek', 0.9996109112639433), ('except', 0.9043053716409097), ('filter', 0.8905077489070118), ('end', 0.8657535811864451)]
Top words for pretrained_BERT neuron indx 4994 [('Off', 1.0), ('e', 0.9388638556828058), ('i', 0.9367254024510782), ('On', 0.9215739758689157), ('upper', 0.818669984691979)]
Top words for pretrained_BERT neuron indx 7042 [('1800', 1.0), ('800', 0.9866564799997788), ('86400', 0.9863777094738257), ('Tab', 0.8900766058786389), ('8000', 0.8732691874981313)]
Top words for pretrained_BERT neuron indx 898 [('close', 1.0), ('format', 0.8670095334826842), ('link', 0.7727183933091806), ('find', 0.7137869080342725), ('partition', 0.6558515801681657)]
Top words for pretrained_BERT neuron indx 7049 [('created', 1.0), ('seek', 0.8659138237144598), ('m', 0.7792142384976841), ('On', 0.7761213119514475), ('wait', 0.7735329534282782)]
Top words for pretrained_BERT neuron indx 9100 [('6', 1.0), ('1000', 0.9331734740823039), ('ZmqProxy', 0.8964610903727996), ('day', 0.8860291022579262), ('__hash__', 0.8847549906860611)]
Top words for pretrained_BERT neuron indx 2959 [('month', 1.0), ('minutes', 0.8639551479877061), ('division', 0.7797253049939824), ('enabled', 0.7771140276899232), ('baseline', 0.7636332613031722)]
Top words for pretrained_BERT neuron indx 5015 [('enabled', 1.0), ('GET', 0.8846101293857712), ('loads', 0.8809147443329731), ('requests', 0.8089737313032593), ('bind', 0.8059852308414887)]
Top words for pretrained_BERT neuron indx 5022 [('sans', 1.0), ('is_authorized', 0.9670731282945934), ('add_argument', 0.9655488263519936), ('upper', 0.9032542216665377), ('set_term_read', 0.9001005410026585)]
Top words for pretrained_BERT neuron indx 9119 [('bare', 1.0), ('uss', 0.6538366269165932), ('Post', 0.610115999769837), ('encode', 0.5932320943290474), ('e', 0.5796515360094453)]
Top words for pretrained_BERT neuron indx 5024 [('80', 1.0), ('target', 0.9575048012142303), ('32', 0.957348450727865), ('40', 0.9220477024132487), ('60', 0.889027031825846)]
Top words for pretrained_BERT neuron indx 9125 [('META', 1.0), ('if', 0.8260026115289699), ('5', 0.7978705940541384), ('with', 0.7373166749859236), ('except', 0.7181854120255851)]
Top words for pretrained_BERT neuron indx 2981 [('raise', 1.0), ('META', 0.9779728465957498), ('description', 0.8910816818344561), ('id', 0.8745435557570488), ('super', 0.8386571351603513)]
Top words for pretrained_BERT neuron indx 2983 [('ndt', 1.0), ('store', 0.8538100411521826), ('wait', 0.7841124002303251), ('count', 0.7650514597041757), ('time', 0.6809381447184986)]
Top words for pretrained_BERT neuron indx 7081 [('__hash__', 1.0), ('__int__', 0.9763276500585123), ('__class__', 0.9686022509513618), ('__add__', 0.9679103065020991), ('join', 0.9230636417541264)]
Top words for pretrained_BERT neuron indx 7082 [('minutes', 1.0), ('force', 0.6909757626783627), ('E', 0.6743044155502885), ('mins', 0.6462341878834714), ('max', 0.6181126076831716)]
Top words for pretrained_BERT neuron indx 940 [('proxy', 1.0), ('component', 0.9856852891282157), ('type', 0.9271152672096424), ('features', 0.9137366407462716), ('add', 0.8664853468327695)]
Top words for pretrained_BERT neuron indx 2999 [('path', 1.0), ('super', 0.9137530114995064), ('policy', 0.9118740560348224), ('log', 0.8915859365322475), ('hour', 0.8879423488332469)]
Top words for pretrained_BERT neuron indx 5052 [('other', 1.0), ('port', 0.9931329166048553), ('is', 0.9335665742514144), ('hpov', 0.9334129812814089), ('break', 0.8832923548259373)]
Top words for pretrained_BERT neuron indx 958 [('1', 1.0), ('authorization', 0.9154589783868614), ('Off', 0.9006642690393686), ('patch', 0.889709469457556), ('2', 0.8796526175320777)]
Top words for pretrained_BERT neuron indx 9151 [('all', 1.0), ('iq', 0.9264710987767887), ('unicode', 0.904308741735168), ('passwd', 0.8572160251725647), ('max', 0.8301264462622555)]
Top words for pretrained_BERT neuron indx 7107 [('24', 1.0), ('VerticalBillboard', 0.9869132293968863), ('component', 0.979955265800505), ('MAXBOARD', 0.9685849761365878), ('HorizontalBillboard', 0.9501927915426205)]
Top words for pretrained_BERT neuron indx 970 [('log', 1.0), ('Tab', 0.969446729555233), ('9', 0.9342332502939003), ('TOKEN_BLOCK', 0.9236627890420036), ('LoadUser', 0.9216147727031161)]
Top words for pretrained_BERT neuron indx 7115 [('__name__', 1.0), ('super', 0.9417776164977202), ('600', 0.9343394572756442), ('__version__', 0.8888802312170838), ('1024', 0.8850257032140918)]
Top words for pretrained_BERT neuron indx 9167 [('9', 1.0), ('1000', 0.9156110033016629), ('oslo', 0.9074136500747133), ('128', 0.8696515220629527), ('600', 0.8278865391274809)]
Top words for pretrained_BERT neuron indx 3030 [('count', 1.0), ('close', 0.8460903111350779), ('value', 0.8444183521493003), ('seek', 0.8308088016469585), ('while', 0.8014528381765269)]
Top words for pretrained_BERT neuron indx 7134 [('k', 1.0), ('s', 0.9915143418786748), ('128', 0.9415251650848233), ('re', 0.9390679730622046), ('sts', 0.8718653209202207)]
Top words for pretrained_BERT neuron indx 990 [('item', 1.0), ('description', 0.9633024407791851), ('core', 0.9613179804834855), ('ndt', 0.914789880853569), ('probe', 0.9052654891944061)]
Top words for pretrained_BERT neuron indx 9189 [('proxy', 1.0), ('day', 0.9993667899222252), ('month', 0.9196926000019822), ('year', 0.8443670418975915), ('models', 0.8341423904568185)]
Top words for pretrained_BERT neuron indx 999 [('join', 1.0), ('query', 0.7996898603178199), ('sans', 0.7866255204895624), ('request', 0.7863964030638332), ('Stretch', 0.7740517337860613)]
Top words for pretrained_BERT neuron indx 7146 [('Off', 1.0), ('minutes', 0.9785628619863269), ('class', 0.8975368293875816), ('to', 0.853463037452035), ('On', 0.8345336191169409)]
Top words for pretrained_BERT neuron indx 1003 [('View', 1.0), ('alt', 0.9536682435751411), ('tag', 0.9008051101694553), ('from', 0.8727032074717465), ('m', 0.8517870596557793)]
Top words for pretrained_BERT neuron indx 1010 [('types', 1.0), ('bare', 0.9844650838637247), ('ms', 0.9691622095158104), ('slug', 0.9150803553340199), ('material', 0.8700785193642058)]
Top words for pretrained_BERT neuron indx 9223 [('Simple', 1.0), ('calendar', 0.9611881845822134), ('META', 0.8718508870452327), ('ref', 0.8321323172975098), ('utc_datetime', 0.7939779731672917)]
Top words for pretrained_BERT neuron indx 7197 [('7', 1.0), ('1024', 0.7665545177185459), ('400', 0.7557373782264031), ('""', 0.7439111041944619), ('error', 0.72040251885935)]
Top words for pretrained_BERT neuron indx 7217 [('sorted', 1.0), ('open', 0.9458259455141645), ('setup', 0.8844670093077712), ('\\\'"\\\'', 0.8775893276313516), ('Node', 0.8765672991354704)]
Top words for pretrained_BERT neuron indx 7218 [('E', 1.0), ('and', 0.9368099829503418), ('400', 0.9159829457968776), ('1000', 0.9115606114607797), ('dict', 0.8821621699426591)]
Top words for pretrained_BERT neuron indx 1077 [('long', 1.0), ('all', 0.7550415305925153), ('identity', 0.7358690707101923), ('replace', 0.7294770953617186), ('Library', 0.7175229092307658)]
Top words for pretrained_BERT neuron indx 5184 [('minutes', 1.0), ('def', 0.9956873417281923), ('count', 0.9380803091881691), ('vCard', 0.9294643680011286), ('slug', 0.8924351334298882)]
Top words for pretrained_BERT neuron indx 9281 [('Mesh', 1.0), ('affinity', 0.9965977984569145), ('mesh', 0.8520031090376969), ('openstack', 0.8290303198358058), ('mesh1', 0.7962996469987417)]
Top words for pretrained_BERT neuron indx 7236 [('minutes', 1.0), ('second', 0.8930344826016714), ('iq', 0.8723474354664756), ('presence', 0.8161129281602293), ('connection', 0.8105303381228537)]
Top words for pretrained_BERT neuron indx 3143 [('link', 1.0), ('800', 0.9009951826412436), ('objects', 0.8726351256024113), ('find', 0.8221400019161718), ('open', 0.807540504162023)]
Top words for pretrained_BERT neuron indx 1101 [('GET', 1.0), ('day', 0.9993303454230943), ('get', 0.9904945390846615), ('other', 0.9619576600572441), ('v', 0.9488540808695562)]
Top words for pretrained_BERT neuron indx 7263 [('32', 1.0), ('80', 0.8787113125106789), ('3', 0.8770519479075617), ('30', 0.8593247872739098), ('write', 0.8411085405200541)]
Top words for pretrained_BERT neuron indx 7266 [('template', 1.0), ('contents', 0.9862088605477194), ('try', 0.8727911191354047), ('__name__', 0.8160109090246875), ('context', 0.7999502636112279)]
Top words for pretrained_BERT neuron indx 9322 [('17', 1.0), ('1', 0.9881390881723506), ('1800', 0.8121736839198184), ('3', 0.7924793741049916), ('3700', 0.7835753227725828)]
Top words for pretrained_BERT neuron indx 7279 [('Mesh', 1.0), ('".."', 0.9875052086531677), ('PY2', 0.9798993841078892), ('8000', 0.9738973613619142), ('Simple', 0.969348391534123)]
Top words for pretrained_BERT neuron indx 5239 [('Authorization', 1.0), ('builtins', 0.9388879950570564), ('authorization', 0.9325424848439305), ('reactor', 0.8905604346998577), ('ref', 0.7924235067281452)]
Top words for pretrained_BERT neuron indx 5240 [('Unauthorized', 1.0), ('oslo', 0.8905388442578879), ('end', 0.8813726729129894), ('id', 0.8777699771280336), ('ignore', 0.8716115488131193)]
Top words for pretrained_BERT neuron indx 5243 [('List', 1.0), ('os', 0.8514480380505932), ('proxy', 0.8441310919943201), ('time', 0.7843964848352449), ('list', 0.7603756349403065)]
Top words for pretrained_BERT neuron indx 5245 [('300', 1.0), ('30', 0.8581448164582579), ('17', 0.839223733089607), ('32', 0.7821000091480733), ('12', 0.7416050079899799)]
Top words for pretrained_BERT neuron indx 3198 [('Exception', 1.0), ('requests', 0.9754520090951453), ('k', 0.9505747691085764), ('put', 0.8584333513128664), ('wait', 0.8576147095896292)]
Top words for pretrained_BERT neuron indx 5250 [('end', 1.0), ('error', 0.9498139013197149), ('builtins', 0.9484282514642935), ('On', 0.927774903646671), ('unicode', 0.8580148304790025)]
Top words for pretrained_BERT neuron indx 7309 [('end', 1.0), ('core', 0.8902212587571143), ('not', 0.8640133434792894), ('context', 0.7998934262963798), ('7', 0.7937324683774013)]
Top words for pretrained_BERT neuron indx 7312 [('models', 1.0), ('"HTTP_BEARER_TOKEN"', 0.8677637918414148), ('s', 0.8474462318457051), ('m', 0.8392100951915334), ('materials', 0.8348441349189066)]
Top words for pretrained_BERT neuron indx 5266 [('put', 1.0), ('1000', 0.7050575723980581), ('text', 0.6828056282247453), ('modes', 0.676954733160287), ('tag', 0.6515969687175303)]
Top words for pretrained_BERT neuron indx 7317 [('upper', 1.0), ('6', 0.8339771712423687), ('broadcast', 0.8117895104639047), ('if', 0.8071223908094598), ('created', 0.7307815237500629)]
Top words for pretrained_BERT neuron indx 7319 [('1800', 1.0), ('GET', 0.9378603615238201), ('store', 0.8769868312822612), ('1', 0.8456810865607445), ('"m_ReflectionProbeUsage"', 0.8174176557775067)]
Top words for pretrained_BERT neuron indx 7325 [('patch', 1.0), ('project', 0.999626862243854), ('Post', 0.974089864287983), ('unicode', 0.9506479385141133), ('post', 0.9484807330469938)]
Top words for pretrained_BERT neuron indx 7326 [('"oslo"', 1.0), ('exceptions', 0.9757584850883447), ('"Port"', 0.9451649611629215), ('add_argument', 0.9002414644109049), ('7', 0.8984398347455325)]
Top words for pretrained_BERT neuron indx 7331 [('if', 1.0), ('get_profile_available_storage_systems', 0.9197857283649599), ('get_profile_networks', 0.9152798196910444), ('with', 0.886705271850755), ('except', 0.8371665985200492)]
Top words for pretrained_BERT neuron indx 3255 [('us', 1.0), ('created', 0.9692599124387427), ('connection', 0.8579323076374964), ('token', 0.8268236592961055), ('Mesh', 0.7958126479791172)]
Top words for pretrained_BERT neuron indx 5304 [('group', 1.0), ('oslo', 0.9192385944820218), ('List', 0.8197771888671531), ('mesh', 0.786573557516161), ('2', 0.7736073881536305)]
Top words for pretrained_BERT neuron indx 1209 [('month', 1.0), ('minute', 0.8997536341164772), ('server', 0.884331223456652), ('minutes', 0.8532958786887902), ('Stretch', 0.8240495483851793)]
Top words for pretrained_BERT neuron indx 1218 [('sans', 1.0), ('text', 0.7920150483450747), ('pop', 0.7532516978075383), ('server', 0.7399874142004983), ('end', 0.702550112682639)]
Top words for pretrained_BERT neuron indx 1219 [('render', 1.0), ('state', 0.9944516454801091), ('len', 0.9754299467283912), ('seek', 0.9692784784822291), ('def', 0.9489880664366186)]
Top words for pretrained_BERT neuron indx 5334 [('count', 1.0), ('close', 0.9664062055283432), ('while', 0.8449294463693201), ('value', 0.8287007697605958), ('log', 0.8219823839297122)]
Top words for pretrained_BERT neuron indx 7384 [('or', 1.0), ('Unauthorized', 0.992776976656103), ('seconds', 0.9075364092209679), ('purpose', 0.8444007845560764), ('try', 0.8382787096540538)]
Top words for pretrained_BERT neuron indx 7388 [('types', 1.0), ('upper', 0.9795783905846255), ('open', 0.9523833400351486), ('zone', 0.9497378779545589), ('secs', 0.931287004759847)]
Top words for pretrained_BERT neuron indx 7392 [('end', 1.0), ('logging', 0.9678786115347725), ('to', 0.9180531660124278), ('max', 0.9153600592872132), ('int', 0.8556534096476982)]
Top words for pretrained_BERT neuron indx 7394 [('\\\'"\\\'', 1.0), ('verbatim', 0.9214140922891267), ('7', 0.8851088573270716), ('add', 0.7807126370487993), ('Unauthorized', 0.7643916087585172)]
Top words for pretrained_BERT neuron indx 3299 [('to', 1.0), ('zone', 0.9824231095588868), ('save', 0.9725687977062228), ('Plugin', 0.919621784072022), ('secs', 0.9186383583336251)]
Top words for pretrained_BERT neuron indx 9442 [('Mesh', 1.0), ('models', 0.9292157356203433), ('__copyright__', 0.9092917293087166), ('MAXCLUB', 0.8543096947825785), ('os', 0.8068642761844813)]
Top words for pretrained_BERT neuron indx 3303 [('query', 1.0), ('split', 0.9243821111383892), ('request', 0.8874828817484237), ('params', 0.8473196565140609), ('ms', 0.8239543603552892)]
Top words for pretrained_BERT neuron indx 9450 [('Renderer', 1.0), ('7', 0.9746858848373473), ('ms', 0.9282199668331292), ('serverProfileTemplateUri', 0.8676818780161071), ('millis', 0.8674563171519506)]
Top words for pretrained_BERT neuron indx 3306 [('push', 1.0), ('description', 0.9697267298829713), ('class', 0.8726467231164208), ('register', 0.8525632096039695), ('Register', 0.8436402306271058)]
Top words for pretrained_BERT neuron indx 3307 [('calendar', 1.0), ('Library', 0.8479526192244927), ('E', 0.8217968664650466), ('Node', 0.7649726380747426), ('m', 0.7399427423166641)]
Top words for pretrained_BERT neuron indx 7406 [('zone', 1.0), ('"purpose"', 0.960213270953466), ('group', 0.9212764221848185), ('join', 0.9162224686301512), ('local', 0.9117728571593264)]
Top words for pretrained_BERT neuron indx 7428 [('models', 1.0), ('utcnow', 0.9890868602916233), ('GetUID', 0.8941078507593687), ('request', 0.8891315351004893), ('int', 0.8632925541225447)]
Top words for pretrained_BERT neuron indx 3334 [('2', 1.0), ('1', 0.9316452854102105), ('write', 0.82970341769103), ('ping', 0.8273606015453401), ('pass', 0.818951422170046)]
Top words for pretrained_BERT neuron indx 7436 [('On', 1.0), ('v', 0.9243954040526119), ('in', 0.8459982624025685), ('end', 0.8327890388847727), ('dest', 0.8116345767844677)]
Top words for pretrained_BERT neuron indx 1293 [('id', 1.0), ('iq', 0.9902043528594523), ('unicode', 0.9459809094652428), ('Simple', 0.9203650397972155), ('info', 0.8703258740692057)]
Top words for pretrained_BERT neuron indx 5390 [('force', 1.0), ('8', 0.9105511611732213), ('Off', 0.8132055025601351), ('zone', 0.7959680528869281), ('15', 0.7873701795937644)]
Top words for pretrained_BERT neuron indx 5394 [('log', 1.0), ('Simple', 0.9341014123589553), ('port', 0.9321193141456517), ('logging', 0.8752983174101869), ('minutes', 0.8529323166782153)]
Top words for pretrained_BERT neuron indx 1303 [('seek', 1.0), ('server', 0.7460121785491614), ('find', 0.680925160596506), ('probe', 0.6795103498355665), ('logging', 0.6491900748461737)]
Top words for pretrained_BERT neuron indx 9495 [('strip', 1.0), ('domain', 0.9877903581087608), ('replace', 0.963346166312059), ('META', 0.9433949962604911), ('if', 0.9217752049229487)]
Top words for pretrained_BERT neuron indx 9501 [('5', 1.0), ('6', 0.9663194307288654), ('7', 0.896409068718847), ('log', 0.7861932686111299), ('oslo', 0.7670386237217264)]
Top words for pretrained_BERT neuron indx 3364 [('tastypie', 1.0), ('prange', 0.808855818004075), ('start', 0.7962382822251156), ('policy', 0.7637161337477131), ('blocking', 0.76239135576127)]
Top words for pretrained_BERT neuron indx 3368 [('except', 1.0), ('UCache', 0.9825857375921623), ('replace', 0.9695071174933599), ('minutes', 0.9129949643343626), ('add', 0.8528982442386528)]
Top words for pretrained_BERT neuron indx 1333 [('os', 1.0), ('import', 0.7969740442741211), ('len', 0.6568650891364878), ('read', 0.6185346795109895), ('range', 0.6173309507719571)]
Top words for pretrained_BERT neuron indx 3384 [('group', 1.0), ('Simple', 0.9874485684209312), ('E', 0.9396577862279031), ('sans', 0.9340813046785595), ('f', 0.8980557681523428)]
Top words for pretrained_BERT neuron indx 3387 [('with', 1.0), ('sorted', 0.8954014098841534), ('part', 0.8261727604442982), ('replace', 0.824574601951191), ('max', 0.8198570467843407)]
Top words for pretrained_BERT neuron indx 3397 [('return', 1.0), ('save', 0.9370736646858356), ('proxy', 0.8981701630854956), ('zone', 0.8324212290803096), ('find', 0.7677286852934131)]
Top words for pretrained_BERT neuron indx 1351 [('Exception', 1.0), ('except', 0.7413088614678691), ('action', 0.7308966604464683), ('horizon', 0.7268914737844372), ('break', 0.7256321064617308)]
Top words for pretrained_BERT neuron indx 3414 [('affinity', 1.0), ('help', 0.994988874209552), ('st', 0.8541965301169735), ('token', 0.8277840255289115), ('str', 0.8196437564670126)]
Top words for pretrained_BERT neuron indx 9560 [('sans', 1.0), ('6', 0.8361812327435717), ('constants', 0.8350581079258957), ('sorted', 0.720984232437773), ('unicode', 0.6975681072662707)]
Top words for pretrained_BERT neuron indx 1372 [('enclosure', 1.0), ('setup', 0.9684181040019793), ('Billboard', 0.9225229696135947), ('material', 0.8898467925720088), ('except', 0.8786687606324712)]
Top words for pretrained_BERT neuron indx 3422 [('unicode', 1.0), ('all', 0.8454332350817726), ('timezone', 0.7529394414729712), ('digest', 0.7401958839762072), ('Digest', 0.7073653147018015)]
Top words for pretrained_BERT neuron indx 1384 [('us', 1.0), ('pass', 0.9678748526900598), ('authorized', 0.9412775051644667), ('pooltype', 0.9243529796976063), ('Unauthorized', 0.8392368132631776)]
Top words for pretrained_BERT neuron indx 5482 [('oslo', 1.0), ('models', 0.8452097910478474), ('15', 0.7146167710073116), ('14', 0.6938436778571984), ('16', 0.6830697779645887)]
Top words for pretrained_BERT neuron indx 1387 [('broadcast', 1.0), ('group', 0.9459069802960401), ('range', 0.9402281169540541), ('policy', 0.9217094730763661), ('join', 0.8297661663297689)]
Top words for pretrained_BERT neuron indx 9580 [('7', 1.0), ('15', 0.9925834331062051), ('8000', 0.9481685713590092), ('6', 0.9381108948803808), ('nargs', 0.8804393331902134)]
Top words for pretrained_BERT neuron indx 1392 [('info', 1.0), ('division', 0.9447924241555468), ('split', 0.7754786213304938), ('required', 0.7744986037643434), ('dt', 0.7660134855763655)]
Top words for pretrained_BERT neuron indx 7537 [('upper', 1.0), ('in', 0.8702975501702032), ('split', 0.8673051739930483), ('k', 0.7410683598896677), ('milliseconds', 0.7314743131391842)]
Top words for pretrained_BERT neuron indx 9590 [('token', 1.0), ('hour', 0.9847059370746128), ('identity', 0.9476463065911597), ('128', 0.8828568786736904), ('minute', 0.874462245990589)]
Top words for pretrained_BERT neuron indx 3447 [('root', 1.0), ('common', 0.9081267551006165), ('strip', 0.8623718212585928), ('identity', 0.8392944887117906), ('1000', 0.8186992832687031)]
Top words for pretrained_BERT neuron indx 1403 [('ignore', 1.0), ('add', 0.9827682588844208), ('local', 0.972687733260063), ('context', 0.9562165621543461), ('path', 0.9246575112779306)]
Top words for pretrained_BERT neuron indx 1404 [('push', 1.0), ('UCache', 0.9040044243250591), ('modes', 0.8454023354168431), ('True', 0.7994434569710012), ('Stretch', 0.7699812384219031)]
Top words for pretrained_BERT neuron indx 1405 [('6', 1.0), ('loads', 0.9428442634735932), ('hour', 0.9123299070420868), ('match', 0.9007027060861569), ('parent', 0.8819267528552285)]
Top words for pretrained_BERT neuron indx 9597 [('6', 1.0), ('"sysop"', 0.9026273215947073), ('Library', 0.9009756727886703), ('ds_owner_created', 0.8704042762137763), ('4', 0.8619621567141036)]
Top words for pretrained_BERT neuron indx 5499 [('mins', 1.0), ('30', 0.8667760608473951), ('millis', 0.8524569021797643), ('GetMirror', 0.7967012233160792), ('long', 0.7765446455773622)]
Top words for pretrained_BERT neuron indx 3457 [('seek', 1.0), ('filters', 0.7652784175083721), ('long', 0.723683209311896), ('proxy', 0.6714210281284853), ('as', 0.6327098699061873)]
Top words for pretrained_BERT neuron indx 9602 [('20', 1.0), ('Distance', 0.9386705506928963), ('type', 0.81269203174492), ('40', 0.7744120135187058), ('1000', 0.7308223449179249)]
Top words for pretrained_BERT neuron indx 7560 [('repr', 1.0), ('probe', 0.8144943523283225), ('1024', 0.8122702694609366), ('argv', 0.8021811236026958), ('kls', 0.7436534583079771)]
Top words for pretrained_BERT neuron indx 5516 [('minutes', 1.0), ('stanza', 0.9005288251069493), ('contents', 0.8343186619491528), ('key', 0.8085926843199737), ('seconds', 0.77079672236044)]
Top words for pretrained_BERT neuron indx 7565 [('9', 1.0), ('pdb', 0.898809531251107), ('".."', 0.8105107718106401), ('if', 0.7558750326648881), ('for', 0.6481765059543347)]
Top words for pretrained_BERT neuron indx 5518 [('sorted', 1.0), ('f', 0.8498765018141697), ('required', 0.8271849779375908), ('v', 0.754432518771131), ('to', 0.7516468993282708)]
Top words for pretrained_BERT neuron indx 5519 [('patch', 1.0), ('Unauthorized', 0.871028365357104), ('and', 0.8645463343563201), ('long', 0.8466751519051351), ('format', 0.7919211556974596)]
Top words for pretrained_BERT neuron indx 9616 [('seek', 1.0), ('method', 0.7867065391747086), ('f', 0.725135293539411), ('META', 0.7122186923608428), ('mesh2', 0.7037087972224707)]
Top words for pretrained_BERT neuron indx 1425 [('affinity', 1.0), ('host', 0.9218545008117669), ('month', 0.9187578766838166), ('E', 0.8817143373530772), ('method', 0.8725827322869533)]
Top words for pretrained_BERT neuron indx 7568 [('save', 1.0), ('Register', 0.9915927244145322), ('purpose', 0.957085235154212), ('bind', 0.9489578275166843), ('us', 0.9271504740155935)]
Top words for pretrained_BERT neuron indx 1424 [('group', 1.0), ('On', 0.8023262927910847), ('calendar', 0.7571194065104913), ('Distance', 0.7494592464803187), ('super', 0.7297518981705131)]
Top words for pretrained_BERT neuron indx 7572 [('month', 1.0), ('get_resources', 0.7647008408403736), ('12', 0.749707677937811), ('consume_in_thread', 0.7430301668415024), ('types', 0.7362744671586484)]
Top words for pretrained_BERT neuron indx 9623 [('META', 1.0), ('store', 0.8732684093697756), ('__copyright__', 0.8690671144547568), ('component', 0.8005055978058757), ('requests', 0.7930577605782525)]
Top words for pretrained_BERT neuron indx 3479 [('loads', 1.0), ('enabled', 0.9423717558422089), ('META', 0.9197812309091131), ('not', 0.8821403153550437), ('script', 0.8701931901808155)]
Top words for pretrained_BERT neuron indx 9630 [('error', 1.0), ('RequestContext', 0.7933619077814335), ('exceptions', 0.7930578308568597), ('template_name', 0.7913236494607634), ('REQUEST', 0.7832344225109745)]
Top words for pretrained_BERT neuron indx 7583 [('bare', 1.0), ('e', 0.6590240018037137), ('created', 0.6417936507332466), ('uss', 0.6208951888922802), ('Post', 0.6126632990712373)]
Top words for pretrained_BERT neuron indx 3491 [('Tab', 1.0), ('Off', 0.8841399218750781), ('ping', 0.8703716627421506), ('wait', 0.820572933107038), ('with', 0.8146091037454303)]
Top words for pretrained_BERT neuron indx 7589 [('META', 1.0), ('5', 0.8565079253928375), ('if', 0.8322235595127961), ('4', 0.7150839145917692), ('2', 0.6998596599005659)]
Top words for pretrained_BERT neuron indx 1445 [('raise', 1.0), ('month', 0.949909930232695), ('script', 0.9022764079767837), ('root', 0.8705727742524741), ('direct', 0.7534257277126463)]
Top words for pretrained_BERT neuron indx 1447 [('loads', 1.0), ('parts', 0.8973241909137253), ('routes', 0.8787606641548776), ('store', 0.8497505264343292), ('route', 0.7970778377972417)]
Top words for pretrained_BERT neuron indx 5545 [('128', 1.0), ('items', 0.9987556717707119), ('requests', 0.942870031313479), ('connection', 0.8867861107111562), ('__hash__', 0.8459856646406568)]
Top words for pretrained_BERT neuron indx 3499 [('seek', 1.0), ('continue', 0.9056765386816645), ('Exception', 0.8795330754011039), ('16', 0.8676630418256578), ('mins', 0.8495015779499817)]
Top words for pretrained_BERT neuron indx 9647 [('mins', 1.0), ('On', 0.9761040451784544), ('month', 0.9468276771844691), ('hour', 0.9131021965425492), ('minutes', 0.8771347410957219)]
Top words for pretrained_BERT neuron indx 5559 [('us', 1.0), ('connection', 0.8822921599877361), ('replace', 0.8754568834851827), ('max', 0.8667170396796442), ('16', 0.8517198271864053)]
Top words for pretrained_BERT neuron indx 7608 [('List', 1.0), ('2', 0.8957656703893049), ('7', 0.8443528124889449), ('9', 0.7680302199319123), ('domain', 0.7341100530997671)]
Top words for pretrained_BERT neuron indx 3513 [('root', 1.0), ('body', 0.9324165603191338), ('9', 0.9320309977733398), ('6', 0.9162509899061075), ('server', 0.8222300570292085)]
Top words for pretrained_BERT neuron indx 3516 [('hpov', 1.0), ('port', 0.9631664295863805), ('id', 0.9627855210423297), ('tz', 0.9505009832506285), ('required', 0.9426534583239661)]
Top words for pretrained_BERT neuron indx 1469 [('sts', 1.0), ('enabled', 0.9577283012057469), ('description', 0.9008317903019035), ('Tab', 0.7977239029539169), ('META', 0.7751987238931956)]
Top words for pretrained_BERT neuron indx 3520 [('parser', 1.0), ('route', 0.9716612378215261), ('oslo', 0.9394662809246697), ('set', 0.9228268115705287), ('ref', 0.8995273777014057)]
Top words for pretrained_BERT neuron indx 1473 [('con', 1.0), ('passwd', 0.8656048630248279), ('loads', 0.8618459292899253), ('pass', 0.8353994159686137), ('count', 0.8247804595712186)]
Top words for pretrained_BERT neuron indx 5571 [('VerticalBillboard', 1.0), ('match', 0.9396037260948087), ('HorizontalBillboard', 0.9279446306087347), ('post', 0.8776024631798048), ('class', 0.8674789475578322)]
Top words for pretrained_BERT neuron indx 7624 [('0', 1.0), ('1', 0.9730017095168499), ('HorizontalBillboard', 0.9455630164171357), ('VerticalBillboard', 0.9377707199893524), ('MAXBOARD', 0.9230923490480046)]
Top words for pretrained_BERT neuron indx 1483 [('settings', 1.0), ('minute', 0.7974393877561801), ('0', 0.7755969080875768), ('message', 0.6985548976055187), ('context', 0.6867998666142324)]
Top words for pretrained_BERT neuron indx 5579 [('minutes', 1.0), ('Tab', 0.9663746746011972), ('fcsans', 0.8968280096529254), ('routes', 0.8425031619488061), ('Board', 0.8410723206076898)]
Top words for pretrained_BERT neuron indx 1494 [('count', 1.0), ('close', 0.915078347223122), ('def', 0.7381483839505852), ('wait', 0.683472048957715), ('info', 0.6537984863374428)]
Top words for pretrained_BERT neuron indx 9694 [('Simple', 1.0), ('component', 0.9628935631410288), ('View', 0.9433533679566194), ('5', 0.8544633050291374), ('ref', 0.8421195027246081)]
Top words for pretrained_BERT neuron indx 9696 [('register', 1.0), ('int', 0.9434876701374456), ('calendar', 0.9239196885891576), ('META', 0.8722106174311633), ('end', 0.8637527691857992)]
Top words for pretrained_BERT neuron indx 7649 [('horizon', 1.0), ('1800', 0.9485080916276721), ('800', 0.8492022636636488), ('not', 0.832975606206188), ('to', 0.8009524905234575)]
Top words for pretrained_BERT neuron indx 9697 [('7', 1.0), ('identity', 0.9322403183040779), ('readline', 0.9041343199867427), ('year', 0.8855597967417492), ('9', 0.8412857566254923)]
Top words for pretrained_BERT neuron indx 5601 [('read', 1.0), ('format', 0.9986188390627295), ('broadcast', 0.8885129737769942), ('Util', 0.8544138080897116), ('settings', 0.8025732931173791)]
Top words for pretrained_BERT neuron indx 7656 [('e', 1.0), ('600', 0.9026681617369597), ('or', 0.8847931344862195), ('to', 0.8812606290982624), ('format', 0.8550546771447306)]
Top words for pretrained_BERT neuron indx 5610 [('class', 1.0), ('Off', 0.9821923438288077), ('seconds', 0.9068459442626633), ('help', 0.8937457648527781), ('sans', 0.8599654500802572)]
Top words for pretrained_BERT neuron indx 9707 [('features', 1.0), ('argv', 0.8620063554368292), ('core', 0.8164601914898649), ('seek', 0.7678855906896248), ('args', 0.7577742543028221)]
Top words for pretrained_BERT neuron indx 7660 [('logging', 1.0), ('post', 0.8996032539851039), ('seconds', 0.879235096033523), ('localize', 0.8758028833176171), ('key', 0.8743387152705278)]
Top words for pretrained_BERT neuron indx 7662 [('List', 1.0), ('GetBoard', 0.9701493621029009), ('24', 0.9347453100214348), ('__repr__', 0.9163699478671226), ('list', 0.8519572807517029)]
Top words for pretrained_BERT neuron indx 7668 [('2', 1.0), ('seconds', 0.9981020702086286), ('minutes', 0.9841951433780382), ('for', 0.9769853666190172), ('1000', 0.9514151731362187)]
Top words for pretrained_BERT neuron indx 1527 [('Unauthorized', 1.0), ('zone', 0.9778412471110092), ('exceptions', 0.9633006323454418), ('upper', 0.9394931084851386), ('save', 0.8878764511369519)]
Top words for pretrained_BERT neuron indx 3584 [('component', 1.0), ('other', 0.8772283443938359), ('Component', 0.8720913715173886), ('break', 0.8708818613471189), ('route', 0.8491915594358558)]
Top words for pretrained_BERT neuron indx 9736 [('pop', 1.0), ('12', 0.7192780368252714), ('proxy', 0.7106946738523574), ('128', 0.6972688483162439), ('log', 0.6955642153743388)]
Top words for pretrained_BERT neuron indx 3592 [('pop', 1.0), ('count', 0.9365131555317889), ('con', 0.8179488267738572), ('On', 0.7749009116520424), ('calendar', 0.7171542446243391)]
Top words for pretrained_BERT neuron indx 1549 [('object', 1.0), ('objects', 0.8882457637232755), ('description', 0.8743508906717852), ('field', 0.8382589466010358), ('seek', 0.8274070034424673)]
Top words for pretrained_BERT neuron indx 5645 [('bind', 1.0), ('write', 0.8641618371098029), ('enclosure', 0.8555973034415046), ('max', 0.848184441717663), ('property', 0.8374224396929721)]
Top words for pretrained_BERT neuron indx 1550 [('key', 1.0), ('len', 0.8873413561278946), ('zone', 0.8585785656426352), ('strip', 0.8198752730357196), ('connection', 0.8166561277169764)]
Top words for pretrained_BERT neuron indx 1567 [('link', 1.0), ('local', 0.9467661791895556), ('authenticator', 0.834617881947599), ('traceback', 0.7682249964117279), ('month', 0.7618696956295096)]
Top words for pretrained_BERT neuron indx 9771 [('7', 1.0), ('sans', 0.9775298562980675), ('with', 0.9117901867014326), ('hour', 0.8100944322809028), ('while', 0.7806730095009603)]
Top words for pretrained_BERT neuron indx 5684 [('with', 1.0), ('is', 0.90395388451863), ('in', 0.8397557432393694), ('int', 0.8098756339800371), ('as', 0.7997000512493961)]
Top words for pretrained_BERT neuron indx 5691 [('sorted', 1.0), ('long', 0.958271830857662), ('field', 0.7882030215536576), ('with', 0.7648791226751382), ('identity', 0.7108368459262951)]
Top words for pretrained_BERT neuron indx 5694 [('division', 1.0), ('exceptions', 0.8320722753781971), ('try', 0.8302538515239696), ('add', 0.7639510382423249), ('put', 0.7321143552869951)]
Top words for pretrained_BERT neuron indx 3648 [('sorted', 1.0), ('vCard', 0.9745943083810689), ('count', 0.9236754810711186), ('minutes', 0.8802895477908856), ('20', 0.8637304607285534)]
Top words for pretrained_BERT neuron indx 1600 [('authorized', 1.0), ('field', 0.8601684149002077), ('stat', 0.855896587577923), ('property', 0.8499959250105832), ('clone', 0.8187961658990027)]
Top words for pretrained_BERT neuron indx 5700 [('minutes', 1.0), ('iq', 0.7225679925049734), ('second', 0.7160198830016653), ('presence', 0.7080135789226281), ('affinity', 0.7018739391203725)]
Top words for pretrained_BERT neuron indx 3655 [('to', 1.0), ('Exception', 0.905343084124394), ('not', 0.7228070793952688), ('con', 0.719883815471336), ('local', 0.6562475199361092)]
Top words for pretrained_BERT neuron indx 5718 [('openstack', 1.0), ('ms', 0.8791491798774509), ('ignore', 0.8783589972283308), ('help', 0.8782719346908185), ('all', 0.8493147927050814)]
Top words for pretrained_BERT neuron indx 5725 [('oslo', 1.0), ('upper', 0.9236160890226454), ('boot', 0.8798699332292846), ('set', 0.8130347164309326), ('purpose', 0.8040177781005504)]
Top words for pretrained_BERT neuron indx 5730 [('contents', 1.0), ('Distance', 0.9276581631264806), ('template', 0.8610047158760121), ('Stretch', 0.774635113040272), ('format', 0.7516606221523178)]
Top words for pretrained_BERT neuron indx 5731 [('sans', 1.0), ('error', 0.8368960440566763), ('default', 0.820691328949505), ('ref', 0.7322124882243093), ('400', 0.7307407651467169)]
Top words for pretrained_BERT neuron indx 9844 [('5', 1.0), ('9', 0.8843600657449012), ('seek', 0.8355402789824334), ('find', 0.7640716601815221), ('save', 0.7514421921233472)]
Top words for pretrained_BERT neuron indx 7799 [('12', 1.0), ('minutes', 0.935537414006235), ('None', 0.8976785396395184), ('local', 0.8335199311580069), ('or', 0.7709827262364124)]
Top words for pretrained_BERT neuron indx 3707 [('proxy', 1.0), ('context', 0.9819172377619545), ('path', 0.9182727932243626), ('local', 0.9043620768107306), ('dt', 0.8191867900142985)]
Top words for pretrained_BERT neuron indx 7804 [('with', 1.0), ('for', 0.7076600327528899), ('core', 0.6972476170513953), ('oslo', 0.6544820956375144), ('and', 0.6436140424348168)]
Top words for pretrained_BERT neuron indx 7807 [('day', 1.0), ('for', 0.9193574004546621), ('models', 0.8684662478217923), ('calendar', 0.8374716043086085), ('""', 0.8175910962773222)]
Top words for pretrained_BERT neuron indx 9859 [('bool', 1.0), ('7', 0.9732580420132241), ('readline', 0.9312352314664862), ('9', 0.9068420367286177), ('REQUEST', 0.8739136992164606)]
Top words for pretrained_BERT neuron indx 7812 [('all', 1.0), ('return', 0.879257547435915), ('is', 0.8103897605891388), ('uss', 0.7624851443185897), ('day', 0.7415639036278253)]
Top words for pretrained_BERT neuron indx 5773 [('end', 1.0), ('sent_close', 0.9063508375677111), ('1', 0.9054987953306146), ('0', 0.8553330634276032), ('root', 0.8293129028619532)]
Top words for pretrained_BERT neuron indx 3727 [('minutes', 1.0), ('month', 0.9824692198371061), ('Exception', 0.9039601752657797), ('baseline', 0.8746331782936345), ('ret', 0.8721505276437106)]
Top words for pretrained_BERT neuron indx 3728 [('On', 1.0), ('group', 0.8426329950137029), ('Simple', 0.765953390016363), ('Off', 0.684477576627616), ('tag', 0.645980839677364)]
Top words for pretrained_BERT neuron indx 5783 [('loads', 1.0), ('bind', 0.961212575750646), ('List', 0.9395207192667133), ('requests', 0.9349685018123614), ('enabled', 0.9004266956853677)]
Top words for pretrained_BERT neuron indx 9881 [('7', 1.0), ('24', 0.9948688524563419), ('IntEnum', 0.9487444823278691), ('20', 0.8829702087714041), ('group', 0.8789910080929937)]
Top words for pretrained_BERT neuron indx 5795 [('except', 1.0), ('with', 0.8648222678787537), ('if', 0.8506476438523076), ('oslo', 0.7818786908532235), ('7', 0.7582534082558751)]
Top words for pretrained_BERT neuron indx 9891 [('v', 1.0), ('k', 0.9981291380659455), ('second', 0.9565120147945742), ('alt', 0.9270362421911819), ('List', 0.8482570467763283)]
Top words for pretrained_BERT neuron indx 9893 [('5', 1.0), ('META', 0.9172447156876381), ('E', 0.861182724687965), ('except', 0.8541269774883178), ('month', 0.8174536804522493)]
Top words for pretrained_BERT neuron indx 3757 [('1000', 1.0), ('600', 0.9883977130859296), ('domain', 0.934424517139316), ('try', 0.8596122092139654), ('title', 0.7554409447100879)]
Top words for pretrained_BERT neuron indx 5807 [('Billboard', 1.0), ('created', 0.9584902215286136), ('bare', 0.9035965333374242), ('affinity', 0.86701253257927), ('authorized', 0.8385974955509318)]
Top words for pretrained_BERT neuron indx 7855 [('".."', 1.0), ('4', 0.9997473800095283), ('"Host"', 0.9938554741500907), ('not', 0.9314686081679829), ('i', 0.9090211294310103)]
Top words for pretrained_BERT neuron indx 5820 [('port', 1.0), ('other', 0.9430225332063641), ('hpov', 0.9082268405709103), ('purpose', 0.9019266553661545), ('None', 0.8575479707767637)]
Top words for pretrained_BERT neuron indx 1729 [('except', 1.0), ('split', 0.825909024987081), ('sans', 0.8192650897375527), ('errors', 0.7870621951869269), ('log', 0.7567650934404961)]
Top words for pretrained_BERT neuron indx 7875 [('24', 1.0), ('17', 0.946268016219997), ('30', 0.9174615528337561), ('receive_shadows', 0.9148041222349647), ('component', 0.9110831664894901)]
Top words for pretrained_BERT neuron indx 5827 [('template', 1.0), ('seek', 0.8795381034615952), ('None', 0.7640935515860299), ('shts', 0.7594772100071481), ('parts', 0.7495297220189775)]
Top words for pretrained_BERT neuron indx 1742 [('ping', 1.0), ('sans', 0.9315951160218525), ('exceptions', 0.8735197232066373), ('loads', 0.8604271981289159), ('alt', 0.8398949706152985)]
Top words for pretrained_BERT neuron indx 9935 [('oslo', 1.0), ('9', 0.8646870093972557), ('8000', 0.7863728633232846), ('0', 0.7771269045702603), ('128', 0.7758046795901515)]
Top words for pretrained_BERT neuron indx 7888 [('zone', 1.0), ('post', 0.7765759028046407), ('from', 0.7551657746287751), ('pass', 0.6910182329139836), ('bind', 0.6847783380458534)]
Top words for pretrained_BERT neuron indx 9942 [('ref', 1.0), ('required', 0.8967830272888425), ('wait', 0.8915356998510631), ('blocking', 0.8836234404973194), ('uss', 0.8600192826617904)]
Top words for pretrained_BERT neuron indx 5856 [('logging', 1.0), ('META', 0.9882931278036192), ('int', 0.9350363943465699), ('with', 0.8209413428033732), ('log', 0.8116104133456385)]
Top words for pretrained_BERT neuron indx 7905 [('__long__', 1.0), ('blocking', 0.9609997676088491), ('Library', 0.9305025975147768), ('seconds', 0.9201935287982538), ('or', 0.8898325789883252)]
Top words for pretrained_BERT neuron indx 3808 [('alt', 1.0), ('context', 0.9257716568453334), ('future', 0.8506628161506756), ('proxy', 0.808548363661865), ('setup', 0.7819113126326203)]
Top words for pretrained_BERT neuron indx 5859 [('host', 1.0), ('send', 0.9885378054525426), ('False', 0.9882877588005101), ('return', 0.9406762684716289), ('day', 0.8878827081067299)]
Top words for pretrained_BERT neuron indx 5862 [('authorization', 1.0), ('authentication', 0.9199003894743404), ('type', 0.9031154213053006), ('context', 0.9023707408514893), ('1024', 0.838083633431657)]
Top words for pretrained_BERT neuron indx 7914 [('minutes', 1.0), ('to', 0.9625022187713859), ('Off', 0.8922012778014251), ('millis', 0.8309712717874563), ('digest', 0.7926656293068329)]
Top words for pretrained_BERT neuron indx 3822 [('board', 1.0), ('Component', 0.9523488177935515), ('component', 0.902191507073327), ('List', 0.8977994168721115), ('count', 0.8816651459331792)]
Top words for pretrained_BERT neuron indx 7920 [('format', 1.0), ('list', 0.9765687023293945), ('7', 0.9279046002046986), ('Billboard', 0.8627076682775937), ('List', 0.7180007743576501)]
Top words for pretrained_BERT neuron indx 7922 [('type', 1.0), ('blocking', 0.9673984274490516), ('all', 0.9222643629124532), ('required', 0.8928234937858904), ('types', 0.884410395013837)]
Top words for pretrained_BERT neuron indx 5878 [('except', 1.0), ('NoRoute', 0.9539812974643788), ('log', 0.9518089931710353), ('freshtime', 0.8951318339873644), ('presence', 0.8382981866053576)]
Top words for pretrained_BERT neuron indx 7929 [('1024', 1.0), ('stanza', 0.8645232002862269), ('ignore', 0.8197008977726646), ('seek', 0.7905604306619717), ('pxe', 0.7892985031203509)]
Top words for pretrained_BERT neuron indx 9978 [('wait', 1.0), ('macType', 0.897949056620221), ('acceptEULA', 0.8909611583150605), ('refresh', 0.8633075189874616), ('alt', 0.8542466588520259)]
Top words for pretrained_BERT neuron indx 1798 [('2', 1.0), ('Post', 0.9468002661722893), ('post', 0.9232135778073516), ('ping', 0.8852700236613681), ('affinity', 0.8775280146535556)]
Top words for pretrained_BERT neuron indx 5896 [('pop', 1.0), ('count', 0.8036643120576814), ('con', 0.7600630875099157), ('On', 0.7357723320557426), ('close', 0.7296963150635933)]
Top words for pretrained_BERT neuron indx 3848 [('super', 1.0), ('type', 0.9088586908512706), ('action', 0.8453740643129131), ('exit', 0.8371429762616658), ('connection', 0.8339250189951255)]
Top words for pretrained_BERT neuron indx 7959 [('all', 1.0), ('ref', 0.9830303486941055), ('long', 0.9716981327433994), ('replace', 0.961447417162411), ('NoPerm', 0.9460288898949085)]
Top words for pretrained_BERT neuron indx 1816 [('ref', 1.0), ('clone', 0.9563071536023203), ('local', 0.8918405847780524), ('while', 0.8699472202195087), ('localize', 0.869857964373159)]
Top words for pretrained_BERT neuron indx 3866 [('models', 1.0), ('logging', 0.8626787042069743), ('m', 0.8467417622471168), ('E', 0.7948640975024847), ('try', 0.7886738462306145)]
Top words for pretrained_BERT neuron indx 7965 [('log', 1.0), ('7', 0.8458378583411341), ('""', 0.7724771704043208), ('zone', 0.7521827111821252), ('sts', 0.7142043329788279)]
Top words for pretrained_BERT neuron indx 1824 [('state', 1.0), ('class', 0.9119104499869545), ('npos', 0.8620947066855075), ('local', 0.8256822773102556), ('import', 0.7878107048772683)]
Top words for pretrained_BERT neuron indx 1828 [('task', 1.0), ('policy', 0.8670139973620952), ('k', 0.8631921648197661), ('item', 0.8140282700129513), ('start', 0.8077967173617565)]
Top words for pretrained_BERT neuron indx 1846 [('strip', 1.0), ('Billboard', 0.9562544528124897), ('slug', 0.7398691012789155), ('Distance', 0.6715460497773623), ('replace', 0.6551841553687755)]
Top words for pretrained_BERT neuron indx 7992 [('while', 1.0), ('for', 0.8651875601416068), ('Off', 0.8383133622119997), ('sans', 0.7694641793016909), ('Billboard', 0.7453082278919769)]
Top words for pretrained_BERT neuron indx 3902 [('7', 1.0), ('sts', 0.9534526259083742), ('enabled', 0.7703208688311282), ('class', 0.7599165784733499), ('32', 0.730956540080315)]
Top words for pretrained_BERT neuron indx 7999 [('is', 1.0), ('META', 0.8956667602294092), ('context', 0.849034302974299), ('VerticalBillboard', 0.8436377389397648), ('HorizontalBillboard', 0.8067474705668155)]
Top words for pretrained_BERT neuron indx 5956 [('k', 1.0), ('m', 0.9753355171656454), ('state', 0.8803370286085916), ('stanza', 0.8378557738753226), ('milliseconds', 0.8372238506764652)]
Top words for pretrained_BERT neuron indx 3911 [('link', 1.0), ('purpose', 0.9402676685460277), ('uss', 0.9322210835524775), ('800', 0.9218630569767341), ('objects', 0.9184200713299778)]
Top words for pretrained_BERT neuron indx 1875 [('local', 1.0), ('val', 0.9464324213470361), ('push', 0.9070901131340963), ('View', 0.8980158156301881), ('feature', 0.8676164815892099)]
Top words for pretrained_BERT neuron indx 1886 [('unicode', 1.0), ('all', 0.8389216668992485), ('digest', 0.7608225615357613), ('ranges', 0.7480261020577402), ('Digest', 0.6726117514656872)]
Top words for pretrained_BERT neuron indx 8038 [('exceptions', 1.0), ('authorization', 0.9922461070929498), ('Authorization', 0.9547643707923356), ('7', 0.9137927609405909), ('authentication', 0.8576515706971027)]
Top words for pretrained_BERT neuron indx 3946 [('oslo', 1.0), ('1800', 0.8748486128932433), ('800', 0.8607674979353516), ('1000', 0.7659647314033502), ('15', 0.7360926873168944)]
Top words for pretrained_BERT neuron indx 8044 [('created', 1.0), ('boot', 0.9261835583030735), ('uuid', 0.8208622815691834), ('nargs', 0.7962986743703568), ('exit', 0.7901257692964452)]
Top words for pretrained_BERT neuron indx 3949 [('set', 1.0), ('5', 0.922958425565777), ('Authorization', 0.8689745238927998), ('broadcast', 0.8408613942963378), ('to', 0.7995511576100862)]
Top words for pretrained_BERT neuron indx 8047 [('".."', 1.0), ('script', 0.9003222410830368), ('Distance', 0.8801346098657938), ('8000', 0.8795059725267256), ('authorized', 0.8598935090138814)]
Top words for pretrained_BERT neuron indx 1911 [('common', 1.0), ('strip', 0.9325262345692557), ('Unauthorized', 0.9137338595381074), ('connection', 0.906662797791906), ('root', 0.9029400263876523)]
Top words for pretrained_BERT neuron indx 1921 [('proxy', 1.0), ('seek', 0.9771405803037397), ('filters', 0.9317436611333723), ('put', 0.8012817978770085), ('send', 0.748823000432833)]
Top words for pretrained_BERT neuron indx 8066 [('20', 1.0), ('On', 0.8365603606509467), ('Off', 0.8353732931807751), ('16', 0.7552637733146549), ('mesh1', 0.7493538749162941)]
Top words for pretrained_BERT neuron indx 8076 [('sts', 1.0), ('store', 0.9112263616140547), ('stanza', 0.9004988522251871), ('os', 0.841184279741317), ('False', 0.818148484340484)]
Top words for pretrained_BERT neuron indx 8077 [('end', 1.0), ('presence', 0.9355929091807802), ('hour', 0.8587188873309488), ('action', 0.8264701712303524), ('second', 0.8207074332142125)]
Top words for pretrained_BERT neuron indx 6030 [('80', 1.0), ('fcs', 0.9518470104257614), ('probed', 0.8749242298680481), ('Board', 0.8747671200279621), ('def', 0.8052952073563495)]
Top words for pretrained_BERT neuron indx 3982 [('sorted', 1.0), ('f', 0.9857923496008385), ('super', 0.8314490791905894), ('v', 0.8112889649523074), ('E', 0.7431578435875309)]
Top words for pretrained_BERT neuron indx 8080 [('models', 1.0), ('s', 0.7957642022882759), ('m', 0.7814409843676784), ('materials', 0.7317930322419463), ('calendar', 0.7212847264282513)]
Top words for pretrained_BERT neuron indx 8081 [('main', 1.0), ('created', 0.9812532118533043), ('GET', 0.9376864152784027), ('con', 0.8996013604390609), ('baseline', 0.8959236724980917)]
Top words for pretrained_BERT neuron indx 6029 [('9', 1.0), ('authorization', 0.8516820703636991), ('pdb', 0.8329787732744441), ('Register', 0.8061644975805594), ('if', 0.8037197902221515)]
Top words for pretrained_BERT neuron indx 1937 [('log', 1.0), ('Billboard', 0.9424803990061182), ('uss', 0.8033013068997806), ('component', 0.7851713237917058), ('text', 0.781515039233273)]
Top words for pretrained_BERT neuron indx 6040 [('time', 1.0), ('path', 0.9143565153872255), ('session', 0.8646303121303964), ('YoungestInFront', 0.8527624062346213), ('1000', 0.7846313687275615)]
Top words for pretrained_BERT neuron indx 1949 [('help', 1.0), ('presence', 0.9214026287453299), ('try', 0.8985267864004494), ('stanza', 0.8360741109794183), ('ranges', 0.7913541057361957)]
Top words for pretrained_BERT neuron indx 8099 [('if', 1.0), ('except', 0.8382830014686536), ('get_profile_available_storage_systems', 0.706247711209979), ('post', 0.7054924265742181), ('with', 0.6698582950189959)]
Top words for pretrained_BERT neuron indx 1958 [('def', 1.0), ('reactor', 0.9869866742193465), ('force', 0.9288368085406562), ('14', 0.9196991473976799), ('count', 0.8688234211778783)]
Top words for pretrained_BERT neuron indx 4010 [('minutes', 1.0), ('60', 0.7012937489682493), ('force', 0.6910798240810725), ('is', 0.6769234390289002), ('script', 0.6683798759390691)]
Top words for pretrained_BERT neuron indx 8111 [('7', 1.0), ('hour', 0.9946942222573563), ('month', 0.9648618982780953), ('second', 0.9280183181457567), ('seconds', 0.9268509570902811)]
Top words for pretrained_BERT neuron indx 8114 [('exit', 1.0), ('9', 0.9008499870388579), ('probe', 0.894903615905924), ('start', 0.8628353543721978), ('purpose', 0.7551765961356038)]
Top words for pretrained_BERT neuron indx 1977 [('9', 1.0), ('month', 0.8760373902013128), ('6', 0.848841686956511), ('server', 0.8325053360234511), ('7', 0.8253637253160702)]
Top words for pretrained_BERT neuron indx 6081 [('port', 1.0), ('script', 0.9839133067993726), ('continue', 0.9746132295575168), ('all', 0.9124862036624709), ('root', 0.885140691035297)]
Top words for pretrained_BERT neuron indx 4033 [('except', 1.0), ('message', 0.8263834661714519), ('identity', 0.7152943678170874), ('tag', 0.7046131616806205), ('features', 0.696013676746276)]
Top words for pretrained_BERT neuron indx 4035 [('match', 1.0), ('component', 0.9133506584940605), ('VerticalBillboard', 0.8850715580776415), ('material', 0.8457706151081564), ('error', 0.8242219499308437)]
Top words for pretrained_BERT neuron indx 8131 [('template', 1.0), ('None', 0.8290284843164462), ('ndt', 0.8182920921449331), ('unicode', 0.816773304995129), ('NotFound', 0.7762487031898138)]
Top words for pretrained_BERT neuron indx 1987 [('render', 1.0), ('template', 0.9272376615493996), ('exceptions', 0.8956841095196044), ('mtime', 0.8677644518792824), ('contents', 0.8672035674013966)]
Top words for pretrained_BERT neuron indx 2009 [('pass', 1.0), ('300', 0.9973819842290575), ('task', 0.9054121958268675), ('models', 0.9048059749933244), ('reactor', 0.9024427615903385)]
Top words for pretrained_BERT neuron indx 8156 [('secs', 1.0), ('minutes', 0.9639066310716594), ('mins', 0.9208626731344628), ('80', 0.9026939667095008), ('upper', 0.8846028675160786)]
Top words for pretrained_BERT neuron indx 4063 [('stanza', 1.0), ('secs', 0.9199827910707046), ('1800', 0.9175847960575855), ('On', 0.7913423072657776), ('1', 0.7606663833635688)]
Top words for pretrained_BERT neuron indx 6113 [('1800', 1.0), ('stanza', 0.9043043820908675), ('try', 0.8668886796769412), ('close', 0.8515813309298335), ('View', 0.7479242374767946)]
Top words for pretrained_BERT neuron indx 6126 [('GetBoard', 1.0), ('board', 0.9594106093631687), ('Mesh', 0.9309661798093264), ('List', 0.8909658463391285), ('list', 0.8061285921464612)]
Top words for pretrained_BERT neuron indx 8174 [('count', 1.0), ('pxe', 0.943712685937869), ('zone', 0.9427324890938937), ('local', 0.9327406673560281), ('day', 0.9229106672541347)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0094
Epoch: [2/10], Loss: 0.0064
Epoch: [3/10], Loss: 0.0046
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0030
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0023
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0023
Epoch: [10/10], Loss: 0.0021
Score (accuracy) of the probe: 0.69
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0067
Epoch: [3/10], Loss: 0.0045
Epoch: [4/10], Loss: 0.0032
Epoch: [5/10], Loss: 0.0028
Epoch: [6/10], Loss: 0.0023
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0023
Epoch: [9/10], Loss: 0.0022
Epoch: [10/10], Loss: 0.0028
Score (accuracy) of the probe: 0.69
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0098
Epoch: [2/10], Loss: 0.0066
Epoch: [3/10], Loss: 0.0047
Epoch: [4/10], Loss: 0.0033
Epoch: [5/10], Loss: 0.0031
Epoch: [6/10], Loss: 0.0030
Epoch: [7/10], Loss: 0.0028
Epoch: [8/10], Loss: 0.0029
Epoch: [9/10], Loss: 0.0028
Epoch: [10/10], Loss: 0.0023
Score (accuracy) of the probe: 0.68
Training classification probe
Creating model...
Number of training instances: 4349
Number of classes: 4
Epoch: [1/10], Loss: 0.0105
Epoch: [2/10], Loss: 0.0080
Epoch: [3/10], Loss: 0.0059
Epoch: [4/10], Loss: 0.0047
Epoch: [5/10], Loss: 0.0045
Epoch: [6/10], Loss: 0.0042
Epoch: [7/10], Loss: 0.0042
Epoch: [8/10], Loss: 0.0043
Epoch: [9/10], Loss: 0.0043
Epoch: [10/10], Loss: 0.0041
Score (accuracy) of the probe: 0.67

The best l1=0, the best l2=0 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.28
{'__OVERALL__': 0.2829827915869981, 'NAME': 0.1752808988764045, 'STRING': 0.21203438395415472, 'NUMBER': 0.34536082474226804, 'KEYWORD': 0.4082687338501292}
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.25

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.592734225621415
----------------------------------------------------------------
