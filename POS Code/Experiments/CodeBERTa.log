Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_CodeBERTa
Loading json activations from ./activations/codeberta_activations_train.json...
54291 7.0
Skipping line:  2668
A: 2, S: 3, T: 3
Deleting line 2668: 2 activations, 3 source, 3 target
Number of tokens:  507518
length of source dictionary:  28818
length of target dictionary:  49
507518
Total instances: 507518
["'e_tag'", 'rzz', 'table', 'onset_front', 'cint', '"div.user-info"', 'get_imap_capabilities', "'str'", 'sgn_prod', "'+refs/heads/*:refs/heads/*'", 'writeToken', "'--speed'", 'instruction_layer', 'nrows', '"lib"', 'logging', 'SelectionInvert', 'labelbottom', 'get_activity_members', '21']
Number of samples:  507518
Stats: Labels with their frequencies in the final set
NAME 175779
KEYWORD 38836
LPAR 37541
RPAR 36846
DOT 35570
COMMA 33435
EQUAL 30541
COLON 19840
STRING 17115
DEDENT 16600
LSQB 14740
RSQB 14613
INDENT 11963
NUMBER 10471
PLUS 1939
EQEQUAL 1830
STAR 1500
MINUS 1458
LBRACE 1070
RBRACE 845
DOUBLESTAR 844
SLASH 630
PERCENT 577
PLUSEQUAL 501
GREATER 456
NOTEQUAL 429
LESS 332
RARROW 330
GREATEREQUAL 175
LESSEQUAL 133
AMPER 94
DOUBLESLASH 94
MINEQUAL 58
ELLIPSIS 55
COMMENT 37
VBAR 35
AT 29
STAREQUAL 27
RIGHTSHIFT 25
LEFTSHIFT 25
SLASHEQUAL 24
VBAREQUAL 23
TILDE 23
CIRCUMFLEX 22
AMPEREQUAL 2
DOUBLESLASHEQUAL 2
RIGHTSHIFTEQUAL 2
ENCODING 1
DOUBLESTAREQUAL 1
pretrained_CodeBERTa distribution after trauncating:
{0: 0.7257567062068282, 3: 0.16034615876895636, 1: 0.07066444812366587, 2: 0.043232686900549544}
{0: 175779, 3: 38836, 1: 17115, 2: 10471}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codeberta_activations_valid.json...
33619 7.0
Number of tokens:  308882
length of source dictionary:  19446
length of target dictionary:  46
308882
Total instances: 308882
['"setWeekendHolidaySchedules"', "'0x0'", 'eio', 'StringValue', "'multiproc_'", 'result_value', 'table', 'raise_exception', 'ints', "'%sbasedOn'", 'inner_iterator_list', "'qvalue'", 'set_facecolor', '*=', '__fn_recur_to_py_ast', 'f_get_explored_parameters', 'exc_tb', 'show_data_values', '_build_model', 'arity_name']
Number of samples:  308882
Stats: Labels with their frequencies in the final set
NAME 106508
DOT 23234
KEYWORD 22857
LPAR 22119
RPAR 21487
COMMA 21037
EQUAL 18195
STRING 12883
COLON 12504
DEDENT 10176
LSQB 8421
RSQB 8348
INDENT 7080
NUMBER 5227
EQEQUAL 1207
PLUS 1136
LBRACE 1077
STAR 963
RBRACE 913
MINUS 741
DOUBLESTAR 555
SLASH 393
PLUSEQUAL 323
GREATER 292
NOTEQUAL 240
PERCENT 222
RARROW 214
LESS 200
GREATEREQUAL 82
LESSEQUAL 47
AT 33
AMPER 29
DOUBLESLASH 27
MINEQUAL 27
VBAR 23
COMMENT 13
ELLIPSIS 13
STAREQUAL 10
LEFTSHIFT 7
TILDE 7
RIGHTSHIFT 4
SLASHEQUAL 3
CIRCUMFLEX 2
ENCODING 1
DOUBLESLASHEQUAL 1
AMPEREQUAL 1
pretrained_CodeBERTa distribution after trauncating:
{0: 0.7222105441600272, 3: 0.1549889811832514, 1: 0.08735717918291236, 2: 0.035443295473809124}
{0: 106508, 3: 22857, 1: 12883, 2: 5227}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codeberta_activations_test.json...
32570 7.0
Number of tokens:  302448
length of source dictionary:  18380
length of target dictionary:  49
302448
Total instances: 302448
["'nupic.hypersearch.minParticlesPerSwarm'", 'ReplaceAll', 'table', 'sio', '"ORPHANED"', 'summarizer_init_op', 'parsimony', 'middle', '*=', '"partitionIn"', '0x03c0003f', 'exc_tb', '_mmResetActive', 'estimateAnomalyLikelihoods', 'path_regex', '"master/scripts/generic/multi-bleu.perl"', 'logbolt', 'geom', 'n', 'createFeedForwardLink']
Number of samples:  302448
Stats: Labels with their frequencies in the final set
NAME 106943
DOT 23125
LPAR 23019
RPAR 22645
KEYWORD 21773
COMMA 19472
EQUAL 18096
COLON 11225
DEDENT 9778
STRING 8156
LSQB 7717
RSQB 7682
NUMBER 7295
INDENT 6823
EQEQUAL 1344
MINUS 1259
PLUS 1013
STAR 863
LBRACE 527
PLUSEQUAL 448
RBRACE 436
GREATER 417
PERCENT 341
NOTEQUAL 341
SLASH 323
DOUBLESTAR 284
LESS 247
GREATEREQUAL 216
LESSEQUAL 107
AMPER 100
RIGHTSHIFT 61
LEFTSHIFT 53
MINEQUAL 48
DOUBLESLASH 48
RARROW 41
VBAR 38
ELLIPSIS 28
COMMENT 19
AT 17
CIRCUMFLEX 17
STAREQUAL 15
SLASHEQUAL 15
VBAREQUAL 12
TILDE 7
SEMI 6
PERCENTEQUAL 5
ENCODING 1
DOUBLESTAREQUAL 1
AMPEREQUAL 1
pretrained_CodeBERTa distribution after trauncating:
{0: 0.7417994409261481, 3: 0.1510262404017563, 1: 0.05657327959935353, 2: 0.05060103907274203}
{0: 106943, 3: 21773, 1: 8156, 2: 7295}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Write tokens in the training set to files:
Write tokens in the validation set to files:
Write tokens in the testing set to files:

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 5001, 3: 5001, 1: 5001, 2: 5001})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in valid:
Counter({3: 540, 0: 540, 1: 540, 2: 540})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({0: 670, 1: 670, 3: 670, 2: 670})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
All-layer probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Independent-layerwise probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Incremental-layerwise probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
select minimum layers
Correlation matrix size (#neurons x #neurons): (1536, 1536)
Number of clusters detected: 774
Correlation matrix size (#neurons x #neurons): (4608, 4608)
Number of clusters detected: 1834
Correlation matrix size (#neurons x #neurons): (4608, 4608)
Number of clusters detected: 1834
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers (run_cc_all.py)
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 4874
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 3314
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 2352
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 1740
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 1281
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 892
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 521
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 192
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 4
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers with finer percentage (run_max_features.py)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

pretrained_CodeBERTa top neurons
array([   2,   16,   26,   37, 4135, 2087,   41, 4144,   49,   55,   59,
         63, 2113,   67, 4166,   84, 4184, 2140,   98, 4196, 2150, 2166,
        118, 4227,  132, 2184, 2190, 4239, 4240, 4269, 2230, 2234, 4283,
        189,  191, 2241,  197, 4296, 4304,  213, 4311,  218, 2274,  240,
        265, 4370,  277, 2328, 4377,  283, 4393, 2348,  308,  319, 4415,
        324,  328, 4431, 2386, 2394, 4462, 4468,  372, 4470, 2426, 2429,
       2433,  392, 2444, 4493, 2465,  422,  424,  430, 2479, 2482, 2486,
       4535,  439, 2502, 2508, 2514, 4572, 4587, 4594, 2549,  508, 2556,
       4615, 4618,  543, 2592,  553, 2621,  596,  606, 4707,  614, 2667,
        635, 4738, 4741,  658,  661, 2718, 4767, 2724, 4774,  701, 2768,
       2772, 4821,  734, 4836, 2791, 2798, 2806, 4858, 2812, 4862, 2824,
        778, 4879,  784, 2834, 2846, 2847,  805,  816,  817,  823, 2877,
       4926,  833,  838, 2899,  857, 4954, 4955,  860,  861,  863, 2926,
       2934, 2938,  897,  909, 5007,  911,  927,  933,  936,  957, 5056,
       3008, 5060, 5075, 3029, 3033, 3034, 3042, 3051, 3052, 1008, 3058,
       1011, 1016, 1019, 3070, 3071, 5128, 3082, 3083, 5134, 5138, 3091,
       1046, 3094, 1050, 5149, 5161, 3116, 3121, 3136, 1092, 1098, 5199,
       1109, 1112, 3164, 5225, 3179, 1146, 5244, 3197, 1150, 3201, 5252,
       3206, 3207, 5256, 1174, 3224, 3230, 3235, 5290, 5293, 1200, 5323,
       3276, 1228, 5328, 3282, 5333, 3288, 3291, 5341, 5352, 5355, 3317,
       1271, 3319, 1277, 1292, 3348, 1300, 3352, 3388, 3398, 3414, 1382,
       3434, 1398, 3447, 1400, 3453, 3459, 3471, 3486, 1444, 3492, 1446,
       1472, 3521, 1484, 3536, 3538, 3577, 1538, 3601, 3619, 3620, 3622,
       1580, 1588, 1597, 3647, 3660, 1615, 1626, 3684, 3687, 1643, 3694,
       3702, 3709, 3720, 3725, 1681, 1693, 3746, 1725, 1746, 3801, 3803,
       1758, 3810, 3819, 1781, 1788, 3839, 3850, 3862, 1829, 1843, 3915,
       3920, 3921, 1897, 1912, 3961, 1914, 3966, 3969, 3975, 3985, 3993,
       3999, 1963, 4016, 4022, 4024, 4029, 2000, 4053, 4062, 2029, 2030,
       4089])
pretrained_CodeBERTa top neurons per class
{'NAME': array([4166, 3536, 4304, 3702, 4836, 2934, 2899, 4493, 1046, 2768, 5355,
       5007,  543, 3051,  189,  240, 3459, 4862,  422, 3179, 1008,  132,
        319, 3206, 1050, 1538, 3121, 1626, 4587,  213, 5293,  778, 4470,
       5138,   98, 3915,  553, 2029, 5328,  191, 1150, 4269, 4053,  197,
       3348, 3620, 3447, 3684, 1092, 5341, 2806, 1615, 2150, 3538, 3471,
       3282, 2386, 2834,  218,  596, 2502, 3136, 3352, 3985,   84,  324,
       5256, 3921,  784, 5149, 2234, 1829, 2549, 2847,    2, 2426]), 'STRING': array([1271, 2934, 4227, 1681, 3720, 3801, 2394, 3033, 1597, 1444, 4144,
       2184,   26, 2000,  817, 3486, 3058, 3694, 1146, 4283, 2718, 1472,
       3201, 3746, 2465, 4269,  265,  860, 5199, 5244, 3052, 3116, 3042,
       2508,  863, 1914, 2348, 5060, 3725, 3660, 1781, 1484, 1588, 3459,
        933, 1398, 2824, 4022, 3398, 4462, 1019, 1580, 1174, 3276,  213,
       3317, 4377, 4858, 3224,  308, 2482, 4304,   16, 4594,   63,  734,
       5075, 2812, 2113, 3091, 2166, 3070,  635, 2926, 1643, 4240, 3810,
       2486, 4296, 4836, 3850, 5256, 4774, 3082, 1016]), 'NUMBER': array([4196, 2621, 1746, 3999, 2877,  911, 1200,  833, 2846, 4135, 2433,
       3388, 2274,  897, 1011, 1788, 2667, 4926, 2772,  838, 3034, 4024,
       2140, 4016, 1112, 5225, 2556, 1109, 3521, 5128,   41, 1693, 3687,
       1400,   37, 3164,   49, 4431, 3291, 3492, 3803, 3577, 1300, 4767,
       4468, 1758, 2087,  909, 3434, 3969, 3230, 1446, 2592, 3029, 3619,
       4572, 3966, 3453, 4535,   59,  927,  553,  277, 2230,  430, 2514,
       4615, 2241, 5134, 4062,  701, 3601, 3319, 3709,  936, 2444, 4738,
       3961, 2724, 1963, 4184,   67, 1277,  805]), 'KEYWORD': array([3051, 4393,   55, 1046, 5056,  328, 2798, 4587, 3819,  439,  372,
       2479, 3647, 3839, 4239, 2429, 4415, 3702,  823,  816, 2190, 4370,
       4954, 4879, 2030, 1228, 3288, 3993, 3083,  701,  189,  118, 3414,
        614, 3862, 3008, 1912, 3975, 4741, 3071, 3235, 1843,  392,  857,
       4707, 4955, 1897, 3094, 5290, 2029, 3197,  658, 1382,  508, 4618,
       1098,  957, 2328, 1292, 4089, 3136, 5323, 5252,  424, 5352, 3622,
        606, 5333, 4821, 3207, 1725, 4311, 4470,  861, 3920, 2791, 4029,
       2938, 5161,  661,  283])}
pretrained_CodeBERTa top words
Top words for pretrained_CodeBERTa neuron indx 2 [('PIPE', 4.401115894317627), ('system', 3.8212156295776367), ('close', 3.3088057041168213), ('port', 3.2905839681625366), ('StopIteration', 3.2011172771453857)]
Top words for pretrained_CodeBERTa neuron indx 16 [('clone', 4.410459041595459), ('Tensor', 4.268242994944255), ('tmp', 4.262454509735107), ('country', 4.085016250610352), ('enumerate', 3.727174997329712)]
Top words for pretrained_CodeBERTa neuron indx 26 [('os', 3.236628746164256), ('height', 3.202042969790372), ('width', 3.1485843658447266), ('"\\\\\\\\ctrl{"', 2.907837688922882), ('gamma', 2.8473148345947266)]
Top words for pretrained_CodeBERTa neuron indx 37 [('"\\\\\\\\"', 3.3960978984832764), ('urljoin', 3.3429226875305176), ('transpose', 3.2379957834879556), ('"-"', 3.0958447456359863), ('nn', 2.9978301525115967)]
Top words for pretrained_CodeBERTa neuron indx 4135 [('parseString', 3.138096332550049), ('Contrast', 3.1000335216522217), ('Dense', 3.036556577682495), ('softmax', 3.016650438308716), ('XML', 2.941676616668701)]
Top words for pretrained_CodeBERTa neuron indx 2087 [('Color', 3.1662819385528564), ('to', 2.9391329288482666), ('builtins', 2.7829664945602417), ('asarray', 2.52346932888031), ('Multiply', 2.4939117431640625)]
Top words for pretrained_CodeBERTa neuron indx 41 [('elif', 4.081111650209169), ('range', 3.4184238343011764), ('keywords', 3.3705129623413086), ('engine', 3.015568256378174), ("'module.'", 2.7470571994781494)]
Top words for pretrained_CodeBERTa neuron indx 4144 [('shortcuts', 3.708179473876953), ('theme', 3.184840440750122), ('type', 3.015491485595703), ('copy', 2.8712884813547133), ('inplace', 2.8202598690986633)]
Top words for pretrained_CodeBERTa neuron indx 49 [('param', 3.353165547053019), ('stdout', 3.305600166320801), ('byte', 3.2942006587982178), ('nn', 3.095693588256836), ('final', 2.9307631651560464)]
Top words for pretrained_CodeBERTa neuron indx 55 [('item', 3.1659778356552124), ('answers', 3.0915776093800864), ('terminated', 3.0436184406280518), ('"phi_polar"', 3.0421323776245117), ('barrier', 3.0044188499450684)]
Top words for pretrained_CodeBERTa neuron indx 59 [('Popen', 3.3256947994232178), ('fid', 3.1799789667129517), ('match', 3.1048048459566555), ('result', 3.062232275803884), ('Optional', 3.042846202850342)]
Top words for pretrained_CodeBERTa neuron indx 63 [('seek', 4.09902286529541), ('numpy', 3.5476393699645996), ('pow', 3.3509418964385986), ('over', 3.1991031169891357), ('Timeout', 2.997507333755493)]
Top words for pretrained_CodeBERTa neuron indx 2113 [('remove', 3.2929810285568237), ("'#'", 3.2661067247390747), ('"/"', 3.250472068786621), ('flush', 3.1091452836990356), ('flatten', 2.966581344604492)]
Top words for pretrained_CodeBERTa neuron indx 67 [('"="', 4.568277563367571), ('total', 4.076964616775513), ('StopIteration', 3.875469923019409), ('f', 3.708461446421487), ('eq', 3.539276599884033)]
Top words for pretrained_CodeBERTa neuron indx 4166 [('alexnet', 2.8212978839874268), ('merge', 2.7153828795467105), ('googlenet', 2.610335350036621), ('to', 2.55755877494812), ('update', 2.535517454147339)]
Top words for pretrained_CodeBERTa neuron indx 84 [('tarfile', 3.6824634075164795), ('oh', 3.429887294769287), ('ele', 3.3682849407196045), ('skill', 3.2938588857650757), ('stack', 3.2597947120666504)]
Top words for pretrained_CodeBERTa neuron indx 4184 [('channels', 2.9762580394744873), ('add', 2.793643593788147), ('PERSPECTIVE', 2.73307204246521), ('o', 2.6408026899610246), ('scandir', 2.570625066757202)]
Top words for pretrained_CodeBERTa neuron indx 2140 [('kernel_size', 3.344219207763672), ('zip', 3.154950181643168), ('format', 3.1138940477371215), ('set', 3.017278861999512), ('println', 3.012836456298828)]
Top words for pretrained_CodeBERTa neuron indx 98 [('splits', 3.581507682800293), ('borders', 3.048184633255005), ('softmax', 3.0103511810302734), ('stream', 2.967285054070609), ('unpack', 2.867555618286133)]
Top words for pretrained_CodeBERTa neuron indx 4196 [('parseString', 3.149062156677246), ('append', 3.012159394054878), ('"(.*):(.*),(.*),(.*)"', 2.9660747051239014), ('rotate', 2.8284133672714233), ('squeeze', 2.762498378753662)]
Top words for pretrained_CodeBERTa neuron indx 2150 [('timedelta', 3.57706880569458), ('tuple', 3.390758991241455), ('unicode', 3.2522988319396973), ('resize', 3.1236621141433716), ('sum', 3.094634246826172)]
Top words for pretrained_CodeBERTa neuron indx 2166 [('palette', 3.783762772878011), ('symbols', 3.4464031457901), ('activation', 3.364245851834615), ('pic', 3.3600023792849645), ('pretrained', 3.1262435913085938)]
Top words for pretrained_CodeBERTa neuron indx 118 [('120', 3.9715378284454346), ('open', 3.912604808807373), ('splits', 3.612638473510742), ("'--'", 3.5882202982902527), ('except', 3.4542363743449367)]
Top words for pretrained_CodeBERTa neuron indx 4227 [('22', 4.263075351715088), ('Number', 4.0100429852803545), ('numbers', 3.553322156270345), ('item', 3.1418946385383606), ('tzinfo', 3.1268547773361206)]
Top words for pretrained_CodeBERTa neuron indx 132 [('permute', 4.379443168640137), ('bias', 3.7507143020629883), ('line', 3.4924774964650473), ('name', 3.462391035897391), ('patterns', 3.412783908843994)]
Top words for pretrained_CodeBERTa neuron indx 2184 [('item', 3.7794400453567505), ('answer', 3.2870566844940186), ('inplace', 3.119551658630371), ('palette', 3.084334929784139), ('contiguous', 2.9294607639312744)]
Top words for pretrained_CodeBERTa neuron indx 2190 [('zipfile', 4.915853977203369), ('stride', 3.7328821818033853), ('index', 3.5343655177525113), ('sourceType', 3.5153619050979614), ('bias', 3.504631996154785)]
Top words for pretrained_CodeBERTa neuron indx 4239 [('tile', 3.5355708599090576), ('Color', 3.4620447158813477), ('interpolation', 3.4037062440599715), ('mul', 3.342499017715454), ('colors', 3.2673192620277405)]
Top words for pretrained_CodeBERTa neuron indx 4240 [('ioctl', 3.3552608489990234), ('dictified', 3.1001514345407486), ('skill', 3.063462018966675), ('RED', 2.9418556690216064), ('add', 2.8014286756515503)]
Top words for pretrained_CodeBERTa neuron indx 4269 [('URLError', 4.131356716156006), ("'|'", 3.4512959718704224), ('splits', 3.1602132320404053), ('scandir', 2.9963488578796387), ('202', 2.97066867351532)]
Top words for pretrained_CodeBERTa neuron indx 2230 [('RED', 3.8364579677581787), ('oh', 3.774144411087036), ('debug', 3.534531593322754), ('line', 3.4162349700927734), ('find', 3.413274049758911)]
Top words for pretrained_CodeBERTa neuron indx 2234 [('console', 3.5483243465423584), ('matches', 3.350449800491333), ('XML', 3.3191351890563965), ('git', 3.101653575897217), ('total', 3.0116716623306274)]
Top words for pretrained_CodeBERTa neuron indx 4283 [('perspective', 3.234792709350586), ('tuple', 3.1207016706466675), ('decoded', 2.867791533470154), ('"batches_seen"', 2.643249273300171), ('Iterable', 2.6208741664886475)]
Top words for pretrained_CodeBERTa neuron indx 189 [('patch', 3.5629738569259644), ('class', 3.3633241653442383), ('")"', 3.23060405254364), ('"|"', 3.2260923385620117), ('zip', 3.186591466267904)]
Top words for pretrained_CodeBERTa neuron indx 191 [('dim', 4.335230350494385), ('transpose', 3.9738778670628867), ('streams', 3.1978670954704285), ('d', 3.142863330386934), ('exceptions', 3.124753713607788)]
Top words for pretrained_CodeBERTa neuron indx 2241 [('label', 3.1843767166137695), ('gui', 3.053957939147949), ('grid', 3.053052282333374), ('200', 3.0403135865926743), ('fallback', 2.9009077548980713)]
Top words for pretrained_CodeBERTa neuron indx 197 [('seq', 3.7556817531585693), ('urljoin', 3.389343023300171), ('Number', 3.0950609842936196), ('urlencode', 3.071967363357544), ('extend', 3.0600271224975586)]
Top words for pretrained_CodeBERTa neuron indx 4296 [('120000', 3.341602325439453), ("'server'", 3.0427279472351074), ("'base_url'", 2.8785901069641113), ('error', 2.8172402381896973), ('raise', 2.755637370623075)]
Top words for pretrained_CodeBERTa neuron indx 4304 [('all', 3.161219596862793), ('autocompleter', 2.577259063720703), ("'severity'", 2.4936423301696777), ("'locales'", 2.475048542022705), ('logger', 2.4685637950897217)]
Top words for pretrained_CodeBERTa neuron indx 213 [("'%'", 3.303419589996338), ('">"', 3.1048336029052734), ('brightness', 3.091249644756317), ('flush', 2.8148573637008667), ('hue', 2.7940805554389954)]
Top words for pretrained_CodeBERTa neuron indx 4311 [('ByteStorage', 2.780256748199463), ('country', 2.759422540664673), ('total', 2.735859990119934), ('mean', 2.721831351518631), ('timestamp', 2.673160672187805)]
Top words for pretrained_CodeBERTa neuron indx 218 [('extend', 3.591233015060425), ('pattern', 3.5387573719024656), ('transpose', 3.4054195880889893), ('upper', 3.396723747253418), ("'{'", 3.3820126056671143)]
Top words for pretrained_CodeBERTa neuron indx 2274 [('scandir', 3.628131628036499), ('cost', 3.518697500228882), ('dirpath', 3.5023515224456787), ('"}"', 3.4579641421635947), ('";"', 3.288418471813202)]
Top words for pretrained_CodeBERTa neuron indx 240 [('gain', 3.1863993406295776), ('Exception', 3.0514214038848877), ('scandir', 2.973910331726074), ('error', 2.869393825531006), ('Color', 2.868028402328491)]
Top words for pretrained_CodeBERTa neuron indx 265 [('answer', 3.223423719406128), ('encode', 3.1485493977864585), ("')'", 2.7127695083618164), ('gui', 2.6861395835876465), ('answerers', 2.641049385070801)]
Top words for pretrained_CodeBERTa neuron indx 4370 [('flush', 2.693814992904663), ('PIPE', 2.587045669555664), ('ValidationException', 2.5097827911376953), ('np', 2.4751273561746645), ('close', 2.323956251144409)]
Top words for pretrained_CodeBERTa neuron indx 277 [('history', 3.8312418460845947), ('find', 3.129931926727295), ('unlink', 2.9952633380889893), ('hasattr', 2.956238269805908), ('tag', 2.944326639175415)]
Top words for pretrained_CodeBERTa neuron indx 2328 [('to', 3.364562511444092), ('palette', 3.1711815198262534), ('StringIO', 3.0644845962524414), ('isdir', 3.0039583444595337), ('path', 2.907662944360213)]
Top words for pretrained_CodeBERTa neuron indx 4377 [('Compose', 2.7258388996124268), ('locales', 2.5205023288726807), ('exceptions', 2.498429775238037), ('sprint', 2.355156421661377), ('enhance', 2.3190082708994546)]
Top words for pretrained_CodeBERTa neuron indx 283 [('bias', 3.3463289737701416), ('interpolation', 3.064746856689453), ('111', 2.9738547801971436), ('"="', 2.905972855431693), ("'--'", 2.8744490444660187)]
Top words for pretrained_CodeBERTa neuron indx 4393 [('urljoin', 3.6709225177764893), ('np', 3.5044912222104196), ('to', 2.9696462154388428), ('RESET', 2.910773277282715), ('Number', 2.803933540980021)]
Top words for pretrained_CodeBERTa neuron indx 2348 [('sprint', 3.3304026126861572), ('affine', 3.195270538330078), ("'video'", 2.8337327241897583), ('">"', 2.769029140472412), ("'$y$'", 2.7377946376800537)]
Top words for pretrained_CodeBERTa neuron indx 308 [('shuffle', 4.146720886230469), ('111', 3.454898238182068), ('contiguous', 3.4256272315979004), ('inplace', 3.313342809677124), ('22', 3.158082604408264)]
Top words for pretrained_CodeBERTa neuron indx 319 [('seek', 4.281879901885986), ('find', 4.134829044342041), ('scandir', 3.9948740005493164), ('decode', 3.847453737258911), ('expanded', 3.5287440617879233)]
Top words for pretrained_CodeBERTa neuron indx 4415 [('color', 2.70499050617218), ('Optional', 2.6489830017089844), ('path', 2.4665712734515015), ('dictified', 2.3801378458738327), ('angle', 2.3308297991752625)]
Top words for pretrained_CodeBERTa neuron indx 324 [('Timeout', 3.6227595806121826), ('gui', 2.9271011352539062), ('splits', 2.900810956954956), ('s', 2.8818538870130266), ('shears', 2.797704041004181)]
Top words for pretrained_CodeBERTa neuron indx 328 [('getattr', 4.8890617688496905), ('stack', 3.7825839519500732), ('convert', 3.3328248977661135), ('query', 3.2709126364101064), ('format', 3.2252847290039064)]
Top words for pretrained_CodeBERTa neuron indx 4431 [('dim', 3.5086867809295654), ('merge', 3.263690859930856), ('copy', 2.991016125679016), ('datetime', 2.816831946372986), ('PIL', 2.809450387954712)]
Top words for pretrained_CodeBERTa neuron indx 2386 [('len', 3.216735769401897), ('squeeze', 3.138744831085205), ('default', 2.9749088287353516), ('request', 2.8429571390151978), ('ValueError', 2.829490900039673)]
Top words for pretrained_CodeBERTa neuron indx 2394 [('debug', 3.7039129734039307), ('any', 3.5334739685058594), ('extend', 3.3915224075317383), ('barrier', 3.2719125747680664), ('opt', 3.249883472919464)]
Top words for pretrained_CodeBERTa neuron indx 4462 [('Lambda', 3.544951868057251), ('upper', 3.47468900680542), ('copy_', 3.4646565914154053), ('copy', 3.202580976486206), ('system', 2.8727424144744873)]
Top words for pretrained_CodeBERTa neuron indx 4468 [('items', 3.056387186050415), ('getElementsByTagName', 2.7081114053726196), ('io', 2.5390872955322266), ('patches', 2.5152352253595986), ('div', 2.4644060134887695)]
Top words for pretrained_CodeBERTa neuron indx 372 [('site', 3.707456350326538), ('dirpath', 3.5351979732513428), ('categories', 3.2933410167694093), ('default', 3.1389613151550293), ('XML', 2.884788990020752)]
Top words for pretrained_CodeBERTa neuron indx 4470 [('channels', 4.503146171569824), ('Image', 3.887785701190724), ('pic', 3.8121818012661404), ('palette', 3.3169135252634683), ('tl', 3.2569262981414795)]
Top words for pretrained_CodeBERTa neuron indx 2426 [('finally', 3.924680709838867), ('stack', 3.3129358291625977), ('param', 3.287942806879679), ('unlink', 3.0321974754333496), ('moves', 3.0306577682495117)]
Top words for pretrained_CodeBERTa neuron indx 2429 [('xpath', 4.095275354385376), ('getattr', 3.894293785095215), ('NotImplementedError', 3.7093915939331055), ('Multiply', 3.3850975036621094), ('hasattr', 3.3849620819091797)]
Top words for pretrained_CodeBERTa neuron indx 2433 [('stdin', 4.61296010017395), ('basename', 4.336603164672852), ('shuffle', 4.280153751373291), ('join', 4.096751689910889), ('argv', 3.836829423904419)]
Top words for pretrained_CodeBERTa neuron indx 392 [('border', 3.2632856369018555), ('row', 2.980215072631836), ('outfile', 2.946453332901001), ('uniform', 2.9337582804939966), ('loads', 2.9325236678123474)]
Top words for pretrained_CodeBERTa neuron indx 2444 [('float', 3.0196151563099454), ('and', 2.6850947152484546), ('opt', 2.6845505833625793), ('force', 2.6334211826324463), ('tzinfo', 2.5301331281661987)]
Top words for pretrained_CodeBERTa neuron indx 4493 [('tzinfo', 3.372127890586853), ("'%'", 2.991410255432129), ('"-"', 2.5747976303100586), ('scandir', 2.4854423999786377), ('"."', 2.4368457794189453)]
Top words for pretrained_CodeBERTa neuron indx 2465 [('patch', 2.6914366483688354), ('VimeoExtractor', 2.4661338329315186), ('struct', 2.420874834060669), ("'=='", 2.324660897254944), ('fcntl', 2.2642719745635986)]
Top words for pretrained_CodeBERTa neuron indx 422 [('numpy', 4.106611013412476), ('zip', 3.377548257509867), ('sum', 3.084887456893921), ('")"', 3.064307689666748), ('"-"', 2.9074602127075195)]
Top words for pretrained_CodeBERTa neuron indx 424 [('"$"', 3.2357609272003174), ('"|"', 3.2350640296936035), ('decoded', 3.102817177772522), ("'\\\\''", 2.975947380065918), ('map', 2.761162042617798)]
Top words for pretrained_CodeBERTa neuron indx 430 [('PIPE', 3.4037415981292725), ('mul', 2.81001877784729), ('error', 2.672752618789673), ('list', 2.658264458179474), ('response_rss', 2.5954079627990723)]
Top words for pretrained_CodeBERTa neuron indx 2479 [('max', 3.531330555677414), ('Response', 3.48917760848999), ('info', 3.2073700726032257), ('req', 3.08451053074428), ('range', 2.9642087732042586)]
Top words for pretrained_CodeBERTa neuron indx 2482 [('"/"', 3.5204224586486816), ('print', 3.442491818558086), ('sleep', 3.3910703659057617), ('":"', 3.2747490406036377), ('system', 3.1862895488739014)]
Top words for pretrained_CodeBERTa neuron indx 2486 [('numpy', 3.2077085971832275), ('ndarr', 2.689417243003845), ('array', 2.65603369474411), ('PIL2array', 2.612364888191223), ('keywords', 2.4757251739501953)]
Top words for pretrained_CodeBERTa neuron indx 4535 [('"="', 3.0703276566096713), ('stdout', 2.9658169746398926), ('six', 2.9172301292419434), ('method', 2.683986470103264), ('io', 2.562181234359741)]
Top words for pretrained_CodeBERTa neuron indx 439 [('asarray', 3.3563358783721924), ('ndim', 2.940695842107137), ('theme', 2.9272704124450684), ('bytes', 2.812446117401123), ("'\\\\\\\\'", 2.8115183115005493)]
Top words for pretrained_CodeBERTa neuron indx 2502 [('expanded', 4.890653769175212), ('ele', 3.8378266096115112), ('zeros', 3.489708423614502), ('permute', 3.4121830463409424), ('reshape', 3.410407304763794)]
Top words for pretrained_CodeBERTa neuron indx 2508 [('exp', 2.520235776901245), ("'metadata.json'", 2.244929075241089), ('".stpd"', 2.244485378265381), ("'{}.local.'", 2.2149312496185303), ("'.{}'", 2.196930170059204)]
Top words for pretrained_CodeBERTa neuron indx 2514 [('io', 3.9041481018066406), ('keepdims', 3.8225619792938232), ('childNodes', 3.5019402503967285), ('"="', 3.384624787739345), ('suggestions', 2.9408458868662515)]
Top words for pretrained_CodeBERTa neuron indx 4572 [('minutes', 3.3234474658966064), ('numpy', 3.2860900163650513), ('tar', 2.994364380836487), ('palette', 2.973436196645101), ('byte', 2.943911075592041)]
Top words for pretrained_CodeBERTa neuron indx 4587 [('datetime', 2.7180016040802), ('units', 2.6731887459754944), ('redirect', 2.5202083587646484), ('moves', 2.514918088912964), ('PY3', 2.491534471511841)]
Top words for pretrained_CodeBERTa neuron indx 4594 [('kwargs', 2.9735598462693233), ('legitimize', 2.901029586791992), ('opts', 2.7579766114552817), ('borders', 2.705716133117676), ('response', 2.699200302362442)]
Top words for pretrained_CodeBERTa neuron indx 2549 [('softmax', 3.2481963634490967), ('Reshape', 2.9419217109680176), ('rmtree', 2.8568613529205322), ('Session', 2.850851535797119), ('flush', 2.795181632041931)]
Top words for pretrained_CodeBERTa neuron indx 508 [('part', 4.097787857055664), ('axis', 3.7041515111923218), ('fallback', 3.2891433238983154), ('self', 3.2574737223787844), ('scale', 3.236696754183088)]
Top words for pretrained_CodeBERTa neuron indx 2556 [('StopIteration', 4.253840446472168), ('gui', 3.8692846298217773), ('ValidationException', 3.6822824478149414), ('exceptions', 3.3382396697998047), ('urljoin', 3.2898061275482178)]
Top words for pretrained_CodeBERTa neuron indx 4615 [('Iterable', 2.8836042881011963), ('PY3', 2.858397960662842), ('units', 2.8520137667655945), ('Tensor', 2.838988463083903), ('find', 2.7902824878692627)]
Top words for pretrained_CodeBERTa neuron indx 4618 [('words', 3.004899501800537), ('gui', 2.758882761001587), ('days', 2.61210298538208), ("'--'", 2.536492168903351), ('hasattr', 2.4665606021881104)]
Top words for pretrained_CodeBERTa neuron indx 543 [('isinstance', 3.101217528184255), ('device', 2.873645210266113), ('dist', 2.872959613800049), ('tile', 2.686995506286621), ('format', 2.6648114204406737)]
Top words for pretrained_CodeBERTa neuron indx 2592 [('channels', 3.7731664180755615), ('mul', 3.696949005126953), ('decoded', 3.347883462905884), ('prepare', 2.8485898971557617), ('symbols', 2.8350865840911865)]
Top words for pretrained_CodeBERTa neuron indx 553 [('activation', 3.7832531134287515), ('")"', 3.613520622253418), ('pretrained', 3.1436976492404938), ('shear', 2.9244387626647947), ('suffix', 2.8642771244049072)]
Top words for pretrained_CodeBERTa neuron indx 2621 [('numpy', 3.0272436141967773), ('numbers', 2.790644725163778), ("'register'", 2.5456600189208984), ("'filesystem'", 2.5334439277648926), ('barrier', 2.5333869457244873)]
Top words for pretrained_CodeBERTa neuron indx 596 [('p', 2.9723521981920515), ('isinstance', 2.943793296813965), ('quote', 2.7899982929229736), ('minutes', 2.7132225036621094), ('"}"', 2.5790834426879883)]
Top words for pretrained_CodeBERTa neuron indx 606 [('fh', 3.368621587753296), ("'://'", 3.2085258960723877), ('preferences', 3.184661936759949), ('trie', 3.039197826385498), ('borders', 3.027029037475586)]
Top words for pretrained_CodeBERTa neuron indx 4707 [('">"', 3.486222743988037), ('moves', 3.385205030441284), ('"/"', 3.345534086227417), ('PIL', 3.2169299125671387), ('filter', 3.1360702514648438)]
Top words for pretrained_CodeBERTa neuron indx 614 [('answer', 3.6971371173858643), ('")"', 3.613384962081909), ("'('", 3.5487122535705566), ('timedelta', 3.5449905395507812), ('permute', 3.480046510696411)]
Top words for pretrained_CodeBERTa neuron indx 2667 [('ValidationException', 3.486532688140869), ('copy', 2.8950799465179444), ('copy_', 2.6038870811462402), ('pid', 2.556950330734253), ('zipfile', 2.5226876735687256)]
Top words for pretrained_CodeBERTa neuron indx 635 [('sub', 3.0851681232452393), ('channels', 3.018078088760376), ('except', 2.9904422205547956), ('history', 2.9604573249816895), ('ValidationException', 2.6904706954956055)]
Top words for pretrained_CodeBERTa neuron indx 4738 [('ET', 3.179100275039673), ('XML', 3.069927930831909), ("'mon'", 3.065737009048462), ("'side'", 3.0366547107696533), ('parseString', 2.939650058746338)]
Top words for pretrained_CodeBERTa neuron indx 4741 [('encoding', 4.973557790120442), ('":"', 2.913827339808146), ('console', 2.784430503845215), ('shutil', 2.768969178199768), ('encode', 2.745950619379679)]
Top words for pretrained_CodeBERTa neuron indx 658 [('git', 3.9125289916992188), ("'--'", 3.8332493603229523), ('exceptions', 3.813045024871826), ('strip', 3.7659687598546348), ('"/"', 3.6841075897216795)]
Top words for pretrained_CodeBERTa neuron indx 661 [('view', 3.80341899394989), ('splits', 3.5708558559417725), ('mode', 3.3380127394640886), ('contiguous', 3.179591655731201), ("')'", 3.1322453022003174)]
Top words for pretrained_CodeBERTa neuron indx 2718 [('gui', 4.247034549713135), ('zipfile', 3.4365434646606445), ('subprocess', 3.1779407262802124), ('exit', 2.979910373687744), ('error', 2.953890323638916)]
Top words for pretrained_CodeBERTa neuron indx 4767 [('shuffle', 3.7428531646728516), ('FloatTensor', 3.5847160816192627), ('activation', 3.193213105201721), ("'!'", 3.114600658416748), ("';'", 3.0863179206848144)]
Top words for pretrained_CodeBERTa neuron indx 2724 [('pow', 3.511200428009033), ('strip', 3.3720059792200723), ('part', 3.1695563793182373), ('cfg', 3.0341705083847046), ('interpolation', 2.936248915536063)]
Top words for pretrained_CodeBERTa neuron indx 4774 [('"""str->str"""', 3.833611249923706), ('bytes', 3.2495076656341553), ('builtins', 3.073494791984558), ('println', 2.921856164932251), ('seconds', 2.8778629302978516)]
Top words for pretrained_CodeBERTa neuron indx 701 [('None', 2.5784799239602507), ('timedelta', 2.5672667026519775), ('eq', 2.559508800506592), ('"_rot"', 2.390589475631714), ('scandir', 2.3707242012023926)]
Top words for pretrained_CodeBERTa neuron indx 2768 [("'locales'", 2.3357460498809814), ('code', 2.3312348127365112), ('ZipFile', 2.272780418395996), ('RED', 2.2722911834716797), ("'extensions'", 2.2277270555496216)]
Top words for pretrained_CodeBERTa neuron indx 2772 [('struct', 3.516756534576416), ('pow', 3.4905741214752197), ('squeeze', 3.420121908187866), ('shutil', 3.418424963951111), ('curr', 3.40751964705331)]
Top words for pretrained_CodeBERTa neuron indx 4821 [('six', 3.149228096008301), ('await', 2.700073480606079), ('extract', 2.4682364463806152), ('accuracy', 2.253462314605713), ('fromstring', 2.2126901149749756)]
Top words for pretrained_CodeBERTa neuron indx 734 [('fh', 4.0352935791015625), ('fill', 3.907616297403971), ('responses', 3.594026494026184), ('sqrt', 3.551424264907837), ('split', 3.4714310231961703)]
Top words for pretrained_CodeBERTa neuron indx 4836 [('111', 4.2354655265808105), ('bias', 3.963643789291382), ('scandir', 3.685411214828491), ('default', 3.6706442832946777), ('basename', 3.662681818008423)]
Top words for pretrained_CodeBERTa neuron indx 2791 [('nn', 3.0874648094177246), ('key', 2.9066213369369507), ("'<root>'", 2.895641565322876), ('squeeze', 2.841550350189209), ('color', 2.600546956062317)]
Top words for pretrained_CodeBERTa neuron indx 2798 [('extend', 4.8621978759765625), ('flatten', 3.795252799987793), ('Exception', 3.7092080116271973), ('StopIteration', 3.5579326152801514), ('word', 3.554101139307022)]
Top words for pretrained_CodeBERTa neuron indx 2806 [('terminated', 3.3815925121307373), ('"%02d:%02d:%02d:%02d"', 3.311504602432251), ('transforms', 3.133305481501988), ('byte', 3.1308043003082275), ('struct', 3.058833360671997)]
Top words for pretrained_CodeBERTa neuron indx 4858 [('lc', 3.4018783569335938), ('continue', 3.380751848220825), ('im', 3.2003661394119263), ('affine', 3.072887659072876), ('english_name', 3.0013550519943237)]
Top words for pretrained_CodeBERTa neuron indx 2812 [('strip', 3.497123042742411), ('sleep', 3.4132020473480225), ('round', 3.3561375617980955), ('to', 2.8850412368774414), ('communicate', 2.8795318603515625)]
Top words for pretrained_CodeBERTa neuron indx 4862 [('group', 3.4607780456542967), ('total', 3.3628469705581665), ('pattern', 3.3283965587615967), ('descend', 3.1929640769958496), ('find', 3.172579526901245)]
Top words for pretrained_CodeBERTa neuron indx 2824 [('PIL', 2.958070993423462), ('graph', 2.8879345655441284), ('set', 2.8489742279052734), ('bias', 2.8282835483551025), ('"http://"', 2.7450010776519775)]
Top words for pretrained_CodeBERTa neuron indx 778 [('mul', 4.229388236999512), ('fcntl', 4.06191873550415), ('makedirs', 3.7032158374786377), ('read', 3.6769681374231973), ('close', 3.5382766723632812)]
Top words for pretrained_CodeBERTa neuron indx 4879 [('degrees', 3.16406520207723), ('opts', 3.0394442876180015), ('"|"', 2.9222640991210938), ('ndim', 2.7098979155222573), ('parse', 2.6659862995147705)]
Top words for pretrained_CodeBERTa neuron indx 784 [('expanded', 4.504823684692383), ('clone', 3.95387601852417), ('unpack', 3.6707820892333984), ('save', 3.489210081100464), ('flatten', 3.444427251815796)]
Top words for pretrained_CodeBERTa neuron indx 2834 [('Lambda', 2.9119642972946167), ('np', 2.6278630846585984), ('ImageOps', 2.598211884498596), ('Compose', 2.4540047645568848), ('completer', 2.3658531506856284)]
Top words for pretrained_CodeBERTa neuron indx 2846 [("'}'", 3.4343173503875732), ('attr', 3.300371527671814), ('argv', 3.0024116039276123), ('200', 2.952342450618744), ('hflip', 2.819058895111084)]
Top words for pretrained_CodeBERTa neuron indx 2847 [('clamp_', 3.5711222887039185), ('dict', 3.2961416244506836), ('adjust_saturation', 3.2123743295669556), ('adjust_brightness', 3.1008490324020386), ('convert', 3.024833822250366)]
Top words for pretrained_CodeBERTa neuron indx 805 [('"percent"', 3.903296947479248), ('"uris"', 3.8122498989105225), ('"children"', 3.8001959323883057), ('"NEST"', 3.665666341781616), ('"delete"', 3.619014859199524)]
Top words for pretrained_CodeBERTa neuron indx 816 [('XML', 4.79247522354126), ('hue', 4.27092182636261), ('y', 3.961968387876238), ('contrast', 3.898566782474518), ('tuple', 3.8948229551315308)]
Top words for pretrained_CodeBERTa neuron indx 817 [('byte', 3.5655107498168945), ('write', 3.4412530263264975), ('final', 3.3486619790395102), ('ByteStorage', 3.1695706844329834), ('KeyError', 3.1514875888824463)]
Top words for pretrained_CodeBERTa neuron indx 823 [('answers', 3.858778476715088), ('locales', 3.6707816123962402), ('children', 3.6617642045021057), ('"|"', 3.5779519081115723), ('perspective', 3.556530714035034)]
Top words for pretrained_CodeBERTa neuron indx 2877 [('F', 3.709790349006653), ('cookies', 3.3995085954666138), ('sourceType', 2.8178791999816895), ('filter', 2.7818710803985596), ('unlink', 2.730282783508301)]
Top words for pretrained_CodeBERTa neuron indx 4926 [('streams', 3.5640017986297607), ('numpy', 2.963447690010071), ('"session"', 2.9473438262939453), ('":english"', 2.9378952980041504), ('strSeed', 2.898480772972107)]
Top words for pretrained_CodeBERTa neuron indx 833 [('system', 3.474809408187866), ('opt', 3.448098301887512), ('opts', 3.138301134109497), ("'://'", 2.8137753009796143), ('len', 2.7915127981792796)]
Top words for pretrained_CodeBERTa neuron indx 838 [("'}'", 5.167179584503174), ('req', 3.4088388851710727), ('RED', 3.3202176094055176), ('dumps', 3.2787721157073975), ('border', 3.1960506439208984)]
Top words for pretrained_CodeBERTa neuron indx 2899 [('Tensor', 4.377713680267334), ('int32', 4.1771345138549805), ('int16', 3.824586272239685), ('FloatTensor', 3.721869945526123), ('float32', 3.566639224688212)]
Top words for pretrained_CodeBERTa neuron indx 857 [('over', 4.015488624572754), ('Tensor', 3.580547332763672), ('transpose', 3.3241361379623413), ('channels', 3.081847667694092), ('skill', 2.9410866498947144)]
Top words for pretrained_CodeBERTa neuron indx 4954 [('StopIteration', 5.053109169006348), ('Concatenate', 4.654816627502441), ('seek', 4.132998466491699), ('Exception', 3.9420812129974365), ('NotImplementedError', 3.7304232120513916)]
Top words for pretrained_CodeBERTa neuron indx 4955 [('nrow', 3.8095664024353026), ('"="', 3.5455495289393832), ("';'", 2.9527111530303953), ('Popen', 2.7745442390441895), ('words', 2.6579928398132324)]
Top words for pretrained_CodeBERTa neuron indx 860 [('remove', 3.5139037370681763), ('os', 3.424655112726935), ('unicode', 3.4139020442962646), ('device', 3.1754572868347166), ('engine', 3.136127471923828)]
Top words for pretrained_CodeBERTa neuron indx 861 [('extend', 3.951291561126709), ('issubclass', 3.339722156524658), ('fh', 3.1627672910690308), ('Concatenate', 3.1230416297912598), ('ndarr', 3.0339908599853516)]
Top words for pretrained_CodeBERTa neuron indx 863 [('stdin', 3.1975295543670654), ('gain', 3.0750964879989624), ('"V"', 2.8064019680023193), ('translate', 2.782921850681305), ('issubclass', 2.605769157409668)]
Top words for pretrained_CodeBERTa neuron indx 2926 [('label', 3.9216394424438477), ('copy', 3.257962369918823), ('Lambda', 3.141246199607849), ('map', 3.0940696001052856), ('upper', 2.9925971031188965)]
Top words for pretrained_CodeBERTa neuron indx 2934 [('channels', 3.5109760761260986), ('pic', 3.32584490776062), ('palette', 3.2994930744171143), ('pretrained', 2.8212649524211884), ('numpy', 2.791636347770691)]
Top words for pretrained_CodeBERTa neuron indx 2938 [('upper', 3.9015800952911377), ('to', 3.1706855297088623), ('streams', 3.0050554871559143), ('accuracy', 2.8942553997039795), ('index', 2.838026463985443)]
Top words for pretrained_CodeBERTa neuron indx 897 [('charset', 4.0695717334747314), ('six', 3.9408466815948486), ('basename', 3.931206703186035), ('stdin', 3.6067038774490356), ('Color', 3.574632167816162)]
Top words for pretrained_CodeBERTa neuron indx 909 [('except', 3.5753351810366607), ('raise', 3.1770380093501163), ('10', 3.0724948736337514), ('pop', 2.8067440589269004), ('100', 2.6631116356168474)]
Top words for pretrained_CodeBERTa neuron indx 5007 [('flatten', 3.373626708984375), ('tile', 3.3227896690368652), ('crop', 2.915472835302353), ('"%s"', 2.7432122230529785), ('over', 2.7061071395874023)]
Top words for pretrained_CodeBERTa neuron indx 911 [('skill', 3.4449987411499023), ('shears', 3.2003710865974426), ('1000', 3.041749954223633), ('tmp', 3.030685782432556), ('tuple', 3.0249334573745728)]
Top words for pretrained_CodeBERTa neuron indx 927 [('add', 3.514058232307434), ('Number', 3.4679977893829346), ('exit', 2.6937406063079834), ('shuffle', 2.6761257648468018), ('is', 2.416689638919141)]
Top words for pretrained_CodeBERTa neuron indx 933 [('div', 3.3758084774017334), ('group', 2.7931241035461425), ('"nearest"', 2.706214666366577), ('c', 2.6173367500305176), ('"accuracy"', 2.490198850631714)]
Top words for pretrained_CodeBERTa neuron indx 936 [('affine', 3.291918992996216), ('Optional', 2.766427516937256), ('sourceType', 2.696124419569969), ('bias', 2.5498905181884766), ('stride', 2.5408174196879068)]
Top words for pretrained_CodeBERTa neuron indx 957 [('zip', 2.9579885800679526), ('shuffle', 2.948213577270508), ('ET', 2.6298446655273438), ('gzip', 2.582568645477295), ('zipfile', 2.482583999633789)]
Top words for pretrained_CodeBERTa neuron indx 5056 [('NotImplementedError', 4.244093894958496), ('contrast', 3.3472083508968353), ('sourceType', 3.229604132473469), ('cfg', 3.1876895427703857), ('"}"', 3.0654110511144004)]
Top words for pretrained_CodeBERTa neuron indx 3008 [('cfg', 2.915719151496887), ('permute', 2.8437750339508057), ('uniform', 2.532965963537043), ('getattr', 2.453782796859741), ('min', 2.441193699836731)]
Top words for pretrained_CodeBERTa neuron indx 5060 [('div', 3.052639961242676), ("'{'", 3.013672113418579), ('KeyboardInterrupt', 2.9630682468414307), ('eq', 2.8729331493377686), ('node', 2.8425815105438232)]
Top words for pretrained_CodeBERTa neuron indx 5075 [('colors', 3.44022399187088), ('affine', 3.091829776763916), ('accuracy', 3.030484914779663), ('ratio', 2.870274543762207), ('seconds', 2.821355938911438)]
Top words for pretrained_CodeBERTa neuron indx 3029 [('nn', 3.895962715148926), ('fid', 3.173771858215332), ('11', 3.1593307852745056), ('termios', 3.0138330459594727), ('cat', 2.7496412992477417)]
Top words for pretrained_CodeBERTa neuron indx 3033 [('timedelta', 3.9339277744293213), ('202', 3.3652608394622803), ('q', 3.23246169090271), ('affine', 3.157956123352051), ('locales', 2.994805097579956)]
Top words for pretrained_CodeBERTa neuron indx 3034 [('tzinfo', 3.307492733001709), ('":"', 2.9467594623565674), ('affine', 2.936194896697998), ('keepdims', 2.8456852436065674), ('ATTRS', 2.767130136489868)]
Top words for pretrained_CodeBERTa neuron indx 3042 [('";"', 4.0517576932907104), ('"}"', 3.5866394440333047), ('"@"', 3.5586671829223633), ('"|"', 3.3164148330688477), ('"#"', 3.2912967999776206)]
Top words for pretrained_CodeBERTa neuron indx 3051 [('units', 3.46236922343572), ('channels', 3.3991079330444336), ('Iterable', 3.2642762660980225), ('stack', 3.0459814071655273), ('ndarray', 2.9769179821014404)]
Top words for pretrained_CodeBERTa neuron indx 3052 [('remove', 3.839476227760315), ('terminated', 3.8244121074676514), ('console', 3.8085765838623047), ('tar', 3.4298282861709595), ('111', 3.3947514295578003)]
Top words for pretrained_CodeBERTa neuron indx 1008 [('childNodes', 3.3274078369140625), ('unicode', 3.2445151805877686), ('growth_rate', 3.234938383102417), ('scandir', 3.1854426860809326), ('stride', 3.1620167891184487)]
Top words for pretrained_CodeBERTa neuron indx 3058 [('sort', 3.1728363037109375), ('index', 3.079423257282802), ('scandir', 2.943676471710205), ('StopIteration', 2.7735953330993652), ('system', 2.727381944656372)]
Top words for pretrained_CodeBERTa neuron indx 1011 [('hostname', 2.751009702682495), ('splits', 2.7283031940460205), ('render', 2.7222349643707275), ('ndim', 2.7119274139404297), ('bl', 2.590698003768921)]
Top words for pretrained_CodeBERTa neuron indx 1016 [('urlencode', 3.865835428237915), ('parseString', 3.3978312015533447), ('resample', 3.025182783603668), ('ndim', 2.9181159337361655), ('Iterable', 2.706141233444214)]
Top words for pretrained_CodeBERTa neuron indx 1019 [('tarfile', 3.7814319133758545), ('"*"', 3.7677217721939087), ('preferred', 3.569586992263794), ('keywords', 3.5159313678741455), ('shutil', 3.3493120670318604)]
Top words for pretrained_CodeBERTa neuron indx 3070 [('any', 3.8720076084136963), ('sub', 3.2764647006988525), ('RED', 3.2170019149780273), ('escape', 3.1498645544052124), ('color', 3.1162056922912598)]
Top words for pretrained_CodeBERTa neuron indx 3071 [('quote', 4.062101364135742), ('KeyboardInterrupt', 3.7815651893615723), ('stdin', 3.693164587020874), ("';'", 3.5268351554870607), ("'='", 3.3720153172810874)]
Top words for pretrained_CodeBERTa neuron indx 5128 [('tensor', 3.7271317563951016), ('graph', 3.0314141511917114), ('argv', 2.9976933002471924), ('pad_right', 2.8567641178766885), ('pad_bottom', 2.8456563353538513)]
Top words for pretrained_CodeBERTa neuron indx 3082 [('items', 3.443995475769043), ('query', 3.261112939227711), ('mul', 3.125588893890381), ('gui', 3.0496864318847656), ('"-"', 3.0363876819610596)]
Top words for pretrained_CodeBERTa neuron indx 3083 [('cookies', 3.7181618213653564), ('filtered', 3.154790163040161), ('days', 3.117363214492798), ('seconds', 3.117094397544861), ('datetime', 2.9783166646957397)]
Top words for pretrained_CodeBERTa neuron indx 5134 [('"="', 3.41158321925572), ('lc', 3.108316659927368), ("')'", 3.0225608348846436), ('"|"', 2.916069984436035), ("'}'", 2.8661816120147705)]
Top words for pretrained_CodeBERTa neuron indx 5138 [('upper', 3.4691762924194336), ('ValidationException', 3.2346174716949463), ('LANGUAGE_CODES', 3.155000686645508), ('getattr', 3.0748217900594077), ('ATTRS', 2.988145112991333)]
Top words for pretrained_CodeBERTa neuron indx 3091 [('div', 3.6455078125), ('get', 3.08542969010093), ('"There\\', 2.7462780475616455), ('key', 2.6939494609832764), ('ele', 2.5460132360458374)]
Top words for pretrained_CodeBERTa neuron indx 1046 [('json', 3.4690430760383606), ('Tensor', 3.4019999504089355), ('PIL', 3.3886635303497314), ('zeros', 3.266406774520874), ('activation', 3.224154233932495)]
Top words for pretrained_CodeBERTa neuron indx 3094 [('Session', 3.6068639755249023), ('">"', 2.9976117610931396), ('history', 2.899492025375366), ('fpath', 2.8708633354731967), ('Request', 2.5637158155441284)]
Top words for pretrained_CodeBERTa neuron indx 1050 [('word', 3.6800211668014526), ('label', 3.201777696609497), ('expand', 3.194587826728821), ('inplace', 2.9829063415527344), ('"proto=none_proto"', 2.9693143367767334)]
Top words for pretrained_CodeBERTa neuron indx 5149 [('shuffle', 3.710636615753174), ('undeflate', 3.5225354433059692), ('exceptions', 3.5060741901397705), ('time', 3.212087392807007), ('crop', 3.0639032125473022)]
Top words for pretrained_CodeBERTa neuron indx 5161 [('urljoin', 3.5527610778808594), ('bytes', 3.5364935398101807), ('degrees', 2.861219882965088), ('words', 2.8312716484069824), ('sprint', 2.810553789138794)]
Top words for pretrained_CodeBERTa neuron indx 3116 [('to', 2.8022823333740234), ('append', 2.6821547833884636), ('affine', 2.678091287612915), ('"steps"', 2.643477201461792), ('conf', 2.6250427067279816)]
Top words for pretrained_CodeBERTa neuron indx 3121 [('fh', 3.204511046409607), ('write', 3.1799000104268393), ('error', 3.113325595855713), ('stdout', 2.8217694759368896), ('seconds', 2.5755796432495117)]
Top words for pretrained_CodeBERTa neuron indx 3136 [('quote', 5.027029991149902), ('pad', 3.8346254229545593), ('unicode', 3.7647533416748047), ('permute', 3.401346445083618), ('decode', 3.343322277069092)]
Top words for pretrained_CodeBERTa neuron indx 1092 [('Timeout', 3.772362232208252), ('stride', 3.3498226006825766), ('s', 3.3273981298719133), ('flush', 3.003533959388733), ('ceil', 2.9575822353363037)]
Top words for pretrained_CodeBERTa neuron indx 1098 [('LongTensor', 2.5530232191085815), ('Sequence', 2.526880661646525), ('ndarray', 2.5176238119602203), ('args', 2.4513096113999686), ('stack', 2.4354658126831055)]
Top words for pretrained_CodeBERTa neuron indx 5199 [('"@"', 4.361721515655518), ('dim', 4.3147783279418945), ('add', 3.4163488149642944), ('default', 3.1542165279388428), ("'resolutions'", 2.869252920150757)]
Top words for pretrained_CodeBERTa neuron indx 1109 [('console', 3.25311279296875), ('colors', 3.241023361682892), ('ValidationException', 3.066004514694214), ('tzinfo', 2.980771541595459), ('stats', 2.795372560620308)]
Top words for pretrained_CodeBERTa neuron indx 1112 [('scandir', 4.168133735656738), ('console', 3.4030890464782715), ('contrast', 3.3881419897079468), ('label', 3.1058311462402344), ('stdout', 2.8755757808685303)]
Top words for pretrained_CodeBERTa neuron indx 3164 [("'['", 4.086055636405945), ('sub', 3.254676580429077), ('escape', 3.213645815849304), ("'+'", 3.1824824810028076), ('getattr', 3.0945440928141275)]
Top words for pretrained_CodeBERTa neuron indx 5225 [('engine', 3.6525044441223145), ('fill', 3.5730998516082764), ('barrier', 3.5355069637298584), ('FloatTensor', 3.035384178161621), ('unicode', 2.959146499633789)]
Top words for pretrained_CodeBERTa neuron indx 3179 [("'HEAD'", 2.942964792251587), ('hasattr', 2.8116343021392822), ('upper', 2.8065056800842285), ('any', 2.680114984512329), ('escape', 2.664720892906189)]
Top words for pretrained_CodeBERTa neuron indx 1146 [('bias', 3.4766368865966797), ('io', 2.995781898498535), ('ceil', 2.6659998893737793), ('matches', 2.638201951980591), ('classes', 2.636475086212158)]
Top words for pretrained_CodeBERTa neuron indx 5244 [('exit', 3.425021171569824), ('q', 2.864133596420288), ('filter', 2.725621461868286), ("'sklearn'", 2.4492294788360596), ('categories', 2.445466470718384)]
Top words for pretrained_CodeBERTa neuron indx 3197 [('Multiply', 3.794003486633301), ('getattr', 3.4014758268992105), ('patch', 3.2754441499710083), ('activation', 3.1038935581843057), ('decompress', 3.0960142612457275)]
Top words for pretrained_CodeBERTa neuron indx 1150 [('child', 3.6976072788238525), ('engines', 3.6620752811431885), ('colors', 3.604359745979309), ('children', 3.587347388267517), ('pop', 3.5213142236073813)]
Top words for pretrained_CodeBERTa neuron indx 3201 [('basename', 4.7620134353637695), ('shuffle', 4.7074971199035645), ('barrier', 4.384319305419922), ('stdin', 4.282252788543701), ('argv', 4.249675750732422)]
Top words for pretrained_CodeBERTa neuron indx 5252 [('"|"', 3.111037254333496), ('RED', 3.0406408309936523), ('basename', 2.9722118377685547), ('"}"', 2.844661593437195), ('keepdims', 2.763145685195923)]
Top words for pretrained_CodeBERTa neuron indx 3206 [('else', 2.524020919377364), ('any', 2.3562231063842773), ('keepdims', 2.2524936199188232), ('sort', 2.225130796432495), ('tile', 2.0645806789398193)]
Top words for pretrained_CodeBERTa neuron indx 3207 [('ceil', 3.7230653762817383), ('getattr', 3.62233829498291), ('softmax', 3.56185781955719), ('asarray', 3.301768183708191), ('sqrt', 3.2799484729766846)]
Top words for pretrained_CodeBERTa neuron indx 5256 [('any', 2.942216396331787), ('"{value}"', 2.8580431938171387), ('opt', 2.758545994758606), ('class', 2.7255650758743286), ('words', 2.6043872833251953)]
Top words for pretrained_CodeBERTa neuron indx 1174 [('basename', 3.204556941986084), ('git', 2.978789806365967), ('loads', 2.941438227891922), ('resize', 2.8622021079063416), ('moves', 2.7339863777160645)]
Top words for pretrained_CodeBERTa neuron indx 3224 [('permute', 4.22835636138916), ('startswith', 3.7447533309459686), ('opt', 3.6686282555262246), ('clamp_', 3.3609100580215454), ("'{}{}'", 3.359395980834961)]
Top words for pretrained_CodeBERTa neuron indx 3230 [('flush', 2.656428337097168), ('ndim', 2.6388051907221475), ('time', 2.531548817952474), ("'['", 2.4997406005859375), ('sub', 2.492041826248169)]
Top words for pretrained_CodeBERTa neuron indx 3235 [('F', 4.1853684186935425), ('minutes', 3.3597304821014404), ('sleep', 3.1894233226776123), ('oh', 3.0920721689860025), ('f', 2.9287896156311035)]
Top words for pretrained_CodeBERTa neuron indx 5290 [('ET', 4.107982158660889), ('version', 4.058078765869141), ('BOLD', 3.7457887331644693), ('XML', 3.5887975692749023), ('writerow', 3.5237483978271484)]
Top words for pretrained_CodeBERTa neuron indx 5293 [('keywords', 3.459299325942993), ('engine', 3.4522740840911865), ('ndim', 3.233952363332113), ('shuffle', 2.8229942321777344), ('words', 2.7376840114593506)]
Top words for pretrained_CodeBERTa neuron indx 1200 [('202', 3.6928133964538574), ('errno', 3.617322325706482), ('n', 3.5462788740793862), ('engines', 3.5142481327056885), ('mean', 3.476245641708374)]
Top words for pretrained_CodeBERTa neuron indx 5323 [('100', 2.912119706471761), ('degrees', 2.4381339152654014), ("'Content-Encoding'", 2.431270122528076), ('pattern', 2.3830748796463013), ("'server'", 2.268760919570923)]
Top words for pretrained_CodeBERTa neuron indx 3276 [("'.{}'", 2.5063400268554688), ("'{}.local.'", 2.080024480819702), ('extract', 2.074531316757202), ('answer', 2.056077003479004), ("'**/*.json'", 2.0403943061828613)]
Top words for pretrained_CodeBERTa neuron indx 1228 [("'>='", 3.748734951019287), ("'---'", 3.194706678390503), ('decode', 3.154417133331299), ('urljoin', 3.084620475769043), ("'('", 3.032318115234375)]
Top words for pretrained_CodeBERTa neuron indx 5328 [('sleep', 3.063922643661499), ('"$"', 2.784750461578369), ('Session', 2.7334365844726562), ('"{value}"', 2.6863317489624023), ('locales', 2.638418674468994)]
Top words for pretrained_CodeBERTa neuron indx 3282 [('keepdims', 4.229917526245117), ('ids', 3.3192790349324546), ('io', 3.2864573001861572), ('to', 3.242238998413086), ('childNodes', 3.190633535385132)]
Top words for pretrained_CodeBERTa neuron indx 5333 [('axis', 3.0101396838823953), ('over', 2.987070083618164), ('gamma_map', 2.9386050701141357), ('dirname', 2.937347173690796), ('ZipFile', 2.873220205307007)]
Top words for pretrained_CodeBERTa neuron indx 3288 [('flatten', 3.674741506576538), ('replace', 3.102998673915863), ('raise', 2.904105929227976), ('map', 2.8998130559921265), ('debug', 2.589557647705078)]
Top words for pretrained_CodeBERTa neuron indx 3291 [('bias', 4.1110405921936035), ("'--'", 3.0124182999134064), ('tmp', 2.852569818496704), ('keepdims', 2.7679803371429443), ('completer', 2.7350516319274902)]
Top words for pretrained_CodeBERTa neuron indx 5341 [('unlink', 3.00296950340271), ('1000', 2.8692019310864536), ('"%s-%s-%s-%s"', 2.776427984237671), ("'_'", 2.7487497528394065), ('childNodes', 2.713935375213623)]
Top words for pretrained_CodeBERTa neuron indx 5352 [('Iterable', 3.9061663150787354), ('tuple', 3.1089314222335815), ('dict', 2.697343111038208), ('Optional', 2.5994250774383545), ('contiguous', 2.5413029193878174)]
Top words for pretrained_CodeBERTa neuron indx 5355 [('unlink', 3.220730781555176), ('Session', 3.0784943103790283), ('units', 3.022167901198069), ('datetime', 2.8879284858703613), ('squeeze_', 2.8601202964782715)]
Top words for pretrained_CodeBERTa neuron indx 3317 [('Session', 3.589975595474243), ('rmtree', 2.978158473968506), ('Iterable', 2.9625487327575684), ('view', 2.9349688291549683), ('exp', 2.9193930625915527)]
Top words for pretrained_CodeBERTa neuron indx 1271 [('splits', 2.789266347885132), ('pad', 2.716158866882324), ('account_number', 2.6766095956166587), ('tile', 2.6538448333740234), ("'username'", 2.5690295696258545)]
Top words for pretrained_CodeBERTa neuron indx 3319 [('strip', 3.781041145324707), ('reshape', 3.229994773864746), ('flush', 3.092441201210022), ('outfile', 2.9614251852035522), ('group', 2.851546812057495)]
Top words for pretrained_CodeBERTa neuron indx 1277 [('pow', 4.650007247924805), ('scandir', 4.048393726348877), ('border', 4.0041704177856445), ('round', 3.9313872337341307), ('filename', 3.8830253199527136)]
Top words for pretrained_CodeBERTa neuron indx 1292 [('type', 3.9162304401397705), ('seconds', 3.781244993209839), ('dict', 3.70656681060791), ('timedelta', 3.7050695419311523), ('"-"', 3.6996753215789795)]
Top words for pretrained_CodeBERTa neuron indx 3348 [('default', 3.3573296070098877), ('extend', 3.1633553504943848), ('dist', 3.1546884775161743), ('border', 3.0790435075759888), ('bytes', 2.8280200958251953)]
Top words for pretrained_CodeBERTa neuron indx 1300 [('symbols', 4.562788724899292), ('unlink', 4.434652805328369), ('remove', 4.121685028076172), ('shutil', 3.9739487171173096), ('copy', 3.8253323554992678)]
Top words for pretrained_CodeBERTa neuron indx 3352 [('childNodes', 2.8972723484039307), ('pad', 2.8228254914283752), ('streams', 2.738375097513199), ('indexes', 2.7333993911743164), ('shortcuts', 2.563525915145874)]
Top words for pretrained_CodeBERTa neuron indx 3388 [('quality', 2.7149208784103394), ('map', 2.573780059814453), ('plugins', 2.541792392730713), ('close', 2.525723934173584), ('parseString', 2.4588730335235596)]
Top words for pretrained_CodeBERTa neuron indx 3398 [('copy', 3.200497055053711), ('merge', 3.080088302067348), ('KeyboardInterrupt', 2.889463186264038), ('to', 2.8266448974609375), ('name', 2.73108548777444)]
Top words for pretrained_CodeBERTa neuron indx 3414 [('close', 3.4951436519622803), ('headers', 3.4837513620203193), ('keywords', 3.2006633281707764), ('makedirs', 3.170893907546997), ('a', 3.1368245258210945)]
Top words for pretrained_CodeBERTa neuron indx 1382 [('ZipFile', 3.0033929347991943), ('unpack', 2.8672258853912354), ('copy', 2.7437296390533445), ('";"', 2.724876046180725), ('tuple', 2.633157968521118)]
Top words for pretrained_CodeBERTa neuron indx 3434 [('120', 4.112240433692932), ('fileobj', 3.514936685562134), ('Timeout', 3.2675716876983643), ('borders', 3.1423134803771973), ('basename', 3.1107945442199707)]
Top words for pretrained_CodeBERTa neuron indx 1398 [('palette', 3.1649192174275718), ('channels', 2.9411518573760986), ('view', 2.904900908470154), ('activation', 2.7912738720575967), ('pic', 2.750344671143426)]
Top words for pretrained_CodeBERTa neuron indx 3447 [('fileobj', 2.881434202194214), ('all', 2.471006393432617), ('contiguous', 2.386524200439453), ('theme', 2.258284091949463), ("'Accept-Encoding'", 2.2268788814544678)]
Top words for pretrained_CodeBERTa neuron indx 1400 [('basename', 3.6206753253936768), ('"&"', 3.4857399463653564), ('system', 3.467257022857666), ('ValueError', 3.2874038219451904), ('stride', 3.264625310897827)]
Top words for pretrained_CodeBERTa neuron indx 3453 [("'--'", 3.4463612139225006), ('letters', 3.3481366634368896), ('asarray', 3.1966347694396973), ('"|"', 3.0838863849639893), ('mime', 3.0650861263275146)]
Top words for pretrained_CodeBERTa neuron indx 3459 [('22', 3.8374840021133423), ('lc', 3.6613550186157227), ('cfg', 3.2655011415481567), ('tzinfo', 3.173725724220276), ('Number', 3.1394179662068686)]
Top words for pretrained_CodeBERTa neuron indx 3471 [('colors', 3.198891818523407), ('class', 2.869033694267273), ('interpolation', 2.7701967784336636), ('sub', 2.471111297607422), ('over', 2.422045946121216)]
Top words for pretrained_CodeBERTa neuron indx 3486 [('except', 3.077394036359565), ('subprocess', 2.8689666986465454), ('elif', 2.8532281115248397), ('zipfile', 2.7537425756454468), ('F', 2.6526734232902527)]
Top words for pretrained_CodeBERTa neuron indx 1444 [('descend', 3.8235130310058594), ('days', 3.731527090072632), ('tarfile', 3.639103651046753), ('isinstance', 3.6338197191556296), ('colors', 3.4996525049209595)]
Top words for pretrained_CodeBERTa neuron indx 3492 [('part', 3.3419528007507324), ('cfg', 3.0529454946517944), ('contiguous', 3.047285556793213), ('interpolation', 2.767482502119882), ('strip', 2.7595128615697226)]
Top words for pretrained_CodeBERTa neuron indx 1446 [('Sequence', 4.302821000417073), ('mean', 3.6482784152030945), ('XML', 3.3898487091064453), ('find', 3.3586905002593994), ('part', 3.3136271238327026)]
Top words for pretrained_CodeBERTa neuron indx 1472 [('Compose', 3.4735400676727295), ('dirname', 3.174217462539673), ('raise', 3.0611493051625214), ('interpolation', 2.865962403161185), ('attr', 2.854988694190979)]
Top words for pretrained_CodeBERTa neuron indx 3521 [("'{}'", 3.425802707672119), ('render', 3.232645571231842), ('shortcuts', 2.778488874435425), ('favicons', 2.765194892883301), ('type', 2.736172676086426)]
Top words for pretrained_CodeBERTa neuron indx 1484 [('subprocess', 3.9807008504867554), ('softmax', 3.4287623167037964), ('io', 3.2330172061920166), ('shear', 3.194827604293823), ('method', 3.0676438212394714)]
Top words for pretrained_CodeBERTa neuron indx 3536 [('code', 2.323871374130249), ('ZipFile', 2.3223865032196045), ('all', 2.1751677989959717), ('"</table>"', 2.1609513759613037), ("'locales'", 2.1213905811309814)]
Top words for pretrained_CodeBERTa neuron indx 3538 [('Optional', 3.9367167949676514), ('lower', 3.6437715689341226), ('upper', 3.3663604259490967), ('"="', 2.931188004357474), ('mul', 2.908465623855591)]
Top words for pretrained_CodeBERTa neuron indx 3577 [('all', 3.1973907947540283), ('split', 2.9919981972167364), ('re', 2.8816411197185516), ('hostname', 2.8191654086112976), ('site', 2.787176012992859)]
Top words for pretrained_CodeBERTa neuron indx 1538 [('console', 3.646127700805664), ('ZipFile', 3.5890567302703857), ('Iterable', 3.4767091274261475), ('port', 3.0447752873102822), ("'\\\\\\\\'", 3.0287801027297974)]
Top words for pretrained_CodeBERTa neuron indx 3601 [('response', 2.912627359231313), ('im', 2.9071608781814575), ('stream', 2.8773773397718156), ('urllib', 2.8343847592671714), ('shortcuts', 2.6665921211242676)]
Top words for pretrained_CodeBERTa neuron indx 3619 [('axis', 3.9665944576263428), ('"-"', 3.6988964080810547), ('label', 3.40315580368042), ('nn', 3.2399709224700928), ('barrier', 3.0599584579467773)]
Top words for pretrained_CodeBERTa neuron indx 3620 [('coeffs', 3.479833245277405), ('tl', 3.1269373893737793), ('barrier', 3.1022379398345947), ('stride', 2.8811655839284263), ('device', 2.8590317249298094)]
Top words for pretrained_CodeBERTa neuron indx 3622 [('json', 3.6016871333122253), ('PIL', 3.5447118282318115), ('console', 3.31095814704895), ('keepdims', 3.2707278728485107), ('ValueError', 3.1054935455322266)]
Top words for pretrained_CodeBERTa neuron indx 1580 [('">"', 3.885213613510132), ('affine', 3.4796760082244873), ('sprint', 3.453709125518799), ('reshape', 2.9655275344848633), ("')'", 2.856203079223633)]
Top words for pretrained_CodeBERTa neuron indx 1588 [('fout', 3.6836089491844177), ('outfile', 3.4210528135299683), ('open', 3.082603899637858), ('finally', 2.9746333360671997), ('themes', 2.952004565132989)]
Top words for pretrained_CodeBERTa neuron indx 1597 [('ratio', 3.070725747517177), ('decode', 2.749078464508057), ('byte', 2.4569478034973145), ("'\\\\\\\\'", 2.3711217641830444), ('fout', 2.332876294851303)]
Top words for pretrained_CodeBERTa neuron indx 3647 [('color', 2.864383816719055), ('find', 2.707049608230591), ('22', 2.58665007352829), ('path', 2.4829559570009057), ('inplace', 2.48250949382782)]
Top words for pretrained_CodeBERTa neuron indx 3660 [('find', 4.514172554016113), ('reshape', 3.998976945877075), ('flatten', 3.682880401611328), ('cat', 3.5445696115493774), ('sum', 3.2041693687438966)]
Top words for pretrained_CodeBERTa neuron indx 1615 [('stack', 3.3482983112335205), ('error', 3.332515001296997), ('hexdigest', 3.2870352268218994), ('param', 2.995980421702067), ('childNodes', 2.772876501083374)]
Top words for pretrained_CodeBERTa neuron indx 1626 [('debug', 3.6072709560394287), ('Exception', 3.4243099689483643), ('enhance', 3.417414665222168), ('timeout', 3.3688949743906655), ('any', 3.3449366092681885)]
Top words for pretrained_CodeBERTa neuron indx 3684 [('label', 3.1849164962768555), ('mul', 3.088672161102295), ('any', 2.874502658843994), ('add', 2.8684626817703247), ('Dense', 2.840112018585205)]
Top words for pretrained_CodeBERTa neuron indx 3687 [('error', 4.436138153076172), ('io', 3.8672902584075928), ('Exception', 3.6948812007904053), ('sub', 3.4645073413848877), ('tzinfo', 3.3658171892166138)]
Top words for pretrained_CodeBERTa neuron indx 1643 [('"parallax"', 3.8956291675567627), ('uniform', 3.313722545450384), ('cfg', 3.290029764175415), ('nn', 3.237947463989258), ('get', 3.2374346147884023)]
Top words for pretrained_CodeBERTa neuron indx 3694 [('Lambda', 3.077931046485901), ('copy_', 2.9470889568328857), ('label', 2.941723585128784), ('console', 2.902350664138794), ('upper', 2.6557583808898926)]
Top words for pretrained_CodeBERTa neuron indx 3702 [('channels', 3.9928200244903564), ('pic', 3.6185392008887396), ('pretrained', 3.3879127353429794), ('activation', 3.169961174329122), ('palette', 3.148996909459432)]
Top words for pretrained_CodeBERTa neuron indx 3709 [('return', 3.1434474167905653), ('Session', 2.3987040519714355), ('console', 2.0995068550109863), ('site', 2.0968323945999146), ('theme', 2.085345983505249)]
Top words for pretrained_CodeBERTa neuron indx 3720 [('palette', 3.2817207177480063), ('answer', 3.194791555404663), ('remove', 3.191223621368408), ('item', 3.066815495491028), ('crop', 2.9675397872924805)]
Top words for pretrained_CodeBERTa neuron indx 3725 [('"$"', 3.447781562805176), ('tzinfo', 3.2187604904174805), ("'%'", 3.1999857425689697), ('"/"', 3.130895233154297), ('"-"', 2.9724578857421875)]
Top words for pretrained_CodeBERTa neuron indx 1681 [('keepdims', 4.051548004150391), ('Multiply', 3.128021717071533), ('bias', 3.024829864501953), ('issubclass', 2.8910138607025146), ('22', 2.855711579322815)]
Top words for pretrained_CodeBERTa neuron indx 1693 [('engine', 3.0314717292785645), ('error', 2.997119426727295), ('result', 2.8594671537478766), ('log', 2.842827844619751), ('"\\', 2.8410781423250833)]
Top words for pretrained_CodeBERTa neuron indx 3746 [('pretrained', 2.7198610082268715), ('logger', 2.6939022541046143), ('answer', 2.57340669631958), ('child', 2.5648467540740967), ('and', 2.483620913665403)]
Top words for pretrained_CodeBERTa neuron indx 1725 [('zip', 4.039031744003296), ('io', 3.6600472927093506), ('shuffle', 3.1637163162231445), ('byte', 3.11721134185791), ('ele', 2.921052932739258)]
Top words for pretrained_CodeBERTa neuron indx 1746 [('keepdims', 3.923849582672119), ('childNodes', 3.6170389652252197), ('mult', 3.379380941390991), ('202', 3.1980247497558594), ('ValueError', 3.1176538467407227)]
Top words for pretrained_CodeBERTa neuron indx 3801 [('timedelta', 3.555267810821533), ('splits', 3.538048267364502), ('affine', 3.322634696960449), ('answers', 3.2864553928375244), ('q', 3.148768663406372)]
Top words for pretrained_CodeBERTa neuron indx 3803 [('Concatenate', 4.000881195068359), ('StopIteration', 3.9325077533721924), ('curr', 3.9191671780177524), ('ele', 3.632642149925232), ('Reshape', 3.5980517864227295)]
Top words for pretrained_CodeBERTa neuron indx 1758 [('getattr', 4.784114519755046), ('hasattr', 4.677851676940918), ('decode', 3.623324155807495), ('reshape', 3.342862129211426), ('pow', 3.3311450481414795)]
Top words for pretrained_CodeBERTa neuron indx 3810 [('";"', 3.979295790195465), ('dict', 3.053497791290283), ('"&"', 3.0063765048980713), ('"}"', 2.9094737768173218), ('":"', 2.845694065093994)]
Top words for pretrained_CodeBERTa neuron indx 3819 [('channels', 3.9638493061065674), ('units', 3.5324273904164634), ('Iterable', 3.4178900718688965), ('narrow', 3.090768337249756), ('host', 2.929213915552412)]
Top words for pretrained_CodeBERTa neuron indx 1781 [('nn', 3.854135274887085), ('coeffs', 3.715886116027832), ('softmax', 3.5225651264190674), ('permute', 3.304591417312622), ('Multiply', 3.00050950050354)]
Top words for pretrained_CodeBERTa neuron indx 1788 [('decode', 3.824490118026733), ('gui', 3.6208972930908203), ('conf', 3.4897444546222687), ('to', 3.3320252895355225), ('read', 3.3236350218454995)]
Top words for pretrained_CodeBERTa neuron indx 3839 [('KeyboardInterrupt', 4.273321151733398), ('"-"', 3.685403823852539), ('descend', 3.6245481967926025), ('"@"', 3.591017007827759), ('stdin', 3.324055552482605)]
Top words for pretrained_CodeBERTa neuron indx 3850 [('query', 3.28130823915655), ('zeros', 3.2487006187438965), ('mul', 3.0469772815704346), ('unicodize', 2.905716896057129), ('";"', 2.8259607553482056)]
Top words for pretrained_CodeBERTa neuron indx 3862 [('Session', 3.265338182449341), ('fpath', 3.25667747429439), ('keepdims', 2.6178958415985107), ('Number', 2.5994131565093994), ('dtype', 2.5351434499025345)]
Top words for pretrained_CodeBERTa neuron indx 1829 [('update', 5.726274013519287), ('device', 4.088469696044922), ('copy', 3.709606409072876), ('numbers', 3.54347292582194), ('error', 3.4590651988983154)]
Top words for pretrained_CodeBERTa neuron indx 1843 [('trie', 3.550082238515218), ('version', 3.404003381729126), ('count', 3.227557897567749), ('sqrt', 3.204669713973999), ('PIPE', 3.124642848968506)]
Top words for pretrained_CodeBERTa neuron indx 3915 [('answer', 3.8229129314422607), ('accuracy', 3.6520845890045166), ('unpack', 3.6064302921295166), ('seconds', 3.5178600549697876), ('narrow', 3.475211977958679)]
Top words for pretrained_CodeBERTa neuron indx 3920 [('stride', 4.051689386367798), ('interpolation', 3.0131852286202565), ('moves', 2.8608789443969727), ('exp', 2.767768621444702), ('kernel_size', 2.6115739345550537)]
Top words for pretrained_CodeBERTa neuron indx 3921 [('saturation', 3.790278375148773), ('find', 3.5244104862213135), ('F', 3.175215721130371), ('hue', 3.044154793024063), ('color', 2.9519108533859253)]
Top words for pretrained_CodeBERTa neuron indx 1897 [('fileobj', 3.287644147872925), ('extract', 3.0008633136749268), ('OSError', 2.9110549688339233), ('prepare', 2.9084692001342773), ('fcntl', 2.8635542392730713)]
Top words for pretrained_CodeBERTa neuron indx 1912 [('gamma', 3.687737147013346), ("')'", 3.4985692501068115), ('bias', 3.343980073928833), ('filtered', 3.307361602783203), ('history', 3.248433828353882)]
Top words for pretrained_CodeBERTa neuron indx 3961 [('clone', 4.1122307777404785), ('keepdims', 3.3216211795806885), ('extract', 3.119682550430298), ('sqrt', 3.0779563188552856), ('parse_host', 3.0679831504821777)]
Top words for pretrained_CodeBERTa neuron indx 1914 [('ceil', 2.9153778553009033), ('theme', 2.7273337841033936), ('io', 2.538128137588501), ('bias', 2.4880409240722656), ('matches', 2.327378511428833)]
Top words for pretrained_CodeBERTa neuron indx 3966 [('"&"', 3.5863733291625977), ("']'", 3.3929617404937744), ('nn', 3.231520175933838), ("'['", 3.112501382827759), ('git', 2.998629093170166)]
Top words for pretrained_CodeBERTa neuron indx 3969 [('basename', 3.7240495681762695), ('shuffle', 3.277697801589966), ("'%'", 3.2610023021698), ('stdin', 3.2033435106277466), ('argv', 3.1306138038635254)]
Top words for pretrained_CodeBERTa neuron indx 3975 [('sqrt', 3.915932774543762), ('asarray', 3.9094778299331665), ('getattr', 3.759915590286255), ('makedirs', 3.744649648666382), ('permute', 3.664862871170044)]
Top words for pretrained_CodeBERTa neuron indx 3985 [('enhance', 3.1759610176086426), ('quote', 3.1055164337158203), ('keepdims', 2.9077401161193848), ('shears', 2.7978280186653137), ('"There\\', 2.691431760787964)]
Top words for pretrained_CodeBERTa neuron indx 3993 [('resample', 3.1002971529960632), ('"</table>"', 3.0239702065785727), ('"$"', 2.8243625164031982), ('stack', 2.745605707168579), ('"<table>"', 2.714485466480255)]
Top words for pretrained_CodeBERTa neuron indx 3999 [('shuffle', 3.9170334339141846), ('graph', 3.5695677995681763), ('descend', 3.165292978286743), ('Tensor', 3.1624486446380615), ("'websocket'", 3.0808627605438232)]
Top words for pretrained_CodeBERTa neuron indx 1963 [('axis', 3.6141317089398703), ('contiguous', 3.5049197673797607), ('upper', 3.419426918029785), ('cat', 3.286603808403015), ('trie', 3.232318337758382)]
Top words for pretrained_CodeBERTa neuron indx 4016 [('"|"', 3.7172133922576904), ('io', 3.4191880226135254), ('error', 3.381955146789551), ('Timeout', 3.2840476036071777), ('keepdims', 2.8538336753845215)]
Top words for pretrained_CodeBERTa neuron indx 4022 [('keywords', 3.082832098007202), ('Popen', 2.827094316482544), ('ndarr', 2.809643507003784), ('preferences_url_params', 2.7194275856018066), ('ndarray', 2.4699602723121643)]
Top words for pretrained_CodeBERTa neuron indx 4024 [('fcntl', 2.9037299156188965), ('border', 2.8161935806274414), ('exp', 2.8021252155303955), ('dirname', 2.6903960704803467), ('Image', 2.6693525945439056)]
Top words for pretrained_CodeBERTa neuron indx 4029 [('zip', 3.4020982583363852), ('RED', 3.2171947956085205), ('enumerate', 3.101553784476386), ('softmax', 2.9222159385681152), ('io', 2.870882511138916)]
Top words for pretrained_CodeBERTa neuron indx 2000 [('code', 2.864384174346924), ('ZipFile', 2.4660730361938477), ("'extensions'", 2.223379969596863), ("'locales'", 2.112565040588379), ('Image', 2.1002363247029923)]
Top words for pretrained_CodeBERTa neuron indx 4053 [('six', 3.0795884132385254), ('decompress', 2.7189910411834717), ('accuracy', 2.704782724380493), ('error', 2.5551295280456543), ('json', 2.554454192519188)]
Top words for pretrained_CodeBERTa neuron indx 4062 [('hasattr', 4.842732906341553), ('dict', 3.6347012519836426), ('TIOCGWINSZ', 3.592573404312134), ('">"', 3.5287630558013916), ('_call', 3.1510369777679443)]
Top words for pretrained_CodeBERTa neuron indx 2029 [('elif', 2.8976213803162447), ('directories', 2.731436014175415), ('div_', 2.693425178527832), ('form', 2.6901253859202066), ('target', 2.6347482999165854)]
Top words for pretrained_CodeBERTa neuron indx 2030 [('extend', 3.8445627689361572), ('softmax', 3.687451124191284), ('nrow', 3.583912801742554), ('activation', 3.4884652296702066), ('padding', 3.391440018018087)]
Top words for pretrained_CodeBERTa neuron indx 4089 [('dumps', 4.003491719563802), ('charset', 3.7380841076374054), ('symbols', 3.417199969291687), ('"&"', 3.127220630645752), ('StringIO', 2.9242496490478516)]
Creating control dataset for pretrained_CodeBERTa POS tagging task

pretrained_CodeBERTa_control_task Selectivity (Diff. between true task and probing task performance):  0.7246268656716417
~~~~~~~~~~~~~~~~~~~~~~~Summary~~~~~~~~~~~~~~~~~~~~~~~
Experimental results for pretrained_CodeBERTa:
Baseline score (probing using all neurons, 768 each, of all layers 7) :{'__OVERALL__': 0.9421641791044776, 'NAME': 0.9970149253731343, 'STRING': 0.9985074626865672, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.7805970149253731}

The accuracy when only using the intercept:{'__OVERALL__': 0.25, 'NAME': 0.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 1.0}

Independent layerwise probing:
Layer 0:{'__OVERALL__': 0.8283582089552238, 'NAME': 0.9925373134328358, 'STRING': 1.0, 'NUMBER': 0.9761194029850746, 'KEYWORD': 0.3447761194029851}
Layer 1:{'__OVERALL__': 0.9582089552238806, 'NAME': 0.991044776119403, 'STRING': 1.0, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.8492537313432836}
Layer 2:{'__OVERALL__': 0.9138059701492537, 'NAME': 0.9865671641791045, 'STRING': 1.0, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.6761194029850747}
Layer 3:{'__OVERALL__': 0.816044776119403, 'NAME': 0.6477611940298508, 'STRING': 1.0, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.6238805970149254}
Layer 4:{'__OVERALL__': 0.9694029850746269, 'NAME': 0.9671641791044776, 'STRING': 0.9970149253731343, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.9208955223880597}
Layer 5:{'__OVERALL__': 0.9108208955223881, 'NAME': 0.7328358208955223, 'STRING': 1.0, 'NUMBER': 0.9970149253731343, 'KEYWORD': 0.9134328358208955}
Layer 6:{'__OVERALL__': 0.9014925373134328, 'NAME': 0.6940298507462687, 'STRING': 0.9985074626865672, 'NUMBER': 0.9835820895522388, 'KEYWORD': 0.9298507462686567}

'Incremental-layerwise probing:
Layer [0, 1]:{'__OVERALL__': 0.9149253731343283, 'NAME': 0.9865671641791045, 'STRING': 1.0, 'NUMBER': 0.9835820895522388, 'KEYWORD': 0.6895522388059702}
Layer [0, 1, 2]:{'__OVERALL__': 0.8630597014925373, 'NAME': 0.991044776119403, 'STRING': 0.9985074626865672, 'NUMBER': 0.9895522388059701, 'KEYWORD': 0.47313432835820896}
Layer [0, 1, 2, 3]:{'__OVERALL__': 0.8850746268656716, 'NAME': 0.9895522388059701, 'STRING': 0.9985074626865672, 'NUMBER': 0.9940298507462687, 'KEYWORD': 0.5582089552238806}
Layer [0, 1, 2, 3, 4]:{'__OVERALL__': 0.9201492537313433, 'NAME': 0.9985074626865672, 'STRING': 0.9970149253731343, 'NUMBER': 0.9940298507462687, 'KEYWORD': 0.691044776119403}
Layer [0, 1, 2, 3, 4, 5]:{'__OVERALL__': 0.9451492537313433, 'NAME': 0.9970149253731343, 'STRING': 0.9970149253731343, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.7940298507462686}

select minimum layers:
To lose 0.03*100% accuracy based on all layers, keep the layers from 0 to 1
Clustering based on the layers above: 0 to 1:
When no clustering:
the probing result is {'__OVERALL__': 0.9261194029850747, 'NAME': 0.9791044776119403, 'STRING': 1.0, 'NUMBER': 0.9835820895522388, 'KEYWORD': 0.7417910447761195}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 53
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9488805970149253, 'NAME': 0.8895522388059701, 'STRING': 0.9925373134328358, 'NUMBER': 0.9626865671641791, 'KEYWORD': 0.9507462686567164}

Clustering threshold:0.3
The number of independent neurons:774
The number of clusters:1536
The probing result (CC score) is :{'__OVERALL__': 0.9585820895522388, 'NAME': 0.9895522388059701, 'STRING': 1.0, 'NUMBER': 0.9895522388059701, 'KEYWORD': 0.8552238805970149}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 161
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9694029850746269, 'NAME': 0.9492537313432836, 'STRING': 0.9985074626865672, 'NUMBER': 0.9776119402985075, 'KEYWORD': 0.9522388059701492}

The best accuracy is: 0.9694029850746269
The corresponding number of neurons:161
The corresponding number of neuron percentage reduction is: 0.9700520833333334
The corresponding clustering threshold is :0.3
To lose 0.02*100% accuracy based on all layers, keep the layers from 0 to 5
Clustering based on the layers above: 0 to 5:
When no clustering:
the probing result is {'__OVERALL__': 0.9291044776119403, 'NAME': 0.9985074626865672, 'STRING': 0.9970149253731343, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.7283582089552239}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 107
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9216417910447762, 'NAME': 0.935820895522388, 'STRING': 0.9895522388059701, 'NUMBER': 0.9, 'KEYWORD': 0.8611940298507462}

Clustering threshold:0.3
The number of independent neurons:1834
The number of clusters:4608
The probing result (CC score) is :{'__OVERALL__': 0.9492537313432836, 'NAME': 0.9970149253731343, 'STRING': 0.9985074626865672, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.808955223880597}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 268
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9406716417910448, 'NAME': 0.9388059701492537, 'STRING': 0.9985074626865672, 'NUMBER': 0.9955223880597015, 'KEYWORD': 0.8298507462686567}

The best accuracy is: 0.9406716417910448
The corresponding number of neurons:268
The corresponding number of neuron percentage reduction is: 0.9501488095238095
The corresponding clustering threshold is :0.3
To lose 0.01*100% accuracy based on all layers, keep the layers from 0 to 5
Clustering based on the layers above: 0 to 5:
When no clustering:
the probing result is {'__OVERALL__': 0.9291044776119403, 'NAME': 0.9985074626865672, 'STRING': 0.9970149253731343, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.7283582089552239}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 107
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9216417910447762, 'NAME': 0.935820895522388, 'STRING': 0.9895522388059701, 'NUMBER': 0.9, 'KEYWORD': 0.8611940298507462}

Clustering threshold:0.3
The number of independent neurons:1834
The number of clusters:4608
The probing result (CC score) is :{'__OVERALL__': 0.9492537313432836, 'NAME': 0.9970149253731343, 'STRING': 0.9985074626865672, 'NUMBER': 0.9925373134328358, 'KEYWORD': 0.808955223880597}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 268
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9406716417910448, 'NAME': 0.9388059701492537, 'STRING': 0.9985074626865672, 'NUMBER': 0.9955223880597015, 'KEYWORD': 0.8298507462686567}

The best accuracy is: 0.9406716417910448
The corresponding number of neurons:268
The corresponding number of neuron percentage reduction is: 0.9501488095238095
The corresponding clustering threshold is :0.3

probe independent neurons based on all layers with clustering (run_cc_all.py)
When no clustering:
The probing result (CC score) is :{'__OVERALL__': 0.9604477611940299, 'NAME': 0.9388059701492537, 'STRING': 0.9985074626865672, 'NUMBER': 0.9880597014925373, 'KEYWORD': 0.9164179104477612}
Clustering threshold:0.1
The number of independent neurons:4874
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9444029850746268, 'NAME': 0.9970149253731343, 'STRING': 0.9985074626865672, 'NUMBER': 0.991044776119403, 'KEYWORD': 0.7910447761194029}
Clustering threshold:0.2
The number of independent neurons:3314
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9503731343283582, 'NAME': 0.8865671641791045, 'STRING': 1.0, 'NUMBER': 0.9970149253731343, 'KEYWORD': 0.917910447761194}
Clustering threshold:0.3
The number of independent neurons:2352
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9563432835820895, 'NAME': 0.8985074626865671, 'STRING': 1.0, 'NUMBER': 0.9985074626865672, 'KEYWORD': 0.9283582089552239}
Clustering threshold:0.4
The number of independent neurons:1740
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.957089552238806, 'NAME': 0.9208955223880597, 'STRING': 1.0, 'NUMBER': 0.9985074626865672, 'KEYWORD': 0.908955223880597}
Clustering threshold:0.5
The number of independent neurons:1281
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.7936567164179105, 'NAME': 0.5776119402985075, 'STRING': 1.0, 'NUMBER': 0.9970149253731343, 'KEYWORD': 0.6}
Clustering threshold:0.6
The number of independent neurons:892
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.8746268656716418, 'NAME': 0.7074626865671642, 'STRING': 1.0, 'NUMBER': 0.9970149253731343, 'KEYWORD': 0.7940298507462686}
Clustering threshold:0.7
The number of independent neurons:521
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9492537313432836, 'NAME': 0.8432835820895522, 'STRING': 1.0, 'NUMBER': 0.9940298507462687, 'KEYWORD': 0.9597014925373134}
Clustering threshold:0.8
The number of independent neurons:192
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9537313432835821, 'NAME': 0.9104477611940298, 'STRING': 0.9985074626865672, 'NUMBER': 0.9776119402985075, 'KEYWORD': 0.9283582089552239}
Clustering threshold:0.9
The number of independent neurons:4
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.41194029850746267, 'NAME': 0.46417910447761196, 'STRING': 0.44776119402985076, 'NUMBER': 0.34328358208955223, 'KEYWORD': 0.3925373134328358}
The best accuracy is: 0.9604477611940299
The corresponding number of neurons:5376
The corresponding number of neuron percentage reduction is: 0.0
The corresponding clustering threshold is :-1

probe independent neurons based on all layers without clustering (run_max_features.py)
Based on all layers: from 0 to 6, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is 112
The performance is {'model_name': 'pretrained_CodeBERTa', 'best_l1': 0, 'best_l2': 0.1, 'scores': {'__OVERALL__': 0.9384328358208955, 'NAME': 0.9537313432835821, 'STRING': 0.9940298507462687, 'NUMBER': 0.982089552238806, 'KEYWORD': 0.8238805970149253}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}}

Probeless:
Based on all layers, from 0 to 6, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is :344
The performance is :{'model_name': 'pretrained_CodeBERTa', 'best_l1': 0, 'best_l2': 0.01, 'scores': {'__OVERALL__': 0.9212686567164179, 'NAME': 0.9567164179104478, 'STRING': 0.9985074626865672, 'NUMBER': 0.9895522388059701, 'KEYWORD': 0.7402985074626866}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}}
----------------------------------------------------------------
