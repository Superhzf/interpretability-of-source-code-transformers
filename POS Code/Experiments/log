Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations_train.json...
18631 13.0
Number of tokens:  178060
length of source dictionary:  11293
length of target dictionary:  47
178060
Total instances: 178060
['b64encode', 'tz', 'onActionChanged', 'dest_target', 'assertEqual', 'network_dst', 'hexdigest', 'not', 'xhtml2pdf', 'sidx', 'async', 'real_otp', 'callback', 'clk', 'visOnly', '_handle_data_files', '"utf-8"', 'ThumbnailCollectionCleaner', 'remove_id', 'setFormatter']
Number of samples:  178060
Stats: Labels with their frequencies in the final set
NAME 57368
NEWLINE 16160
DOT 14150
LPAR 13520
RPAR 12905
KEYWORD 12689
COMMA 10924
EQUAL 9056
COLON 6561
DEDENT 4980
INDENT 4028
NUMBER 2833
LSQB 2738
RSQB 2621
NL 2471
STRING 1386
LBRACE 658
RBRACE 486
EQEQUAL 473
PLUS 403
STAR 271
MINUS 243
PERCENT 230
DOUBLESTAR 182
AT 126
PLUSEQUAL 114
GREATER 94
NOTEQUAL 80
LESS 59
SLASH 43
LESSEQUAL 37
LEFTSHIFT 33
COMMENT 26
GREATEREQUAL 26
SEMI 20
VBAR 16
ELLIPSIS 13
MINEQUAL 11
AMPER 7
TILDE 7
STAREQUAL 4
ERRORTOKEN 2
VBAREQUAL 2
RIGHTSHIFT 1
SLASHEQUAL 1
DOUBLESLASH 1
AMPEREQUAL 1
pretrained_BERT distribution after trauncating:
{0: 0.7723625397167322, 3: 0.17083580160482525, 2: 0.038141526199579945, 1: 0.01866013247886262}
{0: 57368, 3: 12689, 2: 2833, 1: 1386}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from bert_activations_test.json...
12298 13.0
Number of tokens:  135612
length of source dictionary:  7337
length of target dictionary:  46
135612
Total instances: 135612
['vbox', 'r1', 'warn_inplace', 'assertEqual', '0.97', 'c_', 'not', 'NO_DEFAULT', 'test__merge', 'areaRatio', '"utf-8"', 'TestSegment', '_buildMatchDict', 'tweets', 'setFormatter', 'upcast', 'data_as', 'correctY', 'teY', 'visited']
Number of samples:  135612
Stats: Labels with their frequencies in the final set
NAME 43640
NEWLINE 10994
DOT 10330
COMMA 9933
LPAR 9495
RPAR 9310
KEYWORD 7672
EQUAL 6858
NUMBER 5265
LSQB 3797
RSQB 3767
COLON 3664
DEDENT 2755
INDENT 2408
NL 1303
STRING 710
STAR 640
PLUS 616
MINUS 534
EQEQUAL 373
SLASH 273
LBRACE 187
RBRACE 174
PERCENT 122
DOUBLESTAR 119
PLUSEQUAL 97
GREATER 93
AT 85
NOTEQUAL 83
GREATEREQUAL 52
COMMENT 49
LESS 45
LESSEQUAL 31
MINEQUAL 24
STAREQUAL 21
SEMI 21
DOUBLESLASH 18
AMPER 10
LEFTSHIFT 9
VBAR 9
SLASHEQUAL 7
TILDE 7
ELLIPSIS 5
RIGHTSHIFT 4
CIRCUMFLEX 2
VBAREQUAL 1
pretrained_BERT distribution after trauncating:
{0: 0.761778413950809, 3: 0.1339221812976766, 2: 0.09190566795258959, 1: 0.012393736798924712}
{0: 43640, 3: 7672, 2: 5265, 1: 710}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 1201, 2: 1201, 1: 1125, 3: 1101})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({1: 231, 2: 211, 0: 211, 3: 211})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}

The shape of the training set: (3933, 9984)
The shape of the validation set: (695, 9984)
The shape of the testing set: (864, 9984)
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0008
Epoch: [2/10], Loss: 0.0000
Epoch: [3/10], Loss: 0.0000
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0000
Epoch: [10/10], Loss: 0.0000
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0009
Epoch: [2/10], Loss: 0.0000
Epoch: [3/10], Loss: 0.0000
Epoch: [4/10], Loss: 0.0000
Epoch: [5/10], Loss: 0.0000
Epoch: [6/10], Loss: 0.0000
Epoch: [7/10], Loss: 0.0000
Epoch: [8/10], Loss: 0.0000
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0005
Score (accuracy) of the probe: 0.96
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0010
Epoch: [2/10], Loss: 0.0002
Epoch: [3/10], Loss: 0.0002
Epoch: [4/10], Loss: 0.0006
Epoch: [5/10], Loss: 0.0010
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0020
Epoch: [2/10], Loss: 0.0013
Epoch: [3/10], Loss: 0.0011
Epoch: [4/10], Loss: 0.0010
Epoch: [5/10], Loss: 0.0008
Epoch: [6/10], Loss: 0.0008
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0008
Epoch: [9/10], Loss: 0.0010
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 0.95

The best l1=0, the best l2=0 for pretrained_BERT
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.78
{'__OVERALL__': 0.7777777777777778, 'NAME': 0.5639810426540285, 'STRING': 1.0, 'NUMBER': 0.6824644549763034, 'KEYWORD': 0.8436018957345972}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:119,KW_NAME:33
NAME_KW:0,KW_KW:178
NAME_STRING:54,KW_other:0
NAME_NUMBER:38
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'x', 'x', 'X', 'h', 'c', 'W', 'X', 'W', 'h', 'h', 'W', 'U', 'X', 'W', 'h', 'X', 'W', 'h', 'X', 'W', 'h', 'h', 'h', 'W', 'X', 'W', 'h', 'X', 'W', 'h', 'x', 'X', 'X', 'x', 'a', 'a', 'a', 'a', 'i', 'i', 'j', 'x', 'j', 'j', 'x', 'i', 'i', 'i', 'i']
NAME_NUMBER_list:['X', 'X', 'x', 'x', 'h0', 'h0', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'k', 'x', 'x', 'x']
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 0
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0042
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0039
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0049
Epoch: [2/10], Loss: 0.0018
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 0.99

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_0
Accuracy on the test set of probing pretrained_BERT_layer_0 of all layers:
Score (accuracy) of the probe: 0.66
{'__OVERALL__': 0.6550925925925926, 'NAME': 0.6161137440758294, 'STRING': 1.0, 'NUMBER': 0.957345971563981, 'KEYWORD': 0.014218009478672985}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:130,KW_NAME:208
NAME_KW:8,KW_KW:3
NAME_STRING:31,KW_other:0
NAME_NUMBER:42
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'W', 'W', 'W', 'T', 'U', 'W', 'W', 'T', 'W', 'W', 'T', 'U', 'T', 's', 's', 'a', 'a', 'T', 'T', 'a', 'i', 'i', 'i', 'i', 'i', 'i']
NAME_NUMBER_list:['x', 'W2', 'X', 'X', 'X', 'x', 'h0', 'h0', 'h0', 'W1', 'W2', 'V2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x']
Accuracy on the test set of pretrained_BERT_layer_0 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 1
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0044
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0043
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0008
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0052
Epoch: [2/10], Loss: 0.0017
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0.001 for pretrained_BERT_layer_1
Accuracy on the test set of probing pretrained_BERT_layer_1 of all layers:
Score (accuracy) of the probe: 0.63
{'__OVERALL__': 0.6284722222222222, 'NAME': 0.46445497630331756, 'STRING': 1.0, 'NUMBER': 0.985781990521327, 'KEYWORD': 0.02843601895734597}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:98,KW_NAME:205
NAME_KW:1,KW_KW:6
NAME_STRING:76,KW_other:0
NAME_NUMBER:36
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'a', 'h', 'W', 'U', 'T', 'W', 'T', 'h', 'U', 'T', 'c', 'h', 'W', 'U', 'T', 'T', 'W', 'T', 'h', 'U', 'T', 'W', 'T', 'h', 'U', 'T', 'W', 'T', 'h', 'U', 'h', 'h', 'W', 'U', 'T', 'T', 'W', 'T', 'h', 'U', 'T', 'W', 'T', 'h', 'U', 'T', 'T', 't', 't', 'W1', 'W2', 'd', 'd', 's', 's', 'a', 'a', 'T', 'a', 'T', 'a', 'i', 'i', 'i', 'i', 'i', 't', 'i', 'i', 'i', 'i']
NAME_NUMBER_list:['W1', 'V1', 'h0', 'h0', 'V1', 'V2', 'x2', 'o', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2']
Accuracy on the test set of pretrained_BERT_layer_1 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 2
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0039
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0039
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0042
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0056
Epoch: [2/10], Loss: 0.0018
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_2
Accuracy on the test set of probing pretrained_BERT_layer_2 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.8182870370370371, 'NAME': 0.5118483412322274, 'STRING': 1.0, 'NUMBER': 0.9289099526066351, 'KEYWORD': 0.8151658767772512}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:108,KW_NAME:39
NAME_KW:7,KW_KW:172
NAME_STRING:57,KW_other:0
NAME_NUMBER:39
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'a', 'x', 'x', 'X', 'c', 'X', 'U', 'c', 'X', 'U', 'X', 'U', 'X', 'U', 'X', 'U', 'X', 'U', 'X', 'U', 'X', 'U', 'x', 'x', 'p', 'p', 'p', 'p', 'p', 'X', 'X', 'd', 'x', 'x', 'a', 'a', 'a', 'a', 'i', 'i', 'x', 'j', 'j', 'x', 'x', 'x', 'x', 'i', 'i', 'y', 'i', 'i']
NAME_NUMBER_list:['V1', 'b', 'x', 'h0', 'h0', 'V1', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x', 'x', 'k', 'x']
Accuracy on the test set of pretrained_BERT_layer_2 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 3
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0043
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0041
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0044
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0048
Epoch: [2/10], Loss: 0.0017
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_3
Accuracy on the test set of probing pretrained_BERT_layer_3 of all layers:
Score (accuracy) of the probe: 0.77
{'__OVERALL__': 0.7743055555555556, 'NAME': 0.43601895734597157, 'STRING': 1.0, 'NUMBER': 0.8957345971563981, 'KEYWORD': 0.7440758293838863}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:92,KW_NAME:54
NAME_KW:1,KW_KW:157
NAME_STRING:39,KW_other:0
NAME_NUMBER:79
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'x', 'x', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'p', 'p', 'p', 'p', 'p', 'p', 'd', 's', 's', 'o', 'a', 'a', 'a', 'i', 'i', 'i', 'i', 'j', 'x', 'i', 'i', 'i', 'i']
NAME_NUMBER_list:['W1', 'V1', 'W2', 'V2', 'X', 'c', 'b', 'X', 'h', 'b', 'c', 'c', 'X', 'b', 'X', 'b', 'X', 'X', 'X', 'b', 'X', 'b', 'X', 'x', 'x', 'h0', 'x', 'h0', 'W1', 'V1', 'W2', 'V2', 'X', 'X', 'x2', 'x', 'x', 'o', 'e', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'b', 'b', 'b', 'x', 'x', 'x', 'k', 'x', 'x', 'x', 'x']
Accuracy on the test set of pretrained_BERT_layer_3 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 4
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0045
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0049
Epoch: [2/10], Loss: 0.0017
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_4
Accuracy on the test set of probing pretrained_BERT_layer_4 of all layers:
Score (accuracy) of the probe: 0.83
{'__OVERALL__': 0.8321759259259259, 'NAME': 0.5734597156398105, 'STRING': 1.0, 'NUMBER': 0.9146919431279621, 'KEYWORD': 0.8246445497630331}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:121,KW_NAME:37
NAME_KW:1,KW_KW:174
NAME_STRING:23,KW_other:0
NAME_NUMBER:66
NAME_STRING_list:['a', 'a', 'a', 'x', 'p', 'p', 'p', 'p', 'p', 'p', 'o', 'o', 'a', 'a', 'a', 'i', 'i', 'k', 'x', 'i', 'i', 'i', 'i']
NAME_NUMBER_list:['x', 'X', 'c', 'b', 'X', 'b', 'c', 'X', 'b', 'X', 'b', 'X', 'b', 'X', 'X', 'b', 'X', 'X', 'x', 'x', 'h0', 'x', 'h0', 'X', 'X', 'x2', 'x', 'x', 'o', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'b', 'x', 'x', 'x', 'x', 'x', 'x', 'x']
Accuracy on the test set of pretrained_BERT_layer_4 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 5
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0047
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0050
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0043
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0051
Epoch: [2/10], Loss: 0.0017
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_5
Accuracy on the test set of probing pretrained_BERT_layer_5 of all layers:
Score (accuracy) of the probe: 0.79
{'__OVERALL__': 0.7893518518518519, 'NAME': 0.4265402843601896, 'STRING': 1.0, 'NUMBER': 0.8672985781990521, 'KEYWORD': 0.8436018957345972}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:90,KW_NAME:33
NAME_KW:2,KW_KW:178
NAME_STRING:42,KW_other:0
NAME_NUMBER:77
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'x', 'W', 'W', 'c', 'W', 'T', 'W', 'h', 'T', 'W', 'h', 'W', 'W', 'h', 'p', 'p', 't', 'p', 'p', 'p', 'p', 'p', 'p', 's', 's', 'x', 'a', 'a', 'i', 'i', 'j', 'j', 'x', 'i', 'i', 'i', 'i']
NAME_NUMBER_list:['x', 'V1', 'V2', 'X', 'h', 'c', 'U', 'b', 'X', 'h', 'U', 'b', 'X', 'h', 'b', 'X', 'X', 'X', 'X', 'h', 'b', 'X', 'X', 'x', 'x', 'h0', 'x', 'h0', 'W1', 'V1', 'W2', 'V2', 'X', 'X', 'x2', 'x', 'o', 'e', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'b', 'a', 'b', 'x', 'x', 'x', 'x', 'x', 'x', 'x']
Accuracy on the test set of pretrained_BERT_layer_5 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 6
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0038
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0038
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0050
Epoch: [2/10], Loss: 0.0017
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_6
Accuracy on the test set of probing pretrained_BERT_layer_6 of all layers:
Score (accuracy) of the probe: 0.80
{'__OVERALL__': 0.7974537037037037, 'NAME': 0.41706161137440756, 'STRING': 1.0, 'NUMBER': 0.9052132701421801, 'KEYWORD': 0.8483412322274881}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:88,KW_NAME:32
NAME_KW:3,KW_KW:179
NAME_STRING:28,KW_other:0
NAME_NUMBER:92
NAME_STRING_list:['m', 'm', 'm', 'a', 'a', 'x', 'h', 'h', 'h', 'p', 'x', 'p', 'p', 'p', 'p', 'p', 'p', 'a', 'a', 'i', 'i', 'j', 'j', 'x', 'i', 'i', 'i', 'i']
NAME_NUMBER_list:['x', 'W1', 'V1', 'W2', 'V2', 'X', 'h', 'c', 'U', 'b', 'X', 'h', 'U', 'b', 'c', 'c', 'X', 'h', 'U', 'b', 'X', 'X', 'X', 'X', 'h', 'U', 'b', 'X', 'h', 'X', 'x', 'x', 'h0', 'h0', 't', 'h0', 'W1', 'V1', 'W2', 'V2', 'X', 'X', 'x2', 'x', 'x', 'o', 'e', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'a', 'b', 'a', 'b', 'b', 'x', 'x', 'k', 'x', 'k', 'x', 'x', 'x', 'x', 'x', 't']
Accuracy on the test set of pretrained_BERT_layer_6 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 7
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0042
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0042
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0039
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0050
Epoch: [2/10], Loss: 0.0016
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0.01 for pretrained_BERT_layer_7
Accuracy on the test set of probing pretrained_BERT_layer_7 of all layers:
Score (accuracy) of the probe: 0.78
{'__OVERALL__': 0.7835648148148148, 'NAME': 0.3744075829383886, 'STRING': 1.0, 'NUMBER': 0.8957345971563981, 'KEYWORD': 0.8436018957345972}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:79,KW_NAME:33
NAME_KW:1,KW_KW:178
NAME_STRING:40,KW_other:0
NAME_NUMBER:91
NAME_STRING_list:['m', 'm', 'm', 'a', 'x', 'x', 'h', 'c', 'W', 'X', 'T', 'U', 'T', 'X', 'h', 'U', 'T', 'X', 'h', 'U', 'T', 'X', 'T', 'X', 'h', 'U', 'p', 'T', 't', 't', 'p', 'd', 's', 'x', 'e', 'j', 'j', 'i', 'i', 'i']
NAME_NUMBER_list:['a', 'W1', 'V1', 'W2', 'V2', 'X', 'U', 'b', 'h', 'U', 'c', 'c', 'X', 'h', 'U', 'b', 'X', 'X', 'h', 'U', 'b', 'x', 'p', 'x', 'h0', 'x', 'h0', 'p', 'W1', 'p', 'V1', 'p', 'W2', 'p', 'V2', 'p', 'X', 'X', 'x2', 'x', 'o', 'o', 'o', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'a', 'b', 'a', 'a', 'a', 'b', 'i', 'i', 'x', 'j', 'k', 'k', 'x', 'x', 'x', 'o', 'x', 't', 'x', 'i']
Accuracy on the test set of pretrained_BERT_layer_7 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 8
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0035
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0001
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0035
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0045
Epoch: [2/10], Loss: 0.0016
Epoch: [3/10], Loss: 0.0014
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_8
Accuracy on the test set of probing pretrained_BERT_layer_8 of all layers:
Score (accuracy) of the probe: 0.85
{'__OVERALL__': 0.8483796296296297, 'NAME': 0.6208530805687204, 'STRING': 1.0, 'NUMBER': 0.909952606635071, 'KEYWORD': 0.8483412322274881}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:131,KW_NAME:32
NAME_KW:0,KW_KW:179
NAME_STRING:14,KW_other:0
NAME_NUMBER:66
NAME_STRING_list:['m', 'm', 'm', 'a', 'U', 'U', 'U', 'x', 'a', 'a', 'a', 'i', 'i', 'i']
NAME_NUMBER_list:['x', 'W1', 'V1', 'X', 'c', 'W', 'b', 'X', 'X', 'b', 'X', 'X', 'X', 'X', 'U', 'b', 'X', 'X', 'x', 'x', 'h0', 'h0', 'W1', 'X', 'X', 'x2', 'x', 'x', 'o', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'b', 'a', 'b', 'b', 'x', 'k', 'x', 'x', 'x', 'x', 'i']
Accuracy on the test set of pretrained_BERT_layer_8 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 9
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0004
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0001
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0004
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0001
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0035
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0049
Epoch: [2/10], Loss: 0.0015
Epoch: [3/10], Loss: 0.0014
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_9
Accuracy on the test set of probing pretrained_BERT_layer_9 of all layers:
Score (accuracy) of the probe: 0.84
{'__OVERALL__': 0.84375, 'NAME': 0.5971563981042654, 'STRING': 0.9956709956709957, 'NUMBER': 0.9241706161137441, 'KEYWORD': 0.8436018957345972}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:126,KW_NAME:33
NAME_KW:5,KW_KW:178
NAME_STRING:28,KW_other:0
NAME_NUMBER:52
NAME_STRING_list:['h', 'W', 'U', 'W', 'h', 'h', 'W', 'U', 'W', 'h', 'W', 'h', 'W', 'h', 'h', 'W', 'U', 'W', 'W', 'W1', 'o', 'o', 'o', 'a', 'a', 'i', 'i', 'i']
NAME_NUMBER_list:['m', 'm', 'm', 'x', 'x', 'X', 'b', 'X', 'X', 'b', 'X', 'X', 'X', 'X', 'b', 'X', 'X', 'x', 'x', 'h0', 'x', 'X', 'x', 'x', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'b', 'b', 'b', 'k', 'x', 'x']
Accuracy on the test set of pretrained_BERT_layer_9 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 10
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0035
Epoch: [2/10], Loss: 0.0004
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0001
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0041
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0045
Epoch: [2/10], Loss: 0.0015
Epoch: [3/10], Loss: 0.0014
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_10
Accuracy on the test set of probing pretrained_BERT_layer_10 of all layers:
Score (accuracy) of the probe: 0.83
{'__OVERALL__': 0.8321759259259259, 'NAME': 0.5497630331753555, 'STRING': 0.9956709956709957, 'NUMBER': 0.9241706161137441, 'KEYWORD': 0.8436018957345972}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:116,KW_NAME:33
NAME_KW:1,KW_KW:178
NAME_STRING:6,KW_other:0
NAME_NUMBER:88
NAME_STRING_list:['a', 'h', 'X', 'p', 'p', 'a']
NAME_NUMBER_list:['m', 'm', 'm', 'x', 'x', 'T', 'X', 'c', 'W', 'U', 'b', 'X', 'W', 'b', 'c', 'c', 'X', 'W', 'U', 'b', 'X', 'X', 'X', 'X', 'W', 'U', 'b', 'X', 'x', 'p', 'x', 'h0', 'x', 't', 't', 'X', 'X', 'x', 'x', 'o', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'a', 'b', 'T', 'a', 'b', 'a', 'b', 'i', 'i', 'x', 'x', 'k', 'x', 'k', 'x', 'x', 't', 'x', 't', 'x', 't', 'i', 'i']
Accuracy on the test set of pretrained_BERT_layer_10 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 11
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0037
Epoch: [2/10], Loss: 0.0005
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0001
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0036
Epoch: [2/10], Loss: 0.0004
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0002
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0001
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0045
Epoch: [2/10], Loss: 0.0015
Epoch: [3/10], Loss: 0.0014
Epoch: [4/10], Loss: 0.0013
Epoch: [5/10], Loss: 0.0012
Epoch: [6/10], Loss: 0.0012
Epoch: [7/10], Loss: 0.0011
Epoch: [8/10], Loss: 0.0011
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0010
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_11
Accuracy on the test set of probing pretrained_BERT_layer_11 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.8194444444444444, 'NAME': 0.5260663507109005, 'STRING': 1.0, 'NUMBER': 0.8909952606635071, 'KEYWORD': 0.8436018957345972}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:111,KW_NAME:33
NAME_KW:4,KW_KW:178
NAME_STRING:19,KW_other:0
NAME_NUMBER:77
NAME_STRING_list:['a', 'a', 'X', 'X', 'h', 'X', 'h', 'X', 'h', 'X', 'h', 'X', 'p', 'W1', 'p', 'p', 'p', 'p', 'x']
NAME_NUMBER_list:['m', 'm', 'm', 'x', 'X', 'h', 'c', 'W', 'U', 'b', 'W', 'U', 'c', 'c', 'X', 'b', 'h', 'X', 'U', 'b', 'x', 'p', 'x', 'h0', 'x', 'h0', 'p', 'p', 'X', 'X', 'x', 'x', 'o', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'i', 'i', 'j', 'x', 'j', 'j', 'k', 'x', 'x', 'x', 'o', 'x', 't', 't', 'x', 'i', 'i', 'i']
Accuracy on the test set of pretrained_BERT_layer_11 model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT Layer 12
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0039
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0042
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0002
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0004
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0003
Epoch: [9/10], Loss: 0.0003
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0048
Epoch: [2/10], Loss: 0.0016
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0012
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_layer_12
Accuracy on the test set of probing pretrained_BERT_layer_12 of all layers:
Score (accuracy) of the probe: 0.82
{'__OVERALL__': 0.8194444444444444, 'NAME': 0.5071090047393365, 'STRING': 1.0, 'NUMBER': 0.919431279620853, 'KEYWORD': 0.8341232227488151}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:107,KW_NAME:32
NAME_KW:4,KW_KW:176
NAME_STRING:19,KW_other:3
NAME_NUMBER:81
NAME_STRING_list:['a', 'a', 'a', 'U', 'b', 'p', 'p', 'o', 'a', 'a', 'a', 'a', 'i', 'j', 'x', 'j', 'j', 'o', 'i']
NAME_NUMBER_list:['m', 'm', 'm', 'x', 'x', 'X', 'h', 'c', 'W', 'X', 'W', 'h', 'c', 'c', 'X', 'W', 'X', 'h', 'X', 'h', 'h', 'X', 'W', 'X', 'h', 'x', 'p', 'x', 'h0', 'h0', 't', 'W1', 'V1', 'p', 'p', 'W2', 'V2', 'p', 'X', 'd', 'd', 'x', 'x', 'o', 'o', 'e', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'b', 'b', 'b', 'i', 'i', 'j', 'j', 'k', 'x', 'x', 'x', 'i', 'i']
Accuracy on the test set of pretrained_BERT_layer_12 model using the intercept:
Score (accuracy) of the probe: 0.24

pretrained_BERT top neurons
array([4098, 4104,   18, 2068, 8213,   32, 4132, 8228,   48,   50, 6199,
       8250, 6202, 2110,   68, 6216, 8265,   80, 6228, 2132, 8276,   87,
       6237, 8287,   96, 8288,   98, 4194, 2149, 8296, 2157, 8302, 4206,
        115,  124, 4221, 6269, 6271, 8328,  138, 2190, 4239, 6293,  151,
       2202, 6300, 4252, 2206,  162, 6310, 2216, 6313, 6321, 4276,  184,
       6328, 6330,  192, 6340, 8389, 6342, 2250,  215, 4312, 4319, 2272,
       6369, 8416, 2301, 8446,  254, 2306, 6404,  260, 6407,  265,  269,
       8462, 4370,  275,  277, 4373,  280, 6428, 4382,  293, 4393,  300,
       8495, 6447, 2353,  308, 8509,  318, 2369, 8514,  324, 4422, 8519,
       8520,  328,  332,  335, 8532, 6493,  350, 2397, 2402, 4453, 2405,
       4458, 8555, 6512, 4464, 8562,  371, 8567, 8573, 8574, 2431, 8576,
       4483, 4490, 2443, 8594, 8596, 2455, 6559, 4512, 8614,  425, 4522,
        429, 4529, 6577, 6580, 4533,  439, 2489,  444, 4541,  447,  448,
        450, 8643, 8646, 2505, 6604,  465,  472, 6620, 6624, 8680, 8681,
       2536, 4590, 6640, 8692, 6646,  502,  507, 4608, 4610, 8708, 8712,
       6670, 4623, 4624, 6677, 8727,  537, 2585, 6686, 8740,  552, 8751,
       2609,  561, 8757, 8764, 8767, 8770,  579, 8777,  587, 8781,  596,
       2645, 6746, 8795, 2653, 8798, 4701, 6758, 6760, 2666, 8828,  640,
       6785, 2688,  643,  644, 2693,  646, 6787, 2698, 2703, 2710, 2712,
       4764,  669, 6818,  675, 8867,  681, 8875, 8884, 2740, 4792, 8888,
       4794, 6845,  708, 4806,  712, 2761, 8905, 8909, 6876, 2781, 6880,
       6881, 4840, 8943, 2800, 4847, 2806, 2812, 6911, 6912,  770,  774,
       4872,  779, 8971, 6930,  786, 2837, 4885, 2842, 6939, 2857, 2859,
       4911,  816, 9013, 2878, 6976, 6980,  836, 2887, 6984, 9033, 4936,
        841, 9044, 2900, 9047,  858, 2909, 4962, 2917, 4971, 4974,  893,
       7039, 4993, 4997, 2954, 5007,  913, 7058, 7060, 2970, 9115, 7068,
       7078, 5031, 7088, 7096,  952, 7098, 3003, 9149,  962,  964, 7108,
       3015, 3016, 7113,  969, 9164, 5069, 9173,  989, 5088,  993,  994,
       9197, 3054, 5103, 3059, 1019, 3071, 9218, 3074, 7174, 7176, 3084,
       1038, 9230, 9232, 1041, 3087, 1040, 7188, 3095, 7196, 1054, 5153,
       7202, 5154, 7205, 9254, 5161, 3118, 1071, 1073, 1075, 7221, 1086,
       5185, 1093, 7241, 3147, 1101, 9295, 1106, 3157, 1110, 5209, 9308,
       5213, 7260, 7266, 3172, 5223, 9320, 1128, 9329, 1139, 7286, 1152,
       1157, 7304, 5258, 5259, 5261, 5263, 1167, 3215, 9364, 3228, 7326,
       1191, 3244, 7340, 9390, 7348, 5301, 3256, 5309, 9406, 7363, 3267,
       9411, 3273, 9418, 9419, 3276, 7377, 7378, 1236, 1237, 1239, 5342,
       9445, 9450, 9451, 1262, 7407, 3311, 3323, 1276, 7420, 5376, 9476,
       3333, 3339, 9491, 1300, 1299, 1301, 1304, 5404, 9500, 9502, 1316,
       3364, 9527, 9528, 7487, 9539, 5456, 3418, 1373, 7519, 9571, 5476,
       7528, 1386, 3434, 7536, 5490, 3446, 7553, 3460, 7566, 9615, 1424,
       9616, 1426, 1434, 9631, 1445, 1451, 3503, 5562, 9660, 5571, 5574,
       9673, 1482, 3529, 3533, 1486, 9681, 1489, 1493, 3552, 9699, 3561,
       5610, 7663, 5627, 1538, 5636, 7686, 3599, 7698, 3605, 3608, 7708,
       1564, 3613, 5668, 7720, 1578, 1595, 3646, 3649, 9801, 7753, 9815,
       9817, 5722, 7770, 3677, 1634, 9832, 7787, 3701, 7805, 7806, 3719,
       7823, 5775, 3730, 7826, 7837, 1695, 7846, 3752, 5803, 1710, 7856,
       3761, 3760, 5812, 1717, 1720, 9917, 3773, 1727, 5826, 1733, 1741,
       3790, 5841, 9947, 7912, 7913, 7914, 5870, 5871, 9976, 7929, 1787,
       5884, 3839, 3842, 1794, 3845, 7944, 3852, 3855, 7957, 5909, 7959,
       1818, 7970, 7979, 3886, 1839, 1841, 7999, 1857, 3908, 5959, 8009,
       3915, 1869, 1871, 5968, 1880, 5979, 1885, 8034, 3940, 5989, 5991,
       5997, 8054, 1919, 3972, 1925, 6022, 8072, 8079, 6033, 3996, 6056,
       1966, 1972, 6068, 1974, 8124, 6077, 1987, 4041, 2004, 6101, 2005,
       2021, 6129, 2038, 8182, 2046])
pretrained_BERT top neurons per class
{'NAME': array([2004, 2216, 7553, 7914, 9615, 7959, 6369, 7806,  579,  644, 2609,
       1451, 5088, 1424, 6624, 7823, 1073, 8727, 6129, 4590, 8446,  994,
       3608, 9801, 8770, 4319, 9390, 1710, 9047, 1841, 8909,  124, 1925,
       8680,  669, 5775,  192, 2038, 5722, 2068, 7686,   50, 8875, 1741,
       9491,  277,   98, 2712, 3054, 9164, 4276, 3730, 1717, 4239, 7698,
        779, 6785, 8798, 4312, 2812, 8532, 4840, 3649, 1727, 1139, 6493,
       9418, 9528, 5997, 1236, 9451, 4529,  265,  450, 5968, 1818, 1157,
       5007, 6930, 1373, 9660,  675, 1239,   32, 2301, 5223, 7039, 3147,
        913, 1880, 4221, 7377, 3886, 6876, 1987, 8302,   96, 4533,  275,
       3118, 1300, 8574, 7708, 3915, 3323, 2190, 4522, 9254, 5404, 8596,
       4971, 3418, 4194, 1038, 2693, 3761, 9631,  962, 2806,   80, 7221,
       6199, 7378, 3333, 8567, 1110, 4962, 1041,  774, 7326, 7720, 5263,
       3908, 8509, 6980, 9197, 5301, 6293, 3003, 6881, 6512, 4370, 9033,
       5610, 5991, 1075, 2157, 9013,  646,  439, 3503, 7912, 2842, 1299,
       8265, 6577]), 'STRING': array([1787, 3677, 7241, 6300,  450, 4541, 5309, 3016, 5574,  681, 2909,
       6269,  280, 9917, 7566, 8594,  371, 1276, 9115, 4041, 9149, 3561,
       9500, 2800, 6271, 1101, 2878, 3761, 1972, 1426,  465, 1857, 7753,
       8943, 7113, 7286, 7420, 2954,  350, 3790, 3273, 2431,  786, 6845,
       6984,  254, 1966, 6321, 3773, 2505, 9230, 1493, 4764,  712, 5258,
       7407, 9616, 6404, 1482,  816, 7188, 6646,  318, 7039, 5161, 8462,
        335, 8884, 4997, 6216, 8182, 3972, 6022, 6077, 3503, 6101, 1019,
       8054, 7058,   50, 1871, 7205, 2250, 8777, 2812,  893, 1486,  969,
       8573, 6428,  964, 1071, 8681, 3446, 7913, 4872, 4453, 9947, 8296,
       7068, 2857, 8009, 2740, 4847, 5213, 4490, 6559, 3311, 4098,  162,
       5959,   48, 7805, 1869, 5153, 4624, 2353, 3157, 7174,  324,  447,
       9364, 4393, 1316,  308, 7202, 3646, 8288, 8520,  269, 2405, 7348,
       3996, 1301, 5884, 8328, 4623, 9173,  537, 3855, 1919]), 'NUMBER': array([7096, 6228, 7078, 7846, 7348, 3605, 8712, 7837,  184, 8614, 7188,
       4872, 7826, 6686, 4373, 9218, 8287, 1885,  770, 4792, 3852, 8034,
       2306, 1839, 7176,   68, 2110, 7266, 1538,  300, 6310, 1445, 3842,
       3074, 5636, 7519, 1720, 2698, 4806, 7770, 3276, 7663, 6330, 2005,
       8213, 8519, 8072, 1695, 1733, 1237, 4104, 8594, 9044,  215, 8767,
       9232, 2653, 2206,  681, 7304, 8888, 5103, 6640, 2837, 6328, 8751,
       7060, 6746, 9308,   18, 3719, 4453, 8646, 6559, 5871, 7944, 6342,
       1794, 5989, 3839, 1262, 9502, 7536, 6939, 3059, 4610,  138, 2149,
       7108, 4382,  952, 8708,  893,  425,  836, 5154, 4936,  328, 2443,
       6604, 8692, 4974, 3244, 9571, 7528, 2917, 7979,  260, 9476, 3228,
       8250, 6818, 3084, 7970, 6340, 3256, 6758, 5812, 7856, 7196, 7553,
       9832,  841, 5069,   50, 9681, 8764, 2489, 1054, 6760, 7999, 5841,
       7088,  293, 9976, 1086, 4041, 3071, 9230, 5456, 5826, 4098, 5803,
       4206, 4464, 3996, 6911]), 'KEYWORD': array([7363, 3364, 8389,  708,  643, 1987, 4132, 1564, 1489, 9673, 3613,
       8079, 9450, 2970, 3095, 9320, 1434, 7957, 5376, 3533, 6787, 7098,
       8828,  332, 5261, 9329, 4458, 5668, 2132, 7487,  993, 3267, 3323,
       3529, 2202, 6313, 6056, 2703, 8576, 3760, 6912,  444, 5979, 6202,
       5476, 8276, 5627, 3752, 4911, 2645, 9406, 6677, 1386, 1128, 8867,
       3172, 8124, 1093, 5870,  640, 2397, 9527, 9295, 4252, 3599, 1974,
        552, 4993, 2710, 6580, 2688, 9411, 4422, 5909, 2740, 2585, 2859,
       2536, 3552, 5490, 5342, 6880,  429, 2216, 3087, 3701, 4885, 2272,
       2369, 9539, 1106, 7260, 1152, 2761, 8740, 5185, 6670, 8555, 1304,
       8905, 6407,  151, 8495, 9445,  587,  507,  448, 2900, 3460, 9419,
        989, 6447, 7698,  561, 5562, 2666, 4483, 4608, 2887, 1167, 8781,
        115, 7340,  596, 2402, 6620, 4794, 3434, 9817, 2781, 9699, 6976,
       8562,  472, 1040, 5259, 4962, 1191, 8514, 3339, 4512, 1595, 5571,
       6068, 8643, 8971, 6237, 9815, 8416, 8757, 3940,  502, 1578,  858,
       5209, 2046, 8228, 4701, 7929,   87, 1634, 2455, 3845, 7787,  465,
       3015, 2021, 6033, 3215, 5031, 8795])}
The shape of selected features (3933, 588)
The shape of the training set: (3933, 588)
The shape of the validation set: (695, 588)
The shape of the testing set: (864, 588)
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0044
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0004
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0040
Epoch: [2/10], Loss: 0.0006
Epoch: [3/10], Loss: 0.0003
Epoch: [4/10], Loss: 0.0003
Epoch: [5/10], Loss: 0.0002
Epoch: [6/10], Loss: 0.0002
Epoch: [7/10], Loss: 0.0001
Epoch: [8/10], Loss: 0.0001
Epoch: [9/10], Loss: 0.0001
Epoch: [10/10], Loss: 0.0001
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0007
Epoch: [3/10], Loss: 0.0005
Epoch: [4/10], Loss: 0.0004
Epoch: [5/10], Loss: 0.0003
Epoch: [6/10], Loss: 0.0003
Epoch: [7/10], Loss: 0.0003
Epoch: [8/10], Loss: 0.0002
Epoch: [9/10], Loss: 0.0002
Epoch: [10/10], Loss: 0.0002
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0046
Epoch: [2/10], Loss: 0.0016
Epoch: [3/10], Loss: 0.0015
Epoch: [4/10], Loss: 0.0014
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0013
Epoch: [7/10], Loss: 0.0012
Epoch: [8/10], Loss: 0.0012
Epoch: [9/10], Loss: 0.0011
Epoch: [10/10], Loss: 0.0011
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_top5%_mass
Accuracy on the test set of probing pretrained_BERT_top5%_mass of all layers:
Score (accuracy) of the probe: 0.86
{'__OVERALL__': 0.8587962962962963, 'NAME': 0.6492890995260664, 'STRING': 1.0, 'NUMBER': 0.919431279620853, 'KEYWORD': 0.8530805687203792}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:137,KW_NAME:31
NAME_KW:2,KW_KW:180
NAME_STRING:12,KW_other:0
NAME_NUMBER:60
NAME_STRING_list:['a', 'a', 'a', 'a', 'a', 'a', 'i', 'j', 'j', 'j', 'i', 'i']
NAME_NUMBER_list:['x', 'x', 'W1', 'V1', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'x', 'x', 'x', 'h0', 'W1', 'X', 'X', 'x2', 'x', 'x', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x']
Accuracy on the test set of pretrained_BERT_top5%_mass model using the intercept:
Score (accuracy) of the probe: 0.24
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0082
Epoch: [2/10], Loss: 0.0036
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0083
Epoch: [2/10], Loss: 0.0037
Epoch: [3/10], Loss: 0.0023
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0010
Epoch: [7/10], Loss: 0.0009
Epoch: [8/10], Loss: 0.0007
Epoch: [9/10], Loss: 0.0006
Epoch: [10/10], Loss: 0.0006
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0075
Epoch: [2/10], Loss: 0.0034
Epoch: [3/10], Loss: 0.0022
Epoch: [4/10], Loss: 0.0016
Epoch: [5/10], Loss: 0.0013
Epoch: [6/10], Loss: 0.0011
Epoch: [7/10], Loss: 0.0010
Epoch: [8/10], Loss: 0.0009
Epoch: [9/10], Loss: 0.0008
Epoch: [10/10], Loss: 0.0007
Score (accuracy) of the probe: 1.00
Training classification probe
Creating model...
Number of training instances: 3933
Number of classes: 4
Epoch: [1/10], Loss: 0.0096
Epoch: [2/10], Loss: 0.0048
Epoch: [3/10], Loss: 0.0035
Epoch: [4/10], Loss: 0.0029
Epoch: [5/10], Loss: 0.0026
Epoch: [6/10], Loss: 0.0024
Epoch: [7/10], Loss: 0.0022
Epoch: [8/10], Loss: 0.0021
Epoch: [9/10], Loss: 0.0021
Epoch: [10/10], Loss: 0.0020
Score (accuracy) of the probe: 1.00

The best l1=0, the best l2=0 for pretrained_BERT_top200_neurons
Accuracy on the test set of probing pretrained_BERT_top200_neurons of all layers:
Score (accuracy) of the probe: 0.80
{'__OVERALL__': 0.7962962962962963, 'NAME': 0.4028436018957346, 'STRING': 0.987012987012987, 'NUMBER': 0.933649289099526, 'KEYWORD': 0.8436018957345972}
Confusion matrix between NAME and KEYWORD:
NAME_NAME:85,KW_NAME:32
NAME_KW:11,KW_KW:178
NAME_STRING:35,KW_other:1
NAME_NUMBER:80
NAME_STRING_list:['T', 'T', 'T', 'T', 'T', 'T', 'b', 'T', 'T', 'W', 'b', 'T', 'T', 'T', 'b', 'T', 'T', 'W', 'T', 'b', 't', 'T', 'T', 't', 't', 'T', 'T', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 't']
NAME_NUMBER_list:['m', 'm', 'm', 'x', 'x', 'X', 'c', 'U', 'b', 'X', 'b', 'c', 'c', 'c', 'X', 'b', 'X', 'X', 'X', 'X', 'b', 'X', 'X', 'x', 'x', 'x', 'X', 'X', 'd', 'd', 'x2', 'x', 'x', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'x2', 'b', 'b', 'b', 'a', 'b', 'b', 'x', 'x', 'x', 'k', 'x', 'x', 'x', 't', 'x', 't', 'x', 't', 'x']
Accuracy on the test set of pretrained_BERT_top200_neurons model using the intercept:
Score (accuracy) of the probe: 0.24
pretrained_BERT top words
Top words for pretrained_BERT neuron indx 4098 [('2014', 1.0), ('vCard', 0.961857132381499), ('stanza', 0.6605085843152129), ('1800', 0.6460672362160466), ('unicode', 0.6296575498239722)]
Top words for pretrained_BERT neuron indx 4104 [('Distance', 1.0), ('topid', 0.8269090644541374), ('"/_"', 0.7727200144296575), ('hostname', 0.7456558606132344), ('"://"', 0.7436554616466292)]
Top words for pretrained_BERT neuron indx 18 [('300', 1.0), ('bare', 0.8926002420998989), ('ranges', 0.8665906779622802), ('400', 0.827903050290114), ('200', 0.8181755016660679)]
Top words for pretrained_BERT neuron indx 2068 [('_session', 1.0), ('__copyright__', 0.9735134562099674), ('sort_mode', 0.943767032374619), ('_user', 0.9401140332901354), ('_closed', 0.9171883793743063)]
Top words for pretrained_BERT neuron indx 8213 [('False', 1.0), ('or', 0.8955164307070728), ('digest', 0.7422496492398085), ('VerticalBillboard', 0.7270849669302827), ('42', 0.6859583452793528)]
Top words for pretrained_BERT neuron indx 32 [('Unauthorized', 1.0), ('else', 0.8955575458092072), ('horizon', 0.7426590066172467), ('Post', 0.6604698350880679), ('iq', 0.609625614236011)]
Top words for pretrained_BERT neuron indx 4132 [('policy', 1.0), ('disco_info', 0.9065970103619753), ('sconf', 0.8963603826767157), ('disco_items', 0.849490386117289), ('300', 0.8186322507182657)]
Top words for pretrained_BERT neuron indx 8228 [('"teal"', 1.0), ('"yellow"', 0.9960866908122568), ('"G"', 0.9249199302197357), ('800', 0.9183124431905195), ('"reason"', 0.9148707526910668)]
Top words for pretrained_BERT neuron indx 48 [('Register', 1.0), ('List', 0.9528400128883442), ('ping', 0.8415564482373382), ('break', 0.8004017670281225), ('ranges', 0.7947021678315361)]
Top words for pretrained_BERT neuron indx 50 [('unicode', 1.0), ('GET', 0.896586868665689), ('host', 0.82445515496891), ('boot', 0.8234885505296052), ('302', 0.809373375784017)]
Top words for pretrained_BERT neuron indx 6199 [('42', 1.0), ('1800', 0.7345762689502676), ('2150', 0.7262613316076627), ('2.1', 0.6833744942837341), ('1970', 0.6103450966380243)]
Top words for pretrained_BERT neuron indx 8250 [('"location"', 1.0), ('"T"', 0.9955247397823419), ('"Sub-category"', 0.981298098041449), ('"subcategory"', 0.976679301537504), ('"yellow"', 0.964232206881759)]
Top words for pretrained_BERT neuron indx 6202 [('Stretch', 1.0), ('1970', 0.8592745795038917), ('NoPerm', 0.8487964634416522), ('OLDPASSLEN', 0.8049717728470746), ('"restart"', 0.7980590374352643)]
Top words for pretrained_BERT neuron indx 2110 [('pass', 1.0), ('try', 0.9499194104229605), ('del', 0.9367175520335854), ('None', 0.9087852026407021), ('send', 0.8636979703342554)]
Top words for pretrained_BERT neuron indx 68 [('Billboard', 1.0), ('sans', 0.9538846191118807), ('raise', 0.8592378443780387), ('ping', 0.8164299725858091), ('class', 0.7691762146900265)]
Top words for pretrained_BERT neuron indx 6216 [('View', 1.0), ('None', 0.9785650768077239), ('oslo', 0.8692639932160202), ('boot', 0.8546377207878406), ('Session', 0.845582309755991)]
Top words for pretrained_BERT neuron indx 8265 [('oslo', 1.0), ('bare', 0.8303817308190408), ('465', 0.8288448412600543), ('IsBM', 0.7853400407149693), ('is', 0.7781448609056617)]
Top words for pretrained_BERT neuron indx 80 [('None', 1.0), ('roster', 0.9836838979710947), ('closing', 0.9466366664680068), ('None_', 0.9319048336134779), ('iq', 0.8939046471522716)]
Top words for pretrained_BERT neuron indx 6228 [('except', 1.0), ('with', 0.8741217085921229), ('settings', 0.8674856022147484), ('62', 0.7398781540936489), ('try', 0.7018207920458949)]
Top words for pretrained_BERT neuron indx 2132 [('800', 1.0), ('5', 0.8659617507181115), ('400', 0.8619982638525641), ('wait', 0.8593326498445789), ('Simple', 0.8215201578578999)]
Top words for pretrained_BERT neuron indx 8276 [('mesh2', 1.0), ('xmpp', 0.9811074548598578), ('mesh3', 0.9794271014088918), ('12', 0.9631047777986791), ('mesh1', 0.95644069137869)]
Top words for pretrained_BERT neuron indx 87 [('None', 1.0), ('15598', 0.955237820879044), ('15596', 0.9402343816959148), ('Session', 0.8784647548703617), ('getint', 0.8775725193807353)]
Top words for pretrained_BERT neuron indx 6237 [('StreamClosed', 1.0), ('View', 0.8757273337019934), ('23', 0.8365101201317547), ('"http://"', 0.8185482298160405), ('List', 0.8045871167528829)]
Top words for pretrained_BERT neuron indx 8287 [('42', 1.0), ('95', 0.8718232617429146), ('and', 0.7459140025824059), ('"in"', 0.6900814984067146), ('credential', 0.6036932057181542)]
Top words for pretrained_BERT neuron indx 96 [('sts', 1.0), ('"9200"', 0.9705994545299838), ('18', 0.8773497359092245), ('42', 0.8512232552043899), ('"100"', 0.8259658135324276)]
Top words for pretrained_BERT neuron indx 8288 [('return', 1.0), ('Tab', 0.963388178103121), ('75', 0.9233514062935061), ('class', 0.8904576814652806), ('r\\\'\\\\"\\\'', 0.8695790189341113)]
Top words for pretrained_BERT neuron indx 98 [('iq', 1.0), ('pass', 0.8087675675409071), ('baseline', 0.7711235929740237), ('LoadUser', 0.7359533625292316), ('servers', 0.7319604823411475)]
Top words for pretrained_BERT neuron indx 4194 [('42', 1.0), ('23', 0.9612844796636489), ('Distance', 0.8583069117208147), ('21', 0.7725564153693764), ('11', 0.7171228630214213)]
Top words for pretrained_BERT neuron indx 2149 [('Billboard', 1.0), ('topid', 0.7439735309980501), ('stanza', 0.6851156150253106), ('UCache', 0.6805304863713681), ('freshtime', 0.671307599252172)]
Top words for pretrained_BERT neuron indx 8296 [('to', 1.0), ('__copyright__', 0.9502107521263609), ('__license__', 0.9222980271189506), ('On', 0.9072511793578466), ('return', 0.8971427563233242)]
Top words for pretrained_BERT neuron indx 2157 [('slug', 1.0), ('oslo', 0.8875358860921181), ('wait', 0.8760157724519658), ('vcard', 0.7857208684677702), ('21', 0.7279627161031564)]
Top words for pretrained_BERT neuron indx 8302 [('"2:00:00:00"', 1.0), ('180.0', 0.9750884640520951), ('302', 0.9732060112658666), ('3600', 0.9551255739544335), ('"2010-11-12T01:02:03"', 0.9465095916312628)]
Top words for pretrained_BERT neuron indx 4206 [('with', 1.0), ('sts', 0.9981054669139744), ('31', 0.9459572543475689), ('201', 0.8776632574085121), ('2014', 0.8535892157970598)]
Top words for pretrained_BERT neuron indx 115 [('direct', 1.0), ('View', 0.9767285942631746), ('Session', 0.9406094210464195), ('session', 0.9061372383094988), ('Tab', 0.8746958982793043)]
Top words for pretrained_BERT neuron indx 124 [('300', 1.0), ('oslo', 0.972284365582365), ('31', 0.9559332310755828), ('33', 0.7642384123649519), ('horizon', 0.7353493068219987)]
Top words for pretrained_BERT neuron indx 4221 [('"0800305c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 1.0), ('"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.9904524588370288), ('with', 0.9084545232283983), ('for', 0.8920235672033977), ('"1b1f463cef1807a127af668f3a4fdcc7977c647bf2f357d9fa125f13548b1d14"', 0.8528624797867441)]
Top words for pretrained_BERT neuron indx 6269 [('proxy', 1.0), ('bare', 0.9478730336400464), ('UserManager', 0.905796098676121), ('Mesh', 0.8872638464069007), ('bootmode', 0.8525340244778415)]
Top words for pretrained_BERT neuron indx 6271 [('requests', 1.0), ('750', 0.998907384101922), ('95', 0.9680414420982035), ('"amount"', 0.8697227651401822), ('100', 0.8424626540385017)]
Top words for pretrained_BERT neuron indx 8328 [('3785', 1.0), ('204', 0.9265952734667907), ('201', 0.8871788792765557), ('probe', 0.8773692391826164), ('187', 0.8497071093952882)]
Top words for pretrained_BERT neuron indx 138 [('Off', 1.0), ('stanza', 0.9754714720393991), ('Log', 0.9501312828935864), ('ping', 0.9024506571916731), ('rpc', 0.8367383552008621)]
Top words for pretrained_BERT neuron indx 2190 [('unicode', 1.0), ('1970', 0.8955601310387079), ('oslo', 0.8239211036831092), ('GetUser', 0.7299705925863079), ('2014', 0.7264900304972961)]
Top words for pretrained_BERT neuron indx 4239 [('del', 1.0), ('closing', 0.9835321568985643), ('31', 0.9828877197805523), ('baseline', 0.9609514279677017), ('class', 0.9409402325955478)]
Top words for pretrained_BERT neuron indx 6293 [('"Demographics"', 1.0), ('Billboard', 0.9942319052863642), ('LoadConfig', 0.9383710984016236), ('Config', 0.8824230517650002), ('2014', 0.8746037137048156)]
Top words for pretrained_BERT neuron indx 151 [('broadcast', 1.0), ('1800', 0.8214506050401117), ('iq', 0.7366918802605682), ('1000', 0.7306174267209365), ('def', 0.7283698615944315)]
Top words for pretrained_BERT neuron indx 2202 [('96', 1.0), ('1970', 0.9196872832850804), ('connection', 0.8864145344611557), ('reactor', 0.8775236484069221), ('201', 0.7122164058416353)]
Top words for pretrained_BERT neuron indx 6300 [('117', 1.0), ('187', 0.8331325696081182), ('127', 0.8264624674993074), ('18', 0.8248895015205928), ('69', 0.8037964662188781)]
Top words for pretrained_BERT neuron indx 4252 [('204', 1.0), ('Simple', 0.842804087055876), ('On', 0.8059259072293438), ('del', 0.6747296952248887), ('117', 0.6723226802332467)]
Top words for pretrained_BERT neuron indx 2206 [('sconff', 1.0), ('receive_shadows', 0.9484719932526872), ('"delete_rule"', 0.8450251188861355), ('"match_option"', 0.8363205069417593), ('"shared"', 0.8325488022056601)]
Top words for pretrained_BERT neuron indx 162 [('contextlib', 1.0), ('boot', 0.9337874139113852), ('eg', 0.7150805255989948), ('egs', 0.6617176921627251), ('62', 0.6595647071043438)]
Top words for pretrained_BERT neuron indx 6310 [('continue', 1.0), ('wait', 0.903386287519375), ('50', 0.8431105785990313), ('from', 0.8287846547617445), ('ignore', 0.8227310407330011)]
Top words for pretrained_BERT neuron indx 2216 [('1800', 1.0), ('200', 0.7128026214107586), ('unicode', 0.6702870541568455), ('800', 0.6529250337583248), ('15000', 0.6349993861201098)]
Top words for pretrained_BERT neuron indx 6313 [('requests', 1.0), ('connection', 0.8629288508034288), ('from', 0.8339491982801485), ('__license__', 0.8333276321592796), ('__copyright__', 0.830354312198232)]
Top words for pretrained_BERT neuron indx 6321 [('rosters', 1.0), ('117', 0.987426587905072), ('board', 0.9783114294614301), ('except', 0.9609884756694063), ('Board', 0.9523831909218838)]
Top words for pretrained_BERT neuron indx 4276 [('"incidents"', 1.0), ('"Incident"', 0.8981873388946144), ('On', 0.8588870047811833), ('"contributors"', 0.8426897548879363), ('1000', 0.8392911366917853)]
Top words for pretrained_BERT neuron indx 184 [('boot', 1.0), ('iq', 0.9331362874461283), ('probe', 0.7667842002042431), ('__license__', 0.6703545374401596), ('push', 0.6661365281630846)]
Top words for pretrained_BERT neuron indx 6328 [('to', 1.0), ('sans', 0.9522288218700476), ('_closed', 0.86979441854994), ('ping', 0.8649530572915475), ('sts', 0.8075161032278068)]
Top words for pretrained_BERT neuron indx 6330 [('not', 1.0), ('None', 0.9791897962899807), ('Unauthorized', 0.7802996370572509), ('Off', 0.7540275488844038), ('0xFF', 0.6903479297880983)]
Top words for pretrained_BERT neuron indx 192 [('0', 1.0), ('0xFF', 0.6168780486840792), ('0x01', 0.587134792129045), ('0.04', 0.5665008660790555), ('else', 0.5567343277310287)]
Top words for pretrained_BERT neuron indx 6340 [('40', 1.0), ('400', 0.8972600620527614), ('300', 0.8193265070887589), ('36', 0.706579004987501), ('117', 0.7053377750957309)]
Top words for pretrained_BERT neuron indx 8389 [('7', 1.0), ('999999', 0.9847488297373794), ('Unauthorized', 0.9745635154970346), ('1000', 0.8811876423150836), ('800', 0.865003497822581)]
Top words for pretrained_BERT neuron indx 6342 [('enabled', 1.0), ('Off', 0.994991460238955), ('continue', 0.9901030351988319), ('"ip"', 0.9390920724368365), ('"HTTP"', 0.880435433118785)]
Top words for pretrained_BERT neuron indx 2250 [('128', 1.0), ('302', 0.8589483726240789), ('for', 0.8246396382021575), ('modes', 0.8241719974868159), ('choices', 0.810727983362769)]
Top words for pretrained_BERT neuron indx 215 [('stanza', 1.0), ('95', 0.9969114586700542), ('ignore', 0.9242640339397074), ('86400', 0.8654529284005669), ('GetBoard', 0.8623065511812674)]
Top words for pretrained_BERT neuron indx 4312 [('187', 1.0), ('117', 0.9643158250418907), ('Unauthorized', 0.864060886671618), ('except', 0.861515909139575), ('iq', 0.8544863659876888)]
Top words for pretrained_BERT neuron indx 4319 [('__copyright__', 1.0), ('__title__', 0.9593874134894129), ('__disco_info_ns__', 0.9467447226718909), ('to', 0.937770583078521), ('__license__', 0.9288901204139869)]
Top words for pretrained_BERT neuron indx 2272 [('256', 1.0), ('proxy', 0.991728036208126), ('future', 0.9446426603653578), ('mesh', 0.863753341426253), ('Mesh', 0.8437079801375359)]
Top words for pretrained_BERT neuron indx 6369 [('wait', 1.0), ('settings', 0.9238558520493325), ('is', 0.905427632030677), ('fileno', 0.8818360451612999), ('36', 0.7966194117522012)]
Top words for pretrained_BERT neuron indx 8416 [('204', 1.0), ('mesh', 0.9520576815899447), ('255', 0.936783988213859), ('300', 0.9118680003260101), ('127', 0.8861074058611508)]
Top words for pretrained_BERT neuron indx 2301 [('96', 1.0), ('95', 0.9948257070535447), ('3128', 0.9121709904536519), ('3785', 0.9065768174412208), ('Billboard', 0.9005944733671668)]
Top words for pretrained_BERT neuron indx 8446 [('3142', 1.0), ('400', 0.8202627864520048), ('"2dsphere"', 0.7989749904279073), ('2.1', 0.7857991301255387), ('_con', 0.784686462402589)]
Top words for pretrained_BERT neuron indx 254 [('route', 1.0), ('enabled', 0.978439403438357), ('True', 0.965145782342034), ('servers', 0.8479955240591275), ('Log', 0.824423165225441)]
Top words for pretrained_BERT neuron indx 2306 [('bare', 1.0), ('Log', 0.9064194537829675), ('1800', 0.8264761113029303), ('reactor', 0.812845460150067), ('Off', 0.7867774644017369)]
Top words for pretrained_BERT neuron indx 6404 [('mesh', 1.0), ('12', 0.7936682045269884), ('Mesh', 0.749260308865329), ('14', 0.728155977352607), ('mesh3', 0.7195128328399247)]
Top words for pretrained_BERT neuron indx 260 [('servers', 1.0), ('Session', 0.8298425196431187), ('Board', 0.7775679662564621), ('session', 0.7694502542921571), ('board', 0.7464088756017059)]
Top words for pretrained_BERT neuron indx 6407 [('oslo', 1.0), ('Unauthorized', 0.988687659407056), ('not', 0.8986937403845147), ('Distance', 0.72074335193874), ('GET', 0.7144170666046735)]
Top words for pretrained_BERT neuron indx 265 [('sts', 1.0), ('proxy', 0.9359154859097021), ('requests', 0.9345836164147582), ('21', 0.9136056051014317), ('import', 0.8861482602441441)]
Top words for pretrained_BERT neuron indx 269 [('raise', 1.0), ('enum', 0.9990638302459477), ('settings', 0.9252195039538428), ('del', 0.7978398715946707), ('affinity', 0.7737233707146298)]
Top words for pretrained_BERT neuron indx 8462 [('18', 1.0), ('117', 0.9730729998708435), ('800', 0.9416928536788817), ('from_', 0.8940728241739146), ('14', 0.8876582683718265)]
Top words for pretrained_BERT neuron indx 4370 [('Off', 1.0), ('modes', 0.9647984320559767), ('reactor', 0.8478645065104745), ('choices', 0.8409429506016349), ('"63646566676869"', 0.7787813585155391)]
Top words for pretrained_BERT neuron indx 275 [('False', 1.0), ('302', 0.8909940787839353), ('userid', 0.7224728755444924), ('Register', 0.7128133499650546), ('GetUID', 0.703108298200843)]
Top words for pretrained_BERT neuron indx 277 [('settings', 1.0), ('35', 0.9939723091900331), ('GET', 0.9667384748023212), ('Digest', 0.8752415875943513), ('jid', 0.8674135457403741)]
Top words for pretrained_BERT neuron indx 4373 [('or', 1.0), ('None', 0.9859814886335277), ('del', 0.8715456371442819), ('3785', 0.8277107846776555), ('False', 0.8189177517577905)]
Top words for pretrained_BERT neuron indx 280 [('Stretch', 1.0), ('activity', 0.8475620090507526), ('127', 0.8171871348361265), ('View', 0.699059700007919), ('sts', 0.671708648239391)]
Top words for pretrained_BERT neuron indx 6428 [('Plugin', 1.0), ('View', 0.8667003530037548), ('mtitle', 0.734438697622224), ('5001', 0.6992406163520665), ('if', 0.6474537828589975)]
Top words for pretrained_BERT neuron indx 4382 [('Billboard', 1.0), ('policy', 0.8993810448476319), ('256', 0.8689588335743922), ('host', 0.8504869576095578), ('proxy', 0.8407045039824638)]
Top words for pretrained_BERT neuron indx 293 [('material', 1.0), ('def', 0.9520522566401104), ('True', 0.9464119973531901), ('Tab', 0.9281928026536672), ('return', 0.9004631757217388)]
Top words for pretrained_BERT neuron indx 4393 [('750', 1.0), ('break', 0.830977825267412), ('servers', 0.8280062989039637), ('100000', 0.7430509693093958), ('TabGroup', 0.7409167045671508)]
Top words for pretrained_BERT neuron indx 300 [('Util', 1.0), ('closing', 0.9450430175332286), ('bare', 0.8924077827319508), ('settings', 0.8793518754377924), ('36', 0.8387276324381753)]
Top words for pretrained_BERT neuron indx 8495 [('reactor', 1.0), ('host', 0.8330776549348267), ('187', 0.8290991243247329), ('35', 0.8181687497122357), ('32', 0.7555502506396922)]
Top words for pretrained_BERT neuron indx 6447 [('if', 1.0), ('80', 0.9640676379379333), ('63', 0.947725257866278), ('"harvest"', 0.9140264378276052), ('69', 0.8897840366566203)]
Top words for pretrained_BERT neuron indx 2353 [('Distance', 1.0), ('600', 0.9556262173777089), ('2014', 0.9540665035989185), ('enabled', 0.9496833574599064), ('201', 0.8628699141828936)]
Top words for pretrained_BERT neuron indx 308 [('and', 1.0), ('in', 0.8467114630031743), ('".."', 0.8459876539901788), ('to', 0.8328647956439721), ('"in"', 0.7044829767021356)]
Top words for pretrained_BERT neuron indx 8509 [('"6DE9FAF2507F9A99193D"', 1.0), ('999999', 0.9540287997730608), ('"21111111111"', 0.9339847335175865), ('89.999999999999992', 0.9235521474006655), ('"012345678910"', 0.9098409445921523)]
Top words for pretrained_BERT neuron indx 318 [('freshtime', 1.0), ('except', 0.896632050983141), ('return', 0.8943406667888977), ('117', 0.8572914356584613), ('False', 0.8452423359820314)]
Top words for pretrained_BERT neuron indx 2369 [('Mesh', 1.0), ('mesh', 0.8929557256932322), ('oslo', 0.5607354226769459), ('1970', 0.5099770635177608), ('Unauthorized', 0.49299734486377617)]
Top words for pretrained_BERT neuron indx 8514 [('presence', 1.0), ('1970', 0.9767863799809015), ('boot', 0.7849262579681134), ('break', 0.7330601769022198), ('100000', 0.729489613198695)]
Top words for pretrained_BERT neuron indx 324 [('iq', 1.0), ('requests', 0.6959905280866147), ('pass', 0.6628439254058941), ('port', 0.5837116020913726), ('send', 0.566940850491424)]
Top words for pretrained_BERT neuron indx 4422 [('86400', 1.0), ('1800', 0.9810766545299253), ('feature', 0.9416525283402684), ('choices', 0.8860665133808403), ('policy', 0.8365496527697106)]
Top words for pretrained_BERT neuron indx 8519 [('23', 1.0), ('del', 0.9682264393769473), ('conn', 0.8897379900896603), ('Unauthorized', 0.8531189084966725), ('80', 0.7144294788561356)]
Top words for pretrained_BERT neuron indx 8520 [('11', 1.0), ('"functions"', 0.8795499293740365), ('"sodium"', 0.8541290837805102), ('"reason"', 0.8514545122407292), ('MSG', 0.7726444893931019)]
Top words for pretrained_BERT neuron indx 328 [('choices', 1.0), ('Mesh', 0.9693378957895227), ('mesh', 0.9693378957895227), ('Stretch', 0.9005869926132822), ('part', 0.8794150119389076)]
Top words for pretrained_BERT neuron indx 332 [('sts', 1.0), ('sans', 0.976167567361934), ('del', 0.9006822610425207), ('Log', 0.8115526294269625), ('baseline', 0.7734572797916741)]
Top words for pretrained_BERT neuron indx 335 [('srv', 1.0), ('modes', 0.9457648546892645), ('requests', 0.8884560517092659), ('0xFF', 0.8507567372617652), ('builtins', 0.8026421447525894)]
Top words for pretrained_BERT neuron indx 8532 [('"yellow"', 1.0), ('"red"', 0.9491384830294608), ('"green"', 0.8160685359000207), ('"darkred"', 0.7432237597731289), ('"darkgray"', 0.7315677987049392)]
Top words for pretrained_BERT neuron indx 6493 [('oslo', 1.0), ('slug', 0.8215299669134682), ('62', 0.8057958766082259), ('boot', 0.7336841626455054), ('0.04', 0.7333644685018916)]
Top words for pretrained_BERT neuron indx 350 [('digest', 1.0), ('ranges', 0.9950351741086919), ('Digest', 0.9323144317818851), ('except', 0.8699367046369113), ('MAXBOARD', 0.8470030844388353)]
Top words for pretrained_BERT neuron indx 2397 [('List', 1.0), ('unicode', 0.8456835394826648), ('except', 0.7887144044750254), ('2014', 0.7568609784711159), ('23', 0.7488959961572164)]
Top words for pretrained_BERT neuron indx 2402 [('iq', 1.0), ('while', 0.7829485352921061), ('MsgBox', 0.7108844791973741), ('Unauthorized', 0.7042147129728894), ('Simple', 0.677933621609914)]
Top words for pretrained_BERT neuron indx 4453 [('userid', 1.0), ('800', 0.8919349866515605), ('1970', 0.8416539722341978), ('Billboard', 0.7279774035705875), ('WrongArgs', 0.7111577535885727)]
Top words for pretrained_BERT neuron indx 2405 [('stanza', 1.0), ('ping', 0.9792353701315198), ('send', 0.8364828111981041), ('host', 0.7928355574776399), ('ignore', 0.7733918503644642)]
Top words for pretrained_BERT neuron indx 4458 [('try', 1.0), ('600', 0.9986228434225278), ('100000', 0.9881898366054134), ('187', 0.926495446404817), ('except', 0.8926878742541898)]
Top words for pretrained_BERT neuron indx 8555 [('LoadUser', 1.0), ('material', 0.9969746753676931), ('512', 0.9475861966084861), ('activity', 0.9358169772033557), ('enclosureGroupUri', 0.9155764317739209)]
Top words for pretrained_BERT neuron indx 6512 [('Distance', 1.0), ('presence', 0.9931842216099424), ('port', 0.8701045406420445), ('reactor', 0.8407816649536202), ('host', 0.8300951358366966)]
Top words for pretrained_BERT neuron indx 4464 [('63', 1.0), ('75', 0.6524552674766486), ('IsFile', 0.6315489117600901), ('127', 0.6293905369371425), ('117', 0.6156595100166737)]
Top words for pretrained_BERT neuron indx 8562 [('256', 1.0), ('89.999999999999992', 0.9392346147713221), ('"2032e4fd19d4ab49a74ead0984a5f672c26e60da6e992eaf51f05dc874e94bd7"', 0.9126386432014307), ('999999', 0.849616743401238), ('"0301000000001122aabbccdd0102030405060708"', 0.8369327269403584)]
Top words for pretrained_BERT neuron indx 371 [('digest', 1.0), ('enabled', 0.9667826607891575), ('Digest', 0.9594605438861059), ('None', 0.9454779991576073), ('if', 0.9080764306832451)]
Top words for pretrained_BERT neuron indx 8567 [('None', 1.0), ('"background-color:red"', 0.8908137022099858), ('or', 0.8863355128016907), ('"type:yarn"', 0.8747985916558894), ('"oslo"', 0.8743047144959664)]
Top words for pretrained_BERT neuron indx 8573 [('with', 1.0), ('512', 0.8830457459731254), ('187', 0.8389509051699546), ('204', 0.8177372490926191), ('128', 0.7902493025564148)]
Top words for pretrained_BERT neuron indx 8574 [('"0800305c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 1.0), ('"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.9902307840041639), ('requests', 0.8761758623616236), ('"1b1f463cef1807a127af668f3a4fdcc7977c647bf2f357d9fa125f13548b1d14"', 0.8638182946886085), ('ping', 0.8193709267998506)]
Top words for pretrained_BERT neuron indx 2431 [('95', 1.0), ('204', 0.9772618550014828), ('302', 0.9542709809808282), ('86400', 0.8872707120049403), ('1800', 0.8685404554341088)]
Top words for pretrained_BERT neuron indx 8576 [('42', 1.0), ('69', 0.9727101452977648), ('40', 0.8020807330790959), ('62', 0.7827013839705461), ('60', 0.7714375603401463)]
Top words for pretrained_BERT neuron indx 4483 [('credential', 1.0), ('2.1', 0.9231441627272796), ('material', 0.8935673993887113), ('modes', 0.8575021568767232), ('"bytes"', 0.8040678674181229)]
Top words for pretrained_BERT neuron indx 4490 [('201', 1.0), ('unicode', 0.9702374846583813), ('sans', 0.8804713191212656), ('closing', 0.8349817700178881), ('302', 0.7810343100380676)]
Top words for pretrained_BERT neuron indx 2443 [('"-I"', 1.0), ('255', 0.9086815232080161), ('"-D"', 0.7992299659060712), ('"--cabal"', 0.7876084865329179), ('"eng"', 0.7861534056504281)]
Top words for pretrained_BERT neuron indx 8594 [('servers', 1.0), ('mesh', 0.912603541086362), ('Mesh', 0.894953646816087), ('enabled', 0.8535357516945451), ('Post', 0.7599638912181922)]
Top words for pretrained_BERT neuron indx 8596 [('36', 1.0), ('14', 0.803580852914861), ('31', 0.7865403883182908), ('digest', 0.7526001272679045), ('session', 0.7406929449499402)]
Top words for pretrained_BERT neuron indx 2455 [('requests', 1.0), ('True', 0.9751609201232442), ('iq', 0.7454616957093764), ('sans', 0.6952554657380274), ('False', 0.6893597699605505)]
Top words for pretrained_BERT neuron indx 6559 [('boot_mode', 1.0), ('boot_order', 0.9611213525439392), ('affinity', 0.9290808124905106), ('GetUID', 0.762229946888168), ('routes', 0.7580831059808066)]
Top words for pretrained_BERT neuron indx 4512 [('bootSettings', 1.0), ('ShadowsOnly', 0.9715476915147325), ('del', 0.9484003462869567), ('ParticleRenderer', 0.9235146226587141), ('MeshRenderer', 0.883290329465047)]
Top words for pretrained_BERT neuron indx 8614 [('"min"', 1.0), ('__title__', 0.9520813285470543), ('50', 0.8577086329478463), ('"TTP1"', 0.8537358592619537), ('None_', 0.8497446324078225)]
Top words for pretrained_BERT neuron indx 425 [('Simple', 1.0), ('class', 0.6590201553699502), ('affinity', 0.5756334506839744), ('"lists"', 0.5592071383383036), ('7', 0.5276661851959055)]
Top words for pretrained_BERT neuron indx 4522 [('probe', 1.0), ('1970', 0.8661929975597028), ('digest', 0.8273507700454945), ('95', 0.774964208260438), ('"#FF0000"', 0.7748271087255233)]
Top words for pretrained_BERT neuron indx 429 [('modes', 1.0), ('settings', 0.9978273544770001), ('ranges', 0.9350634285615129), ('LoadUser', 0.8733770931122542), ('affinity', 0.8299028635172525)]
Top words for pretrained_BERT neuron indx 4529 [('187', 1.0), ('host', 0.8955729493893788), ('try', 0.8385703746066082), ('pass', 0.8241965853389777), ('feature', 0.7828770133257573)]
Top words for pretrained_BERT neuron indx 6577 [('freshtime', 1.0), ('port', 0.9960268974797387), ('81.4471435546875', 0.9499961713766516), ('23.61432859499169', 0.9419519535784088), ('find_session', 0.9079970603643168)]
Top words for pretrained_BERT neuron indx 6580 [('"ip"', 1.0), ('host', 0.9912704339632855), ('100000', 0.9711065320800736), ('Simple', 0.9483133356001405), ('or', 0.9326767476404685)]
Top words for pretrained_BERT neuron indx 4533 [('boot', 1.0), ('Distance', 0.9813746922243048), ('while', 0.9531412382125479), ('part', 0.8610568807776555), ('port', 0.7497000850177473)]
Top words for pretrained_BERT neuron indx 439 [('36', 1.0), ('egs', 0.9818767612359717), ('Log', 0.9359361389703387), ('choices', 0.9037758929995608), ('broadcast', 0.8692453688478587)]
Top words for pretrained_BERT neuron indx 2489 [('_closed', 1.0), ('else', 0.980071084438906), ('__copyright__', 0.912402619304666), ('continue', 0.8797995740587907), ('__title__', 0.8744974936385445)]
Top words for pretrained_BERT neuron indx 444 [('Tab', 1.0), ('bare', 0.998753907895612), ('direct', 0.7946584415061833), ('port', 0.7863529740245555), ('None', 0.7833061037047152)]
Top words for pretrained_BERT neuron indx 4541 [('None', 1.0), ('255', 0.8143651392287609), ('Off', 0.7877404179957762), ('256', 0.7640198021274908), ('"enabled"', 0.7097261510230197)]
Top words for pretrained_BERT neuron indx 447 [('vCard', 1.0), ('vcard', 0.97054649276817), ('port', 0.9186612793968549), ('boot', 0.9166059155198945), ('raise', 0.8831885845768794)]
Top words for pretrained_BERT neuron indx 448 [('route', 1.0), ('Distance', 0.8257073700960682), ('bare', 0.7946521057142499), ('List', 0.7522005684404282), ('port', 0.7291006493912751)]
Top words for pretrained_BERT neuron indx 450 [('sans', 1.0), ('enclosureGroupUri', 0.5416525590458005), ('DEFAULTBOARD', 0.5175959155533026), ('75', 0.5110506438034959), ('boot', 0.5086221626658548)]
Top words for pretrained_BERT neuron indx 8643 [('28', 1.0), ('187', 0.988560354229165), ('17', 0.9723573272002122), ('204', 0.8747598396326499), ('127', 0.8443496519163626)]
Top words for pretrained_BERT neuron indx 8646 [('1970', 1.0), ('187', 0.988351876280038), ('62', 0.9795493358831067), ('Off', 0.8941924224396688), ('"!@#$%"', 0.865300435813124)]
Top words for pretrained_BERT neuron indx 2505 [('True', 1.0), ('False', 0.8949398075401127), ('material', 0.8193692131427746), ('Unauthorized', 0.8032735549964906), ('1970', 0.8028224348194388)]
Top words for pretrained_BERT neuron indx 6604 [('42', 1.0), ('32', 0.776753391863905), ('or', 0.7408574267539774), ('continue', 0.7394085952816718), ('20', 0.6720543372090896)]
Top words for pretrained_BERT neuron indx 465 [('0', 1.0), ('NotFound', 0.6856782702338852), ('affinity', 0.6771393607588112), ('passwd', 0.6716010499959841), ('except', 0.653298924592955)]
Top words for pretrained_BERT neuron indx 472 [('Simple', 1.0), ('recv', 0.9857069473798118), ('baseline', 0.8478066495545975), ('iq', 0.8062709384704596), ('187', 0.7893679583614857)]
Top words for pretrained_BERT neuron indx 6620 [('to', 1.0), ('Distance', 0.9858979005686405), ('Unauthorized', 0.9040184023854267), ('1970', 0.8970770375266122), ('closing', 0.8862569176461271)]
Top words for pretrained_BERT neuron indx 6624 [('to', 1.0), ('"http://"', 0.9885835288712637), ('Register', 0.9775341123249819), ('ranges', 0.9620450470369711), ('36', 0.9030475557497064)]
Top words for pretrained_BERT neuron indx 8680 [('fileno', 1.0), ('st_mode', 0.9698687276046655), ('get_resources', 0.8427839980789732), ('getpid', 0.8098216957747899), ('Unauthorized', 0.7234423663324583)]
Top words for pretrained_BERT neuron indx 8681 [('62', 1.0), ('Log', 0.8291446750187309), ('or', 0.7501830011611337), ('with', 0.7258173565498871), ('36', 0.6801873614880612)]
Top words for pretrained_BERT neuron indx 2536 [('hpov', 1.0), ('300', 0.9632636326543997), ('Distance', 0.9376825372680855), ('3600', 0.8907783653990189), ('GetString', 0.8820380659734702)]
Top words for pretrained_BERT neuron indx 4590 [('119', 1.0), ('board', 0.9460713587107441), ('GetBoard', 0.9358361497785663), ('List', 0.9291861121756246), ('3785', 0.9107009417524836)]
Top words for pretrained_BERT neuron indx 6640 [('GetContent', 1.0), ('"this_is_the_name_of_my_job"', 0.9368992712993012), ('GetMirror', 0.9356963678866256), ('enum', 0.9100009699398727), ('0x1', 0.8695146563253873)]
Top words for pretrained_BERT neuron indx 8692 [('11', 1.0), ('119', 0.9297368760706551), ('117', 0.7992331050362805), ('33', 0.7841435766628545), ('187', 0.776523281627288)]
Top words for pretrained_BERT neuron indx 6646 [('75', 1.0), ('1024', 0.9554126365630394), ('64', 0.9499548172744224), ('board', 0.9454025199222457), ('NoRoute', 0.9424840990254509)]
Top words for pretrained_BERT neuron indx 502 [('material', 1.0), ('feature', 0.9723269073748889), ('future', 0.8861898429363031), ('presence', 0.8169198456160848), ('1000', 0.7988562266789334)]
Top words for pretrained_BERT neuron indx 507 [('MSG', 1.0), ('presence', 0.9960616747862879), ('Mesh', 0.9144747352443612), ('mesh', 0.9144747352443612), ('break', 0.8809269653983087)]
Top words for pretrained_BERT neuron indx 4608 [('187', 1.0), ('part', 0.821933654001409), ('600', 0.7880060569303965), ('broadcast', 0.7877226030457111), ('profile_template', 0.734969298592253)]
Top words for pretrained_BERT neuron indx 4610 [('7', 1.0), ('95', 0.9840933287597811), ('shts', 0.9740938159448274), ('sts', 0.971980402445049), ('sht', 0.9459955541649102)]
Top words for pretrained_BERT neuron indx 8708 [('mesh', 1.0), ('12', 0.9189511859238357), ('roster', 0.867497212020979), ('"6DE9FAF2507F9A99193D"', 0.828642132451282), ('89.999999999999992', 0.8135442203598414)]
Top words for pretrained_BERT neuron indx 8712 [('"SENTINEL"', 1.0), ('"example"', 0.9971057653559344), ('"%im"', 0.9624422072352301), ('"!@#$%"', 0.9457491878432764), ('choices', 0.9220395911863078)]
Top words for pretrained_BERT neuron indx 6670 [('modes', 1.0), ('Register', 0.8753311963759869), ('not', 0.7972596715807222), ('stanza', 0.7885630699234101), ('requests', 0.7774081003600405)]
Top words for pretrained_BERT neuron indx 4623 [('Tab', 1.0), ('as', 0.9718954333736914), ('"requests"', 0.8460534164295842), ('future', 0.8303316220874705), ('Post', 0.814705352399615)]
Top words for pretrained_BERT neuron indx 4624 [('62', 1.0), ('GET', 0.9408197643878926), ('enabled', 0.930067489342286), ('"boards"', 0.900889351111723), ('On', 0.8907593049369568)]
Top words for pretrained_BERT neuron indx 6677 [('or', 1.0), ('False', 0.9794349702109394), ('None', 0.8455754661368846), ('horizon', 0.8292864261695889), ('else', 0.7977380050919174)]
Top words for pretrained_BERT neuron indx 8727 [('25', 1.0), ('NoPerm', 0.9606542571905534), ('80', 0.9167195187169427), ('20', 0.8678352572480479), ('session', 0.8235575254489859)]
Top words for pretrained_BERT neuron indx 537 [('boot', 1.0), ('Post', 0.760997549109468), ('activity', 0.7597531736020132), ('cert', 0.7595498462274838), ('False', 0.7594458398770143)]
Top words for pretrained_BERT neuron indx 2585 [('send', 1.0), ('sts', 0.9037267677125325), ('oslo', 0.8771308588113292), ('affinity', 0.730655202864024), ('mesh', 0.719480241623597)]
Top words for pretrained_BERT neuron indx 6686 [('Billboard', 1.0), ('policy', 0.779181448546807), ('wait', 0.7526455798622562), ('proxy', 0.6960226325900345), ('cert', 0.6939846784225486)]
Top words for pretrained_BERT neuron indx 8740 [('999999', 1.0), ('89.999999999999992', 0.9443856609176315), ('3785', 0.704438840108814), ('36', 0.700483270389152), ('"Polygon"', 0.7000105443749488)]
Top words for pretrained_BERT neuron indx 552 [('stanza', 1.0), ('choices', 0.7615693407711362), ('Register', 0.6351241453897155), ('100', 0.5888025037812932), ('1800', 0.5619154713242542)]
Top words for pretrained_BERT neuron indx 8751 [('"sodium"', 1.0), ('63', 0.9950489457737237), ('route', 0.9323232797364608), ('2.1', 0.8836702591387963), ('95', 0.8500133861805637)]
Top words for pretrained_BERT neuron indx 2609 [('1970', 1.0), ('material', 0.9954502313728261), ('eg', 0.8801347182059903), ('slug', 0.8052268762855769), ('35', 0.7833389760422288)]
Top words for pretrained_BERT neuron indx 561 [('pass', 1.0), ('passwd', 0.9488555936972255), ('host', 0.7858919653862751), ('1', 0.7603741459267583), ('IDLEN', 0.7299797955271337)]
Top words for pretrained_BERT neuron indx 8757 [('GetMirror', 1.0), ('part', 0.8844893209259135), ('2014', 0.8193747934537657), ('15', 0.8132659089922474), ('500', 0.740290548753482)]
Top words for pretrained_BERT neuron indx 8764 [('256', 1.0), ('iq', 0.9737466416864198), ('sans', 0.717256103716572), ('boot', 0.6986780138627359), ('MAXSIGLINES', 0.690627703435147)]
Top words for pretrained_BERT neuron indx 8767 [('is', 1.0), ('"<#UNKNOWN#>"', 0.9443167021276843), ('HorizontalBillboard', 0.930643627836348), ('VerticalBillboard', 0.9231777405899945), ('future', 0.8596335100421311)]
Top words for pretrained_BERT neuron indx 8770 [('0x00000001', 1.0), ('"0301000000001122aabbccdd0102030405060708"', 0.8354368976451433), ('2150', 0.7794410090142841), ('"#A0A000"', 0.7636594971144385), ('"#A00000"', 0.6915404920329603)]
Top words for pretrained_BERT neuron indx 579 [('750', 1.0), ('horizon', 0.9975563801426003), ('UCache', 0.9952431351938289), ('NoPerm', 0.8403754136278133), ('11', 0.8181015427765534)]
Top words for pretrained_BERT neuron indx 8777 [('127', 1.0), ('31', 0.8186692926079319), ('stat', 0.7851789006449085), ('horizon', 0.7747146867006308), ('42', 0.7673104983914826)]
Top words for pretrained_BERT neuron indx 587 [('slug', 1.0), ('ping', 0.9571967251432059), ('Session', 0.8585915951708546), ('push', 0.8337542896533947), ('session', 0.828810581174065)]
Top words for pretrained_BERT neuron indx 8781 [('42', 1.0), ('204', 0.9025844197553705), ('ParticleRenderer', 0.8988907114333174), ('MeshRenderer', 0.8732214591219831), ('1800', 0.8418721354258949)]
Top words for pretrained_BERT neuron indx 596 [('800', 1.0), ('stanza', 0.9445573040396157), ('wait', 0.9096954628966407), ('else', 0.7830395778983475), ('push', 0.7137666628761787)]
Top words for pretrained_BERT neuron indx 2645 [('continue', 1.0), ('board', 0.9559523624739131), ('Board', 0.9456621574457881), ('2014', 0.9030054587917818), ('0', 0.8669842583306371)]
Top words for pretrained_BERT neuron indx 6746 [('201', 1.0), ('750', 0.8778705060754729), ('62', 0.8687093821838759), ('refresh', 0.8090470309460055), ('302', 0.7418820841642152)]
Top words for pretrained_BERT neuron indx 8795 [('proxy', 1.0), ('Tab', 0.8604045122812963), ('UserManager', 0.8016691137487345), ('send', 0.7991636810053572), ('bare', 0.7750872197311759)]
Top words for pretrained_BERT neuron indx 2653 [('69', 1.0), ('62', 0.7566743606968639), ('boot', 0.7407012642392278), ('75', 0.7265503891845739), ('63', 0.7075919210179695)]
Top words for pretrained_BERT neuron indx 8798 [('"pattern"', 1.0), ('128', 0.9631938487697325), ('"Batman"', 0.8990138066750655), ('with', 0.8975437571339945), ('"year"', 0.8826186260007269)]
Top words for pretrained_BERT neuron indx 4701 [('List', 1.0), ('23', 0.8898339262143495), ('unicode', 0.8611322182430987), ('broadcast', 0.8291608915445345), ('is', 0.781655786727835)]
Top words for pretrained_BERT neuron indx 6758 [('closing', 1.0), ('4095', 0.9763720816556875), ('20000', 0.8982757606300286), ('5001', 0.8898426917669603), ('for', 0.8864831548910324)]
Top words for pretrained_BERT neuron indx 6760 [('import', 1.0), ('vwwn', 0.9492115845656911), ('StreamClosed', 0.9367788438504302), ('return', 0.9290982201830162), ('"mem"', 0.8509511307103302)]
Top words for pretrained_BERT neuron indx 2666 [('On', 1.0), ('1970', 0.9720341654071908), ('"purple"', 0.9428887452235991), ('passwd', 0.9340362658234572), ('10000', 0.805096768803244)]
Top words for pretrained_BERT neuron indx 8828 [('42', 1.0), ('69', 0.8336129297538807), ('443', 0.7598578532498809), ('5001', 0.7474136429241924), ('9', 0.7352844012320356)]
Top words for pretrained_BERT neuron indx 640 [('baseline', 1.0), ('ignore', 0.9332308753688179), ('freshtime', 0.8934586793162479), ('stat', 0.8541241236595402), ('Off', 0.8105415846402217)]
Top words for pretrained_BERT neuron indx 6785 [('GET', 1.0), ('future', 0.8419415175519749), ('"purple"', 0.8062173662531399), ('symlink', 0.8033540545548281), ('sans', 0.791933361886896)]
Top words for pretrained_BERT neuron indx 2688 [('62', 1.0), ('187', 0.991100603541855), ('204', 0.951370673865247), ('127', 0.9434605081929157), ('probe', 0.917819312340337)]
Top words for pretrained_BERT neuron indx 643 [('horizon', 1.0), ('False', 0.9923340938293932), ('1000', 0.8404824173923034), ('return', 0.8053685495897751), ('roster', 0.7812073899808214)]
Top words for pretrained_BERT neuron indx 644 [('stat', 1.0), ('try', 0.916003855324182), ('201', 0.9082010138165452), ('refresh', 0.8837151337575917), ('ping', 0.8301820182765609)]
Top words for pretrained_BERT neuron indx 2693 [('stanza', 1.0), ('200', 0.950766177726154), ('iq', 0.8067813413122583), ('baseline', 0.7872379655622601), ('100', 0.7826791908759816)]
Top words for pretrained_BERT neuron indx 646 [('unicode', 1.0), ('horizon', 0.7798628447475713), ('settings', 0.7086685406877911), ('port', 0.6121088393293468), ('probe', 0.5915970683734928)]
Top words for pretrained_BERT neuron indx 6787 [('204', 1.0), ('300', 0.9710263532694836), ('bare', 0.9619818642438506), ('2.1', 0.9560916014827532), ('mesh', 0.9499142401532907)]
Top words for pretrained_BERT neuron indx 2698 [('23', 1.0), ('500', 0.9961533601706347), ('750', 0.9807908630578087), ('21', 0.917368965312414), ('sans', 0.8678338075835003)]
Top words for pretrained_BERT neuron indx 2703 [('del', 1.0), ('40', 0.8866758177797387), ('baseline', 0.876841041704248), ('16', 0.8674263450167737), ('28', 0.861552723163737)]
Top words for pretrained_BERT neuron indx 2710 [('OLDPASSLEN', 1.0), ('8', 0.9758248845201484), ('send', 0.9532107715531054), ('Billboard', 0.9500729878121672), ('ShadowsOnly', 0.9039391343568776)]
Top words for pretrained_BERT neuron indx 2712 [('42', 1.0), ('187', 0.9763007658213828), ('broadcast', 0.947775687557468), ('117', 0.9427891981779932), ('36', 0.861704330376978)]
Top words for pretrained_BERT neuron indx 4764 [('117', 1.0), ('18', 0.7783009244126246), ('187', 0.7308427879728514), ('127', 0.716133099342589), ('wait', 0.6929079842548327)]
Top words for pretrained_BERT neuron indx 669 [('Board', 1.0), ('board', 0.9766521912874816), ('boardname', 0.9151524167303577), ('return', 0.7130185518032975), ('"Resource"', 0.708262909339501)]
Top words for pretrained_BERT neuron indx 6818 [('Stretch', 1.0), ('materials', 0.9288518483414653), ('affinity', 0.9209845427308183), ('mesh', 0.8772856903662376), ('break', 0.8037347555770913)]
Top words for pretrained_BERT neuron indx 675 [('future', 1.0), ('Board', 0.9625198614931201), ('board', 0.9489126672359435), ('wait', 0.8226545677215393), ('affinity', 0.7632453864294392)]
Top words for pretrained_BERT neuron indx 8867 [('if', 1.0), ('Tab', 0.848970131136241), ('except', 0.8267470079221398), ('"VIEW_DEFINITION"', 0.7619054229723761), ('"note_attributes"', 0.7475090228932328)]
Top words for pretrained_BERT neuron indx 681 [('95', 1.0), ('80', 0.9437364349828996), ('sans', 0.8922908690719635), ('stat', 0.7717442790512462), ('75', 0.7695060960201459)]
Top words for pretrained_BERT neuron indx 8875 [('to', 1.0), ('1970', 0.873233511181991), ('direct', 0.809787949385269), ('90.0', 0.6735158327839649), ('"year"', 0.6601907352798145)]
Top words for pretrained_BERT neuron indx 8884 [('187', 1.0), ('or', 0.9785991692669822), ('del', 0.7633237217877364), ('"Spiderman"', 0.7396341660221567), ('choices', 0.716698404140333)]
Top words for pretrained_BERT neuron indx 2740 [('1000', 1.0), ('oslo', 0.8821843551457883), ('unicode', 0.7621594126444916), ('set_eula', 0.6923438821732995), ('33', 0.6904400273909723)]
Top words for pretrained_BERT neuron indx 4792 [('to', 1.0), ('sans', 0.8228832205488863), ('14', 0.7698625422798073), ('None', 0.6575344639134972), ('Mesh', 0.6504445044100688)]
Top words for pretrained_BERT neuron indx 8888 [('128', 1.0), ('from', 0.9429690998979066), ('Stretch', 0.8694685577931975), ('"0301000000001122aabbccdd0102030405060708"', 0.8642308107439912), ('"teal"', 0.8595241585753863)]
Top words for pretrained_BERT neuron indx 4794 [('not', 1.0), ('None', 0.8515430926416315), ('0xFF', 0.7331788219829547), ('continue', 0.7137414256582045), ('Off', 0.7058194371757033)]
Top words for pretrained_BERT neuron indx 6845 [('None', 1.0), ('255', 0.9420930170008638), ('256', 0.7632819463483748), ('42', 0.751155297016799), ('reactor', 0.7479065419335288)]
Top words for pretrained_BERT neuron indx 708 [('List', 1.0), ('requests', 0.8820179869721647), ('push', 0.8604016876162617), ('board', 0.8126715658190014), ('unicode', 0.8079517249624092)]
Top words for pretrained_BERT neuron indx 4806 [('materials', 1.0), ('unicode', 0.8624238139681212), ('wait', 0.8165849865292053), ('On', 0.7786174968931945), ('.3', 0.7200383694259566)]
Top words for pretrained_BERT neuron indx 712 [('Mesh', 1.0), ('mesh', 1.0), ('routes', 0.7957835981102818), ('send', 0.7742167607437255), ('mesh2', 0.7503997875953516)]
Top words for pretrained_BERT neuron indx 2761 [('500', 1.0), ('119', 0.9505144188217489), ('600', 0.9101004604683058), ('12', 0.8753380410442931), ('None', 0.85894002791883)]
Top words for pretrained_BERT neuron indx 8905 [('_hash', 1.0), ('119', 0.9810728248743117), ('else', 0.8987158840246758), ('512', 0.8743396531206149), ('89.999999999999992', 0.8673856995099831)]
Top words for pretrained_BERT neuron indx 8909 [('750', 1.0), ('"order"', 0.9868722916308107), ('"pattern"', 0.9857786016530992), ('"view"', 0.9179415818962571), ('"sqlite://"', 0.8941875360486181)]
Top words for pretrained_BERT neuron indx 6876 [('302', 1.0), ('204', 0.7964586682527284), ('62', 0.7857005913331423), ('63', 0.7577476541589131), ('201', 0.704294154538602)]
Top words for pretrained_BERT neuron indx 2781 [('proxy', 1.0), ('Off', 0.973714026473243), ('send', 0.922330195680044), ('Distance', 0.888044705571728), ('horizon', 0.8613341841216873)]
Top words for pretrained_BERT neuron indx 6880 [('204', 1.0), ('vCard', 0.9726355977811554), ('300', 0.9717530989443619), ('302', 0.9604692014844237), ('8000', 0.9524537346411179)]
Top words for pretrained_BERT neuron indx 6881 [('horizon', 1.0), ('750', 0.9930729909598129), ('201', 0.9730172103507421), ('1800', 0.9224828169895141), ('not', 0.912803647064646)]
Top words for pretrained_BERT neuron indx 4840 [('Register', 1.0), ('format_exc', 0.9353337074580875), ('fileno', 0.8794195972645359), ('settings', 0.8546988566433718), ('PYTHON_VERSION', 0.8281836658911257)]
Top words for pretrained_BERT neuron indx 8943 [('69', 1.0), ('63', 0.9838017488971605), ('Off', 0.803672359038164), ('204', 0.752283693046805), ('closing', 0.7344403143689239)]
Top words for pretrained_BERT neuron indx 2800 [('Simple', 1.0), ('mesh', 0.9264842665860578), ('Mesh', 0.8985884026417289), ('"null"', 0.8660923863226672), ('horizon', 0.8363643001816252)]
Top words for pretrained_BERT neuron indx 4847 [('future', 1.0), ('1000', 0.9647144231773176), ('"Name!!"', 0.9453658747008008), ('"#666666"', 0.9340242712235953), ('enabled', 0.931033039236207)]
Top words for pretrained_BERT neuron indx 2806 [('presence', 1.0), ('500', 0.9622400098144349), ('IsBM', 0.8908407652035298), ('in', 0.8835586297655625), ('sts', 0.8763926869909169)]
Top words for pretrained_BERT neuron indx 2812 [('activity', 1.0), ('presence', 0.8173666118517625), ('119', 0.7722369833242596), ('routes', 0.7594035953357936), ('route', 0.7197658567394499)]
Top words for pretrained_BERT neuron indx 6911 [('boot', 1.0), ('"teal"', 0.9889906656201777), ('break', 0.8239125750859886), ('reactor', 0.7957545791847963), ('future', 0.7451391742566)]
Top words for pretrained_BERT neuron indx 6912 [('187', 1.0), ('117', 0.7436184148219722), ('broadcast', 0.7340822768889529), ('600', 0.7339521165308712), ('14', 0.7311239686218534)]
Top words for pretrained_BERT neuron indx 770 [('sts', 1.0), ('"sequence"', 0.9852701523494978), ('stanza', 0.933738764328596), ('sht', 0.9323634649301581), ('reactor', 0.8710071005819374)]
Top words for pretrained_BERT neuron indx 774 [('ignore', 1.0), ('800', 0.8067203925693994), ('EffectiveId', 0.738359030016788), ('host', 0.6862598493670974), ('20000', 0.6810542234414161)]
Top words for pretrained_BERT neuron indx 4872 [('Distance', 1.0), ('5001', 0.9640133474483739), ('10000', 0.9384525354853253), ('try', 0.9034012209945969), ('View', 0.8349567163785088)]
Top words for pretrained_BERT neuron indx 779 [('future', 1.0), ('unicode', 0.7166633461052689), ('break', 0.6873157662383012), ('userid', 0.6195547412745109), ('Distance', 0.61266519232994)]
Top words for pretrained_BERT neuron indx 8971 [('18', 1.0), ('refresh', 0.9921564849462143), ('1411135000', 0.9885808438940688), ('choices', 0.9333179384341858), ('"SUCCEEDED"', 0.9299346302536644)]
Top words for pretrained_BERT neuron indx 6930 [('Simple', 1.0), ('512', 0.8959892189779516), ('port', 0.8851205628324349), ('3', 0.7782475043227881), ('True', 0.7732612063395803)]
Top words for pretrained_BERT neuron indx 786 [('300', 1.0), ('600', 0.9683872110766649), ('500', 0.8945359146025105), ('50', 0.8353410504703171), ('200', 0.8247174331444396)]
Top words for pretrained_BERT neuron indx 2837 [('bare', 1.0), ('Unauthorized', 0.9015746709153828), ('None', 0.7678244562876129), ('False', 0.7633133592934853), ('600', 0.7448512957209158)]
Top words for pretrained_BERT neuron indx 4885 [('unicode', 1.0), ('except', 0.9312982266866441), ('MSG', 0.8229262766007766), ('oslo', 0.7950548013108433), ('"bytes"', 0.7912996315947968)]
Top words for pretrained_BERT neuron indx 2842 [('port', 1.0), ('while', 0.9879531232482562), ('2014', 0.9177997143147094), ('boot', 0.8713738617274609), ('25', 0.8536607145320854)]
Top words for pretrained_BERT neuron indx 6939 [('unicode', 1.0), ('materials', 0.9075731962395245), ('material', 0.8014246698589932), ('class', 0.7936272322618274), ('reactor', 0.770326913337041)]
Top words for pretrained_BERT neuron indx 2857 [('break', 1.0), ('750', 0.9301082301846779), ('egs', 0.8482994213349783), ('100000', 0.8250338352404775), ('63', 0.8227811913127537)]
Top words for pretrained_BERT neuron indx 2859 [('100000', 1.0), ('xmlns', 0.974911141931791), ('10000', 0.9716972762103611), ('__title__', 0.9623438993421681), ('fileno', 0.9434793222775184)]
Top words for pretrained_BERT neuron indx 4911 [('try', 1.0), ('80', 0.9205201683668031), ('63', 0.8878807165800657), ('newparts', 0.8614658812417566), ('route', 0.8561106426692607)]
Top words for pretrained_BERT neuron indx 816 [('List', 1.0), ('stanza', 0.901229101784874), ('enabled', 0.828716566125293), ('break', 0.8266840330645986), ('Register', 0.7975630232416233)]
Top words for pretrained_BERT neuron indx 9013 [('"black"', 1.0), ('"red"', 0.8964252523771586), ('"green"', 0.886876051098074), ('readfp', 0.884941887563836), ('import', 0.8385692148820436)]
Top words for pretrained_BERT neuron indx 2878 [('pass', 1.0), ('send', 0.9087281133942507), ('15', 0.8823017629352996), ('None', 0.8336478942980129), ('sans', 0.831982080826733)]
Top words for pretrained_BERT neuron indx 6976 [('512', 1.0), ('256', 0.9313188771194), ('stat', 0.9077348448824845), ('80', 0.8626877237362607), ('999999', 0.824429523892161)]
Top words for pretrained_BERT neuron indx 6980 [('Distance', 1.0), ('"datetime"', 0.9195266879086422), ('choices', 0.8943130753113318), ('class', 0.8753986305371674), ('"location"', 0.8471208557202491)]
Top words for pretrained_BERT neuron indx 836 [('wait', 1.0), ('requests', 0.9798324096235045), ('sans', 0.9085537706665741), ('def', 0.7498561703188954), ('ping', 0.7450786316759105)]
Top words for pretrained_BERT neuron indx 2887 [('55', 1.0), ('Distance', 0.9682584404422727), ('horizon', 0.913467778435206), ('to', 0.89029066963092), ('50', 0.8876968240267159)]
Top words for pretrained_BERT neuron indx 6984 [('View', 1.0), ('for', 0.9431143190729181), ('None', 0.9117045505902226), ('boot', 0.9104014858092554), ('oslo', 0.8470959826712842)]
Top words for pretrained_BERT neuron indx 9033 [('bare', 1.0), ('465', 0.9370319581812617), ('oslo', 0.924421885820098), ('15597', 0.9047150078349585), ('1025', 0.8913230111495744)]
Top words for pretrained_BERT neuron indx 4936 [('23', 1.0), ('3785', 0.9852446856813024), ('95', 0.9658085984625814), ('False', 0.9349647132320581), ('36', 0.858599770272173)]
Top words for pretrained_BERT neuron indx 841 [('42', 1.0), ('GET', 0.9661371505248609), ('28', 0.9122671001068515), ('36', 0.7228693719950909), ('material', 0.7093519298108549)]
Top words for pretrained_BERT neuron indx 9044 [('80', 1.0), ('not', 0.9012050685820325), ('else', 0.8811621351262031), ('12', 0.8735002995794315), ('cert', 0.8699570499898823)]
Top words for pretrained_BERT neuron indx 2900 [('5', 1.0), ('proxy', 0.8590814678243525), ('800', 0.8588692660778372), ('ranges', 0.838417476866364), ('6', 0.8092749772694653)]
Top words for pretrained_BERT neuron indx 9047 [('69', 1.0), ('On', 0.9256046066244121), ('204', 0.7360330184609454), ('slug', 0.7089359032462615), ('reactor', 0.6960915560080156)]
Top words for pretrained_BERT neuron indx 858 [('wait', 1.0), ('return', 0.9637724776475914), ('bare', 0.9380199033325782), ('Tab', 0.9194818802615891), ('unbind_res', 0.7606677024243957)]
Top words for pretrained_BERT neuron indx 2909 [('False', 1.0), ('Tab', 0.9694049342772678), ('Mesh', 0.9195539278962858), ('import', 0.8882280356804214), ('204', 0.844445778289163)]
Top words for pretrained_BERT neuron indx 4962 [('Distance', 1.0), ('23', 0.9656751022738809), ('42', 0.9045824867859176), ('Stretch', 0.8037536165386922), ('21', 0.760753459750839)]
Top words for pretrained_BERT neuron indx 2917 [('Billboard', 1.0), ('topid', 0.9293977224221099), ('userid', 0.8165900474879547), ('WrongArgs', 0.7765996849743617), ('UCache', 0.6889860864955089)]
Top words for pretrained_BERT neuron indx 4971 [('Unauthorized', 1.0), ('or', 0.9853960791862609), ('512', 0.9782225594671455), ('LoadUser', 0.9500223326069597), ('port', 0.9292257879199395)]
Top words for pretrained_BERT neuron indx 4974 [('201', 1.0), ('while', 0.9779319967192935), ('sts', 0.9598700963194564), ('2014', 0.9505798632024945), ('future', 0.8783237532511372)]
Top words for pretrained_BERT neuron indx 893 [('31', 1.0), ('monkey_patch', 0.8908500995173202), ('raise', 0.8437995390962469), ('baseline', 0.8402005590409576), ('28', 0.7870802977976019)]
Top words for pretrained_BERT neuron indx 7039 [('"amount"', 1.0), ('"advertise_service"', 0.9983694164610944), ('750', 0.9564144595892803), ('for', 0.8926954292206157), ('95', 0.874888355623544)]
Top words for pretrained_BERT neuron indx 4993 [('except', 1.0), ('95', 0.9959263915410311), ('1970', 0.9811328700414396), ('69', 0.9091171458890133), ('2014', 0.8989427775808425)]
Top words for pretrained_BERT neuron indx 4997 [('baseline', 1.0), ('stanza', 0.962704386636092), ('iq', 0.887778958289103), ('disco_info', 0.8447755855307256), ('302', 0.7669261277994375)]
Top words for pretrained_BERT neuron indx 2954 [('unicode', 1.0), ('sans', 0.9811456743437541), ('201', 0.9332957124846557), ('continue', 0.9025105277519043), ('Plugin', 0.8538148536405142)]
Top words for pretrained_BERT neuron indx 5007 [('class', 1.0), ('95', 0.8234189571875813), ('baseline', 0.8153058769271072), ('del', 0.7705715397615058), ('closing', 0.7415553594667472)]
Top words for pretrained_BERT neuron indx 913 [('119', 1.0), ('117', 0.991008794593862), ('33', 0.9722440858296288), ('reactor', 0.9164110561630281), ('62', 0.9119267537960726)]
Top words for pretrained_BERT neuron indx 7058 [('servers', 1.0), ('builtins', 0.7923076336039343), ('Post', 0.7845678984246198), ('routes', 0.6732443710408306), ('route', 0.6595581856210243)]
Top words for pretrained_BERT neuron indx 7060 [('digest', 1.0), ('eg', 0.8563469745246761), ('31', 0.8496354808052033), ('Digest', 0.8220571138808889), ('36', 0.7491476462554127)]
Top words for pretrained_BERT neuron indx 2970 [('96', 1.0), ('1970', 0.970061244562428), ('connection', 0.9245112211599015), ('reactor', 0.8933113051612448), ('False', 0.8303586878912433)]
Top words for pretrained_BERT neuron indx 9115 [('36', 1.0), ('"required"', 0.9288936347851792), ('"shared"', 0.9145265939777598), ('35', 0.9140760812287277), ('"correct"', 0.9039295587450897)]
Top words for pretrained_BERT neuron indx 7068 [('117', 1.0), ('18', 0.8988370515984859), ('187', 0.8800461244684301), ('69', 0.8409788587089302), ('127', 0.7575606952891032)]
Top words for pretrained_BERT neuron indx 7078 [('wait', 1.0), ('"/_"', 0.9670655081500298), ('oslo', 0.9323942960893772), ('from', 0.8514800762347995), ('20', 0.8350731722880236)]
Top words for pretrained_BERT neuron indx 5031 [('400', 1.0), ('affinity', 0.9933994080442481), ('300', 0.9683198326038343), ('1800', 0.9533355874674968), ('pass', 0.9359874765438797)]
Top words for pretrained_BERT neuron indx 7088 [('2014', 1.0), ('"eng"', 0.9030920212059229), ('"SUCCEEDED"', 0.9007931661781889), ('"Authorization"', 0.8889724957127045), ('89.999999999999992', 0.8565328328428892)]
Top words for pretrained_BERT neuron indx 7096 [('to', 1.0), ('sans', 0.8319197285766675), ('2', 0.7666832088016403), ('_closed', 0.766546608365323), ('sts', 0.7598821455420126)]
Top words for pretrained_BERT neuron indx 952 [('iq', 1.0), ('boot', 0.8516206765621054), ('3700', 0.755570432361075), ('Board', 0.7119899723994418), ('board', 0.6987796490262002)]
Top words for pretrained_BERT neuron indx 7098 [('None', 1.0), ('not', 0.9364233118701882), ('presence', 0.8526964470610227), ('Off', 0.812865157659997), ('Unauthorized', 0.7966903387051987)]
Top words for pretrained_BERT neuron indx 3003 [('enabled', 1.0), ('standard_library', 0.9301815991643724), ('300', 0.8597703061908415), ('81.4471435546875', 0.8575254326563887), ('MSG', 0.8272703787617474)]
Top words for pretrained_BERT neuron indx 9149 [('None', 1.0), ('255', 0.958575221365923), ('closing', 0.8983822233076705), ('material', 0.8939613667063662), ('choices', 0.8651036947308572)]
Top words for pretrained_BERT neuron indx 962 [('while', 1.0), ('GET', 0.9706693041579801), ('host', 0.9528447256225301), ('55', 0.9453885978126005), ('not', 0.9352863483381381)]
Top words for pretrained_BERT neuron indx 964 [('40', 1.0), ('117', 0.9948607479484588), ('continue', 0.9480696014825547), ('2014', 0.7548183765907907), ('ignore', 0.7457219824273087)]
Top words for pretrained_BERT neuron indx 7108 [('40', 1.0), ('400', 0.792336457190744), ('60', 0.6749737310420441), ('300', 0.665685711884914), ('".."', 0.6595323872708997)]
Top words for pretrained_BERT neuron indx 3015 [('Tab', 1.0), ('modes', 0.8099694439265578), ('oslo', 0.7656904177207565), ('or', 0.762795050944617), ('60', 0.7289060890889412)]
Top words for pretrained_BERT neuron indx 3016 [('On', 1.0), ('probe', 0.9507999687354102), ('21', 0.8075478395912528), ('__title__', 0.7937581549053421), ('routes', 0.6908482799706801)]
Top words for pretrained_BERT neuron indx 7113 [('1970', 1.0), ('oslo', 0.9247683800363059), ('Renderer', 0.898263538976229), ('sans', 0.8279173803821588), ('"Spiderman"', 0.8151541815939276)]
Top words for pretrained_BERT neuron indx 969 [('material', 1.0), ('80', 0.8963996502026783), ('sans', 0.8791650347008011), ('shts', 0.8594287118553886), ('settings', 0.8413990697609212)]
Top words for pretrained_BERT neuron indx 9164 [('r\\\'"\\\\1\\\\2\\\\3"\\\'', 1.0), ('r\\\'\\\\"\\\'', 0.9757372926563886), ('21', 0.9073533871240076), ('"2:00:00:00"', 0.8846675340594607), ('62', 0.848796186497935)]
Top words for pretrained_BERT neuron indx 5069 [('"Spiderman"', 1.0), ('if', 0.9636875351136869), ('"indicators"', 0.939379941722872), ('Unauthorized', 0.9143455970259241), ('requests', 0.9020866126353612)]
Top words for pretrained_BERT neuron indx 9173 [('17', 1.0), ('63', 0.8372431965744442), ('204', 0.79092534324293), ('23', 0.7687869255426326), ('GetMirror', 0.73926460006732)]
Top words for pretrained_BERT neuron indx 989 [('None', 1.0), ('_hash', 0.9571602170155645), ('slug', 0.9302543971515782), ('GetUID', 0.9299930054285103), ('direct', 0.8975325727427866)]
Top words for pretrained_BERT neuron indx 5088 [('to', 1.0), ('"blink"', 0.8900090968442368), ('"HTTP_BEARER_TOKEN"', 0.8394581227722319), ('Register', 0.7998948063018202), ('with', 0.7868947682723332)]
Top words for pretrained_BERT neuron indx 993 [('302', 1.0), ('63', 0.980622457273943), ('settings', 0.9639382118735751), ('9', 0.9597186275156623), ('86400', 0.9328666734248188)]
Top words for pretrained_BERT neuron indx 994 [('baseline', 1.0), ('23', 0.6849814045596117), ('750', 0.6406667740199721), ('requests', 0.6168639283654271), ('42', 0.5737623681787204)]
Top words for pretrained_BERT neuron indx 9197 [('requests', 1.0), ('raise', 0.9607700018104257), ('ranges', 0.879156704509089), ('Distance', 0.8082831075722164), ('settings', 0.7562556794210509)]
Top words for pretrained_BERT neuron indx 3054 [('board', 1.0), ('probe', 0.9548731618371521), ('3785', 0.9001342641704775), ('Board', 0.8849108921957185), ('List', 0.880762945431291)]
Top words for pretrained_BERT neuron indx 5103 [('baseline', 1.0), ('class', 0.8399239010125894), ('2150', 0.7696865347287128), ('presence', 0.7614120372341298), ('from_', 0.6945773339285307)]
Top words for pretrained_BERT neuron indx 3059 [('3128', 1.0), ('80', 0.9936265744224706), ('60', 0.9692188082891057), ('600', 0.952160519944947), ('95', 0.9444097879811068)]
Top words for pretrained_BERT neuron indx 1019 [('17', 1.0), ('9', 0.8681259339319191), ('15', 0.853365195166379), ('18', 0.8509337807719383), ('35', 0.8509048143142071)]
Top words for pretrained_BERT neuron indx 3071 [('boot', 1.0), ('95', 0.9842545131051327), ('future', 0.9465438716942268), ('except', 0.9384784735336242), ('75', 0.8702752317424799)]
Top words for pretrained_BERT neuron indx 9218 [('4', 1.0), ('204', 0.7441074246009676), ('2014', 0.7089437608355755), ('GetMsgCount', 0.6735524861578615), ('255', 0.6699255043637193)]
Top words for pretrained_BERT neuron indx 3074 [('bare', 1.0), ('direct', 0.9482686101866545), ('reactor', 0.8015371789604375), ('digest', 0.782211259732532), ('sts', 0.7524615035135181)]
Top words for pretrained_BERT neuron indx 7174 [('69', 1.0), ('42', 0.8942298222541651), ('62', 0.8224002329756246), ('60', 0.7986089114092552), ('119', 0.7922323860854095)]
Top words for pretrained_BERT neuron indx 7176 [('unicode', 1.0), ('"this"', 0.9475329828201351), ('"VIEW_DEFINITION"', 0.9350375337059267), ('boot_order', 0.9041749543023231), ('port', 0.8954187241519127)]
Top words for pretrained_BERT neuron indx 3084 [('750', 1.0), ('42', 0.9929579009514286), ('GetRange', 0.9206536571272307), ('55', 0.9135291804088472), ('GetMirror', 0.8898238514413318)]
Top words for pretrained_BERT neuron indx 1038 [('future', 1.0), ('Simple', 0.9662668656549402), ('stat', 0.9602650721193485), ('16', 0.9270712097970225), ('17', 0.9139756248052818)]
Top words for pretrained_BERT neuron indx 9230 [('from_', 1.0), ('18', 0.9982752888012862), ('800', 0.9272204021107006), ('False', 0.8897105743854904), ('enabled', 0.8215812932298626)]
Top words for pretrained_BERT neuron indx 9232 [('"green"', 1.0), ('RemoveTags', 0.9650374379180313), ('"red"', 0.9499064280192623), ('"black"', 0.9210014881586935), ('requests', 0.9163546632760962)]
Top words for pretrained_BERT neuron indx 1041 [('import', 1.0), ('9', 0.9912227864767119), ('bare', 0.8732649104099992), ('63', 0.8491263349116057), ('12', 0.8464858120035283)]
Top words for pretrained_BERT neuron indx 3087 [('break', 1.0), ('"run"', 0.7375114691891548), ('15596', 0.7031463951636456), ('srv', 0.6860017420352004), ('slug', 0.6805198508341349)]
Top words for pretrained_BERT neuron indx 1040 [('materials', 1.0), ('False', 0.8935820020065431), ('sans', 0.8904364918393519), ('host', 0.884662853369006), ('hostname', 0.8676692585460141)]
Top words for pretrained_BERT neuron indx 7188 [('sconff', 1.0), ('"amount"', 0.9242506397013632), ('credential', 0.9218797336434112), ('is', 0.9161443283060152), ('"ORDINAL_POSITION"', 0.9104609204188804)]
Top words for pretrained_BERT neuron indx 3095 [('31', 1.0), ('continue', 0.7946560271523824), ('wait', 0.7782721347574477), ('0x00000001', 0.7526666641448886), ('material', 0.7506955627921738)]
Top words for pretrained_BERT neuron indx 7196 [('Plugin', 1.0), ('View', 0.8687642567061492), ('mtitle', 0.752572762375564), ('"Height"', 0.6799769684086697), ('"Width"', 0.6744767423162481)]
Top words for pretrained_BERT neuron indx 1054 [('96', 1.0), ('64', 0.7833641148078815), ('Off', 0.7784895167304137), ('del', 0.7539402009370716), ('sconff', 0.7462267300378803)]
Top words for pretrained_BERT neuron indx 5153 [('"file"', 1.0), ('"Category"', 0.7938080636391851), ('"green"', 0.7213660318268026), ('"HTTP"', 0.6826479264423728), ('NoPerm', 0.6470275316732608)]
Top words for pretrained_BERT neuron indx 7202 [('"KILLED"', 1.0), ('"define"', 0.9745019201203388), ('"include"', 0.9467328722253228), ('"example"', 0.804658966101617), ('"SUCCEEDED"', 0.7652407796694463)]
Top words for pretrained_BERT neuron indx 5154 [('200', 1.0), ('future', 0.9838198735245325), ('session', 0.9429734111868749), ('187', 0.8085721622717582), ('201', 0.8079282644566053)]
Top words for pretrained_BERT neuron indx 7205 [('is', 1.0), ('ignore', 0.9345504059737068), ('Unauthorized', 0.9077306966817197), ('1970', 0.9017344271858325), ('if', 0.8943134291713795)]
Top words for pretrained_BERT neuron indx 9254 [('14', 1.0), ('0x00000001', 0.9977964256418452), ('40', 0.8545638180806833), ('make_boot_settings_dict', 0.8137822412861809), ('else', 0.8110390188635912)]
Top words for pretrained_BERT neuron indx 5161 [('750', 1.0), ('break', 0.9652380067735234), ('servers', 0.8961319010685789), ('TabGroup', 0.8424157650102667), ('roster', 0.8280709677170622)]
Top words for pretrained_BERT neuron indx 3118 [('activity', 1.0), ('probe', 0.964419240647295), ('1000', 0.9354814150495988), ('1024', 0.899379871743578), ('4', 0.8402217164272097)]
Top words for pretrained_BERT neuron indx 1071 [('requests', 1.0), ('boot', 0.7859422445211728), ('feature', 0.7811327979669074), ('route', 0.7531565283038107), ('routes', 0.7345058008674599)]
Top words for pretrained_BERT neuron indx 1073 [('del', 1.0), ('material', 0.9296360088132382), ('future', 0.8552170926697926), ('1970', 0.813516115762793), ('55', 0.7948886547545427)]
Top words for pretrained_BERT neuron indx 1075 [('LoadUser', 1.0), ('pass', 0.986695720517561), ('push', 0.9767729960657009), ('Stretch', 0.9687747028524479), ('roster', 0.9151380376751126)]
Top words for pretrained_BERT neuron indx 7221 [('2014', 1.0), ('TabGroup', 0.8681543230036343), ('GetMirror', 0.8317165274694567), ('svc', 0.8183095254420749), ('Tab', 0.8132516888876232)]
Top words for pretrained_BERT neuron indx 1086 [('return', 1.0), ('False', 0.9962284775975087), ('freshtime', 0.9152978218055167), ('Board', 0.8718519544579049), ('except', 0.8656156620872978)]
Top words for pretrained_BERT neuron indx 5185 [('View', 1.0), ('choices', 0.9761875684584035), ('On', 0.9172475437491465), ('"fields"', 0.8672493872477084), ('14', 0.8192111153923953)]
Top words for pretrained_BERT neuron indx 1093 [('return', 1.0), ('direct', 0.8226804752535032), ('ranges', 0.8169426616097364), ('connection', 0.8068704298636769), ('cert', 0.7593131962758779)]
Top words for pretrained_BERT neuron indx 7241 [('127', 1.0), ('31', 0.8318334255636265), ('42', 0.7873217709801384), ('horizon', 0.7541139411643768), ('18', 0.6375548195262176)]
Top words for pretrained_BERT neuron indx 3147 [('On', 1.0), ('probe', 0.7921565352986493), ('board', 0.7336171476687665), ('"://"', 0.7255719783274777), ('MSG', 0.7026325071944673)]
Top words for pretrained_BERT neuron indx 1101 [('512', 1.0), ('horizon', 0.886880063721376), ('204', 0.8821633369599297), ('board', 0.803173414120532), ('Unauthorized', 0.7989657833838203)]
Top words for pretrained_BERT neuron indx 9295 [('is', 1.0), ('"MadeUp"', 0.9979829514520204), ('"04m"', 0.968102329757386), ('"06m"', 0.9529413955577875), ('"03m"', 0.9365326661058812)]
Top words for pretrained_BERT neuron indx 1106 [('vmac', 1.0), ('presence', 0.9958263656234416), ('activity', 0.7170300743517829), ('False', 0.6922842867007039), ('Simple', 0.6848772735153462)]
Top words for pretrained_BERT neuron indx 3157 [('stat', 1.0), ('"/_"', 0.9165230921235288), ('"://"', 0.8190068817609639), ('"--version"', 0.813019895360739), ('hpov', 0.8055969698583232)]
Top words for pretrained_BERT neuron indx 1110 [('affinity', 1.0), ('else', 0.7325930613130213), ('while', 0.6865916952739167), ('GET', 0.6631830811492663), ('raise', 0.6626331999203481)]
Top words for pretrained_BERT neuron indx 5209 [('Board', 1.0), ('bare', 0.9098015862925166), ('material', 0.8729908505756963), ('13', 0.8306990498372075), ('unicode', 0.8264911538401761)]
Top words for pretrained_BERT neuron indx 9308 [('21', 1.0), ('"darkgreen"', 0.8030218658788941), ('"darkblue"', 0.7479635674864503), ('"lightgray"', 0.7474621647385273), ('def', 0.6924981246875674)]
Top words for pretrained_BERT neuron indx 5213 [('except', 1.0), ('import', 0.7677711559026348), ('digest', 0.6688574676562296), ('False', 0.6569635903833189), ('"x86"', 0.6396477455977274)]
Top words for pretrained_BERT neuron indx 7260 [('Log', 1.0), ('7', 0.9878692816540025), ('6', 0.9622312928175926), ('else', 0.9041484047668432), ('stanza', 0.8900131527766626)]
Top words for pretrained_BERT neuron indx 7266 [('55', 1.0), ('21', 0.9653343387692386), ('95', 0.9635227196708483), ('63', 0.9059532600652059), ('302', 0.9007131611413067)]
Top words for pretrained_BERT neuron indx 3172 [('unicode', 1.0), ('Tab', 0.9919896250713474), ('2014', 0.8691090609123255), ('baseline', 0.84762996963368), ('201', 0.7783611425061944)]
Top words for pretrained_BERT neuron indx 5223 [('Distance', 1.0), ('ignore', 0.9283482191925577), ('64', 0.8812239558526515), ('slug', 0.8591046193278474), ('25', 0.8399868026917572)]
Top words for pretrained_BERT neuron indx 9320 [('69', 1.0), ('2014', 0.9833000478831727), ('17', 0.7717027373607597), ('"L"', 0.7231254835678231), ('7', 0.7147868893875842)]
Top words for pretrained_BERT neuron indx 1128 [('ranges', 1.0), ('10000', 0.6597227898712617), ('750', 0.6121878199342173), ('sts', 0.6100050394109868), ('iq', 0.6078205661987315)]
Top words for pretrained_BERT neuron indx 9329 [('NetworkProfileTab', 1.0), ('69', 0.9924663758355797), ('lightmap_index_dynamic', 0.9916921830750147), ('writedata', 0.9428070186150213), ('symlink', 0.9352498878092116)]
Top words for pretrained_BERT neuron indx 1139 [('digest', 1.0), ('enabled', 0.9487770999242198), ('Digest', 0.8585949625301755), ('try', 0.713355761044792), ('500', 0.6683950647509759)]
Top words for pretrained_BERT neuron indx 7286 [('class', 1.0), ('"FAILED"', 0.9444831697205657), ('"scan"', 0.9021484600285569), ('"weakchecksum"', 0.8928234977519126), ('256', 0.876142396208383)]
Top words for pretrained_BERT neuron indx 1152 [('probe', 1.0), ('List', 0.7774828465588753), ('119', 0.7656329031994958), ('9', 0.7463159588957248), ('23', 0.7314726567650706)]
Top words for pretrained_BERT neuron indx 1157 [('stanza', 1.0), ('__disco_items_ns__', 0.8929732216644731), ('200', 0.8742794960872536), ('100', 0.8731092049013907), ('__disco_info_ns__', 0.8719620994153837)]
Top words for pretrained_BERT neuron indx 7304 [('View', 1.0), ('with', 0.873285465219681), ('GetBoard', 0.8714268165853835), ('find_session', 0.870418980697452), ('Register', 0.7918549966730948)]
Top words for pretrained_BERT neuron indx 5258 [('201', 1.0), ('unicode', 0.8680948473529004), ('closing', 0.8273307209956554), ('302', 0.804669006403236), ('sans', 0.7708728538291484)]
Top words for pretrained_BERT neuron indx 5259 [('reactor', 1.0), ('proxy', 0.8766443679822067), ('3128', 0.8591177747074599), ('201', 0.8567008743920249), ('bare', 0.7623943630644506)]
Top words for pretrained_BERT neuron indx 5261 [('enabled', 1.0), ('baseline', 0.9502112878851925), ('Distance', 0.8198704730629413), ('continue', 0.7141717518202858), ('View', 0.7120319996459822)]
Top words for pretrained_BERT neuron indx 5263 [('55', 1.0), ('36', 0.8951932902447174), ('preload', 0.879141010531274), ('broadcast', 0.8671710619671735), ('ignore', 0.8214318361394536)]
Top words for pretrained_BERT neuron indx 1167 [('del', 1.0), ('baseline', 0.9185295163257697), ('send', 0.873377115597641), ('40', 0.871651555029238), ('host', 0.8404953746141969)]
Top words for pretrained_BERT neuron indx 3215 [('Unauthorized', 1.0), ('materials', 0.7941342924608118), ('24', 0.7571764936163333), ('256', 0.7377298424007241), ('xmlns', 0.7277947288518644)]
Top words for pretrained_BERT neuron indx 9364 [('session', 1.0), ('requests', 0.9177225144882525), ('14', 0.8734607327553503), ('modes', 0.8325089686855914), ('ranges', 0.7991989054265292)]
Top words for pretrained_BERT neuron indx 3228 [('117', 1.0), ('187', 0.7354993778504016), ('wait', 0.6627515638659804), ('18', 0.6518872988517049), ('Session', 0.6074653370602716)]
Top words for pretrained_BERT neuron indx 7326 [('"location"', 1.0), ('"turquoise"', 0.8719478292642996), ('sorting_order', 0.8619905667067651), ('"ip"', 0.8574741049307776), ('length_scale', 0.838555758640353)]
Top words for pretrained_BERT neuron indx 1191 [('_hash', 1.0), ('proxy', 0.9299720266610244), ('300', 0.8503364576909653), ('import', 0.8321167939025531), ('material', 0.8298537706590086)]
Top words for pretrained_BERT neuron indx 3244 [('port', 1.0), ('to', 0.8826146577715559), ('0.8', 0.8222205885422199), ('0.1', 0.815613875854926), ('Session', 0.7962166659334718)]
Top words for pretrained_BERT neuron indx 7340 [('ping', 1.0), ('750', 0.9831990137545222), ('affinity', 0.9651573249950279), ('port', 0.8939865158254428), ('slug', 0.8834934815180038)]
Top words for pretrained_BERT neuron indx 9390 [('24', 1.0), ('as', 0.8318817816061559), ('iq', 0.772458875944825), ('62', 0.7532189589090346), ('23', 0.7413337191467715)]
Top words for pretrained_BERT neuron indx 7348 [('or', 1.0), ('"ip"', 0.751396598084438), ('route', 0.6993452098953696), ('187', 0.6782354166249541), ('host', 0.6410500097770362)]
Top words for pretrained_BERT neuron indx 5301 [('Distance', 1.0), ('boot', 0.9989663513964976), ('while', 0.9669208261490381), ('part', 0.8427739806433433), ('LoadUser', 0.7407195808910562)]
Top words for pretrained_BERT neuron indx 3256 [('to', 1.0), ('sans', 0.9465160514667164), ('201', 0.8771885558822239), ('14', 0.8632929058427311), ('9', 0.8016393584858084)]
Top words for pretrained_BERT neuron indx 5309 [('None', 1.0), ('255', 0.7587547113512196), ('Off', 0.7349603799185308), ('Post', 0.7201533367334035), ('42', 0.6997768518418777)]
Top words for pretrained_BERT neuron indx 9406 [('sans', 1.0), ('baseline', 0.7620648023033172), ('normal_direction', 0.7612882468054282), ('sts', 0.7525246956445407), ('HorizontalBillboard', 0.7334535169837992)]
Top words for pretrained_BERT neuron indx 7363 [('part', 1.0), ('302', 0.9934628246991231), ('None', 0.9136375271736247), ('pxe', 0.8086892133881145), ('NotFound', 0.7746286090558747)]
Top words for pretrained_BERT neuron indx 3267 [('MAXBOARD', 1.0), ('204', 0.8863203187201594), ('VerticalBillboard', 0.8551309891564122), ('512', 0.8510892929322155), ('Board', 0.8481766814381123)]
Top words for pretrained_BERT neuron indx 9411 [('2014', 1.0), ('30', 0.9839917158547825), ('28', 0.936808668187882), ('187', 0.9100499717366308), ('1970', 0.9057512818592481)]
Top words for pretrained_BERT neuron indx 3273 [('True', 1.0), ('False', 0.8961750787463673), ('sans', 0.8684406102792444), ('Off', 0.8460379139433603), ('Board', 0.7787406447710968)]
Top words for pretrained_BERT neuron indx 9418 [('unicode', 1.0), ('"../../%s"', 0.9815351276968283), ('".."', 0.8355414581364587), ('from', 0.7498109040004342), ('ShadowCastingMode', 0.7453423645351893)]
Top words for pretrained_BERT neuron indx 9419 [('2014', 1.0), ('Distance', 0.7624314601262182), ('"next_hop_mtu"', 0.6976709966371474), ('"ApiKey"', 0.6630750593536033), ('187', 0.641709170218261)]
Top words for pretrained_BERT neuron indx 3276 [('oslo', 1.0), ('3128', 0.9655311590350049), ('96', 0.927196972868234), ('15598', 0.8518569658442464), ('del', 0.8477975550442026)]
Top words for pretrained_BERT neuron indx 7377 [('set_term_read', 1.0), ('"21111111111"', 0.9474296722925366), ('"1111111111"', 0.912927228888018), ('create_server_profile_template', 0.8957422593375909), ('get_term_read', 0.8463416358461376)]
Top words for pretrained_BERT neuron indx 7378 [('5001', 1.0), ('mesh', 0.8652700989087876), ('3128', 0.8612086410393642), ('3142', 0.8433133247796639), ('4095', 0.8096737216658597)]
Top words for pretrained_BERT neuron indx 1236 [('Register', 1.0), ('Log', 0.9590768811604257), ('ping', 0.8826483281229363), ('baseline', 0.869812179064472), ('Digest', 0.8132204466173808)]
Top words for pretrained_BERT neuron indx 1237 [('future', 1.0), ('Off', 0.936955130781073), ('continue', 0.9042647428664822), ('enabled', 0.8062761810834346), ('21', 0.756213863589118)]
Top words for pretrained_BERT neuron indx 1239 [('stat', 1.0), ('"example"', 0.6352484277995623), ('"extends"', 0.6048513996719981), ('"Development"', 0.596383573681169), ('break', 0.595091984029054)]
Top words for pretrained_BERT neuron indx 5342 [('117', 1.0), ('send', 0.9189233207201744), ('17', 0.9097362437011041), ('75', 0.8366532937152973), ('119', 0.8318279819862687)]
Top words for pretrained_BERT neuron indx 9445 [('baseline', 1.0), ('mesh', 0.9732316123096306), ('mesh3', 0.8389246625753136), ('iq', 0.8000243012151762), ('mesh1', 0.771991100265512)]
Top words for pretrained_BERT neuron indx 9450 [('89.999999999999992', 1.0), ('2014', 0.9911094431767746), ('999999', 0.9739650613113195), ('Renderer', 0.9439575166508161), ('"127.0.0.1"', 0.9261724522269903)]
Top words for pretrained_BERT neuron indx 9451 [('465', 1.0), ('affinity', 0.8897659662474448), ('oslo', 0.8650725050616406), ('55', 0.8428056356630639), ('horizon', 0.8384090870761958)]
Top words for pretrained_BERT neuron indx 1262 [('feature', 1.0), ('part', 0.967449036186363), ('connection', 0.8322137591012327), ('port', 0.8236012357711031), ('IPLEN', 0.8091615557856529)]
Top words for pretrained_BERT neuron indx 7407 [('closing', 1.0), ('63', 0.978279730906105), ('class', 0.9473071247751002), ('Off', 0.8772475455999673), ('69', 0.8762103348000961)]
Top words for pretrained_BERT neuron indx 3311 [('svc', 1.0), ('cfg', 0.960040461265914), ('Tab', 0.9178885268139398), ('MSG', 0.8532339633183569), ('GET', 0.8477868314887687)]
Top words for pretrained_BERT neuron indx 3323 [('material', 1.0), ('unicode', 0.9460929210107906), ('204', 0.9257553528904243), ('roster', 0.9114103136903933), ('16', 0.8817215494701113)]
Top words for pretrained_BERT neuron indx 1276 [('119', 1.0), ('activity', 0.9914372915421631), ('routes', 0.9359834772630334), ('Board', 0.9196443858234686), ('route', 0.9063954214110862)]
Top words for pretrained_BERT neuron indx 7420 [('activity', 1.0), ('material', 0.66098383410258), ('Tab', 0.6361783288939055), ('with', 0.6358591931237441), ('12', 0.6086848568384472)]
Top words for pretrained_BERT neuron indx 5376 [('187', 1.0), ('part', 0.8693001919456099), ('broadcast', 0.8330234027134711), ('600', 0.8266246700599124), ('baseline', 0.7423250965841129)]
Top words for pretrained_BERT neuron indx 9476 [('mesh', 1.0), ('Mesh', 0.8637121856392554), ('Simple', 0.5802687350796303), ('62', 0.5689365125495301), ('try', 0.5687862459219888)]
Top words for pretrained_BERT neuron indx 3333 [('List', 1.0), ('roster', 0.9360921641507937), ('wait', 0.6403127730337089), ('300', 0.6166834100144292), ('policy', 0.6158634803367785)]
Top words for pretrained_BERT neuron indx 3339 [('42', 1.0), ('True', 0.9678019864823276), ('for', 0.9207057839827916), ('40', 0.8992596888195635), ('choices', 0.8912337213315428)]
Top words for pretrained_BERT neuron indx 9491 [('__copyright__', 1.0), ('GET', 0.9420750601079968), ('Simple', 0.9123604102618748), ('getpid', 0.8858307734532389), ('__license__', 0.882690729906153)]
Top words for pretrained_BERT neuron indx 1300 [('part', 1.0), ('None', 0.9687533260152539), ('sort_mode', 0.9342357933349938), ('None_', 0.8999101215262041), ('128', 0.8958145665976196)]
Top words for pretrained_BERT neuron indx 1299 [('Billboard', 1.0), ('187', 0.8936045436470493), ('Mesh', 0.8656794366169549), ('Off', 0.8495727960827472), ('25', 0.8487139909594841)]
Top words for pretrained_BERT neuron indx 1301 [('bare', 1.0), ('or', 0.9465769092648206), ('"replace"', 0.8534303002341188), ('Unauthorized', 0.8405450212335458), ('stanza', 0.7881677534544617)]
Top words for pretrained_BERT neuron indx 1304 [('probe', 1.0), ('204', 0.8056104665844357), ('"payload"', 0.7686990695970175), ('"Superman"', 0.7434876197662078), ('"category"', 0.718882055516406)]
Top words for pretrained_BERT neuron indx 5404 [('requests', 1.0), ('host', 0.9526005715683694), ('View', 0.7004515492524253), ('unicode', 0.6691583269102668), ('builtins', 0.5837578293454786)]
Top words for pretrained_BERT neuron indx 9500 [('Plugin', 1.0), ('"lots!"', 0.9478453776213963), ('formatter_class', 0.9323478863362309), ('"once"', 0.9203683999380674), ('"django_zappa/*"', 0.905254442170615)]
Top words for pretrained_BERT neuron indx 9502 [('Distance', 1.0), ('BoardManager', 0.9777453919730188), ('"Demographics"', 0.9650856738952736), ('else', 0.930520042033307), ('"fuchsia"', 0.9274454635283504)]
Top words for pretrained_BERT neuron indx 1316 [('62', 1.0), ('choices', 0.9086912220083856), ('closing', 0.8415018230245154), ('Distance', 0.8117993806859553), ('_closed', 0.7834903272782393)]
Top words for pretrained_BERT neuron indx 3364 [('policy', 1.0), ('sconf', 0.958783639796353), ('36', 0.8234645645232299), ('62', 0.7819569465644818), ('Tab', 0.7452023173014194)]
Top words for pretrained_BERT neuron indx 9527 [('28', 1.0), ('18', 0.9706556425392954), ('"http://does.not.exist"', 0.8180157264141767), ('14', 0.789520386539549), ('17', 0.7524338535652845)]
Top words for pretrained_BERT neuron indx 9528 [('"example"', 1.0), ('8000', 0.9961976826486864), ('send', 0.9756317097582224), ('host', 0.9687443857101176), ('15597', 0.9433388096097877)]
Top words for pretrained_BERT neuron indx 7487 [('201', 1.0), ('False', 0.9228253759660427), ('else', 0.8372258689173084), ('100000', 0.827398521889486), ('or', 0.7485567950772922)]
Top words for pretrained_BERT neuron indx 9539 [('7', 1.0), ('"Spiderman"', 0.9930423955487436), ('__status__', 0.9748469784923293), ('32', 0.9437855769220407), ('1970', 0.906075607365033)]
Top words for pretrained_BERT neuron indx 5456 [('material', 1.0), ('materials', 0.9901324562718747), ('not', 0.8008433726803549), ('send', 0.7605367798589178), ('"DATA_TYPE"', 0.7517818790941097)]
Top words for pretrained_BERT neuron indx 3418 [('oslo', 1.0), ('probed', 0.8917280100583098), ('except', 0.8780722954237571), ('100000', 0.8488854782826888), ('0x00000001', 0.8332528743279074)]
Top words for pretrained_BERT neuron indx 1373 [('send', 1.0), ('sans', 0.9680686791140749), ('Mesh', 0.963072944790291), ('On', 0.9627225568114003), ('False', 0.9161428261822724)]
Top words for pretrained_BERT neuron indx 7519 [('42', 1.0), ('"append"', 0.6343930478217338), ('"showversion"', 0.6340830537192107), ('95', 0.6144947044189063), ('"in"', 0.6016581265114124)]
Top words for pretrained_BERT neuron indx 9571 [('unicode', 1.0), ('render_mode', 0.8753813677649557), ('proxy', 0.7883174098264614), ('camera_velocity_scale', 0.6883614481902892), ('enabled', 0.6586398373549688)]
Top words for pretrained_BERT neuron indx 5476 [('unicode', 1.0), ('baseline', 0.9599785194594965), ('del', 0.8890399629844912), ('2014', 0.8325771183600712), ('302', 0.7935140554798217)]
Top words for pretrained_BERT neuron indx 7528 [('return', 1.0), ('pingelem', 0.8850694375466273), ('ZmqProxy', 0.870923745473491), ('Billboard', 0.8614418022498138), ('IPLEN', 0.848354180397017)]
Top words for pretrained_BERT neuron indx 1386 [('None', 1.0), ('600', 0.9991505109871782), ('try', 0.8717009208972832), ('6', 0.8682120417270015), ('Stretch', 0.8490316542188548)]
Top words for pretrained_BERT neuron indx 3434 [('On', 1.0), ('Unauthorized', 0.9460391610978491), ('"purple"', 0.9458624294569894), ('1970', 0.9387326321132615), ('proxy', 0.88084897929621)]
Top words for pretrained_BERT neuron indx 7536 [('62', 1.0), ('"sequence"', 0.7311372858831852), ('42', 0.722636556317188), ('500', 0.7025682792332667), ('63', 0.6929256170946586)]
Top words for pretrained_BERT neuron indx 5490 [('contextlib', 1.0), ('5', 0.8423884542639359), ('xmlns', 0.8119165866134948), ('3', 0.8012160319393918), ('23.61432859499169', 0.7968983778369474)]
Top words for pretrained_BERT neuron indx 3446 [('256', 1.0), ('connection', 0.811676672673483), ('settings', 0.6957165898950574), ('True', 0.6838768899788958), ('15597', 0.6790776083876998)]
Top words for pretrained_BERT neuron indx 7553 [('GET', 1.0), ('symlink', 0.7415638234185182), ('"purple"', 0.7378611277013247), ('"oslo"', 0.7324738998806211), ('"mammouth"', 0.6662746890493626)]
Top words for pretrained_BERT neuron indx 3460 [('stat', 1.0), ('slug', 0.9702215397666667), ('servers', 0.7711612169264767), ('try', 0.7362244292790466), ('None', 0.7343336623325967)]
Top words for pretrained_BERT neuron indx 7566 [('95', 1.0), ('80', 0.9449496981095735), ('31', 0.877697986334467), ('IsBM', 0.8298737697408033), ('400', 0.8126603765859925)]
Top words for pretrained_BERT neuron indx 9615 [('horizon', 1.0), ('40', 0.8443786430625654), ('future', 0.7837698939123761), ('iq', 0.7371731834743989), ('30', 0.7282609357756326)]
Top words for pretrained_BERT neuron indx 1424 [('On', 1.0), ('broadcast', 0.9351316115510101), ('Distance', 0.9318520288654835), ('Simple', 0.8355677755264131), ('stanza', 0.829941078770193)]
Top words for pretrained_BERT neuron indx 9616 [('75', 1.0), ('mesh2', 0.9726740193469968), ('mesh3', 0.9664283113667808), ('mesh1', 0.9049717786279353), ('servers', 0.8998303170166565)]
Top words for pretrained_BERT neuron indx 1426 [('push', 1.0), ('Register', 0.8223819434856329), ('ignore', 0.806664338194461), ('1000', 0.7460747696749338), ('as', 0.741725220027497)]
Top words for pretrained_BERT neuron indx 1434 [('96', 1.0), ('1970', 0.8099488910217044), ('reactor', 0.7674817357199437), ('connection', 0.7630894429519844), ('24', 0.6830612225088726)]
Top words for pretrained_BERT neuron indx 9631 [('11', 1.0), ('69', 0.8863287473637678), ('2014', 0.8772736166441472), ('7', 0.8648506047381792), ('8', 0.7354767219864972)]
Top words for pretrained_BERT neuron indx 1445 [('raise', 1.0), ('direct', 0.7287672971103809), ('Mesh', 0.7152026820065192), ('mesh', 0.6855032099100926), ('Register', 0.6789653913332813)]
Top words for pretrained_BERT neuron indx 1451 [('95', 1.0), ('750', 0.9041609466312963), ('except', 0.8661870652158867), ('75', 0.8350959294804743), ('send', 0.8109538109980652)]
Top words for pretrained_BERT neuron indx 3503 [('25', 1.0), ('ranges', 0.8499744904256559), ('login', 0.8127018627773414), ('512', 0.7889293215491352), ('300', 0.7655518925339847)]
Top words for pretrained_BERT neuron indx 5562 [('not', 1.0), ('None', 0.8741525141603876), ('Unauthorized', 0.7024484108378619), ('Distance', 0.6729601409392226), ('Off', 0.6695974173123279)]
Top words for pretrained_BERT neuron indx 9660 [('"purple"', 1.0), ('"teal"', 0.9952188955895452), ('"lightgray"', 0.9134717068492065), ('mesh', 0.883486063339109), ('13', 0.8706348898518145)]
Top words for pretrained_BERT neuron indx 5571 [('VerticalBillboard', 1.0), ('512', 0.9525636706616445), ('HorizontalBillboard', 0.9340127992690191), ('204', 0.8725310131477522), ('MAXBOARD', 0.8577358863436162)]
Top words for pretrained_BERT neuron indx 5574 [('Off', 1.0), ('materials', 0.7914510422004953), ('"ip"', 0.7519456052688559), ('wait', 0.7357274116125765), ('unicode', 0.7233361395729397)]
Top words for pretrained_BERT neuron indx 9673 [('_hash', 1.0), ('srv', 0.931483603465692), ('512', 0.8953676067446368), ('NotFound', 0.8926393624787801), ('affinity', 0.8755501542689548)]
Top words for pretrained_BERT neuron indx 1482 [('connection', 1.0), ('128', 0.885818182346438), ('board', 0.8730489096556262), ('"</article>"', 0.8631861277969508), ('port', 0.8626528306967468)]
Top words for pretrained_BERT neuron indx 3529 [('unicode', 1.0), ('600', 0.9597177110539604), ('119', 0.95257565550802), ('500', 0.9403865455848786), ('12', 0.8733750536341898)]
Top words for pretrained_BERT neuron indx 3533 [('"distinct"', 1.0), ('"basic"', 0.9901155465931933), ('sconf', 0.9725592688829142), ('0.1', 0.9429395529565125), ('Board', 0.9391260145555965)]
Top words for pretrained_BERT neuron indx 1486 [('push', 1.0), ('while', 0.9637063846884478), ('Billboard', 0.9027763415359505), ('wait', 0.8651680094848142), ('1970', 0.8353514116762021)]
Top words for pretrained_BERT neuron indx 9681 [('"1.2.3"', 1.0), ('0.1', 0.9819779135188008), ('NotFound', 0.9117190312830249), ('750', 0.9064627145914687), ('"#bbbbbb"', 0.8732712182349304)]
Top words for pretrained_BERT neuron indx 1489 [('400', 1.0), ('send', 0.9349361377477868), ('try', 0.9099847357407284), ('GetString', 0.7653958270065867), ('connection', 0.7468413963966283)]
Top words for pretrained_BERT neuron indx 1493 [('17', 1.0), ('33', 0.9628556833544335), ('28', 0.9336701076213486), ('23', 0.9121387652284848), ('host', 0.8764261885177771)]
Top words for pretrained_BERT neuron indx 3552 [('ranges', 1.0), ('to', 0.9247862275731719), ('"HTTP_BEARER_TOKEN"', 0.7088773798835221), ('digest', 0.6982592797072467), ('36', 0.6445875280163851)]
Top words for pretrained_BERT neuron indx 9699 [('Distance', 1.0), ('ParticleSystemRenderMode', 0.7820174370004858), ('break', 0.7742922121271364), ('"OPTIONS"', 0.7250905974951782), ('74.616338', 0.6953456104252111)]
Top words for pretrained_BERT neuron indx 3561 [('ignore', 1.0), ('slug', 0.7271808407194157), ('Session', 0.6636297027573069), ('in', 0.6605257747765482), ('2150', 0.6242569378919431)]
Top words for pretrained_BERT neuron indx 5610 [('Off', 1.0), ('sans', 0.8829857679608912), ('class', 0.8804657488448169), ('freshtime', 0.8537445918961644), ('shts', 0.7848194563384397)]
Top words for pretrained_BERT neuron indx 7663 [('__copyright__', 1.0), ('or', 0.9975680362723309), ('"{}/{}"', 0.9719201534467007), ('"{}-{}-{}"', 0.9554427419882138), ('Register', 0.9106863008507203)]
Top words for pretrained_BERT neuron indx 5627 [('unicode', 1.0), ('session', 0.8288153100899618), ('roster', 0.7837947203094705), ('boot', 0.7153284087843351), ('Register', 0.6751699415862609)]
Top words for pretrained_BERT neuron indx 1538 [('Log', 1.0), ('sts', 0.979681323483792), ('stanza', 0.9439776401118661), ('bare', 0.8318154950487409), ('reactor', 0.8013379437648053)]
Top words for pretrained_BERT neuron indx 5636 [('mesh', 1.0), ('break', 0.7656166225243629), ('Mesh', 0.7555870742938458), ('class', 0.7380710232299426), ('mesh3', 0.7056586794119383)]
Top words for pretrained_BERT neuron indx 7686 [('from_', 1.0), ('8000', 0.9228988729512874), ('bare', 0.8322244277360119), ('20000', 0.8205337828851931), ('EffectiveId', 0.7862987209844908)]
Top words for pretrained_BERT neuron indx 3599 [('stanza', 1.0), ('55', 0.9988117301800866), ('refresh', 0.9627700072328048), ('302', 0.9306597953137604), ('300', 0.9197735136171773)]
Top words for pretrained_BERT neuron indx 7698 [('Simple', 1.0), ('75', 0.8789399445305973), ('port', 0.8424762002356028), ('32', 0.7878575806828995), ('True', 0.753680225628211)]
Top words for pretrained_BERT neuron indx 3605 [('None', 1.0), ('Unauthorized', 0.9082797132233871), ('or', 0.8957546594445182), ('62', 0.8456888179369372), ('600', 0.8452055841315651)]
Top words for pretrained_BERT neuron indx 3608 [('port', 1.0), ('probe', 0.8784701615898494), ('Register', 0.864226985617916), ('"this"', 0.7794861314535464), ('TabGroup', 0.7734195305684284)]
Top words for pretrained_BERT neuron indx 7708 [('"green"', 1.0), ('75', 0.9991004885721965), ('"yellow"', 0.9839060294591501), ('"teal"', 0.9549722767733305), ('r\\\'\\\\"\\\'', 0.9458914783209557)]
Top words for pretrained_BERT neuron indx 1564 [('302', 1.0), ('fcs', 0.9208528343845624), ('pass', 0.8738341166188006), ('requests', 0.8693572663053686), ('builtins', 0.8604082324671144)]
Top words for pretrained_BERT neuron indx 3613 [('probe', 1.0), ('"category"', 0.7921299492359853), ('"amount"', 0.7745580899600415), ('modes', 0.7685791887336968), ('"Tool"', 0.7369118057466985)]
Top words for pretrained_BERT neuron indx 5668 [('disco_info', 1.0), ('policy', 0.957240263787381), ('disco_items', 0.9275368858841053), ('36', 0.8961730560032195), ('unicode', 0.8478120361407502)]
Top words for pretrained_BERT neuron indx 7720 [('62', 1.0), ('presence', 0.9972721954999832), ('del', 0.9793580452982313), ('closing', 0.879356629495639), ('to', 0.8264699942995317)]
Top words for pretrained_BERT neuron indx 1578 [('unicode', 1.0), ('baseline', 0.7200840346368612), ('oslo', 0.680147742717021), ('slug', 0.6451964301370209), ('wait', 0.627802095788211)]
Top words for pretrained_BERT neuron indx 1595 [('future', 1.0), ('3128', 0.8688264541384775), ('oslo', 0.7574679568235239), ('boot', 0.7517062386483814), ('BBS_ROOT', 0.6781218168790105)]
Top words for pretrained_BERT neuron indx 3646 [('None', 1.0), ('Mesh', 0.9988820384550612), ('pass', 0.9896560167257056), ('sts', 0.9536566223803552), ('IsFile', 0.9458494817045278)]
Top words for pretrained_BERT neuron indx 3649 [('Tab', 1.0), ('1411135000', 0.8660603739430935), ('443', 0.8266175300098176), ('attachpos', 0.8133591545196358), ('bootModeSetting', 0.7850222519873143)]
Top words for pretrained_BERT neuron indx 9801 [('15597', 1.0), ('74.616338', 0.9417040851859318), ('horizon', 0.8962565444226551), ('is', 0.8766792933259908), ('1025', 0.8385740642315611)]
Top words for pretrained_BERT neuron indx 7753 [('oslo', 1.0), ('send', 0.8373549635111353), ('Board', 0.8245494936385908), ('42', 0.701243851682471), ('23.61432859499169', 0.6962329131600925)]
Top words for pretrained_BERT neuron indx 9815 [('69', 1.0), ('400', 0.7679585110188774), ('300', 0.7479114789543401), ('8000', 0.7384753410922216), ('MSG', 0.731372318188458)]
Top words for pretrained_BERT neuron indx 9817 [('15', 1.0), ('5', 0.9875802802950246), ('13', 0.9614739280609638), ('Register', 0.8753247487660293), ('2014', 0.8567473888453975)]
Top words for pretrained_BERT neuron indx 5722 [('Mesh', 1.0), ('material', 0.9432816105384315), ('Simple', 0.9349965191465686), ('not', 0.8972629886713955), ('oslo', 0.8566593441454295)]
Top words for pretrained_BERT neuron indx 7770 [('302', 1.0), ('broadcast', 0.9993931117556888), ('750', 0.8999145365279663), ('wait', 0.8542881959330262), ('oslo', 0.8121032588351176)]
Top words for pretrained_BERT neuron indx 3677 [('False', 1.0), ('mesh', 0.7504881710669761), ('import', 0.7363509189782681), ('Mesh', 0.7251206815191257), ('42', 0.7181422415159767)]
Top words for pretrained_BERT neuron indx 1634 [('iq', 1.0), ('MsgBox', 0.581760206300959), ('Simple', 0.5739727218571494), ('Unauthorized', 0.5599962421423208), ('slug', 0.5427009210769876)]
Top words for pretrained_BERT neuron indx 9832 [('fileno', 1.0), ('302', 0.9705880967697683), ('activity', 0.9378697448506816), ('modes', 0.8835529072533966), ('to', 0.8812359335944173)]
Top words for pretrained_BERT neuron indx 7787 [('127', 1.0), ('23.61432859499169', 0.9919292254435765), ('201', 0.9883582211476041), ('512', 0.9871399349494442), ('200', 0.9837388046019918)]
Top words for pretrained_BERT neuron indx 3701 [('ping', 1.0), ('List', 0.848755644907582), ('Billboard', 0.8237334914262581), ('ping_result', 0.726890033502832), ('16', 0.7219708046301985)]
Top words for pretrained_BERT neuron indx 7805 [('with', 1.0), ('proxy', 0.9985642200747498), ('vCard', 0.9481795431468926), ('slug', 0.9255119947033116), ('PolicyProfileTab', 0.879803167761771)]
Top words for pretrained_BERT neuron indx 7806 [('requests', 1.0), ('ping', 0.9520898140767056), ('"0000385c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.8206330821978906), ('"0800305c02001b006162636465666768696a6b6c6d6e6f70717273747576776162"', 0.8198531725870847), ('direct', 0.8029271775008112)]
Top words for pretrained_BERT neuron indx 3719 [('broadcast', 1.0), ('62', 0.8359652372845716), ('Mesh', 0.7836735689330282), ('17', 0.744059608751385), ('push', 0.7417497690033886)]
Top words for pretrained_BERT neuron indx 7823 [('Unauthorized', 1.0), ('port', 0.9773473377639879), ('127', 0.8668257127453678), ('and', 0.8618397614969564), ('256', 0.8043091468259963)]
Top words for pretrained_BERT neuron indx 5775 [('class', 1.0), ('95', 0.8817465491509783), ('del', 0.7947056375122983), ('closing', 0.7765819270746865), ('baseline', 0.699746555583148)]
Top words for pretrained_BERT neuron indx 3730 [('Tab', 1.0), ('Register', 0.9234432769386971), ('modes', 0.8869776137057414), ('material', 0.8320211139841185), ('ranges', 0.800597453389955)]
Top words for pretrained_BERT neuron indx 7826 [('servers', 1.0), ('Mesh', 0.7035826896874706), ('Post', 0.6805023427185446), ('mesh', 0.6580007298991155), ('builtins', 0.6531174451488075)]
Top words for pretrained_BERT neuron indx 7837 [('or', 1.0), ('62', 0.945756343544123), ('routes', 0.8002716947946421), ('"http://[%s]:%d"', 0.765600079096101), ('conn', 0.7549864679328975)]
Top words for pretrained_BERT neuron indx 1695 [('302', 1.0), ('201', 0.8537495223274204), ('ReceivedCloseStream', 0.758466318100959), ('builtins', 0.7262809260679485), ('SentCloseStream', 0.698902681772303)]
Top words for pretrained_BERT neuron indx 7846 [('50', 1.0), ('oslo', 0.9934772096847296), ('20', 0.9891505867818081), ('to', 0.9545274448505296), ('"/_"', 0.946710970315261)]
Top words for pretrained_BERT neuron indx 3752 [('1800', 1.0), ('15000', 0.7692145930420095), ('100000', 0.6885676359066611), ('800', 0.6590379914080443), ('8000', 0.6527571133896249)]
Top words for pretrained_BERT neuron indx 5803 [('1970', 1.0), ('continue', 0.889382429142249), ('pass', 0.8012012020097434), ('Distance', 0.7255118622273091), ('"year"', 0.7004806841651364)]
Top words for pretrained_BERT neuron indx 1710 [('Mesh', 1.0), ('mesh', 0.9699152719773105), ('oslo', 0.8326616292277491), ('Tab', 0.8138413964124026), ('stanza', 0.7627311885507244)]
Top words for pretrained_BERT neuron indx 7856 [('"ex"', 1.0), ('"eng"', 0.9665618133010982), ('2014', 0.9374201852729105), ('"TABLES"', 0.9030695888982744), ('"Test"', 0.8746633089113853)]
Top words for pretrained_BERT neuron indx 3761 [('187', 1.0), ('host', 0.9018256040385038), ('pass', 0.8127053922342152), ('None', 0.7916069227284804), ('try', 0.7773884245958275)]
Top words for pretrained_BERT neuron indx 3760 [('modes', 1.0), ('List', 0.7676090212463399), ('push', 0.6999530106044043), ('def', 0.6893435890089987), ('if', 0.6542980908799884)]
Top words for pretrained_BERT neuron indx 5812 [('On', 1.0), ('1000', 0.9642770367636606), ('5001', 0.9485195959528663), ('100000', 0.9274606326966568), ('host', 0.9245175177724314)]
Top words for pretrained_BERT neuron indx 1717 [('route', 1.0), ('from', 0.9710814599003873), ('routes', 0.886709500666316), ('settings', 0.8589861348430806), ('Log', 0.8507784178530419)]
Top words for pretrained_BERT neuron indx 1720 [('14', 1.0), ('iq', 0.9804817153444242), ('def', 0.8577836596557477), ('3700', 0.854481031030986), ('board', 0.8358604762345295)]
Top words for pretrained_BERT neuron indx 9917 [('None', 1.0), ('GetBoard', 0.9279999311916792), ('GetMirror', 0.9098363258002176), ('255', 0.8910910187650084), ('55', 0.8697361963250398)]
Top words for pretrained_BERT neuron indx 3773 [('None', 1.0), ('enabled', 0.9883480967318263), ('sts', 0.9558291220418158), ('256', 0.8776034892522464), ('reactor', 0.8571533689858761)]
Top words for pretrained_BERT neuron indx 1727 [('session', 1.0), ('18', 0.9259586693657151), ('64', 0.9178004949336999), ('63', 0.9153439627132379), ('36', 0.909617925530802)]
Top words for pretrained_BERT neuron indx 5826 [('to', 1.0), ('ignore', 0.9307414037295045), ('"j"', 0.9007768132375039), ('75', 0.8789756499425465), ('"FAILED"', 0.8590139303984178)]
Top words for pretrained_BERT neuron indx 1733 [('Distance', 1.0), ('material', 0.8942545569990141), ('42', 0.854045203594658), ('or', 0.8257124837701454), ('IPLEN', 0.7862421832780476)]
Top words for pretrained_BERT neuron indx 1741 [('GET', 1.0), ('continue', 0.8128891642040358), ('if', 0.8016425043034504), ('465', 0.7290371265801777), ('3785', 0.722095718638557)]
Top words for pretrained_BERT neuron indx 3790 [('Billboard', 1.0), ('750', 0.9393053713079026), ('117', 0.8303452500203048), ('while', 0.8246191894306522), ('35', 0.7653891761648212)]
Top words for pretrained_BERT neuron indx 5841 [('to', 1.0), ('18', 0.9841686218210635), ('"harvest"', 0.9439060704334823), ('activity', 0.9152676623326487), ('broadcast', 0.8360147332143727)]
Top words for pretrained_BERT neuron indx 9947 [('horizon', 1.0), ('"21111111111"', 0.9954353107383811), ('7', 0.9884422366179426), ('GetBoard', 0.9821291066481718), ('"1111111111"', 0.9458340703345165)]
Top words for pretrained_BERT neuron indx 7912 [('fileno', 1.0), ('st_mode', 0.9324847345869869), ('Unauthorized', 0.8410339285434386), ('getpid', 0.767377465076671), ('get_resources', 0.7573369033346583)]
Top words for pretrained_BERT neuron indx 7913 [('62', 1.0), ('Log', 0.8839649444630793), ('or', 0.7902039499570421), ('36', 0.7404875658624257), ('400', 0.7102119492848354)]
Top words for pretrained_BERT neuron indx 7914 [('to', 1.0), ('Off', 0.9278375014711635), ('21', 0.8571812134205649), ('999999', 0.8070471709482431), ('digest', 0.8016463350523763)]
Top words for pretrained_BERT neuron indx 5870 [('connection', 1.0), ('port', 0.9909165707718185), ('choices', 0.8746186334105318), ('"KILLED"', 0.8318930844507497), ('enabled', 0.8286973535621363)]
Top words for pretrained_BERT neuron indx 5871 [('baseline', 1.0), ('Off', 0.7686408060158004), ('to', 0.7179832539635289), ('class', 0.6938049965909295), ('in', 0.6737057634291712)]
Top words for pretrained_BERT neuron indx 9976 [('material', 1.0), ('"ip"', 0.9243814244843791), ('20', 0.8802221931450713), ('Simple', 0.8342929448821798), ('Distance', 0.8079652807277842)]
Top words for pretrained_BERT neuron indx 7929 [('15596', 1.0), ('15598', 0.9555757089179888), ('15597', 0.9013050313277571), ('1024', 0.8782790898066948), ('89.999999999999992', 0.8497070513036235)]
Top words for pretrained_BERT neuron indx 1787 [('17', 1.0), ('35', 0.9294527127166315), ('9', 0.8915559993262412), ('14', 0.8712513282422047), ('16', 0.8646304642757808)]
Top words for pretrained_BERT neuron indx 5884 [('activity', 1.0), ('routes', 0.5906378825933093), ('Tab', 0.5828512451499799), ('Off', 0.5750509164064738), ('13', 0.5732989165036084)]
Top words for pretrained_BERT neuron indx 3839 [('boot', 1.0), ('95', 0.812047271786993), ('__copyright__', 0.7884577315156743), ('__title__', 0.7769960051885442), ('except', 0.7593741247408051)]
Top words for pretrained_BERT neuron indx 3842 [('bare', 1.0), ('7', 0.9620505956401489), ('digest', 0.9174100603756087), ('sans', 0.8928888865297878), ('Digest', 0.8642889494313455)]
Top words for pretrained_BERT neuron indx 1794 [('unicode', 1.0), ('Tab', 0.8465558171263562), ('255', 0.6644797531322243), ('Register', 0.6485862245456719), ('xmpp', 0.6464727751780828)]
Top words for pretrained_BERT neuron indx 3845 [('affinity', 1.0), ('21', 0.9501431678500425), ('40', 0.9453894887205875), ('Off', 0.9434225160991321), ('stat', 0.886229203827199)]
Top words for pretrained_BERT neuron indx 7944 [('port', 1.0), ('boot', 0.959752152178741), ('Stretch', 0.9338446999798256), ('95', 0.9329868229070369), ('unicode', 0.9275825625220755)]
Top words for pretrained_BERT neuron indx 3852 [('750', 1.0), ('GetRange', 0.9221332633454132), ('42', 0.9057707026584337), ('GetMirror', 0.9045231530962955), ('55', 0.8972735834494293)]
Top words for pretrained_BERT neuron indx 3855 [('break', 1.0), ('GET', 0.9278945885586669), ('Tab', 0.8820433258890225), ('srv', 0.7844118516123164), ('"run"', 0.7763242054629789)]
Top words for pretrained_BERT neuron indx 7957 [('or', 1.0), ('settings', 0.8709152920280221), ('35', 0.78763179439235), ('else', 0.7786242362397834), ('Billboard', 0.7763767724348032)]
Top words for pretrained_BERT neuron indx 5909 [('or', 1.0), ('False', 0.9730423066439375), ('digest', 0.9334543421470868), ('horizon', 0.8903226075176206), ('Digest', 0.8712211635519219)]
Top words for pretrained_BERT neuron indx 7959 [('session', 1.0), ('Session', 0.974578962647557), ('NoPerm', 0.9447660935825134), ('XMPPServer', 0.8804276840080416), ('80', 0.8780833952180123)]
Top words for pretrained_BERT neuron indx 1818 [('probe', 1.0), ('69', 0.7824129363261606), ('ping', 0.7213233621922066), ('Register', 0.6601032912893243), ('del', 0.6110086085491356)]
Top words for pretrained_BERT neuron indx 7970 [('to', 1.0), ('"define"', 0.9682809068375513), ('"KILLED"', 0.9636086726482411), ('"include"', 0.9525888119508352), ('"eu-west-1"', 0.8494772304722547)]
Top words for pretrained_BERT neuron indx 7979 [('reactor', 1.0), ('baseline', 0.8677334147271215), ('stanza', 0.8069538625436921), ('board', 0.711279405322816), ('broadcast', 0.7043189132122435)]
Top words for pretrained_BERT neuron indx 3886 [('1000', 1.0), ('probe', 0.9452720742339207), ('activity', 0.9021527115726351), ('86400', 0.8534863516750303), ('21', 0.8407600985297223)]
Top words for pretrained_BERT neuron indx 1839 [('requests', 1.0), ('routes', 0.8198055067554705), ('boot', 0.8047408493446941), ('route', 0.7875223440925198), ('1000', 0.7603958305926423)]
Top words for pretrained_BERT neuron indx 1841 [('1970', 1.0), ('slug', 0.9647519710072915), ('material', 0.9244370095176462), ('del', 0.8508376200317502), ('affinity', 0.7569552622470757)]
Top words for pretrained_BERT neuron indx 7999 [('750', 1.0), ('3785', 0.9469705863701604), ('74.616338', 0.9291531652447472), ('is', 0.9122989920777205), ('4095', 0.905079014395877)]
Top words for pretrained_BERT neuron indx 1857 [('activity', 1.0), ('svc', 0.91673193131935), ('Tab', 0.80412099032998), ('choices', 0.7706009831557672), ('oslo', 0.7463289956735315)]
Top words for pretrained_BERT neuron indx 3908 [('choices', 1.0), ('Distance', 0.9221548091022209), ('continue', 0.7983345163293725), ('broadcast', 0.7557062413133262), ('sans', 0.7525958428147524)]
Top words for pretrained_BERT neuron indx 5959 [('50', 1.0), ('35', 0.8997793268372458), ('1970', 0.8743927026241766), ('300', 0.8460402125105397), ('Distance', 0.8389775694860216)]
Top words for pretrained_BERT neuron indx 8009 [('127', 1.0), ('42', 0.8179916260578916), ('31', 0.8027742035680004), ('login', 0.746668874603138), ('18', 0.7293451597229975)]
Top words for pretrained_BERT neuron indx 3915 [('On', 1.0), ('2.1', 0.8707439593341202), ('62', 0.8482507036235388), ('readfp', 0.8374454963874639), ('eg', 0.8348879034352984)]
Top words for pretrained_BERT neuron indx 1869 [('512', 1.0), ('256', 0.6908794811527886), ('204', 0.67347357442826), ('Unauthorized', 0.6684567451017509), ('board', 0.6487014875135191)]
Top words for pretrained_BERT neuron indx 1871 [('boot', 1.0), ('class', 0.9377356571309541), ('"title"', 0.913631611772322), ('cert', 0.910853591837738), ('srv', 0.9076297014420333)]
Top words for pretrained_BERT neuron indx 5968 [('boot', 1.0), ('View', 0.9994762093427655), ('proxy', 0.9047147542334403), ('Post', 0.8469912154745309), ('probe', 0.7916489594934989)]
Top words for pretrained_BERT neuron indx 1880 [('42', 1.0), ('18', 0.9479579943016814), ('80', 0.9016291403423476), ('36', 0.8738332431174745), ('69', 0.8580347081295443)]
Top words for pretrained_BERT neuron indx 5979 [('512', 1.0), ('try', 0.9612976598663292), ('2.1', 0.8622815976734965), ('3785', 0.8618161710758084), ('"transmission"', 0.8249008548717515)]
Top words for pretrained_BERT neuron indx 1885 [('69', 1.0), ('slug', 0.8265147348479507), ('75', 0.7968658773921505), ('affinity', 0.7953339990927338), ('boot', 0.7453883185177872)]
Top words for pretrained_BERT neuron indx 8034 [('55', 1.0), ('try', 0.9719892039088448), ('__title__', 0.9531390366544032), ('__status__', 0.9478250168119015), ('21', 0.9451515259586837)]
Top words for pretrained_BERT neuron indx 3940 [('unicode', 1.0), ('2014', 0.9627084701528345), ('baseline', 0.8375558942662142), ('Tab', 0.7805132645427407), ('201', 0.7583882948179181)]
Top words for pretrained_BERT neuron indx 5989 [('18', 1.0), ('187', 0.9201727759622397), ('69', 0.8623331529919355), ('300', 0.8330456014016467), ('33', 0.7956305700492785)]
Top words for pretrained_BERT neuron indx 5991 [('Plugin', 1.0), ('69', 0.8735028892538466), ('proxy', 0.8664514646472266), ('Unauthorized', 0.8464774287261204), ('64', 0.83504449061874)]
Top words for pretrained_BERT neuron indx 5997 [('wait', 1.0), ('"HTTP/"', 0.8206031812795084), ('1970', 0.8167333738269603), ('slug', 0.778745087677561), ('2014', 0.7781728830857677)]
Top words for pretrained_BERT neuron indx 8054 [('95', 1.0), ('Stretch', 0.9560106882167575), ('class', 0.9498548776457396), ('"scan"', 0.9420134530302138), ('18', 0.9107871772491402)]
Top words for pretrained_BERT neuron indx 1919 [('proxy', 1.0), ('75', 0.8248841745278086), ('750', 0.7855505326751588), ('200', 0.7637385583490788), ('def', 0.7486556646273994)]
Top words for pretrained_BERT neuron indx 3972 [('vCard', 1.0), ('0o555', 0.9978827171234516), ('42', 0.9402518919689924), ('1411135000', 0.9399167805872849), ('62', 0.9375801614890104)]
Top words for pretrained_BERT neuron indx 1925 [('stanza', 1.0), ('baseline', 0.9581727157760901), ('200', 0.8238796234090371), ('iq', 0.8068426422923485), ('100', 0.7891190417685996)]
Top words for pretrained_BERT neuron indx 6022 [('sorting_order', 1.0), ('boot_order', 0.7625409271118151), ('Distance', 0.7404318653923567), ('slug', 0.7291244289051156), ('4', 0.7120351518818835)]
Top words for pretrained_BERT neuron indx 8072 [('View', 1.0), ('with', 0.9111536365535732), ('GetBoard', 0.900418862669795), ('0x00000001', 0.8701525015756504), ('0x00', 0.8531040479959006)]
Top words for pretrained_BERT neuron indx 8079 [('baseline', 1.0), ('horizon', 0.9584698856652976), ('future', 0.85462880463977), ('host', 0.8339602435399482), ('class', 0.8317915566001084)]
Top words for pretrained_BERT neuron indx 6033 [('srv', 1.0), ('route', 0.9544349497473591), ('host', 0.9246573885273142), ('modes', 0.8875733861150584), ('svc', 0.8441172644547672)]
Top words for pretrained_BERT neuron indx 3996 [('117', 1.0), ('187', 0.7614977341895636), ('wait', 0.7524197152951247), ('18', 0.6846060109789079), ('69', 0.6637955066285496)]
Top words for pretrained_BERT neuron indx 6056 [('100000', 1.0), ('1800', 0.9844510701718425), ('routes', 0.8148285989492674), ('1000', 0.8087657768648984), ('200', 0.7703368079186744)]
Top words for pretrained_BERT neuron indx 1966 [('raise', 1.0), ('View', 0.8853673554119224), ('proxy', 0.8188662723030845), ('activity', 0.7082576736862164), ('stanza', 0.6926018698143929)]
Top words for pretrained_BERT neuron indx 1972 [('1000', 1.0), ('oslo', 0.7543314240163344), ('33', 0.7375352546917863), ('except', 0.7321145392378197), ('check_msg', 0.6995091794139662)]
Top words for pretrained_BERT neuron indx 6068 [('62', 1.0), ('"eng"', 0.936806897718181), ('try', 0.8846936828562361), ('"E"', 0.8653921015273573), ('part', 0.8471507637420033)]
Top words for pretrained_BERT neuron indx 1974 [('iq', 1.0), ('Tab', 0.9283327501525748), ('probe', 0.8357962174106517), ('route', 0.8183635097499398), ('break', 0.7848183220726194)]
Top words for pretrained_BERT neuron indx 8124 [('mesh', 1.0), ('port', 0.9255532123978543), ('materials', 0.8763804793532767), ('Mesh', 0.7880802542791991), ('100000', 0.6809065725205715)]
Top words for pretrained_BERT neuron indx 6077 [('None', 1.0), ('255', 0.8130736673349872), ('Off', 0.7437108751286097), ('reactor', 0.6956469187444894), ('Post', 0.6625710012302372)]
Top words for pretrained_BERT neuron indx 1987 [('unicode', 1.0), ('800', 0.9924790479769066), ('1000', 0.9372091962267666), ('enabled', 0.9338963909019461), ('11', 0.9288784449996589)]
Top words for pretrained_BERT neuron indx 4041 [('material', 1.0), ('sans', 0.9541492658730023), ('True', 0.8827736867006007), ('not', 0.859486541374453), ('False', 0.8462308514138531)]
Top words for pretrained_BERT neuron indx 2004 [('Log', 1.0), ('ping', 0.9631972673450687), ('pingelem', 0.8918629426474045), ('Register', 0.88930423835526), ('closing', 0.8845019236825451)]
Top words for pretrained_BERT neuron indx 6101 [('"Windows"', 1.0), ('28', 0.9031657398412907), ('23', 0.8736108555387289), ('204', 0.8417494374578963), ('Unauthorized', 0.8131043589644664)]
Top words for pretrained_BERT neuron indx 2005 [('Off', 1.0), ('settings', 0.7147463250425256), ('stanza', 0.7065696363176562), ('View', 0.6981632676960869), ('future', 0.6410879188690844)]
Top words for pretrained_BERT neuron indx 2021 [('iq', 1.0), ('Mesh', 0.916905380072324), ('63', 0.8553105381871133), ('stanza', 0.8076165430387664), ('None', 0.8062392899277642)]
Top words for pretrained_BERT neuron indx 6129 [('1970', 1.0), ('15597', 0.9493223436163756), ('return', 0.9043372969973938), ('3128', 0.8757961196699687), ('List', 0.868178885170045)]
Top words for pretrained_BERT neuron indx 2038 [('presence', 1.0), ('affinity', 0.9004695650735012), ('in', 0.8563163732674676), ('material', 0.7762927680275312), ('500', 0.7640632407566237)]
Top words for pretrained_BERT neuron indx 8182 [('with', 1.0), ('"ttl"', 0.8359693888510275), ('unicode', 0.8328655480071314), ('login', 0.8116650426380734), ('utmpent', 0.808204084741096)]
Top words for pretrained_BERT neuron indx 2046 [('host', 1.0), ('send', 0.9991527302367215), ('ranges', 0.8752403302802481), ('750', 0.8261785317548429), ('fcs', 0.8120276079588051)]
Creating control dataset for pretrained_BERT POS tagging task
Training classification probe
Creating model...
Number of training instances: 4165
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0074
Epoch: [3/10], Loss: 0.0080
Epoch: [4/10], Loss: 0.0117
Epoch: [5/10], Loss: 0.0113
Epoch: [6/10], Loss: 0.0062
Epoch: [7/10], Loss: 0.0058
Epoch: [8/10], Loss: 0.0072
Epoch: [9/10], Loss: 0.0074
Epoch: [10/10], Loss: 0.0049
Score (accuracy) of the probe: 0.26
Training classification probe
Creating model...
Number of training instances: 4165
Number of classes: 4
Epoch: [1/10], Loss: 0.0090
Epoch: [2/10], Loss: 0.0072
Epoch: [3/10], Loss: 0.0076
Epoch: [4/10], Loss: 0.0115
Epoch: [5/10], Loss: 0.0111
Epoch: [6/10], Loss: 0.0071
Epoch: [7/10], Loss: 0.0078
Epoch: [8/10], Loss: 0.0083
Epoch: [9/10], Loss: 0.0071
Epoch: [10/10], Loss: 0.0061
Score (accuracy) of the probe: 0.26
Training classification probe
Creating model...
Number of training instances: 4165
Number of classes: 4
Epoch: [1/10], Loss: 0.0092
Epoch: [2/10], Loss: 0.0077
Epoch: [3/10], Loss: 0.0073
Epoch: [4/10], Loss: 0.0098
Epoch: [5/10], Loss: 0.0103
Epoch: [6/10], Loss: 0.0065
Epoch: [7/10], Loss: 0.0056
Epoch: [8/10], Loss: 0.0071
Epoch: [9/10], Loss: 0.0084
Epoch: [10/10], Loss: 0.0096
Score (accuracy) of the probe: 0.23
Training classification probe
Creating model...
Number of training instances: 4165
Number of classes: 4
Epoch: [1/10], Loss: 0.0102
Epoch: [2/10], Loss: 0.0090
Epoch: [3/10], Loss: 0.0096
Epoch: [4/10], Loss: 0.0124
Epoch: [5/10], Loss: 0.0130
Epoch: [6/10], Loss: 0.0084
Epoch: [7/10], Loss: 0.0069
Epoch: [8/10], Loss: 0.0071
Epoch: [9/10], Loss: 0.0069
Epoch: [10/10], Loss: 0.0080
Score (accuracy) of the probe: 0.25

The best l1=0, the best l2=0 for pretrained_BERT_control_task
Accuracy on the test set of probing pretrained_BERT_control_task of all layers:
Score (accuracy) of the probe: 0.34
Accuracy on the test set of pretrained_BERT_control_task model using the intercept:
Score (accuracy) of the probe: 0.24

pretrained_BERT_control_task Selectivity (Diff. between true task and probing task performance):  0.4363425925925926
----------------------------------------------------------------
