Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_BERT
Loading json activations from bert_activations.json...
32002 13.0
Number of tokens:  325100
length of source dictionary:  17255
length of target dictionary:  47
325100
Total instances: 325100
['"model.x"', 'testConvertFixedCoshaderArrayToDynamicWithFirstPlugUnconnected', '"verbose"', 'NCS_SERVICES_URL', 'JsonEventHandler', 'container_children_recur', 'google', 'ExecComp', 'output_prefix', 'get_java_remote_console_url', 'Expression', 'CONFIG_ONE', 'issubclass', 'oneOf', 'queries', 'test_metrics', 'sqlite3', 'GetFeatureWithLock', 'calculators', '"1m"']
Number of samples:  325100
Stats: Labels with their frequencies in the final set
NAME 104243
NEWLINE 28415
DOT 27737
LPAR 24899
RPAR 23914
KEYWORD 21043
COMMA 18332
EQUAL 15063
COLON 10649
DEDENT 8365
INDENT 7255
LSQB 7221
RSQB 7056
NUMBER 6667
STRING 3985
NL 3586
PLUS 928
LBRACE 870
EQEQUAL 827
MINUS 701
RBRACE 673
STAR 606
PERCENT 459
DOUBLESTAR 242
PLUSEQUAL 204
GREATER 187
SLASH 177
NOTEQUAL 176
AT 165
LESS 90
COMMENT 72
GREATEREQUAL 55
LESSEQUAL 40
VBAR 39
LEFTSHIFT 32
SEMI 22
MINEQUAL 21
AMPER 20
DOUBLESLASH 19
STAREQUAL 16
TILDE 10
ELLIPSIS 6
VBAREQUAL 5
RIGHTSHIFT 3
SLASHEQUAL 2
ERRORTOKEN 2
AMPEREQUAL 1
pretrained_BERT distribution:
{0: 104243, 1: 28415, 2: 27737, 3: 24899, 4: 23914, 5: 21043, 6: 18332, 7: 15063, 8: 10649, 9: 8365, 10: 7255, 11: 7221, 12: 7056, 13: 6667, 14: 3985, 15: 3586, 16: 928, 17: 870, 18: 827, 19: 701, 20: 673, 21: 606, 22: 459, 23: 242, 24: 204, 25: 187, 26: 177, 27: 176, 28: 165, 29: 90, 30: 72, 31: 55, 32: 40, 33: 39, 34: 32, 35: 22, 36: 21, 37: 20, 38: 19, 39: 16, 40: 10, 41: 6, 42: 5, 43: 3, 44: 2, 45: 2, 46: 1}
pretrained_BERT distribution after trauncating:
{0: 0.3206677720322012, 1: 0.0874089842223938, 2: 0.08532335018041658, 3: 0.07659321830559153, 4: 0.07356320424755676, 5: 0.06473155921139655, 6: 0.05639209919989172, 7: 0.04633614391490121, 8: 0.03275798954722054, 9: 0.025732048320264794, 10: 0.022317514711718004, 11: 0.022212925393978733, 12: 0.021705359587302856, 13: 0.020508734746109432, 14: 0.012258483270323396, 15: 0.011031096865089008, 16: 0.002854673143001283, 17: 0.0026762560715637026, 18: 0.0025439813461875654, 19: 0.0021563856392714433, 20: 0.002070253259956749, 21: 0.0018641507808823032, 22: 0.0014119557894801604, 23: 0.0007444298497912828, 24: 0.0006275359064356268, 25: 0.0005752412475659912, 26: 0.0005444796835250292, 27: 0.0005414035271209329, 28: 0.0005075658066758746, 29: 0.0002768540763686589, 30: 0.0002214832610949271, 31: 0.00016918860222529155, 32: 0.0001230462561638484, 33: 0.00011997009975975218, 34: 9.843700493107872e-05, 35: 6.767544089011662e-05, 36: 6.45992844860204e-05, 37: 6.15231280819242e-05, 38: 5.8446971677827984e-05, 39: 4.921850246553936e-05, 40: 3.07615640409621e-05}
Training classification probe
Creating model...
Number of training instances: 260064
Number of classes: 41
Epoch: [1/10], Loss: 0.0298
Epoch: [2/10], Loss: 0.0293
Epoch: [3/10], Loss: 0.0290
Epoch: [4/10], Loss: 0.0286
Epoch: [5/10], Loss: 0.0286
Epoch: [6/10], Loss: 0.0288
Epoch: [7/10], Loss: 0.0283
Epoch: [8/10], Loss: 0.0286
Epoch: [9/10], Loss: 0.0286
Epoch: [10/10], Loss: 0.0283
Accuracy on the test set of probing pretrained_BERT of all layers:
Score (accuracy) of the probe: 0.96
{'__OVERALL__': 0.9625943983881139, 'NAME': 0.9947328098065504, 'NEWLINE': 0.9957424161788185, 'DOT': 1.0, 'LPAR': 1.0, 'RPAR': 0.9941496030087756, 'KEYWORD': 0.9939540507859734, 'COMMA': 1.0, 'EQUAL': 0.9903301100366789, 'COLON': 1.0, 'DEDENT': 0.013723150357995227, 'INDENT': 1.0, 'LSQB': 1.0, 'RSQB': 0.9971509971509972, 'NUMBER': 0.991182953710507, 'STRING': 0.9443069306930693, 'NL': 0.8433242506811989, 'PLUS': 0.9722222222222222, 'LBRACE': 0.9623655913978495, 'EQEQUAL': 0.954248366013072, 'MINUS': 1.0, 'RBRACE': 1.0, 'STAR': 0.2900763358778626, 'PERCENT': 0.8058252427184466, 'DOUBLESTAR': 1.0, 'PLUSEQUAL': 0.0, 'GREATER': 0.0, 'SLASH': 0.0, 'NOTEQUAL': 0.0, 'AT': 1.0, 'LESS': 0.0, 'COMMENT': 0.0, 'GREATEREQUAL': 0.0, 'LESSEQUAL': 0.0, 'VBAR': 0.0, 'LEFTSHIFT': 0.0, 'SEMI': 0.0, 'MINEQUAL': 0.0, 'AMPER': 0.0, 'DOUBLESLASH': 0.0, 'STAREQUAL': 0.0, 'TILDE': 0.0}
Accuracy on the test set of pretrained_BERT model using the intercept:
Score (accuracy) of the probe: 0.32
pretrained_BERT top neurons
array([4100, 8197, 2066, 6173, 4127, 8228, 8230,   41,   42, 4139, 8244,
         54,   56,   58, 2113, 6216,   74, 6228, 2133, 6230,   88,   90,
         97, 2146, 4194, 6242, 2162, 4212, 6267,  126, 6271, 8320,  136,
       8333,  144,  146, 6293, 8343, 2202, 4251,  157, 4260, 8358, 6322,
       4274,  180, 8379,  191, 8387, 6342,  198, 2264, 8416,  225, 8418,
       8417, 2273, 4330, 4331, 4333,  252, 4353, 6405,  262, 8453, 6420,
       4378, 6427, 2332,  282,  289, 4386, 8484,  301, 6458, 4414, 2375,
       8527,  338, 2394, 2395,  346,  349, 2401, 8546, 4454, 8556, 2412,
       2416, 8561, 8568, 8578, 2435, 8581,  399, 4496, 8593, 2452,  409,
       8601, 4516, 6565, 6567,  429, 2477, 4527, 2479, 6582, 2492, 4541,
        446,  459, 6603, 2510, 2511, 8661, 6621,  482,  484,  488, 8682,
       6637,  494, 4593, 8691,  504,  505, 4602, 4609, 6659, 4614, 6664,
       8724, 4629, 8730, 6683, 2589, 2591,  544, 8746, 4650,  563, 2615,
        572, 8768,  583, 4680,  586, 4686, 6735,  590, 2638, 4688, 6740,
        601,  605, 4714, 8814,  623, 2675, 4727,  639,  644,  651,  655,
       8855, 6813, 2721,  674, 2723, 6822,  683,  691, 2740, 6838, 2747,
        701, 2752, 4808, 2763,  718, 8911,  720,  725, 2778,  735,  744,
        745, 6897, 8947, 6906,  763,  762, 2813, 4858, 6911, 8961,  770,
        776, 8968, 6928, 8988, 2847, 2851, 8996,  807, 4903, 4904,  810,
       9010, 2873,  838, 6984, 4953,  860, 7007,  867, 9060,  871, 2922,
       2928,  889,  899, 4997,  902, 2951, 9099, 2956, 9110,  919, 9114,
       9116, 7074,  930, 7080,  940, 5043, 9145,  956,  959, 3014, 9159,
       7114, 9163,  985,  987,  988, 7133, 9179, 5085,  992,  998, 3059,
       5113, 7165, 5123, 1028, 1036, 5133, 7188, 9239, 5148, 7200, 1058,
       7205, 3120, 9269, 7222, 7223, 9277, 7230, 3142, 3143, 5192, 3144,
       5199, 3151, 3156, 7253, 1110, 5211, 5216, 1124, 1133, 9342, 1153,
       9346, 5249, 3205, 1158, 9355, 1169, 5272, 1176, 7320, 3234, 1199,
       5296, 7350, 7351, 1206, 1210, 7360, 9414, 5320, 3273, 7371, 1229,
       1231, 1236, 7381, 3288, 5351, 3304, 3305, 1264, 1270, 5370, 7423,
       3331, 1288, 1292, 9492, 7455, 5408, 9512, 3369, 9514, 3371, 1327,
       5425, 1330, 1331, 1340, 3395, 5448, 7504, 1360, 1365, 9572, 1384,
       3447, 9593, 7546, 7552, 1409, 3474, 9619, 9621, 7575, 7577, 9633,
       3491, 1447, 1452, 5549, 1456, 7603, 3511, 1470, 3521, 7627, 5583,
       5591, 9691, 7649, 3557, 1524, 7677, 7687, 7693, 1555, 5664, 1568,
       5668, 5669, 9772, 1584, 9791, 5696, 5699, 1606, 7752, 9804, 9807,
       7769, 5725, 3678, 1633, 3683, 9828, 9830, 7784, 1650, 7801, 9870,
       3727, 9871, 3730, 3731, 9883, 3739, 3740, 1698, 3753, 1706, 9899,
       3759, 1711, 5809, 1721, 3771, 1725, 3776, 7874, 1739, 9935, 7893,
       5853, 5856, 7910, 5864, 3817, 5866, 9967, 3833, 5891, 1796, 1799,
       1803, 7956, 5915, 5923, 5936, 1853, 3912, 3918, 1871, 1877, 3926,
       3933, 3938, 8035, 5999, 1914, 6012, 1921, 6028, 1934, 6032, 6034,
       1941, 3992, 4002, 4003, 1955, 8103, 4010, 4016, 1971, 8132, 1999,
       2004, 8153, 8157, 2022, 4071, 4072, 6131, 6133, 2041, 6138, 2045])
pretrained_BERT top neurons per class
{'NAME': array([1169,  262, 6664,  409,  429]), 'NEWLINE': array([8561]), 'DOT': array([2416]), 'LPAR': array([1270, 2778]), 'RPAR': array([572]), 'KEYWORD': array([ 505,  919, 8682,  583, 1384]), 'COMMA': array([9269, 4003, 9830, 9572]), 'EQUAL': array([7074, 7677]), 'COLON': array([1153, 1921]), 'DEDENT': array([225]), 'INDENT': array([2332]), 'LSQB': array([763]), 'RSQB': array([41]), 'NUMBER': array([2922]), 'STRING': array([586]), 'NL': array([7230]), 'PLUS': array([126]), 'LBRACE': array([605]), 'EQEQUAL': array([5891, 8244]), 'MINUS': array([3759, 2375, 4527,  136, 3143, 3371, 3776, 3304, 4072, 3933]), 'RBRACE': array([639]), 'STAR': array([5351, 4100, 1796,  651]), 'PERCENT': array([484]), 'DOUBLESTAR': array([6984, 6138, 5370, 6216, 6427, 5199, 7350, 3912, 6582, 3144, 4602,
       1955, 2615, 4680, 9935, 2747, 5448, 1971, 6906, 6735, 7752, 1941,
       7222, 3918, 8228, 2146, 7188, 6230, 7801, 5864, 4686, 6420, 8996]), 'PLUSEQUAL': array([6228, 9492, 9514, 6322, 8768, 8157, 9116, 8103, 7956, 8724, 3771,
       6405, 8153, 3557, 7007, 8746, 5583, 6028, 8593]), 'GREATER': array([ 144, 2395, 8730]), 'SLASH': array([5809]), 'NOTEQUAL': array([9870,  252, 4127,  488, 7893,  762, 6012, 3059, 4260, 9791,  691,
       2591, 5408,  889, 4727, 2951, 8527, 8661]), 'AT': array([  74,  590,  720, 2813]), 'LESS': array([1231, 8387,  446,  191, 1606,  959, 4650, 3059,  776, 1292, 3142,
        683, 1871, 6565, 5591, 2435,  988,  482, 1409, 9163, 5923,  459,
       8333, 6173, 7165, 3120,  735, 7360,  992, 5148, 1650, 9772, 1133,
       6813, 4714]), 'COMMENT': array([2041, 2956, 3727, 1330, 7769, 5320, 7575, 5668, 3730, 8343, 3926,
       1934, 8197, 8418, 3683, 9239, 1739, 5043, 9871, 9145, 6293, 3491,
       1803, 8988,   56, 4071,  544, 9967, 5113, 5192, 8961, 6342, 6838,
       2022, 5211, 2763]), 'GREATEREQUAL': array([6267, 9883, 1110, 8691,   97, 1365, 1524, 1633,  601, 4609, 1555,
       2133, 4541,   58, 4333, 7577,  987, 3678, 5296, 4331,  180, 6603,
       8416, 2477,  770, 3395, 8568, 5936, 6032, 5549, 7205, 7627, 4997,
       3739]), 'LESSEQUAL': array([4016, 2162,   90, 5664,  871,  157, 1028, 1568, 2113, 1288, 1036,
        807, 9010, 6637, 4516, 9277, 6034, 7133, 5699, 2492, 7687, 2847,
       4858, 2851, 4194, 1711, 7546, 6458, 1914, 4010, 9899, 9346, 7552]), 'VBAR': array([4903, 1706, 2752]), 'LEFTSHIFT': array([7223,  494, 4378, 9342, 6911, 3288, 1210,  191, 8230,  998, 6683,
        644, 9179, 3305, 2394, 8968, 3938, 4330, 1584, 5725,  136, 6928,
       1877, 9807, 9114, 1721,  346, 6133, 7200, 4139, 5915, 8947, 6565,
        655]), 'SEMI': array([5272,  701, 3369, 4251, 2479, 7371, 8035, 4274, 5999, 7381, 1725,
       2066,  399, 8814, 6131, 1158, 9159, 6740, 8320, 9593, 2202, 3511,
       7351, 7910, 3474, 3992, 6567, 5425, 7649, 7603,   88, 2638, 4953,
       7114, 2401,  889, 8417, 3833]), 'MINEQUAL': array([2589,  289,  198, 9060,  674, 9828, 1799, 4614,  623, 4212, 8601,
       5669,  838, 1124, 7423, 6897, 7455, 1229, 8358,  349, 2723, 4496,
        745, 9355,  956, 1452,  338, 1340, 8911, 6271, 8578,   54, 3156,
       2452, 7874, 1999,  146]), 'AMPER': array([5085, 5853, 1058, 3234, 2510, 4002, 6659, 7504,  930, 5123, 2928,
       6621, 3521, 5133, 4904]), 'DOUBLESLASH': array([1327,  301, 1176, 7253, 7080, 5696, 1236, 3731, 1199, 9414,  860,
       8855,  985, 1264, 8379,  563, 4386, 1331,  282, 1447, 7693, 2721,
        718, 5249, 1206, 3151, 4454,  940, 2740, 3753, 2675, 4593, 9619,
       8132, 3740, 8556, 1470, 2873, 4629, 3014]), 'STAREQUAL': array([ 867, 2273,  725, 9099, 2004, 9804, 5856, 3205, 2045]), 'TILDE': array([ 744,   42,  504, 3273, 2511,  810, 1698, 6242,  899, 3447, 8484,
       4414, 1456, 2412, 8453, 8546, 1360, 9110, 5866, 9621, 9633, 9512,
       7320, 4688, 6822, 5216, 3331, 3817, 4808, 4353, 8581, 7784, 1853,
       2264, 9691,  902])}
The shape of selected features (260064, 473)
Training classification probe
Creating model...
Number of training instances: 260064
Number of classes: 41
Epoch: [1/10], Loss: 0.0074
Epoch: [2/10], Loss: 0.0063
Epoch: [3/10], Loss: 0.0062
Epoch: [4/10], Loss: 0.0062
Epoch: [5/10], Loss: 0.0062
Epoch: [6/10], Loss: 0.0062
Epoch: [7/10], Loss: 0.0062
Epoch: [8/10], Loss: 0.0062
Epoch: [9/10], Loss: 0.0062
Epoch: [10/10], Loss: 0.0062
Accuracy on the test set of pretrained_BERT model on top 2% neurons:
Score (accuracy) of the probe: 0.98
Training classification probe
Creating model...
Number of training instances: 260064
Number of classes: 41
Epoch: [1/10], Loss: 0.0084
Epoch: [2/10], Loss: 0.0066
Epoch: [3/10], Loss: 0.0065
Epoch: [4/10], Loss: 0.0064
Epoch: [5/10], Loss: 0.0064
Epoch: [6/10], Loss: 0.0064
Epoch: [7/10], Loss: 0.0064
Epoch: [8/10], Loss: 0.0064
Epoch: [9/10], Loss: 0.0064
Epoch: [10/10], Loss: 0.0064
Accuracy on the test set of pretrained_BERT model on top 200 neurons:
Creating control dataset for pretrained_BERT POS tagging task
['\\n/1']
Number of tokens:  325100
length of source dictionary:  17255
length of target dictionary:  47
325100
Total instances: 325100
['"model.x"', 'testConvertFixedCoshaderArrayToDynamicWithFirstPlugUnconnected', '"verbose"', 'NCS_SERVICES_URL', 'JsonEventHandler', 'container_children_recur', 'google', 'ExecComp', 'output_prefix', 'get_java_remote_console_url', 'Expression', 'CONFIG_ONE', 'issubclass', 'oneOf', 'queries', 'test_metrics', 'sqlite3', 'GetFeatureWithLock', 'calculators', '"1m"']
Number of samples:  325100
Stats: Labels with their frequencies in the final set
1 34303
19 30707
16 27751
29 26183
18 22633
25 20883
3 18444
2 15022
34 12801
8 10309
30 8760
10 8023
11 5121
27 4273
40 3888
38 3780
45 3535
42 3385
44 3117
17 3073
0 2834
23 2782
36 2721
20 2642
35 2522
9 2440
43 2409
26 2401
13 2371
46 2339
22 2332
5 2327
12 2287
28 2273
32 2186
4 2147
6 2090
39 2080
31 1960
21 1902
7 1896
24 1868
33 1851
37 1683
41 1671
14 1564
15 1531
Training classification probe
Creating model...
Number of training instances: 260080
Number of classes: 47
Epoch: [1/10], Loss: 0.1139
Epoch: [2/10], Loss: 0.1139
Epoch: [3/10], Loss: 0.1139
Epoch: [4/10], Loss: 0.1139
Epoch: [5/10], Loss: 0.1138
Epoch: [6/10], Loss: 0.1137
Epoch: [7/10], Loss: 0.1139
Epoch: [8/10], Loss: 0.1138
Epoch: [9/10], Loss: 0.1137
Epoch: [10/10], Loss: 0.1135
Accuracy on the test set of pretrained_BERT control model:
Score (accuracy) of the probe: 0.75
pretrained_BERT Selectivity (Diff. between true task and probing task performance):  0.21625481056898133
Accuracy on the test set of pretrained_BERT control model using the intercept:
Score (accuracy) of the probe: 0.06
Training classification probe
Creating model...
Number of training instances: 260080
Number of classes: 47
Epoch: [1/10], Loss: 0.0393
Epoch: [2/10], Loss: 0.0381
Epoch: [3/10], Loss: 0.0380
Epoch: [4/10], Loss: 0.0380
Epoch: [5/10], Loss: 0.0380
Epoch: [6/10], Loss: 0.0380
Epoch: [7/10], Loss: 0.0380
Epoch: [8/10], Loss: 0.0380
Epoch: [9/10], Loss: 0.0380
Epoch: [10/10], Loss: 0.0380
Accuracy on the test set of pretrained_BERT control model on top neurons:
Score (accuracy) of the probe: 0.79
Training classification probe
Creating model...
Number of training instances: 260080
Number of classes: 47
Epoch: [1/10], Loss: 0.0398
Epoch: [2/10], Loss: 0.0384
Epoch: [3/10], Loss: 0.0384
Epoch: [4/10], Loss: 0.0384
Epoch: [5/10], Loss: 0.0384
Epoch: [6/10], Loss: 0.0384
Epoch: [7/10], Loss: 0.0384
Epoch: [8/10], Loss: 0.0384
Epoch: [9/10], Loss: 0.0384
Epoch: [10/10], Loss: 0.0384
Accuracy on the test set of pretrained_BERT control model on top 200 neurons:
Score (accuracy) of the probe: 0.79
----------------------------------------------------------------
