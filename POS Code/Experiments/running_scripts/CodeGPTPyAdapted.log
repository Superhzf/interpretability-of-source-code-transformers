Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_codeGPTPyAdapted
Loading json activations from ./activations/codeGPTPyAdapted_activations_train.json...
54291 13.0
Number of tokens:  507521
length of source dictionary:  28820
length of target dictionary:  49
507521
Total instances: 507521
['statementsAreSame', 'orgs', 'esnull_pos', 'front_is_complete', 'ErrorResponseException', '"r_polar"', '_signal', "'known_url_names'", 'localize', '1e-4', 'tzinfo', 'build_and_validate_headers', '_insert_f_additive', 'WEBHOOK_EVENT', 'file_to_restore', '"counts"', 'get_original_scopes', 'POW_2_381', 'best_period', 'expr_mat']
Number of samples:  507521
Stats: Labels with their frequencies in the final set
NAME 175779
KEYWORD 38836
LPAR 37541
RPAR 36846
DOT 35570
COMMA 33435
EQUAL 30541
COLON 19841
STRING 17117
DEDENT 16600
LSQB 14740
RSQB 14613
INDENT 11963
NUMBER 10471
PLUS 1939
EQEQUAL 1830
STAR 1500
MINUS 1458
LBRACE 1070
RBRACE 845
DOUBLESTAR 844
SLASH 630
PERCENT 577
PLUSEQUAL 501
GREATER 456
NOTEQUAL 429
LESS 332
RARROW 330
GREATEREQUAL 175
LESSEQUAL 133
AMPER 94
DOUBLESLASH 94
MINEQUAL 58
ELLIPSIS 55
COMMENT 37
VBAR 35
AT 29
STAREQUAL 27
RIGHTSHIFT 25
LEFTSHIFT 25
SLASHEQUAL 24
VBAREQUAL 23
TILDE 23
CIRCUMFLEX 22
AMPEREQUAL 2
DOUBLESLASHEQUAL 2
RIGHTSHIFTEQUAL 2
ENCODING 1
DOUBLESTAREQUAL 1
pretrained_codeGPTPyAdapted distribution after trauncating:
{0: 0.7257507132446749, 3: 0.16034483470477245, 1: 0.07067212214547301, 2: 0.04323232990507962}
{0: 175779, 3: 38836, 1: 17117, 2: 10471}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codeGPTPyAdapted_activations_valid.json...
33619 13.0
Number of tokens:  308882
length of source dictionary:  19446
length of target dictionary:  46
308882
Total instances: 308882
['"uuid"', 'pcnt_cands', 'get_block_hash', 'allele', 'f_has_children', '_NO_CACHE_ENVVAR', 'analysis', 'pdf_case_report', 'in_trajectory', 'redirect_stream', 'close', 'currencyFormat', 'variants_treshold', "'conference'", '12.30', 'iaca_analysis', 'FORMATTED_SET_NAME', 'COMPARISON_MAP', '"en"', "'#hgnc_id\\\\thgnc_symbol\\\\tdisease_associated_transcripts\\\\t'"]
Number of samples:  308882
Stats: Labels with their frequencies in the final set
NAME 106508
DOT 23234
KEYWORD 22857
LPAR 22119
RPAR 21487
COMMA 21037
EQUAL 18195
STRING 12883
COLON 12504
DEDENT 10176
LSQB 8421
RSQB 8348
INDENT 7080
NUMBER 5227
EQEQUAL 1207
PLUS 1136
LBRACE 1077
STAR 963
RBRACE 913
MINUS 741
DOUBLESTAR 555
SLASH 393
PLUSEQUAL 323
GREATER 292
NOTEQUAL 240
PERCENT 222
RARROW 214
LESS 200
GREATEREQUAL 82
LESSEQUAL 47
AT 33
AMPER 29
DOUBLESLASH 27
MINEQUAL 27
VBAR 23
COMMENT 13
ELLIPSIS 13
STAREQUAL 10
LEFTSHIFT 7
TILDE 7
RIGHTSHIFT 4
SLASHEQUAL 3
CIRCUMFLEX 2
ENCODING 1
DOUBLESLASHEQUAL 1
AMPEREQUAL 1
pretrained_codeGPTPyAdapted distribution after trauncating:
{0: 0.7222105441600272, 3: 0.1549889811832514, 1: 0.08735717918291236, 2: 0.035443295473809124}
{0: 106508, 3: 22857, 1: 12883, 2: 5227}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codeGPTPyAdapted_activations_test.json...
32570 13.0
Number of tokens:  302448
length of source dictionary:  18380
length of target dictionary:  49
302448
Total instances: 302448
['"uuid"', 'shell_port', "'http://bkjws.sdu.edu.cn/b/ajaxLogin'", "'numRecordsStored'", '"mode_window"', 'numModelIDs', 'ov', 'model_pk', 'table_cell', 'close', 'legacyTemporal', 'preprocessing', "'auth_token'", 'action_space', 'glance', 'pretty_print', 'maxAge', '"--maxPermutations"', 'localize', 'alpha1_temp1']
Number of samples:  302448
Stats: Labels with their frequencies in the final set
NAME 106943
DOT 23125
LPAR 23019
RPAR 22645
KEYWORD 21773
COMMA 19472
EQUAL 18096
COLON 11225
DEDENT 9778
STRING 8156
LSQB 7717
RSQB 7682
NUMBER 7295
INDENT 6823
EQEQUAL 1344
MINUS 1259
PLUS 1013
STAR 863
LBRACE 527
PLUSEQUAL 448
RBRACE 436
GREATER 417
PERCENT 341
NOTEQUAL 341
SLASH 323
DOUBLESTAR 284
LESS 247
GREATEREQUAL 216
LESSEQUAL 107
AMPER 100
RIGHTSHIFT 61
LEFTSHIFT 53
MINEQUAL 48
DOUBLESLASH 48
RARROW 41
VBAR 38
ELLIPSIS 28
COMMENT 19
AT 17
CIRCUMFLEX 17
STAREQUAL 15
SLASHEQUAL 15
VBAREQUAL 12
TILDE 7
SEMI 6
PERCENTEQUAL 5
ENCODING 1
DOUBLESTAREQUAL 1
AMPEREQUAL 1
pretrained_codeGPTPyAdapted distribution after trauncating:
{0: 0.7417994409261481, 3: 0.1510262404017563, 1: 0.05657327959935353, 2: 0.05060103907274203}
{0: 106943, 3: 21773, 1: 8156, 2: 7295}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
label:3, the number of unique tokens:33
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:21572
label:1, the number of unique tokens:6805
label:2, the number of unique tokens:331
The unique labels are:['.00001', '.01', '.05', '.1', '.2', '.3', '.5', '.9', '.95', '0', '0.', '0.0', '0.00002', '0.0001', '0.001', '0.002', '0.005', '0.01', '0.01683697', '0.02', '0.025', '0.03', '0.05', '0.07', '0.1', '0.15', '0.2', '0.20', '0.22', '0.25', '0.3', '0.33', '0.4', '0.400', '0.5', '0.50922', '0.53', '0.7', '0.75', '0.8', '0.80', '0.85', '0.9', '0.95', '0.98', '0.99', '0j', '0o600', '0o644', '0o777', '0x00', '0x08', '0x0B', '0x1', '0x147A', '0x1F', '0x7F', '0x80', '0x8000', '0x84', '0x86', '0x88', '0x89', '0x9F', '0xAC00', '0xFF', '0xFFFF', '0xff', '1', '1.', '1.0', '1.05', '1.08', '1.0e-7', '1.1', '1.10', '1.2', '1.25', '1.3', '1.4', '1.406211e-6', '1.5', '1.J', '1.j', '10', '10.0', '100', '100.', '100.0', '1000', '1000.0', '10000', '1000000', '10000000', '1000000000.0', '100000000000', '101', '101677777', '1023', '1024', '1024.0', '107.7', '109', '10e10', '11', '11025', '11025.0', '111', '113', '12', '12.', '12.0', '120', '120.0', '120000', '12200', '127', '128', '13', '131', '14', '140', '144', '15', '150', '150.0', '152.0', '16', '160', '17', '175', '18', '180', '19', '19.4712', '192', '192.85', '192.85948', '1E-12', '1E-9', '1E3', '1e-09', '1e-10', '1e-12', '1e-2', '1e-3', '1e-4', '1e-5', '1e-6', '1e-9', '1e6', '1j', '2', '2.', '2.0', '2.13', '2.371512e-11', '2.5', '20', '20.0', '20.6', '200', '200.0', '2000', '20000', '200000', '20051', '20060', '20061', '201', '202', '204', '2048', '207', '21', '2147483647', '22', '22.5', '22050', '224', '225', '23', '24', '240', '242854337', '246', '25', '25.0', '250', '25000', '255', '255.', '255.0', '256', '257', '258', '259', '2595.0', '26', '260', '262', '264', '27', '27.12', '27.12825', '270', '27017', '28', '29', '3', '3.', '3.0', '30', '300', '301', '302', '306674912', '307', '31', '314', '32', '32.0', '32.93192', '320.0', '32768', '33', '34', '34736', '34737', '35', '35163', '36', '360', '3600', '365', '37', '38', '384', '39', '4', '4.', '4.0', '4.2', '4.74057', '40', '40.0', '40.11453', '400', '4000.0', '40000', '401', '403', '404', '4096', '41', '410', '42', '420', '4200000', '429', '43', '440.0', '4410', '443', '45', '48', '480', '493', '5', '5.0', '5.5', '50', '50.', '500', '5000', '50000', '502', '503', '504', '512', '52', '55', '550', '55296', '56', '57344', '59', '5e4', '6', '6.', '6.0', '6.5', '60', '60.0', '600', '6000000', '63', '6367', '6379', '64', '650', '65535.0', '65536', '67', '7', '7.', '70', '700.0', '720', '737.9', '75', '77', '8', '8.0', '80', '80.0', '800', '8080', '84', '85', '86400', '882', '8E3', '9', '90', '96', '98', '99', '99.73', '993', '999999.0']
label:3, the number of unique tokens:32
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:13665
label:2, the number of unique tokens:610
The unique labels are:['.02', '.025', '.05', '.8', '.95', '0', '0.', '0.0', '0.000', '0.001', '0.009', '0.01', '0.012', '0.02', '0.025', '0.027', '0.03', '0.032', '0.0349', '0.04', '0.0471', '0.05', '0.075', '0.08', '0.082', '0.0975', '0.1', '0.1125', '0.115', '0.125', '0.15', '0.167', '0.2', '0.206', '0.22', '0.232', '0.25', '0.250', '0.298', '0.3', '0.33', '0.333', '0.35', '0.4', '0.404', '0.435', '0.45', '0.5', '0.500', '0.509', '0.598', '0.6', '0.627', '0.667', '0.685', '0.7', '0.700', '0.73', '0.75', '0.772', '0.794', '0.8', '0.855', '0.9', '0.912', '0.93', '0.948', '0.968', '0.983', '0.997', '0x0000', '0x0140', '0x0280', '0x03c0', '0x0440', '0x0500', '0x06c0', '0x0780', '0x0880', '0x09c0', '0x0F0F', '0x0a00', '0x0b40', '0x0cc0', '0x0d80', '0x0e40', '0x0f00', '0x1040', '0x1100', '0x12c0', '0x1380', '0x1400', '0x1540', '0x1680', '0x17c0', '0x18c0', '0x1980', '0x1a40', '0x1b00', '0x1c80', '0x1dc0', '0x1e00', '0x1f40', '0x2080', '0x21c0', '0x2200', '0x2340', '0x24c0', '0x2580', '0x2640', '0x2700', '0x2800', '0x2940', '0x2a80', '0x2bc0', '0x2c40', '0x2d00', '0x2ec0', '0x2f80', '0x3030303', '0x30c0', '0x3180', '0x3240', '0x3300', '0x3480', '0x35c0', '0x3600', '0x3740', '0x3840', '0x3900', '0x3ac0', '0x3b80', '0x3c00', '0x3d40', '0x3e80', '0x3fc0', '0x4040', '0x4100', '0x42c0', '0x4380', '0x4400', '0x4540', '0x4680', '0x47c0', '0x48c0', '0x4980', '0x4a40', '0x4b00', '0x4c80', '0x4dc0', '0x4e00', '0x4f40', '0x5000', '0x5140', '0x5280', '0x53c0', '0x5440', '0x5500', '0x56c0', '0x5780', '0x5880', '0x59c0', '0x5a00', '0x5b40', '0x5cc0', '0x5d80', '0x5e40', '0x5f00', '0x60c0', '0x6180', '0x6240', '0x6300', '0x6480', '0x65c0', '0x6600', '0x6740', '0x6840', '0x6900', '0x6ac0', '0x6b80', '0x6c00', '0x6d40', '0x6e80', '0x6fc0', '0x7080', '0x71c0', '0x7200', '0x7340', '0x74c0', '0x7580', '0x7640', '0x7700', '0x7800', '0x7940', '0x7F', '0x7F7F', '0x7a80', '0x7bc0', '0x7c40', '0x7d00', '0x7ec0', '0x7f80', '0x8081', '0x81c1', '0x8201', '0x8341', '0x84c1', '0x8581', '0x8641', '0x8701', '0x8801', '0x8941', '0x8a81', '0x8bc1', '0x8c41', '0x8d01', '0x8ec1', '0x8f81', '0x90c1', '0x9181', '0x9241', '0x9301', '0x9481', '0x95c1', '0x9601', '0x9741', '0x9841', '0x9901', '0x9ac1', '0x9b81', '0x9c01', '0x9d41', '0x9e81', '0x9fc1', '0xF000F', '0xFF', '0xFFFF', '0xa001', '0xa141', '0xa281', '0xa3c1', '0xa441', '0xa501', '0xa6c1', '0xa781', '0xa881', '0xa9c1', '0xaa01', '0xab41', '0xacc1', '0xad81', '0xae41', '0xaf01', '0xb041', '0xb101', '0xb2c1', '0xb381', '0xb401', '0xb541', '0xb681', '0xb7c1', '0xb8c1', '0xb981', '0xba41', '0xbb01', '0xbc81', '0xbdc1', '0xbe01', '0xbf41', '0xc0c1', '0xc181', '0xc241', '0xc301', '0xc481', '0xc5c1', '0xc601', '0xc741', '0xc841', '0xc901', '0xcac1', '0xcb81', '0xcc01', '0xcd41', '0xce81', '0xcfc1', '0xd081', '0xd1c1', '0xd201', '0xd341', '0xd4c1', '0xd581', '0xd641', '0xd701', '0xd801', '0xd941', '0xda81', '0xdbc1', '0xdc41', '0xdd01', '0xdec1', '0xdf81', '0xe041', '0xe101', '0xe2c1', '0xe381', '0xe401', '0xe541', '0xe681', '0xe7c1', '0xe8c1', '0xe981', '0xea41', '0xeb01', '0xec81', '0xedc1', '0xee01', '0xef41', '0xf001', '0xf141', '0xf281', '0xf3c1', '0xf441', '0xf501', '0xf6c1', '0xf781', '0xf881', '0xf9c1', '0xfa01', '0xfb41', '0xfcc1', '0xfd81', '0xfe41', '0xff', '0xff01', '0xffff', '1', '1.', '1.0', '1.01', '1.03', '1.033', '1.056', '1.064', '1.088', '1.107', '1.109', '1.121', '1.152', '1.154', '1.167', '1.17', '1.193', '1.208', '1.235', '1.241', '1.3', '1.302', '1.311', '1.32', '1.337', '1.342', '1.389', '1.4', '1.444', '1.446', '1.5', '1.55', '1.56', '1.584', '1.71', '1.86', '1.87', '1.e-9', '10', '10.0', '10.04', '100', '100.', '100.0', '1000', '1000.0', '10000', '1000000', '1024', '103.939', '10e10', '11', '11.11', '110', '116.779', '119.', '12', '12.30', '120', '123.68', '13', '13.86', '138', '14', '14.0', '14.29', '147', '149.597870e6', '15', '15.95', '150', '1500', '15000', '16', '163', '17', '177.', '178.', '18', '180', '184', '187.', '187.5', '188.', '19', '19.34', '194.', '1_000_000_000', '1e-2', '1e-3', '1e-5', '1e3', '1e6', '1e7', '2', '2.', '2.0', '2.10', '2.26', '2.33', '2.4', '2.49', '2.5', '2.64', '2.72', '2.87', '2.9296875', '20', '20.00', '20.08', '200', '2000', '2000.0', '201', '204', '2097151', '21', '21.17', '21000', '211', '212', '22', '22.42', '22.50', '22.51', '22000', '23', '24', '24.', '25.08', '25.10', '254.', '255', '255.', '256', '27', '27.47', '27.58', '27.69', '270', '27017', '28.0', '28.00', '280', '281', '3', '3.', '3.0', '3.11', '3.27', '3.34', '3.35', '3.74', '3.81', '30', '30.0', '30.00', '30.08', '30.11', '300', '304', '31', '32', '32.45', '32.50', '32.58', '34.92', '35.00', '35.04', '35000', '360', '3600', '3600.0', '365.', '37', '37.50', '37.67', '37.83', '37.88', '38', '4', '4.43', '4.44', '4.82', '40', '40.00', '40.14', '40.17', '400', '401', '403', '404', '406', '409', '412', '42', '42.0', '42.42', '42.65', '42.67', '422', '424.2', '45', '45.00', '45.07', '46', '465', '47.00', '47.17', '47.33', '47.50', '4729418', '49.75', '5', '5.0', '5.14', '5.20', '5.28', '5.37', '5.7', '50', '50.', '50.00', '50.08', '50.4', '500', '5000', '50000', '51', '512', '53', '5500', '55000', '58', '587', '59', '6', '6.07', '6.14', '6.29', '60', '60.', '60.0', '63', '64', '65', '7', '7.16', '7.38', '7.46', '7.5', '70', '70.6', '700', '7000', '75', '78', '79', '8', '8.0', '8.33', '80', '8000', '9', '9.01', '9.24', '9.8', '90', '900', '9600', '9800', '99.0', '9999', '999999', '99999999']
label:1, the number of unique tokens:5085
label:3, the number of unique tokens:32
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:14163
label:1, the number of unique tokens:3813
label:2, the number of unique tokens:310
The unique labels are:['.2', '.4', '.5', '0', '0.', '0.0', '0.000001', '0.00001', '0.0001', '0.0003', '0.001', '0.005', '0.01', '0.02', '0.03', '0.032', '0.04', '0.05', '0.1', '0.10', '0.125', '0.2', '0.22', '0.25', '0.258', '0.3', '0.35', '0.352', '0.4', '0.486', '0.5', '0.50', '0.6', '0.65', '0.66', '0.7', '0.75', '0.8', '0.843', '0.9', '0.911', '0.94', '0.95', '0.99', '0.999', '0.99999', '0b001', '0b010', '0b100', '0o070', '0o7', '0o700', '0o755', '0x0', '0x00', '0x00000000', '0x00000001', '0x00000002', '0x00000003', '0x00000004', '0x00000005', '0x00000006', '0x0000000d', '0x00000010', '0x0000003f', '0x00000040', '0x00000080', '0x00000100', '0x000001ff', '0x00000201', '0x00000400', '0x00000800', '0x00000fff', '0x0000800000000000', '0x000306c3', '0x00c10000', '0x00f0b5ff', '0x01c0003f', '0x02', '0x03c0003f', '0x05100800', '0x0F', '0x0f', '0x1', '0x10', '0x1000', '0x1c004121', '0x1c004122', '0x1c004143', '0x1c03c163', '0x1f', '0x2', '0x3', '0x3f', '0x4', '0x49656e69', '0x60', '0x6c65746e', '0x7', '0x756e6547', '0x76035a01', '0x7ffafbff', '0x8', '0x80', '0x90', '0x99', '0xD5', '0xb', '0xbfebfbff', '0xd', '0xf0', '0xf8000000', '0xff', '0xffff', '0xffffffff', '0xffffffffffffffffffffffffffffffff00000000000000000000000000000000', '1', '1.', '1.0', '1.01', '1.1', '1.15', '1.2', '1.279', '1.4142', '1.42', '1.5', '1.5e-5', '1.8', '10', '10.0', '10.6', '100', '100.0', '1000', '10000', '10000.0', '100000', '100000.0', '1000000.0', '101', '1024', '109', '10e-7', '11', '111', '113', '12', '12.', '120', '127.5', '128', '12836', '13', '14', '144', '15', '15.', '150', '1500', '16', '17', '18', '180', '180.0', '19', '19.9', '195', '1e-10', '1e-2', '1e-3', '1e-5', '1e-6', '1e-7', '1e-8', '1e-9', '1e6', '1e9', '2', '2.', '2.0', '20', '20.0', '20.4', '200', '2000', '201', '2012', '2048', '21', '21.0', '21.3', '2147483647', '22', '22.2', '22.4', '22.7', '224', '23', '2396512', '24', '24.0', '24.4', '25', '250', '255', '255.', '255.0', '256', '27.2', '270', '273.15', '28', '282', '3', '3.92', '3.95', '30', '300', '30000', '31', '3119362', '31344016', '32', '32.', '35', '360.0', '3600', '368', '376', '39', '3e-4', '4', '4.0', '4.03', '4.29', '40', '40.0', '400', '4000', '403', '404', '4096', '41', '42', '42.0', '422', '430', '4326', '443', '48', '48.2', '5', '5.0', '5.25', '50', '500', '5000', '5000.0', '50000', '500000', '51', '512', '52', '52.5', '54', '55', '56', '58', '5e-4', '6', '6.0', '6.26', '60', '60.0', '600', '6006', '62', '63', '6379', '64', '650', '7', '7.0', '7.2', '7.8', '7.9', '784', '7e-4', '8', '8.0', '8.03', '8.2', '8.31', '8.4', '8.5', '80', '800', '8000', '80e6', '86400', '888', '9', '9.5', '9.8', '90', '92', '96', '9862', '999999']
Write tokens in the training set to files:
Write tokens in the validation set to files:
Write tokens in the testing set to files:

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 5000, 3: 5000, 1: 5000, 2: 5000})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in valid:
Counter({3: 540, 0: 540, 1: 540, 2: 540})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({3: 365, 0: 365, 1: 365, 2: 365})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
All-layer probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Independent-layerwise probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Incremental-layerwise probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
select minimum layers (LS+CC+LCA)
Correlation matrix size (#neurons x #neurons): (6912, 6912)
Number of clusters detected: 1820
Correlation matrix size (#neurons x #neurons): (8448, 8448)
Number of clusters detected: 2143
Correlation matrix size (#neurons x #neurons): (9216, 9216)
Number of clusters detected: 2366
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers (run_cc_all.py)
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 5693
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 3326
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 2499
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 1954
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 1514
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 1128
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 736
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 318
Correlation matrix size (#neurons x #neurons): (9984, 9984)
Number of clusters detected: 28
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers with finer percentage (run_max_features.py)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

pretrained_codeGPTPyAdapted top neurons
array([   8,   10, 8204, 4109, 8206,   18, 2073,   26,   28, 2079, 6179,
       8233,   45, 2098, 2108, 6205,   63, 8263, 2119,   75,   76,   81,
         83, 6234,   91, 6236, 4188, 6237,   95,   96, 2147,  101,  104,
        105,  109,  119, 2174,  129,  136, 6287, 2194, 2196,  150, 4250,
        165, 4263,  171, 2220, 6318, 4272, 2228,  181,  180, 2232, 6330,
        188, 2240, 4293,  198,  201, 4300,  206,  207,  208, 4309,  218,
       8412,  222,  223,  225, 6369,  228,  236,  240,  241, 4338,  243,
        244, 2296, 2304, 6401,  260,  267, 8468, 2329, 8480, 4388, 6436,
        294,  299,  300,  309,  316,  317, 8514,  324,  325,  327,  329,
        332,  335,  338, 4435,  341, 2396, 2397, 8541,  357, 2414, 6516,
        378,  380, 2434,  389,  391, 4488,  392,  405,  406,  407,  412,
        414, 6558,  424,  425,  426, 4524, 2477,  433, 8627,  435, 2486,
       2490, 4541,  448,  451, 2509, 2511,  466,  468, 2518,  470,  475,
        478,  484,  485,  486,  487, 2537, 4590, 2557, 4608, 2562,  514,
       8708,  519, 2573,  526,  530,  531, 2588, 2595,  553, 2609,  564,
        568,  572,  574,  577,  579,  580, 2629, 4676,  584,  585,  596,
        598, 4698,  605, 4701,  606,  607, 2658,  610,  617,  619,  626,
       2692, 2693,  645,  647, 4745,  650,  653,  656, 8862, 4778,  685,
        688,  691, 6837,  697,  709, 6853, 4813,  723, 2774,  732,  733,
       4833,  744, 4845,  750,  752, 2802,  764,  765, 4865, 2818, 2821,
        778,  779,  783,  785, 4888,  793,  792, 2844, 6946, 6947, 6957,
       2866,  829,  836, 9031, 2892,  858, 7004,  868, 4970,  878, 9077,
       2942,  895,  900,  907, 7055,  914, 2964, 2988,  942, 9138,  947,
        950, 9157, 5068,  972, 5077,  994, 1006, 3062, 3064, 1016, 1021,
       1027, 9236, 1047, 7192, 5145, 3097, 1052, 9250, 1059, 5157, 1063,
       3112, 1067, 9282, 9284, 1093, 9291, 1100, 1104, 1106, 5203, 1108,
       1113, 5210, 3162, 1114, 1116, 1135, 7284, 9340, 1156, 1158, 5264,
       1172, 3224, 1179, 3228, 7324, 7326, 9383, 1193, 5291, 1203, 3258,
       1213, 5309, 1214, 3261, 1215, 1228, 1230, 1235, 1236, 1237, 1239,
       1241, 1246, 9441, 3297, 1266, 1269, 9473, 7427, 1285, 1291, 3341,
       7438, 1296, 1305, 9498, 1306, 3356, 9503, 9506, 3363, 1316, 1318,
       7465, 1324, 1325, 1327, 5431, 1340, 5439, 1344, 1348, 9542, 1351,
       3420, 1372, 1373, 5469, 3426, 3427, 1389, 5491, 1404, 1406, 7560,
       1424, 1429, 1430, 9630, 9634, 1449, 7595, 1452, 9648, 7601, 1458,
       1460, 1464, 5562, 1468, 5565, 1472, 7617, 1476, 9668, 7622, 1484,
       5581, 1487, 7647, 5601, 9698, 1505, 1518, 3570, 1529, 1531, 1533,
       5637, 1555, 7700, 3609, 1561, 1568, 3628, 3629, 7727, 9789, 1604,
       5714, 7772, 1629, 1646, 9838, 9845, 1659, 1661, 1663, 1682, 1688,
       7840, 3756, 9900, 3760, 1718, 5827, 9925, 1741, 1750, 1788, 1794,
       1813, 1815, 5912, 5913, 1818, 1820, 1826, 1828, 1833, 1861, 1874,
       5977, 3930, 3932, 3933, 8052, 1915, 1924, 1925, 6024, 3992, 6043,
       1962, 6060, 8109, 4012, 1967, 6065, 1974, 6077, 1981, 1998, 2019,
       6126, 8175, 2039, 4093])
pretrained_codeGPTPyAdapted top neurons per class
{'NAME': array([ 101,   26,   45,  329,  109, 1052,  793, 1344, 1318, 1646,  650,
        357,  653, 2073, 2942,  572,  878, 2220, 2988, 1340, 1237,  732,
       2174,  723,  596,  519,  564, 1389,  341, 1179,  688,  685,  129,
       2866, 1305,   28, 1021, 1316,  188, 3756, 1059, 1818, 1193,  391,
        568, 1172, 2414, 4093, 4524, 1487,  243, 2557, 3609,  225, 1561,
       5913, 1406,  407,  240, 1533,  260, 1458, 4263, 1659, 1529,  207,
         76,  150, 1203,  744,   91,  580, 1351, 5145, 1135, 1228, 2098,
       1962,  425, 2595, 3112,  647,  764, 1718,  327,  829, 5827,  241,
        785,  598, 1484, 1372, 9900,  119,  783,  414,  165,  553,  389,
       3363, 9291, 1452, 2486, 1468, 1661]), 'STRING': array([1815, 8468, 6236, 1327, 2228,  267, 9340, 3930, 6558, 4698, 1460,
       2964, 6369,  530, 6318, 9282, 8263, 2821,  709, 3426, 9698,  260,
        836, 9838, 1324, 7055, 9634, 8052, 7004,  697, 4833, 9236, 2196,
       7617, 6401, 9630, 2396,   81, 1269, 1266, 7560, 7622, 8514, 8412,
       3228, 5210, 8862, 1464, 1373, 9498, 8708, 8627, 4608, 5264, 4488,
       2397,  405, 6060, 9789, 7284, 6234, 2658, 9077, 7595, 1604,   28,
       9441, 2562, 6516, 4388, 9925, 4293, 4865, 4300, 1047, 1093, 2232,
       8233,  942, 8109, 1828, 2147, 1296, 1794,  574, 6287, 1246, 2537,
       1230,  895, 9157, 7700, 9503, 3162, 1998, 9648, 6436, 6126, 4590,
       7727, 9138,  994, 3628, 4188, 1235, 1915, 9900, 3932, 1063, 9542,
       7772, 5469, 5291,  619,   26, 7465, 8541, 8480, 5601, 8204, 6024,
       1833, 3933, 7647, 8175, 1629, 7192, 1285, 3420, 1874, 4970, 4338,
       9473, 2304, 5912, 7326, 7840, 6853, 7324, 9031, 5068,  585, 2802,
       2774, 5565, 6946, 4745, 1568, 4845, 3297, 9845, 7427, 5714, 2434,
        878, 1306, 2511,  324, 9506]), 'NUMBER': array([ 617,  236,  484,  752, 1241,  105, 2490,  433,  317, 1266,  619,
       1113,  325, 1027,  405,  222,  485,  685,  412, 1750,  605,  104,
        691, 1156,  531, 1788, 1741, 3341, 1604, 1688, 1340,  198, 6957,
       2518, 4109,  451,   95, 2573,   10,  907,  426, 3064,  332, 5581,
         83, 1663,  208, 1213, 1629, 2509,  778, 3224, 4250,  424,  487,
       6077, 5309,  526, 1291, 2692, 2296,  406, 1100, 4701,  733, 2629,
       5203,   45, 1016,  380,  181, 1214, 8206, 1106, 4778, 4272,  468,
       2039, 3570, 1813, 3760, 4012,  868,  223, 1472,  470,  201, 3261,
       4435, 3062, 5637, 1429,  171,  579,  750, 1967,  294, 4888, 1531,
       1826, 5977,  947, 4541, 9284,  610, 2892,  335, 2477, 2079,  900,
        466, 2818,  779, 2240,  119,  584, 6237,  338, 4813, 5439, 1924,
       6043, 1981, 1236, 1348, 2609, 6065, 3629, 3258, 9383, 1925, 1325,
       1424, 7438,  435, 6330, 1861, 1006, 5157,  300, 2019, 1269, 5491,
       1104, 6947, 5562, 4676, 1215, 2844,   18,    8, 2693, 6837,  645,
       2194, 7601, 3992, 1449, 6179, 5431,  656]), 'KEYWORD': array([ 329, 1476,  793,  109,  206,   26, 1318,  357, 1340,  150, 1452,
       1052,  486,  240,  101, 2108,  218,  564,  309,   63, 1818,  225,
        950, 2329, 1059, 1108,  241, 1237, 1406, 1561,  514, 1533, 1487,
       1305,  653,  688, 1158,   96, 2174, 1203,  378, 1468,  606,   45,
       1682,  180,  119,  568, 1820,  316,  391,  475,  572,  895,  136,
        299, 2073, 1239,  783,  392,  723, 2942, 2220,  607,  792,  650,
       1404, 2119,  765, 2296, 1114,  188,   91,  626,  327, 4309,  243,
        519, 1505,   75,  260, 6205, 3356, 4109, 1021, 9250,  785, 1116,
       1351,  577,  972,  914,  858,  244, 1430, 3097, 9668, 1555, 3609,
        228, 3427, 2588,  165, 1518, 1974, 1067,  207, 5077,  448, 1344,
        478, 1228])}
pretrained_codeGPTPyAdapted top words
Top words for pretrained_codeGPTPyAdapted neuron indx 8 [('descend', 5.234714508056641), ('ord', 4.523310257838323), ('println', 4.13169527053833), ('uniform', 4.091913895173506), ('sprint', 3.945913791656494)]
Top words for pretrained_codeGPTPyAdapted neuron indx 10 [('shuffle', 4.095645904541016), ('lower', 3.832686980565389), ('Sequence', 3.4430887699127197), ('im', 3.3734548091888428), ('sub', 3.1869208812713623)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8204 [("'**/*.json'", 3.5890791416168213), ('answer', 3.561007022857666), ("'*.egg-info'", 3.4643518924713135), ("'LICENSE.txt'", 3.4624171257019043), ('message', 3.3098695278167725)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4109 [('eq', 4.783686637878418), ('exit', 4.749271392822266), ('259', 4.401928424835205), ('arg', 3.9058640003204346), ('264', 3.850466728210449)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8206 [('pow', 3.2886714935302734), ('stride', 3.1839041709899902), ('2.13', 2.9882020950317383), ('shears', 2.864088535308838), ('quote', 2.7555994987487793)]
Top words for pretrained_codeGPTPyAdapted neuron indx 18 [('row', 3.594830334186554), ('tensor', 3.412865322828293), ('form', 3.4056275685628257), ('country', 3.1254119873046875), ('RESET', 3.0394694805145264)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2073 [('keywords', 3.8720991611480713), ('border', 3.6798245906829834), ('min', 3.489974445766873), ('corrections', 3.3912362655003867), ('rotate', 3.360260009765625)]
Top words for pretrained_codeGPTPyAdapted neuron indx 26 [('skill', 4.405141115188599), ('scheme', 3.7597014904022217), ('device', 3.5472434520721436), ('43', 3.4888932704925537), ('301', 3.425107479095459)]
Top words for pretrained_codeGPTPyAdapted neuron indx 28 [('hue', 4.96793532371521), ('tw', 3.985889434814453), ('brightness', 3.8684898018836975), ('class', 3.867877721786499), ('pic', 3.7597363842858207)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2079 [('RED', 5.050321102142334), ('git', 4.509332656860352), ('convert', 4.329424953460693), ('redirect', 4.151564598083496), ('cookies', 4.029671788215637)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6179 [('512', 4.602575499836991), ('height', 3.7291953672062266), ('Request', 3.5707125663757324), ('2048', 3.524515390396118), ('half_width', 3.469409132003784)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8233 [('stdout', 3.97621488571167), ('stdin', 3.3644825220108032), ('512', 3.304772600895021), ('expand', 3.1944438219070435), ('262', 3.144498109817505)]
Top words for pretrained_codeGPTPyAdapted neuron indx 45 [('gamma', 4.691929658253987), ('format', 4.4671367645263675), ('println', 4.159637451171875), ('contrast', 4.102177798748016), ('img', 4.001410401784456)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2098 [('144', 5.0385637283325195), ('120', 4.812847137451172), ('squeeze', 3.9855403900146484), ('127', 3.9306204319000244), ('140', 3.803013801574707)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2108 [('borders', 4.069292068481445), ('oh', 3.9515589078267417), ('activation', 3.7641354401906333), ('mult', 3.385694921016693), ('cost', 3.0674679279327393)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6205 [('numbers', 4.302563190460205), ('22', 3.7743678092956543), ('println', 3.129743814468384), ('shuffle', 2.908966302871704), ('print', 2.794710460034284)]
Top words for pretrained_codeGPTPyAdapted neuron indx 63 [('Optional', 2.9948999881744385), ('RED', 2.8506202697753906), ('render', 2.809837579727173), ('final', 2.803212669160631), ('break', 2.7711822191874185)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8263 [("'Access-Control-Allow-Origin'", 3.0785505771636963), ('finally', 3.0740349292755127), ("'Access-Control-Allow-Methods'", 3.0020339488983154), ('0o777', 2.9643239974975586), ('prefix', 2.9253406524658203)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2119 [('800', 4.7415056228637695), ('1000', 3.9872575402259827), ('600', 3.899017572402954), ('squeeze', 3.828381061553955), ('strip', 3.6692121823628745)]
Top words for pretrained_codeGPTPyAdapted neuron indx 75 [('443', 3.542214870452881), ('descend', 3.06748366355896), ('exceptions', 2.9421722888946533), ('503', 2.892552375793457), ('save', 2.862025260925293)]
Top words for pretrained_codeGPTPyAdapted neuron indx 76 [('set', 4.220291996002198), ('type', 4.102119445800781), ('six', 3.9803569316864014), ('lang', 3.414824438095093), ('data', 3.161779374611087)]
Top words for pretrained_codeGPTPyAdapted neuron indx 81 [('dist', 4.320041179656982), ('201', 4.278875112533569), ('Optional', 4.228921890258789), ('terminated', 3.922008991241455), ('";"', 3.8387961983680725)]
Top words for pretrained_codeGPTPyAdapted neuron indx 83 [('append', 5.041131252195777), ('translate', 4.08650079369545), ('find', 3.628373384475708), ('cat', 3.53513240814209), ('div', 3.5095386505126953)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6234 [('Number', 3.906527360280355), ('conf', 3.8216919004917145), ('answer', 3.6382157802581787), ('exceptions', 3.4045729637145996), ('Sequence', 3.4031167030334473)]
Top words for pretrained_codeGPTPyAdapted neuron indx 91 [('attempt', 4.881295204162598), ('gui', 3.8073832988739014), ('width', 3.5913562041062574), ('final', 3.435248533884684), ('split', 3.2371245434409692)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6236 [('600', 3.4604331254959106), ('720', 3.3686840534210205), ('tw', 3.349120020866394), ('add_cookie_header', 3.086336612701416), ('size', 2.953652917004343)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4188 [('language', 3.8817839281899587), ('numbers', 3.4889039198557534), ('tuple', 3.4148133993148804), ('tolist', 3.196799635887146), ('enhance', 3.1460928916931152)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6237 [('render', 5.5703572034835815), ('429', 4.724951267242432), ('Image', 3.8478813451879166), ('ValueError', 3.8217039108276367), ('314', 3.7146213054656982)]
Top words for pretrained_codeGPTPyAdapted neuron indx 95 [('moves', 4.939329147338867), ('println', 4.633004665374756), ('dir', 4.63037109375), ('total', 4.526909828186035), ('stride', 4.2942202885945635)]
Top words for pretrained_codeGPTPyAdapted neuron indx 96 [('BILINEAR', 4.345929861068726), ('im', 4.308263301849365), ('nmaps', 4.051885366439819), ('decompressobj', 3.904697835445404), ('clone', 3.880805492401123)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2147 [('111', 3.866339325904846), ('format', 3.655852165222168), ('write', 3.5716264247894287), ('suggestions', 3.5235533714294434), ('XML', 3.410407781600952)]
Top words for pretrained_codeGPTPyAdapted neuron indx 101 [('cookies', 4.859711050987244), ('192', 4.495579242706299), ('224', 4.131556987762451), ('45', 4.087187131245931), ('minutes', 3.9789812564849854)]
Top words for pretrained_codeGPTPyAdapted neuron indx 104 [('429', 4.690736293792725), ('contiguous', 4.202974796295166), ('axis', 4.166450361410777), ('numbers', 4.11860720316569), ('exp', 4.110816478729248)]
Top words for pretrained_codeGPTPyAdapted neuron indx 105 [('write', 4.254927158355713), ('sys', 4.079073762893676), ('extend', 3.9841485023498535), ('exit', 3.792043924331665), ('except', 3.7628888640292857)]
Top words for pretrained_codeGPTPyAdapted neuron indx 109 [('os', 4.583370767790695), ('root', 4.130545525715269), ('RED', 4.000946998596191), ('termios', 3.690230369567871), ('gui', 3.619271993637085)]
Top words for pretrained_codeGPTPyAdapted neuron indx 119 [('loads', 4.733004868030548), ('days', 4.160800933837891), ('answers', 4.1167906522750854), ('140', 4.003931045532227), ('raise', 3.7624609164702587)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2174 [('accuracy', 4.461670875549316), ('count', 4.08712100982666), ('themes', 3.9108362330330744), ('array', 3.8495128750801086), ('override', 3.658614921569824)]
Top words for pretrained_codeGPTPyAdapted neuron indx 129 [('resp', 6.930060565471649), ('response', 4.756011340353224), ('Response', 4.636016941070556), ('dictify', 4.508479356765747), ('responses', 4.331469202041626)]
Top words for pretrained_codeGPTPyAdapted neuron indx 136 [('Session', 5.889200210571289), ('class', 4.0088582038879395), ('except', 3.975932287615399), ('pred', 3.7441062927246094), ('eq', 3.734130382537842)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6287 [('replace', 4.749027729034424), ('Lambda', 3.38462975025177), ('torch', 2.9906839873339677), ('target', 2.9639178117116294), ('match', 2.93996747640463)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2194 [('keywords', 4.027601718902588), ('random', 3.7387114465236664), ('tag', 3.7380160689353943), ('Number', 3.632790724436442), ('480', 3.6132915019989014)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2196 [('550', 5.583267688751221), ('cookies', 5.017839431762695), ('timeout', 4.970374425252278), ('descend', 3.868417739868164), ('tmp', 3.8317065238952637)]
Top words for pretrained_codeGPTPyAdapted neuron indx 150 [('narrow', 5.040271520614624), ('exceptions', 4.549954414367676), ('RED', 4.481064796447754), ('preferred', 4.327232182025909), ('q', 4.211054801940918)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4250 [('div', 4.4256134033203125), ('replace', 4.159629702568054), ('lower', 3.8594654401143393), ('div_', 3.615633249282837), ('sub', 3.4867968559265137)]
Top words for pretrained_codeGPTPyAdapted neuron indx 165 [('fid', 5.2109715938568115), ('conf', 4.060963034629822), ('arg', 3.826683282852173), ('enhancer', 3.795130729675293), ('git', 3.749354600906372)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4263 [('descend', 3.974717378616333), ('eq', 3.7495126724243164), ('pred', 3.6682587265968323), ('scid', 3.38106232881546), ('dir', 3.344948709011078)]
Top words for pretrained_codeGPTPyAdapted neuron indx 171 [('ratio', 4.931799275534494), ('suggestions', 4.67736800511678), ('res', 4.569096058607101), ('match', 4.520755327664888), ('close', 4.498410224914551)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2220 [('Contrast', 5.2371039390563965), ('confidence', 4.052539348602295), ('over', 4.048451900482178), ('expanded', 3.908776601155599), ('contrast', 3.893286347389221)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6318 [('autocompleter', 3.2608022689819336), ('bokeccID', 2.8111908435821533), ("'continuationToken'", 2.793236255645752), ('cookies', 2.7298859357833862), ("'answers'", 2.7071361541748047)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4272 [('Exception', 6.476345062255859), ('ValidationException', 4.155556678771973), ('sort', 4.023496150970459), ('view', 3.843383312225342), ('quote', 3.7933695316314697)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2228 [('tmp', 4.045588850975037), ('201', 3.991421341896057), ('replace', 3.115272879600525), ('units', 3.0520994464556375), ('div', 3.0410847663879395)]
Top words for pretrained_codeGPTPyAdapted neuron indx 181 [('preferred', 5.855605125427246), ('answer', 5.8527326583862305), ('enhance', 5.365480422973633), ('preferences', 4.923772160212199), ('now', 4.373927116394043)]
Top words for pretrained_codeGPTPyAdapted neuron indx 180 [('pad', 3.264403462409973), ('bytes', 2.9748528003692627), ('unicode', 2.8846182823181152), ('responses', 2.8454039335250854), ('ele', 2.8417683839797974)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2232 [('stride', 4.5622866948445635), ('BOLD', 4.171525080998738), ('std', 3.6797054409980774), ('np', 3.6567237132634873), ('brightness', 3.4830896854400635)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6330 [('90', 3.511565327644348), ('arg', 3.253490447998047), ('tuple', 3.1874934434890747), ('errno', 3.069493889808655), ('246', 3.0290114879608154)]
Top words for pretrained_codeGPTPyAdapted neuron indx 188 [('upper', 5.9013590812683105), ('fid', 5.614864110946655), ('preferred', 5.001898884773254), ('dumps', 4.811447779337565), ('lower', 4.635095755259196)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2240 [('Sequence', 4.592773914337158), ('XML', 3.863076686859131), ('ET', 3.8057971000671387), ('child', 3.722480297088623), ('target', 3.7130045890808105)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4293 [('pop', 4.471223592758179), ('render', 3.928154766559601), ('pow', 3.7896111011505127), ('randint', 3.717389965057373), ('tuple', 3.5450263023376465)]
Top words for pretrained_codeGPTPyAdapted neuron indx 198 [('finally', 5.498481750488281), ('commit', 4.449097514152527), ('Contrast', 4.239120960235596), ('conf', 3.9307059347629547), ('round', 3.768117904663086)]
Top words for pretrained_codeGPTPyAdapted neuron indx 201 [('302', 5.039321422576904), ('301', 4.692823886871338), ('""', 4.6528214666578505), ('saturation', 4.44206166267395), ('squeeze', 4.189225196838379)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4300 [('xpath', 3.533745527267456), ('"identity"', 3.323714780807495), ('"vl"', 3.0944321155548096), ('"_rot"', 3.0862960815429688), ('"\\\\\\\\ctrl{"', 3.077471375465393)]
Top words for pretrained_codeGPTPyAdapted neuron indx 206 [('return', 3.208006840790802), ('oh', 3.1671040852864585), ('tile', 3.0185511112213135), ('squeeze', 2.8927929401397705), ('q', 2.4439127445220947)]
Top words for pretrained_codeGPTPyAdapted neuron indx 207 [('engine', 4.915150165557861), ('git', 4.292753219604492), ('six', 4.262507915496826), ('angle', 4.191371321678162), ('data', 3.6372513829208)]
Top words for pretrained_codeGPTPyAdapted neuron indx 208 [('stride', 4.779726028442383), ('pass', 4.425288379192352), ('314', 4.407893657684326), ('Contrast', 4.39179801940918), ('expand', 4.282062292098999)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4309 [('splits', 3.0180177688598633), ('corrections', 2.92133100827535), ('"%f"', 2.9186675548553467), ('"Bit"', 2.7693190574645996), ('"%"', 2.7138034105300903)]
Top words for pretrained_codeGPTPyAdapted neuron indx 218 [('ratio', 4.915724890572684), ('420', 4.895694255828857), ('ow', 4.8225358327229815), ('saturation', 4.789735913276672), ('finally', 4.517822265625)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8412 [('activation', 3.314140518506368), ('output_dir', 3.1869170139362284), ('RED', 3.0417962074279785), ("'server'", 3.0260119438171387), ('palette', 2.958855708440145)]
Top words for pretrained_codeGPTPyAdapted neuron indx 222 [('decode', 4.479528903961182), ('extract', 4.248921871185303), ('translate', 4.2322016060352325), ('node', 3.9562644958496094), ('PIL', 3.84395170211792)]
Top words for pretrained_codeGPTPyAdapted neuron indx 223 [('sleep', 3.1264986991882324), ('response', 3.0778355730904474), ('dom', 2.809090566635132), ('struct', 2.777667760848999), ('io', 2.7336909770965576)]
Top words for pretrained_codeGPTPyAdapted neuron indx 225 [('redirect', 4.462924003601074), ('sum', 4.425033187866211), ('prepare', 4.007620811462402), ('tr', 3.9920620918273926), ('mult', 3.9376492500305176)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6369 [('now', 3.3514134883880615), ('quality', 3.1570650339126587), ('exceptions', 3.03727388381958), ('over', 2.917351484298706), ('480', 2.7030839920043945)]
Top words for pretrained_codeGPTPyAdapted neuron indx 228 [('resize', 6.521809697151184), ('tar', 6.001534938812256), ('eq', 5.2562456130981445), ('children', 4.728214740753174), ('child', 3.9951263666152954)]
Top words for pretrained_codeGPTPyAdapted neuron indx 236 [('rotate', 4.581627130508423), ('method', 3.8078877925872803), ('Lambda', 3.7667958974838256), ('numbers', 3.6945441563924155), ('oh', 3.6616265773773193)]
Top words for pretrained_codeGPTPyAdapted neuron indx 240 [('144', 3.899829626083374), ('stride', 3.7296772797902427), ('cat', 3.7054758071899414), ('480', 3.5835256576538086), ('Multiply', 3.57897686958313)]
Top words for pretrained_codeGPTPyAdapted neuron indx 241 [('struct', 4.166543483734131), ('io', 3.777240037918091), ('pow', 3.4880881309509277), ('form', 3.1497006151411266), ('barrier', 3.083418130874634)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4338 [('str', 4.098156422376633), ('unicode', 3.409374475479126), ('crop', 3.379937767982483), ('remove', 2.9074395895004272), ('AlexNet', 2.8683738708496094)]
Top words for pretrained_codeGPTPyAdapted neuron indx 243 [('zip', 4.018907189369202), ('ow', 3.7980340321858725), ('contrast', 3.7923590540885925), ('search', 3.550227721532186), ('quality', 3.5271483659744263)]
Top words for pretrained_codeGPTPyAdapted neuron indx 244 [('accuracy', 3.538618803024292), ('render', 3.431457042694092), ('saturation', 3.365004539489746), ('shape', 3.1369267463684083), ('total', 3.070296287536621)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2296 [('prepare', 4.922933578491211), ('quote', 4.913980484008789), ('finally', 4.773837208747864), ('language', 3.9577202115740096), ('preferred', 3.8431748747825623)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2304 [('rotate', 3.732453942298889), ('str', 3.4569451808929443), ('tile', 3.2922046184539795), ('preferences', 2.9408515294392905), ('shuffle', 2.8579182624816895)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6401 [('log', 2.5997084379196167), ('escape', 2.59759783744812), ('Optional', 2.5948405265808105), ('wtf', 2.5756797790527344), ('asarray', 2.5124422311782837)]
Top words for pretrained_codeGPTPyAdapted neuron indx 260 [('sleep', 5.377893447875977), ('quote', 4.51828145980835), ('override', 4.477867698669433), ('update', 4.149008274078369), ('correct', 4.143022179603577)]
Top words for pretrained_codeGPTPyAdapted neuron indx 267 [('ord', 4.0787473275111275), ('enumerate', 3.8539336257510715), ('channels', 3.571305751800537), ('seek', 3.5654513835906982), ('"./*"', 3.3996894359588623)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8468 [("'Z5H5wqd06ExFVPNfJiqhKvAFjkf+cTVodOUirucHGcEVAMO1LfvgqWUkZ/X1ITDZbI0w+SMwVkEQZlkeThbVS/54M22StNDUtfz4Ua20xNDpIPwcWIACAmZ38XxbbTEFJI5WwqrbilNcfzqiGrIPfdO5rl+/xUjHFUdcJdUY/QzBxXsceytVYfEiR9MzOCN2m4C0XnpThUavAu159KrLj8AkuzN0JF87iXv+zOEeZRgEuwmsAnJrRUwkJ4yWokEPnSVdjF0D6f6CscfyvRe9nsWShq7/zRTa41meweh+n006zvf58MbzRdXPB22RI4AN0ksWW7hSC8/QLAKQE+lvaw=='", 2.7516303062438965), ("'application/json;pk=BCpkADawqM1cc6wmJQC2tvoXZt4mrB7bFfi6zGt9QnOzprPZcGLE9OMGJwspQwKfuFYuCjAAJ53JdjI8zGFx1ll4rxhYJ255AXH1BQ10rnm34weknpfG-sippyQ'", 2.52912974357605), ('dim', 2.4429454803466797), ("'eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IjEifQ.eyJhdWQiOiJodHRwczovL2FwaS5hbWF6b25hbGV4YS5jb20iLCJpc3MiOiJBbGV4YVNraWxsS2l0Iiwic3ViIjoiYW16bjEuYXNrLnNraWxsLjhiMTdhNWRlLTM3NDktNDkxOS1hYTFmLWUwYmJhZjhhNDZhNiIsImV4cCI6MTU0NTIyMzY1OCwiaWF0IjoxNTQ1MjIwMDU4LCJuYmYiOjE1NDUyMjAwNTgsInByaXZhdGVDbGFpbXMiOnsiY29uc2VudFRva2VuIjpudWxsLCJkZXZpY2VJZCI6ImFtem4xLmFzay5kZXZpY2UuQUZRQU1MWU9ZUVVVQUNTRTdIRlZZUzRaSTJLVUIzNUpQSFFSVVBLVERDQVUzQTQ3V0VTUDVMNTdLU1dUNUw2UlQzRlZYV0g0T0EyRE5QSlJNWjJWR0VJQUNGM1BKRUlEQ09VV1VCQzRXNVJQSk5VQjNaVlQyMko0VUpONVVMM1QyVUJQMzZSVkhGSjVQNElQVDJIVVkzUDJZT1kzM0lPVTRPMzNIVUFHN1IyQlVOUk9FSDRUMiIsInVzZXJJZCI6ImFtem4xLmFzay5hY2NvdW50LkFHUjRSMkxPVkhNTk1OT0dST0JWTkxVN0NMNEM1N1g0NjVYSkYyVDJGNTVPVVhOVExDWERRUDNJNTVVWFpJQUxFS0taSjZRMk1BNU1FRlNNWlZQRUw1TlZaUzZGWkxFVTQ0NEJWT0xQQjVXVkg1Q0hZVFFBS0dEN1ZGTEdQUkZaVkhISDJOSUI0SEtOSEhHWDZITTZTNlFEV0NLWFdPSVpMN09OTlFTQlVDVlBNWlFLTUNZWFJHNUJBMlBPWUVYRkRYUlhDR0VWRFdWU01QUSJ9fQ.jcomYhBhU485T4uoe2NyhWnL-kZHoPQKpcycFqa-1sy_lSIitfFGup9DKrf2NkN-I9lZ3xwq9llqx9WRN78fVJjN6GLcDhBDH0irPwt3n9_V7_5bfB6KARv5ZG-JKOmZlLBqQbnln0DAJ10D8HNiytMARNEwduMBVDNK0A5z6YxtRcLYYFD2-Ieg_V8Qx90eE2pd2U5xOuIEL0pXfSoiJ8vpxb8BKwaMO47tdE4qhg_k7v8ClwyXg3EMEhZFjixYNqdW1tCrwDGj58IWMXDyzZhIlRMh6uudMOT6scSzcNVD0v42IOTZ3S_X6rG01B7xhUDlZXMqkrCuzOyqctGaPw'", 2.44195556640625), ('items', 2.4193365573883057)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2329 [('enhancer', 3.9552364349365234), ('enhance', 3.818181276321411), ('transpose', 3.718499461809794), ('timeout', 3.6105885903040567), ('activation', 3.482524275779724)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8480 [("'[.]'", 3.3690309524536133), ('Iterable', 3.1791961193084717), ('XML', 3.0566980838775635), ('Image', 2.814704852945664), ('20060', 2.686016082763672)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4388 [('suggestions', 3.7787067890167236), ('RED', 3.5666491985321045), ('attempt', 3.4754834175109863), ("'horizontalalignment'", 3.097668170928955), ("'suggestions'", 3.0709359645843506)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6436 [('90', 3.494768977165222), ('144', 3.1201183795928955), ('14', 3.1185628800165084), ('45', 3.057603041330973), ('system', 3.0174872875213623)]
Top words for pretrained_codeGPTPyAdapted neuron indx 294 [('enhance', 4.396070957183838), ('strip', 4.010954737663269), ('hue', 3.983717381954193), ('KeyboardInterrupt', 3.919745922088623), ('legitimize', 3.8054749965667725)]
Top words for pretrained_codeGPTPyAdapted neuron indx 299 [('site', 4.214847087860107), ('"\\', 3.7124388118584952), ('hit', 3.6228129386901857), ('center', 3.198585629463196), ('res', 3.1832758486270905)]
Top words for pretrained_codeGPTPyAdapted neuron indx 300 [('ord', 4.963745611218306), ('type', 4.745129108428955), ('filter', 4.705005645751953), ('im', 4.654460430145264), ('site', 4.651336669921875)]
Top words for pretrained_codeGPTPyAdapted neuron indx 309 [('expand', 5.633942127227783), ('splits', 4.503059387207031), ('ioctl', 4.272525787353516), ('stride', 4.235394636789958), ('headers', 3.9826936938545923)]
Top words for pretrained_codeGPTPyAdapted neuron indx 316 [('XML', 3.2531185150146484), ("'!'", 3.155022382736206), ("'='", 3.073574701944987), ('tile', 2.870344877243042), ("'!='", 2.834651470184326)]
Top words for pretrained_codeGPTPyAdapted neuron indx 317 [('div', 4.114785671234131), ('exit', 4.036767959594727), ('AlexNet', 3.540656805038452), ('cookies', 3.501886487007141), ('println', 3.213088035583496)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8514 [('207', 3.5700252056121826), ('now', 3.5411840677261353), ('prepare', 3.2185921669006348), ('RED', 3.1134090423583984), ('882', 2.8599886894226074)]
Top words for pretrained_codeGPTPyAdapted neuron indx 324 [('session', 3.6638143062591553), ('theme', 3.6346092224121094), ('group', 3.4123820781707765), ('words', 3.2705531120300293), ('id', 3.1801502108573914)]
Top words for pretrained_codeGPTPyAdapted neuron indx 325 [('barrier', 4.270549774169922), ('merge', 3.4969961685793742), ('hue', 3.304795801639557), ('Image', 3.2660086154937744), ('v', 3.2058390378952026)]
Top words for pretrained_codeGPTPyAdapted neuron indx 327 [('console', 5.368025779724121), ('barrier', 4.974053382873535), ('contiguous', 4.321300983428955), ('stack', 4.138572692871094), ('symbols', 3.8305293321609497)]
Top words for pretrained_codeGPTPyAdapted neuron indx 329 [('eq', 4.034577369689941), ('clone', 4.000526428222656), ('random', 3.9711783826351166), ('tw', 3.5235193371772766), ('lang', 3.4828253269195555)]
Top words for pretrained_codeGPTPyAdapted neuron indx 332 [('barrier', 5.488735198974609), ('center', 5.0576865673065186), ('mul', 4.9722208976745605), ('shuffle', 4.822352409362793), ('Contrast', 4.76449728012085)]
Top words for pretrained_codeGPTPyAdapted neuron indx 335 [('720', 4.337340354919434), ('target', 4.100431442260742), ('ratio', 3.6351166452680315), ('params', 3.5207701126734414), ('hue', 3.497920513153076)]
Top words for pretrained_codeGPTPyAdapted neuron indx 338 [('div', 3.1099355220794678), ('engines', 3.0930999517440796), ('struct', 3.0728328227996826), ('engine', 2.9868316650390625), ('import', 2.857145150502523)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4435 [('random', 4.347470588982105), ('byte', 4.093625068664551), ('224', 3.9355990886688232), ('close', 3.6118576526641846), ('items', 3.2379517555236816)]
Top words for pretrained_codeGPTPyAdapted neuron indx 341 [('param', 4.826406319936116), ('borders', 3.931004524230957), ('console', 3.5393614768981934), ('label', 3.3115344047546387), ('1000', 3.2309941053390503)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2396 [('720', 3.99617600440979), ('extend', 3.5272507667541504), ('categories', 3.4237293720245363), ('themes', 3.3521622154447765), ('cost', 3.159994959831238)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2397 [('render', 6.678303003311157), ('Image', 4.588112242081586), ('terminated', 4.218092441558838), ('259', 4.139655590057373), ('443', 4.118356704711914)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8541 [('0x9F', 3.1112849712371826), ('render', 2.95566588640213), ('34', 2.872380495071411), ('365', 2.728933572769165), ('0x89', 2.7090091705322266)]
Top words for pretrained_codeGPTPyAdapted neuron indx 357 [('min', 3.525308264626397), ('max', 3.4376571476459503), ('predicted', 3.314550757408142), ('center', 3.255553682645162), ('pred', 3.1770898699760437)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2414 [('bias', 4.227316856384277), ('hue', 3.608923554420471), ('decode', 3.191149282455444), ('tw', 2.972326397895813), ('480', 2.8792099952697754)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6516 [('arg', 3.299802780151367), ('lower', 3.0485615730285645), ('debug', 2.8927621841430664), ('close', 2.8433151245117188), ("'127.0.0.1'", 2.791016697883606)]
Top words for pretrained_codeGPTPyAdapted neuron indx 378 [('ref', 5.4194949467976885), ('400', 5.144662857055664), ('34', 5.0906572341918945), ('eq', 4.9543843269348145), ('202', 4.816254734992981)]
Top words for pretrained_codeGPTPyAdapted neuron indx 380 [('borders', 3.6520893573760986), ('hours', 3.6139023303985596), ('area', 3.5537980794906616), ('dist', 3.286665916442871), ('224', 3.2743911743164062)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2434 [('activation', 3.9392736752827964), ('form', 3.9061092535654702), ('all', 3.655313491821289), ('country', 3.6395394802093506), ('101677777', 3.6123600006103516)]
Top words for pretrained_codeGPTPyAdapted neuron indx 389 [('locales', 6.366888523101807), ('categorie', 4.512268900871277), ('answerers', 4.433489799499512), ("'eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IjEifQ.eyJhdWQiOiJodHRwczovL2FwaS5hbWF6b25hbGV4YS5jb20iLCJpc3MiOiJBbGV4YVNraWxsS2l0Iiwic3ViIjoiYW16bjEuYXNrLnNraWxsLjhiMTdhNWRlLTM3NDktNDkxOS1hYTFmLWUwYmJhZjhhNDZhNiIsImV4cCI6MTU0NTIyMzY1OCwiaWF0IjoxNTQ1MjIwMDU4LCJuYmYiOjE1NDUyMjAwNTgsInByaXZhdGVDbGFpbXMiOnsiY29uc2VudFRva2VuIjpudWxsLCJkZXZpY2VJZCI6ImFtem4xLmFzay5kZXZpY2UuQUZRQU1MWU9ZUVVVQUNTRTdIRlZZUzRaSTJLVUIzNUpQSFFSVVBLVERDQVUzQTQ3V0VTUDVMNTdLU1dUNUw2UlQzRlZYV0g0T0EyRE5QSlJNWjJWR0VJQUNGM1BKRUlEQ09VV1VCQzRXNVJQSk5VQjNaVlQyMko0VUpONVVMM1QyVUJQMzZSVkhGSjVQNElQVDJIVVkzUDJZT1kzM0lPVTRPMzNIVUFHN1IyQlVOUk9FSDRUMiIsInVzZXJJZCI6ImFtem4xLmFzay5hY2NvdW50LkFHUjRSMkxPVkhNTk1OT0dST0JWTkxVN0NMNEM1N1g0NjVYSkYyVDJGNTVPVVhOVExDWERRUDNJNTVVWFpJQUxFS0taSjZRMk1BNU1FRlNNWlZQRUw1TlZaUzZGWkxFVTQ0NEJWT0xQQjVXVkg1Q0hZVFFBS0dEN1ZGTEdQUkZaVkhISDJOSUI0SEtOSEhHWDZITTZTNlFEV0NLWFdPSVpMN09OTlFTQlVDVlBNWlFLTUNZWFJHNUJBMlBPWUVYRkRYUlhDR0VWRFdWU01QUSJ9fQ.jcomYhBhU485T4uoe2NyhWnL-kZHoPQKpcycFqa-1sy_lSIitfFGup9DKrf2NkN-I9lZ3xwq9llqx9WRN78fVJjN6GLcDhBDH0irPwt3n9_V7_5bfB6KARv5ZG-JKOmZlLBqQbnln0DAJ10D8HNiytMARNEwduMBVDNK0A5z6YxtRcLYYFD2-Ieg_V8Qx90eE2pd2U5xOuIEL0pXfSoiJ8vpxb8BKwaMO47tdE4qhg_k7v8ClwyXg3EMEhZFjixYNqdW1tCrwDGj58IWMXDyzZhIlRMh6uudMOT6scSzcNVD0v42IOTZ3S_X6rG01B7xhUDlZXMqkrCuzOyqctGaPw'", 4.422057628631592), ('contrast', 4.246945738792419)]
Top words for pretrained_codeGPTPyAdapted neuron indx 391 [('area', 6.162113904953003), ('pow', 4.418883800506592), ('ET', 4.1516289710998535), ('64', 3.9947646747935903), ('site', 3.9198455810546875)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4488 [('error', 5.381034851074219), ('exceptions', 4.905207633972168), ('dumps', 4.830023606618245), ('zip', 4.533164421717326), ('squeeze', 4.426417350769043)]
Top words for pretrained_codeGPTPyAdapted neuron indx 392 [('border', 5.682558536529541), ('borders', 4.463741302490234), ('padding', 4.462597926457723), ('tw', 3.939944326877594), ('torch', 3.799678377203039)]
Top words for pretrained_codeGPTPyAdapted neuron indx 405 [('info', 3.5329860746860504), ('clone', 3.3583035469055176), ('Response', 3.214712905883789), ('bias', 3.0462727546691895), ('flush', 3.043290138244629)]
Top words for pretrained_codeGPTPyAdapted neuron indx 406 [('Sequence', 4.3195414543151855), ('word', 3.8013539910316467), ('pred', 3.7103753089904785), ('timestamp', 3.4974138736724854), ('eq', 3.375295400619507)]
Top words for pretrained_codeGPTPyAdapted neuron indx 407 [('cookies', 3.808215379714966), ('Color', 3.5204977989196777), ('q', 3.2621703147888184), ('scale', 3.167965820857457), ('default', 3.143861770629883)]
Top words for pretrained_codeGPTPyAdapted neuron indx 412 [('extend', 4.400701999664307), ('hours', 3.951929211616516), ('prepare', 3.891822576522827), ('symbols', 3.8074084520339966), ('device', 3.804313039779663)]
Top words for pretrained_codeGPTPyAdapted neuron indx 414 [('default', 4.842798233032227), ('theme', 4.785742282867432), ('host', 4.234363555908203), ('Contrast', 4.187410354614258), ('cookies', 4.110497236251831)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6558 [('clone', 3.253593683242798), ('render', 3.1727561950683594), ('RawTextQuery', 2.848565936088562), ('merge', 2.8106406696140764), ('307', 2.7316577434539795)]
Top words for pretrained_codeGPTPyAdapted neuron indx 424 [('height', 3.0538680228320034), ('Response', 3.046973371505737), ('Request', 3.0042325258255005), ('force', 2.6578601598739624), ('redirect', 2.5511629581451416)]
Top words for pretrained_codeGPTPyAdapted neuron indx 425 [('history', 4.979874610900879), ('Sequence', 4.202674865722656), ('240', 4.120387951533), ('hit', 4.118987560272217), ('fid', 3.900347352027893)]
Top words for pretrained_codeGPTPyAdapted neuron indx 426 [('terminated', 4.89387321472168), ('descend', 3.6851255893707275), ('2048', 3.6492518520355226), ('contiguous', 3.6151862144470215), ('tr', 3.4150274991989136)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4524 [('192', 3.4816460609436035), ('224', 3.2756495475769043), ('800', 2.938263177871704), ('Image', 2.747254525913912), ('else', 2.6935970987220412)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2477 [('pow', 3.040130615234375), ('read', 2.665462295214335), ('perspective', 2.64578914642334), ('borders', 2.47891902923584), ('sprint', 2.4104866981506348)]
Top words for pretrained_codeGPTPyAdapted neuron indx 433 [('tag', 5.665903091430664), ('device', 4.360385894775391), ('strip', 3.9812615315119424), ('degrees', 3.917055288950602), ('flush', 3.810779571533203)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8627 [('"//"', 3.5350964069366455), ('"configure"', 3.1782941818237305), ("'base_url'", 3.0217878818511963), ('"pm_long"', 2.8865561485290527), ('"post_process"', 2.8542673587799072)]
Top words for pretrained_codeGPTPyAdapted neuron indx 435 [('pretrained', 5.5391950607299805), ('hours', 5.51644492149353), ('days', 5.497771263122559), ('ET', 5.468998432159424), ('sprint', 4.733064651489258)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2486 [('conf', 4.2287099957466125), ('Contrast', 4.136839866638184), ('sub', 3.595906972885132), ('unicode', 3.485377311706543), ('expanduser', 3.258762836456299)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2490 [('443', 3.715611696243286), ('dumps', 3.438263018925985), ('246', 3.246087074279785), ('activation', 3.109299977620443), ('indexes', 3.1092404212270464)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4541 [('flush', 4.633188486099243), ('contiguous', 4.463188648223877), ('504', 4.311485767364502), ('units', 4.239694396654765), ('saturation', 4.000950634479523)]
Top words for pretrained_codeGPTPyAdapted neuron indx 448 [('descend', 6.942573070526123), ('202', 4.662086009979248), ('barrier', 4.563779354095459), ('Contrast', 4.221684455871582), ('207', 4.1677398681640625)]
Top words for pretrained_codeGPTPyAdapted neuron indx 451 [('keywords', 4.342161178588867), ('themes', 3.6538708209991455), ('pop', 3.6094067891438804), ('theme', 3.5466296672821045), ('words', 3.539796829223633)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2509 [('301', 4.243595600128174), ('Session', 3.5948996543884277), ('365', 3.535860061645508), ('302', 3.5332391262054443), ('502', 3.5282134413719177)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2511 [('Contrast', 4.389223098754883), ('uniform', 4.3262739398262715), ('Session', 3.4734957218170166), ('504', 3.383761167526245), ('timestamp', 3.2002366383870444)]
Top words for pretrained_codeGPTPyAdapted neuron indx 466 [('dumps', 5.6808648109436035), ('responses', 4.1405730724334715), ('torch', 3.988896634127643), ('stride', 3.900700807571411), ('sub', 3.854342222213745)]
Top words for pretrained_codeGPTPyAdapted neuron indx 468 [('perspective', 4.621804714202881), ('uniform', 3.8110871531746606), ('saturation', 3.678694248199463), ('borders', 3.573706865310669), ('Color', 3.553621292114258)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2518 [('div', 5.736184120178223), ('sub', 4.861056804656982), ('basename', 4.71143102645874), ('bias', 4.4790472984313965), ('Contrast', 3.873677968978882)]
Top words for pretrained_codeGPTPyAdapted neuron indx 470 [('lang', 5.154508638381958), ('random', 4.502969841162364), ('pop', 4.0171858469645185), ('param', 3.9551552136739097), ('language', 3.9195361818586076)]
Top words for pretrained_codeGPTPyAdapted neuron indx 475 [('quote', 6.835746765136719), ('bias', 5.068674564361572), ('patches', 5.063068866729736), ('code', 4.819558143615723), ('accuracy', 4.671104907989502)]
Top words for pretrained_codeGPTPyAdapted neuron indx 478 [('preferences', 4.634197888771693), ('clone', 4.155237674713135), ('corrections', 4.036352554957072), ('eq', 3.6823582649230957), ('quality', 3.652364134788513)]
Top words for pretrained_codeGPTPyAdapted neuron indx 484 [('sleep', 4.817412853240967), ('sys', 4.43828067779541), ('pretrained', 4.167234659194946), ('args', 3.9527511596679688), ('lang', 3.937062644958496)]
Top words for pretrained_codeGPTPyAdapted neuron indx 485 [('console', 4.890597820281982), ('q', 4.7186279296875), ('struct', 3.9722225666046143), ('shuffle', 3.8525261878967285), ('25', 3.709676742553711)]
Top words for pretrained_codeGPTPyAdapted neuron indx 486 [('fallback', 3.322707176208496), ('307', 3.099581003189087), ('503', 3.079576094945272), ('257', 3.052426338195801), ('version', 2.9983818531036377)]
Top words for pretrained_codeGPTPyAdapted neuron indx 487 [('session', 4.755067149798076), ('descend', 3.5474166870117188), ('"""wrapper"""', 3.289137840270996), ('translate', 3.09076389670372), ('fid', 3.0691252946853638)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2537 [('descend', 4.796200275421143), ('logger', 4.035482883453369), ('sub', 3.6753029823303223), ('add', 3.47605037689209), ('cat', 3.4201698303222656)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4590 [('read', 3.397645950317383), ('1000', 3.388703227043152), ('dict', 3.2085657119750977), ('Response', 3.1907864570617677), ('dictify', 3.130530893802643)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2557 [('copy', 4.304086780548095), ('Tensor', 4.102766036987305), ('set', 3.9317007064819336), ('scale', 3.613908358982631), ('t', 3.5069077682495116)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4608 [('str', 3.400210738182068), ('debug', 3.1683905124664307), ('rotate', 3.1036123037338257), ('tile', 2.98445987701416), ('192', 2.925131320953369)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2562 [('shuffle', 4.797833442687988), ('parse', 4.533111214637756), ('443', 4.486155033111572), ('country', 3.99082088470459), ('suffix', 3.874655842781067)]
Top words for pretrained_codeGPTPyAdapted neuron indx 514 [('hue', 4.060104310512543), ('theme', 4.048867702484131), ('permute', 3.654313325881958), ('site', 3.3369455337524414), ('index', 3.3353880984442577)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8708 [('timedelta', 3.633167028427124), ('over', 3.5511879920959473), ('"ignore"', 3.3913629055023193), ('error', 3.3435423374176025), ('exceptions', 3.32474422454834)]
Top words for pretrained_codeGPTPyAdapted neuron indx 519 [('terminated', 5.397886276245117), ('timedelta', 3.903331995010376), ('550', 3.7637343406677246), ('datetime', 3.7604998350143433), ('429', 3.485363245010376)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2573 [('eq', 5.231185436248779), ('259', 5.200092315673828), ('264', 4.2373270988464355), ('257', 4.143571376800537), ('arg', 4.131217002868652)]
Top words for pretrained_codeGPTPyAdapted neuron indx 526 [('dumps', 3.9169119199117026), ('io', 3.647667646408081), ('attempt', 3.6340935230255127), ('20061', 3.602128744125366), ('PIL', 3.1517508029937744)]
Top words for pretrained_codeGPTPyAdapted neuron indx 530 [('patches', 4.430905818939209), ('fill', 3.8616011142730713), ('preferences', 3.829822222391764), ('"#"', 3.3976711432139077), ('ioctl', 3.323352098464966)]
Top words for pretrained_codeGPTPyAdapted neuron indx 531 [('barrier', 4.719083786010742), ('exit', 4.667734622955322), ('communicate', 4.411518096923828), ('sprint', 4.395750999450684), ('420', 4.369715690612793)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2588 [('engine', 5.323041915893555), ('country', 4.285313606262207), ('420', 3.9240379333496094), ('round', 3.905375671386719), ('410', 3.8663715521494546)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2595 [('join', 3.4828738305303784), ('confidence', 3.222418785095215), ('attention', 2.9647436141967773), ('rotate', 2.856837749481201), ('redirect', 2.853442907333374)]
Top words for pretrained_codeGPTPyAdapted neuron indx 553 [('splits', 5.44755744934082), ('theme', 5.299633026123047), ('site', 5.2860260009765625), ('gain', 4.943337917327881), ('ET', 4.939087867736816)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2609 [('enhance', 4.191588401794434), ('skill', 3.7507516145706177), ('2048', 3.5292130947113036), ('dim', 3.517310380935669), ('pop', 3.3012128671010337)]
Top words for pretrained_codeGPTPyAdapted neuron indx 564 [('device', 3.6005760192871095), ('letters', 3.5971328020095825), ('quality', 3.551154851913452), ('ord', 3.548931754552401), ('narrow', 3.5165172815322876)]
Top words for pretrained_codeGPTPyAdapted neuron indx 568 [('202', 4.579653024673462), ('squeeze', 4.323645114898682), ('XML', 4.062343120574951), ('shuffle', 3.9607512950897217), ('filter', 3.9177041053771973)]
Top words for pretrained_codeGPTPyAdapted neuron indx 572 [('final', 3.2033561865488687), ('prefix', 3.0954507986704507), ('append', 3.0579188451534365), ('close', 2.9563863277435303), ('line', 2.9297481775283813)]
Top words for pretrained_codeGPTPyAdapted neuron indx 574 [('bias', 4.878270149230957), ('splits', 4.320519924163818), ('x', 4.109935522079468), ('seq', 4.0872156620025635), ('sum', 4.07261962890625)]
Top words for pretrained_codeGPTPyAdapted neuron indx 577 [('perspective', 4.365310192108154), ('descend', 4.3032684326171875), ('error', 3.909731149673462), ('title', 3.648252555302211), ('skill', 3.47600257396698)]
Top words for pretrained_codeGPTPyAdapted neuron indx 579 [('sprint', 4.560723304748535), ('timestamp', 4.391931533813477), ('predicted', 4.208987355232239), ('target', 3.9325644175211587), ('seq', 3.8747748136520386)]
Top words for pretrained_codeGPTPyAdapted neuron indx 580 [('map', 4.474257230758667), ('escape', 4.3247809410095215), ('hit', 3.889826202392578), ('mult', 3.353164792060852), ('mul', 3.3403515815734863)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2629 [('XML', 4.629624366760254), ('77', 3.804145932197571), ('sub', 3.7632598876953125), ('109', 3.690953016281128), ('clone', 3.632197380065918)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4676 [('144', 3.618010997772217), ('descend', 3.2290494441986084), ('cat', 3.0813944339752197), ('140', 3.07714581489563), ('175', 3.056753396987915)]
Top words for pretrained_codeGPTPyAdapted neuron indx 584 [('90', 4.116847991943359), ('param', 4.073421796162923), ('180', 4.023123413324356), ('resize', 3.8505585193634033), ('queries', 3.8056501150131226)]
Top words for pretrained_codeGPTPyAdapted neuron indx 585 [('enhancer', 4.414432764053345), ('letters', 4.364056587219238), ('pretrained', 4.139978349208832), ('100', 3.6259499016930077), ('1000', 3.610672116279602)]
Top words for pretrained_codeGPTPyAdapted neuron indx 596 [('console', 7.278366565704346), ('barrier', 6.455974578857422), ('scheme', 6.39479398727417), ('squeeze', 6.286985874176025), ('tile', 6.0778069496154785)]
Top words for pretrained_codeGPTPyAdapted neuron indx 598 [('lower', 3.503740390141805), ('children', 3.415939450263977), ('info', 3.3858531415462494), ('63', 3.3358770608901978), ('800', 3.209895133972168)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4698 [('answer', 4.51271915435791), ('Number', 4.431909879048665), ('conf', 3.95265856385231), ('std', 3.720601886510849), ('md5', 3.6922006607055664)]
Top words for pretrained_codeGPTPyAdapted neuron indx 605 [('dom', 3.424174451828003), ('th', 3.2870978116989136), ('shape', 3.2592000007629394), ('head', 3.037229537963867), ('query', 2.94933038408106)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4701 [('render', 5.495681405067444), ('Image', 4.150066642200246), ('shape', 3.3852420330047606), ('strip', 3.326851805051168), ('terminated', 3.240323543548584)]
Top words for pretrained_codeGPTPyAdapted neuron indx 606 [('perspective', 4.592675685882568), ('2048', 4.3971833229064945), ('sum', 4.393831253051758), ('""', 3.88454892900255), ('tmp', 3.718490242958069)]
Top words for pretrained_codeGPTPyAdapted neuron indx 607 [('saturation', 5.507550358772278), ('sprint', 4.29111385345459), ('Session', 4.219992637634277), ('type', 3.9931938648223877), ('site', 3.8839261531829834)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2658 [('pow', 4.083718776702881), ('themes', 3.667697058783637), ('descend', 3.1159191131591797), ('StopIteration', 3.0850636959075928), ('GoogLeNet', 2.950520157814026)]
Top words for pretrained_codeGPTPyAdapted neuron indx 610 [('filename', 4.052307932000411), ('34', 3.7240190505981445), ('os', 3.60030184532034), ('engines', 3.4887055158615112), ('ByteStorage', 3.3893115520477295)]
Top words for pretrained_codeGPTPyAdapted neuron indx 617 [('bl', 4.811304688453674), ('files', 4.8038507870265414), ('timeout', 4.747675100962321), ('contiguous', 4.461979389190674), ('float', 4.1141124452863425)]
Top words for pretrained_codeGPTPyAdapted neuron indx 619 [('resize', 4.455066442489624), ('resample', 3.8747698068618774), ('"histograms"', 3.2889227867126465), ('json', 3.2099142372608185), ('hue', 3.1539160013198853)]
Top words for pretrained_codeGPTPyAdapted neuron indx 626 [('XML', 4.341436862945557), ('palette', 3.890054702758789), ('scheme', 3.683781862258911), ('title', 3.4351747121129717), ('method', 3.362807810306549)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2692 [('stride', 4.812875429789226), ('43', 4.363013744354248), ('activation', 3.617433508237203), ('content', 3.458140035470327), ('prepare', 3.421304702758789)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2693 [('180', 4.022467225790024), ('contrast', 3.3794784545898438), ('192', 3.321174144744873), ('pop', 3.2848536570866904), ('save', 3.185670852661133)]
Top words for pretrained_codeGPTPyAdapted neuron indx 645 [('302', 4.1311116218566895), ('420', 3.2095210552215576), ('barrier', 2.7879202365875244), ('_img', 2.680975317955017), ('502', 2.664550244808197)]
Top words for pretrained_codeGPTPyAdapted neuron indx 647 [('perspective', 5.276258945465088), ('tar', 4.507443785667419), ('exit', 4.050148963928223), ('answer', 3.99823260307312), ('next', 3.912156581878662)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4745 [('form', 3.7843022611406116), ('nn', 3.7136828899383545), ('tw', 3.7131482362747192), ('302', 3.642388105392456), ('days', 3.5557589530944824)]
Top words for pretrained_codeGPTPyAdapted neuron indx 650 [('borders', 4.861314296722412), ('Brightness', 4.455463409423828), ('theme', 4.125775337219238), ('uniform', 3.9220398989590732), ('201', 3.8081134557724)]
Top words for pretrained_codeGPTPyAdapted neuron indx 653 [('csv', 4.412810850143432), ('443', 3.879270553588867), ('site', 3.531964063644409), ('224', 3.5083699226379395), ('symbols', 3.434988498687744)]
Top words for pretrained_codeGPTPyAdapted neuron indx 656 [('force', 3.6357359886169434), ('math', 3.262586236000061), ('brightness', 3.2369344830513), ('180', 3.14041006565094), ('loads', 3.0620598196983337)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8862 [('exp', 3.1442677974700928), ('render', 3.120956838130951), ('307', 3.088778495788574), ('258', 3.006683826446533), ('color', 2.8798844814300537)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4778 [('gain', 3.570615768432617), ('140', 3.503803253173828), ('numbers', 3.210134188334147), ('175', 3.10449481010437), ('bias', 3.1028707027435303)]
Top words for pretrained_codeGPTPyAdapted neuron indx 685 [('Contrast', 5.365250110626221), ('Session', 5.055791854858398), ('Sequence', 4.57664680480957), ('rotate', 4.302480220794678), ('gain', 4.2954933643341064)]
Top words for pretrained_codeGPTPyAdapted neuron indx 688 [('tr', 5.783111810684204), ('dumps', 5.445602099100749), ('escape', 4.30669641494751), ('engines', 4.298049211502075), ('th', 3.8692482113838196)]
Top words for pretrained_codeGPTPyAdapted neuron indx 691 [('loads', 3.586587756872177), ('fallback', 3.5403993129730225), ('y', 3.4984045369284495), ('extend', 3.467874765396118), ('open', 3.210684633255005)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6837 [('append', 3.798179952109732), ('flush', 3.5435950756073), ('pop', 3.2148490746816), ('loads', 3.1860967874526978), ('enhance', 3.0823216438293457)]
Top words for pretrained_codeGPTPyAdapted neuron indx 697 [('line', 5.3341147899627686), ('height', 4.422282262281938), ('narrow', 4.16755473613739), ('round', 4.12996621131897), ('link', 4.083474636077881)]
Top words for pretrained_codeGPTPyAdapted neuron indx 709 [("'sort'", 4.193136692047119), ('"fields"', 3.9315004348754883), ("'six'", 3.7305796146392822), ("'suggestions'", 3.6543586254119873), ('"condition"', 3.6146931648254395)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6853 [('Response', 2.3976118564605713), ("'graph'", 2.3815964698791503), ("'write'", 2.356874108314514), ("'off'", 2.3400394320487976), ('in', 2.235857324275185)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4813 [('301', 3.9213547706604004), ('reshape', 3.725055694580078), ('array', 3.5585216283798218), ('502', 3.453283965587616), ('365', 3.437263011932373)]
Top words for pretrained_codeGPTPyAdapted neuron indx 723 [('tar', 6.240721940994263), ('correct', 5.2861833572387695), ('logger', 4.551298141479492), ('answer', 4.31601095199585), ('site', 4.108999729156494)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2774 [('syst', 3.353971461455027), ('smid', 3.2567803859710693), ('201', 3.106510877609253), ('random', 3.028849276403586), ('width', 2.97818110539363)]
Top words for pretrained_codeGPTPyAdapted neuron indx 732 [('mimetype', 3.644155502319336), ('reporthook', 3.6243529319763184), ('botright', 3.5843135118484497), ('Request', 3.5836604833602905), ('Sequence', 3.4785051345825195)]
Top words for pretrained_codeGPTPyAdapted neuron indx 733 [('descend', 4.4501776695251465), ('parts', 3.732637405395508), ('req', 3.595064776284354), ('content', 3.355460286140442), ('gamma', 3.284037431081136)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4833 [('quality', 3.4635448455810547), ('over', 3.4530389308929443), ('now', 3.4423816204071045), ('quote', 3.3378353118896484), ("'NumFiles'", 3.0546092987060547)]
Top words for pretrained_codeGPTPyAdapted neuron indx 744 [('rotate', 4.573919773101807), ('center', 4.473928133646647), ('scale', 4.086176531655448), ('1000', 3.864868998527527), ('fallback', 3.6402595043182373)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4845 [("'train-labels-idx1-ubyte'", 3.1545615196228027), ("'t10k-labels-idx1-ubyte'", 3.038270950317383), ('escape', 3.020630717277527), ('any', 3.0185365676879883), ("'train-images-idx3-ubyte'", 2.963012218475342)]
Top words for pretrained_codeGPTPyAdapted neuron indx 750 [('dumps', 4.473928610483806), ('fid', 4.029088497161865), ('encode', 3.713177760442098), ('update', 3.5553150177001953), ('PIL', 3.442924976348877)]
Top words for pretrained_codeGPTPyAdapted neuron indx 752 [('part', 3.533304214477539), ('25', 3.229647970199585), ('sub', 3.203549861907959), ('Contrast', 3.0574610233306885), ('tw', 3.0445568561553955)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2802 [('str', 3.9676636159420013), ('sum', 3.4883464336395265), ('log', 3.422550582885742), ('unicode', 3.1359546184539795), ('answer', 3.058745861053467)]
Top words for pretrained_codeGPTPyAdapted neuron indx 764 [('loads', 4.2227373123168945), ('shuffle', 4.097804069519043), ('202', 3.8821394443511963), ('communicate', 3.86399507522583), ('descend', 3.8203964233398438)]
Top words for pretrained_codeGPTPyAdapted neuron indx 765 [('prepare', 5.459333419799805), ('pad', 4.675762176513672), ('resize', 3.7652812004089355), ('copy', 3.746529150009155), ('padding', 3.668686604499817)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4865 [('escape', 4.403084754943848), ('tmp', 2.6976693868637085), ('log', 2.6732277870178223), ('extend', 2.6258020401000977), ('175', 2.619093894958496)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2818 [('ET', 3.632944107055664), ('quote', 3.5360946655273438), ('246', 3.3290598392486572), ('301', 3.326274871826172), ('set', 3.160450983047485)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2821 [('contiguous', 4.725088119506836), ('Dense', 4.309646081924439), ('int', 4.2375174947083), ('F', 3.829556465148926), ('barrier', 3.662940263748169)]
Top words for pretrained_codeGPTPyAdapted neuron indx 778 [('2048', 4.795462131500244), ('timeout', 4.3580864270528155), ('enhance', 4.251678466796875), ('443', 4.213146209716797), ('144', 4.150567531585693)]
Top words for pretrained_codeGPTPyAdapted neuron indx 779 [('contiguous', 4.638062477111816), ('512', 4.5035291997397815), ('260', 3.9245622158050537), ('2048', 3.8765932083129884), ('clone', 3.8280673027038574)]
Top words for pretrained_codeGPTPyAdapted neuron indx 783 [('perspective', 6.159436225891113), ('squeeze', 5.461791038513184), ('cat', 4.897850513458252), ('uniform', 4.562222502448342), ('ele', 4.467979669570923)]
Top words for pretrained_codeGPTPyAdapted neuron indx 785 [('ele', 4.6284120082855225), ('clone', 4.414755821228027), ('443', 4.249216079711914), ('2048', 4.123119802474975), ('tw', 4.0563095808029175)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4888 [('saturation', 3.3856732845306396), ('hue', 3.2142868041992188), ('zip', 3.162545164426168), ('Concatenate', 3.0856754779815674), ('open', 3.057023024559021)]
Top words for pretrained_codeGPTPyAdapted neuron indx 793 [('enhance', 4.883570671081543), ('timeout', 4.294426679611206), ('enhancer', 4.270798921585083), ('barrier', 3.9815073013305664), ('quality', 3.7630025148391724)]
Top words for pretrained_codeGPTPyAdapted neuron indx 792 [('fid', 6.447954416275024), ('dim', 4.041624546051025), ('resize', 3.9751721024513245), ('quality', 3.964734673500061), ('barrier', 3.853318214416504)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2844 [('println', 4.73606014251709), ('Color', 3.8383383750915527), ('request', 3.6582522536769058), ('225', 3.6396572589874268), ('550', 3.502794027328491)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6946 [('dumps', 3.287959655125936), ('sub', 3.1799960136413574), ('raise', 2.7958241204420724), ('await', 2.795654740598467), ('target', 2.771026134490967)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6947 [('512', 4.109900486178514), ('Request', 3.922903895378113), ('height', 3.726728753610091), ('half_width', 3.4432555198669434), ('half_height', 3.382157802581787)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6957 [('mul', 3.681227445602417), ('channels', 3.0835044384002686), ('pic', 2.9600294298595853), ('account_number', 2.9426130453745523), ('count', 2.8599826097488403)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2866 [('144', 5.753777503967285), ('120', 4.719462871551514), ('ZipFile', 3.94724178314209), ('259', 3.9199812412261963), ('160', 3.7715466022491455)]
Top words for pretrained_codeGPTPyAdapted neuron indx 829 [('println', 5.926141738891602), ('ET', 4.659689426422119), ('shuffle', 4.5683088302612305), ('rotate', 4.113011837005615), ('append', 4.0755260746653486)]
Top words for pretrained_codeGPTPyAdapted neuron indx 836 [('144', 4.842243671417236), ('channels', 4.319780349731445), ('symbols', 3.7903460264205933), ('410', 3.7444305419921875), ('480', 3.7310984134674072)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9031 [("'Access-Control-Allow-Origin'", 3.4095938205718994), ("'Access-Control-Allow-Methods'", 3.342352867126465), ("'Access-Control-Allow-Headers'", 3.2814810276031494), ('param', 3.115917523701986), ('finally', 3.0296926498413086)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2892 [('error', 4.587687015533447), ('8080', 4.211774826049805), ('gui', 4.128965854644775), ('480', 4.017690658569336), ('Number', 3.7538063526153564)]
Top words for pretrained_codeGPTPyAdapted neuron indx 858 [('240', 5.838267167409261), ('443', 5.643910884857178), ('Number', 5.0065897305806475), ('260', 4.7964067459106445), ('translate', 4.781527042388916)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7004 [('720', 3.1685166358947754), ('add_cookie_header', 3.1267330646514893), ('tw', 3.0526833534240723), ("'user_fn'", 2.8226704597473145), ("'event_record_callback'", 2.747156858444214)]
Top words for pretrained_codeGPTPyAdapted neuron indx 868 [('basename', 3.50663685798645), ('min', 3.4532422489590116), ('gamma', 3.2032777468363443), ('max', 3.153902292251587), ('random', 3.121281454960505)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4970 [('palette', 3.5075062115987143), ('Optional', 2.9334988594055176), ('contiguous', 2.668760299682617), ('f', 2.652688530938966), ('float', 2.597974487713405)]
Top words for pretrained_codeGPTPyAdapted neuron indx 878 [('bias', 4.808902263641357), ('tw', 3.881851017475128), ('sqrt', 3.3930842876434326), ('hue', 3.2340304255485535), ('ele', 3.1916950941085815)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9077 [('Dense', 3.0933485507965086), ('"%.2f"', 3.088512420654297), ('F', 3.047832727432251), ('"%s-%s-%s-%s"', 2.972759246826172), ('borders', 2.900036334991455)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2942 [('accuracy', 4.835781097412109), ('float', 4.507453611918858), ('opt', 4.113945206006368), ('escape', 4.040610074996948), ('activation', 3.7150059143702188)]
Top words for pretrained_codeGPTPyAdapted neuron indx 895 [('contiguous', 4.8761420249938965), ('fid', 4.0972630977630615), ('degrees', 3.944373846054077), ('tr', 3.9394493103027344), ('85', 3.9283387660980225)]
Top words for pretrained_codeGPTPyAdapted neuron indx 900 [('io', 4.810518741607666), ('Contrast', 4.631096363067627), ('argv', 3.8317601680755615), ('34', 3.437711715698242), ('BytesIO', 3.4123709201812744)]
Top words for pretrained_codeGPTPyAdapted neuron indx 907 [('2048', 5.145795078277588), ('63', 4.823921799659729), ('84', 4.691886043548584), ('override', 4.365736293792724), ('175', 4.258116245269775)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7055 [('replace', 4.617462456226349), ('Lambda', 3.298463821411133), ('23', 2.9826903343200684), ('target', 2.9298840363820395), ('torch', 2.9049862494339815)]
Top words for pretrained_codeGPTPyAdapted neuron indx 914 [('pop', 4.643298069636027), ('tw', 4.606702089309692), ('clone', 4.449418544769287), ('system', 4.26693868637085), ('shuffle', 4.006208896636963)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2964 [('cookies', 4.369024038314819), ('timeout', 4.298016587893168), ('550', 4.167283535003662), ('descend', 3.297424554824829), ('tmp', 3.2707072496414185)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2988 [('Contrast', 4.00836706161499), ('Color', 3.3635711669921875), ('expanded', 3.26003630956014), ('over', 3.2163920402526855), ('predicted', 2.972640037536621)]
Top words for pretrained_codeGPTPyAdapted neuron indx 942 [('2048', 3.536163558959961), ('cookies', 3.285813808441162), ('skill', 2.917911171913147), ('eq', 2.8478078842163086), ('1024', 2.847399592399597)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9138 [('504', 3.552793264389038), ('400', 3.222588380177816), ('Sequence', 3.061769962310791), ('Iterable', 3.0091938972473145), ("'acceptingInput'", 2.9983949661254883)]
Top words for pretrained_codeGPTPyAdapted neuron indx 947 [('32', 4.208464622497559), ('240', 4.122228304545085), ('tmp', 3.8151144981384277), ('cookies', 3.5536125898361206), ('oh', 3.522045691808065)]
Top words for pretrained_codeGPTPyAdapted neuron indx 950 [('Contrast', 4.304133415222168), ('conf', 3.6442688405513763), ('merge', 3.542510338340487), ('re', 3.415735349059105), ('contrast', 3.3941099047660828)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9157 [('">"', 2.3892569541931152), ("'Week'", 2.3867557048797607), ('""', 2.28517783747779), ("'.gz'", 2.2799456119537354), ("'Month'", 2.2580513954162598)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5068 [('xpath', 2.9881779670715334), ('"identity"', 2.8100024700164794), ('"vl"', 2.787473201751709), ('"\\\\\\\\ctrl{"', 2.7444966435432434), ('"""str->str"""', 2.6878557205200195)]
Top words for pretrained_codeGPTPyAdapted neuron indx 972 [('suffix', 5.897113800048828), ('border', 5.179957628250122), ('letters', 4.949855089187622), ('fill', 4.949169317881267), ('reshape', 4.928003787994385)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5077 [('splits', 3.63677978515625), ('"%f"', 2.8155200481414795), ('moves', 2.8070638179779053), ('"Bit"', 2.7511284351348877), ('scheme', 2.741149663925171)]
Top words for pretrained_codeGPTPyAdapted neuron indx 994 [('gui', 4.141027927398682), ('fid', 4.04242879152298), ('predicted', 3.5949722230434418), ('letters', 3.548990249633789), ('param', 3.539292097091675)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1006 [('gamma', 4.9145181973775225), ('720', 3.9309067726135254), ('answer', 3.915278673171997), ('pow', 3.906937599182129), ('json', 3.533261150121689)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3062 [('system', 3.896207571029663), ('round', 3.81821665763855), ('degrees', 3.2767998377482095), ('letters', 3.2035220861434937), ('descend', 3.139352798461914)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3064 [('finally', 5.15462863445282), ('prepare', 4.533108234405518), ('quote', 4.510995864868164), ('language', 4.318070207323347), ('logger', 3.896991014480591)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1016 [('border', 5.562612056732178), ('skill', 4.514334440231323), ('pred', 4.4283599853515625), ('io', 4.411381721496582), ('enhance', 4.367959499359131)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1021 [('scale', 4.5130927222115655), ('Tensor', 4.163102626800537), ('copy', 4.159685516357422), ('set', 3.942513084411621), ('800', 3.9357409477233887)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1027 [('AlexNet', 4.704702854156494), ('pretrained', 4.14689114689827), ('ratio', 3.9215589591435025), ('patterns', 3.8999502182006838), ('uniform', 3.8748776479200884)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9236 [('99.73', 2.947023868560791), ('Conv2d', 2.9069533348083496), ('items', 2.8921213150024414), ('AlexNet', 2.8085293769836426), ("'thu'", 2.695221185684204)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1047 [('quality', 4.752769231796265), ('keywords', 4.67873477935791), ('gamma', 4.172293504079183), ('85', 3.8668839931488037), ('sprint', 3.8164494037628174)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7192 [("'memory_slots'", 3.452836751937866), ("'channel_id'", 3.2919695377349854), ('force', 2.9173130989074707), ("'environment_dict'", 2.9155845642089844), ('re', 2.8950849920511246)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5145 [('convert', 3.2683481693267824), ('uniform', 3.091505939310247), ('min', 3.02273960908254), ('skills_processor', 2.896960973739624), ('name', 2.728895970753261)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3097 [('enhance', 3.984592914581299), ('enhancer', 3.5063143173853555), ('GoogLeNet', 3.1953712701797485), ('transpose', 3.188666899998983), ('result', 3.1383167008558908)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1052 [('engine', 5.549958229064941), ('engines', 4.780513763427734), ('410', 4.538208484649658), ('43', 4.533609867095947), ('pretrained', 4.337596774101257)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9250 [('Color', 4.626999855041504), ('Contrast', 4.429931640625), ('enhance', 3.847951889038086), ('sub', 3.713507652282715), ('440.0', 3.3393340905507407)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1059 [('confidence', 5.153037667274475), ('exp', 5.079339027404785), ('join', 4.323313024308947), ('attention', 3.9885127544403076), ('transform', 3.906994879245758)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5157 [('find', 4.283118724822998), ('ele', 3.7610539197921753), ('extract', 3.722402811050415), ('extend', 3.503190279006958), ('dim', 3.4746344089508057)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1063 [('fid', 5.838408470153809), ('pic', 5.530525493621826), ('streams', 4.923896670341492), ('443', 4.785797119140625), ('stream', 4.732171876089914)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3112 [('now', 4.386226415634155), ('download', 4.1907351811726885), ('ET', 3.7498579025268555), ('180', 3.4756916761398315), ('240', 3.427279233932495)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1067 [('enhance', 5.88688850402832), ('extend', 5.267658233642578), ('preferences', 4.75527861515681), ('quality', 4.534572720527649), ('fid', 4.320146381855011)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9282 [('XML', 4.8877410888671875), ('RED', 3.8514297008514404), ('prepare', 3.6678664684295654), ('upper', 3.570643663406372), ("'1234'", 3.480974316596985)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9284 [('is_tensor', 6.0011680126190186), ('is_dir', 4.862009525299072), ('isfile', 4.446153879165649), ('LongTensor', 4.215226173400879), ('is_master', 3.924175500869751)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1093 [('XML', 5.482640266418457), ('enhance', 4.5140180587768555), ('enhancer', 4.35574730237325), ('443', 4.3089799880981445), ('confidence', 4.1444737911224365)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9291 [('ET', 5.883800029754639), ('bias', 5.364509105682373), ('Optional', 3.7309603691101074), ('enhance', 3.451791763305664), ('sub', 3.392369270324707)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1100 [('240', 6.162608623504639), ('800', 5.434032917022705), ('720', 5.214615821838379), ('system', 4.943147659301758), ('pretrained', 4.758244037628174)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1104 [('85', 4.720702171325684), ('480', 3.6770339012145996), ('550', 3.6485180854797363), ('140', 3.4303903579711914), ('loads', 3.4273698031902313)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1106 [('144', 4.645951747894287), ('contrast', 4.2302276492118835), ('"\\', 4.216849103569984), ('border', 3.852757692337036), ('expand', 3.8492534160614014)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5203 [('random', 3.692060778538386), ('byte', 3.6785473823547363), ('224', 3.659773111343384), ('close', 3.4055898189544678), ('seconds', 3.375996947288513)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1108 [('quality', 5.326370716094971), ('confidence', 4.365823030471802), ('barrier', 4.296828269958496), ('filter', 4.280862331390381), ('240', 4.274985631306966)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1113 [('443', 5.635009288787842), ('260', 5.194248199462891), ('259', 5.038651943206787), ('264', 4.852901458740234), ('barrier', 4.484444618225098)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5210 [('sum', 4.297044134140014), ('314', 4.236970901489258), ('headers', 3.9918074824593286), ('307', 3.9377429485321045), ('days', 3.4177136421203613)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3162 [('answer', 4.96392822265625), ('std', 4.779737502336502), ('Number', 4.514212767283122), ('conf', 4.235726028680801), ('8080', 3.9863991737365723)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1114 [('letters', 5.6496336460113525), ('keywords', 5.013722896575928), ('tar', 4.954952716827393), ('257', 4.033841609954834), ('512', 3.9550652911023394)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1116 [('enhance', 5.21428108215332), ('skill', 4.797050952911377), ('language', 3.9938789776393344), ('brightness', 3.894593060016632), ('contrast', 3.6080586314201355)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1135 [('zip', 5.159294366836548), ('scheme', 4.726558208465576), ('dumps', 4.37840461730957), ('pic', 4.31220186551412), ('dict', 3.5895190238952637)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7284 [("'127.0.0.1'", 2.9671361446380615), ('debug', 2.6498072147369385), ('attempt', 2.5592691898345947), ('720', 2.3948466777801514), ("'Accept-Encoding'", 2.3216865062713623)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9340 [('ioctl', 3.8606507778167725), ('parseString', 3.7395803928375244), ('RED', 3.5017669200897217), ('shear', 3.212600517272949), ('NotImplementedError', 3.0336806774139404)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1156 [('stride', 5.272217909495036), ('84', 4.5778429985046385), ('content', 4.217598080635071), ('43', 4.109067916870117), ('squeeze', 3.726897954940796)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1158 [('preferred', 5.0341246128082275), ('border', 4.756819009780884), ('443', 4.520475387573242), ('six', 4.4911932945251465), ('eq', 4.484020709991455)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5264 [('opt', 3.6560431718826294), ('brightness', 3.14376038312912), ('params', 3.029517635703087), ('patterns', 2.9693081378936768), ('Optional', 2.9040331840515137)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1172 [('sprint', 5.277222156524658), ('append', 5.079938539644567), ('root', 4.12981679521758), ('zip', 4.0719679196675616), ('round', 4.044159746170044)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3224 [('XML', 3.8401639461517334), ('301', 3.4914638996124268), ('suffix', 3.469637155532837), ('bias', 3.4338834285736084), ('exp', 3.3303422927856445)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1179 [('fid', 5.22804594039917), ('365', 4.846651554107666), ('307', 4.505904197692871), ('bytes', 4.402125835418701), ('uniform', 4.277144540439952)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3228 [('ET', 3.1189959049224854), ('translate', 3.057785391807556), ('confidence', 2.9946532249450684), ('Lambda', 2.766771125793457), ('render', 2.713636636734009)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7324 [('byte', 3.941182851791382), ('207', 3.6441562175750732), ('exit', 3.0618252754211426), ('raise', 3.032594222288865), ('90', 2.958217740058899)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7326 [('render', 3.3801201581954956), ('307', 3.196032762527466), ('merge', 3.1138484456709454), ('clone', 3.0540030002593994), ('saturation', 2.804385155439377)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9383 [('bias', 5.651451587677002), ('Contrast', 4.786642551422119), ('27.12', 4.333381652832031), ('192.85', 4.121011257171631), ('27.12825', 3.843710422515869)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1193 [('round', 5.393886756896973), ('enhance', 4.96673059463501), ('squeeze', 4.495650768280029), ('history', 4.4402642250061035), ('translate', 4.095036834478378)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5291 [('append', 3.584010833647193), ('63', 3.0354522466659546), ('println', 2.751166582107544), ('180', 2.7111336290836334), ("'.jpg'", 2.671924352645874)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1203 [('headers', 5.6243039477955215), ('any', 4.717062950134277), ('keywords', 4.565505504608154), ('307', 4.548986434936523), ('decode', 4.377556562423706)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3258 [('443', 3.097944974899292), ('dumps', 2.808086554209391), ('activation', 2.657828132311503), ('"W_proj"', 2.6577303409576416), ('re', 2.6416255831718445)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1213 [('crop', 5.8466944098472595), ('Sequence', 4.997375011444092), ('saturation', 4.735649466514587), ('perspective', 4.6255927085876465), ('fid', 4.512482166290283)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5309 [('flush', 4.551693677902222), ('contiguous', 4.550010681152344), ('close', 4.067001819610596), ('504', 4.059144020080566), ('units', 3.5860294500986734)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1214 [('contiguous', 5.020443439483643), ('XML', 4.651216506958008), ('system', 4.232163906097412), ('ow', 4.19356773296992), ('headers', 4.184838706796819)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3261 [('barrier', 4.2818989753723145), ('131', 3.9727602005004883), ('engines', 3.8320523500442505), ('items', 3.739546775817871), ('UnicodeWriter', 3.417975902557373)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1215 [('site', 5.3675642013549805), ('type', 5.366619110107422), ('q', 5.324486255645752), ('class', 5.223268508911133), ('im', 5.155540227890015)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1228 [('system', 4.9133148193359375), ('hue', 4.752679109573364), ('console', 4.6240386962890625), ('perspective', 4.466861724853516), ('ratio', 4.423903124673026)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1230 [('stride', 5.051273504892985), ('720', 4.518775463104248), ('tr', 4.264835357666016), ('tw', 3.935512125492096), ('seek', 3.868450880050659)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1235 [('ref', 5.5163858731587725), ('expand', 4.7735302448272705), ('width', 4.623854325367854), ('categories', 4.514596080780029), ('lang', 4.497512149810791)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1236 [('saturation', 5.829208254814148), ('exceptions', 5.148669719696045), ('rstrip', 4.594644069671631), ('Sequence', 4.424175262451172), ('squeeze', 4.399652004241943)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1237 [('302', 3.777146816253662), ('corrections', 3.6221773624420166), ('ioctl', 3.576139211654663), ('144', 3.459712505340576), ('translations', 3.4225051005681357)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1239 [('oh', 5.2959872881571455), ('RED', 4.507126808166504), ('seek', 4.218439102172852), ('gamma', 4.120388825734456), ('math', 4.027123689651489)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1241 [('plugins', 4.915830135345459), ('skill', 4.8235766887664795), ('hue', 4.570430874824524), ('fid', 4.446151971817017), ('letters', 4.432981252670288)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1246 [('ET', 7.372880458831787), ('262', 5.981717109680176), ('fid', 5.732980012893677), ('days', 5.036103248596191), ('600', 4.5481390953063965)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9441 [('termios', 4.423256874084473), ('Contrast', 4.012345314025879), ('Exception', 3.5926077365875244), ('ValueError', 3.396416664123535), ('Response', 3.2521596431732176)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3297 [('quality', 5.3875181674957275), ('now', 4.560021877288818), ('tile', 4.463359832763672), ('quote', 4.209371089935303), ('exit', 3.7898356914520264)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1266 [('ele', 3.9668588638305664), ('palette', 3.6156252225240073), ('println', 3.5773723125457764), ('letters', 3.5390650033950806), ('sprint', 3.4937615394592285)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1269 [('barrier', 3.997084617614746), ('sprint', 3.6408042907714844), ('perspective', 3.537489891052246), ('degrees', 3.4249069690704346), ('borders', 3.2777702808380127)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9473 [('RED', 3.7370424270629883), ('torch', 2.9202373478863692), ('to', 2.8002564907073975), ('FFMPEG', 2.7895469665527344), ('8080', 2.5363502502441406)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7427 [('Session', 3.1158790588378906), ("'127.0.0.1'", 2.8106993436813354), ('urls', 2.792831301689148), ('23', 2.74224853515625), ('Response', 2.7388727188110353)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1285 [('contiguous', 4.993669033050537), ('escape', 4.937971115112305), ('palette', 4.610032240549724), ('flush', 4.581296443939209), ('sprint', 4.249314308166504)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1291 [('stride', 6.870686054229736), ('descend', 4.942802429199219), ('2048', 4.677556772232055), ('43', 4.663293361663818), ('XML', 4.132599830627441)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3341 [('eq', 5.281824588775635), ('259', 4.61862850189209), ('exit', 4.303531646728516), ('264', 4.053187847137451), ('arg', 3.9566497802734375)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7438 [('pow', 3.492891550064087), ('zip', 3.1222532987594604), ('stride', 3.1075638930002847), ('quote', 3.067105770111084), ('2.13', 3.064246654510498)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1296 [('exceptions', 4.904470443725586), ('seconds', 4.31365180015564), ('sleep', 4.160487174987793), ('Response', 3.8902507781982423), ('Exception', 3.813521385192871)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1305 [('keywords', 3.628159523010254), ('min', 3.6086825264824762), ('443', 3.5898890495300293), ('Session', 3.513990879058838), ('Contrast', 3.4432084560394287)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9498 [('43', 5.700623035430908), ('bias', 5.6701250076293945), ('493', 3.7735300064086914), ('Popen', 3.4200026988983154), ('0o600', 3.075261354446411)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1306 [('AlexNet', 5.626630783081055), ('timestamp', 4.87970511118571), ('tmp', 4.399013519287109), ('ET', 4.398221969604492), ('gui', 4.231847763061523)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3356 [('engine', 5.431926727294922), ('410', 4.2514894008636475), ('43', 4.0293288230896), ('engines', 3.9667094945907593), ('exceptions', 3.9607648849487305)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9503 [('XML', 3.484097480773926), ('fcntl', 3.3522939682006836), ('termios', 3.2464022636413574), ('clone', 3.1517724990844727), ('os', 3.025555607059906)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9506 [('XML', 4.350664138793945), ('BILINEAR', 4.015069127082825), ('irange', 3.342768430709839), ('bias', 3.2573819160461426), ('softmax', 3.2124005556106567)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3363 [('join', 3.1098820169766745), ('confidence', 3.0890685319900513), ('units', 2.86094339688619), ('429', 2.7904202938079834), ('rotate', 2.651628613471985)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1316 [('Color', 5.966030120849609), ('borders', 4.893345355987549), ('enhance', 4.7828569412231445), ('suggestions', 4.597529172897339), ('Contrast', 4.540584087371826)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1318 [('label', 5.106916427612305), ('sprint', 4.297024726867676), ('shuffle', 4.069783687591553), ('force', 3.8867080211639404), ('unicode', 3.810795307159424)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7465 [('stdout', 4.057708740234375), ('stdin', 3.5596325397491455), ('expand', 3.4566404819488525), ('loads', 3.1855086386203766), ('expanduser', 3.178961753845215)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1324 [('days', 5.248577117919922), ('contiguous', 4.803428649902344), ('Contrast', 4.31503438949585), ('saturation', 4.042814910411835), ('mul', 3.9833273887634277)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1325 [('enhance', 6.149415493011475), ('RED', 5.385804176330566), ('im', 4.761606216430664), ('cat', 4.674053192138672), ('target', 4.2200837930043535)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1327 [('themes', 5.224466707971361), ('letters', 5.098464250564575), ('streams', 4.747942090034485), ('theme', 4.73288631439209), ('reshape', 3.962172746658325)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5431 [('target', 3.5139737129211426), ('output_dir', 2.9631698162524733), ('34', 2.953138589859009), ('36', 2.873588037490845), ('unicode', 2.8277244567871094)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1340 [('borders', 4.666254997253418), ('mult', 3.874130368232727), ('oh', 3.8562214374542236), ('encoding', 3.559910694758097), ('cost', 3.198207139968872)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5439 [('div', 3.720154047012329), ('ET', 3.4992921352386475), ('o', 3.215439575059073), ('keywords', 3.2058191299438477), ('len', 3.1850956732576545)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1344 [('RED', 5.236987113952637), ('shuffle', 4.698523044586182), ('550', 4.650778770446777), ('gamma', 4.352485179901123), ('420', 4.342128753662109)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1348 [('pred', 4.686147749423981), ('escape', 4.18846869468689), ('contrast', 3.9747026562690735), ('predicted', 3.8779186010360718), ('301', 3.7905311584472656)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9542 [('264', 7.8794121742248535), ('TIOCGWINSZ', 6.638499736785889), ('MAX_WBITS', 6.345999717712402), ('32768', 5.606558799743652), ('22050', 4.8372500469518265)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1351 [('squeeze', 4.406718730926514), ('800', 4.111004829406738), ('1000', 4.082687497138977), ('math', 3.6219387451807656), ('angle', 3.5934929847717285)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3420 [('language', 4.347784110477993), ('Response', 3.34534273147583), ('tuple', 3.2234952449798584), ('final', 3.0847489568922253), ('upper', 3.06847882270813)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1372 [('await', 4.234583182467355), ('uniform', 4.091860662807118), ('84', 3.7296228408813477), ('tw', 3.560514450073242), ('120', 3.53271222114563)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1373 [('tar', 4.932461977005005), ('ele', 4.843566417694092), ('404', 4.178012847900391), ('mul', 4.144986152648926), ('pow', 4.129353046417236)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5469 [('render', 5.664295077323914), ('strip', 3.965163747469584), ('314', 3.9262962341308594), ('terminated', 3.8781163692474365), ('Image', 3.6483020782470703)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3426 [('StopIteration', 3.661940097808838), ('pow', 3.3233025074005127), ("'Done.'", 3.296272039413452), ("'Done!'", 3.2373669147491455), ('GoogLeNet', 3.1825095415115356)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3427 [('111', 4.553111553192139), ('over', 4.374730587005615), ('append', 4.133105074487081), ('exp', 4.130746364593506), ('close', 3.734466314315796)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1389 [('stride', 6.3204085032145185), ('padding', 4.414649629592896), ('ratio', 4.309828622000558), ('uniform', 4.109262011267922), ('pretrained', 3.862479329109192)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5491 [('bias', 3.640678882598877), ('stride', 3.4481188456217446), ('109', 2.7119641304016113), ('131', 2.6160409450531006), ('85', 2.5738775730133057)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1404 [('RED', 4.817017078399658), ('ele', 4.44766902923584), ('perspective', 4.4196696281433105), ('info', 3.9170051217079163), ('debug', 3.8703715801239014)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1406 [('accuracy', 4.409420013427734), ('themes', 4.073297096623315), ('escape', 3.979713797569275), ('opt', 3.7051841020584106), ('float', 3.407749686922346)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7560 [('sort', 5.036989688873291), ('dumps', 4.6724317868550616), ('join', 4.438679198424022), ('lower', 4.393996477127075), ('error', 4.1318745613098145)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1424 [('sprint', 4.797641754150391), ('brightness', 4.442782461643219), ('zip', 4.172771692276001), ('dir', 3.8890243768692017), ('tar', 3.651304841041565)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1429 [('view', 3.768761157989502), ('confidence', 3.5229551792144775), ('29', 3.469452738761902), ('activation', 3.333487073580424), ('9', 3.2785558223724367)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1430 [('activation', 5.462794780731201), ('attempt', 4.141517162322998), ('over', 3.6523845195770264), ('answer', 3.5727522373199463), ('Color', 3.2583253383636475)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9630 [('ET', 5.770781993865967), ('render', 3.916795551776886), ("'.'", 3.6595004180382036), ('pretrained', 3.323431074619293), ("'Access-Control-Allow-Methods'", 3.2341599464416504)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9634 [('Contrast', 4.4981513023376465), ('99.73', 4.242796897888184), ('Color', 3.8190064430236816), ('ET', 3.5148277282714844), ("'thursday'", 3.50614070892334)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1449 [('enhance', 3.585606336593628), ('width', 3.359686154585618), ('saturation', 3.359657049179077), ('443', 3.3538124561309814), ('request', 2.8749797849944145)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7595 [('Iterable', 3.6470656394958496), ('append', 3.256684809196286), ("'%Y-%m-%dT%H:%M:%SZ'", 3.1589860916137695), ('println', 3.0558650493621826), ('0.03', 3.0531058311462402)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1452 [('Contrast', 6.440559387207031), ('contrast', 4.998120427131653), ('enhance', 4.418824672698975), ('confidence', 4.294424772262573), ('84', 4.166994333267212)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9648 [('ioctl', 5.443546295166016), ("'TurnContext'", 5.350545167922974), ('keepdims', 4.541674613952637), ('43', 4.454748153686523), ('Iterable', 3.962559223175049)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7601 [('2.13', 3.200864315032959), ('120000', 3.1210789680480957), ('moves', 2.9499430656433105), ('time', 2.751347382863363), ('byte', 2.5887081623077393)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1458 [('println', 6.0968337059021), ('mul', 5.415200710296631), ('mult', 5.241415739059448), ('tmp', 4.892337322235107), ('streams', 4.607982873916626)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1460 [('201', 4.481364011764526), ('tmp', 4.281119346618652), ('div', 3.6629748344421387), ('23', 3.5313665866851807), ('strip', 3.419682741165161)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1464 [('stride', 5.850171248118083), ('std', 4.991879343986511), ('barrier', 4.45164680480957), ('224', 3.7218422889709473), ('perspective', 3.7056655883789062)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5562 [('arg', 3.500774383544922), ('90', 2.91805100440979), ('246', 2.876971960067749), ('sqrt', 2.872830033302307), ('to', 2.8263871669769287)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1468 [('gui', 5.096477031707764), ('terminated', 4.773427486419678), ('XML', 4.594272136688232), ('console', 4.468372344970703), ('border', 4.438904285430908)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5565 [('colors', 3.0651065707206726), ('makedirs', 3.046036958694458), ('Contrast', 3.0419564247131348), ('264', 2.9361956119537354), ('ImageOps', 2.933473587036133)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1472 [('saturation', 5.38281786441803), ('letters', 4.9699201583862305), ('remove', 4.464312553405762), ('themes', 4.264758070309957), ('expand', 4.2543328404426575)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7617 [('140', 3.7441437244415283), ('160', 3.5819194316864014), ('Optional', 3.495072364807129), ('image_ext', 3.3052103519439697), ('tuple', 3.2770063877105713)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1476 [('XML', 4.357006549835205), ('borders', 3.8982605934143066), ('quality', 3.8137118816375732), ('border', 3.735397219657898), ('transform', 3.697232961654663)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9668 [('264', 5.1025776863098145), ('Number', 4.051231940587361), ('22050', 3.8886372654937036), ("'thursday'", 3.6112310886383057), ('unicode', 3.533612012863159)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7622 [('prefix', 3.800851662953695), ('65536', 3.6779532432556152), ('262', 3.4935519695281982), ('F', 3.3366360664367676), ('pattern', 3.335614633560181)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1484 [('saturation', 7.616442322731018), ('240', 5.005478541056315), ('channels', 4.870542049407959), ('palette', 4.666956265767415), ('preferred', 4.634279191493988)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5581 [('301', 3.9415953159332275), ('443', 3.719575881958008), ('join', 3.686782810423109), ('502', 3.393994152545929), ('314', 3.3818166255950928)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1487 [('eq', 5.17340612411499), ('144', 4.794209957122803), ('84', 4.769446849822998), ('264', 4.531163215637207), ('math', 4.393723328908284)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7647 [('json', 3.7219919860363007), ('all', 3.321871280670166), ('git', 2.870220422744751), ('dumps', 2.866048733393351), ('":en"', 2.7213199138641357)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5601 [('quality', 3.5043939352035522), ('over', 3.225703239440918), ('termios', 3.1694860458374023), ('now', 3.151733875274658), ('exceptions', 2.919588804244995)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9698 [('XML', 4.559098243713379), ('pow', 4.059513092041016), ('43', 3.9340717792510986), ('copy', 3.1619730949401856), ('sprint', 3.1480209827423096)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1505 [('contiguous', 4.429952621459961), ('narrow', 4.165349245071411), ('fid', 3.448581278324127), ('tw', 3.438898026943207), ('224', 3.4341790676116943)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1518 [('dumps', 5.048697312672933), ('fallback', 4.308616638183594), ('sprint', 4.290770053863525), ('443', 4.111558437347412), ('512', 3.994702135644308)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3570 [('str', 4.405417382717133), ('sum', 3.394241762161255), ('unicode', 3.201904296875), ('int', 3.1105026840232313), ('log', 3.0438498973846437)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1529 [('RED', 5.890029430389404), ('hue', 4.993268132209778), ('ele', 4.914737224578857), ('eq', 4.858244895935059), ('math', 4.684821565945943)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1531 [('torch', 6.094227597520158), ('streams', 5.058236002922058), ('timeout', 4.498530308405559), ('410', 4.005138158798218), ('stride', 3.848426183064779)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1533 [('render', 4.913921356201172), ('trie', 4.398970635732015), ('squeeze', 4.243852615356445), ('padding', 4.206690804163615), ('engines', 4.178791046142578)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5637 [('key', 4.077311873435974), ('encode', 3.3479607105255127), ('207', 3.3047850131988525), ('child', 3.250917077064514), ('engine', 3.1088616847991943)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1555 [('conf', 3.6677762866020203), ('saturation', 3.6263529658317566), ('message', 3.281183195114136), ('random', 3.2649632170796394), ('key', 3.2563289403915405)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7700 [('85', 2.5363073348999023), ('10000000', 2.3725593090057373), ('dim', 2.3663079738616943), ('colors', 2.306120365858078), ('numbers', 2.2922170956929526)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3609 [('engines', 3.4543256759643555), ('uniform', 3.2310608300295742), ('border', 3.209527850151062), ('min', 3.144361204571194), ('Contrast', 2.9312617778778076)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1561 [('timeout', 4.36778998374939), ('enhance', 4.295462131500244), ('enhancer', 3.918094515800476), ('dir', 3.904934883117676), ('finally', 3.8624709844589233)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1568 [('131', 4.536532402038574), ('skill', 4.5245537757873535), ('tar', 4.430926084518433), ('contiguous', 4.393560409545898), ('close', 4.321004390716553)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3628 [('contiguous', 5.22001838684082), ('request', 5.107352531317509), ('json', 4.361323982477188), ('saturation', 4.3538400530815125), ('Request', 4.297598123550415)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3629 [('enhance', 3.780616044998169), ('sub', 3.7359390258789062), ('div', 3.7356367111206055), ('40', 3.6939666271209717), ('target', 3.468902111053467)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7727 [('404', 3.9191629886627197), ('2.13', 3.1763088703155518), ("'5'", 3.1581926345825195), ("'ScheduleComponent'", 2.8979103565216064), ('form', 2.881703906589084)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9789 [('ET', 6.853382110595703), ('np', 4.182200313187563), ('192', 3.7772581577301025), ('struct', 3.525712490081787), ('error', 3.4903862476348877)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1604 [('144', 4.702877044677734), ('channels', 4.031909465789795), ('410', 3.5935000578562417), ('categories', 3.5830740928649902), ('140', 3.4358248710632324)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5714 [('all', 3.72737455368042), ('force', 3.617686152458191), ('days', 3.5932412147521973), ('accuracy', 3.5095067024230957), ("'Year'", 3.1132149696350098)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7772 [('tw', 3.2753304839134216), ('size', 3.1488481836754882), ('add_cookie_header', 3.1335580348968506), ('"sentence_tagging_and_padding_preprocessor"', 3.1245875358581543), ('600', 3.047354817390442)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1629 [('render', 5.738396525382996), ('429', 4.348830223083496), ('Image', 4.328274502473719), ('sys', 4.215290164947509), ('override', 4.045682764053344)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1646 [('bias', 4.7580389976501465), ('tw', 3.5461299419403076), ('hue', 3.3679744005203247), ('ele', 3.0830955505371094), ('480', 3.0326340198516846)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9838 [('XML', 3.837153434753418), ('43', 3.7999930381774902), ('contiguous', 3.3945090770721436), ('ioctl', 3.2505288124084473), ("'Upgrade'", 3.226942300796509)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9845 [('XML', 4.300364971160889), ('43', 3.9406590461730957), ('bias', 3.692861795425415), ('Dense', 3.659783935546875), ('ET', 3.45223069190979)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1659 [('borders', 4.509048938751221), ('enhance', 4.295750617980957), ('perspective', 4.03074836730957), ('bias', 3.198800563812256), ('conf', 3.090217888355255)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1661 [('443', 5.394681453704834), ('sqrt', 4.503671169281006), ('225', 4.42801570892334), ('items', 4.411948204040527), ('tw', 4.3973387479782104)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1663 [('85', 4.313436985015869), ('tr', 3.9816436767578125), ('fid', 3.8009681701660156), ('contiguous', 3.6807944774627686), ('degrees', 3.3595983187357583)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1682 [('shuffle', 4.074071407318115), ('clone', 4.009963512420654), ('gamma', 3.802339474360148), ('pop', 3.757893721262614), ('system', 3.703526020050049)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1688 [('301', 4.52116060256958), ('XML', 4.1384992599487305), ('fid', 3.898616313934326), ('suffix', 3.809283494949341), ('pow', 3.624049425125122)]
Top words for pretrained_codeGPTPyAdapted neuron indx 7840 [('480', 3.6049716472625732), ('dir', 3.0814297795295715), ('410', 3.052780866622925), ("'std'", 2.9623773097991943), ('sub_', 2.9127519130706787)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3756 [('Contrast', 3.2172293663024902), ('192', 2.8926377296447754), ('enhance', 2.8743069171905518), ('lower', 2.7592416604359946), ('predicted', 2.6705673038959503)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9900 [('43', 5.593180179595947), ('RED', 4.702282428741455), ('Brightness', 4.1821489334106445), ("'TurnContext'", 3.724364399909973), ('Number', 3.6484062671661377)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3760 [('join', 3.637453979916043), ('stride', 3.5366870562235513), ('round', 3.3449941635131837), ('open', 3.317212963104248), ('os', 3.2979337614158104)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1718 [('conf', 4.323959052562714), ('Contrast', 4.220558166503906), ('sub', 3.5712027549743652), ('contrast', 3.453914999961853), ('re', 3.351838082075119)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5827 [('find', 4.010932445526123), ('stdout', 3.785046339035034), ('degrees', 3.6361443201700845), ('id', 3.5971952080726624), ('90', 3.584318995475769)]
Top words for pretrained_codeGPTPyAdapted neuron indx 9925 [('"cl"', 3.1047348976135254), ('"size"', 2.9935343265533447), ('"windows"', 2.9651010036468506), ('"city"', 2.9025845527648926), ('"linux"', 2.860215187072754)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1741 [('301', 4.307018756866455), ('502', 3.8626596927642822), ('365', 3.8050003051757812), ('302', 3.694650888442993), ('420', 3.6237194538116455)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1750 [('div', 5.880115032196045), ('sub', 5.552900314331055), ('bias', 5.066235065460205), ('basename', 4.5137529373168945), ('stride', 4.1928604443868)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1788 [('accuracy', 4.699475288391113), ('cat', 4.530450344085693), ('RESET', 3.745016574859619), ('torch', 3.657263246742455), ('bias', 3.5545742511749268)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1794 [('parse', 4.5309789180755615), ('443', 4.448033332824707), ('shuffle', 4.287271022796631), ('2048', 4.142378187179565), ('country', 3.841884136199951)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1813 [('gamma', 4.010777950286865), ('quality', 3.979105830192566), ('match', 3.5475619847957907), ('ratio', 3.350823538643973), ('matchall', 3.31408429145813)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1815 [('quality', 4.372958660125732), ('ele', 3.549723505973816), ('git', 3.493549346923828), ('crop', 3.459525853395462), ('rotate', 3.40740704536438)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5912 [('keywords', 3.9411232471466064), ('splits', 3.5996930599212646), ('246', 3.4117257595062256), ('175', 3.1366260051727295), ('encoding', 3.128023544947306)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5913 [('clamp_', 2.860212206840515), ('convert', 2.8506827354431152), ('name', 2.7554145199911937), ('uniform', 2.657931913029064), ('1e-6', 2.6306289434432983)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1818 [('println', 4.608545780181885), ('plugins', 4.066142717997233), ('sys', 4.003068733215332), ('os', 3.6730138556710603), ('720', 3.6276535987854004)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1820 [('engine', 5.410846710205078), ('exceptions', 4.605585098266602), ('410', 4.190961917241414), ('merge', 3.988400660242353), ('43', 3.915908098220825)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1826 [('quote', 5.111466407775879), ('range', 4.369149923324585), ('escape', 3.8440088033676147), ('ratio', 3.593506165913173), ('themes', 3.5157830019791922)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1828 [('stride', 3.753427823384603), ("''", 3.353404772174251), ('padding', 3.275417105356852), ('258', 3.1822450160980225), ('""', 3.11014158460829)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1833 [('narrow', 3.989811658859253), ('quote', 3.6194827556610107), ('443', 3.0167088508605957), ('pad', 2.9863452911376953), ('endpoint', 2.7987707257270813)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1861 [('XML', 4.169563293457031), ('29', 4.061950922012329), ('palette', 3.828197399775187), ('enhancer', 3.716052015622457), ('109', 3.549018383026123)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1874 [('communicate', 3.94881010055542), ('384', 3.7145094871520996), ('tile', 3.475555658340454), ('torch', 3.353679507165342), ('144', 3.1050240993499756)]
Top words for pretrained_codeGPTPyAdapted neuron indx 5977 [('numpy', 3.8588939905166626), ('getheader', 3.7397056420644126), ('1.1', 3.606832981109619), ('parse_qs', 3.4415831565856934), ('StopIteration', 3.412975549697876)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3930 [('answer', 4.585236549377441), ('Number', 4.509276231129964), ('std', 4.289429932832718), ('conf', 4.07343652844429), ('8080', 3.612765073776245)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3932 [('720', 3.7184932231903076), ('tw', 3.2706597447395325), ('size', 2.921267666923466), ('cost', 2.9114731550216675), ('exit', 2.902930498123169)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3933 [('render', 6.014772653579712), ('Image', 4.291928024852977), ('strip', 3.714424649874369), ('any', 3.409080982208252), ('shape', 3.2772683620452883)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8052 [("'127.0.0.1'", 3.157106637954712), ('debug', 2.930753707885742), ('365', 2.487513542175293), ('attempt', 2.4489452838897705), ('join', 2.3861794239944882)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1915 [('sqrt', 4.135040283203125), ('DenseNet', 3.5157835483551025), ('update', 3.4249093532562256), ("'videos'", 3.4131531715393066), ('render', 3.384739577770233)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1924 [('stride', 4.393532594045003), ('43', 4.392467498779297), ('84', 3.6565557956695556), ('quote', 3.6388421058654785), ('content', 3.409391204516093)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1925 [('180', 4.534677445888519), ('contrast', 4.1009840965271), ('pop', 3.941446383794149), ('colors', 3.644786536693573), ('save', 3.368606948852539)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6024 [('sort', 5.1409759521484375), ('dumps', 5.13991133371989), ('error', 4.672638416290283), ('zip', 4.644992748896281), ('squeeze', 4.568603992462158)]
Top words for pretrained_codeGPTPyAdapted neuron indx 3992 [('XML', 3.5569369792938232), ('suffix', 3.540971040725708), ('bias', 3.533426284790039), ('fid', 3.450390577316284), ('301', 3.3118772506713867)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6043 [('225', 3.847829818725586), ('255.', 3.490118980407715), ('440.0', 3.397803624471029), ('engine', 3.3799514770507812), ('d', 3.327583085922968)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1962 [('corrections', 4.916568597157796), ('preferences', 4.5360391219456995), ('preferred', 4.456792235374451), ('extend', 4.192166328430176), ('140', 4.1044535636901855)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6060 [('192', 3.968707323074341), ('224', 3.7577931880950928), ('over', 2.9517476558685303), ('"vz"', 2.857070525487264), ('"vlat"', 2.746936321258545)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8109 [('22', 3.9674049615859985), ('23', 3.6080446243286133), ('h', 3.3216036336762564), ('36', 3.1720235109329225), ('upper', 3.1249377727508545)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4012 [('504', 4.021667957305908), ('json', 3.391307532787323), ('headers', 3.3315438357266514), ('attempt', 3.269517421722412), ('convert', 3.2405481815338133)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1967 [('force', 4.231234073638916), ('111', 4.100337505340576), ('enhance', 4.000323295593262), ('render', 3.9479376673698425), ('replace', 3.7901487350463867)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6065 [('moves', 3.45316481590271), ('131', 3.0356860160827637), ('mode', 2.890956989041081), ('2.13', 2.8864951133728027), ('time', 2.798342784245809)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1974 [('262', 4.698702812194824), ('264', 4.470418453216553), ('perspective', 4.340051651000977), ('expanded', 4.277419487635295), ('println', 4.203131198883057)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6077 [('flush', 4.843623876571655), ('504', 4.076172351837158), ('contiguous', 3.861766815185547), ('units', 3.2836174170176187), ('720', 3.225886583328247)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1981 [('Sequence', 4.14100456237793), ('260', 4.057190418243408), ('crop', 3.797477573156357), ('saturation', 3.5146543383598328), ('perspective', 3.3588898181915283)]
Top words for pretrained_codeGPTPyAdapted neuron indx 1998 [('720', 3.8003931045532227), ('barrier', 3.7331132888793945), ('words', 3.570202112197876), ('stride', 3.4997955163319907), ('items', 3.4777510166168213)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2019 [('429', 4.422693252563477), ('dir', 4.0330135226249695), ('144', 3.9602267742156982), ('480', 3.932239532470703), ('257', 3.6479928493499756)]
Top words for pretrained_codeGPTPyAdapted neuron indx 6126 [('ByteStorage', 3.3723223209381104), ('"horizontal"', 3.334339141845703), ('read', 3.2496378819147744), ('dstack', 3.135225534439087), ('ceil', 2.9566242694854736)]
Top words for pretrained_codeGPTPyAdapted neuron indx 8175 [('5.5', 3.9425264596939087), ('22', 3.923448085784912), ('120', 3.6017649173736572), ('2.5', 3.540235996246338), ('20.6', 3.2689077854156494)]
Top words for pretrained_codeGPTPyAdapted neuron indx 2039 [('AlexNet', 3.8310647010803223), ('Color', 3.7632346153259277), ('plugins', 3.7286782264709473), ('sleep', 3.581691026687622), ('filter', 3.364474296569824)]
Top words for pretrained_codeGPTPyAdapted neuron indx 4093 [('Tensor', 4.41681702931722), ('copy', 4.331684398651123), ('set', 3.9140051364898683), ('scale', 3.4874297210148404), ('copy_', 3.4267570972442627)]
Creating control dataset for pretrained_codeGPTPyAdapted POS tagging task

pretrained_codeGPTPyAdapted_control_task Selectivity (Diff. between true task and probing task performance):  0.7349315068493151
~~~~~~~~~~~~~~~~~~~~~~~Summary~~~~~~~~~~~~~~~~~~~~~~~
Experimental results for pretrained_codeGPTPyAdapted:
Baseline score (probing using all neurons, 768 each, of all layers 13) :{'__OVERALL__': 0.9657534246575342, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.8657534246575342}

The accuracy when only using the intercept:{'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}

Independent layerwise probing:
Layer 0:{'__OVERALL__': 0.8164383561643835, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9753424657534246, 'KEYWORD': 0.29041095890410956}
Layer 1:{'__OVERALL__': 0.8924657534246575, 'NAME': 0.6931506849315069, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.8876712328767123}
Layer 2:{'__OVERALL__': 0.9164383561643835, 'NAME': 0.6821917808219178, 'STRING': 1.0, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.9972602739726028}
Layer 3:{'__OVERALL__': 0.9308219178082192, 'NAME': 0.9945205479452055, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.7342465753424657}
Layer 4:{'__OVERALL__': 0.9068493150684932, 'NAME': 0.7643835616438356, 'STRING': 1.0, 'NUMBER': 0.9698630136986301, 'KEYWORD': 0.8931506849315068}
Layer 5:{'__OVERALL__': 0.9582191780821918, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.8493150684931506}
Layer 6:{'__OVERALL__': 0.9541095890410959, 'NAME': 0.9780821917808219, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.8410958904109589}
Layer 7:{'__OVERALL__': 0.9609589041095891, 'NAME': 0.9917808219178083, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.8547945205479452}
Layer 8:{'__OVERALL__': 0.9712328767123287, 'NAME': 0.9424657534246575, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9452054794520548}
Layer 9:{'__OVERALL__': 0.9835616438356164, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9506849315068493}
Layer 10:{'__OVERALL__': 0.9938356164383562, 'NAME': 0.9808219178082191, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.9945205479452055}
Layer 11:{'__OVERALL__': 0.9904109589041096, 'NAME': 0.9643835616438357, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.9972602739726028}
Layer 12:{'__OVERALL__': 0.9986301369863013, 'NAME': 0.9972602739726028, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.9972602739726028}

'Incremental-layerwise probing:
Layer [0]:{'__OVERALL__': 0.8178082191780822, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9753424657534246, 'KEYWORD': 0.2958904109589041}
Layer [0, 1]:{'__OVERALL__': 0.8993150684931507, 'NAME': 0.9698630136986301, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.6356164383561644}
Layer [0, 1, 2]:{'__OVERALL__': 0.9267123287671233, 'NAME': 0.9342465753424658, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.7808219178082192}
Layer [0, 1, 2, 3]:{'__OVERALL__': 0.9328767123287671, 'NAME': 0.9068493150684932, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.8328767123287671}
Layer [0, 1, 2, 3, 4]:{'__OVERALL__': 0.913013698630137, 'NAME': 0.9013698630136986, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.7589041095890411}
Layer [0, 1, 2, 3, 4, 5]:{'__OVERALL__': 0.8376712328767123, 'NAME': 0.9780821917808219, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.38082191780821917}
Layer [0, 1, 2, 3, 4, 5, 6]:{'__OVERALL__': 0.8554794520547945, 'NAME': 0.8684931506849315, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.5589041095890411}
Layer [0, 1, 2, 3, 4, 5, 6, 7]:{'__OVERALL__': 0.9356164383561644, 'NAME': 0.7452054794520548, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 1.0}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8]:{'__OVERALL__': 0.939041095890411, 'NAME': 0.9561643835616438, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.8082191780821918}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:{'__OVERALL__': 0.8410958904109589, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.3726027397260274}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:{'__OVERALL__': 0.9472602739726027, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.7972602739726027}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]:{'__OVERALL__': 0.9719178082191781, 'NAME': 0.9698630136986301, 'STRING': 0.9972602739726028, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9232876712328767}
Layer [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]:{'__OVERALL__': 0.9664383561643836, 'NAME': 0.9698630136986301, 'STRING': 1.0, 'NUMBER': 0.9808219178082191, 'KEYWORD': 0.915068493150685}

select minimum layers:(LS+CC+LCA)
Layerwise (LS):To lose 0.03*100% accuracy based on all layers, keep the layers from 0 to 8
The number of neurons to keep is 6912
The accuracy is:{'__OVERALL__': 0.939041095890411, 'NAME': 0.9561643835616438, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.8082191780821918}
Percentage reduction (neurons):0.3076923076923077

Clustering based on the layers above: 0 to 8:
When no clustering:
the probing result is {'__OVERALL__': 0.8335616438356165, 'NAME': 0.9972602739726028, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.3452054794520548}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 39
The accuracy of the minimum neuron set is {'__OVERALL__': 0.8472602739726027, 'NAME': 0.6246575342465753, 'STRING': 0.9863013698630136, 'NUMBER': 0.8986301369863013, 'KEYWORD': 0.8794520547945206}

Clustering threshold:0.3
The number of independent neurons:1820
The number of clusters:6912
The probing result (CC score) is :{'__OVERALL__': 0.9027397260273973, 'NAME': 0.9616438356164384, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6547945205479452}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 99
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9047945205479452, 'NAME': 0.9945205479452055, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6301369863013698}

Layerwise (LS):To lose 0.02*100% accuracy based on all layers, keep the layers from 0 to 10
The number of neurons to keep is 8448
The accuracy is:{'__OVERALL__': 0.9472602739726027, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.7972602739726027}
Percentage reduction (neurons):0.15384615384615385

Clustering based on the layers above: 0 to 10:
When no clustering:
the probing result is {'__OVERALL__': 0.9445205479452055, 'NAME': 0.7780821917808219, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 1.0}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 1497
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9424657534246575, 'NAME': 0.9945205479452055, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.7808219178082192}

Clustering threshold:0.3
The number of independent neurons:2143
The number of clusters:8448
The probing result (CC score) is :{'__OVERALL__': 0.9780821917808219, 'NAME': 0.9506849315068493, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9643835616438357}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 998
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9835616438356164, 'NAME': 0.989041095890411, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.947945205479452}

Layerwise (LS):To lose 0.01*100% accuracy based on all layers, keep the layers from 0 to 11
The number of neurons to keep is 9216
The accuracy is:{'__OVERALL__': 0.9719178082191781, 'NAME': 0.9698630136986301, 'STRING': 0.9972602739726028, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9232876712328767}
Percentage reduction (neurons):0.07692307692307687

Clustering based on the layers above: 0 to 11:
When no clustering:
the probing result is {'__OVERALL__': 0.934931506849315, 'NAME': 0.8821917808219178, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.863013698630137}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 199
The accuracy of the minimum neuron set is {'__OVERALL__': 0.947945205479452, 'NAME': 0.9945205479452055, 'STRING': 1.0, 'NUMBER': 0.9726027397260274, 'KEYWORD': 0.8246575342465754}

Clustering threshold:0.3
The number of independent neurons:2366
The number of clusters:9216
The probing result (CC score) is :{'__OVERALL__': 0.9746575342465753, 'NAME': 0.9205479452054794, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9808219178082191}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 1497
The accuracy of the minimum neuron set is {'__OVERALL__': 0.9842465753424657, 'NAME': 0.9671232876712329, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9726027397260274}

The result of Layerwise (LS):
Keep the layer from 0 to 11
The best layer delta:0.01
The best number of neurons:9216
The best accuracy:0.9719178082191781
The best percentage reduction: 0.07692307692307687

The result of LS+CC+LCA
Keep the layer from 0 to 11
The best performance delta: 0.01,0.01
The best clustering threshold:0.3
The best number of neurons:1497
The best accuracy: 0.9842465753424657
The best neuron percentage reduction: 0.8500600961538461

probe independent neurons based on all layers with clustering (run_cc_all.py)
When no clustering:
The probing result (CC score) is :{'__OVERALL__': 0.9780821917808219, 'NAME': 0.936986301369863, 'STRING': 1.0, 'NUMBER': 1.0, 'KEYWORD': 0.9753424657534246}
Clustering threshold:0.1
The number of independent neurons:5693
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.952054794520548, 'NAME': 0.9178082191780822, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.8931506849315068}
Clustering threshold:0.2
The number of independent neurons:3326
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9732876712328767, 'NAME': 0.9095890410958904, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9863013698630136}
Clustering threshold:0.3
The number of independent neurons:2499
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9767123287671233, 'NAME': 0.9260273972602739, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9835616438356164}
Clustering threshold:0.4
The number of independent neurons:1954
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9794520547945206, 'NAME': 0.936986301369863, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.9835616438356164}
Clustering threshold:0.5
The number of independent neurons:1514
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.923972602739726, 'NAME': 0.9561643835616438, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.7452054794520548}
Clustering threshold:0.6
The number of independent neurons:1128
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9013698630136986, 'NAME': 0.6438356164383562, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9698630136986301}
Clustering threshold:0.7
The number of independent neurons:736
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9458904109589041, 'NAME': 0.8301369863013699, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.9616438356164384}
Clustering threshold:0.8
The number of independent neurons:318
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.9198630136986301, 'NAME': 0.8931506849315068, 'STRING': 1.0, 'NUMBER': 0.947945205479452, 'KEYWORD': 0.8383561643835616}
Clustering threshold:0.9
The number of independent neurons:28
The number of clusters:9984
The probing result (CC score) is :{'__OVERALL__': 0.6458904109589041, 'NAME': 0.5178082191780822, 'STRING': 0.852054794520548, 'NUMBER': 0.7671232876712328, 'KEYWORD': 0.4465753424657534}
The result of CC:
The best clustering threshold is :0.4
The best number of neurons:1954
The best accuracy is: 0.9794520547945206
Percentage reduction (neurons):0.804286858974359

probe independent neurons based on all layers without clustering (run_max_features.py)
The result of LCA:
Based on all layers: from 0 to 12, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is 1996
The performance is {'model_name': 'pretrained_codeGPTPyAdapted', 'best_l1': 0, 'best_l2': 0.01, 'scores': {'__OVERALL__': 0.9493150684931507, 'NAME': 0.9780821917808219, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.821917808219178}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}}
Percentage reduction (neurons):0.8000801282051282

Probeless:
The result of probeless:
Based on all layers, from 0 to 12, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is :99
The performance is :{'model_name': 'pretrained_codeGPTPyAdapted', 'best_l1': 0, 'best_l2': 0.1, 'scores': {'__OVERALL__': 0.9424657534246575, 'NAME': 0.936986301369863, 'STRING': 0.9917808219178083, 'NUMBER': 0.9397260273972603, 'KEYWORD': 0.9013698630136986}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}}
Percentage reduction (neurons):0.9900841346153846
----------------------------------------------------------------
