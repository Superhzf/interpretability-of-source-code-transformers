Getting activations from json files. If you need to extract them, run with --extract=True 

Anayzing pretrained_CodeBERTa
Loading json activations from ./activations/codeberta_activations_train.json...
54291 7.0
Skipping line:  2668
A: 2, S: 3, T: 3
Deleting line 2668: 2 activations, 3 source, 3 target
Number of tokens:  507518
length of source dictionary:  28818
length of target dictionary:  49
507518
Total instances: 507518
['now_ev_dep', 'month_abbr', 'conversion_rate', 'add_phi', "'date,organization,'", 'convert_persistent_value', "'5_utr_end'", 'parse_aggregate_report_xml', "'person_data'", '"{}_{}_dep"', 'stine_l', 'f_in', "'/api'", 'order_array', 'next_sibling', '"title|timestamp|ids"', 'decode', 'cpu_warnings', '"subscribe"', 'CopySource']
Number of samples:  507518
Stats: Labels with their frequencies in the final set
NAME 175779
KEYWORD 38836
LPAR 37541
RPAR 36846
DOT 35570
COMMA 33435
EQUAL 30541
COLON 19840
STRING 17115
DEDENT 16600
LSQB 14740
RSQB 14613
INDENT 11963
NUMBER 10471
PLUS 1939
EQEQUAL 1830
STAR 1500
MINUS 1458
LBRACE 1070
RBRACE 845
DOUBLESTAR 844
SLASH 630
PERCENT 577
PLUSEQUAL 501
GREATER 456
NOTEQUAL 429
LESS 332
RARROW 330
GREATEREQUAL 175
LESSEQUAL 133
AMPER 94
DOUBLESLASH 94
MINEQUAL 58
ELLIPSIS 55
COMMENT 37
VBAR 35
AT 29
STAREQUAL 27
RIGHTSHIFT 25
LEFTSHIFT 25
SLASHEQUAL 24
VBAREQUAL 23
TILDE 23
CIRCUMFLEX 22
AMPEREQUAL 2
DOUBLESLASHEQUAL 2
RIGHTSHIFTEQUAL 2
ENCODING 1
DOUBLESTAREQUAL 1
pretrained_CodeBERTa distribution after trauncating:
{0: 0.7257567062068282, 3: 0.16034615876895636, 1: 0.07066444812366587, 2: 0.043232686900549544}
{0: 175779, 3: 38836, 1: 17115, 2: 10471}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codeberta_activations_valid.json...
33619 7.0
Number of tokens:  308882
length of source dictionary:  19446
length of target dictionary:  46
308882
Total instances: 308882
['subports', 'update_checklist', 'plot_data', 'key_fn', 'sheets', "r'(?P<eol>$)?'", '"MD5:"', '40', 'get_web_server', 'Udiff', 'f_get_leaves', 'min_samp', 'ascontiguousarray', 'message_factory', 'ipf_max_peptidoform_pep', "'ADMINS'", "'5_utr_end'", "'yrs'", 'PARITY_NONE', '_links_by_source']
Number of samples:  308882
Stats: Labels with their frequencies in the final set
NAME 106508
DOT 23234
KEYWORD 22857
LPAR 22119
RPAR 21487
COMMA 21037
EQUAL 18195
STRING 12883
COLON 12504
DEDENT 10176
LSQB 8421
RSQB 8348
INDENT 7080
NUMBER 5227
EQEQUAL 1207
PLUS 1136
LBRACE 1077
STAR 963
RBRACE 913
MINUS 741
DOUBLESTAR 555
SLASH 393
PLUSEQUAL 323
GREATER 292
NOTEQUAL 240
PERCENT 222
RARROW 214
LESS 200
GREATEREQUAL 82
LESSEQUAL 47
AT 33
AMPER 29
DOUBLESLASH 27
MINEQUAL 27
VBAR 23
COMMENT 13
ELLIPSIS 13
STAREQUAL 10
LEFTSHIFT 7
TILDE 7
RIGHTSHIFT 4
SLASHEQUAL 3
CIRCUMFLEX 2
ENCODING 1
DOUBLESLASHEQUAL 1
AMPEREQUAL 1
pretrained_CodeBERTa distribution after trauncating:
{0: 0.7222105441600272, 3: 0.1549889811832514, 1: 0.08735717918291236, 2: 0.035443295473809124}
{0: 106508, 3: 22857, 1: 12883, 2: 5227}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
Loading json activations from ./activations/codeberta_activations_test.json...
32570 7.0
Number of tokens:  302448
length of source dictionary:  18380
length of target dictionary:  49
302448
Total instances: 302448
['dim_ordering', 'a_id', 'get_string', 'newModels', 'dividend_sign', '"logPathInput"', '"bestPosition"', '40', 'experiences', 'storage_broker', 'anomalyVector', 'errScores', 'notification_output', 'new_namespace', "'yrs'", '"mpii_human_pose_v1_u12_1.mat"', '"float32"', "'imdb'", 'shifter', 'refIndex']
Number of samples:  302448
Stats: Labels with their frequencies in the final set
NAME 106943
DOT 23125
LPAR 23019
RPAR 22645
KEYWORD 21773
COMMA 19472
EQUAL 18096
COLON 11225
DEDENT 9778
STRING 8156
LSQB 7717
RSQB 7682
NUMBER 7295
INDENT 6823
EQEQUAL 1344
MINUS 1259
PLUS 1013
STAR 863
LBRACE 527
PLUSEQUAL 448
RBRACE 436
GREATER 417
PERCENT 341
NOTEQUAL 341
SLASH 323
DOUBLESTAR 284
LESS 247
GREATEREQUAL 216
LESSEQUAL 107
AMPER 100
RIGHTSHIFT 61
LEFTSHIFT 53
MINEQUAL 48
DOUBLESLASH 48
RARROW 41
VBAR 38
ELLIPSIS 28
COMMENT 19
AT 17
CIRCUMFLEX 17
STAREQUAL 15
SLASHEQUAL 15
VBAREQUAL 12
TILDE 7
SEMI 6
PERCENTEQUAL 5
ENCODING 1
DOUBLESTAREQUAL 1
AMPEREQUAL 1
pretrained_CodeBERTa distribution after trauncating:
{0: 0.7417994409261481, 3: 0.1510262404017563, 1: 0.05657327959935353, 2: 0.05060103907274203}
{0: 106943, 3: 21773, 1: 8156, 2: 7295}
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
label:3, the number of unique tokens:33
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:21572
label:1, the number of unique tokens:6803
label:2, the number of unique tokens:331
The unique labels are:['.00001', '.01', '.05', '.1', '.2', '.3', '.5', '.9', '.95', '0', '0.', '0.0', '0.00002', '0.0001', '0.001', '0.002', '0.005', '0.01', '0.01683697', '0.02', '0.025', '0.03', '0.05', '0.07', '0.1', '0.15', '0.2', '0.20', '0.22', '0.25', '0.3', '0.33', '0.4', '0.400', '0.5', '0.50922', '0.53', '0.7', '0.75', '0.8', '0.80', '0.85', '0.9', '0.95', '0.98', '0.99', '0j', '0o600', '0o644', '0o777', '0x00', '0x08', '0x0B', '0x1', '0x147A', '0x1F', '0x7F', '0x80', '0x8000', '0x84', '0x86', '0x88', '0x89', '0x9F', '0xAC00', '0xFF', '0xFFFF', '0xff', '1', '1.', '1.0', '1.05', '1.08', '1.0e-7', '1.1', '1.10', '1.2', '1.25', '1.3', '1.4', '1.406211e-6', '1.5', '1.J', '1.j', '10', '10.0', '100', '100.', '100.0', '1000', '1000.0', '10000', '1000000', '10000000', '1000000000.0', '100000000000', '101', '101677777', '1023', '1024', '1024.0', '107.7', '109', '10e10', '11', '11025', '11025.0', '111', '113', '12', '12.', '12.0', '120', '120.0', '120000', '12200', '127', '128', '13', '131', '14', '140', '144', '15', '150', '150.0', '152.0', '16', '160', '17', '175', '18', '180', '19', '19.4712', '192', '192.85', '192.85948', '1E-12', '1E-9', '1E3', '1e-09', '1e-10', '1e-12', '1e-2', '1e-3', '1e-4', '1e-5', '1e-6', '1e-9', '1e6', '1j', '2', '2.', '2.0', '2.13', '2.371512e-11', '2.5', '20', '20.0', '20.6', '200', '200.0', '2000', '20000', '200000', '20051', '20060', '20061', '201', '202', '204', '2048', '207', '21', '2147483647', '22', '22.5', '22050', '224', '225', '23', '24', '240', '242854337', '246', '25', '25.0', '250', '25000', '255', '255.', '255.0', '256', '257', '258', '259', '2595.0', '26', '260', '262', '264', '27', '27.12', '27.12825', '270', '27017', '28', '29', '3', '3.', '3.0', '30', '300', '301', '302', '306674912', '307', '31', '314', '32', '32.0', '32.93192', '320.0', '32768', '33', '34', '34736', '34737', '35', '35163', '36', '360', '3600', '365', '37', '38', '384', '39', '4', '4.', '4.0', '4.2', '4.74057', '40', '40.0', '40.11453', '400', '4000.0', '40000', '401', '403', '404', '4096', '41', '410', '42', '420', '4200000', '429', '43', '440.0', '4410', '443', '45', '48', '480', '493', '5', '5.0', '5.5', '50', '50.', '500', '5000', '50000', '502', '503', '504', '512', '52', '55', '550', '55296', '56', '57344', '59', '5e4', '6', '6.', '6.0', '6.5', '60', '60.0', '600', '6000000', '63', '6367', '6379', '64', '650', '65535.0', '65536', '67', '7', '7.', '70', '700.0', '720', '737.9', '75', '77', '8', '8.0', '80', '80.0', '800', '8080', '84', '85', '86400', '882', '8E3', '9', '90', '96', '98', '99', '99.73', '993', '999999.0']
label:3, the number of unique tokens:32
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:13665
label:2, the number of unique tokens:610
The unique labels are:['.02', '.025', '.05', '.8', '.95', '0', '0.', '0.0', '0.000', '0.001', '0.009', '0.01', '0.012', '0.02', '0.025', '0.027', '0.03', '0.032', '0.0349', '0.04', '0.0471', '0.05', '0.075', '0.08', '0.082', '0.0975', '0.1', '0.1125', '0.115', '0.125', '0.15', '0.167', '0.2', '0.206', '0.22', '0.232', '0.25', '0.250', '0.298', '0.3', '0.33', '0.333', '0.35', '0.4', '0.404', '0.435', '0.45', '0.5', '0.500', '0.509', '0.598', '0.6', '0.627', '0.667', '0.685', '0.7', '0.700', '0.73', '0.75', '0.772', '0.794', '0.8', '0.855', '0.9', '0.912', '0.93', '0.948', '0.968', '0.983', '0.997', '0x0000', '0x0140', '0x0280', '0x03c0', '0x0440', '0x0500', '0x06c0', '0x0780', '0x0880', '0x09c0', '0x0F0F', '0x0a00', '0x0b40', '0x0cc0', '0x0d80', '0x0e40', '0x0f00', '0x1040', '0x1100', '0x12c0', '0x1380', '0x1400', '0x1540', '0x1680', '0x17c0', '0x18c0', '0x1980', '0x1a40', '0x1b00', '0x1c80', '0x1dc0', '0x1e00', '0x1f40', '0x2080', '0x21c0', '0x2200', '0x2340', '0x24c0', '0x2580', '0x2640', '0x2700', '0x2800', '0x2940', '0x2a80', '0x2bc0', '0x2c40', '0x2d00', '0x2ec0', '0x2f80', '0x3030303', '0x30c0', '0x3180', '0x3240', '0x3300', '0x3480', '0x35c0', '0x3600', '0x3740', '0x3840', '0x3900', '0x3ac0', '0x3b80', '0x3c00', '0x3d40', '0x3e80', '0x3fc0', '0x4040', '0x4100', '0x42c0', '0x4380', '0x4400', '0x4540', '0x4680', '0x47c0', '0x48c0', '0x4980', '0x4a40', '0x4b00', '0x4c80', '0x4dc0', '0x4e00', '0x4f40', '0x5000', '0x5140', '0x5280', '0x53c0', '0x5440', '0x5500', '0x56c0', '0x5780', '0x5880', '0x59c0', '0x5a00', '0x5b40', '0x5cc0', '0x5d80', '0x5e40', '0x5f00', '0x60c0', '0x6180', '0x6240', '0x6300', '0x6480', '0x65c0', '0x6600', '0x6740', '0x6840', '0x6900', '0x6ac0', '0x6b80', '0x6c00', '0x6d40', '0x6e80', '0x6fc0', '0x7080', '0x71c0', '0x7200', '0x7340', '0x74c0', '0x7580', '0x7640', '0x7700', '0x7800', '0x7940', '0x7F', '0x7F7F', '0x7a80', '0x7bc0', '0x7c40', '0x7d00', '0x7ec0', '0x7f80', '0x8081', '0x81c1', '0x8201', '0x8341', '0x84c1', '0x8581', '0x8641', '0x8701', '0x8801', '0x8941', '0x8a81', '0x8bc1', '0x8c41', '0x8d01', '0x8ec1', '0x8f81', '0x90c1', '0x9181', '0x9241', '0x9301', '0x9481', '0x95c1', '0x9601', '0x9741', '0x9841', '0x9901', '0x9ac1', '0x9b81', '0x9c01', '0x9d41', '0x9e81', '0x9fc1', '0xF000F', '0xFF', '0xFFFF', '0xa001', '0xa141', '0xa281', '0xa3c1', '0xa441', '0xa501', '0xa6c1', '0xa781', '0xa881', '0xa9c1', '0xaa01', '0xab41', '0xacc1', '0xad81', '0xae41', '0xaf01', '0xb041', '0xb101', '0xb2c1', '0xb381', '0xb401', '0xb541', '0xb681', '0xb7c1', '0xb8c1', '0xb981', '0xba41', '0xbb01', '0xbc81', '0xbdc1', '0xbe01', '0xbf41', '0xc0c1', '0xc181', '0xc241', '0xc301', '0xc481', '0xc5c1', '0xc601', '0xc741', '0xc841', '0xc901', '0xcac1', '0xcb81', '0xcc01', '0xcd41', '0xce81', '0xcfc1', '0xd081', '0xd1c1', '0xd201', '0xd341', '0xd4c1', '0xd581', '0xd641', '0xd701', '0xd801', '0xd941', '0xda81', '0xdbc1', '0xdc41', '0xdd01', '0xdec1', '0xdf81', '0xe041', '0xe101', '0xe2c1', '0xe381', '0xe401', '0xe541', '0xe681', '0xe7c1', '0xe8c1', '0xe981', '0xea41', '0xeb01', '0xec81', '0xedc1', '0xee01', '0xef41', '0xf001', '0xf141', '0xf281', '0xf3c1', '0xf441', '0xf501', '0xf6c1', '0xf781', '0xf881', '0xf9c1', '0xfa01', '0xfb41', '0xfcc1', '0xfd81', '0xfe41', '0xff', '0xff01', '0xffff', '1', '1.', '1.0', '1.01', '1.03', '1.033', '1.056', '1.064', '1.088', '1.107', '1.109', '1.121', '1.152', '1.154', '1.167', '1.17', '1.193', '1.208', '1.235', '1.241', '1.3', '1.302', '1.311', '1.32', '1.337', '1.342', '1.389', '1.4', '1.444', '1.446', '1.5', '1.55', '1.56', '1.584', '1.71', '1.86', '1.87', '1.e-9', '10', '10.0', '10.04', '100', '100.', '100.0', '1000', '1000.0', '10000', '1000000', '1024', '103.939', '10e10', '11', '11.11', '110', '116.779', '119.', '12', '12.30', '120', '123.68', '13', '13.86', '138', '14', '14.0', '14.29', '147', '149.597870e6', '15', '15.95', '150', '1500', '15000', '16', '163', '17', '177.', '178.', '18', '180', '184', '187.', '187.5', '188.', '19', '19.34', '194.', '1_000_000_000', '1e-2', '1e-3', '1e-5', '1e3', '1e6', '1e7', '2', '2.', '2.0', '2.10', '2.26', '2.33', '2.4', '2.49', '2.5', '2.64', '2.72', '2.87', '2.9296875', '20', '20.00', '20.08', '200', '2000', '2000.0', '201', '204', '2097151', '21', '21.17', '21000', '211', '212', '22', '22.42', '22.50', '22.51', '22000', '23', '24', '24.', '25.08', '25.10', '254.', '255', '255.', '256', '27', '27.47', '27.58', '27.69', '270', '27017', '28.0', '28.00', '280', '281', '3', '3.', '3.0', '3.11', '3.27', '3.34', '3.35', '3.74', '3.81', '30', '30.0', '30.00', '30.08', '30.11', '300', '304', '31', '32', '32.45', '32.50', '32.58', '34.92', '35.00', '35.04', '35000', '360', '3600', '3600.0', '365.', '37', '37.50', '37.67', '37.83', '37.88', '38', '4', '4.43', '4.44', '4.82', '40', '40.00', '40.14', '40.17', '400', '401', '403', '404', '406', '409', '412', '42', '42.0', '42.42', '42.65', '42.67', '422', '424.2', '45', '45.00', '45.07', '46', '465', '47.00', '47.17', '47.33', '47.50', '4729418', '49.75', '5', '5.0', '5.14', '5.20', '5.28', '5.37', '5.7', '50', '50.', '50.00', '50.08', '50.4', '500', '5000', '50000', '51', '512', '53', '5500', '55000', '58', '587', '59', '6', '6.07', '6.14', '6.29', '60', '60.', '60.0', '63', '64', '65', '7', '7.16', '7.38', '7.46', '7.5', '70', '70.6', '700', '7000', '75', '78', '79', '8', '8.0', '8.33', '80', '8000', '9', '9.01', '9.24', '9.8', '90', '900', '9600', '9800', '99.0', '9999', '999999', '99999999']
label:1, the number of unique tokens:5085
label:3, the number of unique tokens:32
The unique labels are:['False', 'None', 'True', 'and', 'as', 'assert', 'await', 'break', 'class', 'continue', 'def', 'del', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']
label:0, the number of unique tokens:14163
label:1, the number of unique tokens:3813
label:2, the number of unique tokens:310
The unique labels are:['.2', '.4', '.5', '0', '0.', '0.0', '0.000001', '0.00001', '0.0001', '0.0003', '0.001', '0.005', '0.01', '0.02', '0.03', '0.032', '0.04', '0.05', '0.1', '0.10', '0.125', '0.2', '0.22', '0.25', '0.258', '0.3', '0.35', '0.352', '0.4', '0.486', '0.5', '0.50', '0.6', '0.65', '0.66', '0.7', '0.75', '0.8', '0.843', '0.9', '0.911', '0.94', '0.95', '0.99', '0.999', '0.99999', '0b001', '0b010', '0b100', '0o070', '0o7', '0o700', '0o755', '0x0', '0x00', '0x00000000', '0x00000001', '0x00000002', '0x00000003', '0x00000004', '0x00000005', '0x00000006', '0x0000000d', '0x00000010', '0x0000003f', '0x00000040', '0x00000080', '0x00000100', '0x000001ff', '0x00000201', '0x00000400', '0x00000800', '0x00000fff', '0x0000800000000000', '0x000306c3', '0x00c10000', '0x00f0b5ff', '0x01c0003f', '0x02', '0x03c0003f', '0x05100800', '0x0F', '0x0f', '0x1', '0x10', '0x1000', '0x1c004121', '0x1c004122', '0x1c004143', '0x1c03c163', '0x1f', '0x2', '0x3', '0x3f', '0x4', '0x49656e69', '0x60', '0x6c65746e', '0x7', '0x756e6547', '0x76035a01', '0x7ffafbff', '0x8', '0x80', '0x90', '0x99', '0xD5', '0xb', '0xbfebfbff', '0xd', '0xf0', '0xf8000000', '0xff', '0xffff', '0xffffffff', '0xffffffffffffffffffffffffffffffff00000000000000000000000000000000', '1', '1.', '1.0', '1.01', '1.1', '1.15', '1.2', '1.279', '1.4142', '1.42', '1.5', '1.5e-5', '1.8', '10', '10.0', '10.6', '100', '100.0', '1000', '10000', '10000.0', '100000', '100000.0', '1000000.0', '101', '1024', '109', '10e-7', '11', '111', '113', '12', '12.', '120', '127.5', '128', '12836', '13', '14', '144', '15', '15.', '150', '1500', '16', '17', '18', '180', '180.0', '19', '19.9', '195', '1e-10', '1e-2', '1e-3', '1e-5', '1e-6', '1e-7', '1e-8', '1e-9', '1e6', '1e9', '2', '2.', '2.0', '20', '20.0', '20.4', '200', '2000', '201', '2012', '2048', '21', '21.0', '21.3', '2147483647', '22', '22.2', '22.4', '22.7', '224', '23', '2396512', '24', '24.0', '24.4', '25', '250', '255', '255.', '255.0', '256', '27.2', '270', '273.15', '28', '282', '3', '3.92', '3.95', '30', '300', '30000', '31', '3119362', '31344016', '32', '32.', '35', '360.0', '3600', '368', '376', '39', '3e-4', '4', '4.0', '4.03', '4.29', '40', '40.0', '400', '4000', '403', '404', '4096', '41', '42', '42.0', '422', '430', '4326', '443', '48', '48.2', '5', '5.0', '5.25', '50', '500', '5000', '5000.0', '50000', '500000', '51', '512', '52', '52.5', '54', '55', '56', '58', '5e-4', '6', '6.0', '6.26', '60', '60.0', '600', '6006', '62', '63', '6379', '64', '650', '7', '7.0', '7.2', '7.8', '7.9', '784', '7e-4', '8', '8.0', '8.03', '8.2', '8.31', '8.4', '8.5', '80', '800', '8000', '80e6', '86400', '888', '9', '9.5', '9.8', '90', '92', '96', '9862', '999999']
Write tokens in the training set to files:
Write tokens in the validation set to files:
Write tokens in the testing set to files:

The distribution of classes in training after removing repeated tokens between training and tesing:
Counter({0: 5000, 3: 5000, 1: 5000, 2: 5000})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in valid:
Counter({3: 540, 0: 540, 1: 540, 2: 540})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
The distribution of classes in testing:
Counter({3: 365, 0: 365, 1: 365, 2: 365})
{'NAME': 0, 'STRING': 1, 'NUMBER': 2, 'KEYWORD': 3}
All-layer probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Independent-layerwise probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Incremental-layerwise probing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
select minimum layers (LS+CC+LCA)
Correlation matrix size (#neurons x #neurons): (768, 768)
Number of clusters detected: 764
Correlation matrix size (#neurons x #neurons): (768, 768)
Number of clusters detected: 764
Correlation matrix size (#neurons x #neurons): (768, 768)
Number of clusters detected: 764
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers (run_cc_all.py)
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 4894
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 3326
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 2364
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 1754
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 1285
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 915
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 570
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 207
Correlation matrix size (#neurons x #neurons): (5376, 5376)
Number of clusters detected: 2
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
probing independent neurons based on all layers with finer percentage (run_max_features.py)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

pretrained_CodeBERTa top neurons
array([   0,    5, 2056, 4113,   20, 4116,   37,   49, 4148,   53, 4150,
       2107, 2114, 2131, 4182, 4192, 2163, 2166, 2167, 2168,  118, 2181,
        143, 4240, 2192,  147,  149,  154,  155,  159, 2208,  167, 4269,
       2230,  189, 2239, 2253, 2255, 4307,  215,  236, 4341, 4344,  253,
       2304,  265,  283, 2337,  291,  296, 2353, 4411,  319, 2371,  328,
        334, 2383, 4438, 4444, 4455, 4461, 4469,  374, 4476,  385,  401,
        402, 2459, 2461, 2463, 4512,  417,  432, 2493, 2497,  449, 2502,
       2508,  463, 4559,  480,  482, 2531,  493,  494,  495, 2549,  501,
        519, 2575, 4623,  534, 4632, 2587, 4640,  557,  559, 4659,  574,
        583,  595,  600,  601,  606,  612, 2661,  614,  626,  631, 4735,
        643,  645,  661, 4761, 2715,  671,  672,  680, 2729, 2737, 2739,
       2741,  701,  702,  705, 4810, 4811, 2767,  721, 2778,  740, 2798,
       4863,  768, 2830,  784, 4881, 4884,  791,  798, 4896,  805,  809,
       4908,  813,  817, 4916,  821, 2875, 4929,  834,  835, 4936, 4937,
        847,  848, 2899,  855, 4980, 2933, 4982, 2935,  886,  894,  911,
       5008,  915, 2964, 5013,  922,  927, 5037, 5045, 3004,  957, 5056,
       5061, 3023, 5072,  978,  983, 5081,  995, 5109, 1021, 3071, 3072,
       1033, 5144, 3104, 3105, 1059, 3107, 1079, 5175, 5186, 1096, 3159,
       5212, 3180, 1144, 1154, 5253, 3208, 1168, 3224, 3229, 5280, 1200,
       3248, 1203, 5300, 3256, 3261, 1216, 3265, 3267, 3276, 1231, 5343,
       1250, 3303, 5355, 1262, 1269, 1272, 3348, 1302, 3355, 3363, 1331,
       3382, 1337, 3393, 3395, 3398, 1363, 1369, 1374, 1380, 3429, 3441,
       1397, 1399, 3448, 1413, 1439, 1440, 3497, 3501, 1454, 3504, 3507,
       3512, 1485, 1487, 1489, 1508, 1536, 1540, 1571, 1573, 3638, 3643,
       1603, 1615, 3667, 3678, 1643, 3701, 3714, 1674, 1681, 3732, 1691,
       1693, 1695, 3744, 3768, 3772, 1725, 1763, 3822, 1781, 3839, 3849,
       1807, 3877, 1839, 1859, 3907, 1864, 1873, 1893, 1921, 3985, 1947,
       1971, 4024, 1984, 4042, 4043, 1999, 2002, 4051, 2018, 2030, 2037,
       2044])
pretrained_CodeBERTa top neurons per class
{'NAME': array([2899, 1999, 2181,  159, 2463, 4937, 5355, 2131, 1231, 2230,  401,
       2715,  645, 5300, 3643, 1971,  978, 1059, 1363, 2830, 1947, 2163,
       2729,  154, 4461,  927, 1216, 1540, 4908,  721, 4024, 1413,  740,
       2304,  798, 3267,  671, 1695, 3714, 2875, 3507, 1691, 3256, 2739,
       3877, 1859, 5212, 5144, 2767, 1674, 5013, 1571,  291, 3849, 2166,
        463, 1200, 3363, 3159, 4659,  983, 5343,  215, 1203, 1536, 1693,
        855, 3072, 2502, 3667, 2459,    5, 5072, 1439, 4444, 2107, 4929,
       4811,  848, 2114, 4438,  784, 4863, 4411]), 'STRING': array([2255, 3023,  253, 4269, 4916, 4051, 2549, 3429, 4042, 2661, 2575,
        265, 1033,  374, 1781,  236, 2497, 3448, 3224, 1079, 1681,  805,
       1440, 1380, 4980, 1893, 1397,  385,   37,  334, 5008, 5037, 3180,
       3208, 3985, 4936, 3398,  449, 5280,  626,  495, 1807, 1573, 3744,
       3276, 4735, 4240, 3512, 1096, 4469, 4896, 4810, 4307, 1487,  328,
       2208, 1839, 3256, 4182, 4148, 3501, 3105, 1643, 3822, 2056, 1454,
       1873, 4761, 4559, 2508, 2778, 5081, 3248, 2741, 3382,   20, 3701,
       2737,  283, 3768, 5253, 2181, 1021, 2337, 2933, 5175, 4512]), 'NUMBER': array([  49,  740, 4455, 4113, 4916, 4632, 1059, 1380, 3441, 4444, 1369,
       1337, 1536, 3265, 3072, 1399,  680, 5212, 3497, 3448,  583,  291,
       3229, 5045, 2304,  432, 2729,  557, 4623, 2935,  894,  631,  768,
       4240,  265,  480,  702,  600,  612, 5061,  817,  519, 1200, 3907,
       2168, 1603, 1508, 4881, 2002, 2167,  147, 1984, 1440, 4863, 4982,
        922,  643,  154,  402, 4344,  601, 1485,    5, 3504, 3104, 2253,
       1331, 2461,  595, 2255,    0, 2353,  915, 4640, 2371, 2192, 3023,
        167, 2497, 4043, 4476,  672]), 'KEYWORD': array([2899,  189,  118, 4116,  957, 2030, 3772,  606, 2131, 1725, 3667,
       4884, 1262, 2056, 1921,  534, 1615, 3393,  482,  791,  143, 2037,
        328, 4150, 2493, 1269, 3839,  911,  494, 5056, 1489, 3261, 2044,
         53, 1864,  661, 3004,  574, 1302,  612,  493, 1250, 5186,  721,
       1763, 1144,  701,  614,  886,  417,  319,  995,  155, 4192,  834,
       2587,  835, 3732, 2018, 2964,  821,  501, 2531,  296, 3678, 2239,
        813, 1272, 3071, 1168, 3348,  559,  149, 1154, 3355, 1374, 2383,
       1231, 1096, 2798,  809, 5109, 4341, 3303,  847, 3638, 3395, 3107,
        705])}
pretrained_CodeBERTa top words
Top words for pretrained_CodeBERTa neuron indx 0 [('dir', 3.2403717041015625), ('code', 3.1733198165893555), ('90', 3.1063055992126465), ('tag', 3.0995631217956543), ('40', 3.0589065551757812)]
Top words for pretrained_CodeBERTa neuron indx 5 [('array', 3.9066288769245148), ('tarfile', 3.79941987991333), ('float', 3.7600925990513394), ('urlparse', 3.5377166271209717), ('expand', 3.4254631400108337)]
Top words for pretrained_CodeBERTa neuron indx 2056 [('set', 3.526227855682373), ('PIL', 3.300736427307129), ('parseString', 3.0680184364318848), ('system', 3.020148992538452), ('mode', 2.916182769669427)]
Top words for pretrained_CodeBERTa neuron indx 4113 [('is', 3.329801094532013), ('y', 3.051271915435791), ('n', 2.88962988058726), ('384', 2.7325594425201416), ('6.', 2.703896999359131)]
Top words for pretrained_CodeBERTa neuron indx 20 [('dumps', 4.225894212722778), ('zeros', 3.3252625465393066), ('urlencode', 3.294172763824463), ('seconds', 3.216318726539612), ('degrees', 3.200119892756144)]
Top words for pretrained_CodeBERTa neuron indx 4116 [('mean', 2.7735178470611572), ('map', 2.6960891485214233), ('keywords', 2.57673716545105), ('"table"', 2.4795031547546387), ('"@"', 2.4103567600250244)]
Top words for pretrained_CodeBERTa neuron indx 37 [('"\\\\\\\\"', 3.3631978034973145), ('urljoin', 3.310025453567505), ('transpose', 3.2051045894622803), ('"-"', 3.0629615783691406), ('nn', 3.030369758605957)]
Top words for pretrained_CodeBERTa neuron indx 49 [('64', 3.3996161330829966), ('param', 3.3653957843780518), ('stdout', 3.3175556659698486), ('byte', 3.3060901165008545), ('429', 3.2382125854492188)]
Top words for pretrained_CodeBERTa neuron indx 4148 [('258', 3.2147228717803955), ('gzip', 3.0154260396957397), ('"="', 3.0143419333866666), ("'/Cell'", 3.0098671913146973), ('259', 2.9431886672973633)]
Top words for pretrained_CodeBERTa neuron indx 53 [('410', 4.094037691752116), ('302', 3.7508084774017334), ('timestamp', 3.4485741456349692), ('arg', 3.3585119247436523), ('301', 3.3566370010375977)]
Top words for pretrained_CodeBERTa neuron indx 4150 [('scandir', 3.6052496433258057), ('splits', 3.2569925785064697), ('moves', 2.9011611938476562), ('all', 2.7590930461883545), ('85', 2.700805425643921)]
Top words for pretrained_CodeBERTa neuron indx 2107 [('scheme', 4.207941055297852), ('color', 3.7832934856414795), ('plugins', 3.54943052927653), ('language', 3.5047045094626292), ('urls', 3.359987035393715)]
Top words for pretrained_CodeBERTa neuron indx 2114 [('"{}"', 2.884305715560913), ('"-"', 2.83343243598938), ('"_"', 2.8027976155281067), ("'.'", 2.7890097848300277), ('class', 2.687000274658203)]
Top words for pretrained_CodeBERTa neuron indx 2131 [('Tensor', 3.5864444573720298), ('ext', 3.286914678180919), ('version', 3.2396512031555176), ('outfile', 3.2310208082199097), ('classes', 3.2157748540242515)]
Top words for pretrained_CodeBERTa neuron indx 4182 [('quote', 3.642245054244995), ('default', 3.4203057289123535), ('sub', 3.1092445850372314), ('squeeze', 3.084481716156006), ('makedirs', 3.0250437259674072)]
Top words for pretrained_CodeBERTa neuron indx 4192 [('shortcuts', 3.2814457416534424), ('43', 2.8063533306121826), ('23', 2.657688617706299), ('Sequence', 2.6548608938852944), ('history', 2.635517120361328)]
Top words for pretrained_CodeBERTa neuron indx 2163 [('12200', 3.149634838104248), ('429', 2.864010810852051), ('140', 2.8632583618164062), ('22', 2.856297492980957), ('77', 2.822996497154236)]
Top words for pretrained_CodeBERTa neuron indx 2166 [('palette', 3.883131265640259), ('symbols', 3.5349440574645996), ('activation', 3.4501501321792603), ('pic', 3.445770463678572), ('pretrained', 3.2045093774795532)]
Top words for pretrained_CodeBERTa neuron indx 2167 [('inplace', 5.071173429489136), ('elif', 3.4478909969329834), ('child', 3.3998799324035645), ('32768', 3.2710015773773193), ('33', 3.261234402656555)]
Top words for pretrained_CodeBERTa neuron indx 2168 [("'Referer'", 3.271317481994629), ('90', 3.2495810985565186), ('listdir', 2.622756338119507), ('descend', 2.593674659729004), ("'apiEndpoint'", 2.5552492141723633)]
Top words for pretrained_CodeBERTa neuron indx 118 [('256', 4.98563848223005), ('30', 4.0272323290507), ('150', 3.932231903076172), ('120', 3.903878927230835), ('192', 3.8750431537628174)]
Top words for pretrained_CodeBERTa neuron indx 2181 [('byte', 4.019931793212891), ('int', 3.8339881636202335), ('float', 3.6574060235704695), ('randint', 2.993158721923828), ("'../..'", 2.8382394313812256)]
Top words for pretrained_CodeBERTa neuron indx 143 [('tmp', 3.857969641685486), ('skill', 3.673404097557068), ('shears', 2.8058571219444275), ('area', 2.7322781085968018), ('"/"', 2.6917396545410157)]
Top words for pretrained_CodeBERTa neuron indx 4240 [('ioctl', 3.378105401992798), ('dictified', 3.120729371905327), ('skill', 3.0837138891220093), ('RED', 2.9749646186828613), ('add', 2.8193522691726685)]
Top words for pretrained_CodeBERTa neuron indx 2192 [('63', 3.513331115245819), ('answer', 2.947551727294922), ('hasattr', 2.9414994716644287), ('std', 2.9260471165180206), ('99', 2.9111820062001548)]
Top words for pretrained_CodeBERTa neuron indx 147 [('85', 4.622093677520752), ('channels', 3.7966556549072266), ('attr', 3.603362202644348), ('unicode', 3.433260917663574), ('elem', 3.392324606577555)]
Top words for pretrained_CodeBERTa neuron indx 149 [('kwargs', 3.312302188987428), ('border', 3.30538272857666), ('row', 3.1224448680877686), ('days', 2.9680919647216797), ('type', 2.9001030921936035)]
Top words for pretrained_CodeBERTa neuron indx 154 [('tuple', 4.137866377830505), ('unpack', 3.393510580062866), ('41', 3.1875216960906982), ('pad', 3.1867164373397827), ('i', 3.172847291256519)]
Top words for pretrained_CodeBERTa neuron indx 155 [('404', 3.6575350761413574), ('len', 3.495929176157171), ('ele', 3.3554056882858276), ('finally', 3.129984498023987), ('tl', 3.1250287294387817)]
Top words for pretrained_CodeBERTa neuron indx 159 [('Number', 4.148767630259196), ('add', 3.8736162185668945), ("'>='", 2.97617769241333), ('RED', 2.7918081283569336), ('save', 2.7365556240081785)]
Top words for pretrained_CodeBERTa neuron indx 2208 [('365', 2.9221913814544678), ('50', 2.3161044915517173), ('strip', 2.212281425793966), ("'__line__'", 2.1826391220092773), ('503', 2.1666413148244223)]
Top words for pretrained_CodeBERTa neuron indx 167 [('pow', 3.8713316917419434), ('is', 2.9694412541676716), ('isinstance', 2.7039476732412973), ('tobytes', 2.6376683712005615), ('affine', 2.574341297149658)]
Top words for pretrained_CodeBERTa neuron indx 4269 [('URLError', 4.058026313781738), ("'|'", 3.497339129447937), ('splits', 3.0903773307800293), ('503', 3.0616376399993896), ('504', 3.0610904693603516)]
Top words for pretrained_CodeBERTa neuron indx 2230 [('RED', 3.8035242557525635), ('oh', 3.741362730662028), ('debug', 3.5494723320007324), ('224', 3.442819833755493), ('line', 3.4314645528793335)]
Top words for pretrained_CodeBERTa neuron indx 189 [('patch', 3.4308910369873047), ('class', 3.271221399307251), ('")"', 3.109279155731201), ('"|"', 3.1049134731292725), ('zip', 3.1002090771993003)]
Top words for pretrained_CodeBERTa neuron indx 2239 [('endpoints', 3.369864821434021), ('scheme', 3.3389346599578857), ('id', 3.1444347500801086), ('method', 2.992118000984192), ('name', 2.9849174363272533)]
Top words for pretrained_CodeBERTa neuron indx 2253 [('classes', 3.7237540086110434), ('arg', 3.642179012298584), ('">"', 3.5219340324401855), ('attrib', 3.4886847734451294), ('cat', 3.208706855773926)]
Top words for pretrained_CodeBERTa neuron indx 2255 [('A', 3.270161271095276), ('pic', 2.904314031865862), ('view', 2.9035102128982544), ('lower', 2.8836336930592856), ('any', 2.8749160766601562)]
Top words for pretrained_CodeBERTa neuron indx 4307 [('scheme', 3.8130979537963867), ('find', 3.449922561645508), ('confidence', 3.353009521961212), ('43', 3.291322946548462), ('colors', 3.184640645980835)]
Top words for pretrained_CodeBERTa neuron indx 215 [('suffix', 4.328243017196655), ('urljoin', 4.232832431793213), ('symbols', 3.9319649934768677), ('gui', 3.8086798191070557), ('dirname', 3.7344510555267334)]
Top words for pretrained_CodeBERTa neuron indx 236 [('io', 3.7422866821289062), ('settings', 3.622424602508545), ('line', 3.615367889404297), ('301', 3.5233492851257324), ('std', 3.4737494587898254)]
Top words for pretrained_CodeBERTa neuron indx 4341 [("'%'", 4.218517303466797), ('pow', 3.9651715755462646), ('ceil', 3.1901967525482178), ('mul', 2.856903553009033), ('"pm_lat"', 2.6725118160247803)]
Top words for pretrained_CodeBERTa neuron indx 4344 [('365', 3.1170830726623535), ('160', 3.1059796810150146), ('384', 3.049447536468506), ('req', 2.777650628771101), ('flush', 2.7646429538726807)]
Top words for pretrained_CodeBERTa neuron indx 253 [("')'", 3.3899329900741577), ('zeros', 2.8747212886810303), ('version', 2.7724802494049072), ('33', 2.6903117895126343), ('nn', 2.6648547649383545)]
Top words for pretrained_CodeBERTa neuron indx 2304 [('gui', 3.1565558910369873), ('YELLOW', 2.8095297813415527), ('exceptions', 2.7892587184906006), ('suffix', 2.752809166908264), ('s', 2.631250790187291)]
Top words for pretrained_CodeBERTa neuron indx 265 [('answer', 3.270000457763672), ('encode', 3.1927507718404136), ("')'", 2.7431466579437256), ('gui', 2.715672254562378), ('answerers', 2.6691514253616333)]
Top words for pretrained_CodeBERTa neuron indx 283 [('800', 4.414334297180176), ('bias', 3.278808355331421), ('224', 3.1199581623077393), ('interpolation', 3.0018586771828786), ('111', 2.9124622344970703)]
Top words for pretrained_CodeBERTa neuron indx 2337 [('attr', 3.7348421812057495), ('except', 3.3131917521011), ('device', 3.239523506164551), ('gamma', 3.1146002610524497), ('node', 2.8633328676223755)]
Top words for pretrained_CodeBERTa neuron indx 291 [('attempt', 3.220114231109619), ('console', 3.046603202819824), ('find', 2.983355760574341), ('Request', 2.9773610830307007), ('now', 2.82125186920166)]
Top words for pretrained_CodeBERTa neuron indx 296 [('dist', 4.16524076461792), ('800', 4.127162933349609), ('matches', 4.062458356221517), ('locales', 4.0044026374816895), ('lang', 3.9406173706054686)]
Top words for pretrained_CodeBERTa neuron indx 2353 [('write', 4.013496955235799), ('fh', 3.8901020288467407), ('engines', 3.4403995275497437), ('byte', 3.13814377784729), ('error', 3.094496965408325)]
Top words for pretrained_CodeBERTa neuron indx 4411 [('reshape', 3.6485607624053955), ('color', 3.4912781715393066), ('language', 3.2984228134155273), ('padding', 3.2289543549219766), ('border', 3.1691734790802)]
Top words for pretrained_CodeBERTa neuron indx 319 [('seek', 4.249679088592529), ('find', 4.101803302764893), ('scandir', 3.9610626697540283), ('decode', 3.8128149032592775), ('expanded', 3.492316246032715)]
Top words for pretrained_CodeBERTa neuron indx 2371 [('90', 3.3743427991867065), ('5', 2.8997619356427875), ('25', 2.7573575019836425), ('8', 2.6686890220642088), ('answer', 2.64836049079895)]
Top words for pretrained_CodeBERTa neuron indx 328 [('getattr', 4.836742083231608), ('stack', 3.7439496517181396), ('convert', 3.2997533321380614), ('query', 3.222306804223494), ('format', 3.177243223190308)]
Top words for pretrained_CodeBERTa neuron indx 334 [('expanded', 3.3820365269978843), ('brightness', 3.322726845741272), ('67', 3.3098671436309814), ('builtins', 3.2677425146102905), ('dim', 3.191559076309204)]
Top words for pretrained_CodeBERTa neuron indx 2383 [("'://'", 3.663114070892334), ('param', 3.0601449012756348), ('503', 2.985307057698568), ('32', 2.77258563041687), ('println', 2.7187209129333496)]
Top words for pretrained_CodeBERTa neuron indx 4438 [("'://'", 3.1474714279174805), ('Exception', 3.0493955612182617), ('errno', 2.9192464351654053), ('_save_response_content', 2.8711400032043457), ('append', 2.7986755923527045)]
Top words for pretrained_CodeBERTa neuron indx 4444 [('println', 3.337409496307373), ('150', 3.083970069885254), ('over', 2.98421311378479), ('34', 2.982783317565918), ('F', 2.9252719283103943)]
Top words for pretrained_CodeBERTa neuron indx 4455 [('sub', 3.726475238800049), ('24', 3.300809860229492), ('dumps', 3.2723244031270347), ('moves', 3.184382677078247), ('io', 2.8980636596679688)]
Top words for pretrained_CodeBERTa neuron indx 4461 [('tzinfo', 4.050414085388184), ("'touch'", 3.593663215637207), ('enhance', 3.3979718685150146), ('default', 3.2203805446624756), ('Reshape', 3.214656352996826)]
Top words for pretrained_CodeBERTa neuron indx 4469 [('exit', 3.7499160766601562), ('ndim', 3.130923589070638), ('errno', 2.9914472103118896), ('builtins', 2.9611005783081055), ('reshape', 2.919895887374878)]
Top words for pretrained_CodeBERTa neuron indx 374 [('save', 3.8905803203582763), ('update', 3.042236328125), ('url', 2.9433182686874546), ('_call', 2.881566047668457), ('type', 2.674943208694458)]
Top words for pretrained_CodeBERTa neuron indx 4476 [('365', 2.655630350112915), ('os', 2.627145077134001), ('datetime', 2.4988397359848022), ('shortcuts', 2.4378764629364014), ('exit', 2.420502185821533)]
Top words for pretrained_CodeBERTa neuron indx 385 [('debug', 2.8313674926757812), ('301', 2.722687005996704), ('format', 2.667775354385376), ('args', 2.566005617380142), ('192', 2.4499473571777344)]
Top words for pretrained_CodeBERTa neuron indx 401 [('seconds', 3.683310627937317), ('random', 3.366406003634135), ('suffix', 3.123481035232544), ('write', 3.0020553270975747), ('target', 2.9762865702311196)]
Top words for pretrained_CodeBERTa neuron indx 402 [('sub', 3.2042596340179443), ('shape', 3.092354965209961), ('form', 3.0346754921807184), ("':'", 2.923918533325195), ('re', 2.844271630048752)]
Top words for pretrained_CodeBERTa neuron indx 2459 [('argv', 3.711754083633423), ("'('", 3.3281099796295166), ('flatten', 3.108065366744995), ('404', 3.0872137546539307), ('"*"', 3.082808256149292)]
Top words for pretrained_CodeBERTa neuron indx 2461 [('redirect', 3.6438980102539062), ('dict', 3.2625744342803955), ('bytes', 3.1728814840316772), ('error', 3.1661336421966553), ('50000', 3.03361439704895)]
Top words for pretrained_CodeBERTa neuron indx 2463 [('activation', 2.763436436653137), ('Tensor', 2.576653480529785), ('subprocess', 2.5448424220085144), ('graph', 2.534171223640442), ('descend', 2.491774320602417)]
Top words for pretrained_CodeBERTa neuron indx 4512 [('symbols', 2.8564220666885376), ('365', 2.7579421997070312), ("'sequence_no'", 2.6077237129211426), ("'/lstm_cell/'", 2.4919674396514893), ("'decode_raw2get_char_ids'", 2.4210236072540283)]
Top words for pretrained_CodeBERTa neuron indx 417 [('datetime', 4.159858226776123), ('find', 3.831312894821167), ('close', 3.813288688659668), ('attrib', 3.7539443969726562), ('graph', 3.6400887966156006)]
Top words for pretrained_CodeBERTa neuron indx 432 [('engines', 3.512142062187195), ('total', 3.4520320892333984), ('opts', 3.27305277188619), ('n', 3.265929381052653), ('zlib', 3.040424346923828)]
Top words for pretrained_CodeBERTa neuron indx 2493 [('zip', 3.587311029434204), ('io', 3.463810920715332), ('descend', 3.2927258014678955), ('ele', 3.099990963935852), ('RED', 3.000453233718872)]
Top words for pretrained_CodeBERTa neuron indx 2497 [('127', 3.501816749572754), ('XML', 3.3646090030670166), ('except', 3.1714357331741687), ('140', 3.1066691875457764), ('inplace', 3.081208109855652)]
Top words for pretrained_CodeBERTa neuron indx 449 [('dtype', 3.684193640947342), ('opt', 3.4965234200159707), ('redirect', 3.359720230102539), ('sort', 3.3232834339141846), ('StringIO', 3.007467031478882)]
Top words for pretrained_CodeBERTa neuron indx 2502 [('expanded', 4.846331437428792), ('ele', 3.801435112953186), ('zeros', 3.455939292907715), ('permute', 3.378997802734375), ('reshape', 3.3772354125976562)]
Top words for pretrained_CodeBERTa neuron indx 2508 [('exp', 2.60089111328125), ("'metadata.json'", 2.266528606414795), ('".stpd"', 2.266075611114502), ('dumps', 2.2447728315989175), ("'{}.local.'", 2.235887050628662)]
Top words for pretrained_CodeBERTa neuron indx 463 [('tzinfo', 3.655112862586975), ('locales', 3.3265280723571777), ('Image', 3.2611414264230167), ('outfile', 3.108659505844116), ('row', 3.079673707485199)]
Top words for pretrained_CodeBERTa neuron indx 4559 [('50', 2.918940802415212), ('lower', 2.8561646938323975), ('120', 2.8552844524383545), ('to', 2.7482218742370605), ('any', 2.7156460285186768)]
Top words for pretrained_CodeBERTa neuron indx 480 [('stdout', 4.185976505279541), ('bias', 4.063998699188232), ('autocompleter', 3.3790555000305176), ("'+'", 3.2659947872161865), ("'--'", 3.0454809963703156)]
Top words for pretrained_CodeBERTa neuron indx 482 [("'!'", 4.069848418235779), ('85', 3.96260929107666), ('Response', 3.6088812828063963), ('kwargs', 3.552815683344577), ('channels', 3.4984521865844727)]
Top words for pretrained_CodeBERTa neuron indx 2531 [('Image', 3.2293386319104362), ('transforms', 2.9714395829609463), ('locales', 2.7726733684539795), ('childNodes', 2.7591958045959473), ('29', 2.728714346885681)]
Top words for pretrained_CodeBERTa neuron indx 493 [('"|"', 3.8831546306610107), ('update', 2.944873571395874), ('attrib', 2.827725887298584), ('group', 2.809679079055786), ('"("', 2.7995641231536865)]
Top words for pretrained_CodeBERTa neuron indx 494 [('301', 3.3868725299835205), ('63', 3.2815226316452026), ('suffix', 3.1754651069641113), ('attention', 3.04195374250412), ('softmax', 3.0172115564346313)]
Top words for pretrained_CodeBERTa neuron indx 495 [('shutil', 3.0838379859924316), ('format', 2.918028450012207), ('flatten', 2.843222141265869), ('shuffle', 2.721731662750244), ('node', 2.565477728843689)]
Top words for pretrained_CodeBERTa neuron indx 2549 [('140', 3.639220714569092), ('softmax', 3.2472118139266968), ('443', 3.0156989097595215), ('8', 2.981089482307434), ('Reshape', 2.94827938079834)]
Top words for pretrained_CodeBERTa neuron indx 501 [('history', 3.4388864040374756), ('"-"', 3.3766465187072754), ('save', 3.226911211013794), ('trie', 3.215696589152018), ('sqrt', 3.1672523021698)]
Top words for pretrained_CodeBERTa neuron indx 519 [('transpose', 3.5730886856714883), ('loads', 3.281817525625229), ('180', 3.244221493601799), ('Compose', 3.0984394550323486), ('accuracy', 2.9825439453125)]
Top words for pretrained_CodeBERTa neuron indx 2575 [('ndim', 3.3504788875579834), ('termios', 2.9922358989715576), ('width', 2.9024812074807973), ('429', 2.8617427349090576), ('in', 2.6543417101180085)]
Top words for pretrained_CodeBERTa neuron indx 4623 [('xpath', 3.610010528564453), ('country', 3.5225090980529785), ('Exception', 3.36246919631958), ('tag', 3.1973785161972046), ('attrib', 3.1734848022460938)]
Top words for pretrained_CodeBERTa neuron indx 534 [('args', 3.3723681966463723), ('render', 2.815961241722107), ('next', 2.714617371559143), ('head', 2.689389228820801), ('force', 2.673228621482849)]
Top words for pretrained_CodeBERTa neuron indx 4632 [('palette', 3.0494633515675864), ('message', 3.0003681659698485), ('ValueError', 2.961103916168213), ('800', 2.8612921237945557), ("'exp'", 2.818058490753174)]
Top words for pretrained_CodeBERTa neuron indx 2587 [('class', 3.524727702140808), ('800', 3.107947587966919), ('filter', 3.001746892929077), ('sleep', 2.838994264602661), ('except', 2.799515740815983)]
Top words for pretrained_CodeBERTa neuron indx 4640 [("'>='", 3.1906986236572266), ('label', 2.947080373764038), ('keywords', 2.828486204147339), ('43', 2.696624517440796), ('NotImplementedError', 2.6807069778442383)]
Top words for pretrained_CodeBERTa neuron indx 557 [('attempt', 3.317988872528076), ('";"', 3.275698244571686), ('25', 3.0447504043579103), ('1024', 3.0270504156748452), ('65536', 3.025371551513672)]
Top words for pretrained_CodeBERTa neuron indx 559 [('800', 4.1662278175354), ('re', 2.615792989730835), ('600', 2.5376923084259033), ('contiguous', 2.45363187789917), ('cfg', 2.405367851257324)]
Top words for pretrained_CodeBERTa neuron indx 4659 [('engine', 4.06073522567749), ('urlparse', 3.916061004002889), ('scheme', 3.508344888687134), ('println', 3.309295892715454), ('engines', 3.2692030668258667)]
Top words for pretrained_CodeBERTa neuron indx 574 [('patch', 3.9033217430114746), ('search', 3.660942898856269), ('quote', 3.545576333999634), ('completer', 3.537928819656372), ('group', 3.536694049835205)]
Top words for pretrained_CodeBERTa neuron indx 583 [('fileobj', 2.8778669834136963), ('flush', 2.6536284685134888), ('join', 2.6366926001177893), ('basename', 2.5339300632476807), ('Iterable', 2.5251803398132324)]
Top words for pretrained_CodeBERTa neuron indx 595 [('unpack', 3.5735857486724854), ('tarfile', 3.5493791103363037), ('six', 3.5092201232910156), ('attrib', 3.504794716835022), ('43', 3.4870858192443848)]
Top words for pretrained_CodeBERTa neuron indx 600 [('23', 3.759298801422119), ('model', 3.3688404685572575), ('sum', 3.2612265586853026), ('makedirs', 3.1410605907440186), ('im', 3.120708703994751)]
Top words for pretrained_CodeBERTa neuron indx 601 [('stride', 4.0745062828063965), ('words', 3.481480121612549), ('">"', 3.4269919395446777), ('part', 2.846161961555481), ('mode', 2.7903636119983815)]
Top words for pretrained_CodeBERTa neuron indx 606 [('fh', 3.3257219791412354), ("'://'", 3.16693377494812), ('preferences', 3.14326495329539), ('trie', 2.998988898595174), ('borders', 2.986919403076172)]
Top words for pretrained_CodeBERTa neuron indx 612 [('narrow', 3.415553092956543), ('correct', 3.2602018117904663), ('140', 3.1672229766845703), ('5', 3.105294132232666), ('sleep', 2.9752652645111084)]
Top words for pretrained_CodeBERTa neuron indx 2661 [('urljoin', 3.615842580795288), ('Timeout', 3.027914047241211), ('")"', 2.997439742088318), ('";"', 2.991496503353119), ("'#eeeeee'", 2.9415318965911865)]
Top words for pretrained_CodeBERTa neuron indx 614 [('answer', 3.6431524753570557), ('")"', 3.560904622077942), ("'('", 3.47255277633667), ('timedelta', 3.468897819519043), ('permute', 3.405120372772217)]
Top words for pretrained_CodeBERTa neuron indx 626 [('permute', 3.414411783218384), ("'}'", 3.3494677543640137), ('requests', 3.2325961589813232), ('lc', 3.2299118041992188), ('request', 3.1402866984858657)]
Top words for pretrained_CodeBERTa neuron indx 631 [('34', 3.5780246257781982), ('tar', 3.290943741798401), ('inplace', 3.28469455242157), ('target', 3.16497802734375), ('content', 3.1649754444758096)]
Top words for pretrained_CodeBERTa neuron indx 4735 [("';'", 4.64680290222168), ("'>'", 3.1186485290527344), ('144', 2.9210047721862793), ("'!'", 2.8593642711639404), ("'>='", 2.816685438156128)]
Top words for pretrained_CodeBERTa neuron indx 643 [('Optional', 4.608392238616943), ('curr', 4.198078700474331), ("'+'", 4.179660797119141), ('"&"', 4.09012508392334), ('im', 3.6566274166107178)]
Top words for pretrained_CodeBERTa neuron indx 645 [('find', 3.476250410079956), ('args', 3.418504536151886), ('scheme', 3.2698850631713867), ('float', 3.1873572383608137), ('224', 3.0751969814300537)]
Top words for pretrained_CodeBERTa neuron indx 661 [('view', 3.78208327293396), ('splits', 3.5028297901153564), ('mode', 3.3223169997886375), ('contiguous', 3.116307020187378), ("')'", 3.0695343017578125)]
Top words for pretrained_CodeBERTa neuron indx 4761 [('"{},{}"', 3.6602566242218018), ('ValidationException', 3.6423263549804688), ('"interval"', 3.5654454231262207), ('resample', 3.4315178990364075), ('"{key}"', 3.3380444049835205)]
Top words for pretrained_CodeBERTa neuron indx 2715 [('netloc', 3.6042094230651855), ('57344', 3.5374743938446045), ('seconds', 3.4099041223526), ('attempt', 3.33868670463562), ('ndarray', 3.087229549884796)]
Top words for pretrained_CodeBERTa neuron indx 671 [('tzinfo', 4.826344966888428), ('mul', 4.223874092102051), ('d', 3.782437040692284), ('f', 3.455852917262486), ('label', 3.3851242065429688)]
Top words for pretrained_CodeBERTa neuron indx 672 [('mul', 3.6738154888153076), ('stack', 3.5528836250305176), ('OSError', 3.206979751586914), ('border', 3.0310723781585693), ('errno', 3.0240564346313477)]
Top words for pretrained_CodeBERTa neuron indx 680 [('copy', 3.894339942932129), ('77', 3.748595714569092), ("'{}{}'", 3.641211986541748), ('tuple', 3.440068006515503), ("'hls'", 3.1410603523254395)]
Top words for pretrained_CodeBERTa neuron indx 2729 [('contiguous', 4.7166876792907715), ('childNodes', 3.6421825885772705), ('hexdigest', 3.5238733291625977), ('quote', 3.4924352169036865), ('pad', 3.417339503765106)]
Top words for pretrained_CodeBERTa neuron indx 2737 [('dim', 3.7935521602630615), ('else', 3.695263995707614), ('tile', 3.3817555904388428), ('form', 3.203109211391873), ('height', 3.1136939092115923)]
Top words for pretrained_CodeBERTa neuron indx 2739 [('elif', 3.0966955713323645), ('pop', 2.889011104901632), ('match', 2.8857625172688413), ('exit', 2.8333609104156494), ('strip', 2.8237011830012)]
Top words for pretrained_CodeBERTa neuron indx 2741 [('root', 3.621633640651045), ('"&"', 3.5692591667175293), ('512', 2.9988895392999417), ('Dense', 2.9858428478240966), ('nn', 2.9091696739196777)]
Top words for pretrained_CodeBERTa neuron indx 701 [('98', 2.730532964070638), ('None', 2.5619297429530117), ('timedelta', 2.553952932357788), ('eq', 2.5430686473846436), ('"_rot"', 2.3783011436462402)]
Top words for pretrained_CodeBERTa neuron indx 702 [('except', 2.8610403537750244), ('KeyError', 2.5070815086364746), ("'}'", 2.413626194000244), ('tar', 2.348158538341522), ('getattr', 2.3080639044443765)]
Top words for pretrained_CodeBERTa neuron indx 705 [('Request', 3.7433587312698364), ('200', 3.0589107970396676), ('1000', 2.993164896965027), ('enhancer', 2.9637540578842163), ('class', 2.931942939758301)]
Top words for pretrained_CodeBERTa neuron indx 4810 [('color', 3.4960697889328003), ('Timeout', 3.171820878982544), ('Brightness', 3.1570780277252197), ('elif', 3.0469128441166236), ('array', 2.9969999194145203)]
Top words for pretrained_CodeBERTa neuron indx 4811 [('dirname', 3.731865882873535), ('tmp', 3.470900058746338), ('curr_agenda', 3.468852162361145), ('squeeze_', 3.3766636848449707), ('splits', 3.3035354614257812)]
Top words for pretrained_CodeBERTa neuron indx 2767 [('now', 3.7274484634399414), ('tzinfo', 3.278818726539612), ('cat', 3.208835482597351), ('row', 3.1063525080680847), ('F', 2.970225155353546)]
Top words for pretrained_CodeBERTa neuron indx 721 [('skill', 3.8743969202041626), ('quote', 3.1946229934692383), ('dict', 3.0819225311279297), ('all', 3.0318613052368164), ('f', 3.019744438784463)]
Top words for pretrained_CodeBERTa neuron indx 2778 [('8080', 4.085199356079102), ('":"', 3.136106252670288), ('503', 3.080432971318563), ('502', 2.9783374071121216), ('306674912', 2.8921358585357666)]
Top words for pretrained_CodeBERTa neuron indx 740 [('softmax', 3.6284945011138916), ('find', 3.420825481414795), ('Optional', 3.300408363342285), ('sum', 3.030170440673828), ('output', 2.8920223474502564)]
Top words for pretrained_CodeBERTa neuron indx 2798 [('extend', 4.8172478675842285), ('flatten', 3.7560293674468994), ('Exception', 3.708153486251831), ('StopIteration', 3.557689666748047), ('word', 3.5538790822029114)]
Top words for pretrained_CodeBERTa neuron indx 4863 [('encoding', 4.547214190165202), ('Iterable', 3.5938823223114014), ('skill', 3.5639647245407104), ('mime', 3.522576093673706), ('50', 3.496046264966329)]
Top words for pretrained_CodeBERTa neuron indx 768 [('code', 3.1260906457901), ('tag', 2.8822277784347534), ('seconds', 2.694667935371399), ('replace', 2.661575436592102), ('pattern', 2.586593198776245)]
Top words for pretrained_CodeBERTa neuron indx 2830 [('lc', 3.1433526277542114), ('prefix', 2.9645793437957764), ('attr', 2.916560173034668), ('units', 2.8239996631940207), ('interpolation', 2.7266153948647633)]
Top words for pretrained_CodeBERTa neuron indx 784 [('expanded', 4.490724881490071), ('clone', 3.9404306411743164), ('unpack', 3.657672882080078), ('save', 3.4763161659240724), ('flatten', 3.431586265563965)]
Top words for pretrained_CodeBERTa neuron indx 4881 [('stdout', 5.222023010253906), ('isdir', 4.356537461280823), ('n', 3.882886370023092), ('open', 3.399647760391235), ('y', 3.325258493423462)]
Top words for pretrained_CodeBERTa neuron indx 4884 [('reshape', 2.947439432144165), ('"\\\\\\\\"', 2.8356449604034424), ('finally', 2.533358156681061), ('mean', 2.482775717973709), ('keywords', 2.470790386199951)]
Top words for pretrained_CodeBERTa neuron indx 791 [('replace', 3.7868231534957886), ('copy', 3.506434679031372), ('shutil', 3.309538960456848), ('extend', 2.9836440086364746), ('zipfile', 2.842154860496521)]
Top words for pretrained_CodeBERTa neuron indx 798 [('Iterable', 5.766702175140381), ('clone', 3.8726322650909424), ('graph', 3.6650044918060303), ('Multiply', 3.508359432220459), ('Sequence', 3.360365072886149)]
Top words for pretrained_CodeBERTa neuron indx 4896 [("'\\\\\\\\'", 3.47725248336792), ('break', 3.1873222986857095), ('StopIteration', 2.654045581817627), ('ele', 2.633749485015869), ('urlparse', 2.6333374977111816)]
Top words for pretrained_CodeBERTa neuron indx 805 [('"percent"', 3.8963470458984375), ('"uris"', 3.804790496826172), ('"children"', 3.7926690578460693), ('"NEST"', 3.657386302947998), ('"delete"', 3.6104736328125)]
Top words for pretrained_CodeBERTa neuron indx 809 [('elif', 3.5653355572674728), ('tmp', 3.4827921390533447), ('F', 3.0870832800865173), ('seek', 3.0391151905059814), ('engine', 2.9777674674987793)]
Top words for pretrained_CodeBERTa neuron indx 4908 [('keywords', 3.9418957233428955), ('ValidationException', 3.183450937271118), ('dict', 3.072561025619507), ('git', 2.9888110160827637), ('tzinfo', 2.8459689617156982)]
Top words for pretrained_CodeBERTa neuron indx 813 [('answer', 3.46738338470459), ('flatten', 2.7528059482574463), ('hit', 2.7192239284515383), ('answers', 2.7066741784413657), ('"auto"', 2.580281893412272)]
Top words for pretrained_CodeBERTa neuron indx 817 [('byte', 3.603550672531128), ('64', 3.573679425499656), ('write', 3.4777976671854653), ('final', 3.384092171986898), ('ByteStorage', 3.202845811843872)]
Top words for pretrained_CodeBERTa neuron indx 4916 [('400', 3.772932449976603), ('258', 3.57358455657959), ('gzip', 3.3087830543518066), ('301', 3.2947165966033936), ('minutes', 3.2448153495788574)]
Top words for pretrained_CodeBERTa neuron indx 821 [('302', 3.370323657989502), ('410', 3.3438376585642495), ('301', 3.268638849258423), ('filename', 3.248255536744469), ('urljoin', 3.2038116455078125)]
Top words for pretrained_CodeBERTa neuron indx 2875 [('scheme', 4.562955856323242), ('color', 3.6543456315994263), ('reshape', 3.188401937484741), ('padding', 3.106517966588338), ('streams', 3.0460094213485718)]
Top words for pretrained_CodeBERTa neuron indx 4929 [('encoding', 3.2893731594085693), ('"qargs"', 3.036560535430908), ('childNodes', 2.929729700088501), ('c', 2.9243513345718384), ('"<DIGIT>"', 2.763077735900879)]
Top words for pretrained_CodeBERTa neuron indx 834 [('302', 3.9536280632019043), ('group', 3.9394732475280763), ('sub', 3.8949387073516846), ('download', 3.42820151646932), ('perspective', 3.206035852432251)]
Top words for pretrained_CodeBERTa neuron indx 835 [('sub', 4.074045181274414), ('384', 3.9155662059783936), ('85', 3.531651020050049), ('borders', 3.500976800918579), ('9', 3.402922344207764)]
Top words for pretrained_CodeBERTa neuron indx 4936 [('Dense', 4.416478300094605), ('zeros', 3.8002285957336426), ('23', 3.55704927444458), ('Multiply', 3.4158008098602295), ('pic', 3.341504916879866)]
Top words for pretrained_CodeBERTa neuron indx 4937 [('302', 3.8215808868408203), ('cfg', 3.4344223737716675), ('border', 3.3201264142990112), ('20060', 3.053900957107544), ('paging', 3.03563129901886)]
Top words for pretrained_CodeBERTa neuron indx 847 [('tag', 3.517363727092743), ('scandir', 3.345285654067993), ('suffix', 3.2872555255889893), ('param', 3.1217625935872397), ('503', 3.007262627283732)]
Top words for pretrained_CodeBERTa neuron indx 848 [('interpolation', 3.447584901537214), ('responses', 3.3937953114509583), ('stride', 3.328557809193929), ('ceil', 3.2307393550872803), ('tmp', 3.2111282348632812)]
Top words for pretrained_CodeBERTa neuron indx 2899 [('Tensor', 4.364140510559082), ('int32', 4.1640613079071045), ('int16', 3.8123912811279297), ('FloatTensor', 3.709930658340454), ('float32', 3.555086851119995)]
Top words for pretrained_CodeBERTa neuron indx 855 [("'*'", 3.670119673013687), ('min', 3.5476291444566517), ('RED', 3.3298146724700928), ('tobytes', 3.15863037109375), ('to', 3.1349475383758545)]
Top words for pretrained_CodeBERTa neuron indx 4980 [('param', 3.5020583073298135), ('debug', 3.2319440841674805), ('hours', 3.172855854034424), ('pop', 3.158385157585144), ('undeflate', 3.107463836669922)]
Top words for pretrained_CodeBERTa neuron indx 2933 [('border', 3.2277835607528687), ('color', 3.1024508476257324), ('default', 2.9019649028778076), ('":"', 2.798234462738037), ('escape', 2.7624634504318237)]
Top words for pretrained_CodeBERTa neuron indx 4982 [('PIPE', 3.402259111404419), ('moves', 2.4702870845794678), ('144', 2.3199291229248047), ('Popen', 2.273522138595581), ('await', 2.2720498426092997)]
Top words for pretrained_CodeBERTa neuron indx 2935 [('inplace', 3.736883044242859), ('elif', 3.5656115042196737), ('except', 2.951469438020573), ('tag', 2.92475426197052), ('pretrained', 2.690881237387657)]
Top words for pretrained_CodeBERTa neuron indx 886 [('256', 4.96174693107605), ('strip', 3.918410301208496), ('fh', 3.813006281852722), ('read', 3.661646326382955), ('192', 3.658027410507202)]
Top words for pretrained_CodeBERTa neuron indx 894 [("'['", 4.483286380767822), ('nn', 4.190334320068359), ('upper', 4.146671295166016), ("'{'", 3.6438679695129395), ("']'", 3.4360102812449136)]
Top words for pretrained_CodeBERTa neuron indx 911 [('skill', 3.4150696992874146), ('shears', 3.2007020115852356), ('tmp', 3.0317723751068115), ('tuple', 2.9968754053115845), ('now', 2.9754844903945923)]
Top words for pretrained_CodeBERTa neuron indx 5008 [("'SINGLE'", 3.5117568969726562), ("'kernels'", 3.06339955329895), ("'unknown'", 3.0629823207855225), ("'PipelineDefinition'", 2.9272329807281494), ("'application'", 2.898913860321045)]
Top words for pretrained_CodeBERTa neuron indx 915 [('85', 3.889137029647827), ('attr', 3.824620246887207), ('VGG', 3.679701805114746), ('padding', 3.486121932665507), ('channels', 3.2602758407592773)]
Top words for pretrained_CodeBERTa neuron indx 2964 [('224', 3.359415054321289), ('bias', 3.022291898727417), ('429', 3.0007119178771973), ('RED', 2.955333948135376), ('padding', 2.8566067934036257)]
Top words for pretrained_CodeBERTa neuron indx 5013 [('unpack', 4.404956340789795), ("'---'", 4.109406471252441), ('transpose', 3.8345669905344644), ('channels', 3.5571093559265137), ('302', 3.531031847000122)]
Top words for pretrained_CodeBERTa neuron indx 922 [('i', 4.505380668538682), ('77', 3.322293519973755), ('pow', 3.247990608215332), ('tzinfo', 3.226821541786194), ('tuple', 3.18683922290802)]
Top words for pretrained_CodeBERTa neuron indx 927 [('add', 3.5147809982299805), ('Number', 3.468627373377482), ('exit', 2.6927998065948486), ('shuffle', 2.6751492023468018), ('is', 2.415186966901802)]
Top words for pretrained_CodeBERTa neuron indx 5037 [("'|'", 4.361322999000549), ("'_'", 3.375870962937673), ('to', 2.7794034481048584), ("'*'", 2.753000169992447), ('session', 2.7441455324490867)]
Top words for pretrained_CodeBERTa neuron indx 5045 [('system', 2.758899211883545), ('hue', 2.687530040740967), ('2', 2.624653746187687), ('update', 2.5560696125030518), ('splits', 2.5280110836029053)]
Top words for pretrained_CodeBERTa neuron indx 3004 [('pop', 2.909433205922445), ('re', 2.860791936516762), ('console', 2.7875237464904785), ('system', 2.723787307739258), ('read', 2.64005978902181)]
Top words for pretrained_CodeBERTa neuron indx 957 [('zip', 2.966860850652059), ('shuffle', 2.956989049911499), ('443', 2.672572612762451), ('ET', 2.635465621948242), ('gzip', 2.587721109390259)]
Top words for pretrained_CodeBERTa neuron indx 5056 [('NotImplementedError', 4.270043849945068), ('contrast', 3.3728414475917816), ('sourceType', 3.255195692181587), ('cfg', 3.2132660150527954), ('"}"', 3.0909444093704224)]
Top words for pretrained_CodeBERTa neuron indx 5061 [('arg', 3.960167407989502), ('attempt', 3.200523853302002), ('builtins', 3.1856764554977417), ('opt', 3.10156786441803), ('65536', 2.989657402038574)]
Top words for pretrained_CodeBERTa neuron indx 3023 [('any', 3.4682729244232178), ('lower', 3.0140302181243896), ('view', 3.0068857669830322), ('to', 2.9260759353637695), ('A', 2.738918423652649)]
Top words for pretrained_CodeBERTa neuron indx 5072 [('ndarray', 2.9462313055992126), ('":"', 2.5855570634206138), ('all', 2.5774691104888916), ('autocompleter', 2.571868896484375), ('";"', 2.5468183755874634)]
Top words for pretrained_CodeBERTa neuron indx 978 [('Session', 3.396646022796631), ('29', 3.3396624326705933), ('subprocess', 3.33209490776062), ('192', 3.2976601123809814), ('filename', 3.2453769759127966)]
Top words for pretrained_CodeBERTa neuron indx 983 [('strip', 4.105457107226054), ('dumps', 3.68342653910319), ('tar', 3.6662102937698364), ('zipfile', 3.4300206899642944), ('suffix', 3.411663770675659)]
Top words for pretrained_CodeBERTa neuron indx 5081 [('basename', 3.0464391708374023), ('quote', 2.8857297897338867), ('dirname', 2.847820281982422), ('country', 2.7824950218200684), ('prefix', 2.76900186141332)]
Top words for pretrained_CodeBERTa neuron indx 995 [('theme', 3.232375383377075), ('minutes', 3.19042706489563), ('skill', 3.010662794113159), ('plugins', 2.997842868169149), ('eq', 2.8932697772979736)]
Top words for pretrained_CodeBERTa neuron indx 5109 [("'%'", 3.9708199501037598), ('exp', 3.4789113998413086), ('mul', 3.419274091720581), ('pow', 3.3903396129608154), ('ceil', 3.378242254257202)]
Top words for pretrained_CodeBERTa neuron indx 1021 [("')'", 3.123878002166748), ('answer', 3.0675430297851562), ('strip', 3.0467900037765503), ('timedelta', 2.9505820274353027), ('zeros', 2.8208792209625244)]
Top words for pretrained_CodeBERTa neuron indx 3071 [('quote', 3.9396557807922363), ('KeyboardInterrupt', 3.6660618782043457), ('stdin', 3.579848885536194), ("';'", 3.417635440826416), ('extend', 3.2670419216156006)]
Top words for pretrained_CodeBERTa neuron indx 3072 [('theme', 3.3954944610595703), ('exceptions', 3.214749336242676), ('YELLOW', 3.1485135555267334), ('Request', 3.03472363948822), ('BILINEAR', 2.697160482406616)]
Top words for pretrained_CodeBERTa neuron indx 1033 [("'{'", 3.144562244415283), ('struct', 3.1357510089874268), ('barrier', 2.9239602088928223), ('answerers', 2.7755513191223145), ("')'", 2.685638904571533)]
Top words for pretrained_CodeBERTa neuron indx 5144 [('fcntl', 3.4397590160369873), ('symbols', 3.3730456829071045), ('90', 2.9134562015533447), ('20000', 2.881958246231079), ('numpy', 2.7235392332077026)]
Top words for pretrained_CodeBERTa neuron indx 3104 [('narrow', 3.2261099815368652), ('tzinfo', 2.684356927871704), ('float', 2.6669078213827953), ('PIL', 2.656045436859131), ('unicode', 2.6446237564086914)]
Top words for pretrained_CodeBERTa neuron indx 3105 [('gamma', 3.1219695409139), ('except', 3.0513988650122355), ('attr', 3.0424365997314453), ('to', 2.810067892074585), ('node', 2.776119589805603)]
Top words for pretrained_CodeBERTa neuron indx 1059 [('engine', 3.7938108444213867), ('attempt', 3.4769155979156494), ('now', 3.4739240407943726), ('find', 3.459954261779785), ('console', 3.455662727355957)]
Top words for pretrained_CodeBERTa neuron indx 3107 [('hue', 3.0559375882148743), ('Sequence', 3.031245470046997), ('perspective', 2.721142530441284), ('and', 2.5134986082938586), ("']'", 2.399406989415487)]
Top words for pretrained_CodeBERTa neuron indx 1079 [('23', 3.60841703414917), ('subprocess', 3.446787714958191), ('109', 3.262744903564453), ('copy', 2.9583474159240724), ('36', 2.809627890586853)]
Top words for pretrained_CodeBERTa neuron indx 5175 [('PIL', 3.920435905456543), ('update', 3.6417603492736816), ('softmax', 3.568150520324707), ('120000', 3.0936782360076904), ('parseString', 3.0876448154449463)]
Top words for pretrained_CodeBERTa neuron indx 5186 [('narrow', 2.9576319456100464), ('flatten', 2.722524881362915), ('dirpath', 2.6406633853912354), ("'*'", 2.597423329949379), ("'.'", 2.5476751944114424)]
Top words for pretrained_CodeBERTa neuron indx 1096 [('patterns', 3.6648982048034666), ('getattr', 3.623922427495321), ('stack', 3.0286917686462402), ('41', 3.027236223220825), ('query', 3.0042833523316816)]
Top words for pretrained_CodeBERTa neuron indx 3159 [('urljoin', 2.965376138687134), ('builtins', 2.9476213455200195), ('line', 2.855968157450358), ('seconds', 2.7113999128341675), ("'*'", 2.6555520594120026)]
Top words for pretrained_CodeBERTa neuron indx 5212 [('system', 3.4358887672424316), ('println', 3.415989398956299), ('debug', 3.0266799926757812), ('F', 2.6774152517318726), ('__builtin__', 2.66279399394989)]
Top words for pretrained_CodeBERTa neuron indx 3180 [('99', 3.990339438120524), ('update', 3.8322505950927734), ('find', 3.5883827209472656), ('encode', 3.307373046875), ('torch', 3.1849736522983862)]
Top words for pretrained_CodeBERTa neuron indx 1144 [('units', 3.7059688170750937), ('gamma', 3.6716078917185464), ('activation', 3.4835384289423623), ('bias', 3.4254231452941895), ('filtered', 3.27141535282135)]
Top words for pretrained_CodeBERTa neuron indx 1154 [('Number', 4.074961185455322), ('Trie', 3.6988996267318726), ('Color', 3.5787293910980225), ('BytesIO', 3.388778805732727), ('65536', 3.102821111679077)]
Top words for pretrained_CodeBERTa neuron indx 5253 [('2048', 3.757223491668701), ('140', 3.6152000427246094), ('25000', 3.4008736610412598), ('512', 3.3883381442325873), ('suggestions', 3.318516413370768)]
Top words for pretrained_CodeBERTa neuron indx 3208 [('accuracy', 3.126877546310425), ('"="', 3.042900323867798), ('":"', 2.969826062520345), ('charset', 2.848534047603607), ('symbols', 2.684430241584778)]
Top words for pretrained_CodeBERTa neuron indx 1168 [('34', 3.845332145690918), ('override', 3.5339725017547607), ('exp', 3.365569829940796), ('index', 3.117979679788862), ('j', 3.1107937812805178)]
Top words for pretrained_CodeBERTa neuron indx 3224 [('permute', 4.253454685211182), ('startswith', 3.7691450119018555), ('opt', 3.655073324839274), ('clamp_', 3.384740471839905), ("'{}{}'", 3.383224368095398)]
Top words for pretrained_CodeBERTa neuron indx 3229 [('50000', 3.1722252368927), ('redirect', 3.154284715652466), ('error', 3.1029012203216553), ('headers', 2.900225379250266), ('bytes', 2.886261224746704)]
Top words for pretrained_CodeBERTa neuron indx 5280 [('symbols', 3.3960713148117065), ('365', 2.968473196029663), ("'/lstm_cell/'", 2.763885498046875), ('50', 2.6914116541544595), ("'pytest'", 2.6574153900146484)]
Top words for pretrained_CodeBERTa neuron indx 1200 [('429', 3.9008681774139404), ('503', 3.8769657611846924), ('202', 3.7017869353294373), ('502', 3.5869460701942444), ('errno', 3.572713017463684)]
Top words for pretrained_CodeBERTa neuron indx 3248 [('"|"', 3.0115277767181396), ('error', 2.9251785278320312), ('write', 2.8243434031804404), ("b''", 2.820303440093994), ('im', 2.805258631706238)]
Top words for pretrained_CodeBERTa neuron indx 1203 [('lc', 3.5431196689605713), ('sourceType', 3.320088028907776), ('dim', 3.1000795364379883), ('Multiply', 3.08138108253479), ('NotImplementedError', 3.051701068878174)]
Top words for pretrained_CodeBERTa neuron indx 5300 [('numbers', 3.6852742036183677), ('unicode', 3.1179027557373047), ('country', 2.859574794769287), ('continue', 2.8211824893951416), ('hasattr', 2.7359228134155273)]
Top words for pretrained_CodeBERTa neuron indx 3256 [('Image', 3.026546029483571), ('exp', 2.780799388885498), ('IS_ANSI_TERMINAL', 2.7780730724334717), ('dirname', 2.748913288116455), ('resize', 2.6982375979423523)]
Top words for pretrained_CodeBERTa neuron indx 3261 [('io', 3.483003854751587), ('shuffle', 3.332982063293457), ('zip', 3.270562767982483), ('argv', 3.014089822769165), ('descend', 2.9897801876068115)]
Top words for pretrained_CodeBERTa neuron indx 1216 [('override', 3.846467685699463), ('elif', 3.771700620651245), ('struct', 3.704498529434204), ('format', 3.687834062576294), ('lc', 3.646166682243347)]
Top words for pretrained_CodeBERTa neuron indx 3265 [('inplace', 3.2587608098983765), ('escape', 3.240679144859314), ('XML', 3.013702869415283), ('decoded', 2.85030996799469), ('except', 2.8349994892297787)]
Top words for pretrained_CodeBERTa neuron indx 3267 [('mean', 3.546845555305481), ('pretrained', 3.4714878499507904), ('println', 3.383209705352783), ('ref', 3.298898696899414), ('debug', 3.2078239917755127)]
Top words for pretrained_CodeBERTa neuron indx 3276 [("'.{}'", 2.549161672592163), ('answer', 2.1466546058654785), ("'{}.local.'", 2.1103813648223877), ('extract', 2.1047277450561523), ("'**/*.json'", 2.0695924758911133)]
Top words for pretrained_CodeBERTa neuron indx 1231 [('tzinfo', 3.9245702028274536), ('row', 3.5115309357643127), ('mean', 3.4847291707992554), ('y', 3.4831410135541643), ('outfile', 3.482408285140991)]
Top words for pretrained_CodeBERTa neuron indx 5343 [('Sequence', 3.3793794314066568), ('Iterable', 3.2782680988311768), ('exp', 2.9447078704833984), ('transpose', 2.78469709555308), ('scheme', 2.5437183380126953)]
Top words for pretrained_CodeBERTa neuron indx 1250 [('mode', 3.5006011856926813), ('gui', 3.4622695446014404), ('kwargs', 3.3555750402998417), ('byte', 3.2385058403015137), ('zipfile', 3.2110886573791504)]
Top words for pretrained_CodeBERTa neuron indx 3303 [('terminated', 3.6600899696350098), ('ndim', 2.9881532986958823), ('"<td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td><td>%s</td></tr>"', 2.6707406044006348), ('AlexNet', 2.597459316253662), ('"$"', 2.593613862991333)]
Top words for pretrained_CodeBERTa neuron indx 5355 [('365', 3.7882473468780518), ('24', 3.1638630628585815), ('unlink', 3.1569831371307373), ('Session', 3.0178089141845703), ('units', 2.951518177986145)]
Top words for pretrained_CodeBERTa neuron indx 1262 [('softmax', 4.132000684738159), ('activation', 3.69539475440979), ('extend', 3.608872175216675), ('unpack', 3.379896640777588), ('keepdims', 3.364638090133667)]
Top words for pretrained_CodeBERTa neuron indx 1269 [('trie', 3.661912536621094), ('"-"', 3.1138253211975098), ('cost', 3.1095770597457886), ('save', 2.9652211666107178), ('matchall', 2.914461851119995)]
Top words for pretrained_CodeBERTa neuron indx 1272 [('format', 3.558392057418823), ('byte', 3.33648943901062), ('expand', 3.1829506158828735), ('Timeout', 3.1772725582122803), ('join', 3.13702968094084)]
Top words for pretrained_CodeBERTa neuron indx 3348 [('default', 3.3416647911071777), ('extend', 3.1487648487091064), ('dist', 3.140145778656006), ('border', 3.0590686798095703), ('bytes', 2.8094351291656494)]
Top words for pretrained_CodeBERTa neuron indx 1302 [('tag', 2.9857598543167114), ('quality', 2.9835129976272583), ('args', 2.9689200719197593), ('force', 2.8929232358932495), ('Optional', 2.7555623054504395)]
Top words for pretrained_CodeBERTa neuron indx 3355 [('class', 3.460694670677185), ('filter', 3.0927224159240723), ('sleep', 3.0010361671447754), ('q', 2.827077865600586), ('borders', 2.635470390319824)]
Top words for pretrained_CodeBERTa neuron indx 3363 [('engine', 4.118607044219971), ('history', 3.575148105621338), ('inplace', 3.3819364309310913), ('locales', 3.3769021034240723), ('completer', 3.3028906981150308)]
Top words for pretrained_CodeBERTa neuron indx 1331 [('urlencode', 3.7643837928771973), ('items', 3.638657569885254), ('coeffs', 2.978847026824951), ('hasattr', 2.7966325283050537), ('ndarray', 2.7608806490898132)]
Top words for pretrained_CodeBERTa neuron indx 3382 [('loads', 3.548157513141632), ('moves', 3.243889808654785), ('childNodes', 3.178102493286133), ('splits', 3.1092352867126465), ('scandir', 3.1012237071990967)]
Top words for pretrained_CodeBERTa neuron indx 1337 [('narrow', 3.4441457986831665), ('replace', 3.381731390953064), ('Sequence', 3.192512035369873), ('stream', 2.85843665259225), ('merge', 2.6991109916142055)]
Top words for pretrained_CodeBERTa neuron indx 3393 [('label', 3.0922415256500244), ('request', 2.88437830137484), ('outfile', 2.7699100971221924), ('tag', 2.691624701023102), ('encoding', 2.6632160345713296)]
Top words for pretrained_CodeBERTa neuron indx 3395 [('exp', 2.865506172180176), ('502', 2.8154634535312653), ('seconds', 2.7429500818252563), ('shortcuts', 2.6705989837646484), ('gzip', 2.627487897872925)]
Top words for pretrained_CodeBERTa neuron indx 3398 [('copy', 3.295060563087463), ('merge', 3.169439617225102), ('KeyboardInterrupt', 3.058516263961792), ('to', 2.9050254821777344), ('name', 2.805329646383013)]
Top words for pretrained_CodeBERTa neuron indx 1363 [('Tensor', 3.8935447533925376), ('attrib', 3.8762704133987427), ('border', 3.745345115661621), ('preferred', 3.6162213683128357), ('unpack', 3.4853649139404297)]
Top words for pretrained_CodeBERTa neuron indx 1369 [('">"', 3.2969348430633545), ('stride', 3.2896783351898193), ('120', 3.1444449424743652), ('title', 3.040903964745147), ('mode', 2.9639681268621376)]
Top words for pretrained_CodeBERTa neuron indx 1374 [('fh', 3.4593732357025146), ('system', 3.1217033863067627), ('extract', 3.069751262664795), ('println', 2.8728766441345215), ('preferences', 2.871936591466268)]
Top words for pretrained_CodeBERTa neuron indx 1380 [('mul', 3.716655969619751), ('sleep', 3.5307376384735107), ('correct', 3.1302796602249146), ('seek', 3.0622270107269287), ('140', 3.0256102085113525)]
Top words for pretrained_CodeBERTa neuron indx 3429 [('urljoin', 3.9454264640808105), ('time', 3.681352694829305), ('Timeout', 3.591299533843994), ("'#eeeeee'", 3.00312602519989), ("'text/xml'", 2.782390832901001)]
Top words for pretrained_CodeBERTa neuron indx 3441 [("'://'", 3.742138385772705), ('ratio', 3.6180930818830217), ('34', 3.479313373565674), ('interpolation', 3.191133601324899), ('affine', 2.917165994644165)]
Top words for pretrained_CodeBERTa neuron indx 1397 [('upper', 4.533857345581055), ('color', 4.394659519195557), ('uniform', 3.7222775545987217), ('border', 3.6788742542266846), ('brightness', 3.5631872415542603)]
Top words for pretrained_CodeBERTa neuron indx 1399 [('inplace', 3.9521007537841797), ('BICUBIC', 3.0659337043762207), ('keywords', 2.9554824829101562), ('response', 2.7507815625932484), ('message', 2.7168586254119873)]
Top words for pretrained_CodeBERTa neuron indx 3448 [('engines', 3.0591846704483032), ('RED', 3.0484702587127686), ("')'", 3.04353404045105), ('numbers', 2.9023807048797607), ('type', 2.895327568054199)]
Top words for pretrained_CodeBERTa neuron indx 1413 [('float', 3.4523397513798306), ('int', 3.357678461819887), ("'../..'", 3.3077735900878906), ('scheme', 3.200087070465088), ('days', 3.1936404705047607)]
Top words for pretrained_CodeBERTa neuron indx 1439 [('mul', 4.458135604858398), ('d', 4.169916709264119), ('tzinfo', 4.114359378814697), ('tmp', 3.855735182762146), ('degrees', 3.815697193145752)]
Top words for pretrained_CodeBERTa neuron indx 1440 [('stack', 3.252094268798828), ('cat', 2.6574259996414185), ('strip', 2.4479658206303916), ('suffix', 2.4084888696670532), ('mul', 2.389141082763672)]
Top words for pretrained_CodeBERTa neuron indx 3497 [('childNodes', 4.3606157302856445), ('crop', 4.1890555918216705), ('contiguous', 4.000269412994385), ('pad', 3.886390209197998), ('Dense', 3.7591970443725584)]
Top words for pretrained_CodeBERTa neuron indx 3501 [('splits', 3.4135823249816895), ('">"', 3.2953848838806152), ('scandir', 3.158043384552002), ('URLError', 3.072951316833496), ('504', 2.949310064315796)]
Top words for pretrained_CodeBERTa neuron indx 1454 [('params', 3.544762909412384), ('kwargs', 3.3982361434622015), ('headers', 3.059501062739979), ('errno', 3.034425377845764), ('url', 2.9816911687556003)]
Top words for pretrained_CodeBERTa neuron indx 3504 [('mean', 4.553575754165649), ('find', 4.251805782318115), ('language', 4.000828606741769), ('302', 3.8877651691436768), ('print', 3.6849430040879683)]
Top words for pretrained_CodeBERTa neuron indx 3507 [('KeyError', 3.5260140895843506), ('elif', 2.982946286330352), ('StopIteration', 2.9770076274871826), ('ValueError', 2.799565553665161), ('strip', 2.7570671240488687)]
Top words for pretrained_CodeBERTa neuron indx 3512 [('pred', 4.162941336631775), ('302', 3.7615160942077637), ('decompress', 3.5900156497955322), ('ioctl', 3.1104607582092285), ('StopIteration', 3.0918681621551514)]
Top words for pretrained_CodeBERTa neuron indx 1485 [('cat', 4.226424694061279), ('classes', 4.008634646733602), ('group', 3.796208381652832), ('exceptions', 3.699444055557251), ('arg', 3.677668333053589)]
Top words for pretrained_CodeBERTa neuron indx 1487 [('A', 4.0466508865356445), ('narrow', 3.5091441869735718), ('lower', 3.298368215560913), ('pad', 2.8743265867233276), ('min', 2.8364606698354087)]
Top words for pretrained_CodeBERTa neuron indx 1489 [('"$"', 3.5512518882751465), ('skill', 3.273416519165039), ('quote', 3.15649676322937), ('reshape', 2.994381904602051), ('tzinfo', 2.779074192047119)]
Top words for pretrained_CodeBERTa neuron indx 1508 [('find', 2.5483150482177734), ('query', 2.4077580083500254), ('topk', 2.3256009817123413), ('hflip', 2.324063539505005), ('palette', 2.304589033126831)]
Top words for pretrained_CodeBERTa neuron indx 1536 [('"}"', 3.2336812814076743), ('code', 3.0703502893447876), ('YELLOW', 2.9171178340911865), ('seconds', 2.9079854488372803), ('replace', 2.846260726451874)]
Top words for pretrained_CodeBERTa neuron indx 1540 [('force', 3.466823101043701), ('message', 3.2584899425506593), ('shape', 3.15090594291687), ('matrix', 3.0302302042643228), ('debug', 2.963733434677124)]
Top words for pretrained_CodeBERTa neuron indx 1571 [('and', 3.5370101728222587), ('Sequence', 3.299459139506022), ("'['", 3.2408547401428223), ("']'", 3.2080866495768228), ('pow', 3.203106641769409)]
Top words for pretrained_CodeBERTa neuron indx 1573 [('argv', 3.5847039222717285), ('terminated', 3.5725340843200684), ('enhance', 3.5624728202819824), ('"delete"', 3.381499767303467), ('unpack', 3.3266704082489014)]
Top words for pretrained_CodeBERTa neuron indx 3638 [('softmax', 3.2419499158859253), ('33', 2.957785725593567), ('ceil', 2.9292080402374268), ('31', 2.8941229581832886), ('32', 2.8113832473754883)]
Top words for pretrained_CodeBERTa neuron indx 3643 [('scheme', 4.2064971923828125), ('color', 3.6047760248184204), ('reshape', 3.5263161659240723), ('torch', 3.4253202515679435), ('language', 3.382509469985962)]
Top words for pretrained_CodeBERTa neuron indx 1603 [('sub', 4.078083038330078), ('exp', 3.4466207027435303), ('85', 3.3124141693115234), ('5', 3.1563738346099854), ('unicode', 3.0950310230255127)]
Top words for pretrained_CodeBERTa neuron indx 1615 [('stack', 3.2828190326690674), ('error', 3.2816414833068848), ('hexdigest', 3.2369534969329834), ('param', 2.950967709223429), ('32', 2.875377893447876)]
Top words for pretrained_CodeBERTa neuron indx 3667 [('Tensor', 4.492444038391113), ('int32', 3.817643642425537), ('int16', 3.688982367515564), ('KeyError', 3.6195785999298096), ('float32', 3.619061748186747)]
Top words for pretrained_CodeBERTa neuron indx 3678 [('Popen', 3.1059114933013916), ('clone', 2.5326335430145264), ('xpath', 2.519691801071167), ('preferences', 2.400606737534205), ('Session', 2.386749505996704)]
Top words for pretrained_CodeBERTa neuron indx 1643 [('"parallax"', 3.889284372329712), ('192', 3.858335018157959), ('uniform', 3.262505357915705), ('cfg', 3.2390016317367554), ('443', 3.2218551635742188)]
Top words for pretrained_CodeBERTa neuron indx 3701 [('32', 3.161787509918213), ('cfg', 3.0075109004974365), ('"="', 2.940909113202776), ('NotImplementedError', 2.7754454612731934), ('builtins', 2.7310335636138916)]
Top words for pretrained_CodeBERTa neuron indx 3714 [('remove', 3.2535442113876343), ('add', 2.965819835662842), ('update', 2.767122507095337), ('"┐"', 2.5682928562164307), ('Image', 2.5617397523978176)]
Top words for pretrained_CodeBERTa neuron indx 1674 [('items', 4.283290863037109), ('item', 3.751780092716217), ('children', 3.242667496204376), ('child', 3.194486379623413), ('list', 3.1236408267702376)]
Top words for pretrained_CodeBERTa neuron indx 1681 [('keepdims', 3.9233832359313965), ('Multiply', 3.0242247581481934), ('bias', 2.923755407333374), ('issubclass', 2.7934701442718506), ('24', 2.7782639265060425)]
Top words for pretrained_CodeBERTa neuron indx 3732 [('224', 3.2192187309265137), ('429', 2.930295467376709), ('202', 2.8544039130210876), ('io', 2.813300609588623), ('RED', 2.5856332778930664)]
Top words for pretrained_CodeBERTa neuron indx 1691 [('404', 4.021466255187988), ('argv', 3.689037561416626), ('flatten', 3.5101704597473145), ('410', 3.4738709131876626), ('find', 3.417780876159668)]
Top words for pretrained_CodeBERTa neuron indx 1693 [('engine', 3.0339996814727783), ('error', 2.9995288848876953), ('50', 2.8940923611323037), ('result', 2.8614014834165573), ('log', 2.84470477104187)]
Top words for pretrained_CodeBERTa neuron indx 1695 [('is', 2.8377281036721653), ('Number', 2.7809433937072754), ('descend', 2.688926935195923), ('hasattr', 2.607323169708252), ('activation', 2.5988341768582663)]
Top words for pretrained_CodeBERTa neuron indx 3744 [('365', 2.876870632171631), ('50', 2.386303881804148), ('"""str->str"""', 2.1870601177215576), ('symbols', 2.1215734481811523), ("'/lstm_cell/'", 2.111957311630249)]
Top words for pretrained_CodeBERTa neuron indx 3768 [('update', 2.153184413909912), ("'BoxSize'", 1.99709951877594), ('arg', 1.928091049194336), ("'ScheduleComponent'", 1.8859316110610962), ('None', 1.824568888375653)]
Top words for pretrained_CodeBERTa neuron indx 3772 [('re', 3.1427476555109024), ('pop', 3.0361351569493613), ('extract', 2.81535005569458), ('replace', 2.680681526660919), ('sub', 2.627458095550537)]
Top words for pretrained_CodeBERTa neuron indx 1725 [('zip', 4.028756062189738), ('io', 3.649791717529297), ('shuffle', 3.153487205505371), ('byte', 3.106984853744507), ('ele', 2.9309581518173218)]
Top words for pretrained_CodeBERTa neuron indx 1763 [('dom', 3.337539625167847), ('minutes', 3.299778699874878), ('childNodes', 3.0737874507904053), ('save', 2.91489782333374), ('perspective', 2.8931655883789062)]
Top words for pretrained_CodeBERTa neuron indx 3822 [('endpoints', 2.769532402356466), ('continue', 2.3907063007354736), ('is', 2.3757695409188786), ("'wss'", 2.2514357566833496), ('_', 2.1763135313987734)]
Top words for pretrained_CodeBERTa neuron indx 1781 [('nn', 3.8390004634857178), ('coeffs', 3.702319860458374), ('softmax', 3.5111920833587646), ('43', 3.3316900730133057), ('permute', 3.2956912517547607)]
Top words for pretrained_CodeBERTa neuron indx 3839 [('KeyboardInterrupt', 4.184037685394287), ('67', 4.096924304962158), ('"-"', 3.6057848930358887), ('descend', 3.545929431915283), ('"@"', 3.5129494667053223)]
Top words for pretrained_CodeBERTa neuron indx 3849 [('ValidationException', 3.325537919998169), ('301', 3.230130910873413), ('Response', 3.133304977416992), ('label', 2.875046968460083), ('192', 2.874969482421875)]
Top words for pretrained_CodeBERTa neuron indx 1807 [('history', 3.4081878662109375), ('ndim', 3.1607417265574136), ('shear', 3.1412261962890624), ('get', 2.755405447699807), ('find', 2.747847318649292)]
Top words for pretrained_CodeBERTa neuron indx 3877 [('numpy', 4.075211048126221), ('attr', 3.4054590463638306), ('63', 3.3815595507621765), ('tzinfo', 3.262500762939453), ('argv', 3.2105472087860107)]
Top words for pretrained_CodeBERTa neuron indx 1839 [('s', 3.6122732162475586), ('timeout', 3.3476378122965493), ('round', 3.306900453567505), ('autocompleter', 3.1189682483673096), ('parseString', 2.802616834640503)]
Top words for pretrained_CodeBERTa neuron indx 1859 [('ET', 3.508483648300171), ('expand', 3.4316882491111755), ('elem', 3.06349778175354), ('gzip', 3.015471577644348), ('502', 2.973438262939453)]
Top words for pretrained_CodeBERTa neuron indx 3907 [('90', 2.9301700592041016), ('communicate', 2.686147928237915), ('unicode', 2.570889711380005), ('childNodes', 2.526212692260742), ('25', 2.4954237937927246)]
Top words for pretrained_CodeBERTa neuron indx 1864 [('patterns', 3.902501440048218), ('getattr', 3.401481548945109), ('"%s-%s-%s-%s"', 3.1983702182769775), ('Multiply', 2.8154866695404053), ('time', 2.809016227722168)]
Top words for pretrained_CodeBERTa neuron indx 1873 [('isinstance', 3.390395293633143), ('clone', 2.9949381351470947), ('timedelta', 2.833681344985962), ('attrib', 2.7144083976745605), ('host', 2.659283603940691)]
Top words for pretrained_CodeBERTa neuron indx 1893 [('")"', 3.2173123359680176), ('";"', 3.1917434334754944), ('"$"', 3.160104513168335), ('quote', 2.821685791015625), ('":"', 2.7814878622690835)]
Top words for pretrained_CodeBERTa neuron indx 1921 [('descend', 3.1555979251861572), ('params', 2.980290581782659), ('headers', 2.746231187473644), ('communicate', 2.707777738571167), ('randint', 2.6178240537643434)]
Top words for pretrained_CodeBERTa neuron indx 3985 [('enhance', 3.126258452733358), ('quote', 3.056295871734619), ('keepdims', 2.8598732948303223), ('shears', 2.7507129907608032), ('"There\\', 2.7009847164154053)]
Top words for pretrained_CodeBERTa neuron indx 1947 [('shear', 3.9143306255340575), ('netloc', 3.5940020084381104), ('attempt', 3.3237709999084473), ('sprint', 3.3067049980163574), ('160', 3.2761707305908203)]
Top words for pretrained_CodeBERTa neuron indx 1971 [('pop', 3.505215565363566), ('tensor', 3.171346551179886), ('Color', 3.1581006050109863), ('StopIteration', 3.1528854370117188), ('elif', 3.1410030352102742)]
Top words for pretrained_CodeBERTa neuron indx 4024 [('fcntl', 2.890754461288452), ('border', 2.803214907646179), ('exp', 2.7891457080841064), ('dirname', 2.677412509918213), ('Image', 2.6563680943320778)]
Top words for pretrained_CodeBERTa neuron indx 1984 [('elif', 3.6216642792160445), ('arg', 3.50288724899292), ('struct', 3.478574275970459), ('lc', 3.4084866046905518), ('device', 3.4065394401550293)]
Top words for pretrained_CodeBERTa neuron indx 4042 [('coeffs', 3.172747254371643), ("'['", 3.10663104057312), ('find', 3.065189838409424), ("'exit'", 3.0362045764923096), ("'{'", 3.0199973583221436)]
Top words for pretrained_CodeBERTa neuron indx 4043 [('tmp', 3.4425179958343506), ('quote', 3.3258049488067627), ('sub', 3.015143394470215), ('println', 2.955479383468628), ('dirname', 2.918041944503784)]
Top words for pretrained_CodeBERTa neuron indx 1999 [('row', 3.383234202861786), ('Image', 3.3817520702586457), ('tzinfo', 3.350716471672058), ('accuracy', 3.2838540077209473), ('now', 3.2576853036880493)]
Top words for pretrained_CodeBERTa neuron indx 2002 [('io', 3.2882091999053955), ('upper', 3.251528024673462), ('NotImplementedError', 3.214487075805664), ('lower', 3.0019330978393555), ('tar', 2.86541485786438)]
Top words for pretrained_CodeBERTa neuron indx 4051 [('h', 2.8729023592812672), ('unicode', 2.7765634059906006), ('total_time', 2.611816167831421), ('fake_headers', 2.521911144256592), ("'.'", 2.4925528271444914)]
Top words for pretrained_CodeBERTa neuron indx 2018 [('mode', 3.6873911221822104), ('32', 3.525707483291626), ('bytes', 3.2835652828216553), ('escape', 3.225603699684143), ('encoding', 3.180192470550537)]
Top words for pretrained_CodeBERTa neuron indx 2030 [('extend', 3.8186771869659424), ('softmax', 3.662696123123169), ('nrow', 3.5599027633666993), ('activation', 3.465141932169596), ('padding', 3.368814810117086)]
Top words for pretrained_CodeBERTa neuron indx 2037 [('extend', 3.669829845428467), ('trie', 3.5973514556884765), ('shuffle', 3.200530529022217), ('save', 3.107646369934082), ('result', 3.0085357427597046)]
Top words for pretrained_CodeBERTa neuron indx 2044 [('round', 3.480631160736084), ('strip', 3.048060496648153), ('quote', 3.0238654613494873), ('sleep', 2.9198999404907227), ('finally', 2.707734227180481)]
Creating control dataset for pretrained_CodeBERTa POS tagging task

pretrained_CodeBERTa_control_task Selectivity (Diff. between true task and probing task performance):  0.6746575342465754
~~~~~~~~~~~~~~~~~~~~~~~Summary~~~~~~~~~~~~~~~~~~~~~~~
Experimental results for pretrained_CodeBERTa:
Baseline score (probing using all neurons, 768 each, of all layers 7) :{'__OVERALL__': 0.8993150684931507, 'NAME': 0.9671232876712329, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.6328767123287671}

The accuracy when only using the intercept:{'__OVERALL__': 0.25, 'NAME': 0.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 1.0}

Independent layerwise probing:
Layer 0:{'__OVERALL__': 0.8842465753424658, 'NAME': 0.9698630136986301, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.5780821917808219}
Layer 1:{'__OVERALL__': 0.8986301369863013, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.6191780821917808}
Layer 2:{'__OVERALL__': 0.9041095890410958, 'NAME': 0.9671232876712329, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6547945205479452}
Layer 3:{'__OVERALL__': 0.9136986301369863, 'NAME': 0.9698630136986301, 'STRING': 0.9972602739726028, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.6904109589041096}
Layer 4:{'__OVERALL__': 0.9301369863013699, 'NAME': 0.9753424657534246, 'STRING': 0.9972602739726028, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.7589041095890411}
Layer 5:{'__OVERALL__': 0.9273972602739726, 'NAME': 0.7698630136986301, 'STRING': 1.0, 'NUMBER': 0.9726027397260274, 'KEYWORD': 0.9671232876712329}
Layer 6:{'__OVERALL__': 0.9116438356164384, 'NAME': 0.7041095890410959, 'STRING': 0.9972602739726028, 'NUMBER': 0.9753424657534246, 'KEYWORD': 0.9698630136986301}

'Incremental-layerwise probing:
Layer [0]:{'__OVERALL__': 0.9089041095890411, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6547945205479452}
Layer [0, 1]:{'__OVERALL__': 0.8993150684931507, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6164383561643836}
Layer [0, 1, 2]:{'__OVERALL__': 0.9041095890410958, 'NAME': 0.9260273972602739, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.6931506849315069}
Layer [0, 1, 2, 3]:{'__OVERALL__': 0.9054794520547945, 'NAME': 0.8986301369863013, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.726027397260274}
Layer [0, 1, 2, 3, 4]:{'__OVERALL__': 0.9054794520547945, 'NAME': 1.0, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.6246575342465753}
Layer [0, 1, 2, 3, 4, 5]:{'__OVERALL__': 0.9034246575342466, 'NAME': 0.9315068493150684, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.684931506849315}
Layer [0, 1, 2, 3, 4, 5, 6]:{'__OVERALL__': 0.9068493150684932, 'NAME': 0.9972602739726028, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.6328767123287671}

select minimum layers:(LS+CC+LCA)
Layerwise (LS):To lose 0.03*100% accuracy based on all layers, keep the layers from 0 to 0
The number of neurons to keep is 768
The accuracy is:{'__OVERALL__': 0.9089041095890411, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6547945205479452}
Percentage reduction (neurons):0.8571428571428572

Clustering based on the layers above: 0 to 0:
When no clustering:
the probing result is {'__OVERALL__': 0.8856164383561644, 'NAME': 0.9671232876712329, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.5780821917808219}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 107
The accuracy of the minimum neuron set is {'__OVERALL__': 0.928082191780822, 'NAME': 0.9863013698630136, 'STRING': 0.9917808219178083, 'NUMBER': 0.9753424657534246, 'KEYWORD': 0.7589041095890411}

Clustering threshold:0.3
The number of independent neurons:764
The number of clusters:768
The probing result (CC score) is :{'__OVERALL__': 0.8753424657534247, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.5260273972602739}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 268
The accuracy of the minimum neuron set is {'__OVERALL__': 0.8965753424657534, 'NAME': 0.9424657534246575, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.6547945205479452}

Layerwise (LS):To lose 0.02*100% accuracy based on all layers, keep the layers from 0 to 0
The number of neurons to keep is 768
The accuracy is:{'__OVERALL__': 0.9089041095890411, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6547945205479452}
Percentage reduction (neurons):0.8571428571428572

Clustering based on the layers above: 0 to 0:
When no clustering:
the probing result is {'__OVERALL__': 0.8856164383561644, 'NAME': 0.9671232876712329, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.5780821917808219}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 107
The accuracy of the minimum neuron set is {'__OVERALL__': 0.928082191780822, 'NAME': 0.9863013698630136, 'STRING': 0.9917808219178083, 'NUMBER': 0.9753424657534246, 'KEYWORD': 0.7589041095890411}

Clustering threshold:0.3
The number of independent neurons:764
The number of clusters:768
The probing result (CC score) is :{'__OVERALL__': 0.8753424657534247, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.5260273972602739}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 268
The accuracy of the minimum neuron set is {'__OVERALL__': 0.8965753424657534, 'NAME': 0.9424657534246575, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.6547945205479452}

Layerwise (LS):To lose 0.01*100% accuracy based on all layers, keep the layers from 0 to 0
The number of neurons to keep is 768
The accuracy is:{'__OVERALL__': 0.9089041095890411, 'NAME': 0.9863013698630136, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.6547945205479452}
Percentage reduction (neurons):0.8571428571428572

Clustering based on the layers above: 0 to 0:
When no clustering:
the probing result is {'__OVERALL__': 0.8856164383561644, 'NAME': 0.9671232876712329, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.5780821917808219}
To lose 0.01*100% of accuracy based on the model above:no-clustering
The minimum number of neurons needed is 107
The accuracy of the minimum neuron set is {'__OVERALL__': 0.928082191780822, 'NAME': 0.9863013698630136, 'STRING': 0.9917808219178083, 'NUMBER': 0.9753424657534246, 'KEYWORD': 0.7589041095890411}

Clustering threshold:0.3
The number of independent neurons:764
The number of clusters:768
The probing result (CC score) is :{'__OVERALL__': 0.8753424657534247, 'NAME': 0.9835616438356164, 'STRING': 1.0, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.5260273972602739}
To lose 0.01*100% of accuracy based on the model above:clustering-0.3
The minimum number of neurons needed is 268
The accuracy of the minimum neuron set is {'__OVERALL__': 0.8965753424657534, 'NAME': 0.9424657534246575, 'STRING': 1.0, 'NUMBER': 0.989041095890411, 'KEYWORD': 0.6547945205479452}

The result of Layerwise (LS):
Keep the layer from 0 to 0
The best layer delta:0.03
The best number of neurons:768
The best accuracy:0.9089041095890411
The best percentage reduction: 0.8571428571428572

The result of LS+CC+LCA
Keep the layer from 0 to 0
The best performance delta: 0.03,0.01
The best clustering threshold:-1
The best number of neurons:107
The best accuracy: 0.928082191780822
The best neuron percentage reduction: 0.9800967261904762

probe independent neurons based on all layers with clustering (run_cc_all.py)
When no clustering:
The probing result (CC score) is :{'__OVERALL__': 0.9054794520547945, 'NAME': 0.9424657534246575, 'STRING': 0.9972602739726028, 'NUMBER': 1.0, 'KEYWORD': 0.6821917808219178}
Clustering threshold:0.1
The number of independent neurons:4894
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.8972602739726028, 'NAME': 0.8849315068493151, 'STRING': 1.0, 'NUMBER': 0.9945205479452055, 'KEYWORD': 0.7095890410958904}
Clustering threshold:0.2
The number of independent neurons:3326
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9089041095890411, 'NAME': 0.9013698630136986, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.736986301369863}
Clustering threshold:0.3
The number of independent neurons:2364
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9095890410958904, 'NAME': 0.9232876712328767, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.7178082191780822}
Clustering threshold:0.4
The number of independent neurons:1754
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9116438356164384, 'NAME': 0.9561643835616438, 'STRING': 1.0, 'NUMBER': 0.9972602739726028, 'KEYWORD': 0.6931506849315069}
Clustering threshold:0.5
The number of independent neurons:1285
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9123287671232877, 'NAME': 0.9671232876712329, 'STRING': 0.9972602739726028, 'NUMBER': 0.9917808219178083, 'KEYWORD': 0.6931506849315069}
Clustering threshold:0.6
The number of independent neurons:915
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9054794520547945, 'NAME': 0.7150684931506849, 'STRING': 1.0, 'NUMBER': 0.9835616438356164, 'KEYWORD': 0.9232876712328767}
Clustering threshold:0.7
The number of independent neurons:570
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.9260273972602739, 'NAME': 0.8328767123287671, 'STRING': 1.0, 'NUMBER': 0.9863013698630136, 'KEYWORD': 0.8849315068493151}
Clustering threshold:0.8
The number of independent neurons:207
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.910958904109589, 'NAME': 0.9287671232876712, 'STRING': 1.0, 'NUMBER': 0.9506849315068493, 'KEYWORD': 0.7643835616438356}
Clustering threshold:0.9
The number of independent neurons:2
The number of clusters:5376
The probing result (CC score) is :{'__OVERALL__': 0.38972602739726026, 'NAME': 0.12602739726027398, 'STRING': 0.936986301369863, 'NUMBER': 0.22465753424657534, 'KEYWORD': 0.27123287671232876}
The result of CC:
The best clustering threshold is :0.7
The best number of neurons:570
The best accuracy is: 0.9260273972602739
Percentage reduction (neurons):0.8939732142857143

probe independent neurons based on all layers without clustering (run_max_features.py)
The result of LCA:
Based on all layers: from 0 to 6, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is 43
The performance is {'model_name': 'pretrained_CodeBERTa', 'best_l1': 0, 'best_l2': 0.001, 'scores': {'__OVERALL__': 0.8972602739726028, 'NAME': 0.8054794520547945, 'STRING': 0.9698630136986301, 'NUMBER': 0.9232876712328767, 'KEYWORD': 0.8904109589041096}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}}
Percentage reduction (neurons):0.9920014880952381

Probeless:
The result of probeless:
Based on all layers, from 0 to 6, no clustering, to lose only 0.01*100% of accuracy:
The minimum number of neurons needed is :107
The performance is :{'model_name': 'pretrained_CodeBERTa', 'best_l1': 0, 'best_l2': 0.1, 'scores': {'__OVERALL__': 0.8910958904109589, 'NAME': 0.8602739726027397, 'STRING': 0.9972602739726028, 'NUMBER': 0.8958904109589041, 'KEYWORD': 0.810958904109589}, 'intercept': {'__OVERALL__': 0.25, 'NAME': 1.0, 'STRING': 0.0, 'NUMBER': 0.0, 'KEYWORD': 0.0}}
Percentage reduction (neurons):0.9800967261904762
----------------------------------------------------------------
